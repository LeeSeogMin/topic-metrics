{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 전체 구조\n",
    "1. 필요한 라이브러리 import\n",
    "2. 데이터 로드 및 전처리 함수들\n",
    "3. 토픽 모델링 함수들\n",
    "4. 평가 지표 계산 함수들\n",
    "5. LLM 평가 관련 함수들\n",
    "6. 상관관계 분석 함수\n",
    "7. summarize_results 함수\n",
    "8. 메인 실행 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\user\\anaconda3\\envs\\topic\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gensim\n",
    "from gensim import models, corpora, matutils\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.stats import pearsonr, spearmanr, f_oneway, kruskal\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from bertopic import BERTopic\n",
    "from transformers import BertTokenizer, BertModel \n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from scipy.spatial.distance import cityblock, jensenshannon\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 texts from data/academy/business.csv\n",
      "Loaded 80 texts from data/academy/ACL.csv\n",
      "Loaded 80 texts from data/academy/covid.csv\n",
      "Loaded 80 texts from data/media/clothing_review.csv\n",
      "Loaded 80 texts from data/media/vaccine_tweets.csv\n",
      "Loaded 80 texts from data/media/reddit_comments.csv\n",
      "Loaded 80 texts from data/news/20newsgroups.csv\n",
      "Loaded 80 texts from data/news/agnews.csv\n",
      "Loaded 80 texts from data/news/Huffpost.csv\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 선정 함수\n",
    "def load_data(file_path, sample_size=80):\n",
    "    df = pd.read_csv(file_path, header=None, names=['text'])\n",
    "    texts = df['text'].astype(str)\n",
    "\n",
    "    # 샘플링\n",
    "    if len(texts) > sample_size:\n",
    "        texts = texts.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    print(f\"Loaded {len(texts)} texts from {file_path}\")\n",
    "    return texts.tolist()\n",
    "\n",
    "# 데이터셋 로드\n",
    "datasets = {\n",
    "    'academy': {\n",
    "        'business': load_data('data/academy/business.csv'),\n",
    "        'ACL': load_data('data/academy/ACL.csv'),\n",
    "        'covid': load_data('data/academy/covid.csv')\n",
    "    },\n",
    "    'media': {\n",
    "        'clothing_review': load_data('data/media/clothing_review.csv'),\n",
    "        'vaccine_tweets': load_data('data/media/vaccine_tweets.csv'),\n",
    "        'reddit_comments': load_data('data/media/reddit_comments.csv')\n",
    "    },\n",
    "    'news': {\n",
    "        'newsgroups': load_data('data/news/20newsgroups.csv'),\n",
    "        'agnews': load_data('data/news/agnews.csv'),\n",
    "        'Huffpost': load_data('data/news/Huffpost.csv')\n",
    "    }\n",
    "}\n",
    "\n",
    "# VAE 모델 정의\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "def perform_topic_modeling(data, num_topics, model_type):\n",
    "    # Ensure all data is of type string\n",
    "    data = [str(doc) for doc in data if isinstance(doc, str) or pd.notna(doc)]\n",
    "\n",
    "    # Check if num_topics is greater than the number of documents\n",
    "    if num_topics > len(data):\n",
    "        print(f\"Adjusting num_topics from {num_topics} to {len(data)}\")\n",
    "        num_topics = len(data)  # Adjust to the number of documents\n",
    "\n",
    "    # Common vectorizer\n",
    "    vectorizer = CountVectorizer(max_df=0.95, min_df=1, stop_words='english')\n",
    "    doc_term_matrix = vectorizer.fit_transform(data)\n",
    "\n",
    "    # GPU usage setting\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if model_type == 'LDA':\n",
    "        # Create corpus and dictionary for LDA\n",
    "        corpus = matutils.Sparse2Corpus(doc_term_matrix, documents_columns=False)\n",
    "        id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "\n",
    "        # Create LDA model\n",
    "        lda_model = models.LdaMulticore(\n",
    "            corpus=corpus,\n",
    "            id2word=id2word,\n",
    "            num_topics=num_topics,\n",
    "            workers=2,  # Number of cores to use\n",
    "            passes=10,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        return lda_model, vectorizer\n",
    "\n",
    "    elif model_type == 'BERTopic':\n",
    "        # Create BERTopic model\n",
    "        bertopic_model = BERTopic(nr_topics=num_topics)\n",
    "        \n",
    "        # Ensure documents is a Series\n",
    "        if not isinstance(data, pd.Series):\n",
    "            data = pd.Series(data)\n",
    "        \n",
    "        bertopic_topics, _ = bertopic_model.fit_transform(data)\n",
    "\n",
    "        return bertopic_model, None  # BERTopic uses its own vectorizer\n",
    "\n",
    "    elif model_type == 'VAE':\n",
    "        # VAE part\n",
    "        input_dim = doc_term_matrix.shape[1]\n",
    "        hidden_dim = 256\n",
    "        latent_dim = num_topics\n",
    "\n",
    "        vae_model = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
    "        optimizer = torch.optim.Adam(vae_model.parameters(), lr=1e-3)\n",
    "\n",
    "        # VAE training\n",
    "        num_epochs = 2  # 10\n",
    "        batch_size = 128\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(0, doc_term_matrix.shape[0], batch_size):\n",
    "                batch = torch.FloatTensor(doc_term_matrix[i:i+batch_size].toarray()).to(device)\n",
    "                batch = batch / batch.max()  # Normalize batch to between 0 and 1\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                recon_batch, mu, logvar = vae_model(batch)\n",
    "                loss = vae_loss(recon_batch, batch, mu, logvar)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Extract topic words from latent vectors\n",
    "        latent_vectors = []\n",
    "        doc_term_matrix = vectorizer.transform(data)\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, doc_term_matrix.shape[0], 128):\n",
    "                batch = torch.FloatTensor(doc_term_matrix[i:i+128].toarray()).to(device)\n",
    "                mu, logvar = vae_model.encode(batch)\n",
    "                z = vae_model.reparameterize(mu, logvar)\n",
    "                latent_vectors.append(z.cpu().numpy())\n",
    "\n",
    "        latent_vectors = np.vstack(latent_vectors)\n",
    "        kmeans = KMeans(n_clusters=num_topics, random_state=42).fit(latent_vectors)\n",
    "\n",
    "        topics = [[] for _ in range(num_topics)]\n",
    "        for idx, label in enumerate(kmeans.labels_):\n",
    "            doc = data[idx]\n",
    "            topics[label].extend(doc.split())\n",
    "\n",
    "        # Extract top 10 words for each topic\n",
    "        topics = [list(pd.Series(words).value_counts().index[:10]) for words in topics]\n",
    "\n",
    "        # Return VAE model, vectorizer, and topic words\n",
    "        return vae_model, vectorizer, topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸리티 함수들\n",
    "def extract_topics(model_type, model, num_topics, topics=None):\n",
    "    if model_type == 'LDA':\n",
    "        return [model.show_topic(i, topn=10) for i in range(num_topics)]\n",
    "    elif model_type == 'BERTopic':\n",
    "        return [model.get_topic(i) for i in range(num_topics) if model.get_topic(i)]\n",
    "    elif model_type == 'VAE':\n",
    "        return topics  # VAE의 경우 이미 추출된 토픽을 사용\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "\n",
    "# 토픽 간 구별성 지표(distinct) 측정 함수\n",
    "def compute_distinctiveness_score(phi, word_embeddings, reduced_dim=50):\n",
    "    # Step 2: 차원 축소 (선택 사항)\n",
    "    def reduce_dimensionality(embeddings, n_components):\n",
    "        pca = PCA(n_components=n_components)\n",
    "        reduced_embeddings = pca.fit_transform(embeddings)\n",
    "        return reduced_embeddings\n",
    "\n",
    "    # 차원 축소 적용\n",
    "    word_embeddings_reduced = reduce_dimensionality(word_embeddings, reduced_dim)\n",
    "\n",
    "    # Step 3: 토픽 임베딩 계산\n",
    "    def compute_topic_embeddings(phi, word_embeddings):\n",
    "        num_topics = phi.shape[0]\n",
    "        topic_embeddings = np.zeros((num_topics, word_embeddings.shape[1]))\n",
    "        for i in range(num_topics):\n",
    "            weights = phi[i]\n",
    "            weights = weights / weights.sum()  # 가중치 정규화\n",
    "            topic_embedding = np.dot(weights, word_embeddings)\n",
    "            topic_embeddings[i] = topic_embedding\n",
    "        return topic_embeddings\n",
    "\n",
    "    topic_embeddings = compute_topic_embeddings(phi, word_embeddings_reduced)\n",
    "\n",
    "    # Step 4: 토픽 간 거리 계산\n",
    "    def compute_distance_matrix(topic_embeddings, metric='cosine'):\n",
    "        if metric == 'cosine':\n",
    "            distance_matrix = cosine_distances(topic_embeddings)\n",
    "        elif metric == 'euclidean':\n",
    "            distance_matrix = euclidean_distances(topic_embeddings)\n",
    "        elif metric == 'manhattan':\n",
    "            num_topics = topic_embeddings.shape[0]\n",
    "            distance_matrix = np.zeros((num_topics, num_topics))\n",
    "            for i in range(num_topics):\n",
    "                for j in range(i+1, num_topics):\n",
    "                    dist = cityblock(topic_embeddings[i], topic_embeddings[j])\n",
    "                    distance_matrix[i, j] = dist\n",
    "                    distance_matrix[j, i] = dist\n",
    "        else:\n",
    "            raise ValueError(\"지원하지 않는 거리 척도입니다.\")\n",
    "        return distance_matrix\n",
    "\n",
    "    # 거리 행렬 계산 (코사인 거리 사용)\n",
    "    distance_matrix = compute_distance_matrix(topic_embeddings, metric='cosine')\n",
    "\n",
    "    # Step 5: 구별성 점수 계산\n",
    "    def compute_distinctiveness_score(distance_matrix):\n",
    "        num_topics = distance_matrix.shape[0]\n",
    "        # 상삼각 행렬의 값만 사용하여 평균 거리 계산\n",
    "        triu_indices = np.triu_indices(num_topics, k=1)\n",
    "        distances = distance_matrix[triu_indices]\n",
    "        avg_distance = distances.mean()\n",
    "        return avg_distance\n",
    "\n",
    "    distinctiveness_score = compute_distinctiveness_score(distance_matrix)\n",
    "    return distinctiveness_score\n",
    "\n",
    "# Jensen-Shannon Divergence (JSD) 계산 함수\n",
    "def compute_pairwise_jsd(phi):\n",
    "    num_topics = phi.shape[0]\n",
    "    jsd_matrix = np.zeros((num_topics, num_topics))\n",
    "    for i in range(num_topics):\n",
    "        for j in range(i+1, num_topics):\n",
    "            jsd = jensenshannon(phi[i], phi[j])\n",
    "            jsd_matrix[i, j] = jsd\n",
    "            jsd_matrix[j, i] = jsd  # 대칭으로 만듭니다.\n",
    "    return jsd_matrix\n",
    "\n",
    "def compute_average_jsd(jsd_matrix):\n",
    "    num_topics = jsd_matrix.shape[0]\n",
    "    # 상삼각 행렬의 값만 사용하여 평균을 계산합니다.\n",
    "    triu_indices = np.triu_indices(num_topics, k=1)\n",
    "    avg_jsd = jsd_matrix[triu_indices].mean()\n",
    "    return avg_jsd\n",
    "\n",
    "# Hellinger Distance 계산 함수\n",
    "def compute_pairwise_hellinger(phi):\n",
    "    num_topics = phi.shape[0]\n",
    "    hellinger_matrix = np.zeros((num_topics, num_topics))\n",
    "    for i in range(num_topics):\n",
    "        sqrt_phi_i = np.sqrt(phi[i])\n",
    "        for j in range(i+1, num_topics):\n",
    "            sqrt_phi_j = np.sqrt(phi[j])\n",
    "            distance = np.linalg.norm(sqrt_phi_i - sqrt_phi_j) / np.sqrt(2)\n",
    "            hellinger_matrix[i, j] = distance\n",
    "            hellinger_matrix[j, i] = distance  # 대칭으로 만듭니다.\n",
    "    return hellinger_matrix\n",
    "\n",
    "def compute_average_hellinger(hellinger_matrix):\n",
    "    num_topics = hellinger_matrix.shape[0]\n",
    "    # 상삼각 행렬의 값만 사용하여 평균을 계산합니다.\n",
    "    triu_indices = np.triu_indices(num_topics, k=1)\n",
    "    avg_hellinger = hellinger_matrix[triu_indices].mean()\n",
    "    return avg_hellinger\n",
    "\n",
    "# 평가 지표 계산 통합 함수\n",
    "\n",
    "# BERT 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model = bert_model.to(device)\n",
    "\n",
    "def calculate_evaluation_metrics(model, data, model_type, vectorizer=None, num_topics=10, topics=None):\n",
    "    if model_type == 'LDA':\n",
    "        phi = model.get_topics()\n",
    "    elif model_type == 'BERTopic':\n",
    "        phi = np.array([model.get_topic(i) for i in range(num_topics)])\n",
    "    elif model_type == 'VAE':\n",
    "        phi = model.fc4.weight.data.cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "\n",
    "    # BERT를 사용하여 단어 임베딩 생성\n",
    "    vocab = vectorizer.get_feature_names() if vectorizer else list(set([word for topic in topics for word in topic]))\n",
    "    word_embeddings = []\n",
    "    \n",
    "    for word in vocab:\n",
    "        inputs = tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        word_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # [CLS] 토큰의 임베딩 사용\n",
    "        word_embeddings.append(word_embedding)\n",
    "\n",
    "    word_embeddings = np.vstack(word_embeddings)\n",
    "\n",
    "    # Distinctiveness 계산\n",
    "    distinctiveness = compute_distinctiveness_score(phi, word_embeddings)\n",
    "\n",
    "    # JSD 계산\n",
    "    jsd_matrix = compute_pairwise_jsd(phi)\n",
    "    avg_jsd = compute_average_jsd(jsd_matrix)\n",
    "\n",
    "    # Hellinger Distance 계산\n",
    "    hellinger_matrix = compute_pairwise_hellinger(phi)\n",
    "    avg_hellinger = compute_average_hellinger(hellinger_matrix)\n",
    "\n",
    "    return distinctiveness, avg_jsd, avg_hellinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(metrics_df):\n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "    # 지표 목록\n",
    "    metric_names = ['Distinctiveness', 'JSD', 'Hellinger']\n",
    "\n",
    "    # 모델별, 토픽 수별로 상관관계 계산\n",
    "    for model in metrics_df['Model'].unique():\n",
    "        for num_topics in metrics_df['Num_Topics'].unique():\n",
    "            subset = metrics_df[(metrics_df['Model'] == model) & (metrics_df['Num_Topics'] == num_topics)]\n",
    "            if len(subset) < 2:\n",
    "                continue  # 상관계수를 계산하기 위한 데이터가 충분하지 않으면 건너뜀\n",
    "            print(f\"\\n상관관계 분석 - 모델: {model}, 토픽 수: {num_topics}\")\n",
    "            for i in range(len(metric_names)):\n",
    "                for j in range(i+1, len(metric_names)):\n",
    "                    metric1 = metric_names[i]\n",
    "                    metric2 = metric_names[j]\n",
    "                    pearson_corr, p_value_pearson = pearsonr(subset[metric1], subset[metric2])\n",
    "                    spearman_corr, p_value_spearman = spearmanr(subset[metric1], subset[metric2])\n",
    "                    print(f\"{metric1} vs {metric2}:\")\n",
    "                    print(f\"  Pearson: 상관계수 = {pearson_corr:.4f}, p-value = {p_value_pearson:.4f}\")\n",
    "                    print(f\"  Spearman: 상관계수 = {spearman_corr:.4f}, p-value = {p_value_spearman:.4f}\")\n",
    "\n",
    "    # 전체 데이터에 대한 상관관계 분석\n",
    "    print(\"\\n전체 데이터에 대한 상관관계 분석:\")\n",
    "    for i in range(len(metric_names)):\n",
    "        for j in range(i+1, len(metric_names)):\n",
    "            metric1 = metric_names[i]\n",
    "            metric2 = metric_names[j]\n",
    "            pearson_corr, p_value_pearson = pearsonr(metrics_df[metric1], metrics_df[metric2])\n",
    "            spearman_corr, p_value_spearman = spearmanr(metrics_df[metric1], metrics_df[metric2])\n",
    "            print(f\"{metric1} vs {metric2}:\")\n",
    "            print(f\"  Pearson: 상관계수 = {pearson_corr:.4f}, p-value = {p_value_pearson:.4f}\")\n",
    "            print(f\"  Spearman: 상관계수 = {spearman_corr:.4f}, p-value = {p_value_spearman:.4f}\")\n",
    "\n",
    "# LLM 평가 함수\n",
    "def call_openai_api(prompt: str, max_tokens: int = 3000) -> str:\n",
    "    client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    full_response = \"\"\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an expert in topic modeling and text analysis. Your task is to evaluate the coherence of topics based on provided documents.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt + (\"\\n\\nContinue from: \" + full_response if full_response else \"\")\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=max_tokens,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0.1,\n",
    "                presence_penalty=0.1,\n",
    "            )\n",
    "            chunk = response.choices[0].message.content\n",
    "            full_response += chunk\n",
    "            \n",
    "            if not response.choices[0].finish_reason == \"length\":\n",
    "                break\n",
    "            \n",
    "            prompt = \"Continue the previous response:\"\n",
    "        except openai.error.RateLimitError:\n",
    "            print(\"Rate limit exceeded. Retrying...\")\n",
    "            time.sleep(60)  # Wait for 60 seconds before retrying\n",
    "        except openai.error.AuthenticationError:\n",
    "            print(\"Authentication error. Check your API key.\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            raise\n",
    "    return full_response\n",
    "\n",
    "def llm_evaluation(topics, documents, model=\"gpt-4o-mini\"):\n",
    "    scores = []\n",
    "    feedbacks = []\n",
    "\n",
    "    if not isinstance(documents, list):\n",
    "        documents = list(documents)\n",
    "\n",
    "    for topic_words in topics:\n",
    "        topic = ', '.join(topic_words)\n",
    "        docs_sample = documents[:3]\n",
    "        prompt = f\"\"\"\n",
    "주어진 토픽과 관련 문서를 평가해주세요. 다음 기준에 따라 1-10 척도로 점수를 매겨주세요:\n",
    "일관성: 토픽 내 단어들이 의미적으로 얼마나 연관되어 있는가?\n",
    "\n",
    "토픽: {topic}\n",
    "관련 문서 샘플:\n",
    "{docs_sample}\n",
    "\n",
    "일관성에 대해 1-10 점수를 매기고, 간단한 설명을 덧붙여주세요.\n",
    "\"\"\"\n",
    "        try:\n",
    "            evaluation = call_openai_api(prompt)\n",
    "\n",
    "            match = re.search(r'(\\d+)', evaluation)\n",
    "            if match:\n",
    "                topic_score = int(match.group(1))\n",
    "                scores.append(topic_score)\n",
    "                feedbacks.append(evaluation)\n",
    "            else:\n",
    "                print(f\"점수를 추출할 수 없습니다: {evaluation}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            raise\n",
    "\n",
    "    return scores, feedbacks\n",
    "\n",
    "def analyze_llm_results(llm_df):\n",
    "    llm_df['LLM_Avg_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.mean([s for s in scores if s is not None]))\n",
    "    llm_df['LLM_Std_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.std([s for s in scores if s is not None]))\n",
    "    llm_df['LLM_Median_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.median([s for s in scores if s is not None]))\n",
    "\n",
    "    print(\"\\nLLM 평가 결과:\")\n",
    "    print(llm_df[['Domain', 'Model', 'Num_Topics', 'LLM_Avg_Score', 'LLM_Std_Score', 'LLM_Median_Score']])\n",
    "\n",
    "def llm_auto_metric_correlation(metrics_df, llm_df):\n",
    "    merged_df = pd.merge(metrics_df, llm_df, on=['Domain', 'Dataset', 'Model', 'Num_Topics'])\n",
    "\n",
    "    metric_names = ['Distinctiveness', 'JSD', 'Hellinger']\n",
    "    for metric in metric_names:\n",
    "        valid_idx = merged_df['LLM_Avg_Score'].notnull()\n",
    "        pearson_corr, p_value_pearson = pearsonr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n",
    "        spearman_corr, p_value_spearman = spearmanr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n",
    "        print(f\"\\nLLM 평가 점수와 {metric}의 상관관계:\")\n",
    "        print(f\"Pearson: 상관계수 = {pearson_corr:.4f}, p-value = {p_value_pearson:.4f}\")\n",
    "        print(f\"Spearman: 상관계수 = {spearman_corr:.4f}, p-value = {p_value_spearman:.4f}\")\n",
    "\n",
    "def verify_llm_consistency(topics, documents, n_repeats=5):\n",
    "    all_scores = []\n",
    "    for _ in range(n_repeats):\n",
    "        scores, _ = llm_evaluation(topics, documents)\n",
    "        all_scores.append(scores)\n",
    "    all_scores = np.array(all_scores)\n",
    "    std_scores = np.std(all_scores, axis=0)\n",
    "    avg_std = np.mean(std_scores)\n",
    "    cv_scores = std_scores / np.mean(all_scores, axis=0)\n",
    "    avg_cv = np.mean(cv_scores)\n",
    "    print(f\"\\nLLM 평가의 평균 표준편차: {avg_std:.4f}\")\n",
    "    print(f\"LLM 평가의 평균 변동계수(CV): {avg_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(metrics_df, llm_df):\n",
    "    print(\"\\n=== 결과 요약 ===\")\n",
    "    \n",
    "    # 모델별, 토픽 수별, 도메인별 평균 성능 비교\n",
    "    for groupby_col in ['Model', 'Num_Topics', 'Domain']:\n",
    "        print(f\"\\n{groupby_col}별 평균 성능:\")\n",
    "        print(metrics_df.groupby(groupby_col)[['Distinctiveness', 'JSD', 'Hellinger']].mean())\n",
    "    \n",
    "    # LLM 평가 결과\n",
    "    if llm_df is not None:\n",
    "        print(\"\\nLLM 평가 결과:\")\n",
    "        print(llm_df.groupby('Model')['LLM_Avg_Score'].mean())\n",
    "    \n",
    "    # 최고 성능 모델\n",
    "    best_models = {\n",
    "        'Distinctiveness': metrics_df.loc[metrics_df['Distinctiveness'].idxmax()],\n",
    "        'JSD': metrics_df.loc[metrics_df['JSD'].idxmin()],\n",
    "        'Hellinger': metrics_df.loc[metrics_df['Hellinger'].idxmin()]\n",
    "    }\n",
    "    \n",
    "    print(\"\\n최고 성능 모델:\")\n",
    "    for metric, best_model in best_models.items():\n",
    "        print(f\"{metric}: {best_model['Model']} (토픽 수: {best_model['Num_Topics']}, 점수: {best_model[metric]:.4f})\")\n",
    "    \n",
    "    # 결론 및 해석\n",
    "    print(\"\\n결론 및 해석:\")\n",
    "    print(\"1. 전반적으로 가장 좋은 성능을 보인 모델은 ...\")\n",
    "    print(\"2. 토픽 수에 따른 성능 변화를 보면 ...\")\n",
    "    print(\"3. 도메인별 성능 차이는 ...\")\n",
    "    print(\"4. Distinctiveness, JSD, Hellinger 지표 간의 관계는 ...\")\n",
    "    print(\"5. LLM 평가 결과와 자동 평가 지표 간의 일치도는 ...\")\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == '__main__':\n",
    "    # 평가 지표 결과 저장을 위한 데이터프레임 초기화\n",
    "    metrics_list = []\n",
    "\n",
    "    # 계산 시간 저장을 위한 딕셔너리 초기화\n",
    "    computation_times = {}\n",
    "\n",
    "    # 모델 유형 및 토픽 수 설정\n",
    "    model_types = ['LDA', 'BERTopic', 'VAE']\n",
    "    num_topics_list = [2, 4]\n",
    "\n",
    "    # 토픽 모델링 및 지표 계산\n",
    "    for domain, domain_datasets in datasets.items():\n",
    "        for dataset_name, data in domain_datasets.items():\n",
    "            print(f\"\\nProcessing {domain} - {dataset_name}\")\n",
    "            for model_type in model_types:\n",
    "                for num_topics in num_topics_list:\n",
    "                    print(f\"\\nModel: {model_type}, Num Topics: {num_topics}\")\n",
    "                    try:\n",
    "                        start_time = time.time()\n",
    "                        if model_type == 'VAE':\n",
    "                            model, vectorizer, topics = perform_topic_modeling(data, num_topics, model_type)\n",
    "                        else:\n",
    "                            model, vectorizer = perform_topic_modeling(data, num_topics, model_type)\n",
    "                            topics = None  # VAE가 아닌 경우\n",
    "                        topic_modeling_time = time.time() - start_time\n",
    "\n",
    "                        start_time = time.time()\n",
    "                        distinctiveness, jsd, hellinger = calculate_evaluation_metrics(model, data, model_type, vectorizer, num_topics, topics)\n",
    "                        evaluation_time = time.time() - start_time\n",
    "\n",
    "                        # 결과 저장\n",
    "                        metrics_list.append({\n",
    "                            'Domain': domain,\n",
    "                            'Dataset': dataset_name,\n",
    "                            'Model': model_type,\n",
    "                            'Num_Topics': num_topics,\n",
    "                            'Distinctiveness': distinctiveness,\n",
    "                            'JSD': jsd,\n",
    "                            'Hellinger': hellinger\n",
    "                        })\n",
    "\n",
    "                        computation_times[f\"{domain}_{dataset_name}_{model_type}_{num_topics}\"] = {\n",
    "                            'Topic Modeling': topic_modeling_time,\n",
    "                            'Evaluation': evaluation_time\n",
    "                        }\n",
    "\n",
    "                        print(f\"Distinctiveness: {distinctiveness:.4f}\")\n",
    "                        print(f\"JSD: {jsd:.4f}\")\n",
    "                        print(f\"Hellinger: {hellinger:.4f}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {domain} - {dataset_name} - {model_type} - {num_topics}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "    # metrics_df 생성\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # 상관관계 분석 실행\n",
    "    correlation_analysis(metrics_df)\n",
    "\n",
    "    # LLM 평가 실행 (선택적)\n",
    "    llm_df = llm_evaluation(metrics_df, datasets)\n",
    "\n",
    "    # LLM 평가 결과 분석\n",
    "    analyze_llm_results(llm_df)\n",
    "\n",
    "    # LLM 평가와 자동 평가 지표 간의 상관관계 분석\n",
    "    llm_auto_metric_correlation(metrics_df, llm_df)\n",
    "\n",
    "    # LLM 평가의 일관성 검증\n",
    "    verify_llm_consistency(topics, documents)\n",
    "\n",
    "    # 결과 종합 및 해석\n",
    "    summarize_results(metrics_df, llm_df)\n",
    "\n",
    "    # 결과 분석 및 시각화 함수\n",
    "    def analyze_results(metrics_df):\n",
    "        metrics = ['Distinctiveness', 'JSD', 'Hellinger']\n",
    "        \n",
    "        # 모델별 성능 비교 및 토픽 수에 따른 성능 변화\n",
    "        for metric in metrics:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.boxplot(x='Model', y=metric, data=metrics_df)\n",
    "            plt.title(f'Model {metric} Comparison')\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.lineplot(x='Num_Topics', y=metric, hue='Model', data=metrics_df)\n",
    "            plt.title(f'{metric} vs Number of Topics')\n",
    "            plt.show()\n",
    "\n",
    "        # 도메인별 성능 비교\n",
    "        for metric in metrics:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.boxplot(x='Domain', y=metric, data=metrics_df)\n",
    "            plt.title(f'{metric} Comparison by Domain')\n",
    "            plt.show()\n",
    "\n",
    "        # 상관관계 분석\n",
    "        correlation_matrix = metrics_df[metrics].corr()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "        plt.title('Correlation between Evaluation Metrics')\n",
    "        plt.show()\n",
    "\n",
    "    # 결과 분석 실행\n",
    "    analyze_results(metrics_df)\n",
    "\n",
    "    print(\"실험 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
