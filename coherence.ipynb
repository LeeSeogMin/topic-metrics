{"cells":[{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-11 10:57:07,314 - INFO - 데이터셋 로딩 시작\n","2024-10-11 10:57:07,431 - INFO - 토픽 모델링 및 메트릭 계산 시작\n","2024-10-11 10:57:07,435 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:07,436 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"]},{"name":"stdout","output_type":"stream","text":["Loaded 100 texts from data/academy/business.csv\n","Loaded 100 texts from data/media/clothing_review.csv\n","Loaded 100 texts from data/news/agnews.csv\n"]},{"name":"stderr","output_type":"stream","text":["2024-10-11 10:57:12,324 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:12,340 - INFO - built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\n","2024-10-11 10:57:12,340 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\", 'datetime': '2024-10-11T10:57:12.340630', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:12,579 - INFO - Coherence: 0.9424, NPMI: 0.0371, U_Mass: -0.9558\n","2024-10-11 10:57:12,608 - INFO - 에폭 1/5, 손실: 841.3606\n","2024-10-11 10:57:12,616 - INFO - 에폭 2/5, 손실: 826.9162\n","2024-10-11 10:57:12,625 - INFO - 에폭 3/5, 손실: 812.4379\n","2024-10-11 10:57:12,633 - INFO - 에폭 4/5, 손실: 799.4985\n","2024-10-11 10:57:12,642 - INFO - 에폭 5/5, 손실: 785.6868\n","2024-10-11 10:57:12,660 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:12,673 - INFO - built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\n","2024-10-11 10:57:12,674 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\", 'datetime': '2024-10-11T10:57:12.674079', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:12,860 - INFO - Coherence: 0.9208, NPMI: 0.5294, U_Mass: -1.2842\n","2024-10-11 10:57:12,865 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:12,865 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:16,987 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:16,993 - INFO - built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\n","2024-10-11 10:57:16,994 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\", 'datetime': '2024-10-11T10:57:16.994054', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:17,173 - INFO - Coherence: 0.9416, NPMI: 0.0918, U_Mass: -1.3522\n","2024-10-11 10:57:17,186 - INFO - 에폭 1/5, 손실: 255.6215\n","2024-10-11 10:57:17,193 - INFO - 에폭 2/5, 손실: 251.9327\n","2024-10-11 10:57:17,200 - INFO - 에폭 3/5, 손실: 248.0143\n","2024-10-11 10:57:17,208 - INFO - 에폭 4/5, 손실: 244.0069\n","2024-10-11 10:57:17,213 - INFO - 에폭 5/5, 손실: 240.5773\n","2024-10-11 10:57:17,218 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:17,222 - INFO - built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\n","2024-10-11 10:57:17,224 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\", 'datetime': '2024-10-11T10:57:17.224058', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:17,443 - INFO - Coherence: 0.9127, NPMI: 0.4898, U_Mass: -1.3613\n","2024-10-11 10:57:17,448 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:17,449 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:21,974 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:21,978 - INFO - built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\n","2024-10-11 10:57:21,979 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\", 'datetime': '2024-10-11T10:57:21.979360', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:22,151 - INFO - Coherence: 0.9173, NPMI: 0.4260, U_Mass: -1.3618\n","2024-10-11 10:57:22,165 - INFO - 에폭 1/5, 손실: 170.2076\n","2024-10-11 10:57:22,171 - INFO - 에폭 2/5, 손실: 166.7083\n","2024-10-11 10:57:22,178 - INFO - 에폭 3/5, 손실: 163.4622\n","2024-10-11 10:57:22,184 - INFO - 에폭 4/5, 손실: 160.2511\n","2024-10-11 10:57:22,191 - INFO - 에폭 5/5, 손실: 157.4440\n","2024-10-11 10:57:22,195 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:22,199 - INFO - built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\n","2024-10-11 10:57:22,200 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\", 'datetime': '2024-10-11T10:57:22.200362', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:22,411 - INFO - Coherence: 0.9392, NPMI: 0.4428, U_Mass: -1.2835\n","2024-10-11 10:57:22,412 - INFO - BERTopic 결과 출력\n","2024-10-11 10:57:22,413 - INFO - \n","VAE 결과 출력\n","2024-10-11 10:57:22,414 - INFO - 메트릭 분석 시작\n","2024-10-11 10:57:22,417 - INFO - 일치도 분석 시작\n","2024-10-11 10:57:22,422 - INFO - 안정성 분석 시작\n","2024-10-11 10:57:22,423 - INFO - Analyzing stability for domain: academy\n","2024-10-11 10:57:22,423 - INFO - Original data type: <class 'list'>\n","2024-10-11 10:57:22,424 - INFO - Processed data type: <class 'list'>\n","2024-10-11 10:57:22,425 - INFO - Sample of processed data: ['collection big data different source internet thing social medium search engine created significant opportunity businesstobusiness bb industrial marketing organization take analytical view developing programmatic marketing approach online display advertising cleansing processing analyzing large datasets create challenge marketing organization particularly realtime decision making comparative implication importantly limited research interplay utilizing problematization approach paper contributes exploration link big data programmatic marketing realtime processing relevant decision making bb industrial marketing organization depend big datadriven marketing big datasavvy manager exploration subsequently encompasses appropriate big data source effective batch realtime processing linked structured unstructured datasets influence relative processing technique consequently along direction future research paper develops interdisciplinary dialogue overlay computerengineering framework apache storm hadoop within bb marketing viewpoint implication contemporary marketing practice', 'development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm', 'field data science emerged recent year building advance computational statistic machine learning artificial intelligence big data modern organization immersed data turning toward data science address variety business problem numerous complex problem science become solvable data science scientific solution equally applicable business many dataintensive business problem situated complex sociopolitical behavioral context still elude commonly used scientific method extent problem addressed data science data science inherent blind spot regard type business problem likely addressed data science near future develop conceptual framework inform application data science business framework draw extensive review data science literature across four domain data method interface cognition draw ashbys law requisite variety theoretical principle conclude datascientific advance across four domain aggregate could constitute requisite variety particular type business problem explains problem fully partially addressed solved automated data science distinguish situation improved due crossdomain compensatory effect problem data science best contributes merely better understanding complex phenomenon', 'product review play crucial role providing valuable insight consumer producer analyzing vast amount data generated around product post comment view challenging business intelligence purpose sentiment analysis content help consumer producer gain better understanding market status enabling make informed decision study propose novel hybrid approach based deep neural network dnns sentiment analysis product review focusing classification sentiment expressed approach utilizes recursive neural network rnn algorithm sentiment classification address imbalanced distribution positive negative sample social network data employ resampling technique balance dataset increasing sample minority class decreasing sample majority class evaluate approach using amazon data comprising four product category clothing car luxury good household appliance experimental result demonstrate proposed approach performs well sentiment analysis product review particularly context digital marketing furthermore attentionbased rnn algorithm outperforms baseline rnn approximately notably study reveals consumer sentiment variation across different product particularly relation appearance price aspect', 'sentiment analysis emerged one prominent research branch endless usage application monitoring social medium forum blog online resource customer review product competition survey response understand customer insight significant importance business analytics proliferation informal user generated data online use mixed language become common phenomenon mixed language arises use linguistic code switching lcs practice using one language single sentence mixed language rarely subject sentiment analysis lack clear grammatical structure render previous approach sentiment analysis ineffective text paper propose strategy determine sentiment sentence written mixed language comprising hindi english lexicon technique used analyze sentiment data belonging one source language well mixed language data grammatical transition common mixed language taken account sentiment analysis demonstrate effectiveness proposed approach via case study social medium data set']\n","2024-10-11 10:57:22,430 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:22,431 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"]},{"name":"stdout","output_type":"stream","text":["\n","도메인: academy\n","BERTopic 토픽 수: 3\n","BERTopic 토픽:\n","  토픽 1: social, medium, analysis, data, business, sentiment, user, approach, research, study\n","  토픽 2: data, analytics, big, business, research, information, organization, unstructured, knowledge, decision\n","\n","도메인: media\n","BERTopic 토픽 수: 4\n","BERTopic 토픽:\n","  토픽 1: top, great, look, color, like, love, back, fit, one, bit\n","  토픽 2: dress, quality, fit, get, fabric, expected, like, would, little, button\n","  토픽 3: size, medium, small, fit, wear, dress, sizing, waist, im, thought\n","\n","도메인: news\n","BERTopic 토픽 수: 4\n","BERTopic 토픽:\n","  토픽 1: new, company, reuters, stock, tuesday, software, linux, york, oil, quot\n","  토픽 2: player, field, oakland, quarterback, texas, game, tuesday, phelps, frank, college\n","  토픽 3: said, american, militant, killed, baghdad, iraq, one, hostage, bomber, army\n","\n","도메인: academy\n","VAE 토픽 수: 3\n","VAE 토픽:\n","  토픽 1: adjust, utilizing, evaluated, utilize, dataintensive, set, direct, lead, identifying, space\n","  토픽 2: coding, conceptualize, gartner, common, studied, evidence, banking, sociological, given, currently\n","  토픽 3: banking, evidence, gartner, utilization, landscape, coding, meaningful, importantly, conceptualize, google\n","\n","도메인: media\n","VAE 토픽 수: 4\n","VAE 토픽:\n","  토픽 1: maybe, bad, body, day, felt, appropriate, sheer, star, bra, winter\n","  토픽 2: felt, day, good, sheer, spend, cute, gorgeous, pilcro, definitely, delicate\n","  토픽 3: pair, use, touch, place, sheer, lb, gave, collar, bad, stay\n","  토픽 4: pair, pleat, tie, slim, good, typically, felt, longer, pilcro, bad\n","\n","도메인: news\n","VAE 토픽 수: 4\n","VAE 토픽:\n","  토픽 1: decision, inning, reached, slightly, new, dollar, saudi, relatively, investor, federal\n","  토픽 2: fan, head, francisco, linux, new, claimed, violence, island, official, hostage\n","  토픽 3: relatively, reached, new, official, federal, month, fan, head, computer, claim\n","  토픽 4: relatively, new, investor, head, hostage, identified, fan, federal, reached, slightly\n","\n","일치도 분석 결과 (Spearman 상관계수):\n","Coherence vs NPMI: -0.7143\n","Coherence vs U_Mass: 0.7714\n","NPMI vs U_Mass: -0.2571\n"]},{"name":"stderr","output_type":"stream","text":["2024-10-11 10:57:27,255 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:57:27,256 - INFO - Sample of sampled data: ['purpose purpose paper mine competitive intelligence social medium find market insight comparing consumer opinion sale performance business one competitor analyzing public social medium data designmethodologyapproach exploratory test using multiple case study approach used compare two competing smartphone manufacturer opinion mining sentiment analysis conducted first followed validation result using statistical analysis total tweet mentioning iphone galaxy collected four month following release iphone analyzed using natural language processing lexiconbased sentiment analysis purchase intention classification finding analysis showed social medium data contain competitive intelligence volume tweet revealed significant gap market leader one follower purchase intention data also reflected gap less pronounced extent addition author assessed whether social opinion could explain sale performance gap competitor found social opinion gap similar shipment gap research limitationsimplications study compared social medium opinion shipment gap two rival smart phone business take consumer opinion toward product also toward product competitor social medium analytics furthermore business predict market sale performance estimate gap competing product result decision maker adjust market strategy rapidly compensate weakness contrasting rival well originalityvalue paper main contribution demonstrat competitive intelligence via consumer opinion mining social medium data researcher business analyst practitioner adopt method social medium analysis achieve objective implement practical procedure data collection spam elimination machine learning classification sentiment analysis feature categorization result visualization', 'modern audit engagement often involve examination client using big data analytics remain competitive relevant today business environment client system integrated cloud internet thing external data source social medium furthermore many engagement client integrating big data new complex business analytical approach generate intelligence decision making scenario provides almost limitless opportunity urgency external auditor utilize advanced analytics paper first position need external audit profession move toward big data audit analytics review regulation regarding audit evidence analytical procedure contrast emerging environment big data advanced analytics big data environment audit profession potential undertake advanced predictive prescriptiveoriented analytics next section proposes discusses six key research question idea followed emphasis research need quantification measurement reporting paper provides synthesis review concern facing audit community growing use big data complex analytics client contributes literature expanding upon emerging concern providing opportunity future research', 'organization develop manage employee data analytics skill create business value enhance organizational competitive advantage order address prominent critical research question research conceptualize operationalize data analytics skill individual level develop nomological network model examine critical antecedent outcome lens adaptation structuration theory test core proposition research model using survey data collected frontline employee three dataintensive research institute china discover datadriven culture data analytics affordance individual absorptive capacity positively associated employee data analytics skill turn positive influence task innovative performance classify employee digital immigrant digital native based age examine different influence three salient antecedent data analytics skill two group research finding suggest datadriven culture play significant role driving data analytics skill digital immigrant data analytics affordance exhibit stronger influence data analytics skill digital native', 'cooperative work process analysis decision support currently gain strong attention business world motivated spreading corporate structure technical development like social medium networkoriented data storage encourage user comprehension demand easy communication data article reflects state research domain business intelligence regarding opening process new data source analyst existing approach often labeled collaborative business intelligence cbi differ heavily definition focus therefore framework presented three main field research cbi identified encompass internal communication data storage external partner data analysis partner article compare finding development software market describes open topic research domain', 'decision making required organization however decisionmaking style may differ commonly used decision style include autocratic democratic consensus participatory globalization expansion business professional become highly dependent upon technology support decisionmaking process decisionsupport system come fastest growing discipline present work discusses evolution computerized decision support considering modeldriven datadriven communicationdriven documentdriven knowledgedriven decisionsupport system three different business levelsoperational tactical strategichave considered present work review development decisionsupport system traditional data analysisbased approach compared latest data analytics approach including social medium analytics web analytics example different industry sector incorporated better illustration decision support']\n","2024-10-11 10:57:27,260 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:27,261 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:31,936 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:31,948 - INFO - built Dictionary<2410 unique tokens: ['achieve', 'addition', 'adjust', 'adopt', 'also']...> from 80 documents (total 9425 corpus positions)\n","2024-10-11 10:57:31,949 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2410 unique tokens: ['achieve', 'addition', 'adjust', 'adopt', 'also']...> from 80 documents (total 9425 corpus positions)\", 'datetime': '2024-10-11T10:57:31.949595', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:32,089 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:57:32,090 - INFO - Sample of sampled data: ['study aim provide comprehensive network analysis understand current state big data research tourism investigating multidisciplinary contribution relevant big data comprehensive network analytical method includes cocitation clustering trend analysis applied systematically analyse publication two unique data set web science collected first data set focus big data research tourism hospitality second data set involves discipline computer science comparison tourism result suggest application social medium usergenerated content gaining momentum whereas theorybased study big data tourism remain limited tourism relevant domain similar concern challenge involved big data privacy data quality appropriate data use comparative network analysis implication future big data research tourism', 'analysis social medium increased importance understanding human behavior interest opinion business intelligence based social medium reduce cost managing customer trend complexity paper focus analyzing sensation information representing human perceptual experience social medium five sens sight hearing touch smell taste first measurement defined estimate social sensation intensity subsequently sensation characteristic geosocial medium identified using geospatial footprint finally evaluate accuracy fmeasure approach comparing baseline', 'development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm', 'opinion leader key participant emerge social medium identifying influential user help decision maker effectively target source influence hence bring change community research developed approach identifying influential user online social network interest policy maker general public present finding empirical study u immigration reform discussion user posted tweet maynovember present finding analysis provide list influential user identified discus implication predictive analytics social medium analytics research contribute providing new case new empirical finding applying influence analytics analyzing social medium network strong implication predictive analytics business intelligence social medium analytics', 'study attempt analyze value graffiti tour perspective sustainable tourism examining actual review social medium user using text mining social network analysis text mining technique indicates artist history political culture social city background great recommend excellent worth frequently used keywords review comparing word frequency per review result show word history political culture social frequently used time furthermore network visualization show word connoting sociocultural sustainability mutually connected therefore study suggests graffiti tour potential assuming role sustainable tourism since keywords review associated perspective sociocultural sustainability']\n","2024-10-11 10:57:32,094 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:32,094 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:36,796 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:36,809 - INFO - built Dictionary<2465 unique tokens: ['aim', 'analyse', 'analysis', 'analytical', 'application']...> from 80 documents (total 9659 corpus positions)\n","2024-10-11 10:57:36,810 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2465 unique tokens: ['aim', 'analyse', 'analysis', 'analytical', 'application']...> from 80 documents (total 9659 corpus positions)\", 'datetime': '2024-10-11T10:57:36.810006', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:36,951 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:57:36,952 - INFO - Sample of sampled data: ['increasing number social medium user affect individual corporation user banking sector example use social medium support social customer relationship management activity investigate dynamic evolution conversation network bank customer using social network analysis methodology measurement conducted calculating network property see characteristic active network customer talking bank service also express opinion social medium therefore perform sentiment analysis classify customer opinion positive negative neutral class research performed twitter conversation bank mandiri bank central asia bca bank negara indonesia bni result research beneficial business intelligence purpose support decision making', 'popularity online content social medium frequently experience ebb flow thus evolution often involves different stage burst valley exploring pattern popularity evolution especially burst form decay even predicting trend popularity evolution important research topic beneficial support decision making many application emergency management business intelligence public security previous work popularity prediction focused predicting popularity volume online content popularity burst ignored exploration popularity evolution prediction stage fill gap paper propose method popularity stage prediction problem microscopic level macroscopic level microscopic level first extract multiple dynamic factor infer future evolution stage considering contribution different dynamic factor macroscopic level extract overall evolution pattern popularity stage adopt pattern matchingbased method predict future popularity stage evaluate proposed approach using tweet sinaweibo popular twitterlike social medium platform china experimental result show effectiveness proposed approach predicting popularity evolution stage', 'opportunity gain insight social medium user generated data triggered interest many company see chance better understand customer preference identify trend however huge amount data always manageable identification influencers specific industry monitoring behaviour social medium could proved great importance towards direction reducing amount data analysis extracting useful targeted insight context paper aim present platform provide data analyst productservice designer influencer identification functionality per industry topic time also visualise correlation among influencers based specific topic interest platform evaluated use case fashion industry', 'paper proposed advanced business intelligence framework firm postpandemic phase increase performance productivity proposed framework utilizes significant tool era social medium big data analysis business intelligence system addition survey outstanding related paper study open challenge based framework described well proposed methodology minimize challenge given finally conclusion research point worth studying discussed', 'online business intelligence system often collect text different source social medium news website heterogeneous practice collection bring difficulty managing organizing comprehensive information hidden different text system effectively organize multisourced text help online user acquire wider knowledge propose business intelligence system integrates multisourced text multisources regarding many occasion multisourced text share common content respect topic example tweet news report may talk event therefore goal correlate text different source respect similar topic get integrated comprehensive information facilitate data mining task well online application handle problem propose heterogeneous information networkbased text aligning hinta framework paper hinta applies metapaths calculate text similarity construct correlated pair two type text next hinta first applies anchored pair bridge combine different type text finally three different inference method employed align multisourced text experimental result realworld dataset show effectiveness efficiency framework addressing text alignment problem']\n","2024-10-11 10:57:36,956 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:36,957 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:42,221 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:42,234 - INFO - built Dictionary<2522 unique tokens: ['active', 'activity', 'affect', 'also', 'analysis']...> from 80 documents (total 9878 corpus positions)\n","2024-10-11 10:57:42,235 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2522 unique tokens: ['active', 'activity', 'affect', 'also', 'analysis']...> from 80 documents (total 9878 corpus positions)\", 'datetime': '2024-10-11T10:57:42.235296', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:42,253 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:57:42,254 - INFO - Sample of sampled data: ['business intelligence analytics bia system demonstrated potential enhance decision making however linkage bia decision support system ds contested completely denied others research investigate foundation bia using foundational literature ds open black box bia system argue bia fundamentally subfield ds seeking convert data deeper insight lost connection ds literature thereby missed research opportunity paper first define ds bia present systematic review foundational ds literature assess leveraging bia research classifying cited ds article citing bia article four area conceptual framework design implementation business value organizational use cognition decision making potential research bia uncovered reconcile two research stream mapping bia framework classical ds component interview practitioner result formulated comparative processlevel architecture converting data insight new research opportunity bia suggested motivated foundational ds literature', 'purpose purpose paper mine competitive intelligence social medium find market insight comparing consumer opinion sale performance business one competitor analyzing public social medium data designmethodologyapproach exploratory test using multiple case study approach used compare two competing smartphone manufacturer opinion mining sentiment analysis conducted first followed validation result using statistical analysis total tweet mentioning iphone galaxy collected four month following release iphone analyzed using natural language processing lexiconbased sentiment analysis purchase intention classification finding analysis showed social medium data contain competitive intelligence volume tweet revealed significant gap market leader one follower purchase intention data also reflected gap less pronounced extent addition author assessed whether social opinion could explain sale performance gap competitor found social opinion gap similar shipment gap research limitationsimplications study compared social medium opinion shipment gap two rival smart phone business take consumer opinion toward product also toward product competitor social medium analytics furthermore business predict market sale performance estimate gap competing product result decision maker adjust market strategy rapidly compensate weakness contrasting rival well originalityvalue paper main contribution demonstrat competitive intelligence via consumer opinion mining social medium data researcher business analyst practitioner adopt method social medium analysis achieve objective implement practical procedure data collection spam elimination machine learning classification sentiment analysis feature categorization result visualization', 'study aim provide comprehensive network analysis understand current state big data research tourism investigating multidisciplinary contribution relevant big data comprehensive network analytical method includes cocitation clustering trend analysis applied systematically analyse publication two unique data set web science collected first data set focus big data research tourism hospitality second data set involves discipline computer science comparison tourism result suggest application social medium usergenerated content gaining momentum whereas theorybased study big data tourism remain limited tourism relevant domain similar concern challenge involved big data privacy data quality appropriate data use comparative network analysis implication future big data research tourism', 'huge amount data creating fourth industry revaluation data generating explosively various field internet thing iot organization producing storing huge amount data data server every moment data come social medium sensor tracking website online news article google facebook walmart taobao remarkable organization generating data web server data come three form structured textnumeric semi structured audio video image unstructured xml rss feed business make revenue analysis data structured form data unstructured therefore unstructured data contains valuable information help organization improve business productive better decisionmaking extract insight new product service understand market condition various field shopping finance education manufacturing healthcare unstructured data needed analyzed distribute structured manner required information gathered data mining technique used mining data paper expose importance data analytics data management beneficial usage business intelligence big data data mining machine data management addition different technique used discover knowledge useful information data analyzed beneficial numerous user concern text mining convert complex data meaningful information researcher analyst data scientist business decision maker well', 'document evolution academic research bibliometric analysis retail analytics article published top operation management journal isolate nine decision area via manual coding verify using automated text analysis topic modeling track variation across decision area methodusage evolution per analytics type featuring degree big data eg clickstream social medium product review analytics suited new data source eg machine learning used analysis reveals rapidly growing field evolving term content decision retail sector data methodology determine state practice interviewed global practitioner current use retail analytics interview shed light barrier enablers adopting advanced analytics retail also highlight set company frontier eg amazon alibaba walmart apart rest combining insight survey academic research interview practitioner provide direction future academic research take advantage availability big data']\n","2024-10-11 10:57:42,259 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:42,259 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:46,996 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:47,009 - INFO - built Dictionary<2467 unique tokens: ['analytics', 'architecture', 'area', 'argue', 'article']...> from 80 documents (total 9884 corpus positions)\n","2024-10-11 10:57:47,010 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2467 unique tokens: ['analytics', 'architecture', 'area', 'argue', 'article']...> from 80 documents (total 9884 corpus positions)\", 'datetime': '2024-10-11T10:57:47.010906', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:47,156 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:57:47,157 - INFO - Sample of sampled data: ['big data collection large datasets traditional digital source identify trend pattern quantity variety computer data growing exponentially many reason example retailer building vast database customer sale activity organization working logistics financial service public social medium sharing vast quantity sentiment related sale price product challenge big data include volume variety structured unstructured data paper implemented several machine learning model spark mllib using pyspark scalable fast easily integrated tool better performance traditional model studied stock top company whose data include historical stock price mllib model linear regression generalized linear regression random forest decision tree implemented naive bayes logistic regression classification model experimental result suggest linear regression random forest generalized linear regression provide accuracy experimental result decision tree well predict share price movement stock market', 'research examines impact social medium capability innovation performance knowledge ambidexterity potential moderator role business analytics talent equation test proposed theory performing partial least square path modeling secondary dataset sample composed small u firm result empirical analysis suggest social medium capability enables firm effectively balance exploration exploitation knowledge ie knowledge ambidexterity turn facilitates innovation performance business analytics talent play moderator role relationship', 'study attempt analyze value graffiti tour perspective sustainable tourism examining actual review social medium user using text mining social network analysis text mining technique indicates artist history political culture social city background great recommend excellent worth frequently used keywords review comparing word frequency per review result show word history political culture social frequently used time furthermore network visualization show word connoting sociocultural sustainability mutually connected therefore study suggests graffiti tour potential assuming role sustainable tourism since keywords review associated perspective sociocultural sustainability', 'information system research provides significant insight information technology affect strategic agility firm research date studied responding element agility expense sensing extant research mainly focused sensing formal strong signal might influence agility highly turbulent fastchanging competitive landscape digital age argue need expand focus research include examining manager identify make sense weak signal sensing weak signal influence digitalenabled strategic agility drawing social network theory paper present two stream research several research avenue stimulate potentially guide research effort topic', 'web data extraction important problem studied mean different scientific tool broad range application many approach extracting data web designed solve specific problem operate adhoc domain approach instead heavily reuse technique algorithm developed field information extraction survey aim providing structured comprehensive overview literature field web data extraction provided simple classification framework existing web data extraction application grouped two main class namely application enterprise level social web level enterprise level web data extraction technique emerge key tool perform data analysis business competitive intelligence system well business process reengineering social web level web data extraction technique allow gather large amount structured data continuously generated disseminated web social medium online social network user offer unprecedented opportunity analyze human behavior large scale discus also potential crossfertilization ie possibility reusing web data extraction technique originally designed work given domain domain c elsevier bv right reserved']\n","2024-10-11 10:57:47,161 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:47,161 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:51,819 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:51,833 - INFO - built Dictionary<2547 unique tokens: ['accuracy', 'activity', 'bayes', 'better', 'big']...> from 80 documents (total 10118 corpus positions)\n","2024-10-11 10:57:51,833 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2547 unique tokens: ['accuracy', 'activity', 'bayes', 'better', 'big']...> from 80 documents (total 10118 corpus positions)\", 'datetime': '2024-10-11T10:57:51.833887', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:51,972 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:57:51,973 - INFO - Sample of sampled data: ['paper proposed advanced business intelligence framework firm postpandemic phase increase performance productivity proposed framework utilizes significant tool era social medium big data analysis business intelligence system addition survey outstanding related paper study open challenge based framework described well proposed methodology minimize challenge given finally conclusion research point worth studying discussed', 'purpose research social medium frequently analyze social medium usage smus positive consequence organization individual however recent innovation study caution smu may always lead positive new product development npd outcome competing stream research highlight fundamental tension exists social medium literature exemplified question smu good bad npd manuscript author suggest appropriate question follows positive negative indirect effect smu npd performance purpose paper discus aforementioned point detail designmethodologyapproach literature review provides model hypothesis using sample chinese firm author conducted empirical test following multiple regression analysis finding result demonstrate smu facilitates business analytics ability social legitimacy opportunity impairs entrepreneurial proclivity motivation three construct turn mediate effect smu npd performance moreover paper explores technological turbulence moderate smus effect business analytics entrepreneurship proclivity social legitimacy research limitationsimplications result may affected context solely china type crosssectional data set future research might take decompositional approach study smus effect innovation different npd stage furthermore widely varying purpose eg marketing information searching partner collaboration new product launch etc certainly need clarity understanding firm leverage different social medium activity successful npd practical implication first suggest manager china explicitly aware doubleedged sword effect smu npd performance second study encourages manager use social medium carefully technological turbulence becomes intense originalityvalue drawing abilitymotivationopportunity framework one first study simultaneously examines benefit cost smu npd addition paper bridge separate literature social medium business analytics entrepreneurial proclivity social legitimacy contributes npd research', 'social medium major platform opinion sharing order better understand exploit opinion social medium aim classify user opposite opinion topic decision support rather mining text content introduce linkbased classification model named global consistency maximization gcm partition social network two class user opposite opinion experiment twitter data set show global approach achieves higher accuracy two baseline approach linkbased classifier robust small training sample selected properly c elsevier bv right reserved', 'social medium emerged new communication channel consumer company generate large volume unstructured text data social medium content contains consumer opinion interest recognized valuable material business mine useful information consequently many researcher reported opinionmining framework method technique tool business intelligence various industry study sometimes focused use opinion mining business field emphasized method analyzing content achieve result accurate also considered visualize result ensure easier understanding however found approach often technically complex insufficiently userfriendly help business decision planning therefore study attempt formulate comprehensive practical methodology conduct social medium opinion mining apply methodology case study oldest instant noodle product korea also present graphical tool visualized output include volume sentiment graph timeseries graph topic word cloud heat map valence tree map classification resource publicdomain social medium content blog forum message news article analyze natural language processing statistic graphic package freeware r project environment believe methodology visualization output provide practical reliable guide immediate use food industry industry well', 'last decade social medium platform become important communication channel business consumer result lot consumergenerated data available online unfortunately fully utilized partly nature unstructured subjective exist massive database make use data one research method needed study proposes new multiple approach social medium data analysis counteracts aforementioned characteristic social medium data new approach data first extracted systematically coded following principle content analysis comprehensive literature review conducted guide coding strategy next relationship code identified statistical cluster analysis relationship used next step analysis evaluation criterion weight derived basis social medium data probability weighting function case study employed test proposed approach']\n","2024-10-11 10:57:51,976 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:51,977 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:57:56,758 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:57:56,771 - INFO - built Dictionary<2518 unique tokens: ['addition', 'advanced', 'analysis', 'based', 'big']...> from 80 documents (total 9999 corpus positions)\n","2024-10-11 10:57:56,771 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2518 unique tokens: ['addition', 'advanced', 'analysis', 'based', 'big']...> from 80 documents (total 9999 corpus positions)\", 'datetime': '2024-10-11T10:57:56.771708', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:57:56,903 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:57:56,904 - INFO - Sample of sampled data: ['field data science emerged recent year building advance computational statistic machine learning artificial intelligence big data modern organization immersed data turning toward data science address variety business problem numerous complex problem science become solvable data science scientific solution equally applicable business many dataintensive business problem situated complex sociopolitical behavioral context still elude commonly used scientific method extent problem addressed data science data science inherent blind spot regard type business problem likely addressed data science near future develop conceptual framework inform application data science business framework draw extensive review data science literature across four domain data method interface cognition draw ashbys law requisite variety theoretical principle conclude datascientific advance across four domain aggregate could constitute requisite variety particular type business problem explains problem fully partially addressed solved automated data science distinguish situation improved due crossdomain compensatory effect problem data science best contributes merely better understanding complex phenomenon', 'understudied area field social medium research design decision support system aid manager way automated message component generation recent advance form artificial intelligence suggested allow content creator manager transcend task creation towards editing thus overcoming common problem tyranny blank screen research address topic proposing novel system design suggest engagementdriven message feature well automatically generate critical fully written unique tweet message component goal maximizing probability relatively high engagement level multimethods design relies use econometrics machine learning bayesian statistic widely used emerging field business marketing analytics system design intended analyze tweet message purpose generating critical component structure tweet propose econometric model judge quality written tweet way engagementlevel prediction well generative probability model autogeneration tweet message testing design demonstrates need take account contextual semantic syntactic feature message controlling individual user characteristic generated tweet component structure maximizes potential engagement level', 'significant advancement technology past decade given rise relatively straightforward array internet application based open source software application service aim enhance online collaboration broad audience particularly social networking site platform transformed dynamic online interaction information exchange million user regularly engaging sharing various digital content user express thought opinion diverse topic contributing valuable insight personal academic commercial purpose however sheer volume rapid generation data present challenge decisionmakers underlying technology extract meaningful insight leverage data derived social network researcher focused assisting company comprehending conduct competitive analysis convert data actionable knowledge paper offer comprehensive literature review data warehouse approach derived social network commence introducing fundamental concept data warehousing social network followed presentation three category data warehouse approach along overview notable conduct comparative analysis existing work', 'main purpose social business intelligence help company making decision performing multidimensional analysis relevant information disseminated social network although data quality general issue sbi approach aimed assessing data collection context dependent task paper define quality indicator metric serf assess overall quality collection integrates measure obtained several quality criterion applied filter post relevant sbi project selection best quality criterion include quality indicator complex task requires deep understanding context objective analysis paper propose new methodology design quality indicator sbi project whose quality criterion consider content coherence data provenance thus context defined objective analysis methodology help user find quality criterion best suit user available data integrate valid quality indicator', 'opinion leader key participant emerge social medium identifying influential user help decision maker effectively target source influence hence bring change community research developed approach identifying influential user online social network interest policy maker general public present finding empirical study u immigration reform discussion user posted tweet maynovember present finding analysis provide list influential user identified discus implication predictive analytics social medium analytics research contribute providing new case new empirical finding applying influence analytics analyzing social medium network strong implication predictive analytics business intelligence social medium analytics']\n","2024-10-11 10:57:56,908 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:57:56,909 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:02,110 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:02,124 - INFO - built Dictionary<2522 unique tokens: ['across', 'address', 'addressed', 'advance', 'aggregate']...> from 80 documents (total 10198 corpus positions)\n","2024-10-11 10:58:02,124 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2522 unique tokens: ['across', 'address', 'addressed', 'advance', 'aggregate']...> from 80 documents (total 10198 corpus positions)\", 'datetime': '2024-10-11T10:58:02.124086', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:02,267 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:02,268 - INFO - Sample of sampled data: ['enabled web technology social medium provide unparalleled platform consumer share product experience opinion wordofmouth wom consumer review become increasingly important understand wom content metric influence consumer purchase product sale integrating marketing theory text mining technique propose set novel measure focus sentiment divergence consumer product review test validity metric conduct empirical study based data amazoncom bncom barnes noble result demonstrate significant effect proposed measure product sale effect fully captured nontextual review measure numerical rating furthermore capturing sale effect review content divergence metric shown superior appropriate commonly used textual measure literature finding provide important insight business impact social medium usergenerated content emerging problem business intelligence research managerial perspective result suggest firm pay special attention textual content information managing social medium importantly focus right measure', 'purpose recent year rise big data led obvious shift competence profile expected controller management accountant among others business analytics competence information technology skill considered must capability controlling profession still remains unclear requirement fulfilled today employee purpose study examine supply business analytics competence current competence profile controlling professional attempt answer question whether skill gap exists designmethodologyapproach based set member profile german controlling professional extracted business social network xing text analytics approach conducted discover pattern semistructured data second purpose study encourage researcher practitioner integrate advance big data analytics method inquiry research process finding apart mediating role gender company size variable result indicate current competence profile controller comply recent requirement towards business analytics competence however answer question whether skill gap exist must made cautiously taking account specific organizational context level adoption degree job specialization originalityvalue insight provided study extend ongoing debate accounting literature business medium skill change controlling profession big data era originality study lie explicit attempt integrate recent advance data analytics explore selfreported competence supply controlling professional based comprehensive set semistructured data theoretically founded explanatory model proposed integrates empirically validated finding extant research across various discipline', 'paper build previous research investigated critical factor underpinning ecrm activity smes however marketing practice moved e ecrm today disruptive technology crm social medium particularly true smes social medium free tool used foster engagement organization consumer thus social crm scrm online survey completed smes exploratory factor analysis uncovered seven factor underpinning scrm activity finding illustrate importance customer relationship orientation uncover support data issue around social medium use promote importance customer engagement online community recognise driving role information process study contributes theory measuring scrm smes dynamic capability lens sme ownermanagers emphasis need strategically combine social medium use crm activity', 'social medium three billion user sharing event comment feeling throughout world serf critical information source large volume high velocity wide variety data previous study information spreading relationship analyzing individual modeling etc heavily conducted explore tremendous social commercial value social medium data survey study previous literature existing application practical perspective outline commonly used pipeline building social mediabased application focus discussing available analysis technique topic analysis time series analysis sentiment analysis network analysis present impact application three different area including disaster management healthcare business finally list existing challenge suggest promising future research direction term data privacy g wireless network multilingual support', 'consumer often consider multiple alternative product category prior making purchase uncovering predominant pattern coconsiderations help business learn competitive structure market mind consumer extant research shown various type online offline consumer activity data eg shopping basket search browsing history social medium mention used infer product coconsiderations paper study case uncovering coconsideration pattern using massive dataset online price quote request u auto shopper main challenge face privacy protection unique individual identifier anonymous otherwise contained data data deficiency prevents u using existing method affinity analysis inferring coconsiderations however leveraging spatiotemporal pattern data manage probabilistically uncover predominant pattern coconsiderations u auto market validation illustration usefulness embed inferred market structure sale response model show substantial improvement predictive performance c direct marketing educational foundation inc dba marketing edge right reserved']\n","2024-10-11 10:58:02,273 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:02,273 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:06,961 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:06,974 - INFO - built Dictionary<2506 unique tokens: ['amazoncom', 'appropriate', 'attention', 'barnes', 'based']...> from 80 documents (total 9858 corpus positions)\n","2024-10-11 10:58:06,975 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2506 unique tokens: ['amazoncom', 'appropriate', 'attention', 'barnes', 'based']...> from 80 documents (total 9858 corpus positions)\", 'datetime': '2024-10-11T10:58:06.975988', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:07,113 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:07,114 - INFO - Sample of sampled data: ['big data collection large datasets traditional digital source identify trend pattern quantity variety computer data growing exponentially many reason example retailer building vast database customer sale activity organization working logistics financial service public social medium sharing vast quantity sentiment related sale price product challenge big data include volume variety structured unstructured data paper implemented several machine learning model spark mllib using pyspark scalable fast easily integrated tool better performance traditional model studied stock top company whose data include historical stock price mllib model linear regression generalized linear regression random forest decision tree implemented naive bayes logistic regression classification model experimental result suggest linear regression random forest generalized linear regression provide accuracy experimental result decision tree well predict share price movement stock market', 'emergence web possible usergenerated content ugc social medium express opinion customer experience related service product customer review useful understand customer experience associated stay hotel considering different dimension associated hotel service accommodation business intelligence analytics increasingly considered amanagement strategy examine customer satisfaction hotel product service positioning compared economic sector however ugc difficult analyze compare rating fill gap business intelligence environment considered along text mining approach holistic decisionsupport system help decisionmaking strategic management hotel', 'human emotion expressed social medium play increasingly important role shaping policy decision however process emotion produce influence online social medium network relatively unknown previous work focus largely sentiment classification polarity identification adequately consider way emotion affect user influence research developed novel framework theorybased model proofofconcept system dissecting emotion user influence social medium network system model emotiontriggered influence facilitates analysis emotioninfluence causality context u border security using tweet posted user motivated theory emotion spread model integrated influencecomputation method called interaction modeling im approach compared benchmark using user centrality uc approach based social position im found identified influential user broadly related u cultural issue influential user tended express intense emotion fear anger disgust sadness emotion trust distinguishes influential user others whereas anger fear contributed significantly causing user influence research contributes incorporating human emotion datainformationknowledgewisdom model knowledge management providing new information system artifact new causality finding emotioninfluence analysis', 'product review play crucial role providing valuable insight consumer producer analyzing vast amount data generated around product post comment view challenging business intelligence purpose sentiment analysis content help consumer producer gain better understanding market status enabling make informed decision study propose novel hybrid approach based deep neural network dnns sentiment analysis product review focusing classification sentiment expressed approach utilizes recursive neural network rnn algorithm sentiment classification address imbalanced distribution positive negative sample social network data employ resampling technique balance dataset increasing sample minority class decreasing sample majority class evaluate approach using amazon data comprising four product category clothing car luxury good household appliance experimental result demonstrate proposed approach performs well sentiment analysis product review particularly context digital marketing furthermore attentionbased rnn algorithm outperforms baseline rnn approximately notably study reveals consumer sentiment variation across different product particularly relation appearance price aspect', 'major business trend organization big data business analytics along mobile cloud social medium technology big data may characterized volume velocity variety data heterogenous unstructured contains mixed often indeterminate amount different kind information text image date number information various format data analyst scientist spend time preparing cleaning wrangling data data analytics may divided descriptive analytics predictive analytics prescriptive analytics continuing growth data mean largescale analytics becomes critical business competitiveness also facilitating internal decisionmaking process based data internal organization big data requires complex advanced visualization technique order fully understand information contained data machine learning deep learning method integrated data analytics process machine learning us statistical technique give computer system ability learn ie progressively improve performance specific task data current issue challenge big data analysis reviewed']\n","2024-10-11 10:58:07,118 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:07,118 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:11,904 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:11,916 - INFO - built Dictionary<2373 unique tokens: ['accuracy', 'activity', 'bayes', 'better', 'big']...> from 80 documents (total 9240 corpus positions)\n","2024-10-11 10:58:11,917 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2373 unique tokens: ['accuracy', 'activity', 'bayes', 'better', 'big']...> from 80 documents (total 9240 corpus positions)\", 'datetime': '2024-10-11T10:58:11.917344', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:12,059 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:12,060 - INFO - Sample of sampled data: ['social identity linkage across different social medium platform critical importance business intelligence gaining social data deeper understanding accurate profiling user paper propose solution framework hydra consists three key step model heterogeneous behavior longterm topical distribution analysis multiresolution temporal behavior matching high noise information missing behavior similarity described multidimensional similarity vector user pair ii build structure consistency model maximize structure behavior consistency user core social structure across different platform thus task identity linkage performed group user beyond individual level linkage previous study iii propose normalizedmarginbased linkage function formulation learn linkage function multiobjective optimization supervised pairwise linkage function learning structure consistency maximization conducted towards unified pareto optimal solution model able deal drastic information missing avoid curseofdimensionality handling high dimensional sparse representation extensive experiment million user across seven popular social network platform demonstrate hydra correctly identifies real user linkage across different platform massive noisy user behavior data record outperforms existing stateoftheart approach least percent different setting four time better setting', 'introduction big data analytics bda healthcare allow use new technology treatment patient health management paper aim analyzing possibility using big data analytics healthcare research based critical analysis literature well presentation selected result direct research use big data analytics medical facility direct research carried based research questionnaire conducted sample medical facility poland literature study shown use big data analytics bring many benefit medical facility direct research shown medical facility poland moving towards databased healthcare use structured unstructured data reach analytics administrative business clinical area research positively confirmed medical facility working structural data unstructured data following kind source data distinguished database transaction data unstructured content email document data device sensor however use data social medium lower activity reach analytics administrative business also clinical area clearly show decision made medical facility highly datadriven result study confirm analyzed literature medical facility moving towards databased healthcare together benefit', 'huge amount data creating fourth industry revaluation data generating explosively various field internet thing iot organization producing storing huge amount data data server every moment data come social medium sensor tracking website online news article google facebook walmart taobao remarkable organization generating data web server data come three form structured textnumeric semi structured audio video image unstructured xml rss feed business make revenue analysis data structured form data unstructured therefore unstructured data contains valuable information help organization improve business productive better decisionmaking extract insight new product service understand market condition various field shopping finance education manufacturing healthcare unstructured data needed analyzed distribute structured manner required information gathered data mining technique used mining data paper expose importance data analytics data management beneficial usage business intelligence big data data mining machine data management addition different technique used discover knowledge useful information data analyzed beneficial numerous user concern text mining convert complex data meaningful information researcher analyst data scientist business decision maker well', 'last decade social medium platform become important communication channel business consumer result lot consumergenerated data available online unfortunately fully utilized partly nature unstructured subjective exist massive database make use data one research method needed study proposes new multiple approach social medium data analysis counteracts aforementioned characteristic social medium data new approach data first extracted systematically coded following principle content analysis comprehensive literature review conducted guide coding strategy next relationship code identified statistical cluster analysis relationship used next step analysis evaluation criterion weight derived basis social medium data probability weighting function case study employed test proposed approach', 'digitization era altering several industry include way data analyzed inferred zettabyte data exist digital world today data generated per second every human approximate amount megabyte volume data would double every year thus reach zb point interactive data corporation idc estimated end year ecommerce transaction bb bc hit billion per day internet advent big real time data triggered disruptive change many field exploding volume different source data like heterogeneous data data integration spatiotemporal correlation data batch analytics realtime analytics data sharing semantic interoperability requires development scalable platform fuse multiple data layer handle data intelligently big data approach challenge anymore collect data draw valuable conclusion properly analyzing growth unstructured data generated business irrefutable pressure preserve longer period time clear exploiting collected data always considered practitioner researcher huge velocity heterogeneity enormity massive stream realtime data shove limit current storage management processing capability admittedly traditional method extract transform load etl challenged applied emerging opportunistically crowed sensed data stream data stream structured way serve one predefined purpose directly used mean yet emerging unstructured data contextbased data internet social medium well credit card transaction clear used better understand mobility pattern analytical company gartner state billion interconnected device obvious produce massive amount meaningful data data used many application realtime industrial equipment monitoring traffic planning automated maintenance etc therefore essential develop modern system abstraction allow u resourcefully process huge new data stream enormous amount data urge growth integrated insightful big realtime data analytics platform upcoming contemporary technology like digital twin integrates historical data past machine usage current data us sensor collect realtime data working status operational data attached physical model component send relevant data via cloudbased system side bridge help data analytics platform produce required insight big realtime data analytics platform assist perform useful operation data analytics complete package purpose data analytics platform used acquire constructive insight huge volume data data analytics platform ecosystem technology service help business increasing revenue enhance operational efficiency stabilize marketing campaign customer service effort respondmore quickly toemerging market trend gain competitive edge rival data analytics platform find pattern relationship data applying statistical technique communicates result generated analytical model executive end user make decision help data visualization tool display data single screen updated real time new information becomes available big data realtime data analytics platform support full spectrum data type protocol integration speed simplify data wrangling process big data real time platform provides accurate data increase efficiency workspace give answer complex question along security hence play key role business analytics']\n","2024-10-11 10:58:12,064 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:12,065 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:16,800 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:16,814 - INFO - built Dictionary<2525 unique tokens: ['able', 'accurate', 'across', 'analysis', 'approach']...> from 80 documents (total 9942 corpus positions)\n","2024-10-11 10:58:16,814 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2525 unique tokens: ['able', 'accurate', 'across', 'analysis', 'approach']...> from 80 documents (total 9942 corpus positions)\", 'datetime': '2024-10-11T10:58:16.814911', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:16,953 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:16,954 - INFO - Sample of sampled data: ['paper aim present current social medium analytics marketing research bottomup thematic content analysis academic paper top marketing information system journal conducted type social medium platform data analytics marketing theme field study involved social medium analytics research identified match technological input marketing output presented finding reveal current status social medium analytics marketing research identify various untapped area research paper proposes impact social medium analytics restricted marketing research method foster amplifies change marketing approach structure culture organisation maximise benefit paper suggests firm could strategically build technological knowledge base social medium analytics strategically manage support use facilitating itmarketing itorganisation alignment', 'large number structured unstructured data core big data organization institution potentially analysis business well requirement big data platform data information basically come different source importantly collected outcome scientific experiment used internet thing big data system data may treated source intelligent system mechanism use separate software tool analytics important fact technology rising everyday eg social medium creation information take second user data science program another terminology big data data science also referred business analytics simply analytics domain several application big data found different sector include healthcare banking finance information foundation well corporate sector currently shortage data scientist analyst experience working big data medical service emerging area application cloud based service highly noticed day moreover analyzing big data management system help managing information multiple scale health care service include particular disease detailed dna protein metabolite cell tissue organ organism ecosystem conceptual also kind policy paper several general aspect big data focused medical system illustrated paper also explores potentiality creating manpower medical informatics similar professional adequate knowledge big data analytics technology', 'cooperative work process analysis decision support currently gain strong attention business world motivated spreading corporate structure technical development like social medium networkoriented data storage encourage user comprehension demand easy communication data article reflects state research domain business intelligence regarding opening process new data source analyst existing approach often labeled collaborative business intelligence cbi differ heavily definition focus therefore framework presented three main field research cbi identified encompass internal communication data storage external partner data analysis partner article compare finding development software market describes open topic research domain', 'organization develop manage employee data analytics skill create business value enhance organizational competitive advantage order address prominent critical research question research conceptualize operationalize data analytics skill individual level develop nomological network model examine critical antecedent outcome lens adaptation structuration theory test core proposition research model using survey data collected frontline employee three dataintensive research institute china discover datadriven culture data analytics affordance individual absorptive capacity positively associated employee data analytics skill turn positive influence task innovative performance classify employee digital immigrant digital native based age examine different influence three salient antecedent data analytics skill two group research finding suggest datadriven culture play significant role driving data analytics skill digital immigrant data analytics affordance exhibit stronger influence data analytics skill digital native', 'paper investigates referred open information transaction transaction contrast traditional transaction typically two party transaction one information transaction example sale seller purchaser typically one information transaction however emerging technology blockchain accounting supply chain social medium hashtag commerce making information transaction potentially openly available others paper investigates implication strategy include use open information example open information accounting supply chain transaction provides potential business intelligence analysis information possibly misleading illusory transaction analogous garnered recent attention justice department cryptocurrencies finally paper suggests blockchain transaction processing provide reliable information setting single truth feed information flow phenomenon interest ability offblockchain transaction large penalty cost limitation single identity enterprise blockchain']\n","2024-10-11 10:58:16,978 - INFO - 에폭 1/5, 손실: 686.6417\n","2024-10-11 10:58:16,986 - INFO - 에폭 2/5, 손실: 676.8480\n","2024-10-11 10:58:16,994 - INFO - 에폭 3/5, 손실: 667.4816\n","2024-10-11 10:58:17,002 - INFO - 에폭 4/5, 손실: 659.8427\n","2024-10-11 10:58:17,010 - INFO - 에폭 5/5, 손실: 651.6294\n","2024-10-11 10:58:17,024 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:17,033 - INFO - built Dictionary<2345 unique tokens: ['academic', 'aim', 'alignment', 'amplifies', 'analysis']...> from 80 documents (total 9169 corpus positions)\n","2024-10-11 10:58:17,034 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2345 unique tokens: ['academic', 'aim', 'alignment', 'amplifies', 'analysis']...> from 80 documents (total 9169 corpus positions)\", 'datetime': '2024-10-11T10:58:17.034916', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:17,219 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:17,220 - INFO - Sample of sampled data: ['study problem largescale social identity linkage across different social medium platform critical importance business intelligence gaining social data deeper understanding accurate profiling user paper proposes hydra solution framework consists three key step modeling heterogeneous behavior longterm behavior distribution analysis multiresolution temporal information matching ii constructing structural consistency graph measure highorder structure consistency user core social structure across different platform iii learning mapping function multiobjective optimization composed supervised learning pairwise id linkage information crossplatform structure consistency maximization extensive experiment million user across seven popular social network platform demonstrate hydra correctly identifies real user linkage across different platform outperforms existing stateoftheart algorithm least different setting time better setting', 'customer loyalty significantly evolved last decade specifically social medium platform marketer engage customer regularly omnichannel approach allows brand interact customer whether persontoperson persontocommunity customer loyalty characterised literature psychological process whereby customer loyalty attache towards specific service brand time customer loyalty contributes consumer behaviour preference specific brand service therefore company consider formulating developing appropriate business intelligence strategy drive customer towards loyalty increase engagement brand furthermore psychological shopper behaviour might expand improve current research towards customer perspective distinguishing customer incentivised brand activity venture suggesting customer loyalty customer judgement business notable positive impact brand identify business centre attention attraction brand understand identify best loyalty strategy target customer business must use opportunity enable brand develop new innovative approach approach continuously drive brand loyalty sale creating competitive advantage market customer loyalty become strategy business marketing empowers consumer engaged throughout initial interaction purchase journey become loyal brand engagement journey help brand establish grow due continuous support consumer general aim study determine nature relationship customer engagement factor brand loyalty study identified five customer engagement factor literature brand reputation social medium wordofmouth customer experience merchandising view investigating role brand loyalty noteworthy factor welldocumented precovid environment question remains however whether factor still valid reliable covid business environment study aim determine response precisely question quantitative research design selfdeveloped questionnaire used measure one factor fivepoint likert scale factor respective measuring criterion validated empirically using exploratory factor analysis social medium platform instagram used initiate snowball sample total social medium participant responded completing online google form questionnaire respondent profile show brand social medium page preferred method brand communication followed email sm telephonic communication method latter fact clearly disliked found respondent prefer email followed sm social medium platform receive brand communication however communication via telephone conversation disliked consumer respondent find brand advertisement memorable seen different platform channel communication memorable channel social medium recall rate total participant first read review new product launched find way wordofmouth brand community make informed discussion purchasing product listening consumer share review platform data reliable alpha ge sample deemed adequate kmo ge multiple regression analysis used determine relationship customer engagement factor brand loyalty result indicated significant p le positive relationship factor brand reputation r p le social medium r p le wordofmouth r p le visibility r p le model explains satisfactory cumulative variance r factor customer experience however reconsidered antecedent significantly influence consumer loyalty brand exploratory factor analysis used determine whether factor determine brand loyalty eight factor identified explaining variance cumulatively factor visibility merchandise brand reputation brand trust brand reference outside shop advice inside shop brand ambassador purchase experience personal choice eight new factor make sense factor manage brand loyalty management rather focus factor concentrate initial five factor indicated literature possible area future research investigate age demographic area regard participant could viewed opinion centralised focus towards different age group generation gen z millennials gen x boomer silent generation also investigated compare illustrate engagement strategy influential towards brand loyalty', 'increased access data affordable technology today made business analytics within reach organization however many organization unsure translate analytics use organizational value area business analytics value creation become popular point discussion amongst practitioner much research needed provide insight effective use business analytics objective paper deepen understanding effective implementation analytics within organization specifically performed indepth case study rovio entertainment investigate pioneer mobile game initiated analyticsdriven transformation study contributes theory practice business analytics two way first drawing perspective technology affordances study shed light varying affordances business analytics second study present empiricallyinformed insight affordances could effectively actualized analyticsdriven transformation organization collectively study open blackbox effective implementation business analytics organizational value creation c elsevier bv right reserved', 'purpose business intelligence gained significant attraction recent past facilitates manager efficient business decisionmaking year attraction toward cryptocurrency cc market increased since cc market highly volatile extremely sensitive shock web data related large event happening around globe designmethodologyapproach research study provides business intelligence model predict five topperforming cc study deep learning linear regression support vector regression svr used predict cc price sentiment megaevents also used enhance performance model finding result show model business intelligence deep learning svr provide better result moreover result show incorporation social medium sentiment data significantly improves performance proposed model overall accuracy model improves approximately twofold multiple event sentiment incorporated originalityvalue use social medium sentiment global local event different country along deep learning cc forecasting', 'pressing need vehicle quality management professional decision support vehicle defect discovery classification process paper employ text mining popular social medium used vehicle enthusiast online discussion forum find sentiment analysis conventional technique consumer complaint detection insufficient finding categorizing prioritizing vehicle defect discussed online forum describe evaluate new process decision support system automotive defect identification prioritization finding provide managerial insight social medium analytics improve automotive quality management c elsevier bv right reserved']\n","2024-10-11 10:58:17,240 - INFO - 에폭 1/5, 손실: 695.1856\n","2024-10-11 10:58:17,247 - INFO - 에폭 2/5, 손실: 685.8389\n","2024-10-11 10:58:17,253 - INFO - 에폭 3/5, 손실: 676.3837\n","2024-10-11 10:58:17,260 - INFO - 에폭 4/5, 손실: 666.4875\n","2024-10-11 10:58:17,267 - INFO - 에폭 5/5, 손실: 655.7034\n","2024-10-11 10:58:17,282 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:17,295 - INFO - built Dictionary<2500 unique tokens: ['accurate', 'across', 'algorithm', 'analysis', 'behavior']...> from 80 documents (total 9781 corpus positions)\n","2024-10-11 10:58:17,296 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2500 unique tokens: ['accurate', 'across', 'algorithm', 'analysis', 'behavior']...> from 80 documents (total 9781 corpus positions)\", 'datetime': '2024-10-11T10:58:17.296215', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:17,473 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:17,474 - INFO - Sample of sampled data: ['paper aim present current social medium analytics marketing research bottomup thematic content analysis academic paper top marketing information system journal conducted type social medium platform data analytics marketing theme field study involved social medium analytics research identified match technological input marketing output presented finding reveal current status social medium analytics marketing research identify various untapped area research paper proposes impact social medium analytics restricted marketing research method foster amplifies change marketing approach structure culture organisation maximise benefit paper suggests firm could strategically build technological knowledge base social medium analytics strategically manage support use facilitating itmarketing itorganisation alignment', 'emerging big data bd recent year latest development business intelligence bi business analytics ba representing new unusual source data eg social medium sensor advanced technology eg hadoop architecture visualisation predictive analytics new requirement user skill eg data scientist major impact fundamental traditional business intelligence bi knowledge management km process trend square way conceptualize knowledge intellectual capital value knowledge management business intelligence recognized data information though generally nonvalue precursor valuable knowledge asset establishing conceptual foundation big data additional valuable asset related knowledge making case bringing big data business intelligence km fold developing theoretical foundation concept tacit explicit knowledge learning others deployed increase understanding result believe help field better understand idea big data relates knowledge asset well providing justification bringing knowledge management tool process bear big data business intelligence move towards integrated conceptual model big data bd business intelligence bi knowledge management km km continuum bd main information deposit bi activity necessary mobilization information resource thus necessitates collective intelligence structured context bi convert data actionable knowledge strategic advantage relative various organizational environment paper contribute creation model focus ongoing research aim propose integrated bdbikm model represents processing raw data transformation contextual knowledge adopted add specific business value practice innovate knowledge provide unique competitive advantage', 'decision making required organization however decisionmaking style may differ commonly used decision style include autocratic democratic consensus participatory globalization expansion business professional become highly dependent upon technology support decisionmaking process decisionsupport system come fastest growing discipline present work discusses evolution computerized decision support considering modeldriven datadriven communicationdriven documentdriven knowledgedriven decisionsupport system three different business levelsoperational tactical strategichave considered present work review development decisionsupport system traditional data analysisbased approach compared latest data analytics approach including social medium analytics web analytics example different industry sector incorporated better illustration decision support', 'market surveillance system msss increasingly used monitor trading activity financial market maintain market integrity existing msss primarily focus statistical analysis market activity data largely ignore textual market information including limited news report various social medium suggested theoretical exploration finance prevailing market surveillance practice unstructured market information hold major yet underexplored opportunity surveillance paper propose news analysis approach help commonsense knowledge assess risk suspicious transaction identified market activity analysis approach explicitly model semantic relation transaction news article provides semantic reference word news article conducted experiment using data collected realworld market found proposed approach significantly outperforms existing method based transaction characteristic traditional textual analysis method experiment also show performance advantage proposed approach mainly come modeling newstransaction relationship research contributes market surveillance literature significant practical implication', 'social medium major platform opinion sharing order better understand exploit opinion social medium aim classify user opposite opinion topic decision support rather mining text content introduce linkbased classification model named global consistency maximization gcm partition social network two class user opposite opinion experiment twitter data set show global approach achieves higher accuracy two baseline approach linkbased classifier robust small training sample selected properly c elsevier bv right reserved']\n","2024-10-11 10:58:17,493 - INFO - 에폭 1/5, 손실: 733.9181\n","2024-10-11 10:58:17,500 - INFO - 에폭 2/5, 손실: 719.4314\n","2024-10-11 10:58:17,507 - INFO - 에폭 3/5, 손실: 705.6360\n","2024-10-11 10:58:17,515 - INFO - 에폭 4/5, 손실: 692.6880\n","2024-10-11 10:58:17,523 - INFO - 에폭 5/5, 손실: 678.3579\n","2024-10-11 10:58:17,539 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:17,551 - INFO - built Dictionary<2519 unique tokens: ['academic', 'aim', 'alignment', 'amplifies', 'analysis']...> from 80 documents (total 10060 corpus positions)\n","2024-10-11 10:58:17,552 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2519 unique tokens: ['academic', 'aim', 'alignment', 'amplifies', 'analysis']...> from 80 documents (total 10060 corpus positions)\", 'datetime': '2024-10-11T10:58:17.552214', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:17,733 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:17,734 - INFO - Sample of sampled data: ['social medium platform become integral part daily life generate vast amount data analyzed various purpose however quality data obtained social medium often questionable due factor noise bias incompleteness enhancing data quality crucial ensure reliability validity result obtained data paper proposes enhanced decisionmaking framework based business decision management system bdms address challenge incorporating data quality enhancement component framework includes backtracking method improve plan failure risktaking ability steep optimized strategy enhance training plan resource management contribute improving quality data examine efficacy proposed framework research data provides evidence ability increase level effectiveness performance enhancing data quality additionally demonstrate reliability proposed framework simulation analysis includes true positive analysis performance analysis error analysis accuracy analysis research contributes field business intelligence providing framework address critical data quality challenge faced organization decisionmaking environment', 'decision making required organization however decisionmaking style may differ commonly used decision style include autocratic democratic consensus participatory globalization expansion business professional become highly dependent upon technology support decisionmaking process decisionsupport system come fastest growing discipline present work discusses evolution computerized decision support considering modeldriven datadriven communicationdriven documentdriven knowledgedriven decisionsupport system three different business levelsoperational tactical strategichave considered present work review development decisionsupport system traditional data analysisbased approach compared latest data analytics approach including social medium analytics web analytics example different industry sector incorporated better illustration decision support', 'social medium monitoring become important mean business analytics trend detection instance analyzing sentiment towards certain product decision lot work dedicated analyze sentiment english text much less effort put providing accurate sentiment classification german language paper analyze three established classifier german language respect facebook post present hierarchical approach classify sentiment evaluate using data set similar facebook post corporate well governmental facebook page compare approach three sentiment classifier german ie alchemyap iota semantria sentistrength accuracy approach performs better classifier application scenario demonstrate classifier ability monitor change sentiment respect refugee crisis', 'business intelligence analytics bia system demonstrated potential enhance decision making however linkage bia decision support system ds contested completely denied others research investigate foundation bia using foundational literature ds open black box bia system argue bia fundamentally subfield ds seeking convert data deeper insight lost connection ds literature thereby missed research opportunity paper first define ds bia present systematic review foundational ds literature assess leveraging bia research classifying cited ds article citing bia article four area conceptual framework design implementation business value organizational use cognition decision making potential research bia uncovered reconcile two research stream mapping bia framework classical ds component interview practitioner result formulated comparative processlevel architecture converting data insight new research opportunity bia suggested motivated foundational ds literature', 'large number structured unstructured data core big data organization institution potentially analysis business well requirement big data platform data information basically come different source importantly collected outcome scientific experiment used internet thing big data system data may treated source intelligent system mechanism use separate software tool analytics important fact technology rising everyday eg social medium creation information take second user data science program another terminology big data data science also referred business analytics simply analytics domain several application big data found different sector include healthcare banking finance information foundation well corporate sector currently shortage data scientist analyst experience working big data medical service emerging area application cloud based service highly noticed day moreover analyzing big data management system help managing information multiple scale health care service include particular disease detailed dna protein metabolite cell tissue organ organism ecosystem conceptual also kind policy paper several general aspect big data focused medical system illustrated paper also explores potentiality creating manpower medical informatics similar professional adequate knowledge big data analytics technology']\n","2024-10-11 10:58:17,759 - INFO - 에폭 1/5, 손실: 698.8299\n","2024-10-11 10:58:17,769 - INFO - 에폭 2/5, 손실: 688.1950\n","2024-10-11 10:58:17,776 - INFO - 에폭 3/5, 손실: 677.5748\n","2024-10-11 10:58:17,785 - INFO - 에폭 4/5, 손실: 669.2243\n","2024-10-11 10:58:17,810 - INFO - 에폭 5/5, 손실: 656.9991\n","2024-10-11 10:58:17,827 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:17,841 - INFO - built Dictionary<2427 unique tokens: ['ability', 'accuracy', 'additionally', 'address', 'amount']...> from 80 documents (total 9786 corpus positions)\n","2024-10-11 10:58:17,842 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2427 unique tokens: ['ability', 'accuracy', 'additionally', 'address', 'amount']...> from 80 documents (total 9786 corpus positions)\", 'datetime': '2024-10-11T10:58:17.842761', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:18,053 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:18,054 - INFO - Sample of sampled data: ['since mids business topic received much attention big data business analytics including unstructured data derived social medium blog chat email message addition unstructured data youtube vimeo video source represent another aspect organization customer service ibm survey professional country industry identified big data business analytics major business trend organization along mobile cloud social business technology', 'last year use social networking site increased tremendously nowadays social networking site generate large amount data million people conveniently express view opinion wide array topic via microblogging website paper discus extraction sentiment famous microblogging website twitter user post view opinion done sentiment analysis tweet help provide prediction business intelligence use hadoop framework processing movie data set available twitter website form review feedback comment result sentiment analysis twitter data displayed different section presenting positive negative neutral sentiment', 'decision making required organization however decisionmaking style may differ commonly used decision style include autocratic democratic consensus participatory globalization expansion business professional become highly dependent upon technology support decisionmaking process decisionsupport system come fastest growing discipline present work discusses evolution computerized decision support considering modeldriven datadriven communicationdriven documentdriven knowledgedriven decisionsupport system three different business levelsoperational tactical strategichave considered present work review development decisionsupport system traditional data analysisbased approach compared latest data analytics approach including social medium analytics web analytics example different industry sector incorporated better illustration decision support', 'development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm', 'purpose organization widely adopt knowledge management km develop promote technology improve business effectiveness analytics aid km augmenting company performance decisionmaking significant research domain analytics km past decade therefore paper aim examine current body literature adoption analytics km offering prominent theme laying research path future research endeavor field km analyticsdesignmethodologyapproach comprehensive analysis conducted collection article sourced scopus database research used latent dirichlet allocation methodology topic modeling content analysis discover prominent theme literaturefindings km analytics literature categorized three cluster research km analytics optimizing business process km analytics industrial context km analytics social mediaoriginalityvalue systematizing literature km analytics received minimal attention km analytics view examined using complementary topic modeling technique including machinebased algorithm enable reliable systematic thorough objective mapping developing field research']\n","2024-10-11 10:58:18,080 - INFO - 에폭 1/5, 손실: 725.1655\n","2024-10-11 10:58:18,087 - INFO - 에폭 2/5, 손실: 713.2812\n","2024-10-11 10:58:18,094 - INFO - 에폭 3/5, 손실: 700.9250\n","2024-10-11 10:58:18,100 - INFO - 에폭 4/5, 손실: 691.9177\n","2024-10-11 10:58:18,109 - INFO - 에폭 5/5, 손실: 680.1787\n","2024-10-11 10:58:18,124 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:18,135 - INFO - built Dictionary<2534 unique tokens: ['addition', 'along', 'analytics', 'another', 'aspect']...> from 80 documents (total 10068 corpus positions)\n","2024-10-11 10:58:18,136 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2534 unique tokens: ['addition', 'along', 'analytics', 'another', 'aspect']...> from 80 documents (total 10068 corpus positions)\", 'datetime': '2024-10-11T10:58:18.136662', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:18,299 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:18,299 - INFO - Sample of sampled data: ['machine continually channelized current era automation deliver accurate interpretation people communicate social medium human specie today engulfed concept people believe decision made result mostly dependent sway mass social medium platform usage internet well social medium booming day day today ocean data used fruitful purpose analysis social medium sentiment textual post supply knowledge information used citizen opinion polling business intelligence social context internet thing iotmood triggered device manuscript main focus sentiment analysis based emotional recognition er proposed system highlight process gaining actual sentiment mood person key idea system posed fact smile laughter two different category happy happpyyyyyy happy novel lexicon based system proposed considers lengthened word instead omitted normalized aggregated intensified sentiscores lengthened word calculated using framed lexicon rule sentiscores lengthened word used calculate level sentiment person dataset used paper informal chat happened among different friend group facebook tweet personal chat performance proposed system compared traditional system ignore lengthened word proposed system outperform tradition system achieving fmeasure rate datasets', 'ebusiness eeducation egovernment social medium mobile service generate capture trillion byte data every second customer supplier employee type data growing quantity big data important part every sector global economy however significant shortage business data analyst author explored random sample association advance collegiate school businessaccredited u business college official website regarding business analytics program offering varied academic level finding indicate minority college offered business analytics program varied academic level', 'emergence web possible usergenerated content ugc social medium express opinion customer experience related service product customer review useful understand customer experience associated stay hotel considering different dimension associated hotel service accommodation business intelligence analytics increasingly considered amanagement strategy examine customer satisfaction hotel product service positioning compared economic sector however ugc difficult analyze compare rating fill gap business intelligence environment considered along text mining approach holistic decisionsupport system help decisionmaking strategic management hotel', 'online business intelligence system often collect text different source social medium news website heterogeneous practice collection bring difficulty managing organizing comprehensive information hidden different text system effectively organize multisourced text help online user acquire wider knowledge propose business intelligence system integrates multisourced text multisources regarding many occasion multisourced text share common content respect topic example tweet news report may talk event therefore goal correlate text different source respect similar topic get integrated comprehensive information facilitate data mining task well online application handle problem propose heterogeneous information networkbased text aligning hinta framework paper hinta applies metapaths calculate text similarity construct correlated pair two type text next hinta first applies anchored pair bridge combine different type text finally three different inference method employed align multisourced text experimental result realworld dataset show effectiveness efficiency framework addressing text alignment problem', 'huge amount data creating fourth industry revaluation data generating explosively various field internet thing iot organization producing storing huge amount data data server every moment data come social medium sensor tracking website online news article google facebook walmart taobao remarkable organization generating data web server data come three form structured textnumeric semi structured audio video image unstructured xml rss feed business make revenue analysis data structured form data unstructured therefore unstructured data contains valuable information help organization improve business productive better decisionmaking extract insight new product service understand market condition various field shopping finance education manufacturing healthcare unstructured data needed analyzed distribute structured manner required information gathered data mining technique used mining data paper expose importance data analytics data management beneficial usage business intelligence big data data mining machine data management addition different technique used discover knowledge useful information data analyzed beneficial numerous user concern text mining convert complex data meaningful information researcher analyst data scientist business decision maker well']\n","2024-10-11 10:58:18,322 - INFO - 에폭 1/5, 손실: 721.9266\n","2024-10-11 10:58:18,329 - INFO - 에폭 2/5, 손실: 710.2436\n","2024-10-11 10:58:18,337 - INFO - 에폭 3/5, 손실: 699.5680\n","2024-10-11 10:58:18,345 - INFO - 에폭 4/5, 손실: 690.0354\n","2024-10-11 10:58:18,352 - INFO - 에폭 5/5, 손실: 680.2270\n","2024-10-11 10:58:18,370 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:18,383 - INFO - built Dictionary<2585 unique tokens: ['accurate', 'achieving', 'actual', 'aggregated', 'among']...> from 80 documents (total 10108 corpus positions)\n","2024-10-11 10:58:18,384 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2585 unique tokens: ['accurate', 'achieving', 'actual', 'aggregated', 'among']...> from 80 documents (total 10108 corpus positions)\", 'datetime': '2024-10-11T10:58:18.384664', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:18,569 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:18,570 - INFO - Sample of sampled data: ['enabled web technology social medium provide unparalleled platform consumer share product experience opinion wordofmouth wom consumer review become increasingly important understand wom content metric influence consumer purchase product sale integrating marketing theory text mining technique propose set novel measure focus sentiment divergence consumer product review test validity metric conduct empirical study based data amazoncom bncom barnes noble result demonstrate significant effect proposed measure product sale effect fully captured nontextual review measure numerical rating furthermore capturing sale effect review content divergence metric shown superior appropriate commonly used textual measure literature finding provide important insight business impact social medium usergenerated content emerging problem business intelligence research managerial perspective result suggest firm pay special attention textual content information managing social medium importantly focus right measure', 'classical supervised machine learning technique explored semantically annotating unstructured textual data consumer comment archived social medium website extract business intelligence however technique often require large number manually labeled training example produce accurate annotation several active learning approach designed based probabilistic sequence model explored minimize number labeled training example semantic annotation task recent research shown largemargin classifier viable alternative automated semantic annotation given strong generalization capability ability process highdimensional data however existing active learning method designed probabilistic sequence model easily adapted applied largemargin classifier main contribution paper development novel active learning method largemargin classifier fill aforementioned research gap particular propose innovative perspective taking active learning search optimal parameter largemargin classifier rigorous evaluation involving two benchmark test empirical test based realworld data extracted amazoncom reveals proposed active learning method train effective classifier significantly fewer training example achieving similar annotation performance compared typical stateoftheart classifier us several labeled training example specifically one proposed active learning method reduce number training example level f compared best baseline method evaluated based amazon data set research open door application intelligent semantic annotation technique support realworld application automatically analyzing consumer comment customer relationship management', 'purpose business intelligence gained significant attraction recent past facilitates manager efficient business decisionmaking year attraction toward cryptocurrency cc market increased since cc market highly volatile extremely sensitive shock web data related large event happening around globe designmethodologyapproach research study provides business intelligence model predict five topperforming cc study deep learning linear regression support vector regression svr used predict cc price sentiment megaevents also used enhance performance model finding result show model business intelligence deep learning svr provide better result moreover result show incorporation social medium sentiment data significantly improves performance proposed model overall accuracy model improves approximately twofold multiple event sentiment incorporated originalityvalue use social medium sentiment global local event different country along deep learning cc forecasting', 'online business intelligence system often collect text different source social medium news website heterogeneous practice collection bring difficulty managing organizing comprehensive information hidden different text system effectively organize multisourced text help online user acquire wider knowledge propose business intelligence system integrates multisourced text multisources regarding many occasion multisourced text share common content respect topic example tweet news report may talk event therefore goal correlate text different source respect similar topic get integrated comprehensive information facilitate data mining task well online application handle problem propose heterogeneous information networkbased text aligning hinta framework paper hinta applies metapaths calculate text similarity construct correlated pair two type text next hinta first applies anchored pair bridge combine different type text finally three different inference method employed align multisourced text experimental result realworld dataset show effectiveness efficiency framework addressing text alignment problem', 'social medium platform become new source useful information company ensuring business value social medium first requires analysis quality relevant data development practical business intelligence solution paper aim building highquality datasets social business intelligence sobi proposed method offer integrated dynamic approach identify relevant quality metric analysis domain method employ novel multidimensional data model construction cube impact measure various quality metric model quality metric indicator organized two main ax first one concern kind fact extracted namely post user topic second axis refers quality perspective assessed namely credibility reputation usefulness completeness additionally quality cube include userrole dimension quality metric evaluated term user business role demonstrate usefulness approach author applied method two separate domain automotive business natural disaster management result show tradeoff quantity quality social medium data focused small percentage relevant user thus data filtering easily performed simply ranking post according quality metric identified proposed method far author know first approach integrates extraction analytical fact assessment social medium data quality framework']\n","2024-10-11 10:58:18,590 - INFO - 에폭 1/5, 손실: 711.6606\n","2024-10-11 10:58:18,597 - INFO - 에폭 2/5, 손실: 698.4681\n","2024-10-11 10:58:18,605 - INFO - 에폭 3/5, 손실: 686.0947\n","2024-10-11 10:58:18,612 - INFO - 에폭 4/5, 손실: 675.6613\n","2024-10-11 10:58:18,619 - INFO - 에폭 5/5, 손실: 661.2072\n","2024-10-11 10:58:18,634 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:18,647 - INFO - built Dictionary<2455 unique tokens: ['amazoncom', 'appropriate', 'attention', 'barnes', 'based']...> from 80 documents (total 9816 corpus positions)\n","2024-10-11 10:58:18,648 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2455 unique tokens: ['amazoncom', 'appropriate', 'attention', 'barnes', 'based']...> from 80 documents (total 9816 corpus positions)\", 'datetime': '2024-10-11T10:58:18.648662', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:18,834 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:18,835 - INFO - Sample of sampled data: ['last decade social medium platform become important communication channel business consumer result lot consumergenerated data available online unfortunately fully utilized partly nature unstructured subjective exist massive database make use data one research method needed study proposes new multiple approach social medium data analysis counteracts aforementioned characteristic social medium data new approach data first extracted systematically coded following principle content analysis comprehensive literature review conducted guide coding strategy next relationship code identified statistical cluster analysis relationship used next step analysis evaluation criterion weight derived basis social medium data probability weighting function case study employed test proposed approach', 'online social medium perfect text source stance analysis stance human communication concerned speaker attitude belief feeling opinion expression stance associated speaker view talking discussion negotiation intersubjective exchange taking stance thus crucial social construction meaning increased knowledge stance useful many application field business intelligence security analytics social medium monitoring order process large amount text data stance analysis linguist need interactive tool explore textual source well processed data based computational linguistics technique original text derived data important refining analysis iteratively work present visual analytics tool online social medium text data used open investigation stance phenomenon approach complement traditional linguistic analysis technique based analysis utterance associated two stance category sentiment certainty contribution include description novel webbased solution analyzing use pattern stance meaning expression human communication time specialized technique used visualizing analysis provenance corpus overviewnavigation demonstrate approach mean text medium highly controversial scandal regard expression anger provide expert review linguist using tool', 'purposethe purpose paper analyze correlation twitter activity two airline company stock performance istanbul stock exchange bist designmethodologyapproachoverall tweet divided semantic share tweet semantic tweet tweet mentioning company product service labeled manually deep learning model share tweet divided relevant irrelevant tweet findingsa positive correlation found share tweet stock performance semantic tweet display correlation stock performance relevant share tweet displayed strong correlation share tweet one company also manual labeling tweet led discovery many insight related service provision airway industry management digital support channel management reputation social medium using twitter customer support platform practical implicationsrelevant share tweet comprise share tweet one company show level correlation stock performance mean efficiency business intelligence solution created monitor twitter activity improved five time saving computational power network bandwidth data storage originalityvalueprevious research analyzed twitter activity taken together dividing tweet semantic share tweet paper illustrates fact share tweet correlated stock performance semantic tweet', 'although term big data often used refer large datasets generated science engineering business analytics effort increasingly used refer social networking website enormous quantity personal information post networking activity contained therein quantity sensitive nature information constitutes fascinating mean inferring sociological parameter grave risk security privacy present study aimed find evidence literature malware already adapted significant degree specific form big data evidence potential abuse personal information found predictive model personal trait facebook user alarmingly effective minimal depth information like likely complex form information eg post photo connection status could lead unprecedented level intrusiveness familiarity sensitive personal information support view potential abuse private information exploited found research describing rapid adaptation malware social networking site purpose social engineering involuntary surrendering personal information', 'development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm']\n","2024-10-11 10:58:18,856 - INFO - 에폭 1/5, 손실: 719.4649\n","2024-10-11 10:58:18,864 - INFO - 에폭 2/5, 손실: 707.8444\n","2024-10-11 10:58:18,873 - INFO - 에폭 3/5, 손실: 696.4755\n","2024-10-11 10:58:18,879 - INFO - 에폭 4/5, 손실: 684.6940\n","2024-10-11 10:58:18,888 - INFO - 에폭 5/5, 손실: 674.7902\n","2024-10-11 10:58:18,904 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:18,917 - INFO - built Dictionary<2504 unique tokens: ['aforementioned', 'analysis', 'approach', 'available', 'basis']...> from 80 documents (total 9984 corpus positions)\n","2024-10-11 10:58:18,918 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2504 unique tokens: ['aforementioned', 'analysis', 'approach', 'available', 'basis']...> from 80 documents (total 9984 corpus positions)\", 'datetime': '2024-10-11T10:58:18.918663', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:19,153 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:19,154 - INFO - Sample of sampled data: ['today world flooded unstructured information big data description raw volume real issue usability major part information retrieval giant experience big data real challenge identifying developing cost effective reliable method extracting value terabyte petabyte data available thats big data analytics become necessary conventional analytics focused structured data method appropriate large volume unstructured data order extract knowledge text analytics way extract significance unstructured text find pattern transformation importance text analytics increased social medium business intelligence study reveals big data text analytics breed new insight world text information discusses various research carried text analytics', 'pressing need vehicle quality management professional decision support vehicle defect discovery classification process paper employ text mining popular social medium used vehicle enthusiast online discussion forum find sentiment analysis conventional technique consumer complaint detection insufficient finding categorizing prioritizing vehicle defect discussed online forum describe evaluate new process decision support system automotive defect identification prioritization finding provide managerial insight social medium analytics improve automotive quality management c elsevier bv right reserved', 'cooperative work process analysis decision support currently gain strong attention business world motivated spreading corporate structure technical development like social medium networkoriented data storage encourage user comprehension demand easy communication data article reflects state research domain business intelligence regarding opening process new data source analyst existing approach often labeled collaborative business intelligence cbi differ heavily definition focus therefore framework presented three main field research cbi identified encompass internal communication data storage external partner data analysis partner article compare finding development software market describes open topic research domain', 'social medium platform become integral part daily life generate vast amount data analyzed various purpose however quality data obtained social medium often questionable due factor noise bias incompleteness enhancing data quality crucial ensure reliability validity result obtained data paper proposes enhanced decisionmaking framework based business decision management system bdms address challenge incorporating data quality enhancement component framework includes backtracking method improve plan failure risktaking ability steep optimized strategy enhance training plan resource management contribute improving quality data examine efficacy proposed framework research data provides evidence ability increase level effectiveness performance enhancing data quality additionally demonstrate reliability proposed framework simulation analysis includes true positive analysis performance analysis error analysis accuracy analysis research contributes field business intelligence providing framework address critical data quality challenge faced organization decisionmaking environment', 'product review play crucial role providing valuable insight consumer producer analyzing vast amount data generated around product post comment view challenging business intelligence purpose sentiment analysis content help consumer producer gain better understanding market status enabling make informed decision study propose novel hybrid approach based deep neural network dnns sentiment analysis product review focusing classification sentiment expressed approach utilizes recursive neural network rnn algorithm sentiment classification address imbalanced distribution positive negative sample social network data employ resampling technique balance dataset increasing sample minority class decreasing sample majority class evaluate approach using amazon data comprising four product category clothing car luxury good household appliance experimental result demonstrate proposed approach performs well sentiment analysis product review particularly context digital marketing furthermore attentionbased rnn algorithm outperforms baseline rnn approximately notably study reveals consumer sentiment variation across different product particularly relation appearance price aspect']\n","2024-10-11 10:58:19,176 - INFO - 에폭 1/5, 손실: 700.5239\n","2024-10-11 10:58:19,183 - INFO - 에폭 2/5, 손실: 690.4862\n","2024-10-11 10:58:19,190 - INFO - 에폭 3/5, 손실: 679.7166\n","2024-10-11 10:58:19,198 - INFO - 에폭 4/5, 손실: 670.1898\n","2024-10-11 10:58:19,207 - INFO - 에폭 5/5, 손실: 660.7050\n","2024-10-11 10:58:19,223 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:19,236 - INFO - built Dictionary<2457 unique tokens: ['analytics', 'appropriate', 'available', 'become', 'big']...> from 80 documents (total 9747 corpus positions)\n","2024-10-11 10:58:19,238 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2457 unique tokens: ['analytics', 'appropriate', 'available', 'become', 'big']...> from 80 documents (total 9747 corpus positions)\", 'datetime': '2024-10-11T10:58:19.238667', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:19,427 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:19,428 - INFO - Sample of sampled data: ['document evolution academic research bibliometric analysis retail analytics article published top operation management journal isolate nine decision area via manual coding verify using automated text analysis topic modeling track variation across decision area methodusage evolution per analytics type featuring degree big data eg clickstream social medium product review analytics suited new data source eg machine learning used analysis reveals rapidly growing field evolving term content decision retail sector data methodology determine state practice interviewed global practitioner current use retail analytics interview shed light barrier enablers adopting advanced analytics retail also highlight set company frontier eg amazon alibaba walmart apart rest combining insight survey academic research interview practitioner provide direction future academic research take advantage availability big data', 'social medium monitoring become important mean business analytics trend detection instance analyzing sentiment towards certain product decision lot work dedicated analyze sentiment english text much less effort put providing accurate sentiment classification german language paper analyze three established classifier german language respect facebook post present hierarchical approach classify sentiment evaluate using data set similar facebook post corporate well governmental facebook page compare approach three sentiment classifier german ie alchemyap iota semantria sentistrength accuracy approach performs better classifier application scenario demonstrate classifier ability monitor change sentiment respect refugee crisis', 'main purpose social business intelligence help company making decision performing multidimensional analysis relevant information disseminated social network although data quality general issue sbi approach aimed assessing data collection context dependent task paper define quality indicator metric serf assess overall quality collection integrates measure obtained several quality criterion applied filter post relevant sbi project selection best quality criterion include quality indicator complex task requires deep understanding context objective analysis paper propose new methodology design quality indicator sbi project whose quality criterion consider content coherence data provenance thus context defined objective analysis methodology help user find quality criterion best suit user available data integrate valid quality indicator', 'classical supervised machine learning technique explored semantically annotating unstructured textual data consumer comment archived social medium website extract business intelligence however technique often require large number manually labeled training example produce accurate annotation several active learning approach designed based probabilistic sequence model explored minimize number labeled training example semantic annotation task recent research shown largemargin classifier viable alternative automated semantic annotation given strong generalization capability ability process highdimensional data however existing active learning method designed probabilistic sequence model easily adapted applied largemargin classifier main contribution paper development novel active learning method largemargin classifier fill aforementioned research gap particular propose innovative perspective taking active learning search optimal parameter largemargin classifier rigorous evaluation involving two benchmark test empirical test based realworld data extracted amazoncom reveals proposed active learning method train effective classifier significantly fewer training example achieving similar annotation performance compared typical stateoftheart classifier us several labeled training example specifically one proposed active learning method reduce number training example level f compared best baseline method evaluated based amazon data set research open door application intelligent semantic annotation technique support realworld application automatically analyzing consumer comment customer relationship management', 'purpose purpose paper better understand management accounting automation exploring programmability management accounting work designmethodologyapproach build upon literature digitalization management accounting draw upon pragmatic constructivist methodology understand digitalization take place individual actor level accounting practice paper us data set interventionist case study machinery manufacturer finding examine actual process automating management accounting task development process surprisingly calculation task remained fit human machine though initially thought programmable research limitationsimplications according finding practitioner may interpret expert nonprogrammable work task programmable seek automate identifying factual possibility automating accountingrelated work lead automationimproved efficiency finding increasingly relevant advanced analytics initiative application within management accounting eg robotic process automation big data machine learning artificial intelligence practical implication practitioner need carefully analyze entity wish automate understand factual possibility using maintaining planned automatic system throughout life cycle originalityvalue paper show process assessed distance nonprogrammable management accounting task expertise become misinterpreted programmable goal automating little chance success also show possibility human accountant remain relevant comparison machine pave way study advanced decision technology management accounting']\n","2024-10-11 10:58:19,450 - INFO - 에폭 1/5, 손실: 683.7307\n","2024-10-11 10:58:19,458 - INFO - 에폭 2/5, 손실: 669.2756\n","2024-10-11 10:58:19,467 - INFO - 에폭 3/5, 손실: 656.6617\n","2024-10-11 10:58:19,475 - INFO - 에폭 4/5, 손실: 645.0164\n","2024-10-11 10:58:19,482 - INFO - 에폭 5/5, 손실: 633.4130\n","2024-10-11 10:58:19,496 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:19,509 - INFO - built Dictionary<2394 unique tokens: ['academic', 'across', 'adopting', 'advanced', 'advantage']...> from 80 documents (total 9231 corpus positions)\n","2024-10-11 10:58:19,510 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2394 unique tokens: ['academic', 'across', 'adopting', 'advanced', 'advantage']...> from 80 documents (total 9231 corpus positions)\", 'datetime': '2024-10-11T10:58:19.510306', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:19,692 - INFO - Analyzing stability for domain: media\n","2024-10-11 10:58:19,693 - INFO - Original data type: <class 'list'>\n","2024-10-11 10:58:19,693 - INFO - Processed data type: <class 'list'>\n","2024-10-11 10:58:19,694 - INFO - Sample of processed data: ['short ageappropriate theyre loose fitting cal rolled left end knee fabric soft color fun', 'thought top looked adorable material soft top like dont usually look great someone little bit busty make look fat like youre wearing maternity real issue arm hole large seemed gape bit didnt look flattering even wore cute lacy bandeau bra way material stick around arm hole would still look awkward bad since cute top well made', 'sweater nice addition fall spring wardrobe must layered sheer read review snagging issue yet', 'loved got flattering fit slightly loose body flowy nice weight fabric comfortable fabric perfect scoop neck doesnt show much cleavage washed delicate line dried shirt came riddled hole', 'worried skirt might look much like bedspread gorgeous cut flattering ordered petite small fit perfectly great fallwinter skirt']\n","2024-10-11 10:58:19,698 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:19,699 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:24,293 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:24,294 - INFO - Sample of sampled data: ['huge otherwise thought nice top slimming didnt bother looking another size though got medium wear small medium', 'worn top multiple time jean neckline make even u small busted look great top', 'top new favorite ordered whim oh boy glad excited shipped arrived couldnt wait put put couldnt wait show great bluishgrayish color look great big hoop earring short sandal easy classic simple shirt probably wear much', 'agree othersthis type sweater hooked retailer ten year ago love new sweater recommend wearing long sleeve tee underneath sleeve itchy', 'dress nice flow simple versatile pair jacket cardigan winter use year round however run one size large']\n","2024-10-11 10:58:24,298 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:24,298 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:28,289 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:28,293 - INFO - built Dictionary<856 unique tokens: ['another', 'bother', 'didnt', 'got', 'huge']...> from 80 documents (total 2295 corpus positions)\n","2024-10-11 10:58:28,294 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<856 unique tokens: ['another', 'bother', 'didnt', 'got', 'huge']...> from 80 documents (total 2295 corpus positions)\", 'datetime': '2024-10-11T10:58:28.294551', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:28,303 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:28,304 - INFO - Sample of sampled data: ['love sweater found sale section week ago wasnt sure would bulky dark smudge collar left someone something thought maybe left behind others reason quality nice thankfully washed smudge came live houston tx dont need wear wool cashmere sweater warmth mostly cotton well made sleeve longer model', 'bought outfit online sale paid think saw person first probably wouldnt purchased design cute fabric beyond cheap polyester like plastic polyester think dress high heel necklace armful bangle probably distract fabric lb purchased x little big still', 'great swingy tank summer smocking add nice design element otherwise plain white top typically wear l sometimes xl top retailer l pretty loose hoping shrink quite bit wash otherwise really love top sale price definitely right wish black one still available', 'drew shirt beautiful silver gold embroidery front shirt folded store make sense hung fewer people would try shirt sheer front sheer back bug many clothes made day cheaply made thin cloth forced layer camisole something else order wear public cant wear sheer clothes', 'retailer store mostly white left pilcro linen pant tried main reason leave store could see washing tag inside pant clear day white pant seethrough really looking casual item wear office least lined pant would come home otherwise think fit tt']\n","2024-10-11 10:58:28,308 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:28,309 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:32,338 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:32,343 - INFO - built Dictionary<864 unique tokens: ['ago', 'behind', 'bulky', 'came', 'cashmere']...> from 80 documents (total 2330 corpus positions)\n","2024-10-11 10:58:32,344 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<864 unique tokens: ['ago', 'behind', 'bulky', 'came', 'cashmere']...> from 80 documents (total 2330 corpus positions)\", 'datetime': '2024-10-11T10:58:32.344576', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:32,490 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:32,491 - INFO - Sample of sampled data: ['im lb buying clothes retailer always stuggle petite frame dont fall petite height range usually order petite size deal shorter length hard youre limb purchased r im love fit top dress fit arm perfectly waist dress also hit nicely usually waist regular sized dress fall natural waistline due short', 'cute comfy dont throw leg like model mostly read skirt leg full really comfortable pair well surprising number top', 'absolutely gorgeous word cant describe beauty dress hope restock cause would order size didnt know run', 'shirt awful anything pretty there reason main photo model arm crossed waist run good top get body garment run straight yet pleat even make manage expand little get lovely detailed hem rein left bit poof effect making rounder wrong way one im lazy send back awful', 'great addition wardrobe go nice trouser dressier shoe work jean trainer casual look didnt find run small indeed thought fit id expect']\n","2024-10-11 10:58:32,495 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:32,495 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:36,463 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:36,468 - INFO - built Dictionary<884 unique tokens: ['also', 'always', 'arm', 'buying', 'clothes']...> from 80 documents (total 2343 corpus positions)\n","2024-10-11 10:58:36,468 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<884 unique tokens: ['also', 'always', 'arm', 'buying', 'clothes']...> from 80 documents (total 2343 corpus positions)\", 'datetime': '2024-10-11T10:58:36.468823', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:36,602 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:36,602 - INFO - Sample of sampled data: ['im normally one spend dress retailer dress arrived mail nobrainer would keep hang beautifully body fabric extremely comfortable tie waist really flattering neckline add little bit fun imagine go season season pretty easily springtime cardigan flat summer wedge fall tights boot love piece serve different purpose', 'drew shirt beautiful silver gold embroidery front shirt folded store make sense hung fewer people would try shirt sheer front sheer back bug many clothes made day cheaply made thin cloth forced layer camisole something else order wear public cant wear sheer clothes', 'like people wanted beautiful dress fit decided see maybe maybe negative review wrong werent sort breast top probably wont fit properly imagine narrow upper torso like possibly might find top part dress close properly c could get size button waist hit strange spot despite picture showing narrow waist grad', 'cut boxy side im sold tiered effect love silk fabric print much dont care silk deliciously light breathable print neutral enough pair several different cardigan necklace mix quality construction excellentall seam expertly sewn pressed print lined like online picture given material construction quality de', 'dress made lightweight linen lined separate slip high quality nice detail tt sleeve average length length dress feel appropriate frame hookandeye closure chest area keep button aligned quality detail think lovely dress go work play']\n","2024-10-11 10:58:36,607 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:36,608 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:40,592 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:40,596 - INFO - built Dictionary<870 unique tokens: ['add', 'arrived', 'beautifully', 'bit', 'body']...> from 80 documents (total 2336 corpus positions)\n","2024-10-11 10:58:40,597 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<870 unique tokens: ['add', 'arrived', 'beautifully', 'bit', 'body']...> from 80 documents (total 2336 corpus positions)\", 'datetime': '2024-10-11T10:58:40.597261', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:40,731 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:40,731 - INFO - Sample of sampled data: ['normally wear small sometimes medium even extra small feel large length gorgeous though', 'dress made lightweight linen lined separate slip high quality nice detail tt sleeve average length length dress feel appropriate frame hookandeye closure chest area keep button aligned quality detail think lovely dress go work play', 'bought outfit online sale paid think saw person first probably wouldnt purchased design cute fabric beyond cheap polyester like plastic polyester think dress high heel necklace armful bangle probably distract fabric lb purchased x little big still', 'lightweight cardigan looked like eggplant color online brown hint burgandy bad unexpected short waisted lie high torso seam unfinished look cheaply made glad got sale', 'im obsessed top actually love side bit higher front back feel like give shape bought jean similar pic look good together love']\n","2024-10-11 10:58:40,736 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:40,736 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:45,299 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:45,303 - INFO - built Dictionary<837 unique tokens: ['even', 'extra', 'feel', 'gorgeous', 'large']...> from 80 documents (total 2257 corpus positions)\n","2024-10-11 10:58:45,304 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<837 unique tokens: ['even', 'extra', 'feel', 'gorgeous', 'large']...> from 80 documents (total 2257 corpus positions)\", 'datetime': '2024-10-11T10:58:45.304306', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:45,314 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:45,314 - INFO - Sample of sampled data: ['ordered p yellow yellow rich golden yellow easter yellow see monitor hoping itd im keeping fit perfectly chesty size ddd somehow dont look bigger top also broad shoulder doesnt feel tight move arm bonus loop keep bra strap place dock star though quite fabric thread trim f', 'cute short great fabric lined lay smooth body really love material dressier feel ran bit large looked sort frumpy curvy body im returning trying small elastic waist great baby would look fine belt covered shirt', 'love dress would definitely accessorize belt body type fit best style dress dont big bust size would try first shorter love length', 'beautiful flattering breathablecomfortable mock neck turtleneck thats great layering unfamiliar weston top like many others essentially made panty hose nylon make super comfy stretchy top albeit delicate one mindful hair accessory jewelery wearing wish arm lined large tattoo arm see look little odd mixe', 'come scoop basically ever elevenses jumpsuit release perfection always perfect fit quality fabric im taller side found fit perfectly yet somehow look equally perfect shorter lady saw dressing room awesome']\n","2024-10-11 10:58:45,319 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:45,319 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:49,671 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:49,676 - INFO - built Dictionary<883 unique tokens: ['also', 'arm', 'bigger', 'bonus', 'bra']...> from 80 documents (total 2423 corpus positions)\n","2024-10-11 10:58:49,677 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<883 unique tokens: ['also', 'arm', 'bigger', 'bonus', 'bra']...> from 80 documents (total 2423 corpus positions)\", 'datetime': '2024-10-11T10:58:49.677910', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:49,813 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:49,814 - INFO - Sample of sampled data: ['really cute fabric little stiff detail nice waist seems big suggest sizing bought p usual size sent back p waist big', 'love dress high quality dress classic style cotton eyelet detailing favorite part really elevates another black dress swing silhouette described product description little volume regular dress thats make fun breezy great dress cant wait wear get little warmer', 'wanted like top especially comfortable material color asymmetrical shape didnt hang well also run big got small although bodice fit okay sleeve long bottom top looked mishaped dumpy top going back', 'hoping find slimming cozy sweater unfortunately one baggy material really bulky one occasion would never purchased person online cant quite tell style fit returned item', 'agree othersthis type sweater hooked retailer ten year ago love new sweater recommend wearing long sleeve tee underneath sleeve itchy']\n","2024-10-11 10:58:49,817 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:49,818 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:53,769 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:53,774 - INFO - built Dictionary<895 unique tokens: ['back', 'big', 'bought', 'cute', 'detail']...> from 80 documents (total 2414 corpus positions)\n","2024-10-11 10:58:53,775 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<895 unique tokens: ['back', 'big', 'bought', 'cute', 'detail']...> from 80 documents (total 2414 corpus positions)\", 'datetime': '2024-10-11T10:58:53.775980', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:53,785 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:53,785 - INFO - Sample of sampled data: ['one special dress ever owned kind dress person one beautiful detailing sheer sleeve bodice bottom half lined fit beautifully little busty worried button front buttoning popping open addition button hidden hook ensure stay closed unusual reflection quality dress length right abou', 'thought top looked adorable material soft top like dont usually look great someone little bit busty make look fat like youre wearing maternity real issue arm hole large seemed gape bit didnt look flattering even wore cute lacy bandeau bra way material stick around arm hole would still look awkward bad since cute top well made', 'like people wanted beautiful dress fit decided see maybe maybe negative review wrong werent sort breast top probably wont fit properly imagine narrow upper torso like possibly might find top part dress close properly c could get size button waist hit strange spot despite picture showing narrow waist grad', 'drew shirt beautiful silver gold embroidery front shirt folded store make sense hung fewer people would try shirt sheer front sheer back bug many clothes made day cheaply made thin cloth forced layer camisole something else order wear public cant wear sheer clothes', 'dress thick cotton material like sweatshirt hoping wear wedding tunic best bell part sleeve also stick awkwardly fabric']\n","2024-10-11 10:58:53,790 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:53,791 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:58:57,736 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:58:57,740 - INFO - built Dictionary<874 unique tokens: ['abou', 'addition', 'beautiful', 'beautifully', 'bodice']...> from 80 documents (total 2338 corpus positions)\n","2024-10-11 10:58:57,741 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<874 unique tokens: ['abou', 'addition', 'beautiful', 'beautifully', 'bodice']...> from 80 documents (total 2338 corpus positions)\", 'datetime': '2024-10-11T10:58:57.741486', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:58:57,751 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:58:57,751 - INFO - Sample of sampled data: ['one special dress ever owned kind dress person one beautiful detailing sheer sleeve bodice bottom half lined fit beautifully little busty worried button front buttoning popping open addition button hidden hook ensure stay closed unusual reflection quality dress length right abou', 'fell charcoal one bought standard size ml first wearing slim jean booty long sleeved body vest fine wavy shoulderlength hair found large wide collar overwhelming top tried folding collar photo gray one still much altered paring inch back neck tapering meet lapel midchest fabric look like boiled wool actually tigh', 'sweater little bit let ordered pink actually tan sweater bright coral material woven throughout wasnt soft pinkcoral color appeared online material cozy sweater short boxy wouldve like width better length wouldve little proportionate ordered petite small probably returning', 'coat cool cut classic well fit ive wearing jacket every day since purchasing day ago already begun slightly pill worn jacket pilling quickly basic wear', 'worried skirt might look much like bedspread gorgeous cut flattering ordered petite small fit perfectly great fallwinter skirt']\n","2024-10-11 10:58:57,756 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:58:57,756 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:02,981 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:02,989 - INFO - built Dictionary<879 unique tokens: ['abou', 'addition', 'beautiful', 'beautifully', 'bodice']...> from 80 documents (total 2385 corpus positions)\n","2024-10-11 10:59:02,990 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<879 unique tokens: ['abou', 'addition', 'beautiful', 'beautifully', 'bodice']...> from 80 documents (total 2385 corpus positions)\", 'datetime': '2024-10-11T10:59:02.990105', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:03,009 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:03,010 - INFO - Sample of sampled data: ['love coat great fall piece bought green color look shown picture great retailer purchase', 'shirt awful anything pretty there reason main photo model arm crossed waist run good top get body garment run straight yet pleat even make manage expand little get lovely detailed hem rein left bit poof effect making rounder wrong way one im lazy send back awful', 'sweater run oversized soft comfortable color spot fall love sleeve length', 'love dress would definitely accessorize belt body type fit best style dress dont big bust size would try first shorter love length', 'absolutely lovely dress gorgeous color drape well perfect blend pretty sexy much beautiful person']\n","2024-10-11 10:59:03,019 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:03,020 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:07,945 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:07,951 - INFO - built Dictionary<870 unique tokens: ['bought', 'coat', 'color', 'fall', 'great']...> from 80 documents (total 2276 corpus positions)\n","2024-10-11 10:59:07,952 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<870 unique tokens: ['bought', 'coat', 'color', 'fall', 'great']...> from 80 documents (total 2276 corpus positions)\", 'datetime': '2024-10-11T10:59:07.952047', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:07,965 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:07,966 - INFO - Sample of sampled data: ['thought top looked adorable material soft top like dont usually look great someone little bit busty make look fat like youre wearing maternity real issue arm hole large seemed gape bit didnt look flattering even wore cute lacy bandeau bra way material stick around arm hole would still look awkward bad since cute top well made', 'thank goodness nice white basic tee see go back forth x depending want item fit dont like thing form fitting still little postbaby pooch went shirt work well complaint neckline totally straight seam come arm hit neckline bump little bit great nicer basic go well almost', 'top new favorite ordered whim oh boy glad excited shipped arrived couldnt wait put put couldnt wait show great bluishgrayish color look great big hoop earring short sandal easy classic simple shirt probably wear much', 'normally wear small sometimes medium even extra small feel large length gorgeous though', 'wore suit first time yesterday black inner lining leaking causing stain white section seriously bummed super lovely suit']\n","2024-10-11 10:59:07,990 - INFO - 에폭 1/5, 손실: 223.7641\n","2024-10-11 10:59:08,002 - INFO - 에폭 2/5, 손실: 220.1383\n","2024-10-11 10:59:08,011 - INFO - 에폭 3/5, 손실: 216.6652\n","2024-10-11 10:59:08,021 - INFO - 에폭 4/5, 손실: 213.1657\n","2024-10-11 10:59:08,030 - INFO - 에폭 5/5, 손실: 210.1343\n","2024-10-11 10:59:08,036 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:08,042 - INFO - built Dictionary<885 unique tokens: ['adorable', 'arm', 'around', 'awkward', 'bad']...> from 80 documents (total 2405 corpus positions)\n","2024-10-11 10:59:08,043 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<885 unique tokens: ['adorable', 'arm', 'around', 'awkward', 'bad']...> from 80 documents (total 2405 corpus positions)\", 'datetime': '2024-10-11T10:59:08.043562', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:08,296 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:08,297 - INFO - Sample of sampled data: ['come scoop basically ever elevenses jumpsuit release perfection always perfect fit quality fabric im taller side found fit perfectly yet somehow look equally perfect shorter lady saw dressing room awesome', 'large cup size year year search perfect suit support doesnt look matronly year baby wanted move one piece still wanted feel sexy youthful thought way suit going look good andor support ff gave try star review tried husband said wow suit hug right place actually support dont know doe', 'bought top size im longer torso thought first would boxy cropped fit well still cover stomach raise arm material thicker side little structured think give nice look drape feel like could wear shirt casual day work blazer dress highly recommend especially since material linen cotton whic', 'ordered purple size xl fit match model think true size wouldnt say there much purple print cant really find area bluered overlap look navy photo show really look great mix light brown peach white red different shade blue variation pattern placement love styleits comfortable', 'bought dress black polka dot pattern style adorable love empire waist fit flattering v come bit low cami work underneath coverage main complaint fabric thin wrinkle extremely easily luckily dark color hide bit disappointing easily wrinkle great style legging tights really allseason dress though ran large purcha']\n","2024-10-11 10:59:08,317 - INFO - 에폭 1/5, 손실: 211.5464\n","2024-10-11 10:59:08,328 - INFO - 에폭 2/5, 손실: 208.2183\n","2024-10-11 10:59:08,339 - INFO - 에폭 3/5, 손실: 205.1755\n","2024-10-11 10:59:08,349 - INFO - 에폭 4/5, 손실: 202.5532\n","2024-10-11 10:59:08,359 - INFO - 에폭 5/5, 손실: 198.6752\n","2024-10-11 10:59:08,366 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:08,373 - INFO - built Dictionary<872 unique tokens: ['always', 'awesome', 'basically', 'come', 'dressing']...> from 80 documents (total 2378 corpus positions)\n","2024-10-11 10:59:08,375 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<872 unique tokens: ['always', 'awesome', 'basically', 'come', 'dressing']...> from 80 documents (total 2378 corpus positions)\", 'datetime': '2024-10-11T10:59:08.374564', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:08,634 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:08,635 - INFO - Sample of sampled data: ['cut boxy side im sold tiered effect love silk fabric print much dont care silk deliciously light breathable print neutral enough pair several different cardigan necklace mix quality construction excellentall seam expertly sewn pressed print lined like online picture given material construction quality de', 'hoping find slimming cozy sweater unfortunately one baggy material really bulky one occasion would never purchased person online cant quite tell style fit returned item', 'overall constructioncraftmanship skirt poor dot sewn seam dot didnt lay flat side seam looked like dot missing around top part skirt back disappointed quality retailer last order similar complaint item sad', 'wonderful cheerful spring dress material slightly thicker expected suppose thought would little thinner summery really work season fit exactly spot would expect tracy reese im ordered p color fit like product photo highly recommended', 'love jean fit great flattering tad snug usual size think time stretch bit receive compliment every time wear go sale buy another']\n","2024-10-11 10:59:08,649 - INFO - 에폭 1/5, 손실: 202.0152\n","2024-10-11 10:59:08,656 - INFO - 에폭 2/5, 손실: 198.3157\n","2024-10-11 10:59:08,663 - INFO - 에폭 3/5, 손실: 194.8101\n","2024-10-11 10:59:08,669 - INFO - 에폭 4/5, 손실: 191.3406\n","2024-10-11 10:59:08,697 - INFO - 에폭 5/5, 손실: 188.0446\n","2024-10-11 10:59:08,703 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:08,708 - INFO - built Dictionary<856 unique tokens: ['boxy', 'breathable', 'cardigan', 'care', 'construction']...> from 80 documents (total 2293 corpus positions)\n","2024-10-11 10:59:08,710 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<856 unique tokens: ['boxy', 'breathable', 'cardigan', 'care', 'construction']...> from 80 documents (total 2293 corpus positions)\", 'datetime': '2024-10-11T10:59:08.709164', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:08,964 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:08,965 - INFO - Sample of sampled data: ['youre curvy girl like shirt flattering hang nicely front clingy also accordian back nice hide back fat plum gorgeous king first time cant yet comment hold washing whether back retains accordian loom hang dry recommendation', 'absolutely gorgeous word cant describe beauty dress hope restock cause would order size didnt know run', 'even shortwaisted lb body super short also super boxy flattering blue good color going back', 'hoping find slimming cozy sweater unfortunately one baggy material really bulky one occasion would never purchased person online cant quite tell style fit returned item', 'loved dress ordered online found color bit muted expected unfortunately fabric quality seemed low considering price point ultimately decided return couldnt justify spending dress didnt seem well made would expect retailer']\n","2024-10-11 10:59:08,979 - INFO - 에폭 1/5, 손실: 221.9167\n","2024-10-11 10:59:08,989 - INFO - 에폭 2/5, 손실: 217.6616\n","2024-10-11 10:59:08,996 - INFO - 에폭 3/5, 손실: 213.7923\n","2024-10-11 10:59:09,004 - INFO - 에폭 4/5, 손실: 210.1103\n","2024-10-11 10:59:09,011 - INFO - 에폭 5/5, 손실: 206.9808\n","2024-10-11 10:59:09,017 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:09,022 - INFO - built Dictionary<892 unique tokens: ['accordian', 'also', 'back', 'cant', 'clingy']...> from 80 documents (total 2393 corpus positions)\n","2024-10-11 10:59:09,023 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<892 unique tokens: ['accordian', 'also', 'back', 'cant', 'clingy']...> from 80 documents (total 2393 corpus positions)\", 'datetime': '2024-10-11T10:59:09.023165', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:09,224 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:09,225 - INFO - Sample of sampled data: ['dress made lightweight linen lined separate slip high quality nice detail tt sleeve average length length dress feel appropriate frame hookandeye closure chest area keep button aligned quality detail think lovely dress go work play', 'cut boxy side im sold tiered effect love silk fabric print much dont care silk deliciously light breathable print neutral enough pair several different cardigan necklace mix quality construction excellentall seam expertly sewn pressed print lined like online picture given material construction quality de', 'love sweater found sale section week ago wasnt sure would bulky dark smudge collar left someone something thought maybe left behind others reason quality nice thankfully washed smudge came live houston tx dont need wear wool cashmere sweater warmth mostly cotton well made sleeve longer model', 'reason everyone giving dress star stunning flattering versatile comfortable im slim athletic size store one medium im generally small hanger look like slim tube thought id try fit fabulous due stretch shape dress id say size medium could fit dont worry sizing one dress suuuuuper stretchy even though fit close throu', 'burgundy plaid color caught eye perfect fall season usually like shoulder top stay one others stated arm stay inside help stayed usual small keep length fine got compliment first time wore glad restocked size sold']\n","2024-10-11 10:59:09,237 - INFO - 에폭 1/5, 손실: 209.3656\n","2024-10-11 10:59:09,244 - INFO - 에폭 2/5, 손실: 205.8343\n","2024-10-11 10:59:09,250 - INFO - 에폭 3/5, 손실: 202.8247\n","2024-10-11 10:59:09,258 - INFO - 에폭 4/5, 손실: 199.7561\n","2024-10-11 10:59:09,264 - INFO - 에폭 5/5, 손실: 196.8915\n","2024-10-11 10:59:09,270 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:09,274 - INFO - built Dictionary<858 unique tokens: ['aligned', 'appropriate', 'area', 'average', 'button']...> from 80 documents (total 2304 corpus positions)\n","2024-10-11 10:59:09,275 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<858 unique tokens: ['aligned', 'appropriate', 'area', 'average', 'button']...> from 80 documents (total 2304 corpus positions)\", 'datetime': '2024-10-11T10:59:09.275148', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:09,480 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:09,481 - INFO - Sample of sampled data: ['im lb buying clothes retailer always stuggle petite frame dont fall petite height range usually order petite size deal shorter length hard youre limb purchased r im love fit top dress fit arm perfectly waist dress also hit nicely usually waist regular sized dress fall natural waistline due short', 'top girlnextdoor sweet im mad plaid love first sight love blouse touch spandex like fitted look tight loose spandex give bit yield size regular fit well im b waist hip hem fall mid hip sleeve fall pas wrist plan wear top tucked sleeve rolled since weather warmer color honey versatile blue motif', 'hoping find slimming cozy sweater unfortunately one baggy material really bulky one occasion would never purchased person online cant quite tell style fit returned item', 'really like top lightweight great quality ive worn casual weekend outing also dressed work', 'even shortwaisted lb body super short also super boxy flattering blue good color going back']\n","2024-10-11 10:59:09,494 - INFO - 에폭 1/5, 손실: 210.6580\n","2024-10-11 10:59:09,501 - INFO - 에폭 2/5, 손실: 207.4470\n","2024-10-11 10:59:09,508 - INFO - 에폭 3/5, 손실: 204.8175\n","2024-10-11 10:59:09,515 - INFO - 에폭 4/5, 손실: 201.9074\n","2024-10-11 10:59:09,522 - INFO - 에폭 5/5, 손실: 198.9239\n","2024-10-11 10:59:09,528 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:09,532 - INFO - built Dictionary<893 unique tokens: ['also', 'always', 'arm', 'buying', 'clothes']...> from 80 documents (total 2381 corpus positions)\n","2024-10-11 10:59:09,533 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<893 unique tokens: ['also', 'always', 'arm', 'buying', 'clothes']...> from 80 documents (total 2381 corpus positions)\", 'datetime': '2024-10-11T10:59:09.533184', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:09,732 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:09,733 - INFO - Sample of sampled data: ['love sweater used work casual wear ease soft seems durable highly recommend', 'bought dress black polka dot pattern style adorable love empire waist fit flattering v come bit low cami work underneath coverage main complaint fabric thin wrinkle extremely easily luckily dark color hide bit disappointing easily wrinkle great style legging tights really allseason dress though ran large purcha', 'wanted love dress like scratchy lining also like scratchy lining considerably smaller overall swing dress clung curve uncomfortably wish done silk would much nicer material returned', 'design dress lb frame lowcut tight bust voluminous unstructured around hip making look wide belt didnt help much fabric nice overall effect dress frumpy', 'retailer defense silk chiffon general super fragile got top turquoise color design beautiful im lb took x fit true size im able wear nude strapless bra top look great worn top couple time end day snag able pull thread back inside top never ever cut silk chiffon love top much bought second one color size back un']\n","2024-10-11 10:59:09,746 - INFO - 에폭 1/5, 손실: 215.8942\n","2024-10-11 10:59:09,752 - INFO - 에폭 2/5, 손실: 212.0056\n","2024-10-11 10:59:09,758 - INFO - 에폭 3/5, 손실: 208.3859\n","2024-10-11 10:59:09,767 - INFO - 에폭 4/5, 손실: 205.0671\n","2024-10-11 10:59:09,775 - INFO - 에폭 5/5, 손실: 201.9335\n","2024-10-11 10:59:09,781 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:09,784 - INFO - built Dictionary<897 unique tokens: ['casual', 'durable', 'ease', 'highly', 'love']...> from 80 documents (total 2346 corpus positions)\n","2024-10-11 10:59:09,785 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<897 unique tokens: ['casual', 'durable', 'ease', 'highly', 'love']...> from 80 documents (total 2346 corpus positions)\", 'datetime': '2024-10-11T10:59:09.785187', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:10,001 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:10,002 - INFO - Sample of sampled data: ['cant wait get colder wear love ochre color paired maroon faux fur lapel especially love detail pocket edge well made faux fur luxuriously soft removable go great denim long skirt wool bit stiff opinion thats okay make great addition autumn winter closet outerwear black dark blue dark grey nice able wear bit', 'retailer store mostly white left pilcro linen pant tried main reason leave store could see washing tag inside pant clear day white pant seethrough really looking casual item wear office least lined pant would come home otherwise think fit tt', 'top new favorite ordered whim oh boy glad excited shipped arrived couldnt wait put put couldnt wait show great bluishgrayish color look great big hoop earring short sandal easy classic simple shirt probably wear much', 'come scoop basically ever elevenses jumpsuit release perfection always perfect fit quality fabric im taller side found fit perfectly yet somehow look equally perfect shorter lady saw dressing room awesome', 'color top amazingmuch vibrant photo fit perfect flirty pretty detailing around top gorgeous pricey splurged glad look adorable corduroy skirt boot fall']\n","2024-10-11 10:59:10,016 - INFO - 에폭 1/5, 손실: 224.0800\n","2024-10-11 10:59:10,022 - INFO - 에폭 2/5, 손실: 220.2678\n","2024-10-11 10:59:10,029 - INFO - 에폭 3/5, 손실: 217.1499\n","2024-10-11 10:59:10,034 - INFO - 에폭 4/5, 손실: 214.3385\n","2024-10-11 10:59:10,042 - INFO - 에폭 5/5, 손실: 210.8954\n","2024-10-11 10:59:10,048 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:10,053 - INFO - built Dictionary<889 unique tokens: ['able', 'addition', 'autumn', 'bit', 'black']...> from 80 documents (total 2434 corpus positions)\n","2024-10-11 10:59:10,054 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<889 unique tokens: ['able', 'addition', 'autumn', 'bit', 'black']...> from 80 documents (total 2434 corpus positions)\", 'datetime': '2024-10-11T10:59:10.054184', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:10,264 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:10,264 - INFO - Sample of sampled data: ['bought celebrate birthday get new suit every year milestone birthday dress disappoint', 'cant wait get colder wear love ochre color paired maroon faux fur lapel especially love detail pocket edge well made faux fur luxuriously soft removable go great denim long skirt wool bit stiff opinion thats okay make great addition autumn winter closet outerwear black dark blue dark grey nice able wear bit', 'purchased tank interesting open neck realizing strap elastic love material super soft fit nicely snug tight strap wide enough cover bra strap neckline little wider really flattering got black one going get color great buy', 'purchased dress redorange color impressed quality fabric waist sat bit higher picture look much like empire waist', 'come scoop basically ever elevenses jumpsuit release perfection always perfect fit quality fabric im taller side found fit perfectly yet somehow look equally perfect shorter lady saw dressing room awesome']\n","2024-10-11 10:59:10,277 - INFO - 에폭 1/5, 손실: 220.1102\n","2024-10-11 10:59:10,283 - INFO - 에폭 2/5, 손실: 217.1884\n","2024-10-11 10:59:10,291 - INFO - 에폭 3/5, 손실: 214.2833\n","2024-10-11 10:59:10,298 - INFO - 에폭 4/5, 손실: 211.4429\n","2024-10-11 10:59:10,304 - INFO - 에폭 5/5, 손실: 209.5189\n","2024-10-11 10:59:10,309 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:10,314 - INFO - built Dictionary<901 unique tokens: ['birthday', 'bought', 'celebrate', 'disappoint', 'dress']...> from 80 documents (total 2441 corpus positions)\n","2024-10-11 10:59:10,315 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<901 unique tokens: ['birthday', 'bought', 'celebrate', 'disappoint', 'dress']...> from 80 documents (total 2441 corpus positions)\", 'datetime': '2024-10-11T10:59:10.315184', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:10,580 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:10,581 - INFO - Sample of sampled data: ['love pilcro wear time usually size grow wearing tried usual size felt like tight sure get looser material feel really good lightweight stripe subtle cute sure ill keep maybe size', 'liked color dress material fine could tell picture seam waist atypical frankly unflattering scalloped hip look horrible hip', 'love almost everything jean color fabric rise perfect unfortunately bag knee ordered size smaller usual since worn keep', 'wanted like top especially comfortable material color asymmetrical shape didnt hang well also run big got small although bodice fit okay sleeve long bottom top looked mishaped dumpy top going back', 'loved got flattering fit slightly loose body flowy nice weight fabric comfortable fabric perfect scoop neck doesnt show much cleavage washed delicate line dried shirt came riddled hole']\n","2024-10-11 10:59:10,595 - INFO - 에폭 1/5, 손실: 217.5083\n","2024-10-11 10:59:10,602 - INFO - 에폭 2/5, 손실: 213.8625\n","2024-10-11 10:59:10,609 - INFO - 에폭 3/5, 손실: 210.6908\n","2024-10-11 10:59:10,616 - INFO - 에폭 4/5, 손실: 207.6875\n","2024-10-11 10:59:10,623 - INFO - 에폭 5/5, 손실: 204.9945\n","2024-10-11 10:59:10,629 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:10,634 - INFO - built Dictionary<880 unique tokens: ['cute', 'feel', 'felt', 'get', 'good']...> from 80 documents (total 2384 corpus positions)\n","2024-10-11 10:59:10,635 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<880 unique tokens: ['cute', 'feel', 'felt', 'get', 'good']...> from 80 documents (total 2384 corpus positions)\", 'datetime': '2024-10-11T10:59:10.635031', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:10,868 - INFO - Analyzing stability for domain: news\n","2024-10-11 10:59:10,869 - INFO - Original data type: <class 'list'>\n","2024-10-11 10:59:10,870 - INFO - Processed data type: <class 'list'>\n","2024-10-11 10:59:10,871 - INFO - Sample of processed data: ['new startup offering certification testing distribution existing opensource software could become dell software industry', 'sir richard branson hope new company first send adventuresome tourist space branson founder airline entertainment telecom holding company virgin group announced monday', 'welfare authority solomon island reacted outrage local soccer fan reportedly offered eightyearold son bait bet solomon clash australia', 'halftime monday night man wearing kansa city jersey put nice move ran field unfortunately chief real', 'one police officer shot dead un peacekeeper haitian riot police took holdout militant loyal ousted president jeanbertrand aristide']\n","2024-10-11 10:59:10,877 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:10,877 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:15,496 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:15,497 - INFO - Sample of sampled data: ['astana kazakhstan reuters russia curtly told united state stay business wednesday u criticism echoed european union president vladimir putin plan radical change boost kremlin power', 'sir richard branson hope new company first send adventuresome tourist space branson founder airline entertainment telecom holding company virgin group announced monday', 'texas ranger pitcher frank francisco suspended rest season fined yesterday throwing chair hit woman broke nose game oakland earlier week', 'despite slight seasonal dip software maker surpasses earnings expectation yearoveryear growth come strong', 'saudi minister ali alnaimi sought take heat oil market promising kingdom could pump extra barrel day immediately demand increase']\n","2024-10-11 10:59:15,501 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:15,502 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:19,514 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:19,517 - INFO - built Dictionary<1059 unique tokens: ['astana', 'boost', 'business', 'change', 'criticism']...> from 80 documents (total 1450 corpus positions)\n","2024-10-11 10:59:19,518 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1059 unique tokens: ['astana', 'boost', 'business', 'change', 'criticism']...> from 80 documents (total 1450 corpus positions)\", 'datetime': '2024-10-11T10:59:19.518989', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:19,738 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:19,739 - INFO - Sample of sampled data: ['though bea system signed licensing deal worth million added new customer quarter licensing revenue dropped million', 'bryon russell playoff every year one played nba final three time kind experience denver nugget could use', 'saudi minister ali alnaimi sought take heat oil market promising kingdom could pump extra barrel day immediately demand increase', 'london president general pervez musharraf succeeded persuading british prime minister tony blair severity kashmir palestine dispute', 'new york uneasy investor sold stock mostly lower tuesday oil price climbed per barrel creating new worry rising energy cost would curb consumer spending corporate profit']\n","2024-10-11 10:59:19,743 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:19,744 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:24,285 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:24,288 - INFO - built Dictionary<1043 unique tokens: ['added', 'bea', 'customer', 'deal', 'dropped']...> from 80 documents (total 1427 corpus positions)\n","2024-10-11 10:59:24,289 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1043 unique tokens: ['added', 'bea', 'customer', 'deal', 'dropped']...> from 80 documents (total 1427 corpus positions)\", 'datetime': '2024-10-11T10:59:24.289777', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:24,468 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:24,469 - INFO - Sample of sampled data: ['new york stock enjoyed lateday rally wednesday finishing higher despite new record price oil gloomy thirdquarter outlook several company volume relatively light investor awaited government job creation report end week', 'athens greece quest surpass mark spitz way michael phelps could savor one greatest race swimming history phelps claimed second third gold medal athens game tuesday winning', 'chris sutton echoed word martin neill saying celtic going win tonight champion league meeting shakhtar donetsk', 'net phone service retailer push misleading product consumer sipphone charge', 'u retail giant walmart investedone million u dollar establish china first retail research center beijing prestigious tsinghua university']\n","2024-10-11 10:59:24,472 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:24,473 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:28,473 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:28,476 - INFO - built Dictionary<1059 unique tokens: ['awaited', 'company', 'creation', 'despite', 'end']...> from 80 documents (total 1486 corpus positions)\n","2024-10-11 10:59:28,477 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1059 unique tokens: ['awaited', 'company', 'creation', 'despite', 'end']...> from 80 documents (total 1486 corpus positions)\", 'datetime': '2024-10-11T10:59:28.477612', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:28,659 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:28,660 - INFO - Sample of sampled data: ['warrant placing former chilean dictator augusto pinochet house arrest charge murder kidnapping suspended appeal lawyer', 'welfare authority solomon island reacted outrage local soccer fan reportedly offered eightyearold son bait bet solomon clash australia', 'free standard group announce tuesday availability linux standard base lsb standard support almost global linux distribution vendor', 'microsofts legal fight eu antitrust penalty enters second day focus turn medium player', 'three congressman asking general accounting office investigate irregularity voting machine presidential election dont anticipate change election outcome kim zetter']\n","2024-10-11 10:59:28,664 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:28,664 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:32,750 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:32,753 - INFO - built Dictionary<1050 unique tokens: ['appeal', 'arrest', 'augusto', 'charge', 'chilean']...> from 80 documents (total 1420 corpus positions)\n","2024-10-11 10:59:32,754 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1050 unique tokens: ['appeal', 'arrest', 'augusto', 'charge', 'chilean']...> from 80 documents (total 1420 corpus positions)\", 'datetime': '2024-10-11T10:59:32.754464', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:32,887 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:32,888 - INFO - Sample of sampled data: ['ap navy put least january decision contract replace aging marine one presidential helicopter fleet giving prospective contractor time lobby prized job', 'sure quarterback controversy boston college nothing new head coach tom brien two choice two senior paul peterson quinton porter', 'washington reuters concerned health official began investigating went wrong british vaccine plant half u flu shot made american jostled nowscarce immunization friday', 'tennessee quarterback steve mcnair released hospital tuesday morning twonight stay bruised sternum', 'texas ranger pitcher frank francisco suspended rest season fined yesterday throwing chair hit woman broke nose game oakland earlier week']\n","2024-10-11 10:59:32,892 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:32,893 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:37,303 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:37,306 - INFO - built Dictionary<1048 unique tokens: ['aging', 'ap', 'contract', 'contractor', 'decision']...> from 80 documents (total 1450 corpus positions)\n","2024-10-11 10:59:37,307 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1048 unique tokens: ['aging', 'ap', 'contract', 'contractor', 'decision']...> from 80 documents (total 1450 corpus positions)\", 'datetime': '2024-10-11T10:59:37.307927', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:37,488 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:37,490 - INFO - Sample of sampled data: ['despite slight seasonal dip software maker surpasses earnings expectation yearoveryear growth come strong', 'saudi minister ali alnaimi sought take heat oil market promising kingdom could pump extra barrel day immediately demand increase', 'universe violent place thought australian astronomer found quotgalactically speaking thing seem little bit safer quot said graham whose research support idea', 'texas ranger pitcher frank francisco suspended rest season fined yesterday throwing chair hit woman broke nose game oakland earlier week', 'fresh fear petrol price today saboteur attacked number pipeline southern iraq latest attack add pressure petrol company raise price pump order protect investment']\n","2024-10-11 10:59:37,495 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:37,496 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:41,620 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:41,623 - INFO - built Dictionary<1046 unique tokens: ['come', 'despite', 'dip', 'earnings', 'expectation']...> from 80 documents (total 1438 corpus positions)\n","2024-10-11 10:59:41,624 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1046 unique tokens: ['come', 'despite', 'dip', 'earnings', 'expectation']...> from 80 documents (total 1438 corpus positions)\", 'datetime': '2024-10-11T10:59:41.624133', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:41,818 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:41,818 - INFO - Sample of sampled data: ['though bea system signed licensing deal worth million added new customer quarter licensing revenue dropped million', 'jack hensley second american citizen held hostage iraq beheadedxinhuaafp photo baghdad sept xinhuanet second american citizen held hostage iraq beheaded kidnapper islamist website said tuesday', 'ap navy put least january decision contract replace aging marine one presidential helicopter fleet giving prospective contractor time lobby prized job', 'forward antawn jamison expected team offensive threat working within framework offense', 'tiger wood married swedish model elin nordegren exclusive resort barbados sunset ceremony reportedly cost million according witness']\n","2024-10-11 10:59:41,822 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:41,823 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:46,514 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:46,518 - INFO - built Dictionary<1072 unique tokens: ['added', 'bea', 'customer', 'deal', 'dropped']...> from 80 documents (total 1461 corpus positions)\n","2024-10-11 10:59:46,518 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1072 unique tokens: ['added', 'bea', 'customer', 'deal', 'dropped']...> from 80 documents (total 1461 corpus positions)\", 'datetime': '2024-10-11T10:59:46.518007', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:46,707 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:46,708 - INFO - Sample of sampled data: ['u federal reserve policymakers probably keep nudging interest rate upward next year trying guard inflation moving moderately enough keep economy expanding', 'nasa broken genesis capsule stuck utah desert shuttle assembly building battered hurricane cape canaveral u space agency defended budget mission wednesday', 'top seed vincent spadea beat fellow american james blake reach quarterfinal u dollar millennium international tennis tournament delray beach florida thursday', 'new york uneasy investor sold stock mostly lower tuesday oil price climbed per barrel creating new worry rising energy cost would curb consumer spending corporate profit', 'london president general pervez musharraf succeeded persuading british prime minister tony blair severity kashmir palestine dispute']\n","2024-10-11 10:59:46,713 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:46,713 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:50,773 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:50,777 - INFO - built Dictionary<1040 unique tokens: ['economy', 'enough', 'expanding', 'federal', 'guard']...> from 80 documents (total 1439 corpus positions)\n","2024-10-11 10:59:50,777 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1040 unique tokens: ['economy', 'enough', 'expanding', 'federal', 'guard']...> from 80 documents (total 1439 corpus positions)\", 'datetime': '2024-10-11T10:59:50.777729', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:50,970 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:50,971 - INFO - Sample of sampled data: ['u retail giant walmart investedone million u dollar establish china first retail research center beijing prestigious tsinghua university', 'warrant placing former chilean dictator augusto pinochet house arrest charge murder kidnapping suspended appeal lawyer', 'astana kazakhstan reuters russia curtly told united state stay business wednesday u criticism echoed european union president vladimir putin plan radical change boost kremlin power', 'reuters german business software giant sap starting see silver lining potentiallinkup rival oracle peoplesoft german sunday newspaper welt sonntag reported', 'vice president annette lu margaret thatcher feisty island taiwan unyielding immensely quotable never taking intellectual prisoner easygoing chen']\n","2024-10-11 10:59:50,976 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:50,977 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:55,108 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:55,112 - INFO - built Dictionary<1060 unique tokens: ['beijing', 'center', 'china', 'dollar', 'establish']...> from 80 documents (total 1472 corpus positions)\n","2024-10-11 10:59:55,113 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1060 unique tokens: ['beijing', 'center', 'china', 'dollar', 'establish']...> from 80 documents (total 1472 corpus positions)\", 'datetime': '2024-10-11T10:59:55.113761', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:55,239 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:55,240 - INFO - Sample of sampled data: ['web developer david poteet new city medium report user interface conference', 'vice president annette lu margaret thatcher feisty island taiwan unyielding immensely quotable never taking intellectual prisoner easygoing chen', 'however coming earlier longhorn trimmed innovative stuff seen earlier build', 'open source development lab upgraded key linux kernel development tool scalable test platform new feature improve simulation enterprise data center linux kernel', 'new york uneasy investor sold stock mostly lower tuesday oil price climbed per barrel creating new worry rising energy cost would curb consumer spending corporate profit']\n","2024-10-11 10:59:55,245 - INFO - Use pytorch device_name: cpu\n","2024-10-11 10:59:55,245 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 10:59:59,235 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:59,238 - INFO - built Dictionary<1027 unique tokens: ['city', 'conference', 'david', 'developer', 'interface']...> from 80 documents (total 1407 corpus positions)\n","2024-10-11 10:59:59,239 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1027 unique tokens: ['city', 'conference', 'david', 'developer', 'interface']...> from 80 documents (total 1407 corpus positions)\", 'datetime': '2024-10-11T10:59:59.239806', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:59,371 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:59,372 - INFO - Sample of sampled data: ['washington reuters amtrak another financial hole posting billion operating loss last fiscal year receiving far less requested federal subsidy influential transportation watchdog said sunday', 'chief organisation american state accused corruption costa rica quits two week job', 'belarus electoral commission announced sunday referendum approved lifting constitutional ban third consecutive term president lukashenko', 'tiger wood married swedish model elin nordegren exclusive resort barbados sunset ceremony reportedly cost million according witness', 'web site visitor clicked banner ad number popular european web site weekend may infected computer variant bofra worm expert said today']\n","2024-10-11 10:59:59,383 - INFO - 에폭 1/5, 손실: 128.1588\n","2024-10-11 10:59:59,389 - INFO - 에폭 2/5, 손실: 126.3137\n","2024-10-11 10:59:59,394 - INFO - 에폭 3/5, 손실: 124.0617\n","2024-10-11 10:59:59,400 - INFO - 에폭 4/5, 손실: 122.4646\n","2024-10-11 10:59:59,406 - INFO - 에폭 5/5, 손실: 120.7454\n","2024-10-11 10:59:59,410 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:59,414 - INFO - built Dictionary<1058 unique tokens: ['amtrak', 'another', 'billion', 'far', 'federal']...> from 80 documents (total 1444 corpus positions)\n","2024-10-11 10:59:59,415 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1058 unique tokens: ['amtrak', 'another', 'billion', 'far', 'federal']...> from 80 documents (total 1444 corpus positions)\", 'datetime': '2024-10-11T10:59:59.415597', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:59,637 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:59,637 - INFO - Sample of sampled data: ['music industry magazine soon publishing list bestselling ring tone according source', 'u retail giant walmart investedone million u dollar establish china first retail research center beijing prestigious tsinghua university', 'gold medalwinning marlon devonish say men xm olympic relay triumph put british sprinting back map devonish darren campbell jason gardener mark lewisfrancis edged american', 'vice president annette lu margaret thatcher feisty island taiwan unyielding immensely quotable never taking intellectual prisoner easygoing chen', 'reuters hewlettpackard co theworlds numbertwo pc maker said friday launched yuan computer china turning heat theintensely competitive market']\n","2024-10-11 10:59:59,649 - INFO - 에폭 1/5, 손실: 126.6656\n","2024-10-11 10:59:59,655 - INFO - 에폭 2/5, 손실: 124.9583\n","2024-10-11 10:59:59,660 - INFO - 에폭 3/5, 손실: 123.2458\n","2024-10-11 10:59:59,666 - INFO - 에폭 4/5, 손실: 122.0562\n","2024-10-11 10:59:59,675 - INFO - 에폭 5/5, 손실: 120.6575\n","2024-10-11 10:59:59,691 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:59,694 - INFO - built Dictionary<1054 unique tokens: ['according', 'bestselling', 'industry', 'list', 'magazine']...> from 80 documents (total 1453 corpus positions)\n","2024-10-11 10:59:59,695 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1054 unique tokens: ['according', 'bestselling', 'industry', 'list', 'magazine']...> from 80 documents (total 1453 corpus positions)\", 'datetime': '2024-10-11T10:59:59.695597', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 10:59:59,951 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 10:59:59,952 - INFO - Sample of sampled data: ['google warned thursday increased competition maturing company would result quotinevitable quot slowing growth', 'new startup offering certification testing distribution existing opensource software could become dell software industry', 'texas ranger pitcher frank francisco suspended rest season fined yesterday throwing chair hit woman broke nose game oakland earlier week', 'ap video posted monday web site showed beheading man identified american civil engineer eugene armstrong militant group led abu musab alzarqawi claimed responsibility slaying said another hostage either american briton would killed hour', 'nasa broken genesis capsule stuck utah desert shuttle assembly building battered hurricane cape canaveral u space agency defended budget mission wednesday']\n","2024-10-11 10:59:59,962 - INFO - 에폭 1/5, 손실: 124.9326\n","2024-10-11 10:59:59,967 - INFO - 에폭 2/5, 손실: 122.9465\n","2024-10-11 10:59:59,971 - INFO - 에폭 3/5, 손실: 121.1055\n","2024-10-11 10:59:59,976 - INFO - 에폭 4/5, 손실: 119.7849\n","2024-10-11 10:59:59,981 - INFO - 에폭 5/5, 손실: 117.6069\n","2024-10-11 10:59:59,984 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 10:59:59,987 - INFO - built Dictionary<1064 unique tokens: ['company', 'competition', 'google', 'growth', 'increased']...> from 80 documents (total 1461 corpus positions)\n","2024-10-11 10:59:59,988 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1064 unique tokens: ['company', 'competition', 'google', 'growth', 'increased']...> from 80 documents (total 1461 corpus positions)\", 'datetime': '2024-10-11T10:59:59.988985', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:00,208 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 11:00:00,209 - INFO - Sample of sampled data: ['page brin schmidt hold one third company stock still retain current holding san francisco reuters google inc', 'northern irish drug maker warner chilcott plc received bid approach worth penny per share value company billion pound', 'sudan decided postpone decision expel head two british aid agency oxfam save child citing administrative difficulty humanitarian ground', 'ap navy put least january decision contract replace aging marine one presidential helicopter fleet giving prospective contractor time lobby prized job', 'new york uneasy investor sold stock mostly lower tuesday oil price climbed per barrel creating new worry rising energy cost would curb consumer spending corporate profit']\n","2024-10-11 11:00:00,219 - INFO - 에폭 1/5, 손실: 131.8202\n","2024-10-11 11:00:00,224 - INFO - 에폭 2/5, 손실: 129.5124\n","2024-10-11 11:00:00,229 - INFO - 에폭 3/5, 손실: 127.0726\n","2024-10-11 11:00:00,235 - INFO - 에폭 4/5, 손실: 124.8378\n","2024-10-11 11:00:00,240 - INFO - 에폭 5/5, 손실: 122.0996\n","2024-10-11 11:00:00,244 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:00,248 - INFO - built Dictionary<1060 unique tokens: ['brin', 'company', 'current', 'francisco', 'google']...> from 80 documents (total 1464 corpus positions)\n","2024-10-11 11:00:00,249 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1060 unique tokens: ['brin', 'company', 'current', 'francisco', 'google']...> from 80 documents (total 1464 corpus positions)\", 'datetime': '2024-10-11T11:00:00.249983', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:00,476 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 11:00:00,477 - INFO - Sample of sampled data: ['reuters hewlettpackard co theworlds numbertwo pc maker said friday launched yuan computer china turning heat theintensely competitive market', 'indianapolisbased drug manufacturer eli lilly eliminating u job order streamline operation become competitive', 'texas ranger pitcher frank francisco suspended rest season fined yesterday throwing chair hit woman broke nose game oakland earlier week', 'tiger wood married swedish model elin nordegren exclusive resort barbados sunset ceremony reportedly cost million according witness', 'though bea system signed licensing deal worth million added new customer quarter licensing revenue dropped million']\n","2024-10-11 11:00:00,487 - INFO - 에폭 1/5, 손실: 133.0550\n","2024-10-11 11:00:00,492 - INFO - 에폭 2/5, 손실: 130.9802\n","2024-10-11 11:00:00,497 - INFO - 에폭 3/5, 손실: 129.2652\n","2024-10-11 11:00:00,502 - INFO - 에폭 4/5, 손실: 127.4018\n","2024-10-11 11:00:00,507 - INFO - 에폭 5/5, 손실: 125.6903\n","2024-10-11 11:00:00,510 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:00,514 - INFO - built Dictionary<1034 unique tokens: ['china', 'co', 'competitive', 'computer', 'friday']...> from 80 documents (total 1446 corpus positions)\n","2024-10-11 11:00:00,515 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1034 unique tokens: ['china', 'co', 'competitive', 'computer', 'friday']...> from 80 documents (total 1446 corpus positions)\", 'datetime': '2024-10-11T11:00:00.515984', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:00,772 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 11:00:00,773 - INFO - Sample of sampled data: ['however coming earlier longhorn trimmed innovative stuff seen earlier build', 'google warned thursday increased competition maturing company would result quotinevitable quot slowing growth', 'many around nfl say surprised team poor performance question whether problem lie redskin system player joe gibbs', 'texas ranger pitcher frank francisco suspended rest season fined yesterday throwing chair hit woman broke nose game oakland earlier week', 'open source development lab upgraded key linux kernel development tool scalable test platform new feature improve simulation enterprise data center linux kernel']\n","2024-10-11 11:00:00,783 - INFO - 에폭 1/5, 손실: 128.0378\n","2024-10-11 11:00:00,788 - INFO - 에폭 2/5, 손실: 125.5527\n","2024-10-11 11:00:00,793 - INFO - 에폭 3/5, 손실: 123.5779\n","2024-10-11 11:00:00,799 - INFO - 에폭 4/5, 손실: 121.5057\n","2024-10-11 11:00:00,805 - INFO - 에폭 5/5, 손실: 119.0505\n","2024-10-11 11:00:00,809 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:00,811 - INFO - built Dictionary<1056 unique tokens: ['build', 'coming', 'earlier', 'however', 'innovative']...> from 80 documents (total 1445 corpus positions)\n","2024-10-11 11:00:00,813 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1056 unique tokens: ['build', 'coming', 'earlier', 'however', 'innovative']...> from 80 documents (total 1445 corpus positions)\", 'datetime': '2024-10-11T11:00:00.813470', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:01,020 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 11:00:01,021 - INFO - Sample of sampled data: ['oakland calif texas reliever frank francisco threw chair fan lower box left ranger bullpen along rightfield line ninth inning oakland athletics monday night', 'ap car bomber rammed u convoy wednesday american force battled militant north baghdad leaving total least people dead witness said', 'ap video posted monday web site showed beheading man identified american civil engineer eugene armstrong militant group led abu musab alzarqawi claimed responsibility slaying said another hostage either american briton would killed hour', 'cell carrier certifies quicktime format delivering video handset', 'patriot safety rodney harrison voted dirtiest player football recent poll conducted sport illustrated current former nfl player surprised']\n","2024-10-11 11:00:01,031 - INFO - 에폭 1/5, 손실: 130.4334\n","2024-10-11 11:00:01,036 - INFO - 에폭 2/5, 손실: 128.2578\n","2024-10-11 11:00:01,041 - INFO - 에폭 3/5, 손실: 126.1434\n","2024-10-11 11:00:01,047 - INFO - 에폭 4/5, 손실: 123.9176\n","2024-10-11 11:00:01,052 - INFO - 에폭 5/5, 손실: 121.9878\n","2024-10-11 11:00:01,056 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:01,060 - INFO - built Dictionary<1052 unique tokens: ['along', 'athletics', 'box', 'bullpen', 'calif']...> from 80 documents (total 1446 corpus positions)\n","2024-10-11 11:00:01,061 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1052 unique tokens: ['along', 'athletics', 'box', 'bullpen', 'calif']...> from 80 documents (total 1446 corpus positions)\", 'datetime': '2024-10-11T11:00:01.061471', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:01,315 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 11:00:01,316 - INFO - Sample of sampled data: ['tiger wood married swedish model elin nordegren exclusive resort barbados sunset ceremony reportedly cost million according witness', 'reuters german business software giant sap starting see silver lining potentiallinkup rival oracle peoplesoft german sunday newspaper welt sonntag reported', 'police launched investigation claim birmingham dwight yorke racially abused prior game blackburn', 'intel ibm ntt docomo launched security technology mobile device claim bolster mcommerce service', 'boston red sox buried decade futility anguish week maryland football program slain mighty dragon']\n","2024-10-11 11:00:01,326 - INFO - 에폭 1/5, 손실: 121.8357\n","2024-10-11 11:00:01,331 - INFO - 에폭 2/5, 손실: 119.6887\n","2024-10-11 11:00:01,336 - INFO - 에폭 3/5, 손실: 117.6261\n","2024-10-11 11:00:01,342 - INFO - 에폭 4/5, 손실: 115.7810\n","2024-10-11 11:00:01,347 - INFO - 에폭 5/5, 손실: 114.2379\n","2024-10-11 11:00:01,352 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:01,354 - INFO - built Dictionary<1049 unique tokens: ['according', 'barbados', 'ceremony', 'cost', 'elin']...> from 80 documents (total 1438 corpus positions)\n","2024-10-11 11:00:01,356 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1049 unique tokens: ['according', 'barbados', 'ceremony', 'cost', 'elin']...> from 80 documents (total 1438 corpus positions)\", 'datetime': '2024-10-11T11:00:01.356990', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:01,619 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 11:00:01,620 - INFO - Sample of sampled data: ['many around nfl say surprised team poor performance question whether problem lie redskin system player joe gibbs', 'ap video posted monday web site showed beheading man identified american civil engineer eugene armstrong militant group led abu musab alzarqawi claimed responsibility slaying said another hostage either american briton would killed hour', 'zurich reuters credit suisse plan focus investment banking activity highmargin business float insurer winterthur longawaited revamp aimed boosting earnings power europe thlargest bank', 'jack hensley second american citizen held hostage iraq beheadedxinhuaafp photo baghdad sept xinhuanet second american citizen held hostage iraq beheaded kidnapper islamist website said tuesday', 'web site visitor clicked banner ad number popular european web site weekend may infected computer variant bofra worm expert said today']\n","2024-10-11 11:00:01,630 - INFO - 에폭 1/5, 손실: 131.4349\n","2024-10-11 11:00:01,634 - INFO - 에폭 2/5, 손실: 129.0086\n","2024-10-11 11:00:01,639 - INFO - 에폭 3/5, 손실: 126.6066\n","2024-10-11 11:00:01,646 - INFO - 에폭 4/5, 손실: 124.9652\n","2024-10-11 11:00:01,652 - INFO - 에폭 5/5, 손실: 122.3270\n","2024-10-11 11:00:01,656 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:01,659 - INFO - built Dictionary<1037 unique tokens: ['around', 'gibbs', 'joe', 'lie', 'many']...> from 80 documents (total 1450 corpus positions)\n","2024-10-11 11:00:01,660 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1037 unique tokens: ['around', 'gibbs', 'joe', 'lie', 'many']...> from 80 documents (total 1450 corpus positions)\", 'datetime': '2024-10-11T11:00:01.660992', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:01,868 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 11:00:01,869 - INFO - Sample of sampled data: ['toshiba corporation quottoshiba quot lt ahref quothttpmatsushitacojp quot target quotnew quot gtmatsushita electric industrial co', 'athens greece quest surpass mark spitz way michael phelps could savor one greatest race swimming history phelps claimed second third gold medal athens game tuesday winning', 'though bea system signed licensing deal worth million added new customer quarter licensing revenue dropped million', 'terrorist insurgent stepping attack oil gas operation overseas effort disrupt jittery energy market destabilize government scare foreign worker analyst said', 'police launched investigation claim birmingham dwight yorke racially abused prior game blackburn']\n","2024-10-11 11:00:01,880 - INFO - 에폭 1/5, 손실: 116.7894\n","2024-10-11 11:00:01,884 - INFO - 에폭 2/5, 손실: 114.9403\n","2024-10-11 11:00:01,890 - INFO - 에폭 3/5, 손실: 113.3039\n","2024-10-11 11:00:01,896 - INFO - 에폭 4/5, 손실: 111.5573\n","2024-10-11 11:00:01,901 - INFO - 에폭 5/5, 손실: 110.0344\n","2024-10-11 11:00:01,905 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:01,907 - INFO - built Dictionary<1039 unique tokens: ['ahref', 'co', 'corporation', 'electric', 'gtmatsushita']...> from 80 documents (total 1429 corpus positions)\n","2024-10-11 11:00:01,908 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1039 unique tokens: ['ahref', 'co', 'corporation', 'electric', 'gtmatsushita']...> from 80 documents (total 1429 corpus positions)\", 'datetime': '2024-10-11T11:00:01.908993', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:02,127 - INFO - 토픽 품질 시각화 시작\n","2024-10-11 11:00:02,724 - INFO - 일관성 안정성 평가 시작\n","2024-10-11 11:00:02,729 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:02,729 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:08,387 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:08,402 - INFO - built Dictionary<2497 unique tokens: ['access', 'affective', 'aim', 'allow', 'allowing']...> from 80 documents (total 10035 corpus positions)\n","2024-10-11 11:00:08,403 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2497 unique tokens: ['access', 'affective', 'aim', 'allow', 'allowing']...> from 80 documents (total 10035 corpus positions)\", 'datetime': '2024-10-11T11:00:08.403398', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:08,555 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:08,556 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:13,702 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:13,716 - INFO - built Dictionary<2487 unique tokens: ['abstraction', 'accurate', 'acquire', 'admittedly', 'advent']...> from 80 documents (total 9968 corpus positions)\n","2024-10-11 11:00:13,716 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2487 unique tokens: ['abstraction', 'accurate', 'acquire', 'admittedly', 'advent']...> from 80 documents (total 9968 corpus positions)\", 'datetime': '2024-10-11T11:00:13.716579', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:13,871 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:13,871 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:18,621 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:18,634 - INFO - built Dictionary<2527 unique tokens: ['activity', 'advantage', 'also', 'analysis', 'approach']...> from 80 documents (total 9999 corpus positions)\n","2024-10-11 11:00:18,635 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2527 unique tokens: ['activity', 'advantage', 'also', 'analysis', 'approach']...> from 80 documents (total 9999 corpus positions)\", 'datetime': '2024-10-11T11:00:18.635100', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:18,806 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:18,807 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:23,549 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:23,562 - INFO - built Dictionary<2523 unique tokens: ['activity', 'analysis', 'around', 'build', 'capability']...> from 80 documents (total 9885 corpus positions)\n","2024-10-11 11:00:23,563 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2523 unique tokens: ['activity', 'analysis', 'around', 'build', 'capability']...> from 80 documents (total 9885 corpus positions)\", 'datetime': '2024-10-11T11:00:23.563332', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:23,740 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:23,741 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:29,352 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:29,367 - INFO - built Dictionary<2547 unique tokens: ['absorptive', 'adaptation', 'address', 'advantage', 'affordance']...> from 80 documents (total 10257 corpus positions)\n","2024-10-11 11:00:29,368 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2547 unique tokens: ['absorptive', 'adaptation', 'address', 'advantage', 'affordance']...> from 80 documents (total 10257 corpus positions)\", 'datetime': '2024-10-11T11:00:29.368342', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:29,529 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:29,530 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:33,498 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:33,502 - INFO - built Dictionary<877 unique tokens: ['beautiful', 'book', 'complementary', 'cut', 'dont']...> from 80 documents (total 2325 corpus positions)\n","2024-10-11 11:00:33,503 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<877 unique tokens: ['beautiful', 'book', 'complementary', 'cut', 'dont']...> from 80 documents (total 2325 corpus positions)\", 'datetime': '2024-10-11T11:00:33.503662', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:33,649 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:33,650 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:37,668 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:37,672 - INFO - built Dictionary<879 unique tokens: ['amount', 'buy', 'cant', 'case', 'cute']...> from 80 documents (total 2282 corpus positions)\n","2024-10-11 11:00:37,673 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<879 unique tokens: ['amount', 'buy', 'cant', 'case', 'cute']...> from 80 documents (total 2282 corpus positions)\", 'datetime': '2024-10-11T11:00:37.673109', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:37,686 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:37,686 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:41,631 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:41,635 - INFO - built Dictionary<883 unique tokens: ['also', 'clung', 'considerably', 'curve', 'done']...> from 80 documents (total 2368 corpus positions)\n","2024-10-11 11:00:41,636 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<883 unique tokens: ['also', 'clung', 'considerably', 'curve', 'done']...> from 80 documents (total 2368 corpus positions)\", 'datetime': '2024-10-11T11:00:41.636137', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:41,649 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:41,649 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:45,651 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:45,655 - INFO - built Dictionary<868 unique tokens: ['even', 'extra', 'feel', 'gorgeous', 'large']...> from 80 documents (total 2366 corpus positions)\n","2024-10-11 11:00:45,656 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<868 unique tokens: ['even', 'extra', 'feel', 'gorgeous', 'large']...> from 80 documents (total 2366 corpus positions)\", 'datetime': '2024-10-11T11:00:45.656564', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:45,669 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:45,670 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:50,256 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:50,261 - INFO - built Dictionary<886 unique tokens: ['actually', 'andor', 'baby', 'cup', 'doe']...> from 80 documents (total 2424 corpus positions)\n","2024-10-11 11:00:50,262 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<886 unique tokens: ['actually', 'andor', 'baby', 'cup', 'doe']...> from 80 documents (total 2424 corpus positions)\", 'datetime': '2024-10-11T11:00:50.262638', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:50,276 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:50,277 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:54,296 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:54,300 - INFO - built Dictionary<1046 unique tokens: ['administrative', 'agency', 'aid', 'british', 'child']...> from 80 documents (total 1465 corpus positions)\n","2024-10-11 11:00:54,301 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1046 unique tokens: ['administrative', 'agency', 'aid', 'british', 'child']...> from 80 documents (total 1465 corpus positions)\", 'datetime': '2024-10-11T11:00:54.301499', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:54,442 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:54,443 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:00:58,441 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:00:58,445 - INFO - built Dictionary<1075 unique tokens: ['accused', 'american', 'chief', 'corruption', 'costa']...> from 80 documents (total 1470 corpus positions)\n","2024-10-11 11:00:58,445 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1075 unique tokens: ['accused', 'american', 'chief', 'corruption', 'costa']...> from 80 documents (total 1470 corpus positions)\", 'datetime': '2024-10-11T11:00:58.445198', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:00:58,618 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:00:58,619 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:01:02,582 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:02,585 - INFO - built Dictionary<1044 unique tokens: ['awaited', 'company', 'creation', 'despite', 'end']...> from 80 documents (total 1417 corpus positions)\n","2024-10-11 11:01:02,586 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1044 unique tokens: ['awaited', 'company', 'creation', 'despite', 'end']...> from 80 documents (total 1417 corpus positions)\", 'datetime': '2024-10-11T11:01:02.586463', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:02,755 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:01:02,755 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:01:07,281 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:07,285 - INFO - built Dictionary<1045 unique tokens: ['come', 'despite', 'dip', 'earnings', 'expectation']...> from 80 documents (total 1456 corpus positions)\n","2024-10-11 11:01:07,285 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1045 unique tokens: ['come', 'despite', 'dip', 'earnings', 'expectation']...> from 80 documents (total 1456 corpus positions)\", 'datetime': '2024-10-11T11:01:07.285282', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:07,460 - INFO - Use pytorch device_name: cpu\n","2024-10-11 11:01:07,461 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 11:01:11,429 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:11,433 - INFO - built Dictionary<1060 unique tokens: ['almost', 'announce', 'availability', 'base', 'distribution']...> from 80 documents (total 1455 corpus positions)\n","2024-10-11 11:01:11,433 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1060 unique tokens: ['almost', 'announce', 'availability', 'base', 'distribution']...> from 80 documents (total 1455 corpus positions)\", 'datetime': '2024-10-11T11:01:11.433226', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:11,637 - INFO - 에폭 1/5, 손실: 708.2950\n","2024-10-11 11:01:11,644 - INFO - 에폭 2/5, 손실: 697.5443\n","2024-10-11 11:01:11,650 - INFO - 에폭 3/5, 손실: 687.1552\n","2024-10-11 11:01:11,658 - INFO - 에폭 4/5, 손실: 677.2607\n","2024-10-11 11:01:11,666 - INFO - 에폭 5/5, 손실: 666.8110\n","2024-10-11 11:01:11,684 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:11,694 - INFO - built Dictionary<2455 unique tokens: ['accuracy', 'affiliation', 'algorithm', 'allows', 'alone']...> from 80 documents (total 9804 corpus positions)\n","2024-10-11 11:01:11,695 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2455 unique tokens: ['accuracy', 'affiliation', 'algorithm', 'allows', 'alone']...> from 80 documents (total 9804 corpus positions)\", 'datetime': '2024-10-11T11:01:11.695226', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:12,256 - INFO - 에폭 1/5, 손실: 716.5699\n","2024-10-11 11:01:12,264 - INFO - 에폭 2/5, 손실: 706.9167\n","2024-10-11 11:01:12,270 - INFO - 에폭 3/5, 손실: 695.3894\n","2024-10-11 11:01:12,276 - INFO - 에폭 4/5, 손실: 686.2241\n","2024-10-11 11:01:12,281 - INFO - 에폭 5/5, 손실: 675.7799\n","2024-10-11 11:01:12,298 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:12,312 - INFO - built Dictionary<2492 unique tokens: ['adopt', 'application', 'approach', 'beneficial', 'burst']...> from 80 documents (total 10068 corpus positions)\n","2024-10-11 11:01:12,312 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2492 unique tokens: ['adopt', 'application', 'approach', 'beneficial', 'burst']...> from 80 documents (total 10068 corpus positions)\", 'datetime': '2024-10-11T11:01:12.312340', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:12,884 - INFO - 에폭 1/5, 손실: 711.2569\n","2024-10-11 11:01:12,891 - INFO - 에폭 2/5, 손실: 699.6018\n","2024-10-11 11:01:12,900 - INFO - 에폭 3/5, 손실: 690.3040\n","2024-10-11 11:01:12,906 - INFO - 에폭 4/5, 손실: 679.3132\n","2024-10-11 11:01:12,914 - INFO - 에폭 5/5, 손실: 668.3592\n","2024-10-11 11:01:12,934 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:12,946 - INFO - built Dictionary<2495 unique tokens: ['activity', 'adequate', 'advantage', 'advertisement', 'advice']...> from 80 documents (total 9997 corpus positions)\n","2024-10-11 11:01:12,947 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2495 unique tokens: ['activity', 'adequate', 'advantage', 'advertisement', 'advice']...> from 80 documents (total 9997 corpus positions)\", 'datetime': '2024-10-11T11:01:12.947339', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:13,483 - INFO - 에폭 1/5, 손실: 741.8395\n","2024-10-11 11:01:13,491 - INFO - 에폭 2/5, 손실: 729.8000\n","2024-10-11 11:01:13,497 - INFO - 에폭 3/5, 손실: 719.3105\n","2024-10-11 11:01:13,505 - INFO - 에폭 4/5, 손실: 710.0233\n","2024-10-11 11:01:13,512 - INFO - 에폭 5/5, 손실: 699.3552\n","2024-10-11 11:01:13,528 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:13,539 - INFO - built Dictionary<2532 unique tokens: ['adopt', 'application', 'approach', 'beneficial', 'burst']...> from 80 documents (total 9993 corpus positions)\n","2024-10-11 11:01:13,540 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2532 unique tokens: ['adopt', 'application', 'approach', 'beneficial', 'burst']...> from 80 documents (total 9993 corpus positions)\", 'datetime': '2024-10-11T11:01:13.540940', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:14,087 - INFO - 에폭 1/5, 손실: 715.7349\n","2024-10-11 11:01:14,094 - INFO - 에폭 2/5, 손실: 704.1576\n","2024-10-11 11:01:14,100 - INFO - 에폭 3/5, 손실: 693.4957\n","2024-10-11 11:01:14,106 - INFO - 에폭 4/5, 손실: 683.7557\n","2024-10-11 11:01:14,113 - INFO - 에폭 5/5, 손실: 674.1444\n","2024-10-11 11:01:14,135 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:14,152 - INFO - built Dictionary<2486 unique tokens: ['aim', 'also', 'always', 'among', 'amount']...> from 80 documents (total 9728 corpus positions)\n","2024-10-11 11:01:14,153 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2486 unique tokens: ['aim', 'also', 'always', 'among', 'amount']...> from 80 documents (total 9728 corpus positions)\", 'datetime': '2024-10-11T11:01:14.153941', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:14,742 - INFO - 에폭 1/5, 손실: 220.9950\n","2024-10-11 11:01:14,749 - INFO - 에폭 2/5, 손실: 217.3536\n","2024-10-11 11:01:14,754 - INFO - 에폭 3/5, 손실: 214.2656\n","2024-10-11 11:01:14,762 - INFO - 에폭 4/5, 손실: 211.2794\n","2024-10-11 11:01:14,768 - INFO - 에폭 5/5, 손실: 208.2084\n","2024-10-11 11:01:14,773 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:14,777 - INFO - built Dictionary<913 unique tokens: ['boxy', 'breathable', 'cardigan', 'care', 'construction']...> from 80 documents (total 2413 corpus positions)\n","2024-10-11 11:01:14,778 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<913 unique tokens: ['boxy', 'breathable', 'cardigan', 'care', 'construction']...> from 80 documents (total 2413 corpus positions)\", 'datetime': '2024-10-11T11:01:14.778560', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:15,324 - INFO - 에폭 1/5, 손실: 213.9771\n","2024-10-11 11:01:15,331 - INFO - 에폭 2/5, 손실: 210.6477\n","2024-10-11 11:01:15,336 - INFO - 에폭 3/5, 손실: 207.4470\n","2024-10-11 11:01:15,343 - INFO - 에폭 4/5, 손실: 204.4064\n","2024-10-11 11:01:15,348 - INFO - 에폭 5/5, 손실: 201.0278\n","2024-10-11 11:01:15,353 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:15,357 - INFO - built Dictionary<908 unique tokens: ['almost', 'bag', 'color', 'everything', 'fabric']...> from 80 documents (total 2409 corpus positions)\n","2024-10-11 11:01:15,358 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<908 unique tokens: ['almost', 'bag', 'color', 'everything', 'fabric']...> from 80 documents (total 2409 corpus positions)\", 'datetime': '2024-10-11T11:01:15.358560', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:15,892 - INFO - 에폭 1/5, 손실: 219.7485\n","2024-10-11 11:01:15,898 - INFO - 에폭 2/5, 손실: 215.7770\n","2024-10-11 11:01:15,904 - INFO - 에폭 3/5, 손실: 212.6619\n","2024-10-11 11:01:15,910 - INFO - 에폭 4/5, 손실: 208.9724\n","2024-10-11 11:01:15,916 - INFO - 에폭 5/5, 손실: 206.0924\n","2024-10-11 11:01:15,921 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:15,925 - INFO - built Dictionary<890 unique tokens: ['boxy', 'breathable', 'cardigan', 'care', 'construction']...> from 80 documents (total 2395 corpus positions)\n","2024-10-11 11:01:15,926 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<890 unique tokens: ['boxy', 'breathable', 'cardigan', 'care', 'construction']...> from 80 documents (total 2395 corpus positions)\", 'datetime': '2024-10-11T11:01:15.926558', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:16,440 - INFO - 에폭 1/5, 손실: 223.9116\n","2024-10-11 11:01:16,445 - INFO - 에폭 2/5, 손실: 220.4034\n","2024-10-11 11:01:16,451 - INFO - 에폭 3/5, 손실: 216.9960\n","2024-10-11 11:01:16,457 - INFO - 에폭 4/5, 손실: 214.0754\n","2024-10-11 11:01:16,464 - INFO - 에폭 5/5, 손실: 210.9854\n","2024-10-11 11:01:16,468 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:16,473 - INFO - built Dictionary<890 unique tokens: ['anything', 'around', 'back', 'baggy', 'boxy']...> from 80 documents (total 2420 corpus positions)\n","2024-10-11 11:01:16,474 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<890 unique tokens: ['anything', 'around', 'back', 'baggy', 'boxy']...> from 80 documents (total 2420 corpus positions)\", 'datetime': '2024-10-11T11:01:16.474027', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:17,023 - INFO - 에폭 1/5, 손실: 214.1578\n","2024-10-11 11:01:17,030 - INFO - 에폭 2/5, 손실: 210.7920\n","2024-10-11 11:01:17,036 - INFO - 에폭 3/5, 손실: 207.4184\n","2024-10-11 11:01:17,041 - INFO - 에폭 4/5, 손실: 203.9011\n","2024-10-11 11:01:17,046 - INFO - 에폭 5/5, 손실: 201.3190\n","2024-10-11 11:01:17,051 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:17,054 - INFO - built Dictionary<841 unique tokens: ['actually', 'back', 'bit', 'bought', 'feel']...> from 80 documents (total 2300 corpus positions)\n","2024-10-11 11:01:17,055 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<841 unique tokens: ['actually', 'back', 'bit', 'bought', 'feel']...> from 80 documents (total 2300 corpus positions)\", 'datetime': '2024-10-11T11:01:17.055625', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:17,584 - INFO - 에폭 1/5, 손실: 129.1788\n","2024-10-11 11:01:17,590 - INFO - 에폭 2/5, 손실: 126.9957\n","2024-10-11 11:01:17,595 - INFO - 에폭 3/5, 손실: 125.3097\n","2024-10-11 11:01:17,600 - INFO - 에폭 4/5, 손실: 122.8699\n","2024-10-11 11:01:17,606 - INFO - 에폭 5/5, 손실: 121.7333\n","2024-10-11 11:01:17,610 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:17,613 - INFO - built Dictionary<1072 unique tokens: ['broke', 'chair', 'earlier', 'fined', 'francisco']...> from 80 documents (total 1481 corpus positions)\n","2024-10-11 11:01:17,614 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1072 unique tokens: ['broke', 'chair', 'earlier', 'fined', 'francisco']...> from 80 documents (total 1481 corpus positions)\", 'datetime': '2024-10-11T11:01:17.614147', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:18,101 - INFO - 에폭 1/5, 손실: 121.2516\n","2024-10-11 11:01:18,105 - INFO - 에폭 2/5, 손실: 119.0656\n","2024-10-11 11:01:18,111 - INFO - 에폭 3/5, 손실: 117.1901\n","2024-10-11 11:01:18,116 - INFO - 에폭 4/5, 손실: 115.2494\n","2024-10-11 11:01:18,122 - INFO - 에폭 5/5, 손실: 113.4432\n","2024-10-11 11:01:18,126 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:18,129 - INFO - built Dictionary<1050 unique tokens: ['ali', 'alnaimi', 'barrel', 'could', 'day']...> from 80 documents (total 1425 corpus positions)\n","2024-10-11 11:01:18,130 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1050 unique tokens: ['ali', 'alnaimi', 'barrel', 'could', 'day']...> from 80 documents (total 1425 corpus positions)\", 'datetime': '2024-10-11T11:01:18.130500', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:18,699 - INFO - 에폭 1/5, 손실: 129.6892\n","2024-10-11 11:01:18,704 - INFO - 에폭 2/5, 손실: 127.7909\n","2024-10-11 11:01:18,710 - INFO - 에폭 3/5, 손실: 125.9218\n","2024-10-11 11:01:18,715 - INFO - 에폭 4/5, 손실: 123.3896\n","2024-10-11 11:01:18,721 - INFO - 에폭 5/5, 손실: 121.9871\n","2024-10-11 11:01:18,725 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:18,728 - INFO - built Dictionary<1038 unique tokens: ['annette', 'chen', 'easygoing', 'feisty', 'immensely']...> from 80 documents (total 1440 corpus positions)\n","2024-10-11 11:01:18,729 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1038 unique tokens: ['annette', 'chen', 'easygoing', 'feisty', 'immensely']...> from 80 documents (total 1440 corpus positions)\", 'datetime': '2024-10-11T11:01:18.729501', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:19,261 - INFO - 에폭 1/5, 손실: 127.7876\n","2024-10-11 11:01:19,266 - INFO - 에폭 2/5, 손실: 125.6663\n","2024-10-11 11:01:19,272 - INFO - 에폭 3/5, 손실: 123.9206\n","2024-10-11 11:01:19,278 - INFO - 에폭 4/5, 손실: 121.6847\n","2024-10-11 11:01:19,285 - INFO - 에폭 5/5, 손실: 120.0184\n","2024-10-11 11:01:19,289 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:19,293 - INFO - built Dictionary<1050 unique tokens: ['buraida', 'deadly', 'force', 'friday', 'gunbattle']...> from 80 documents (total 1440 corpus positions)\n","2024-10-11 11:01:19,294 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1050 unique tokens: ['buraida', 'deadly', 'force', 'friday', 'gunbattle']...> from 80 documents (total 1440 corpus positions)\", 'datetime': '2024-10-11T11:01:19.294529', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:19,951 - INFO - 에폭 1/5, 손실: 121.6829\n","2024-10-11 11:01:19,958 - INFO - 에폭 2/5, 손실: 119.7105\n","2024-10-11 11:01:19,966 - INFO - 에폭 3/5, 손실: 117.5863\n","2024-10-11 11:01:19,973 - INFO - 에폭 4/5, 손실: 115.8722\n","2024-10-11 11:01:19,982 - INFO - 에폭 5/5, 손실: 113.6580\n","2024-10-11 11:01:19,988 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 11:01:19,992 - INFO - built Dictionary<1045 unique tokens: ['allawi', 'army', 'baghdad', 'belief', 'close']...> from 80 documents (total 1438 corpus positions)\n","2024-10-11 11:01:19,993 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1045 unique tokens: ['allawi', 'army', 'baghdad', 'belief', 'close']...> from 80 documents (total 1438 corpus positions)\", 'datetime': '2024-10-11T11:01:19.993418', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 11:01:20,658 - INFO - 결과 출력 시작\n","2024-10-11 11:01:20,659 - INFO - \n","=== 결과 분석 ===\n","2024-10-11 11:01:20,660 - INFO - \n","모델별 지표 평균 성능:\n","2024-10-11 11:01:20,662 - INFO -           Coherence      NPMI    U_Mass\n","Model                                  \n","BERTopic   0.933767  0.184972 -1.223236\n","VAE        0.924239  0.487324 -1.309670\n","2024-10-11 11:01:20,666 - INFO - \n","도메인별 지표 평균 성능:\n","2024-10-11 11:01:20,668 - INFO -          Coherence      NPMI    U_Mass\n","Domain                                \n","academy   0.931576  0.283236 -1.119988\n","media     0.927167  0.290823 -1.356754\n","news      0.928265  0.434385 -1.322617\n","2024-10-11 11:01:20,671 - INFO - \n"," 지표 간 일치도 분석 결과 (Spearman 상관계수):\n","2024-10-11 11:01:20,671 - INFO - Coherence vs NPMI: -0.7143\n","2024-10-11 11:01:20,673 - INFO - Coherence vs U_Mass: 0.7714\n","2024-10-11 11:01:20,673 - INFO - NPMI vs U_Mass: -0.2571\n","2024-10-11 11:01:20,674 - INFO - \n","일관성지표 안정성 개별 결과:\n","2024-10-11 11:01:20,674 - INFO -       Model   Domain  Coherence_Stability  NPMI_Stability  UMass_Stability  \\\n","0  BERTopic  academy             0.004360        0.089225        -0.057631   \n","1  BERTopic    media             2.000000             NaN              NaN   \n","2  BERTopic     news             0.009631        0.200855        -0.092025   \n","3       VAE  academy             0.006638        0.247277        -0.056495   \n","4       VAE    media             0.014663        0.133373        -0.037469   \n","5       VAE     news             0.007869        0.074100        -0.019581   \n","\n","   Mean_Coherence  Mean_NPMI  Mean_UMass  \n","0        0.933750   0.053463   -1.039724  \n","1        0.189247        NaN         NaN  \n","2        0.913391   0.390578   -1.378469  \n","3        0.916823   0.324161   -1.393060  \n","4        0.911280   0.362605   -1.354924  \n","5        0.913834   0.593807   -1.160960  \n","2024-10-11 11:01:20,678 - INFO - \n"," 일관성지표 안정성 전체 결과:\n","2024-10-11 11:01:20,680 - INFO - Model     Metric   \n","BERTopic  Coherence    0.521225\n","          NPMI         0.201930\n","          U_Mass      -0.087335\n","VAE       Coherence    0.014276\n","          NPMI         0.207654\n","          U_Mass      -0.062605\n","Name: CV, dtype: float64\n","2024-10-11 11:01:20,683 - INFO - \n","분석 완료. 결과를 확인하고 해석하세요.\n","2024-10-11 11:01:20,684 - INFO - 모든 분석 완료\n"]}],"source":["# Cell 1: 모델 실행, 평가 지표 실행, 기타 결과 분석\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from gensim import models, corpora\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.preprocessing import MinMaxScaler\n","from gensim.models.coherencemodel import CoherenceModel\n","import time\n","import json\n","from nltk.corpus import stopwords\n","from math import log\n","from itertools import combinations\n","from tqdm import tqdm\n","import logging\n","from collections import Counter, defaultdict\n","import gensim\n","from gensim import corpora\n","from scipy.sparse import csr_matrix\n","from gensim.utils import simple_preprocess\n","from gensim.corpora import Dictionary\n","from transformers import BertTokenizer, BertModel\n","from bertopic import BERTopic\n","import seaborn as sns\n","from scipy import stats\n","import os\n","import re\n","import matplotlib\n","from tabulate import tabulate\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import MDS\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# NLTK 데이터 다운로드\n","import nltk\n","nltk.download('punkt', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","\n","# 로깅 설정\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# stop_words 정의\n","stop_words = set(stopwords.words('english'))\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained('bert-base-uncased')\n","\n","def load_data(file_path, sample_size=100):\n","    try:\n","        df = pd.read_csv(file_path, header=None, names=['text'])\n","    except FileNotFoundError:\n","        logging.error(f\"File not found: {file_path}\")\n","        return []\n","    except Exception as e:\n","        logging.error(f\"Error loading file {file_path}: {e}\")\n","        return []\n","    texts = df['text'].astype(str)\n","    if len(texts) > sample_size:\n","        texts = texts.sample(n=sample_size, random_state=42)\n","    print(f\"Loaded {len(texts)} texts from {file_path}\")\n","    return texts.tolist()\n","\n","def load_all_datasets():\n","    datasets = {\n","        'academy': {\n","            'business': load_data('data/academy/business.csv')\n","        },\n","        'media': {\n","            'clothing_review': load_data('data/media/clothing_review.csv')\n","        },\n","        'news': {\n","            'agnews': load_data('data/news/agnews.csv')\n","        }\n","    }\n","    return datasets\n","\n","class VAE(nn.Module):\n","    def __init__(self, input_dim, hidden_dim=50, latent_dim=None):\n","        if latent_dim is None:\n","            raise ValueError(\"latent_dim must be specified\")\n","        super(VAE, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc21 = nn.Linear(hidden_dim, latent_dim)  \n","        self.fc22 = nn.Linear(hidden_dim, latent_dim)  \n","        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n","        self.fc4 = nn.Linear(hidden_dim, input_dim)\n","\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.sigmoid(self.fc4(h3))\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","def vae_loss(recon_x, x, mu, logvar):\n","    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    return BCE + KLD\n","\n","def extract_vae_topics(vae_model, vectorizer, num_topics, top_n=10):\n","    with torch.no_grad():\n","        latent_vectors = torch.eye(num_topics).to(vae_model.fc3.weight.device)\n","        decoder_output = vae_model.decode(latent_vectors)\n","        decoder_output = decoder_output.cpu().numpy()\n","\n","    feature_names = vectorizer.get_feature_names_out()\n","    topics = []\n","    for topic_distribution in decoder_output:\n","        top_indices = topic_distribution.argsort()[-top_n:][::-1]\n","        topic_words = [feature_names[i] for i in top_indices]\n","        topics.append(topic_words)\n","    return topics\n","\n","def perform_vae_topic_modeling(data, num_topics, num_epochs=5, hidden_dim=50):\n","    data = [str(doc) for doc in data if isinstance(doc, str) and len(doc) > 0]\n","\n","    # TfidfVectorizer 사용\n","    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n","    doc_term_matrix = vectorizer.fit_transform(data)\n","\n","    # MinMaxScaler를 사용하여 0-1 사이로 정규화\n","    scaler = MinMaxScaler()\n","    normalized_matrix = scaler.fit_transform(doc_term_matrix.toarray())\n","\n","    vocab_size = len(vectorizer.get_feature_names_out())\n","    input_dim = vocab_size\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    vae_model = VAE(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=num_topics).to(device)\n","    optimizer = torch.optim.Adam(vae_model.parameters(), lr=1e-3)\n","\n","    batch_size = 64\n","    data_loader = DataLoader(normalized_matrix.astype(np.float32), batch_size=batch_size, shuffle=True)\n","\n","    vae_model.train()\n","    for epoch in range(num_epochs):\n","        train_loss = 0\n","        for batch in data_loader:\n","            batch = batch.to(device)\n","            optimizer.zero_grad()\n","            recon_batch, mu, logvar = vae_model(batch)\n","            loss = vae_loss(recon_batch, batch, mu, logvar)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","        logging.info(f\"에폭 {epoch+1}/{num_epochs}, 손실: {train_loss / len(data_loader.dataset):.4f}\")\n","\n","    topics = extract_vae_topics(vae_model, vectorizer, num_topics)\n","    return vae_model, topics\n","\n","def perform_bertopic_modeling(data):\n","    if isinstance(data, dict):\n","        data = list(data.values())[0]\n","    elif isinstance(data, pd.DataFrame):\n","        data = data['text'].tolist() if 'text' in data.columns else data.values.flatten().tolist()\n","    elif isinstance(data, pd.Series):\n","        data = data.tolist()\n","    elif isinstance(data, np.ndarray):\n","        data = data.flatten().tolist()\n","    elif isinstance(data, list):\n","        pass\n","    else:\n","        raise ValueError(f\"Unsupported data format for BERTopic modeling: {type(data)}\")\n","\n","    # 데이터가 문자열 리스트인지 확인\n","    if not all(isinstance(item, str) for item in data):\n","        raise ValueError(\"All items in the data must be strings\")\n","\n","    try:\n","        bertopic_model = BERTopic(language=\"english\", calculate_probabilities=True)\n","        topics, _ = bertopic_model.fit_transform(data)\n","        \n","        num_topics = len(bertopic_model.get_topics())\n","        topic_words = []\n","        for i in range(num_topics):\n","            topic = bertopic_model.get_topic(i)\n","            if topic:\n","                words = [word for word, _ in topic[:10]]  # 상위 10개 단어만 추출\n","                topic_words.append(words)\n","        \n","        return bertopic_model, topic_words, num_topics\n","    except AttributeError as e:\n","        logging.error(f\"BERTopic 모델링 중 오류 발생: {e}\")\n","        return None, None, None\n","\n","def perform_vae_topic_modeling(data, num_topics, num_epochs=5, hidden_dim=50):\n","    try:\n","        # 데이터 전처리\n","        data = [str(doc) for doc in data if isinstance(doc, str) and len(doc) > 0]\n","        vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n","        doc_term_matrix = vectorizer.fit_transform(data)\n","\n","        # MinMaxScaler를 사용하여 0-1 사이로 정규화\n","        scaler = MinMaxScaler()\n","        normalized_matrix = scaler.fit_transform(doc_term_matrix.toarray())\n","\n","        # VAE 모델 초기화 및 학습\n","        input_dim = doc_term_matrix.shape[1]\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        vae_model = VAE(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=num_topics).to(device)\n","        optimizer = torch.optim.Adam(vae_model.parameters(), lr=1e-3)\n","\n","        batch_size = 64\n","        data_loader = DataLoader(normalized_matrix.astype(np.float32), batch_size=batch_size, shuffle=True)\n","\n","        vae_model.train()\n","        for epoch in range(num_epochs):\n","            train_loss = 0\n","            for batch in data_loader:\n","                batch = batch.to(device)\n","                optimizer.zero_grad()\n","                recon_batch, mu, logvar = vae_model(batch)\n","                loss = vae_loss(recon_batch, batch, mu, logvar)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss += loss.item()\n","            logging.info(f\"에폭 {epoch+1}/{num_epochs}, 손실: {train_loss / len(data_loader.dataset):.4f}\")\n","\n","        topics = extract_vae_topics(vae_model, vectorizer, num_topics)\n","        return vae_model, topics\n","    except Exception as e:\n","        logging.error(f\"VAE 모델링 중 오류 발생: {e}\")\n","        return None, None\n","\n","def calculate_coherence(topics, tokenizer, bert_model):\n","    \"\"\"\n","    Calculate the coherence score for given topics using BERT embeddings.\n","\n","    Args:\n","    topics (list): List of topic word lists.\n","    tokenizer (BertTokenizer): BERT tokenizer.\n","    bert_model (BertModel): Pre-trained BERT model.\n","\n","    Returns:\n","    float: Average coherence score across all topics.\n","    \"\"\"\n","    coherence_scores = []\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    bert_model.to(device)\n","    bert_model.eval()\n","\n","    for topic_words in topics:\n","        inputs = tokenizer(topic_words, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","        with torch.no_grad():\n","            outputs = bert_model(**inputs)\n","        embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] 토큰의 임베딩 사용\n","\n","        num_words = len(topic_words)\n","        if num_words < 2:\n","            coherence_scores.append(0)\n","            continue\n","\n","        pairwise_similarities = []\n","        for i in range(num_words):\n","            for j in range(i + 1, num_words):\n","                cosine_sim = torch.nn.functional.cosine_similarity(embeddings[i], embeddings[j], dim=0)\n","                pairwise_similarities.append(cosine_sim.item())\n","\n","        coherence = np.mean(pairwise_similarities)\n","        coherence_scores.append(coherence)\n","\n","    final_coherence = np.mean(coherence_scores) if coherence_scores else 0\n","    return final_coherence\n","\n","def process_metrics(domain, model_type, topics, data, metrics_list, tokenizer, bert_model):\n","    tokenized_data = [simple_preprocess(doc) for doc in data]\n","    dictionary = Dictionary(tokenized_data)\n","    corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n","\n","    coherence = calculate_coherence(topics, tokenizer, bert_model)\n","    npmi = calculate_npmi(topics, corpus, dictionary)\n","    umass = calculate_umass(topics, corpus, dictionary)\n","\n","    metrics_list.append({\n","        'Domain': domain,\n","        'Model': model_type,\n","        'Coherence': coherence,\n","        'NPMI': npmi,\n","        'U_Mass': umass\n","    })\n","\n","    logging.info(f\"Coherence: {coherence:.4f}, NPMI: {npmi:.4f}, U_Mass: {umass:.4f}\")\n","    \n","    return [metrics_list[-1]]  # 마지막에 추가된 메트릭을 리스트로 반환\n","\n","def calculate_npmi(topics, corpus, dictionary, top_n=10):\n","    # 토픽에서 사용된 모든 단어의 집합 생성\n","    topic_words_set = set()\n","    for topic in topics:\n","        topic_words_set.update(topic[:top_n])\n","\n","    # 단어를 ID로 매핑\n","    word2id = {word: dictionary.token2id[word] for word in topic_words_set if word in dictionary.token2id}\n","    id2word = {id: word for word, id in word2id.items()}\n","\n","    # 단어와 단어 쌍의 문서 빈도 계산\n","    total_docs = len(corpus)\n","    word_doc_freq = defaultdict(int)\n","    pair_doc_freq = defaultdict(int)\n","\n","    for doc in corpus:\n","        doc_word_ids = set([id for id, _ in doc])\n","        topic_word_ids_in_doc = doc_word_ids.intersection(set(word2id.values()))\n","\n","        for word_id in topic_word_ids_in_doc:\n","            word_doc_freq[word_id] += 1\n","\n","        for word_id1, word_id2 in combinations(topic_word_ids_in_doc, 2):\n","            pair = tuple(sorted((word_id1, word_id2)))\n","            pair_doc_freq[pair] += 1\n","\n","    # NPMI 계산\n","    npmi_scores = []\n","    for topic in topics:\n","        topic_word_ids = [word2id[word] for word in topic[:top_n] if word in word2id]\n","        if len(topic_word_ids) < 2:\n","            continue\n","        pair_npmi_scores = []\n","        for word_id1, word_id2 in combinations(topic_word_ids, 2):\n","            pair = tuple(sorted((word_id1, word_id2)))\n","            co_doc_count = pair_doc_freq.get(pair, 0)\n","            if co_doc_count == 0:\n","                continue\n","            p_w1_w2 = co_doc_count / total_docs\n","            p_w1 = word_doc_freq[word_id1] / total_docs\n","            p_w2 = word_doc_freq[word_id2] / total_docs\n","\n","            pmi = np.log(p_w1_w2 / (p_w1 * p_w2) + 1e-12)\n","            npmi = pmi / (-np.log(p_w1_w2 + 1e-12))\n","            pair_npmi_scores.append(npmi)\n","        if pair_npmi_scores:\n","            npmi_scores.append(np.mean(pair_npmi_scores))\n","\n","    return np.mean(npmi_scores) if npmi_scores else float('nan')\n","\n","def calculate_umass(topics, corpus, dictionary, top_n=10):\n","    # 토픽에서 사용된 모든 단어의 집합 생성\n","    topic_words_set = set()\n","    for topic in topics:\n","        topic_words_set.update(topic[:top_n])\n","\n","    # 단어를 ID로 매핑\n","    word2id = {word: dictionary.token2id[word] for word in topic_words_set if word in dictionary.token2id}\n","\n","    # 단어와 단어 쌍의 빈도 계산\n","    word_counts = defaultdict(int)\n","    pair_counts = defaultdict(int)\n","\n","    for doc in corpus:\n","        doc_word_ids = set([id for id, _ in doc])\n","        topic_word_ids_in_doc = doc_word_ids.intersection(set(word2id.values()))\n","\n","        for word_id in topic_word_ids_in_doc:\n","            word_counts[word_id] += 1\n","\n","        for word_id1, word_id2 in combinations(topic_word_ids_in_doc, 2):\n","            pair = tuple(sorted((word_id1, word_id2)))\n","            pair_counts[pair] += 1\n","\n","    # U_Mass 계산\n","    umass_scores = []\n","    for topic in topics:\n","        topic_word_ids = [word2id[word] for word in topic[:top_n] if word in word2id]\n","        if len(topic_word_ids) < 2:\n","            continue\n","        pair_umass_scores = []\n","        for i, word_id1 in enumerate(topic_word_ids):\n","            for word_id2 in topic_word_ids[:i]:\n","                pair = tuple(sorted((word_id1, word_id2)))\n","                co_occurrence = pair_counts.get(pair, 0) + 1  # 스무딩을 위해 +1\n","                word2_count = word_counts[word_id2] + 1  # 스무딩을 위해 +1\n","                umass = np.log(co_occurrence / word2_count)\n","                pair_umass_scores.append(umass)\n","        if pair_umass_scores:\n","            umass_scores.append(np.mean(pair_umass_scores))\n","\n","    return np.mean(umass_scores) if umass_scores else float('nan')\n","\n","# 일치도 분석 함수 (계속)\n","def analyze_agreement(metrics_df):\n","    metrics = ['Coherence', 'NPMI', 'U_Mass']\n","    correlations = {}\n","    for i in range(len(metrics)):\n","        for j in range(i+1, len(metrics)):\n","            metric1, metric2 = metrics[i], metrics[j]\n","            spearman_corr, _ = stats.spearmanr(metrics_df[metric1], metrics_df[metric2])\n","            correlations[f'{metric1} vs {metric2}'] = spearman_corr\n","    \n","    print(\"\\n일치도 분석 결과 (Spearman 상관계수):\")\n","    for pair, corr in correlations.items():\n","        print(f\"{pair}: {corr:.4f}\")\n","    \n","    return correlations\n","\n","# 안정성 분석 함수\n","def analyze_stability(datasets, model_types, n_runs=10, sample_ratio=0.8):\n","    stability_results = []\n","    \n","    for domain, domain_datasets in datasets.items():\n","        # 각 도메인에서 첫 번째 데이터셋만 사용\n","        data = next(iter(domain_datasets.values()))\n","        \n","        logging.info(f\"Analyzing stability for domain: {domain}\")\n","        logging.info(f\"Original data type: {type(data)}\")\n","        \n","        # 데이터 형식 확인 및 변환\n","        if isinstance(data, pd.DataFrame):\n","            data = data['text'].tolist() if 'text' in data.columns else data.values.flatten().tolist()\n","        elif isinstance(data, pd.Series):\n","            data = data.tolist()\n","        elif isinstance(data, np.ndarray):\n","            data = data.flatten().tolist()\n","        elif isinstance(data, list):\n","            pass\n","        else:\n","            raise ValueError(f\"Unsupported data format for domain {domain}: {type(data)}\")\n","        \n","        logging.info(f\"Processed data type: {type(data)}\")\n","        logging.info(f\"Sample of processed data: {data[:5]}\")  # 처음 5개 항목 출력\n","        \n","        # BERTopic으로 초기 토픽 수 결정\n","        _, _, num_topics = perform_bertopic_modeling(data)\n","        \n","        for model_type in model_types:\n","            metric_values = {\n","                'Coherence': [],\n","                'NPMI': [],\n","                'U_Mass': []\n","            }\n","            \n","            for _ in range(n_runs):\n","                sampled_data = np.random.choice(data, size=int(len(data) * sample_ratio), replace=False)\n","                sampled_data = sampled_data.tolist()  # numpy array를 리스트로 변환\n","                \n","                logging.info(f\"Sampled data type: {type(sampled_data)}\")\n","                logging.info(f\"Sample of sampled data: {sampled_data[:5]}\")  # 처음 5개 항목 출력\n","                \n","                if model_type == 'BERTopic':\n","                    model, topics, _ = perform_bertopic_modeling(sampled_data)\n","                elif model_type == 'VAE':\n","                    model, topics = perform_vae_topic_modeling(sampled_data, num_topics)\n","                else:\n","                    raise ValueError(f\"Unsupported model type: {model_type}\")\n","                \n","                if model is None or topics is None:\n","                    logging.warning(f\"Model or topics is None for {model_type} in domain {domain}\")\n","                    continue\n","                \n","                tokenized_data = [simple_preprocess(doc) for doc in sampled_data]\n","                dictionary = Dictionary(tokenized_data)\n","                corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n","                \n","                coherence = calculate_coherence(topics, tokenizer, bert_model)\n","                npmi = calculate_npmi(topics, corpus, dictionary)\n","                umass = calculate_umass(topics, corpus, dictionary)\n","                \n","                metric_values['Coherence'].append(coherence)\n","                metric_values['NPMI'].append(npmi)\n","                metric_values['U_Mass'].append(umass)\n","            \n","            for metric, values in metric_values.items():\n","                cv = np.std(values) / np.mean(values) if np.mean(values) != 0 else float('nan')\n","                stability_results.append({\n","                    'Domain': domain,\n","                    'Model': model_type,\n","                    'Metric': metric,\n","                    'CV': cv\n","                })\n","    \n","    return pd.DataFrame(stability_results)\n","\n","# 개선된 토픽 품질 시각화 함수\n","def visualize_topic_quality(metrics_df):\n","        \n","    metrics = ['Coherence', 'NPMI', 'U_Mass']\n","    metrics_df = metrics_df.dropna(subset=metrics)\n","    \n","    scaler = StandardScaler()\n","    scaled_metrics = scaler.fit_transform(metrics_df[metrics])\n","    \n","    mds = MDS(n_components=2, random_state=42)\n","    mds_coords = mds.fit_transform(scaled_metrics)\n","    \n","    plt.figure(figsize=(12, 8))\n","    scatter = plt.scatter(mds_coords[:, 0], mds_coords[:, 1], \n","                          c=metrics_df['Coherence'], cmap='viridis', \n","                          s=50, alpha=0.6)\n","    plt.colorbar(scatter, label='Coherence')\n","    plt.title('MDS Visualization of Topic Quality')\n","    plt.xlabel('MDS Dimension 1')\n","    plt.ylabel('MDS Dimension 2')\n","    plt.savefig('mds_topic_quality.png')\n","    plt.close()\n","\n","    # 상관관계 히트맵\n","    corr_matrix = metrics_df[metrics].corr(method='spearman')\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n","    plt.title('Correlation Heatmap of Coherence Metrics')\n","    plt.tight_layout()\n","    plt.savefig('correlation_heatmap.png')\n","    plt.close()\n","\n","    # 지표별 토픽 순위 변화 그래프\n","    plt.figure(figsize=(12, 6))\n","    for metric in metrics:\n","        plt.plot(range(len(metrics_df)), metrics_df[metric].rank(ascending=False), label=metric)\n","    plt.xlabel('Topics')\n","    plt.ylabel('Rank')\n","    plt.title('Topic Ranks by Different Metrics')\n","    plt.legend()\n","    plt.savefig('topic_ranks_comparison.png')\n","    plt.close()\n","\n","    # 토픽 품질 분포 비교\n","    plt.figure(figsize=(12, 6))\n","    for metric in metrics:\n","        sns.kdeplot(metrics_df[metric], label=metric)\n","    plt.xlabel('Metric Value')\n","    plt.ylabel('Density')\n","    plt.title('Distribution of Topic Quality Metrics')\n","    plt.legend()\n","    plt.savefig('topic_quality_distribution.png')\n","    plt.close()\n","\n","def analyze_llm_results(llm_df):\n","    llm_df['LLM_Avg_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.mean([s for s in scores if s is not None]))\n","    llm_df['LLM_Std_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.std([s for s in scores if s is not None]))\n","    llm_df['LLM_Median_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.median([s for s in scores if s is not None]))\n","\n","    print(\"\\nLLM 평가 결과:\")\n","    print(llm_df[['Domain', 'Model', 'LLM_Avg_Score', 'LLM_Std_Score', 'LLM_Median_Score']])\n","\n","def llm_auto_metric_correlation(metrics_df, llm_df):\n","    merged_df = pd.merge(metrics_df, llm_df, on=['Domain', 'Model'])\n","\n","    metric_names = ['Coherence', 'NPMI', 'U_Mass']\n","    for metric in metric_names:\n","        valid_idx = merged_df['LLM_Avg_Score'].notnull()\n","        pearson_corr, p_value_pearson = stats.pearsonr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n","        spearman_corr, p_value_spearman = stats.spearmanr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n","        print(f\"\\nLLM 평가 점수와 {metric}의 상관관계:\")\n","        print(f\"Pearson: 상관계수 = {pearson_corr:.4f}, p-value = {p_value_pearson:.4f}\")\n","        print(f\"Spearman: 상관계수 = {spearman_corr:.4f}, p-value = {p_value_spearman:.4f}\")\n","\n","def verify_llm_consistency(topics, documents, n_repeats=5):\n","    all_scores = []\n","    for _ in range(n_repeats):\n","        scores, _ = llm_evaluation(topics, documents)\n","        all_scores.append(scores)\n","    all_scores = np.array(all_scores)\n","    std_scores = np.std(all_scores, axis=0)\n","    avg_std = np.mean(std_scores)\n","    cv_scores = std_scores / np.mean(all_scores, axis=0)\n","    avg_cv = np.mean(cv_scores)\n","    print(f\"\\nLLM 평가의 평균 표준편차: {avg_std:.4f}\")\n","    print(f\"LLM 평가의 평균 변동계수(CV): {avg_cv:.4f}\")\n","\n","def analyze_llm_feedback(llm_df):\n","    all_words = []\n","    for feedbacks in llm_df['LLM_Feedbacks']:\n","        for feedback in feedbacks:\n","            words = feedback.lower().split()\n","            all_words.extend([word for word in words if word not in stop_words])\n","\n","    word_freq = Counter(all_words)\n","    print(\"\\n피드백에서 가장 자주 등장하는 키워드:\")\n","    for word, count in word_freq.most_common(10):\n","        print(f\"{word}: {count}\")\n","\n","    coherence_keywords = ['coherent', 'consistent', 'related', 'connected', 'meaningful']\n","    print(\"\\n일관성 관련 키워드 빈도:\")\n","    for keyword in coherence_keywords:\n","        print(f\"{keyword}: {word_freq[keyword]}\")\n","\n","    positive_keywords = ['good', 'great', 'excellent', 'well', 'clear']\n","    negative_keywords = ['poor', 'bad', 'unclear', 'confusing', 'unrelated']\n","    \n","    positive_count = sum(word_freq[word] for word in positive_keywords)\n","    negative_count = sum(word_freq[word] for word in negative_keywords)\n","    \n","    print(f\"\\n긍정적 피드백 키워드 수: {positive_count}\")\n","    print(f\"부정적 피드백 키워드 수: {negative_count}\")\n","\n","    relationship_keywords = ['related', 'similar', 'overlapping', 'connected', 'distinct']\n","    print(\"\\n토픽 간 관계 관련 키워드 빈도:\")\n","    for keyword in relationship_keywords:\n","        print(f\"{keyword}: {word_freq[keyword]}\")\n","\n","    quality_keywords = ['coherent', 'meaningful', 'interpretable', 'clear', 'specific']\n","    print(\"\\n토픽 품질 관련 키워드 빈도:\")\n","    for keyword in quality_keywords:\n","        print(f\"{keyword}: {word_freq[keyword]}\")\n","\n","    scores = [score for scores in llm_df['LLM_Scores'] for score in scores if score is not None]\n","    print(\"\\n일관성 점수 분포:\")\n","    print(f\"평균: {np.mean(scores):.2f}\")\n","    print(f\"중앙값: {np.median(scores):.2f}\")\n","    print(f\"표준편차: {np.std(scores):.2f}\")\n","    print(f\"최소값: {np.min(scores):.2f}\")\n","    print(f\"최대값: {np.max(scores):.2f}\")\n","\n","    print(\"\\n모델별 평균 일관성 점수:\")\n","    for model in llm_df['Model'].unique():\n","        model_scores = [score for scores, m in zip(llm_df['LLM_Scores'], llm_df['Model']) \n","                        for score in scores if score is not None and m == model]\n","        print(f\"{model}: {np.mean(model_scores):.2f}\")\n","\n","def visualize_llm_results(llm_df):\n","    plt.figure(figsize=(12, 6))\n","    sns.boxplot(x='Model', y='LLM_Avg_Score', data=llm_df)\n","    plt.title('모델별 LLM 평가 점수 분포')\n","    plt.savefig('llm_model_score_distribution.png')\n","    plt.close()\n","\n","    plt.figure(figsize=(12, 6))\n","    sns.scatterplot(x='Model', y='LLM_Avg_Score', data=llm_df)\n","    plt.title('모델별 LLM 평가 점수')\n","    plt.legend()\n","    plt.savefig('llm_model_score.png')\n","    plt.close()\n","\n","\n","def evaluate_coherence_stability(models, domains, datasets, n_runs=5):\n","    stability_results = []\n","    \n","    for model in models:\n","        for domain, data in zip(domains, datasets):\n","            # data가 딕셔너리인 경우 적절히 처리\n","            if isinstance(data, dict):\n","                data = list(data.values())[0]\n","            elif isinstance(data, pd.DataFrame):\n","                data = data['text'].tolist()\n","            elif not isinstance(data, list):\n","                raise ValueError(f\"Unsupported data format for domain {domain}\")\n","\n","            coherence_scores = []\n","            npmi_scores = []\n","            umass_scores = []\n","\n","            for _ in range(n_runs):\n","                # 데이터 샘플링 (예: 80%의 데이터 사용)\n","                sampled_data = np.random.choice(data, size=int(len(data) * 0.8), replace=False)\n","\n","                if model == 'BERTopic':\n","                    _, topics, _ = perform_bertopic_modeling(sampled_data)\n","                elif model == 'VAE':\n","                    _, topics = perform_vae_topic_modeling(sampled_data, num_topics=10)  # num_topics는 적절히 조정\n","                else:\n","                    raise ValueError(f\"Unsupported model type: {model}\")\n","\n","                # 토큰화된 데이터 준비\n","                tokenized_data = [simple_preprocess(doc) for doc in sampled_data]\n","                dictionary = Dictionary(tokenized_data)\n","                corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n","\n","                # 일관성 메트릭 계산\n","                coherence = calculate_coherence(topics, tokenizer, bert_model)\n","                npmi = calculate_npmi(topics, corpus, dictionary)\n","                umass = calculate_umass(topics, corpus, dictionary)\n","\n","                coherence_scores.append(coherence)\n","                npmi_scores.append(npmi)\n","                umass_scores.append(umass)\n","\n","            # 안정성 계산 (변동 계수 사용)\n","            coherence_stability = np.std(coherence_scores) / np.mean(coherence_scores)\n","            npmi_stability = np.std(npmi_scores) / np.mean(npmi_scores)\n","            umass_stability = np.std(umass_scores) / np.mean(umass_scores)\n","\n","            stability_results.append({\n","                'Model': model,\n","                'Domain': domain,\n","                'Coherence_Stability': coherence_stability,\n","                'NPMI_Stability': npmi_stability,\n","                'UMass_Stability': umass_stability,\n","                'Mean_Coherence': np.mean(coherence_scores),\n","                'Mean_NPMI': np.mean(npmi_scores),\n","                'Mean_UMass': np.mean(umass_scores)\n","            })\n","\n","    return pd.DataFrame(stability_results)\n","\n","def print_results(metrics_df, agreement_results, stability_df, stability_results):\n","    logging.info(\"\\n=== 결과 분석 ===\")\n","    \n","    # 모델별 성능 평가에서 지표 간 평가의 차이 분석 \n","    logging.info(\"\\n모델별 지표 평균 성능:\")\n","    logging.info(metrics_df.groupby('Model')[['Coherence', 'NPMI', 'U_Mass']].mean())\n","    logging.info(\"\\n도메인별 지표 평균 성능:\")\n","    logging.info(metrics_df.groupby('Domain')[['Coherence', 'NPMI', 'U_Mass']].mean())\n","\n","    # 지표 간 상관관계 분석을 통해 새로운 지표의 새로운 영역 측정 가능성 판단 \n","    logging.info(\"\\n 지표 간 일치도 분석 결과 (Spearman 상관계수):\")\n","    for pair, corr in agreement_results.items():\n","        logging.info(f\"{pair}: {corr:.4f}\")\n","    \n","    # 일관성 지표가 안정적으로 측정되는지 확인 \n","    logging.info(\"\\n일관성지표 안정성 개별 결과:\")\n","    logging.info(stability_results)\n","    logging.info(\"\\n 일관성지표 안정성 전체 결과:\")\n","    logging.info(stability_df.groupby(['Model', 'Metric'])['CV'].mean())\n","\n","    logging.info(\"\\n분석 완료. 결과를 확인하고 해석하세요.\")\n","\n","def process_datasets(datasets):\n","    all_metrics = []\n","    bertopic_results = {}\n","    vae_results = {}\n","    \n","    for domain, domain_datasets in datasets.items():\n","        for dataset_name, data in domain_datasets.items():\n","            # BERTopic 모델링\n","            bertopic_model, bertopic_topics, num_topics = perform_bertopic_modeling(data)\n","            bertopic_results[domain] = {\n","                'num_topics': num_topics,\n","                'topics': bertopic_topics\n","            }\n","            \n","            # BERTopic 메트릭 계산\n","            bertopic_metrics = process_metrics(domain, 'BERTopic', bertopic_topics, data, [], tokenizer, bert_model)\n","            all_metrics.extend(bertopic_metrics)\n","            \n","            # VAE 모델링\n","            vae_model, vae_topics = perform_vae_topic_modeling(data, num_topics)\n","            vae_results[domain] = {\n","                'num_topics': num_topics,  # VAE는 BERTopic의 토픽 수를 사용합니다\n","                'topics': vae_topics\n","            }\n","            \n","            # VAE 메트릭 계산\n","            vae_metrics = process_metrics(domain, 'VAE', vae_topics, data, [], tokenizer, bert_model)\n","            all_metrics.extend(vae_metrics)\n","    \n","    return all_metrics, bertopic_topics, bertopic_results, vae_results\n","\n","def main():\n","    try:\n","        logging.info(\"데이터셋 로딩 시작\")\n","        datasets = load_all_datasets()\n","        \n","        logging.info(\"토픽 모델링 및 메트릭 계산 시작\")\n","        all_metrics, bertopic_topics,bertopic_results,vae_results, *extra = process_datasets(datasets)\n","        \n","        logging.info(\"BERTopic 결과 출력\")\n","        for domain, result in bertopic_results.items():\n","            print(f\"\\n도메인: {domain}\")\n","            print(f\"BERTopic 토픽 수: {result['num_topics']}\")\n","            print(\"BERTopic 토픽:\")\n","            for i, topic in enumerate(result['topics']):\n","                print(f\"  토픽 {i+1}: {', '.join(topic[:10])}\")  # 각 토픽의 상위 10개 단어만 출력\n","        \n","        logging.info(\"\\nVAE 결과 출력\")\n","        for domain, result in vae_results.items():\n","            print(f\"\\n도메인: {domain}\")\n","            print(f\"VAE 토픽 수: {result['num_topics']}\")\n","            print(\"VAE 토픽:\")\n","            for i, topic in enumerate(result['topics']):\n","                print(f\"  토픽 {i+1}: {', '.join(topic[:10])}\")  # 각 토픽의 상위 10개 단어만 출력\n","        \n","        logging.info(\"메트릭 분석 시작\")\n","        metrics_df = pd.DataFrame(all_metrics)\n","        metrics_df.to_csv('topic_modeling_metrics.csv', index=False)\n","        \n","        logging.info(\"일치도 분석 시작\")\n","        agreement_results = analyze_agreement(metrics_df)\n","        \n","        logging.info(\"안정성 분석 시작\")\n","        stability_df = analyze_stability(datasets, ['BERTopic', 'VAE'])\n","        \n","        logging.info(\"토픽 품질 시각화 시작\")\n","        visualize_topic_quality(metrics_df)\n","        \n","        logging.info(\"일관성 안정성 평가 시작\")\n","        stability_results = evaluate_coherence_stability(['BERTopic', 'VAE'], list(datasets.keys()), list(datasets.values()))\n","        \n","        logging.info(\"결과 출력 시작\")\n","        print_results(metrics_df, agreement_results, stability_df, stability_results)\n","        \n","        logging.info(\"모든 분석 완료\")\n","    except Exception as e:\n","        logging.error(f\"메인 함수 실행 중 예상치 못한 오류 발생: {e}\")\n","        raise\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Cell 2: LLM 평가 관련 함수와 실행 코드\n","\n","import openai\n","from tenacity import retry, stop_after_attempt, wait_random_exponential\n","\n","@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))\n","def call_openai_api(prompt: str, max_tokens: int = 3000) -> str:\n","    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","    full_response = \"\"\n","    while True:\n","        try:\n","            response = openai.ChatCompletion.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\n","                        \"role\": \"system\",\n","                        \"content\": \"You are an expert in topic modeling and text analysis. Your task is to evaluate the coherence of topics based on provided documents.\"\n","                    },\n","                    {\n","                        \"role\": \"user\",\n","                        \"content\": prompt + (\"\\n\\nContinue from: \" + full_response if full_response else \"\")\n","                    }\n","                ],\n","                temperature=0,\n","                max_tokens=max_tokens,\n","                top_p=1,\n","                frequency_penalty=0.1,\n","                presence_penalty=0.1,\n","            )\n","            chunk = response.choices[0].message['content']\n","            full_response += chunk\n","\n","            if response.choices[0].finish_reason != \"length\":\n","                break\n","\n","            prompt = \"Continue the previous response:\"\n","        except openai.error.RateLimitError:\n","            print(\"Rate limit exceeded. Retrying...\")\n","            time.sleep(60)\n","        except openai.error.AuthenticationError:\n","            print(\"Authentication error. Check your API key.\")\n","            raise\n","        except Exception as e:\n","            print(f\"Unexpected error: {e}\")\n","            raise\n","\n","    return full_response\n","\n","def llm_evaluation(topics, documents, model=\"gpt-4o-mini\"):\n","    scores = []\n","    feedbacks = []\n","\n","    if not isinstance(documents, list):\n","        documents = list(documents)\n","\n","    prompt = f\"\"\"\n","Evaluate the following topics based on their coherence. Coherence is an important metric for assessing the quality of topic modeling:\n","\n","1. Coherence measures how semantically related the words within each topic are.\n","2. It is typically calculated by considering the co-occurrence probabilities of word pairs within the topic.\n","3. Higher coherence scores indicate that the words in a topic are closely related and form a meaningful theme.\n","4. Lower coherence scores suggest that the topic may be less meaningful or coherent.\n","\n","Please evaluate the following topics. For each topic, provide a coherence score on a scale of 1-10 and explain your reasoning:\n","\n","{topics}\n","\n","When evaluating, consider:\n","1. How semantically related are the words within each topic?\n","2. How clear and interpretable is the topic?\n","3. Do the words in the topic represent a consistent theme or concept?\n","\n","Please respond for each topic in the following format:\n","Topic X: [score]\n","Reason: [explanation]\n","\"\"\"\n","\n","    try:\n","        evaluation = call_openai_api(prompt)\n","\n","        # Updated parsing logic to extract structured responses\n","        topic_evaluations = re.findall(r\"Topic \\d+:.*?(?=Topic \\d+:|$)\", evaluation, re.DOTALL)\n","        for eval in topic_evaluations:\n","            score_match = re.search(r'Topic (\\d+):\\s*(\\d+)', eval)\n","            reason_match = re.search(r'Reason:\\s*(.*)', eval, re.DOTALL)\n","            if score_match and reason_match:\n","                topic_score = int(score_match.group(2))\n","                if 1 <= topic_score <= 10:\n","                    scores.append(topic_score)\n","                    feedbacks.append(reason_match.group(1).strip())\n","                else:\n","                    print(f\"Invalid score (not between 1 and 10): {eval}\")\n","            else:\n","                print(f\"Could not extract score or reason: {eval}\")\n","\n","    except Exception as e:\n","        print(f\"Unexpected error: {e}\")\n","        raise\n","\n","    return scores, feedbacks\n","\n","def run_llm_evaluation(metrics_df, datasets, sample_size=100, chunk_size=10):\n","    llm_results = []\n","    actual_sample_size = min(sample_size, len(metrics_df))\n","    \n","    for index, row in tqdm(metrics_df.sample(n=actual_sample_size, random_state=42).iterrows(), total=actual_sample_size):\n","        domain = row['Domain']\n","        model_type = row['Model']\n","        \n","        logging.info(f\"LLM 평가 진행 중 - 도메인: {domain}, 모델: {model_type}\")\n","\n","        try:\n","            # 각 도메인에서 첫 번째 데이터셋만 사용\n","            data = next(iter(datasets[domain].values()))\n","            \n","            if model_type == 'BERTopic':\n","                model, topics, num_topics = perform_bertopic_modeling(data)\n","            elif model_type == 'VAE':\n","                # num_topics는 BERTopic에서 생성된 토픽 수를 사용\n","                model, topics = perform_vae_topic_modeling(data, num_topics)\n","            else:\n","                continue\n","            \n","            scores, feedbacks = llm_evaluation(topics, data)\n","\n","            result = {\n","                'Domain': domain,\n","                'Model': model_type,\n","                'LLM_Scores': scores,\n","                'LLM_Feedbacks': feedbacks\n","            }\n","            llm_results.append(result)\n","\n","            if len(llm_results) % chunk_size == 0:\n","                save_results_chunk(llm_results[-chunk_size:])\n","                \n","        except Exception as e:\n","            logging.error(f\"Error processing {domain} - {model_type}: {str(e)}\")\n","            continue\n","\n","    if len(llm_results) % chunk_size != 0:\n","        save_results_chunk(llm_results[-(len(llm_results) % chunk_size):])\n","\n","    llm_df = pd.DataFrame(llm_results)\n","    return llm_df\n","\n","def save_results_chunk(results_chunk):\n","    with open('llm_evaluation_results.json', 'a') as f:\n","        for result in results_chunk:\n","            json.dump(result, f)\n","            f.write('\\n')\n","\n","# LLM 평가 실행\n","logging.info(\"LLM 평가 시작\")\n","metrics_df = pd.read_csv('topic_modeling_metrics.csv')\n","\n","# datasets 재로드\n","datasets = load_all_datasets()\n","\n","# bertopic_topics 재생성\n","_, bertopic_topics = process_datasets(datasets)\n","\n","llm_df = run_llm_evaluation(metrics_df, datasets)\n","analyze_llm_results(llm_df)\n","visualize_llm_results(llm_df)\n","\n","logging.info(\"LLM 평가와 자동 메트릭 상관관계 분석 시작\")\n","llm_auto_metric_correlation(metrics_df, llm_df)\n","\n","logging.info(\"LLM 평가 일관성 검증 시작\")\n","verify_llm_consistency(bertopic_topics, next(iter(datasets.values()))[0])\n","\n","logging.info(\"LLM 피드백 분석 시작\")\n","analyze_llm_feedback(llm_df)\n","\n","logging.info(\"LLM 평가 완료\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN1HMc8DJjEA0c4VoVpICAu","gpuType":"T4","mount_file_id":"1A2KBLTvWLDpZRfvqTW6X-K99HG5QCvQ-","provenance":[]},"kernelspec":{"display_name":"topic","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
