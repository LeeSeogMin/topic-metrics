{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-11 04:19:21,948 - INFO - 데이터셋 로딩 시작\n","2024-10-11 04:19:22,062 - INFO - 토픽 모델링 및 메트릭 계산 시작\n","2024-10-11 04:19:22,066 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:22,066 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"]},{"name":"stdout","output_type":"stream","text":["Loaded 100 texts from data/academy/business.csv\n","Loaded 100 texts from data/media/clothing_review.csv\n","Loaded 100 texts from data/news/agnews.csv\n"]},{"name":"stderr","output_type":"stream","text":["2024-10-11 04:19:26,999 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:27,015 - INFO - built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\n","2024-10-11 04:19:27,016 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\", 'datetime': '2024-10-11T04:19:27.016015', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:27,245 - INFO - Coherence: 0.9366, NPMI: 0.0574, U_Mass: -1.2095\n","2024-10-11 04:19:27,268 - INFO - 에폭 1/5, 손실: 837.6761\n","2024-10-11 04:19:27,276 - INFO - 에폭 2/5, 손실: 824.4698\n","2024-10-11 04:19:27,284 - INFO - 에폭 3/5, 손실: 813.1926\n","2024-10-11 04:19:27,292 - INFO - 에폭 4/5, 손실: 801.1149\n","2024-10-11 04:19:27,299 - INFO - 에폭 5/5, 손실: 788.8202\n","2024-10-11 04:19:27,317 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:27,332 - INFO - built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\n","2024-10-11 04:19:27,334 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2812 unique tokens: ['advertising', 'along', 'analytical', 'analyzing', 'apache']...> from 100 documents (total 12288 corpus positions)\", 'datetime': '2024-10-11T04:19:27.334016', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:27,516 - INFO - Coherence: 0.8961, NPMI: 0.2298, U_Mass: -1.4415\n","2024-10-11 04:19:27,521 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:27,522 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:19:31,684 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:31,690 - INFO - built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\n","2024-10-11 04:19:31,691 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\", 'datetime': '2024-10-11T04:19:31.691936', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:31,820 - INFO - Coherence: 0.9327, NPMI: 0.1027, U_Mass: -1.4376\n","2024-10-11 04:19:31,833 - INFO - 에폭 1/5, 손실: 254.5795\n","2024-10-11 04:19:31,839 - INFO - 에폭 2/5, 손실: 249.7950\n","2024-10-11 04:19:31,845 - INFO - 에폭 3/5, 손실: 244.5620\n","2024-10-11 04:19:31,851 - INFO - 에폭 4/5, 손실: 240.5456\n","2024-10-11 04:19:31,858 - INFO - 에폭 5/5, 손실: 235.2451\n","2024-10-11 04:19:31,863 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:31,868 - INFO - built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\n","2024-10-11 04:19:31,869 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<996 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 100 documents (total 2952 corpus positions)\", 'datetime': '2024-10-11T04:19:31.868936', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:32,040 - INFO - Coherence: 0.9402, NPMI: 0.3832, U_Mass: -1.4872\n","2024-10-11 04:19:32,044 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:32,044 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:19:36,196 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:36,200 - INFO - built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\n","2024-10-11 04:19:36,201 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\", 'datetime': '2024-10-11T04:19:36.201066', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:36,373 - INFO - Coherence: 0.9130, NPMI: 0.4225, U_Mass: -1.3961\n","2024-10-11 04:19:36,384 - INFO - 에폭 1/5, 손실: 171.9864\n","2024-10-11 04:19:36,390 - INFO - 에폭 2/5, 손실: 169.0830\n","2024-10-11 04:19:36,395 - INFO - 에폭 3/5, 손실: 166.2034\n","2024-10-11 04:19:36,400 - INFO - 에폭 4/5, 손실: 163.2408\n","2024-10-11 04:19:36,407 - INFO - 에폭 5/5, 손실: 160.9903\n","2024-10-11 04:19:36,411 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:36,414 - INFO - built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\n","2024-10-11 04:19:36,414 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1260 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 100 documents (total 1809 corpus positions)\", 'datetime': '2024-10-11T04:19:36.414066', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:36,629 - INFO - Coherence: 0.9044, NPMI: 0.6187, U_Mass: -1.1576\n","2024-10-11 04:19:36,630 - INFO - 메트릭 분석 시작\n","2024-10-11 04:19:36,632 - INFO - 일치도 분석 시작\n","2024-10-11 04:19:36,637 - INFO - 안정성 분석 시작\n","2024-10-11 04:19:36,638 - INFO - Analyzing stability for domain: academy\n","2024-10-11 04:19:36,638 - INFO - Original data type: <class 'list'>\n","2024-10-11 04:19:36,639 - INFO - Processed data type: <class 'list'>\n","2024-10-11 04:19:36,640 - INFO - Sample of processed data: ['collection big data different source internet thing social medium search engine created significant opportunity businesstobusiness bb industrial marketing organization take analytical view developing programmatic marketing approach online display advertising cleansing processing analyzing large datasets create challenge marketing organization particularly realtime decision making comparative implication importantly limited research interplay utilizing problematization approach paper contributes exploration link big data programmatic marketing realtime processing relevant decision making bb industrial marketing organization depend big datadriven marketing big datasavvy manager exploration subsequently encompasses appropriate big data source effective batch realtime processing linked structured unstructured datasets influence relative processing technique consequently along direction future research paper develops interdisciplinary dialogue overlay computerengineering framework apache storm hadoop within bb marketing viewpoint implication contemporary marketing practice', 'development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm', 'field data science emerged recent year building advance computational statistic machine learning artificial intelligence big data modern organization immersed data turning toward data science address variety business problem numerous complex problem science become solvable data science scientific solution equally applicable business many dataintensive business problem situated complex sociopolitical behavioral context still elude commonly used scientific method extent problem addressed data science data science inherent blind spot regard type business problem likely addressed data science near future develop conceptual framework inform application data science business framework draw extensive review data science literature across four domain data method interface cognition draw ashbys law requisite variety theoretical principle conclude datascientific advance across four domain aggregate could constitute requisite variety particular type business problem explains problem fully partially addressed solved automated data science distinguish situation improved due crossdomain compensatory effect problem data science best contributes merely better understanding complex phenomenon', 'product review play crucial role providing valuable insight consumer producer analyzing vast amount data generated around product post comment view challenging business intelligence purpose sentiment analysis content help consumer producer gain better understanding market status enabling make informed decision study propose novel hybrid approach based deep neural network dnns sentiment analysis product review focusing classification sentiment expressed approach utilizes recursive neural network rnn algorithm sentiment classification address imbalanced distribution positive negative sample social network data employ resampling technique balance dataset increasing sample minority class decreasing sample majority class evaluate approach using amazon data comprising four product category clothing car luxury good household appliance experimental result demonstrate proposed approach performs well sentiment analysis product review particularly context digital marketing furthermore attentionbased rnn algorithm outperforms baseline rnn approximately notably study reveals consumer sentiment variation across different product particularly relation appearance price aspect', 'sentiment analysis emerged one prominent research branch endless usage application monitoring social medium forum blog online resource customer review product competition survey response understand customer insight significant importance business analytics proliferation informal user generated data online use mixed language become common phenomenon mixed language arises use linguistic code switching lcs practice using one language single sentence mixed language rarely subject sentiment analysis lack clear grammatical structure render previous approach sentiment analysis ineffective text paper propose strategy determine sentiment sentence written mixed language comprising hindi english lexicon technique used analyze sentiment data belonging one source language well mixed language data grammatical transition common mixed language taken account sentiment analysis demonstrate effectiveness proposed approach via case study social medium data set']\n","2024-10-11 04:19:36,644 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:36,644 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"]},{"name":"stdout","output_type":"stream","text":["\n","일치도 분석 결과 (Spearman 상관계수):\n","Coherence vs NPMI: -0.3714\n","Coherence vs U_Mass: -0.2571\n","NPMI vs U_Mass: 0.2000\n"]},{"name":"stderr","output_type":"stream","text":["2024-10-11 04:19:42,224 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:19:42,225 - INFO - Sample of sampled data: ['human emotion expressed social medium play increasingly important role shaping policy decision however process emotion produce influence online social medium network relatively unknown previous work focus largely sentiment classification polarity identification adequately consider way emotion affect user influence research developed novel framework theorybased model proofofconcept system dissecting emotion user influence social medium network system model emotiontriggered influence facilitates analysis emotioninfluence causality context u border security using tweet posted user motivated theory emotion spread model integrated influencecomputation method called interaction modeling im approach compared benchmark using user centrality uc approach based social position im found identified influential user broadly related u cultural issue influential user tended express intense emotion fear anger disgust sadness emotion trust distinguishes influential user others whereas anger fear contributed significantly causing user influence research contributes incorporating human emotion datainformationknowledgewisdom model knowledge management providing new information system artifact new causality finding emotioninfluence analysis', 'effect digital transition today knowledge creation process becoming relevant company operating different industry body literature examining impact fastly growing nevertheless systematizing existing study digital technology supporting firm knowledge creation process reconceptualise existing knowledge management model paradigm still challenge scenario seci model provide theoretical guidance achieve research objective indeed implementation digital technology firm redesigning way access manage knowledge therefore paper aim critically analyse literature impact digital transition knowledge creation providing novel structuring model model seek analyse role digital transition along innovative digital knowledge creation process identified webinarisation informalisation systematisation explication digitalisation according traditional epistemological ontological dimension integrating perspective author design wised model evaluate impact digital transition knowledgecreating company', 'although term big data often used refer large datasets generated science engineering business analytics effort increasingly used refer social networking website enormous quantity personal information post networking activity contained therein quantity sensitive nature information constitutes fascinating mean inferring sociological parameter grave risk security privacy present study aimed find evidence literature malware already adapted significant degree specific form big data evidence potential abuse personal information found predictive model personal trait facebook user alarmingly effective minimal depth information like likely complex form information eg post photo connection status could lead unprecedented level intrusiveness familiarity sensitive personal information support view potential abuse private information exploited found research describing rapid adaptation malware social networking site purpose social engineering involuntary surrendering personal information', 'decision making required organization however decisionmaking style may differ commonly used decision style include autocratic democratic consensus participatory globalization expansion business professional become highly dependent upon technology support decisionmaking process decisionsupport system come fastest growing discipline present work discusses evolution computerized decision support considering modeldriven datadriven communicationdriven documentdriven knowledgedriven decisionsupport system three different business levelsoperational tactical strategichave considered present work review development decisionsupport system traditional data analysisbased approach compared latest data analytics approach including social medium analytics web analytics example different industry sector incorporated better illustration decision support', 'product review play crucial role providing valuable insight consumer producer analyzing vast amount data generated around product post comment view challenging business intelligence purpose sentiment analysis content help consumer producer gain better understanding market status enabling make informed decision study propose novel hybrid approach based deep neural network dnns sentiment analysis product review focusing classification sentiment expressed approach utilizes recursive neural network rnn algorithm sentiment classification address imbalanced distribution positive negative sample social network data employ resampling technique balance dataset increasing sample minority class decreasing sample majority class evaluate approach using amazon data comprising four product category clothing car luxury good household appliance experimental result demonstrate proposed approach performs well sentiment analysis product review particularly context digital marketing furthermore attentionbased rnn algorithm outperforms baseline rnn approximately notably study reveals consumer sentiment variation across different product particularly relation appearance price aspect']\n","2024-10-11 04:19:42,230 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:42,231 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:19:46,900 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:46,914 - INFO - built Dictionary<2538 unique tokens: ['adequately', 'affect', 'analysis', 'anger', 'approach']...> from 80 documents (total 10025 corpus positions)\n","2024-10-11 04:19:46,915 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2538 unique tokens: ['adequately', 'affect', 'analysis', 'anger', 'approach']...> from 80 documents (total 10025 corpus positions)\", 'datetime': '2024-10-11T04:19:46.915344', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:47,063 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:19:47,064 - INFO - Sample of sampled data: ['last year use social networking site increased tremendously nowadays social networking site generate large amount data million people conveniently express view opinion wide array topic via microblogging website paper discus extraction sentiment famous microblogging website twitter user post view opinion done sentiment analysis tweet help provide prediction business intelligence use hadoop framework processing movie data set available twitter website form review feedback comment result sentiment analysis twitter data displayed different section presenting positive negative neutral sentiment', 'emerging big data bd recent year latest development business intelligence bi business analytics ba representing new unusual source data eg social medium sensor advanced technology eg hadoop architecture visualisation predictive analytics new requirement user skill eg data scientist major impact fundamental traditional business intelligence bi knowledge management km process trend square way conceptualize knowledge intellectual capital value knowledge management business intelligence recognized data information though generally nonvalue precursor valuable knowledge asset establishing conceptual foundation big data additional valuable asset related knowledge making case bringing big data business intelligence km fold developing theoretical foundation concept tacit explicit knowledge learning others deployed increase understanding result believe help field better understand idea big data relates knowledge asset well providing justification bringing knowledge management tool process bear big data business intelligence move towards integrated conceptual model big data bd business intelligence bi knowledge management km km continuum bd main information deposit bi activity necessary mobilization information resource thus necessitates collective intelligence structured context bi convert data actionable knowledge strategic advantage relative various organizational environment paper contribute creation model focus ongoing research aim propose integrated bdbikm model represents processing raw data transformation contextual knowledge adopted add specific business value practice innovate knowledge provide unique competitive advantage', 'web data extraction important problem studied mean different scientific tool broad range application many approach extracting data web designed solve specific problem operate adhoc domain approach instead heavily reuse technique algorithm developed field information extraction survey aim providing structured comprehensive overview literature field web data extraction provided simple classification framework existing web data extraction application grouped two main class namely application enterprise level social web level enterprise level web data extraction technique emerge key tool perform data analysis business competitive intelligence system well business process reengineering social web level web data extraction technique allow gather large amount structured data continuously generated disseminated web social medium online social network user offer unprecedented opportunity analyze human behavior large scale discus also potential crossfertilization ie possibility reusing web data extraction technique originally designed work given domain domain c elsevier bv right reserved', 'opinion leader key participant emerge social medium identifying influential user help decision maker effectively target source influence hence bring change community research developed approach identifying influential user online social network interest policy maker general public present finding empirical study u immigration reform discussion user posted tweet maynovember present finding analysis provide list influential user identified discus implication predictive analytics social medium analytics research contribute providing new case new empirical finding applying influence analytics analyzing social medium network strong implication predictive analytics business intelligence social medium analytics', 'recent year mobile phone access point free wifi service enhanced made easier traveller share story picture video clip online trip time online travel review otr website grown significantly allowing user post travel experience opinion comment rating structured way moreover internet search engine play crucial role locating presenting otrs throughout trip evolution social medium information communication technology upset classic source information projected tourist destination image tdi allowing electronic wordofmouth occupy prominent position hence aim paper propose method based big data technology analysing measuring perceived transmitted tdi otrs presented search engine emphasising cognitive spatial temporal evaluative affective tdi dimension test approach massive analysis metadata processed search engine performed tripadvisor otrs thing ile de france outstanding smart tourist destination result obtained consistent allow extraction insight business intelligence']\n","2024-10-11 04:19:47,068 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:47,069 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:19:51,731 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:51,744 - INFO - built Dictionary<2554 unique tokens: ['amount', 'analysis', 'array', 'available', 'business']...> from 80 documents (total 10275 corpus positions)\n","2024-10-11 04:19:51,745 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2554 unique tokens: ['amount', 'analysis', 'array', 'available', 'business']...> from 80 documents (total 10275 corpus positions)\", 'datetime': '2024-10-11T04:19:51.745089', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:51,889 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:19:51,889 - INFO - Sample of sampled data: ['sentiment analysis social medium textual post provide information knowledge applicable social setting business intelligence evaluation citizen opinion governance mood triggered device internet thing feature extraction selection key determinant accuracy computational cost machine learning model analysis feature extraction selection technique utilize bag word ngrams frequencybased algorithm especially term frequencyinverse document frequency however approach consider relationship word ignore word characteristic suffer high feature dimensionality paper propose evaluate feature extraction selection approach utilizes fixed hybrid ngram window feature extraction minimum redundancy maximum relevance feature selection algorithm sentence level sentiment analysis approach improves existing feature extraction technique specifically ngram generating hybrid vector word part speech po tag word semantic orientation vector extracted using static trigram window identified lexicon sentiment word appears sentence blend word po tag sentiment orientation static trigram used build feature vector optimal feature vector selected using minimum redundancy maximum relevance mrmr algorithm experiment carried using public yelp dataset compare performance proposed model existing feature extraction model bow normal ngrams lexiconbased bag word semantic orientation using supervised machine learning classifier experimental result showed proposed model highest fmeasure compared highest baseline approach wilcoxon test carried ascertained proposed approach performed significantly better baseline approach comparative performance analysis datasets affirmed proposed approach generalizable', 'purpose research social medium frequently analyze social medium usage smus positive consequence organization individual however recent innovation study caution smu may always lead positive new product development npd outcome competing stream research highlight fundamental tension exists social medium literature exemplified question smu good bad npd manuscript author suggest appropriate question follows positive negative indirect effect smu npd performance purpose paper discus aforementioned point detail designmethodologyapproach literature review provides model hypothesis using sample chinese firm author conducted empirical test following multiple regression analysis finding result demonstrate smu facilitates business analytics ability social legitimacy opportunity impairs entrepreneurial proclivity motivation three construct turn mediate effect smu npd performance moreover paper explores technological turbulence moderate smus effect business analytics entrepreneurship proclivity social legitimacy research limitationsimplications result may affected context solely china type crosssectional data set future research might take decompositional approach study smus effect innovation different npd stage furthermore widely varying purpose eg marketing information searching partner collaboration new product launch etc certainly need clarity understanding firm leverage different social medium activity successful npd practical implication first suggest manager china explicitly aware doubleedged sword effect smu npd performance second study encourages manager use social medium carefully technological turbulence becomes intense originalityvalue drawing abilitymotivationopportunity framework one first study simultaneously examines benefit cost smu npd addition paper bridge separate literature social medium business analytics entrepreneurial proclivity social legitimacy contributes npd research', 'market surveillance system msss increasingly used monitor trading activity financial market maintain market integrity existing msss primarily focus statistical analysis market activity data largely ignore textual market information including limited news report various social medium suggested theoretical exploration finance prevailing market surveillance practice unstructured market information hold major yet underexplored opportunity surveillance paper propose news analysis approach help commonsense knowledge assess risk suspicious transaction identified market activity analysis approach explicitly model semantic relation transaction news article provides semantic reference word news article conducted experiment using data collected realworld market found proposed approach significantly outperforms existing method based transaction characteristic traditional textual analysis method experiment also show performance advantage proposed approach mainly come modeling newstransaction relationship research contributes market surveillance literature significant practical implication', 'web data extraction important problem studied mean different scientific tool broad range application many approach extracting data web designed solve specific problem operate adhoc domain approach instead heavily reuse technique algorithm developed field information extraction survey aim providing structured comprehensive overview literature field web data extraction provided simple classification framework existing web data extraction application grouped two main class namely application enterprise level social web level enterprise level web data extraction technique emerge key tool perform data analysis business competitive intelligence system well business process reengineering social web level web data extraction technique allow gather large amount structured data continuously generated disseminated web social medium online social network user offer unprecedented opportunity analyze human behavior large scale discus also potential crossfertilization ie possibility reusing web data extraction technique originally designed work given domain domain c elsevier bv right reserved', 'driven fierce competition airline industry carrier strive increase customer satisfaction understanding expectation tailoring service offering due explosive growth social medium usage airline opportunity capitalize abundantly available online customer review ocr extract key insight service competitor however analysis unstructured textual data complex timeconsuming research aim automatically efficiently extract airlinespecific intelligence ie passengerperceived strength weakness ocr topic modeling algorithm employed discover prominent service quality aspect discussed ocr likewise sentiment analysis method collocation analysis used classify review sentence sentiment ascertain major reason passenger satisfactiondissatisfaction respectively subsequently ensembleassisted topic model eatm sentiment analyzer esa proposed classify review sentence representative aspect sentiment case study involving airline review sentence usbased target carrier four competitor used validate proposed framework proposed eatm esa achieved higher classification accuracy individual benchmark model respectively result reveal different aspect airline service quality ocr airlinespecific sentiment summary towards aspect root cause passenger satisfactiondissatisfaction identified topic finally several theoretical managerial implication improving airline service derived based result']\n","2024-10-11 04:19:51,893 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:51,894 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:19:57,018 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:19:57,031 - INFO - built Dictionary<2439 unique tokens: ['accuracy', 'affirmed', 'algorithm', 'analysis', 'appears']...> from 80 documents (total 9599 corpus positions)\n","2024-10-11 04:19:57,031 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2439 unique tokens: ['accuracy', 'affirmed', 'algorithm', 'analysis', 'appears']...> from 80 documents (total 9599 corpus positions)\", 'datetime': '2024-10-11T04:19:57.031241', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:19:57,176 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:19:57,177 - INFO - Sample of sampled data: ['pressing need vehicle quality management professional decision support vehicle defect discovery classification process paper employ text mining popular social medium used vehicle enthusiast online discussion forum find sentiment analysis conventional technique consumer complaint detection insufficient finding categorizing prioritizing vehicle defect discussed online forum describe evaluate new process decision support system automotive defect identification prioritization finding provide managerial insight social medium analytics improve automotive quality management c elsevier bv right reserved', 'introduction big data analytics bda healthcare allow use new technology treatment patient health management paper aim analyzing possibility using big data analytics healthcare research based critical analysis literature well presentation selected result direct research use big data analytics medical facility direct research carried based research questionnaire conducted sample medical facility poland literature study shown use big data analytics bring many benefit medical facility direct research shown medical facility poland moving towards databased healthcare use structured unstructured data reach analytics administrative business clinical area research positively confirmed medical facility working structural data unstructured data following kind source data distinguished database transaction data unstructured content email document data device sensor however use data social medium lower activity reach analytics administrative business also clinical area clearly show decision made medical facility highly datadriven result study confirm analyzed literature medical facility moving towards databased healthcare together benefit', 'significant advancement technology past decade given rise relatively straightforward array internet application based open source software application service aim enhance online collaboration broad audience particularly social networking site platform transformed dynamic online interaction information exchange million user regularly engaging sharing various digital content user express thought opinion diverse topic contributing valuable insight personal academic commercial purpose however sheer volume rapid generation data present challenge decisionmakers underlying technology extract meaningful insight leverage data derived social network researcher focused assisting company comprehending conduct competitive analysis convert data actionable knowledge paper offer comprehensive literature review data warehouse approach derived social network commence introducing fundamental concept data warehousing social network followed presentation three category data warehouse approach along overview notable conduct comparative analysis existing work', 'paper proposed advanced business intelligence framework firm postpandemic phase increase performance productivity proposed framework utilizes significant tool era social medium big data analysis business intelligence system addition survey outstanding related paper study open challenge based framework described well proposed methodology minimize challenge given finally conclusion research point worth studying discussed', 'understudied area field social medium research design decision support system aid manager way automated message component generation recent advance form artificial intelligence suggested allow content creator manager transcend task creation towards editing thus overcoming common problem tyranny blank screen research address topic proposing novel system design suggest engagementdriven message feature well automatically generate critical fully written unique tweet message component goal maximizing probability relatively high engagement level multimethods design relies use econometrics machine learning bayesian statistic widely used emerging field business marketing analytics system design intended analyze tweet message purpose generating critical component structure tweet propose econometric model judge quality written tweet way engagementlevel prediction well generative probability model autogeneration tweet message testing design demonstrates need take account contextual semantic syntactic feature message controlling individual user characteristic generated tweet component structure maximizes potential engagement level']\n","2024-10-11 04:19:57,181 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:19:57,182 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:01,863 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:01,875 - INFO - built Dictionary<2366 unique tokens: ['analysis', 'analytics', 'automotive', 'bv', 'categorizing']...> from 80 documents (total 9060 corpus positions)\n","2024-10-11 04:20:01,876 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2366 unique tokens: ['analysis', 'analytics', 'automotive', 'bv', 'categorizing']...> from 80 documents (total 9060 corpus positions)\", 'datetime': '2024-10-11T04:20:01.876142', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:02,013 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:02,014 - INFO - Sample of sampled data: ['modern audit engagement often involve examination client using big data analytics remain competitive relevant today business environment client system integrated cloud internet thing external data source social medium furthermore many engagement client integrating big data new complex business analytical approach generate intelligence decision making scenario provides almost limitless opportunity urgency external auditor utilize advanced analytics paper first position need external audit profession move toward big data audit analytics review regulation regarding audit evidence analytical procedure contrast emerging environment big data advanced analytics big data environment audit profession potential undertake advanced predictive prescriptiveoriented analytics next section proposes discusses six key research question idea followed emphasis research need quantification measurement reporting paper provides synthesis review concern facing audit community growing use big data complex analytics client contributes literature expanding upon emerging concern providing opportunity future research', 'paper build previous research investigated critical factor underpinning ecrm activity smes however marketing practice moved e ecrm today disruptive technology crm social medium particularly true smes social medium free tool used foster engagement organization consumer thus social crm scrm online survey completed smes exploratory factor analysis uncovered seven factor underpinning scrm activity finding illustrate importance customer relationship orientation uncover support data issue around social medium use promote importance customer engagement online community recognise driving role information process study contributes theory measuring scrm smes dynamic capability lens sme ownermanagers emphasis need strategically combine social medium use crm activity', 'customer loyalty significantly evolved last decade specifically social medium platform marketer engage customer regularly omnichannel approach allows brand interact customer whether persontoperson persontocommunity customer loyalty characterised literature psychological process whereby customer loyalty attache towards specific service brand time customer loyalty contributes consumer behaviour preference specific brand service therefore company consider formulating developing appropriate business intelligence strategy drive customer towards loyalty increase engagement brand furthermore psychological shopper behaviour might expand improve current research towards customer perspective distinguishing customer incentivised brand activity venture suggesting customer loyalty customer judgement business notable positive impact brand identify business centre attention attraction brand understand identify best loyalty strategy target customer business must use opportunity enable brand develop new innovative approach approach continuously drive brand loyalty sale creating competitive advantage market customer loyalty become strategy business marketing empowers consumer engaged throughout initial interaction purchase journey become loyal brand engagement journey help brand establish grow due continuous support consumer general aim study determine nature relationship customer engagement factor brand loyalty study identified five customer engagement factor literature brand reputation social medium wordofmouth customer experience merchandising view investigating role brand loyalty noteworthy factor welldocumented precovid environment question remains however whether factor still valid reliable covid business environment study aim determine response precisely question quantitative research design selfdeveloped questionnaire used measure one factor fivepoint likert scale factor respective measuring criterion validated empirically using exploratory factor analysis social medium platform instagram used initiate snowball sample total social medium participant responded completing online google form questionnaire respondent profile show brand social medium page preferred method brand communication followed email sm telephonic communication method latter fact clearly disliked found respondent prefer email followed sm social medium platform receive brand communication however communication via telephone conversation disliked consumer respondent find brand advertisement memorable seen different platform channel communication memorable channel social medium recall rate total participant first read review new product launched find way wordofmouth brand community make informed discussion purchasing product listening consumer share review platform data reliable alpha ge sample deemed adequate kmo ge multiple regression analysis used determine relationship customer engagement factor brand loyalty result indicated significant p le positive relationship factor brand reputation r p le social medium r p le wordofmouth r p le visibility r p le model explains satisfactory cumulative variance r factor customer experience however reconsidered antecedent significantly influence consumer loyalty brand exploratory factor analysis used determine whether factor determine brand loyalty eight factor identified explaining variance cumulatively factor visibility merchandise brand reputation brand trust brand reference outside shop advice inside shop brand ambassador purchase experience personal choice eight new factor make sense factor manage brand loyalty management rather focus factor concentrate initial five factor indicated literature possible area future research investigate age demographic area regard participant could viewed opinion centralised focus towards different age group generation gen z millennials gen x boomer silent generation also investigated compare illustrate engagement strategy influential towards brand loyalty', 'internet era everincreasing interaction among participant size data increasing rapidly information available u near future going unpredictable modeling visualizing data one challenging task data analytics field therefore business intelligence way company use data improve business operational efficiency whereas data analytics involves improving way making intelligence data acting thus proposed work focus prevailing challenge data analytics application social medium like facebook twitter blog ecommerce eservice among possible interaction ecommerce eeducation eservices identified important domain analytics technique focus machine learning technique improving practice research ex domain empirical analysis done show performance proposed system using realtime datasets', 'malaysian actively expressing feeling opinion social network twitter expression harvested studying customer sentiment towards certain brand preference customer business analytics becoming important sentiment analysis may provide crucial information making customerdriven decision therefore accuracy critical determining reliability integrity analysis although processing massive message social medium huge challenge made easier advancement big data architecture many technique interpreting message however malaysian consists people diversified background multitude culture language daily use therefore common find message social medium mixture various local language slang slang used mostly dialect expressed alphabet project explores technique analyzing popularity telecommunication company malaysia address shortfall using existing english sentiment dictionary accomplishment project new localized dictionary developed compiling various mixture english malay localized sentiwords slang dictionary new dictionary proven capture analyze extra keywords malaysian tweet sampled additional match improve accuracy compared existing dictionary']\n","2024-10-11 04:20:02,018 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:02,019 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:06,804 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:06,818 - INFO - built Dictionary<2558 unique tokens: ['advanced', 'almost', 'analytical', 'analytics', 'approach']...> from 80 documents (total 10257 corpus positions)\n","2024-10-11 04:20:06,818 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2558 unique tokens: ['advanced', 'almost', 'analytical', 'analytics', 'approach']...> from 80 documents (total 10257 corpus positions)\", 'datetime': '2024-10-11T04:20:06.818270', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:06,947 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:06,948 - INFO - Sample of sampled data: ['modern audit engagement often involve examination client using big data analytics remain competitive relevant today business environment client system integrated cloud internet thing external data source social medium furthermore many engagement client integrating big data new complex business analytical approach generate intelligence decision making scenario provides almost limitless opportunity urgency external auditor utilize advanced analytics paper first position need external audit profession move toward big data audit analytics review regulation regarding audit evidence analytical procedure contrast emerging environment big data advanced analytics big data environment audit profession potential undertake advanced predictive prescriptiveoriented analytics next section proposes discusses six key research question idea followed emphasis research need quantification measurement reporting paper provides synthesis review concern facing audit community growing use big data complex analytics client contributes literature expanding upon emerging concern providing opportunity future research', 'sentiment analysis emerged one prominent research branch endless usage application monitoring social medium forum blog online resource customer review product competition survey response understand customer insight significant importance business analytics proliferation informal user generated data online use mixed language become common phenomenon mixed language arises use linguistic code switching lcs practice using one language single sentence mixed language rarely subject sentiment analysis lack clear grammatical structure render previous approach sentiment analysis ineffective text paper propose strategy determine sentiment sentence written mixed language comprising hindi english lexicon technique used analyze sentiment data belonging one source language well mixed language data grammatical transition common mixed language taken account sentiment analysis demonstrate effectiveness proposed approach via case study social medium data set', 'malaysian actively expressing feeling opinion social network twitter expression harvested studying customer sentiment towards certain brand preference customer business analytics becoming important sentiment analysis may provide crucial information making customerdriven decision therefore accuracy critical determining reliability integrity analysis although processing massive message social medium huge challenge made easier advancement big data architecture many technique interpreting message however malaysian consists people diversified background multitude culture language daily use therefore common find message social medium mixture various local language slang slang used mostly dialect expressed alphabet project explores technique analyzing popularity telecommunication company malaysia address shortfall using existing english sentiment dictionary accomplishment project new localized dictionary developed compiling various mixture english malay localized sentiwords slang dictionary new dictionary proven capture analyze extra keywords malaysian tweet sampled additional match improve accuracy compared existing dictionary', 'web data extraction important problem studied mean different scientific tool broad range application many approach extracting data web designed solve specific problem operate adhoc domain approach instead heavily reuse technique algorithm developed field information extraction survey aim providing structured comprehensive overview literature field web data extraction provided simple classification framework existing web data extraction application grouped two main class namely application enterprise level social web level enterprise level web data extraction technique emerge key tool perform data analysis business competitive intelligence system well business process reengineering social web level web data extraction technique allow gather large amount structured data continuously generated disseminated web social medium online social network user offer unprecedented opportunity analyze human behavior large scale discus also potential crossfertilization ie possibility reusing web data extraction technique originally designed work given domain domain c elsevier bv right reserved', 'big data collection large datasets traditional digital source identify trend pattern quantity variety computer data growing exponentially many reason example retailer building vast database customer sale activity organization working logistics financial service public social medium sharing vast quantity sentiment related sale price product challenge big data include volume variety structured unstructured data paper implemented several machine learning model spark mllib using pyspark scalable fast easily integrated tool better performance traditional model studied stock top company whose data include historical stock price mllib model linear regression generalized linear regression random forest decision tree implemented naive bayes logistic regression classification model experimental result suggest linear regression random forest generalized linear regression provide accuracy experimental result decision tree well predict share price movement stock market']\n","2024-10-11 04:20:06,952 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:06,953 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:11,654 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:11,667 - INFO - built Dictionary<2477 unique tokens: ['advanced', 'almost', 'analytical', 'analytics', 'approach']...> from 80 documents (total 9944 corpus positions)\n","2024-10-11 04:20:11,668 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2477 unique tokens: ['advanced', 'almost', 'analytical', 'analytics', 'approach']...> from 80 documents (total 9944 corpus positions)\", 'datetime': '2024-10-11T04:20:11.668392', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:11,813 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:11,814 - INFO - Sample of sampled data: ['increased access data affordable technology today made business analytics within reach organization however many organization unsure translate analytics use organizational value area business analytics value creation become popular point discussion amongst practitioner much research needed provide insight effective use business analytics objective paper deepen understanding effective implementation analytics within organization specifically performed indepth case study rovio entertainment investigate pioneer mobile game initiated analyticsdriven transformation study contributes theory practice business analytics two way first drawing perspective technology affordances study shed light varying affordances business analytics second study present empiricallyinformed insight affordances could effectively actualized analyticsdriven transformation organization collectively study open blackbox effective implementation business analytics organizational value creation c elsevier bv right reserved', 'recently social medium shown provide information tourism politics recent study conducted wine sale tourism trend forecast using machine learning algorithm hundred thousand blog online news article twitter tweet previous research shown mining social medium predict realtime market penetration figure also forecast social business trend tourism extend research evaluate predictive value social medium forecasting trend value publicly traded hospitality tourism company', 'increasing number social medium user affect individual corporation user banking sector example use social medium support social customer relationship management activity investigate dynamic evolution conversation network bank customer using social network analysis methodology measurement conducted calculating network property see characteristic active network customer talking bank service also express opinion social medium therefore perform sentiment analysis classify customer opinion positive negative neutral class research performed twitter conversation bank mandiri bank central asia bca bank negara indonesia bni result research beneficial business intelligence purpose support decision making', 'study gathered data professional user information via survey twitter perceived service useful information reason one may expect content tweet give valuable information derived extracted information tweeted tweeted professional user aware tweet manipulated communication department adjust understanding content delivered reason fake news seen problem either professional twitter seen valuable alongside social medium software additional software solution used directly together software integrated software solution standalone service found less value experienced user sign twitter valuable tool learning', 'product review play crucial role providing valuable insight consumer producer analyzing vast amount data generated around product post comment view challenging business intelligence purpose sentiment analysis content help consumer producer gain better understanding market status enabling make informed decision study propose novel hybrid approach based deep neural network dnns sentiment analysis product review focusing classification sentiment expressed approach utilizes recursive neural network rnn algorithm sentiment classification address imbalanced distribution positive negative sample social network data employ resampling technique balance dataset increasing sample minority class decreasing sample majority class evaluate approach using amazon data comprising four product category clothing car luxury good household appliance experimental result demonstrate proposed approach performs well sentiment analysis product review particularly context digital marketing furthermore attentionbased rnn algorithm outperforms baseline rnn approximately notably study reveals consumer sentiment variation across different product particularly relation appearance price aspect']\n","2024-10-11 04:20:11,818 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:11,818 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:17,010 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:17,023 - INFO - built Dictionary<2493 unique tokens: ['access', 'actualized', 'affordable', 'affordances', 'amongst']...> from 80 documents (total 9815 corpus positions)\n","2024-10-11 04:20:17,024 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2493 unique tokens: ['access', 'actualized', 'affordable', 'affordances', 'amongst']...> from 80 documents (total 9815 corpus positions)\", 'datetime': '2024-10-11T04:20:17.024145', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:17,176 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:17,177 - INFO - Sample of sampled data: ['starting engine must continually check dashboard optimize fuel consumption love research chapter explains critical term layman language avoid beginner mistake business analytics similar car dashboard need useful metric speed ambient temperature fuel consumption improve performance comprehensive metric empower u demonstrate social medium marketing word mouth wom social sharing help achieve corporate objective e g increase sale andor reduce cost x percent unless successfully link measure strategic objective management unlikely interested social medium outcome', 'global socialnomics rise big data make enterprise face tremendous tide data time efficiently process analyze unstructured data dig useful information issue every level enterprise face settle gartner conducted survey gartner cio agenda cio worldwide found business intelligence based big data primary issue ibm hence understanding developing trend social medium research mainly based author previously proposed paper ises face tremendous tidesign implementation web crawler based social networkst time efficiently process analyze unstructured data dig useful infed architecture web crawler new architecture added concept object structure design implementation whole system author also investigate improved object structure brings convenience system maintenance', 'human emotion expressed social medium play increasingly important role shaping policy decision however process emotion produce influence online social medium network relatively unknown previous work focus largely sentiment classification polarity identification adequately consider way emotion affect user influence research developed novel framework theorybased model proofofconcept system dissecting emotion user influence social medium network system model emotiontriggered influence facilitates analysis emotioninfluence causality context u border security using tweet posted user motivated theory emotion spread model integrated influencecomputation method called interaction modeling im approach compared benchmark using user centrality uc approach based social position im found identified influential user broadly related u cultural issue influential user tended express intense emotion fear anger disgust sadness emotion trust distinguishes influential user others whereas anger fear contributed significantly causing user influence research contributes incorporating human emotion datainformationknowledgewisdom model knowledge management providing new information system artifact new causality finding emotioninfluence analysis', 'study examines role social medium analytics sma providing competitive intelligence ci building ci theory data qualitative semistructured interview respondent belonging social medium manufacturing telecommunication service industry analyzed using nvivo coding matrix query result show sma provides expanded ci beyond previous limit customersmarkets competitor including insight supply chain cost informationflow moreover smadriven ci provide visibility supply chain uncertainty enabling improvement demand planning inventory management sma provide ci competitor strength weakness customer dynamic however bidirectional nature ci could determinantal smlinked customer educatedkept informed matrix query result illuminate differencessimilarities respondent view academically study show sma provides expanded ci business beyond previously known scope competitor analysis', 'era information overload text clustering play important part analysis processing pipeline partitioning highquality text unseen category tremendously help application information retrieval database business intelligence domain short text social medium environment tweet however remain difficult interpret due broad aspect context traditional text similarity approach rely lexical matching ignoring semantic meaning word recent advance distributional semantic space opened alternative approach utilizing highquality word embeddings aid interpretation text semantics paper investigate word mover distance metric automatically cluster short text using word semantic information utilize agglomerative strategy clustering method efficiently group text based similarity experiment indicates word mover distance outperformed standard metric short text clustering task']\n","2024-10-11 04:20:17,181 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:17,182 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:22,264 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:22,277 - INFO - built Dictionary<2455 unique tokens: ['achieve', 'ambient', 'analytics', 'andor', 'avoid']...> from 80 documents (total 9668 corpus positions)\n","2024-10-11 04:20:22,278 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2455 unique tokens: ['achieve', 'ambient', 'analytics', 'andor', 'avoid']...> from 80 documents (total 9668 corpus positions)\", 'datetime': '2024-10-11T04:20:22.278100', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:22,417 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:22,418 - INFO - Sample of sampled data: ['significant advancement technology past decade given rise relatively straightforward array internet application based open source software application service aim enhance online collaboration broad audience particularly social networking site platform transformed dynamic online interaction information exchange million user regularly engaging sharing various digital content user express thought opinion diverse topic contributing valuable insight personal academic commercial purpose however sheer volume rapid generation data present challenge decisionmakers underlying technology extract meaningful insight leverage data derived social network researcher focused assisting company comprehending conduct competitive analysis convert data actionable knowledge paper offer comprehensive literature review data warehouse approach derived social network commence introducing fundamental concept data warehousing social network followed presentation three category data warehouse approach along overview notable conduct comparative analysis existing work', 'digitization era altering several industry include way data analyzed inferred zettabyte data exist digital world today data generated per second every human approximate amount megabyte volume data would double every year thus reach zb point interactive data corporation idc estimated end year ecommerce transaction bb bc hit billion per day internet advent big real time data triggered disruptive change many field exploding volume different source data like heterogeneous data data integration spatiotemporal correlation data batch analytics realtime analytics data sharing semantic interoperability requires development scalable platform fuse multiple data layer handle data intelligently big data approach challenge anymore collect data draw valuable conclusion properly analyzing growth unstructured data generated business irrefutable pressure preserve longer period time clear exploiting collected data always considered practitioner researcher huge velocity heterogeneity enormity massive stream realtime data shove limit current storage management processing capability admittedly traditional method extract transform load etl challenged applied emerging opportunistically crowed sensed data stream data stream structured way serve one predefined purpose directly used mean yet emerging unstructured data contextbased data internet social medium well credit card transaction clear used better understand mobility pattern analytical company gartner state billion interconnected device obvious produce massive amount meaningful data data used many application realtime industrial equipment monitoring traffic planning automated maintenance etc therefore essential develop modern system abstraction allow u resourcefully process huge new data stream enormous amount data urge growth integrated insightful big realtime data analytics platform upcoming contemporary technology like digital twin integrates historical data past machine usage current data us sensor collect realtime data working status operational data attached physical model component send relevant data via cloudbased system side bridge help data analytics platform produce required insight big realtime data analytics platform assist perform useful operation data analytics complete package purpose data analytics platform used acquire constructive insight huge volume data data analytics platform ecosystem technology service help business increasing revenue enhance operational efficiency stabilize marketing campaign customer service effort respondmore quickly toemerging market trend gain competitive edge rival data analytics platform find pattern relationship data applying statistical technique communicates result generated analytical model executive end user make decision help data visualization tool display data single screen updated real time new information becomes available big data realtime data analytics platform support full spectrum data type protocol integration speed simplify data wrangling process big data real time platform provides accurate data increase efficiency workspace give answer complex question along security hence play key role business analytics', 'social medium emerged new communication channel consumer company generate large volume unstructured text data social medium content contains consumer opinion interest recognized valuable material business mine useful information consequently many researcher reported opinionmining framework method technique tool business intelligence various industry study sometimes focused use opinion mining business field emphasized method analyzing content achieve result accurate also considered visualize result ensure easier understanding however found approach often technically complex insufficiently userfriendly help business decision planning therefore study attempt formulate comprehensive practical methodology conduct social medium opinion mining apply methodology case study oldest instant noodle product korea also present graphical tool visualized output include volume sentiment graph timeseries graph topic word cloud heat map valence tree map classification resource publicdomain social medium content blog forum message news article analyze natural language processing statistic graphic package freeware r project environment believe methodology visualization output provide practical reliable guide immediate use food industry industry well', 'popularity online content social medium frequently experience ebb flow thus evolution often involves different stage burst valley exploring pattern popularity evolution especially burst form decay even predicting trend popularity evolution important research topic beneficial support decision making many application emergency management business intelligence public security previous work popularity prediction focused predicting popularity volume online content popularity burst ignored exploration popularity evolution prediction stage fill gap paper propose method popularity stage prediction problem microscopic level macroscopic level microscopic level first extract multiple dynamic factor infer future evolution stage considering contribution different dynamic factor macroscopic level extract overall evolution pattern popularity stage adopt pattern matchingbased method predict future popularity stage evaluate proposed approach using tweet sinaweibo popular twitterlike social medium platform china experimental result show effectiveness proposed approach predicting popularity evolution stage', 'although term big data often used refer large datasets generated science engineering business analytics effort increasingly used refer social networking website enormous quantity personal information post networking activity contained therein quantity sensitive nature information constitutes fascinating mean inferring sociological parameter grave risk security privacy present study aimed find evidence literature malware already adapted significant degree specific form big data evidence potential abuse personal information found predictive model personal trait facebook user alarmingly effective minimal depth information like likely complex form information eg post photo connection status could lead unprecedented level intrusiveness familiarity sensitive personal information support view potential abuse private information exploited found research describing rapid adaptation malware social networking site purpose social engineering involuntary surrendering personal information c elsevier ltd right reserved']\n","2024-10-11 04:20:22,423 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:22,424 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:27,100 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:27,113 - INFO - built Dictionary<2467 unique tokens: ['academic', 'actionable', 'advancement', 'aim', 'along']...> from 80 documents (total 9848 corpus positions)\n","2024-10-11 04:20:27,114 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2467 unique tokens: ['academic', 'actionable', 'advancement', 'aim', 'along']...> from 80 documents (total 9848 corpus positions)\", 'datetime': '2024-10-11T04:20:27.114878', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:27,251 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:27,252 - INFO - Sample of sampled data: ['era information overload text clustering play important part analysis processing pipeline partitioning highquality text unseen category tremendously help application information retrieval database business intelligence domain short text social medium environment tweet however remain difficult interpret due broad aspect context traditional text similarity approach rely lexical matching ignoring semantic meaning word recent advance distributional semantic space opened alternative approach utilizing highquality word embeddings aid interpretation text semantics paper investigate word mover distance metric automatically cluster short text using word semantic information utilize agglomerative strategy clustering method efficiently group text based similarity experiment indicates word mover distance outperformed standard metric short text clustering task', 'digitization era altering several industry include way data analyzed inferred zettabyte data exist digital world today data generated per second every human approximate amount megabyte volume data would double every year thus reach zb point interactive data corporation idc estimated end year ecommerce transaction bb bc hit billion per day internet advent big real time data triggered disruptive change many field exploding volume different source data like heterogeneous data data integration spatiotemporal correlation data batch analytics realtime analytics data sharing semantic interoperability requires development scalable platform fuse multiple data layer handle data intelligently big data approach challenge anymore collect data draw valuable conclusion properly analyzing growth unstructured data generated business irrefutable pressure preserve longer period time clear exploiting collected data always considered practitioner researcher huge velocity heterogeneity enormity massive stream realtime data shove limit current storage management processing capability admittedly traditional method extract transform load etl challenged applied emerging opportunistically crowed sensed data stream data stream structured way serve one predefined purpose directly used mean yet emerging unstructured data contextbased data internet social medium well credit card transaction clear used better understand mobility pattern analytical company gartner state billion interconnected device obvious produce massive amount meaningful data data used many application realtime industrial equipment monitoring traffic planning automated maintenance etc therefore essential develop modern system abstraction allow u resourcefully process huge new data stream enormous amount data urge growth integrated insightful big realtime data analytics platform upcoming contemporary technology like digital twin integrates historical data past machine usage current data us sensor collect realtime data working status operational data attached physical model component send relevant data via cloudbased system side bridge help data analytics platform produce required insight big realtime data analytics platform assist perform useful operation data analytics complete package purpose data analytics platform used acquire constructive insight huge volume data data analytics platform ecosystem technology service help business increasing revenue enhance operational efficiency stabilize marketing campaign customer service effort respondmore quickly toemerging market trend gain competitive edge rival data analytics platform find pattern relationship data applying statistical technique communicates result generated analytical model executive end user make decision help data visualization tool display data single screen updated real time new information becomes available big data realtime data analytics platform support full spectrum data type protocol integration speed simplify data wrangling process big data real time platform provides accurate data increase efficiency workspace give answer complex question along security hence play key role business analytics', 'consumer often consider multiple alternative product category prior making purchase uncovering predominant pattern coconsiderations help business learn competitive structure market mind consumer extant research shown various type online offline consumer activity data eg shopping basket search browsing history social medium mention used infer product coconsiderations paper study case uncovering coconsideration pattern using massive dataset online price quote request u auto shopper main challenge face privacy protection unique individual identifier anonymous otherwise contained data data deficiency prevents u using existing method affinity analysis inferring coconsiderations however leveraging spatiotemporal pattern data manage probabilistically uncover predominant pattern coconsiderations u auto market validation illustration usefulness embed inferred market structure sale response model show substantial improvement predictive performance c direct marketing educational foundation inc dba marketing edge right reserved', 'social medium three billion user sharing event comment feeling throughout world serf critical information source large volume high velocity wide variety data previous study information spreading relationship analyzing individual modeling etc heavily conducted explore tremendous social commercial value social medium data survey study previous literature existing application practical perspective outline commonly used pipeline building social mediabased application focus discussing available analysis technique topic analysis time series analysis sentiment analysis network analysis present impact application three different area including disaster management healthcare business finally list existing challenge suggest promising future research direction term data privacy g wireless network multilingual support', 'online analytical processing olap approach widely used business intelligence cater multidimensional query decade era cuttingedge technology internet data generation rate rising exponentially internet thing sensor social medium platform major contributor leading toward absolute data boom storage speed crucial parameter undoubtedly burning issue efficient data handling key idea address two challenge big data computing olap article author proposed implemented olap hadoop indexing oohi oohi offer simplified multidimensional model store dimension schema server measure hadoop cluster overall setup divided various module namely data storage module dsm dimension encoding module dem cube segmentation module segment selection module ssm block selection process bsap module serialization deserialization concept applied dsm storage retrieval data efficient space utilization integer encoding adopted dem dimension hierarchy selected escape sparsity problem multidimensional big data reduce search space chunk cube queried chunk ssm play important role map reducebased indexing approach series seek operation bsap module integrated achieve parallelism fault tolerance realtime oceanography data supermarket data set applied demonstrate oohi model data independent various test case designed cover scope dimension volume data set comparative result performance analytics portray oohi outperforms data storage dice slice rollup operation compared hadoop based olap']\n","2024-10-11 04:20:27,256 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:27,257 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:32,686 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:32,700 - INFO - built Dictionary<2486 unique tokens: ['advance', 'agglomerative', 'aid', 'alternative', 'analysis']...> from 80 documents (total 9804 corpus positions)\n","2024-10-11 04:20:32,701 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2486 unique tokens: ['advance', 'agglomerative', 'aid', 'alternative', 'analysis']...> from 80 documents (total 9804 corpus positions)\", 'datetime': '2024-10-11T04:20:32.701581', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:32,850 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:32,851 - INFO - Sample of sampled data: ['social medium major platform opinion sharing order better understand exploit opinion social medium aim classify user opposite opinion topic decision support rather mining text content introduce linkbased classification model named global consistency maximization gcm partition social network two class user opposite opinion experiment twitter data set show global approach achieves higher accuracy two baseline approach linkbased classifier robust small training sample selected properly c elsevier bv right reserved', 'human emotion expressed social medium play increasingly important role shaping policy decision however process emotion produce influence online social medium network relatively unknown previous work focus largely sentiment classification polarity identification adequately consider way emotion affect user influence research developed novel framework theorybased model proofofconcept system dissecting emotion user influence social medium network system model emotiontriggered influence facilitates analysis emotioninfluence causality context u border security using tweet posted user motivated theory emotion spread model integrated influencecomputation method called interaction modeling im approach compared benchmark using user centrality uc approach based social position im found identified influential user broadly related u cultural issue influential user tended express intense emotion fear anger disgust sadness emotion trust distinguishes influential user others whereas anger fear contributed significantly causing user influence research contributes incorporating human emotion datainformationknowledgewisdom model knowledge management providing new information system artifact new causality finding emotioninfluence analysis', 'increased access data affordable technology today made business analytics within reach organization however many organization unsure translate analytics use organizational value area business analytics value creation become popular point discussion amongst practitioner much research needed provide insight effective use business analytics objective paper deepen understanding effective implementation analytics within organization specifically performed indepth case study rovio entertainment investigate pioneer mobile game initiated analyticsdriven transformation study contributes theory practice business analytics two way first drawing perspective technology affordances study shed light varying affordances business analytics second study present empiricallyinformed insight affordances could effectively actualized analyticsdriven transformation organization collectively study open blackbox effective implementation business analytics organizational value creation c elsevier bv right reserved', 'main purpose social business intelligence help company making decision performing multidimensional analysis relevant information disseminated social network although data quality general issue sbi approach aimed assessing data collection context dependent task paper define quality indicator metric serf assess overall quality collection integrates measure obtained several quality criterion applied filter post relevant sbi project selection best quality criterion include quality indicator complex task requires deep understanding context objective analysis paper propose new methodology design quality indicator sbi project whose quality criterion consider content coherence data provenance thus context defined objective analysis methodology help user find quality criterion best suit user available data integrate valid quality indicator', 'research examines impact social medium capability innovation performance knowledge ambidexterity potential moderator role business analytics talent equation test proposed theory performing partial least square path modeling secondary dataset sample composed small u firm result empirical analysis suggest social medium capability enables firm effectively balance exploration exploitation knowledge ie knowledge ambidexterity turn facilitates innovation performance business analytics talent play moderator role relationship']\n","2024-10-11 04:20:32,870 - INFO - 에폭 1/5, 손실: 732.6713\n","2024-10-11 04:20:32,878 - INFO - 에폭 2/5, 손실: 717.5418\n","2024-10-11 04:20:32,885 - INFO - 에폭 3/5, 손실: 706.7284\n","2024-10-11 04:20:32,892 - INFO - 에폭 4/5, 손실: 696.5648\n","2024-10-11 04:20:32,900 - INFO - 에폭 5/5, 손실: 686.4436\n","2024-10-11 04:20:32,916 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:32,926 - INFO - built Dictionary<2558 unique tokens: ['accuracy', 'achieves', 'aim', 'approach', 'baseline']...> from 80 documents (total 10207 corpus positions)\n","2024-10-11 04:20:32,927 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2558 unique tokens: ['accuracy', 'achieves', 'aim', 'approach', 'baseline']...> from 80 documents (total 10207 corpus positions)\", 'datetime': '2024-10-11T04:20:32.927077', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:33,098 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:33,099 - INFO - Sample of sampled data: ['development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm', 'purpose purpose paper mine competitive intelligence social medium find market insight comparing consumer opinion sale performance business one competitor analyzing public social medium data designmethodologyapproach exploratory test using multiple case study approach used compare two competing smartphone manufacturer opinion mining sentiment analysis conducted first followed validation result using statistical analysis total tweet mentioning iphone galaxy collected four month following release iphone analyzed using natural language processing lexiconbased sentiment analysis purchase intention classification finding analysis showed social medium data contain competitive intelligence volume tweet revealed significant gap market leader one follower purchase intention data also reflected gap less pronounced extent addition author assessed whether social opinion could explain sale performance gap competitor found social opinion gap similar shipment gap research limitationsimplications study compared social medium opinion shipment gap two rival smart phone business take consumer opinion toward product also toward product competitor social medium analytics furthermore business predict market sale performance estimate gap competing product result decision maker adjust market strategy rapidly compensate weakness contrasting rival well originalityvalue paper main contribution demonstrat competitive intelligence via consumer opinion mining social medium data researcher business analyst practitioner adopt method social medium analysis achieve objective implement practical procedure data collection spam elimination machine learning classification sentiment analysis feature categorization result visualization', 'web data extraction important problem studied mean different scientific tool broad range application many approach extracting data web designed solve specific problem operate adhoc domain approach instead heavily reuse technique algorithm developed field information extraction survey aim providing structured comprehensive overview literature field web data extraction provided simple classification framework existing web data extraction application grouped two main class namely application enterprise level social web level enterprise level web data extraction technique emerge key tool perform data analysis business competitive intelligence system well business process reengineering social web level web data extraction technique allow gather large amount structured data continuously generated disseminated web social medium online social network user offer unprecedented opportunity analyze human behavior large scale discus also potential crossfertilization ie possibility reusing web data extraction technique originally designed work given domain domain c elsevier bv right reserved', 'consumer often consider multiple alternative product category prior making purchase uncovering predominant pattern coconsiderations help business learn competitive structure market mind consumer extant research shown various type online offline consumer activity data eg shopping basket search browsing history social medium mention used infer product coconsiderations paper study case uncovering coconsideration pattern using massive dataset online price quote request u auto shopper main challenge face privacy protection unique individual identifier anonymous otherwise contained data data deficiency prevents u using existing method affinity analysis inferring coconsiderations however leveraging spatiotemporal pattern data manage probabilistically uncover predominant pattern coconsiderations u auto market validation illustration usefulness embed inferred market structure sale response model show substantial improvement predictive performance c direct marketing educational foundation inc dba marketing edge right reserved', 'pressing need vehicle quality management professional decision support vehicle defect discovery classification process paper employ text mining popular social medium used vehicle enthusiast online discussion forum find sentiment analysis conventional technique consumer complaint detection insufficient finding categorizing prioritizing vehicle defect discussed online forum describe evaluate new process decision support system automotive defect identification prioritization finding provide managerial insight social medium analytics improve automotive quality management c elsevier bv right reserved']\n","2024-10-11 04:20:33,119 - INFO - 에폭 1/5, 손실: 701.6761\n","2024-10-11 04:20:33,127 - INFO - 에폭 2/5, 손실: 690.6332\n","2024-10-11 04:20:33,135 - INFO - 에폭 3/5, 손실: 680.8837\n","2024-10-11 04:20:33,143 - INFO - 에폭 4/5, 손실: 670.9563\n","2024-10-11 04:20:33,151 - INFO - 에폭 5/5, 손실: 660.8326\n","2024-10-11 04:20:33,169 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:33,180 - INFO - built Dictionary<2500 unique tokens: ['accessing', 'active', 'algorithm', 'analysis', 'analyze']...> from 80 documents (total 9904 corpus positions)\n","2024-10-11 04:20:33,181 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2500 unique tokens: ['accessing', 'active', 'algorithm', 'analysis', 'analyze']...> from 80 documents (total 9904 corpus positions)\", 'datetime': '2024-10-11T04:20:33.181074', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:33,341 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:33,342 - INFO - Sample of sampled data: ['organization develop manage employee data analytics skill create business value enhance organizational competitive advantage order address prominent critical research question research conceptualize operationalize data analytics skill individual level develop nomological network model examine critical antecedent outcome lens adaptation structuration theory test core proposition research model using survey data collected frontline employee three dataintensive research institute china discover datadriven culture data analytics affordance individual absorptive capacity positively associated employee data analytics skill turn positive influence task innovative performance classify employee digital immigrant digital native based age examine different influence three salient antecedent data analytics skill two group research finding suggest datadriven culture play significant role driving data analytics skill digital immigrant data analytics affordance exhibit stronger influence data analytics skill digital native', 'effect digital transition today knowledge creation process becoming relevant company operating different industry body literature examining impact fastly growing nevertheless systematizing existing study digital technology supporting firm knowledge creation process reconceptualise existing knowledge management model paradigm still challenge scenario seci model provide theoretical guidance achieve research objective indeed implementation digital technology firm redesigning way access manage knowledge therefore paper aim critically analyse literature impact digital transition knowledge creation providing novel structuring model model seek analyse role digital transition along innovative digital knowledge creation process identified webinarisation informalisation systematisation explication digitalisation according traditional epistemological ontological dimension integrating perspective author design wised model evaluate impact digital transition knowledgecreating company', 'since mids business topic received much attention big data business analytics including unstructured data derived social medium blog chat email message addition unstructured data youtube vimeo video source represent another aspect organization customer service ibm survey professional country industry identified big data business analytics major business trend organization along mobile cloud social business technology', 'starting engine must continually check dashboard optimize fuel consumption love research chapter explains critical term layman language avoid beginner mistake business analytics similar car dashboard need useful metric speed ambient temperature fuel consumption improve performance comprehensive metric empower u demonstrate social medium marketing word mouth wom social sharing help achieve corporate objective e g increase sale andor reduce cost x percent unless successfully link measure strategic objective management unlikely interested social medium outcome', 'opportunity gain insight social medium user generated data triggered interest many company see chance better understand customer preference identify trend however huge amount data always manageable identification influencers specific industry monitoring behaviour social medium could proved great importance towards direction reducing amount data analysis extracting useful targeted insight context paper aim present platform provide data analyst productservice designer influencer identification functionality per industry topic time also visualise correlation among influencers based specific topic interest platform evaluated use case fashion industry']\n","2024-10-11 04:20:33,360 - INFO - 에폭 1/5, 손실: 704.0749\n","2024-10-11 04:20:33,368 - INFO - 에폭 2/5, 손실: 690.3887\n","2024-10-11 04:20:33,376 - INFO - 에폭 3/5, 손실: 678.4029\n","2024-10-11 04:20:33,384 - INFO - 에폭 4/5, 손실: 667.4895\n","2024-10-11 04:20:33,391 - INFO - 에폭 5/5, 손실: 657.3895\n","2024-10-11 04:20:33,407 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:33,418 - INFO - built Dictionary<2503 unique tokens: ['absorptive', 'adaptation', 'address', 'advantage', 'affordance']...> from 80 documents (total 9831 corpus positions)\n","2024-10-11 04:20:33,419 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2503 unique tokens: ['absorptive', 'adaptation', 'address', 'advantage', 'affordance']...> from 80 documents (total 9831 corpus positions)\", 'datetime': '2024-10-11T04:20:33.419590', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:33,607 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:33,608 - INFO - Sample of sampled data: ['organization develop manage employee data analytics skill create business value enhance organizational competitive advantage order address prominent critical research question research conceptualize operationalize data analytics skill individual level develop nomological network model examine critical antecedent outcome lens adaptation structuration theory test core proposition research model using survey data collected frontline employee three dataintensive research institute china discover datadriven culture data analytics affordance individual absorptive capacity positively associated employee data analytics skill turn positive influence task innovative performance classify employee digital immigrant digital native based age examine different influence three salient antecedent data analytics skill two group research finding suggest datadriven culture play significant role driving data analytics skill digital immigrant data analytics affordance exhibit stronger influence data analytics skill digital native', 'study gathered data professional user information via survey twitter perceived service useful information reason one may expect content tweet give valuable information derived extracted information tweeted tweeted professional user aware tweet manipulated communication department adjust understanding content delivered reason fake news seen problem either professional twitter seen valuable alongside social medium software additional software solution used directly together software integrated software solution standalone service found less value experienced user sign twitter valuable tool learning', 'opportunity gain insight social medium user generated data triggered interest many company see chance better understand customer preference identify trend however huge amount data always manageable identification influencers specific industry monitoring behaviour social medium could proved great importance towards direction reducing amount data analysis extracting useful targeted insight context paper aim present platform provide data analyst productservice designer influencer identification functionality per industry topic time also visualise correlation among influencers based specific topic interest platform evaluated use case fashion industry', 'social medium emerged new communication channel consumer company generate large volume unstructured text data social medium content contains consumer opinion interest recognized valuable material business mine useful information consequently many researcher reported opinionmining framework method technique tool business intelligence various industry study sometimes focused use opinion mining business field emphasized method analyzing content achieve result accurate also considered visualize result ensure easier understanding however found approach often technically complex insufficiently userfriendly help business decision planning therefore study attempt formulate comprehensive practical methodology conduct social medium opinion mining apply methodology case study oldest instant noodle product korea also present graphical tool visualized output include volume sentiment graph timeseries graph topic word cloud heat map valence tree map classification resource publicdomain social medium content blog forum message news article analyze natural language processing statistic graphic package freeware r project environment believe methodology visualization output provide practical reliable guide immediate use food industry industry well', 'last decade social medium platform become important communication channel business consumer result lot consumergenerated data available online unfortunately fully utilized partly nature unstructured subjective exist massive database make use data one research method needed study proposes new multiple approach social medium data analysis counteracts aforementioned characteristic social medium data new approach data first extracted systematically coded following principle content analysis comprehensive literature review conducted guide coding strategy next relationship code identified statistical cluster analysis relationship used next step analysis evaluation criterion weight derived basis social medium data probability weighting function case study employed test proposed approach']\n","2024-10-11 04:20:33,626 - INFO - 에폭 1/5, 손실: 733.5777\n","2024-10-11 04:20:33,633 - INFO - 에폭 2/5, 손실: 718.2927\n","2024-10-11 04:20:33,641 - INFO - 에폭 3/5, 손실: 704.1260\n","2024-10-11 04:20:33,647 - INFO - 에폭 4/5, 손실: 690.0423\n","2024-10-11 04:20:33,654 - INFO - 에폭 5/5, 손실: 678.5677\n","2024-10-11 04:20:33,673 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:33,684 - INFO - built Dictionary<2574 unique tokens: ['absorptive', 'adaptation', 'address', 'advantage', 'affordance']...> from 80 documents (total 10224 corpus positions)\n","2024-10-11 04:20:33,685 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2574 unique tokens: ['absorptive', 'adaptation', 'address', 'advantage', 'affordance']...> from 80 documents (total 10224 corpus positions)\", 'datetime': '2024-10-11T04:20:33.685595', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:33,850 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:33,851 - INFO - Sample of sampled data: ['emergence web possible usergenerated content ugc social medium express opinion customer experience related service product customer review useful understand customer experience associated stay hotel considering different dimension associated hotel service accommodation business intelligence analytics increasingly considered amanagement strategy examine customer satisfaction hotel product service positioning compared economic sector however ugc difficult analyze compare rating fill gap business intelligence environment considered along text mining approach holistic decisionsupport system help decisionmaking strategic management hotel', 'social medium emerged new communication channel consumer company generate large volume unstructured text data social medium content contains consumer opinion interest recognized valuable material business mine useful information consequently many researcher reported opinionmining framework method technique tool business intelligence various industry study sometimes focused use opinion mining business field emphasized method analyzing content achieve result accurate also considered visualize result ensure easier understanding however found approach often technically complex insufficiently userfriendly help business decision planning therefore study attempt formulate comprehensive practical methodology conduct social medium opinion mining apply methodology case study oldest instant noodle product korea also present graphical tool visualized output include volume sentiment graph timeseries graph topic word cloud heat map valence tree map classification resource publicdomain social medium content blog forum message news article analyze natural language processing statistic graphic package freeware r project environment believe methodology visualization output provide practical reliable guide immediate use food industry industry well', 'study examines role social medium analytics sma providing competitive intelligence ci building ci theory data qualitative semistructured interview respondent belonging social medium manufacturing telecommunication service industry analyzed using nvivo coding matrix query result show sma provides expanded ci beyond previous limit customersmarkets competitor including insight supply chain cost informationflow moreover smadriven ci provide visibility supply chain uncertainty enabling improvement demand planning inventory management sma provide ci competitor strength weakness customer dynamic however bidirectional nature ci could determinantal smlinked customer educatedkept informed matrix query result illuminate differencessimilarities respondent view academically study show sma provides expanded ci business beyond previously known scope competitor analysis', 'demand realtime business intelligence popularity social medium offer room synthesis recent topic interest perspective cultural heritage empirically evidenced twitter introduction hashtag culturalheritage opportunity offered linking concept acknowledged recent scientific literature relative underexposure quantitative study devoted assess potential effectiveness social pulse activity supporting organization promoting cultural heritage recorded work data driven approach proposed basing effective employment domain specific general ontology aim identify set key performance indicator kpis quantitative estimation cultural heritage sensitivity expressed social network user quantitative analysis huge datasets tweet combining natural language processing nlp semantic technology georeferencing temporal analysis issued long period time geographical area italy different density ch resource performed example computed measure characterizing people interest sensitivity ch subject geographical density ch resource temporal proximity chrelated event obtained result encourage businessintelligence approach', 'use social medium business becoming new norm gaining business intelligence research work increasing social medium analytics sma aspect business intelligence knowledge sma facilitates product intelligence pi still limited address gap data qualitative interview analyzed using nvivo coding matrix query result show product process people underpin mechanism providing smaenabled pi serving dichotomous objective people act conduit providing insight product process subject gathering behavioral insight pi gathered product could help understanding process effectiveness used planning product promotional strategy development impulsive nature sm utility pi sma may limited gaining shorttomediumterm benefit important indicator customer market sentiment theoretically study develops framework smaenabled pi highlighting mechanism yield pi advancing knowledge role sma improving business efficiency result provide managerial insight lever limitation guide design sma strategy acquiring pi']\n","2024-10-11 04:20:33,873 - INFO - 에폭 1/5, 손실: 728.0629\n","2024-10-11 04:20:33,880 - INFO - 에폭 2/5, 손실: 714.3735\n","2024-10-11 04:20:33,887 - INFO - 에폭 3/5, 손실: 703.0958\n","2024-10-11 04:20:33,896 - INFO - 에폭 4/5, 손실: 691.9552\n","2024-10-11 04:20:33,902 - INFO - 에폭 5/5, 손실: 679.5468\n","2024-10-11 04:20:33,921 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:33,932 - INFO - built Dictionary<2456 unique tokens: ['accommodation', 'along', 'amanagement', 'analytics', 'analyze']...> from 80 documents (total 9923 corpus positions)\n","2024-10-11 04:20:33,933 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2456 unique tokens: ['accommodation', 'along', 'amanagement', 'analytics', 'analyze']...> from 80 documents (total 9923 corpus positions)\", 'datetime': '2024-10-11T04:20:33.933590', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:34,109 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:34,110 - INFO - Sample of sampled data: ['purpose paper aim propose knowledge management km framework leveraging big social medium data help interested organization integrate big data technology social medium km system store share leverage social medium data specifically research focus extracting valuable knowledge social medium contextually comparing social medium knowledge among competitor designmethodologyapproach case study conducted analyze nearly one million twitter message associated five large company retail industry costco walmart kmart kohl home depot extract generate new knowledge derive business decision big social medium data finding case study confirms proposed framework sensible useful term integrating big data technology social medium km cohesive way design km system process extracted knowledge presented visually variety way discover business intelligence originalityvalue practical guidance integrating big data social medium km scarce proposed framework pioneering effort using big data technology extract valuable knowledge social medium discover business intelligence contextually comparing social medium knowledge among competitor', 'web data extraction important problem studied mean different scientific tool broad range application many approach extracting data web designed solve specific problem operate adhoc domain approach instead heavily reuse technique algorithm developed field information extraction survey aim providing structured comprehensive overview literature field web data extraction provided simple classification framework existing web data extraction application grouped two main class namely application enterprise level social web level enterprise level web data extraction technique emerge key tool perform data analysis business competitive intelligence system well business process reengineering social web level web data extraction technique allow gather large amount structured data continuously generated disseminated web social medium online social network user offer unprecedented opportunity analyze human behavior large scale discus also potential crossfertilization ie possibility reusing web data extraction technique originally designed work given domain domain c elsevier bv right reserved', 'collection big data different source internet thing social medium search engine created significant opportunity businesstobusiness bb industrial marketing organization take analytical view developing programmatic marketing approach online display advertising cleansing processing analyzing large datasets create challenge marketing organization particularly realtime decision making comparative implication importantly limited research interplay utilizing problematization approach paper contributes exploration link big data programmatic marketing realtime processing relevant decision making bb industrial marketing organization depend big datadriven marketing big datasavvy manager exploration subsequently encompasses appropriate big data source effective batch realtime processing linked structured unstructured datasets influence relative processing technique consequently along direction future research paper develops interdisciplinary dialogue overlay computerengineering framework apache storm hadoop within bb marketing viewpoint implication contemporary marketing practice', 'main purpose social business intelligence help company making decision performing multidimensional analysis relevant information disseminated social network although data quality general issue sbi approach aimed assessing data collection context dependent task paper define quality indicator metric serf assess overall quality collection integrates measure obtained several quality criterion applied filter post relevant sbi project selection best quality criterion include quality indicator complex task requires deep understanding context objective analysis paper propose new methodology design quality indicator sbi project whose quality criterion consider content coherence data provenance thus context defined objective analysis methodology help user find quality criterion best suit user available data integrate valid quality indicator', 'demand realtime business intelligence popularity social medium offer room synthesis recent topic interest perspective cultural heritage empirically evidenced twitter introduction hashtag culturalheritage opportunity offered linking concept acknowledged recent scientific literature relative underexposure quantitative study devoted assess potential effectiveness social pulse activity supporting organization promoting cultural heritage recorded work data driven approach proposed basing effective employment domain specific general ontology aim identify set key performance indicator kpis quantitative estimation cultural heritage sensitivity expressed social network user quantitative analysis huge datasets tweet combining natural language processing nlp semantic technology georeferencing temporal analysis issued long period time geographical area italy different density ch resource performed example computed measure characterizing people interest sensitivity ch subject geographical density ch resource temporal proximity chrelated event obtained result encourage businessintelligence approach']\n","2024-10-11 04:20:34,129 - INFO - 에폭 1/5, 손실: 704.5196\n","2024-10-11 04:20:34,136 - INFO - 에폭 2/5, 손실: 693.6558\n","2024-10-11 04:20:34,142 - INFO - 에폭 3/5, 손실: 684.6801\n","2024-10-11 04:20:34,148 - INFO - 에폭 4/5, 손실: 674.0759\n","2024-10-11 04:20:34,154 - INFO - 에폭 5/5, 손실: 665.0120\n","2024-10-11 04:20:34,173 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:34,183 - INFO - built Dictionary<2517 unique tokens: ['aim', 'among', 'analyze', 'associated', 'big']...> from 80 documents (total 9772 corpus positions)\n","2024-10-11 04:20:34,184 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2517 unique tokens: ['aim', 'among', 'analyze', 'associated', 'big']...> from 80 documents (total 9772 corpus positions)\", 'datetime': '2024-10-11T04:20:34.184592', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:34,360 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:34,361 - INFO - Sample of sampled data: ['main purpose social business intelligence help company making decision performing multidimensional analysis relevant information disseminated social network although data quality general issue sbi approach aimed assessing data collection context dependent task paper define quality indicator metric serf assess overall quality collection integrates measure obtained several quality criterion applied filter post relevant sbi project selection best quality criterion include quality indicator complex task requires deep understanding context objective analysis paper propose new methodology design quality indicator sbi project whose quality criterion consider content coherence data provenance thus context defined objective analysis methodology help user find quality criterion best suit user available data integrate valid quality indicator', 'purpose recent year rise big data led obvious shift competence profile expected controller management accountant among others business analytics competence information technology skill considered must capability controlling profession still remains unclear requirement fulfilled today employee purpose study examine supply business analytics competence current competence profile controlling professional attempt answer question whether skill gap exists designmethodologyapproach based set member profile german controlling professional extracted business social network xing text analytics approach conducted discover pattern semistructured data second purpose study encourage researcher practitioner integrate advance big data analytics method inquiry research process finding apart mediating role gender company size variable result indicate current competence profile controller comply recent requirement towards business analytics competence however answer question whether skill gap exist must made cautiously taking account specific organizational context level adoption degree job specialization originalityvalue insight provided study extend ongoing debate accounting literature business medium skill change controlling profession big data era originality study lie explicit attempt integrate recent advance data analytics explore selfreported competence supply controlling professional based comprehensive set semistructured data theoretically founded explanatory model proposed integrates empirically validated finding extant research across various discipline', 'sentiment analysis emerged one prominent research branch endless usage application monitoring social medium forum blog online resource customer review product competition survey response understand customer insight significant importance business analytics proliferation informal user generated data online use mixed language become common phenomenon mixed language arises use linguistic code switching lcs practice using one language single sentence mixed language rarely subject sentiment analysis lack clear grammatical structure render previous approach sentiment analysis ineffective text paper propose strategy determine sentiment sentence written mixed language comprising hindi english lexicon technique used analyze sentiment data belonging one source language well mixed language data grammatical transition common mixed language taken account sentiment analysis demonstrate effectiveness proposed approach via case study social medium data set', 'order organisation remain competitive time ambiguity uncertainty need detect anticipate unknown unknown also called black swan ignored may lead competitive struggle paper build view suggest big data analytics provide necessary insight help change strategy making research suggests ambidextrous organisation focus developing maintaining dynamic capability following take dynamic capability perspective propose theoretical framework explain intricacy big data analytics framework explains ability organisation detect anticipate respond strategically ambiguous uncertain business environment metasynthesis case big data analytics employ multimethod approach incorporates natural language processing semantic analysis case analysis allowing extraction analysis structured information unstructured data overall find evidence big data analytics helping detect anticipate respond industry disruption offer six proposition relationship level data analytics capability strategic dynamic capability find descriptive data analytics improves capability organisation understand business context sensing predictive data analytics aid realisation business opportunity seizing study contributes understanding big data analytics dynamic organisational capability support strategic decisionmaking time ambiguity uncertainty conclude suggesting area investigation particularly regard strategic application prescriptive data analytics', 'evolvement social medium made important valuable part people daily life world many business use social medium different way benefit business advertise product service way strengthening relationship institute utilize social medium promote program course current prospective student advertise important event career fair interact various institute member provide date news information regarding wellbeing health security comfort satisfaction throughout work web mining opinion mining applied general business twitter account explore developing theme discussion amongst business online community account analysed text mining social network analysis sentiment analysis important monitor topic word trending high volume specific online twitter community objective try conclude sentiment post posted twitter account']\n","2024-10-11 04:20:34,380 - INFO - 에폭 1/5, 손실: 724.2880\n","2024-10-11 04:20:34,387 - INFO - 에폭 2/5, 손실: 711.9699\n","2024-10-11 04:20:34,395 - INFO - 에폭 3/5, 손실: 699.4260\n","2024-10-11 04:20:34,401 - INFO - 에폭 4/5, 손실: 688.2139\n","2024-10-11 04:20:34,409 - INFO - 에폭 5/5, 손실: 676.8949\n","2024-10-11 04:20:34,424 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:34,434 - INFO - built Dictionary<2540 unique tokens: ['aimed', 'although', 'analysis', 'applied', 'approach']...> from 80 documents (total 10100 corpus positions)\n","2024-10-11 04:20:34,435 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2540 unique tokens: ['aimed', 'although', 'analysis', 'applied', 'approach']...> from 80 documents (total 10100 corpus positions)\", 'datetime': '2024-10-11T04:20:34.435074', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:34,616 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:34,617 - INFO - Sample of sampled data: ['purpose purpose paper better understand management accounting automation exploring programmability management accounting work designmethodologyapproach build upon literature digitalization management accounting draw upon pragmatic constructivist methodology understand digitalization take place individual actor level accounting practice paper us data set interventionist case study machinery manufacturer finding examine actual process automating management accounting task development process surprisingly calculation task remained fit human machine though initially thought programmable research limitationsimplications according finding practitioner may interpret expert nonprogrammable work task programmable seek automate identifying factual possibility automating accountingrelated work lead automationimproved efficiency finding increasingly relevant advanced analytics initiative application within management accounting eg robotic process automation big data machine learning artificial intelligence practical implication practitioner need carefully analyze entity wish automate understand factual possibility using maintaining planned automatic system throughout life cycle originalityvalue paper show process assessed distance nonprogrammable management accounting task expertise become misinterpreted programmable goal automating little chance success also show possibility human accountant remain relevant comparison machine pave way study advanced decision technology management accounting', 'development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm', 'purpose purpose paper mine competitive intelligence social medium find market insight comparing consumer opinion sale performance business one competitor analyzing public social medium data designmethodologyapproach exploratory test using multiple case study approach used compare two competing smartphone manufacturer opinion mining sentiment analysis conducted first followed validation result using statistical analysis total tweet mentioning iphone galaxy collected four month following release iphone analyzed using natural language processing lexiconbased sentiment analysis purchase intention classification finding analysis showed social medium data contain competitive intelligence volume tweet revealed significant gap market leader one follower purchase intention data also reflected gap less pronounced extent addition author assessed whether social opinion could explain sale performance gap competitor found social opinion gap similar shipment gap research limitationsimplications study compared social medium opinion shipment gap two rival smart phone business take consumer opinion toward product also toward product competitor social medium analytics furthermore business predict market sale performance estimate gap competing product result decision maker adjust market strategy rapidly compensate weakness contrasting rival well originalityvalue paper main contribution demonstrat competitive intelligence via consumer opinion mining social medium data researcher business analyst practitioner adopt method social medium analysis achieve objective implement practical procedure data collection spam elimination machine learning classification sentiment analysis feature categorization result visualization', 'machine continually channelized current era automation deliver accurate interpretation people communicate social medium human specie today engulfed concept people believe decision made result mostly dependent sway mass social medium platform usage internet well social medium booming day day today ocean data used fruitful purpose analysis social medium sentiment textual post supply knowledge information used citizen opinion polling business intelligence social context internet thing iotmood triggered device manuscript main focus sentiment analysis based emotional recognition er proposed system highlight process gaining actual sentiment mood person key idea system posed fact smile laughter two different category happy happpyyyyyy happy novel lexicon based system proposed considers lengthened word instead omitted normalized aggregated intensified sentiscores lengthened word calculated using framed lexicon rule sentiscores lengthened word used calculate level sentiment person dataset used paper informal chat happened among different friend group facebook tweet personal chat performance proposed system compared traditional system ignore lengthened word proposed system outperform tradition system achieving fmeasure rate datasets', 'effect digital transition today knowledge creation process becoming relevant company operating different industry body literature examining impact fastly growing nevertheless systematizing existing study digital technology supporting firm knowledge creation process reconceptualise existing knowledge management model paradigm still challenge scenario seci model provide theoretical guidance achieve research objective indeed implementation digital technology firm redesigning way access manage knowledge therefore paper aim critically analyse literature impact digital transition knowledge creation providing novel structuring model model seek analyse role digital transition along innovative digital knowledge creation process identified webinarisation informalisation systematisation explication digitalisation according traditional epistemological ontological dimension integrating perspective author design wised model evaluate impact digital transition knowledgecreating company']\n","2024-10-11 04:20:34,638 - INFO - 에폭 1/5, 손실: 731.4866\n","2024-10-11 04:20:34,646 - INFO - 에폭 2/5, 손실: 720.6297\n","2024-10-11 04:20:34,654 - INFO - 에폭 3/5, 손실: 707.3405\n","2024-10-11 04:20:34,662 - INFO - 에폭 4/5, 손실: 697.7811\n","2024-10-11 04:20:34,668 - INFO - 에폭 5/5, 손실: 687.4388\n","2024-10-11 04:20:34,686 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:34,697 - INFO - built Dictionary<2580 unique tokens: ['according', 'accountant', 'accounting', 'actor', 'actual']...> from 80 documents (total 10078 corpus positions)\n","2024-10-11 04:20:34,698 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2580 unique tokens: ['according', 'accountant', 'accounting', 'actor', 'actual']...> from 80 documents (total 10078 corpus positions)\", 'datetime': '2024-10-11T04:20:34.698590', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:34,873 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:34,874 - INFO - Sample of sampled data: ['starting engine must continually check dashboard optimize fuel consumption love research chapter explains critical term layman language avoid beginner mistake business analytics similar car dashboard need useful metric speed ambient temperature fuel consumption improve performance comprehensive metric empower u demonstrate social medium marketing word mouth wom social sharing help achieve corporate objective e g increase sale andor reduce cost x percent unless successfully link measure strategic objective management unlikely interested social medium outcome', 'social medium data become invaluable component business analytics multitude nuance social medium text make job conventional text analytical tool difficult codemixing text phenomenon prevalent among social medium user wherein word used borrowed multiple language though written commonly understood roman script existing supervised learning method task part speech po tagging codemixed social medium cmsm text typically depend large amount training data preparation large training data resourceintensive requiring expertise multiple language though preparation small dataset possible vocabulary oov word pose major difficulty learning model cmsm text number different way writing nonnative word roman script huge po tagging codemixed text nontrivial tagging deal syntactic rule multiple language important research question addressed article whether abundantly available unlabeled data help resolving difficulty posed codemixed text po tagging develop approach scraping building word embeddings codemixed text illustrating bengalienglish hindienglish teluguenglish codemixing scenario used hierarchical deep recurrent neural network linearchain crf layer top improve performance po tagging cmsm text capturing contextual word feature charactersequencebased information prepared labeled resource po tagging cmsm text correcting label existing resource detailed analysis performance approach varying level codemixing provided result indicate fscore approach custom embeddings better crfbased baseline bengali hindi telugu language respectively', 'study examines role social medium analytics sma providing competitive intelligence ci building ci theory data qualitative semistructured interview respondent belonging social medium manufacturing telecommunication service industry analyzed using nvivo coding matrix query result show sma provides expanded ci beyond previous limit customersmarkets competitor including insight supply chain cost informationflow moreover smadriven ci provide visibility supply chain uncertainty enabling improvement demand planning inventory management sma provide ci competitor strength weakness customer dynamic however bidirectional nature ci could determinantal smlinked customer educatedkept informed matrix query result illuminate differencessimilarities respondent view academically study show sma provides expanded ci business beyond previously known scope competitor analysis', 'study analyzes twitter contribution green energy global tweet sent containing term green energy greenenergy analyzed tweet captured web scraping processed using algorithm technique analysis massive datasets social network particular relationship user mention determined according louvain multilevel algorithm identify community analyze global density centralization nodelevel centrality metric subsequently content conversation subject semantic analysis cooccurrence relevant word hashtag analysis frequency analysis sentiment analysis using vader model result reveal nine main community leader well three main topic conversation emotional state digital discussion main community revolve around politics socioeconomic issue environmental activism conversation developed mostly positive term focus green energy source storage aligned main community identified ie political socioeconomic climate change issue although conversation socioeconomic issue presence leading company account minor main aim work take first step toward innovative competitive intelligence methodology study determine trend within different scientific field technology society enable strategic decision made', 'though full promise big data research success often contingent access newest advanced often expensive hardware system expertise needed build implement system result accessibility growing number big datacapable technology solution often preserve business analytics pay storeprocess service like amazon web service opened possibility smaller scale big data project high demand type research digital humanity digital sociology example however scholar increasingly finding disadvantage available data set interest continue grow size complexity without large amount funding ability form interdisciplinary partnership select find position successfully engage big data article identifies several notable popular big data technology typically implemented using large extremely powerful cloudbased system investigates feasibility utility development big data analytics system implemented using lowcost commodity hardware basic easily maintainable configuration use within academic social research investigation experimental case study growing field social twitter analytics found solution like clouderas hadoop feasible also enable robust deep fruitful research outcome variety usecase scenario across discipline']\n","2024-10-11 04:20:34,893 - INFO - 에폭 1/5, 손실: 706.4682\n","2024-10-11 04:20:34,900 - INFO - 에폭 2/5, 손실: 694.4858\n","2024-10-11 04:20:34,908 - INFO - 에폭 3/5, 손실: 684.0293\n","2024-10-11 04:20:34,916 - INFO - 에폭 4/5, 손실: 675.2175\n","2024-10-11 04:20:34,923 - INFO - 에폭 5/5, 손실: 662.9050\n","2024-10-11 04:20:34,937 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:34,948 - INFO - built Dictionary<2512 unique tokens: ['achieve', 'ambient', 'analytics', 'andor', 'avoid']...> from 80 documents (total 9885 corpus positions)\n","2024-10-11 04:20:34,949 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2512 unique tokens: ['achieve', 'ambient', 'analytics', 'andor', 'avoid']...> from 80 documents (total 9885 corpus positions)\", 'datetime': '2024-10-11T04:20:34.949587', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:35,127 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:35,128 - INFO - Sample of sampled data: ['increasing use digital technology significantly reshaped marketing consumer behavior cb online community cuttingedge innovation artificial intelligence ai disrupt advance consumer attitude specific product service online community supported ai technology creating new knowledge consumer interaction platform like social medium consumer share experience specific product service since ai designed learn improve data generated digital technology linked consumer interaction ai relies consumer knowledgesharing k activity replicate new knowledge product service improvement however given knowledge gap area article applies fsqca technique data generated participant develop cb metaframework predicted concept ai cb k result suggest ai advance consumer attitude behavior knowledge acquired online community promote curiosity engage consumer learn sharing experience specific product service furthermore understanding causality ai cb k concept offer critical decisionmaking insight marketing expert across industry', 'era information overload text clustering play important part analysis processing pipeline partitioning highquality text unseen category tremendously help application information retrieval database business intelligence domain short text social medium environment tweet however remain difficult interpret due broad aspect context traditional text similarity approach rely lexical matching ignoring semantic meaning word recent advance distributional semantic space opened alternative approach utilizing highquality word embeddings aid interpretation text semantics paper investigate word mover distance metric automatically cluster short text using word semantic information utilize agglomerative strategy clustering method efficiently group text based similarity experiment indicates word mover distance outperformed standard metric short text clustering task', 'customer loyalty significantly evolved last decade specifically social medium platform marketer engage customer regularly omnichannel approach allows brand interact customer whether persontoperson persontocommunity customer loyalty characterised literature psychological process whereby customer loyalty attache towards specific service brand time customer loyalty contributes consumer behaviour preference specific brand service therefore company consider formulating developing appropriate business intelligence strategy drive customer towards loyalty increase engagement brand furthermore psychological shopper behaviour might expand improve current research towards customer perspective distinguishing customer incentivised brand activity venture suggesting customer loyalty customer judgement business notable positive impact brand identify business centre attention attraction brand understand identify best loyalty strategy target customer business must use opportunity enable brand develop new innovative approach approach continuously drive brand loyalty sale creating competitive advantage market customer loyalty become strategy business marketing empowers consumer engaged throughout initial interaction purchase journey become loyal brand engagement journey help brand establish grow due continuous support consumer general aim study determine nature relationship customer engagement factor brand loyalty study identified five customer engagement factor literature brand reputation social medium wordofmouth customer experience merchandising view investigating role brand loyalty noteworthy factor welldocumented precovid environment question remains however whether factor still valid reliable covid business environment study aim determine response precisely question quantitative research design selfdeveloped questionnaire used measure one factor fivepoint likert scale factor respective measuring criterion validated empirically using exploratory factor analysis social medium platform instagram used initiate snowball sample total social medium participant responded completing online google form questionnaire respondent profile show brand social medium page preferred method brand communication followed email sm telephonic communication method latter fact clearly disliked found respondent prefer email followed sm social medium platform receive brand communication however communication via telephone conversation disliked consumer respondent find brand advertisement memorable seen different platform channel communication memorable channel social medium recall rate total participant first read review new product launched find way wordofmouth brand community make informed discussion purchasing product listening consumer share review platform data reliable alpha ge sample deemed adequate kmo ge multiple regression analysis used determine relationship customer engagement factor brand loyalty result indicated significant p le positive relationship factor brand reputation r p le social medium r p le wordofmouth r p le visibility r p le model explains satisfactory cumulative variance r factor customer experience however reconsidered antecedent significantly influence consumer loyalty brand exploratory factor analysis used determine whether factor determine brand loyalty eight factor identified explaining variance cumulatively factor visibility merchandise brand reputation brand trust brand reference outside shop advice inside shop brand ambassador purchase experience personal choice eight new factor make sense factor manage brand loyalty management rather focus factor concentrate initial five factor indicated literature possible area future research investigate age demographic area regard participant could viewed opinion centralised focus towards different age group generation gen z millennials gen x boomer silent generation also investigated compare illustrate engagement strategy influential towards brand loyalty', 'social revolution promotes use mass collaboration principle tool every organization factory excluded social medium advance book author consultant tooting benefit business intelligence cloud computing even web interface used manufacturing department however swot analysis threat weakness study aim discovering could go bad social revolution enabled factory productionwise try prove two could used together promote cautious approach subject c author published elsevier ltd', 'development information technology increase mean facility accessing internet number user popular social network started increase rapidly twitter requested microblog site million active user twitter user instantly express idea emotion reaction tweet scalable data microblog site fast effective response obtained used political social economic area possible analyze characteristic trend behavior user revealing interaction recent year especially emotional analysis user become popular analyzing character effect trend user twitter business intelligence application developed individual social strategy created study twitter profile turkey presidential election candidate examined profile measured physical emotional metric density reciprocity centralization modularity polarity subjectivity user profile confidence level social authority index determined relation revealed examining metric effect social medium usage habit user follower examined social medium performance measured candidate tweet follower analysis confidence index related week time series extracted using hierarchical classification algorithm']\n","2024-10-11 04:20:35,146 - INFO - 에폭 1/5, 손실: 706.0624\n","2024-10-11 04:20:35,152 - INFO - 에폭 2/5, 손실: 694.1493\n","2024-10-11 04:20:35,160 - INFO - 에폭 3/5, 손실: 682.3561\n","2024-10-11 04:20:35,167 - INFO - 에폭 4/5, 손실: 672.2852\n","2024-10-11 04:20:35,175 - INFO - 에폭 5/5, 손실: 660.0691\n","2024-10-11 04:20:35,190 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:35,200 - INFO - built Dictionary<2437 unique tokens: ['acquired', 'across', 'activity', 'advance', 'ai']...> from 80 documents (total 9667 corpus positions)\n","2024-10-11 04:20:35,201 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2437 unique tokens: ['acquired', 'across', 'activity', 'advance', 'ai']...> from 80 documents (total 9667 corpus positions)\", 'datetime': '2024-10-11T04:20:35.201588', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:35,392 - INFO - Analyzing stability for domain: media\n","2024-10-11 04:20:35,393 - INFO - Original data type: <class 'list'>\n","2024-10-11 04:20:35,394 - INFO - Processed data type: <class 'list'>\n","2024-10-11 04:20:35,395 - INFO - Sample of processed data: ['short ageappropriate theyre loose fitting cal rolled left end knee fabric soft color fun', 'thought top looked adorable material soft top like dont usually look great someone little bit busty make look fat like youre wearing maternity real issue arm hole large seemed gape bit didnt look flattering even wore cute lacy bandeau bra way material stick around arm hole would still look awkward bad since cute top well made', 'sweater nice addition fall spring wardrobe must layered sheer read review snagging issue yet', 'loved got flattering fit slightly loose body flowy nice weight fabric comfortable fabric perfect scoop neck doesnt show much cleavage washed delicate line dried shirt came riddled hole', 'worried skirt might look much like bedspread gorgeous cut flattering ordered petite small fit perfectly great fallwinter skirt']\n","2024-10-11 04:20:35,399 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:35,399 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:39,551 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:39,551 - INFO - Sample of sampled data: ['bought lovely silkvelvet shirt quotskyquot color teal blue side sky blue disappointed definitely darker appears photo still luxurious wellmade beauty sassy appeal drape like snake slithering body come attitude', 'come scoop basically ever elevenses jumpsuit release perfection always perfect fit quality fabric im taller side found fit perfectly yet somehow look equally perfect shorter lady saw dressing room awesome', 'wore suit first time yesterday black inner lining leaking causing stain white section seriously bummed super lovely suit', 'top girlnextdoor sweet im mad plaid love first sight love blouse touch spandex like fitted look tight loose spandex give bit yield size regular fit well im b waist hip hem fall mid hip sleeve fall pas wrist plan wear top tucked sleeve rolled since weather warmer color honey versatile blue motif', 'retailer defense silk chiffon general super fragile got top turquoise color design beautiful im lb took x fit true size im able wear nude strapless bra top look great worn top couple time end day snag able pull thread back inside top never ever cut silk chiffon love top much bought second one color size back un']\n","2024-10-11 04:20:39,556 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:39,556 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:43,568 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:43,573 - INFO - built Dictionary<840 unique tokens: ['appeal', 'appears', 'attitude', 'beauty', 'blue']...> from 80 documents (total 2304 corpus positions)\n","2024-10-11 04:20:43,573 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<840 unique tokens: ['appeal', 'appears', 'attitude', 'beauty', 'blue']...> from 80 documents (total 2304 corpus positions)\", 'datetime': '2024-10-11T04:20:43.573328', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:43,719 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:43,720 - INFO - Sample of sampled data: ['like people wanted beautiful dress fit decided see maybe maybe negative review wrong werent sort breast top probably wont fit properly imagine narrow upper torso like possibly might find top part dress close properly c could get size button waist hit strange spot despite picture showing narrow waist grad', 'great addition wardrobe go nice trouser dressier shoe work jean trainer casual look didnt find run small indeed thought fit id expect', 'hoping find slimming cozy sweater unfortunately one baggy material really bulky one occasion would never purchased person online cant quite tell style fit returned item', 'bought celebrate birthday get new suit every year milestone birthday dress disappoint', 'agree othersthis type sweater hooked retailer ten year ago love new sweater recommend wearing long sleeve tee underneath sleeve itchy']\n","2024-10-11 04:20:43,725 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:43,726 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:47,627 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:47,632 - INFO - built Dictionary<882 unique tokens: ['beautiful', 'breast', 'button', 'close', 'could']...> from 80 documents (total 2312 corpus positions)\n","2024-10-11 04:20:47,632 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<882 unique tokens: ['beautiful', 'breast', 'button', 'close', 'could']...> from 80 documents (total 2312 corpus positions)\", 'datetime': '2024-10-11T04:20:47.632095', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:47,642 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:47,642 - INFO - Sample of sampled data: ['short ageappropriate theyre loose fitting cal rolled left end knee fabric soft color fun', 'great cut fit length perfect like weight skirt overall good season', 'thank goodness nice white basic tee see go back forth x depending want item fit dont like thing form fitting still little postbaby pooch went shirt work well complaint neckline totally straight seam come arm hit neckline bump little bit great nicer basic go well almost', 'im lb buying clothes retailer always stuggle petite frame dont fall petite height range usually order petite size deal shorter length hard youre limb purchased r im love fit top dress fit arm perfectly waist dress also hit nicely usually waist regular sized dress fall natural waistline due short', 'pant really pretty color feel nice fit great really shrink washing received lot compliment first time wore']\n","2024-10-11 04:20:47,647 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:47,647 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:51,991 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:51,996 - INFO - built Dictionary<857 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 80 documents (total 2350 corpus positions)\n","2024-10-11 04:20:51,996 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<857 unique tokens: ['ageappropriate', 'cal', 'color', 'end', 'fabric']...> from 80 documents (total 2350 corpus positions)\", 'datetime': '2024-10-11T04:20:51.996736', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:52,126 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:52,127 - INFO - Sample of sampled data: ['lightweight cardigan looked like eggplant color online brown hint burgandy bad unexpected short waisted lie high torso seam unfinished look cheaply made glad got sale', 'loved dress ordered online found color bit muted expected unfortunately fabric quality seemed low considering price point ultimately decided return couldnt justify spending dress didnt seem well made would expect retailer', 'ordered p yellow yellow rich golden yellow easter yellow see monitor hoping itd im keeping fit perfectly chesty size ddd somehow dont look bigger top also broad shoulder doesnt feel tight move arm bonus loop keep bra strap place dock star though quite fabric thread trim f', 'agree othersthis type sweater hooked retailer ten year ago love new sweater recommend wearing long sleeve tee underneath sleeve itchy', 'dress thick cotton material like sweatshirt hoping wear wedding tunic best bell part sleeve also stick awkwardly fabric']\n","2024-10-11 04:20:52,131 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:52,132 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:20:56,093 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:20:56,098 - INFO - built Dictionary<878 unique tokens: ['bad', 'brown', 'burgandy', 'cardigan', 'cheaply']...> from 80 documents (total 2355 corpus positions)\n","2024-10-11 04:20:56,098 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<878 unique tokens: ['bad', 'brown', 'burgandy', 'cardigan', 'cheaply']...> from 80 documents (total 2355 corpus positions)\", 'datetime': '2024-10-11T04:20:56.098811', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:20:56,218 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:20:56,219 - INFO - Sample of sampled data: ['agree othersthis type sweater hooked retailer ten year ago love new sweater recommend wearing long sleeve tee underneath sleeve itchy', 'reason everyone giving dress star stunning flattering versatile comfortable im slim athletic size store one medium im generally small hanger look like slim tube thought id try fit fabulous due stretch shape dress id say size medium could fit dont worry sizing one dress suuuuuper stretchy even though fit close throu', 'color top amazingmuch vibrant photo fit perfect flirty pretty detailing around top gorgeous pricey splurged glad look adorable corduroy skirt boot fall', 'loved dress ordered online found color bit muted expected unfortunately fabric quality seemed low considering price point ultimately decided return couldnt justify spending dress didnt seem well made would expect retailer', 'cute comfy dont throw leg like model mostly read skirt leg full really comfortable pair well surprising number top']\n","2024-10-11 04:20:56,223 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:20:56,224 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:00,308 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:00,313 - INFO - built Dictionary<891 unique tokens: ['ago', 'agree', 'hooked', 'itchy', 'long']...> from 80 documents (total 2466 corpus positions)\n","2024-10-11 04:21:00,313 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<891 unique tokens: ['ago', 'agree', 'hooked', 'itchy', 'long']...> from 80 documents (total 2466 corpus positions)\", 'datetime': '2024-10-11T04:21:00.313646', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:00,323 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:00,323 - INFO - Sample of sampled data: ['loved dress ordered online found color bit muted expected unfortunately fabric quality seemed low considering price point ultimately decided return couldnt justify spending dress didnt seem well made would expect retailer', 'sweater nice addition fall spring wardrobe must layered sheer read review snagging issue yet', 'overall constructioncraftmanship skirt poor dot sewn seam dot didnt lay flat side seam looked like dot missing around top part skirt back disappointed quality retailer last order similar complaint item sad', 'even shortwaisted lb body super short also super boxy flattering blue good color going back', 'large cup size year year search perfect suit support doesnt look matronly year baby wanted move one piece still wanted feel sexy youthful thought way suit going look good andor support ff gave try star review tried husband said wow suit hug right place actually support dont know doe']\n","2024-10-11 04:21:00,328 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:00,328 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:04,890 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:04,894 - INFO - built Dictionary<853 unique tokens: ['bit', 'color', 'considering', 'couldnt', 'decided']...> from 80 documents (total 2332 corpus positions)\n","2024-10-11 04:21:04,895 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<853 unique tokens: ['bit', 'color', 'considering', 'couldnt', 'decided']...> from 80 documents (total 2332 corpus positions)\", 'datetime': '2024-10-11T04:21:04.895509', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:04,905 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:04,906 - INFO - Sample of sampled data: ['cute short great fabric lined lay smooth body really love material dressier feel ran bit large looked sort frumpy curvy body im returning trying small elastic waist great baby would look fine belt covered shirt', 'purchased tank interesting open neck realizing strap elastic love material super soft fit nicely snug tight strap wide enough cover bra strap neckline little wider really flattering got black one going get color great buy', 'lightweight cardigan looked like eggplant color online brown hint burgandy bad unexpected short waisted lie high torso seam unfinished look cheaply made glad got sale', 'hoping find slimming cozy sweater unfortunately one baggy material really bulky one occasion would never purchased person online cant quite tell style fit returned item', 'short ageappropriate theyre loose fitting cal rolled left end knee fabric soft color fun']\n","2024-10-11 04:21:04,911 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:04,911 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:09,048 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:09,053 - INFO - built Dictionary<872 unique tokens: ['baby', 'belt', 'bit', 'body', 'covered']...> from 80 documents (total 2358 corpus positions)\n","2024-10-11 04:21:09,054 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<872 unique tokens: ['baby', 'belt', 'bit', 'body', 'covered']...> from 80 documents (total 2358 corpus positions)\", 'datetime': '2024-10-11T04:21:09.054294', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:09,178 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:09,179 - INFO - Sample of sampled data: ['product better pic nice fit nice throw boot nap glad took chance one', 'great addition wardrobe go nice trouser dressier shoe work jean trainer casual look didnt find run small indeed thought fit id expect', 'shirt awful anything pretty there reason main photo model arm crossed waist run good top get body garment run straight yet pleat even make manage expand little get lovely detailed hem rein left bit poof effect making rounder wrong way one im lazy send back awful', 'bought lovely silkvelvet shirt quotskyquot color teal blue side sky blue disappointed definitely darker appears photo still luxurious wellmade beauty sassy appeal drape like snake slithering body come attitude', 'burgundy plaid color caught eye perfect fall season usually like shoulder top stay one others stated arm stay inside help stayed usual small keep length fine got compliment first time wore glad restocked size sold']\n","2024-10-11 04:21:09,183 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:09,184 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:13,267 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:13,271 - INFO - built Dictionary<882 unique tokens: ['better', 'boot', 'chance', 'fit', 'glad']...> from 80 documents (total 2399 corpus positions)\n","2024-10-11 04:21:13,272 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<882 unique tokens: ['better', 'boot', 'chance', 'fit', 'glad']...> from 80 documents (total 2399 corpus positions)\", 'datetime': '2024-10-11T04:21:13.272683', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:13,282 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:13,283 - INFO - Sample of sampled data: ['worn top multiple time jean neckline make even u small busted look great top', 'bought suit similar last year loved year bought pineapple print beautiful size classysexy long torso like cover better one piece swim suit try highly recommend product', 'dress made lightweight linen lined separate slip high quality nice detail tt sleeve average length length dress feel appropriate frame hookandeye closure chest area keep button aligned quality detail think lovely dress go work play', 'bought celebrate birthday get new suit every year milestone birthday dress disappoint', 'really cute fabric little stiff detail nice waist seems big suggest sizing bought p usual size sent back p waist big']\n","2024-10-11 04:21:13,288 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:13,289 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:17,404 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:17,409 - INFO - built Dictionary<878 unique tokens: ['busted', 'even', 'great', 'jean', 'look']...> from 80 documents (total 2350 corpus positions)\n","2024-10-11 04:21:17,409 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<878 unique tokens: ['busted', 'even', 'great', 'jean', 'look']...> from 80 documents (total 2350 corpus positions)\", 'datetime': '2024-10-11T04:21:17.409369', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:17,419 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:17,419 - INFO - Sample of sampled data: ['thank goodness nice white basic tee see go back forth x depending want item fit dont like thing form fitting still little postbaby pooch went shirt work well complaint neckline totally straight seam come arm hit neckline bump little bit great nicer basic go well almost', 'worried skirt might look much like bedspread gorgeous cut flattering ordered petite small fit perfectly great fallwinter skirt', 'large cup size year year search perfect suit support doesnt look matronly year baby wanted move one piece still wanted feel sexy youthful thought way suit going look good andor support ff gave try star review tried husband said wow suit hug right place actually support dont know doe', 'absolutely lovely dress gorgeous color drape well perfect blend pretty sexy much beautiful person', 'thought blouse ran bit largeswinging wide hip bunch bust area larger correct undergarment fixed problem ddd thought size perfect']\n","2024-10-11 04:21:17,426 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:17,427 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:21,895 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:21,899 - INFO - built Dictionary<874 unique tokens: ['almost', 'arm', 'back', 'basic', 'bit']...> from 80 documents (total 2348 corpus positions)\n","2024-10-11 04:21:21,900 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<874 unique tokens: ['almost', 'arm', 'back', 'basic', 'bit']...> from 80 documents (total 2348 corpus positions)\", 'datetime': '2024-10-11T04:21:21.900175', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:21,908 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:21,909 - INFO - Sample of sampled data: ['wasnt sure jacket got mail seemed little boxy maybe smaller size wouldve worked better want able layer however im keeping versatile love contrast frontback button sleeve actually button unbutton meaning arent show sleeve easily rolled great basic jacket neat detail', 'coat cool cut classic well fit ive wearing jacket every day since purchasing day ago already begun slightly pill worn jacket pilling quickly basic wear', 'ordered whim discount upon sale price bit worried looked like burlap sack initially trying tank legging decided keeper quite soft flattering usually wear medium got ml fit well', 'bought lovely silkvelvet shirt quotskyquot color teal blue side sky blue disappointed definitely darker appears photo still luxurious wellmade beauty sassy appeal drape like snake slithering body come attitude', 'love shirt although see tank work great wear work button back sewn really well come far enough short pound tight neck kept otherwise would fit fine since blousy shirt would tight shoulder armpit']\n","2024-10-11 04:21:21,933 - INFO - 에폭 1/5, 손실: 216.4920\n","2024-10-11 04:21:21,941 - INFO - 에폭 2/5, 손실: 211.9822\n","2024-10-11 04:21:21,948 - INFO - 에폭 3/5, 손실: 208.2045\n","2024-10-11 04:21:21,955 - INFO - 에폭 4/5, 손실: 203.9903\n","2024-10-11 04:21:21,962 - INFO - 에폭 5/5, 손실: 199.4796\n","2024-10-11 04:21:21,968 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:21,972 - INFO - built Dictionary<860 unique tokens: ['able', 'actually', 'arent', 'basic', 'better']...> from 80 documents (total 2333 corpus positions)\n","2024-10-11 04:21:21,973 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<860 unique tokens: ['able', 'actually', 'arent', 'basic', 'better']...> from 80 documents (total 2333 corpus positions)\", 'datetime': '2024-10-11T04:21:21.973303', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,040 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,041 - INFO - Sample of sampled data: ['super soft comfortable great throw run errand ease still looking stylish lace front make special standard tee shirt dress', 'im love dress first tried petite size store dont enormous shoulder think petite would fit someone range im trying say dress pretty long cut beautiful pattern perfectly complementary ive reading marie kondos book one spark joy', 'agree othersthis type sweater hooked retailer ten year ago love new sweater recommend wearing long sleeve tee underneath sleeve itchy', 'like people wanted beautiful dress fit decided see maybe maybe negative review wrong werent sort breast top probably wont fit properly imagine narrow upper torso like possibly might find top part dress close properly c could get size button waist hit strange spot despite picture showing narrow waist grad', 'color top amazingmuch vibrant photo fit perfect flirty pretty detailing around top gorgeous pricey splurged glad look adorable corduroy skirt boot fall']\n","2024-10-11 04:21:22,055 - INFO - 에폭 1/5, 손실: 221.3337\n","2024-10-11 04:21:22,060 - INFO - 에폭 2/5, 손실: 215.7775\n","2024-10-11 04:21:22,066 - INFO - 에폭 3/5, 손실: 211.9479\n","2024-10-11 04:21:22,072 - INFO - 에폭 4/5, 손실: 207.6933\n","2024-10-11 04:21:22,078 - INFO - 에폭 5/5, 손실: 202.6821\n","2024-10-11 04:21:22,082 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,087 - INFO - built Dictionary<878 unique tokens: ['comfortable', 'dress', 'ease', 'errand', 'front']...> from 80 documents (total 2404 corpus positions)\n","2024-10-11 04:21:22,088 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<878 unique tokens: ['comfortable', 'dress', 'ease', 'errand', 'front']...> from 80 documents (total 2404 corpus positions)\", 'datetime': '2024-10-11T04:21:22.088069', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,152 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,153 - INFO - Sample of sampled data: ['know youre shopping dont buy something like later cant stop thinking case sweater saw paired cute top store tried whim im glad eventually got toasty soft thick perfect amount quirk', 'great addition wardrobe go nice trouser dressier shoe work jean trainer casual look didnt find run small indeed thought fit id expect', 'really cute fabric little stiff detail nice waist seems big suggest sizing bought p usual size sent back p waist big', 'thought blouse ran bit largeswinging wide hip bunch bust area larger correct undergarment fixed problem ddd thought size perfect', 'thank goodness nice white basic tee see go back forth x depending want item fit dont like thing form fitting still little postbaby pooch went shirt work well complaint neckline totally straight seam come arm hit neckline bump little bit great nicer basic go well almost']\n","2024-10-11 04:21:22,166 - INFO - 에폭 1/5, 손실: 210.6244\n","2024-10-11 04:21:22,171 - INFO - 에폭 2/5, 손실: 206.2861\n","2024-10-11 04:21:22,177 - INFO - 에폭 3/5, 손실: 202.2476\n","2024-10-11 04:21:22,183 - INFO - 에폭 4/5, 손실: 197.9554\n","2024-10-11 04:21:22,189 - INFO - 에폭 5/5, 손실: 194.3521\n","2024-10-11 04:21:22,194 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,197 - INFO - built Dictionary<858 unique tokens: ['amount', 'buy', 'cant', 'case', 'cute']...> from 80 documents (total 2316 corpus positions)\n","2024-10-11 04:21:22,198 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<858 unique tokens: ['amount', 'buy', 'cant', 'case', 'cute']...> from 80 documents (total 2316 corpus positions)\", 'datetime': '2024-10-11T04:21:22.198399', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,267 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,268 - INFO - Sample of sampled data: ['thank goodness nice white basic tee see go back forth x depending want item fit dont like thing form fitting still little postbaby pooch went shirt work well complaint neckline totally straight seam come arm hit neckline bump little bit great nicer basic go well almost', 'lightweight cardigan looked like eggplant color online brown hint burgandy bad unexpected short waisted lie high torso seam unfinished look cheaply made glad got sale', 'dress stunning quality impeccable craftsmanship stunning ordered typical size snug sizing would worked may beautiful high quality piece ive ever seen retailer', 'drew shirt beautiful silver gold embroidery front shirt folded store make sense hung fewer people would try shirt sheer front sheer back bug many clothes made day cheaply made thin cloth forced layer camisole something else order wear public cant wear sheer clothes', 'shirt awful anything pretty there reason main photo model arm crossed waist run good top get body garment run straight yet pleat even make manage expand little get lovely detailed hem rein left bit poof effect making rounder wrong way one im lazy send back awful']\n","2024-10-11 04:21:22,279 - INFO - 에폭 1/5, 손실: 211.8159\n","2024-10-11 04:21:22,286 - INFO - 에폭 2/5, 손실: 208.5107\n","2024-10-11 04:21:22,293 - INFO - 에폭 3/5, 손실: 205.1101\n","2024-10-11 04:21:22,299 - INFO - 에폭 4/5, 손실: 201.9848\n","2024-10-11 04:21:22,305 - INFO - 에폭 5/5, 손실: 198.6162\n","2024-10-11 04:21:22,311 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,314 - INFO - built Dictionary<897 unique tokens: ['almost', 'arm', 'back', 'basic', 'bit']...> from 80 documents (total 2409 corpus positions)\n","2024-10-11 04:21:22,315 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<897 unique tokens: ['almost', 'arm', 'back', 'basic', 'bit']...> from 80 documents (total 2409 corpus positions)\", 'datetime': '2024-10-11T04:21:22.315216', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,382 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,383 - INFO - Sample of sampled data: ['love top beautiful soft fabric much prettier picture worn shoulder extremely flattering fall perfect length great short pant long skirt', 'normally wear small sometimes medium even extra small feel large length gorgeous though', 'cut boxy side im sold tiered effect love silk fabric print much dont care silk deliciously light breathable print neutral enough pair several different cardigan necklace mix quality construction excellentall seam expertly sewn pressed print lined like online picture given material construction quality de', 'dress nice flow simple versatile pair jacket cardigan winter use year round however run one size large', 'sweater little bit let ordered pink actually tan sweater bright coral material woven throughout wasnt soft pinkcoral color appeared online material cozy sweater short boxy wouldve like width better length wouldve little proportionate ordered petite small probably returning']\n","2024-10-11 04:21:22,397 - INFO - 에폭 1/5, 손실: 205.7717\n","2024-10-11 04:21:22,402 - INFO - 에폭 2/5, 손실: 203.2557\n","2024-10-11 04:21:22,408 - INFO - 에폭 3/5, 손실: 200.3537\n","2024-10-11 04:21:22,414 - INFO - 에폭 4/5, 손실: 197.5510\n","2024-10-11 04:21:22,419 - INFO - 에폭 5/5, 손실: 195.3798\n","2024-10-11 04:21:22,423 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,426 - INFO - built Dictionary<855 unique tokens: ['beautiful', 'extremely', 'fabric', 'fall', 'flattering']...> from 80 documents (total 2336 corpus positions)\n","2024-10-11 04:21:22,427 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<855 unique tokens: ['beautiful', 'extremely', 'fabric', 'fall', 'flattering']...> from 80 documents (total 2336 corpus positions)\", 'datetime': '2024-10-11T04:21:22.427855', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,494 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,495 - INFO - Sample of sampled data: ['reason everyone giving dress star stunning flattering versatile comfortable im slim athletic size store one medium im generally small hanger look like slim tube thought id try fit fabulous due stretch shape dress id say size medium could fit dont worry sizing one dress suuuuuper stretchy even though fit close throu', 'worn top multiple time jean neckline make even u small busted look great top', 'wanted love dress like scratchy lining also like scratchy lining considerably smaller overall swing dress clung curve uncomfortably wish done silk would much nicer material returned', 'absolutely gorgeous word cant describe beauty dress hope restock cause would order size didnt know run', 'thought top looked adorable material soft top like dont usually look great someone little bit busty make look fat like youre wearing maternity real issue arm hole large seemed gape bit didnt look flattering even wore cute lacy bandeau bra way material stick around arm hole would still look awkward bad since cute top well made']\n","2024-10-11 04:21:22,507 - INFO - 에폭 1/5, 손실: 216.1311\n","2024-10-11 04:21:22,512 - INFO - 에폭 2/5, 손실: 211.8240\n","2024-10-11 04:21:22,518 - INFO - 에폭 3/5, 손실: 207.6351\n","2024-10-11 04:21:22,524 - INFO - 에폭 4/5, 손실: 204.0609\n","2024-10-11 04:21:22,530 - INFO - 에폭 5/5, 손실: 200.2015\n","2024-10-11 04:21:22,534 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,539 - INFO - built Dictionary<874 unique tokens: ['athletic', 'close', 'comfortable', 'could', 'dont']...> from 80 documents (total 2362 corpus positions)\n","2024-10-11 04:21:22,541 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<874 unique tokens: ['athletic', 'close', 'comfortable', 'could', 'dont']...> from 80 documents (total 2362 corpus positions)\", 'datetime': '2024-10-11T04:21:22.541484', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,602 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,602 - INFO - Sample of sampled data: ['love pilcro wear time usually size grow wearing tried usual size felt like tight sure get looser material feel really good lightweight stripe subtle cute sure ill keep maybe size', 'short ageappropriate theyre loose fitting cal rolled left end knee fabric soft color fun', 'wore pant work fit looked great however first time put wash became discolored completely stained unwearable disappointing spend much money wear pair pant', 'hoping find slimming cozy sweater unfortunately one baggy material really bulky one occasion would never purchased person online cant quite tell style fit returned item', 'im love dress first tried petite size store dont enormous shoulder think petite would fit someone range im trying say dress pretty long cut beautiful pattern perfectly complementary ive reading marie kondos book one spark joy']\n","2024-10-11 04:21:22,614 - INFO - 에폭 1/5, 손실: 223.8744\n","2024-10-11 04:21:22,621 - INFO - 에폭 2/5, 손실: 219.6388\n","2024-10-11 04:21:22,627 - INFO - 에폭 3/5, 손실: 215.6198\n","2024-10-11 04:21:22,634 - INFO - 에폭 4/5, 손실: 211.9658\n","2024-10-11 04:21:22,639 - INFO - 에폭 5/5, 손실: 207.9096\n","2024-10-11 04:21:22,644 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,648 - INFO - built Dictionary<892 unique tokens: ['cute', 'feel', 'felt', 'get', 'good']...> from 80 documents (total 2454 corpus positions)\n","2024-10-11 04:21:22,649 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<892 unique tokens: ['cute', 'feel', 'felt', 'get', 'good']...> from 80 documents (total 2454 corpus positions)\", 'datetime': '2024-10-11T04:21:22.649947', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,723 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,724 - INFO - Sample of sampled data: ['dress made lightweight linen lined separate slip high quality nice detail tt sleeve average length length dress feel appropriate frame hookandeye closure chest area keep button aligned quality detail think lovely dress go work play', 'bought top size im longer torso thought first would boxy cropped fit well still cover stomach raise arm material thicker side little structured think give nice look drape feel like could wear shirt casual day work blazer dress highly recommend especially since material linen cotton whic', 'agree othersthis type sweater hooked retailer ten year ago love new sweater recommend wearing long sleeve tee underneath sleeve itchy', 'love pilcro wear time usually size grow wearing tried usual size felt like tight sure get looser material feel really good lightweight stripe subtle cute sure ill keep maybe size', 'top new favorite ordered whim oh boy glad excited shipped arrived couldnt wait put put couldnt wait show great bluishgrayish color look great big hoop earring short sandal easy classic simple shirt probably wear much']\n","2024-10-11 04:21:22,736 - INFO - 에폭 1/5, 손실: 223.0766\n","2024-10-11 04:21:22,743 - INFO - 에폭 2/5, 손실: 216.9287\n","2024-10-11 04:21:22,751 - INFO - 에폭 3/5, 손실: 212.4141\n","2024-10-11 04:21:22,760 - INFO - 에폭 4/5, 손실: 207.5654\n","2024-10-11 04:21:22,766 - INFO - 에폭 5/5, 손실: 203.2046\n","2024-10-11 04:21:22,772 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,776 - INFO - built Dictionary<879 unique tokens: ['aligned', 'appropriate', 'area', 'average', 'button']...> from 80 documents (total 2406 corpus positions)\n","2024-10-11 04:21:22,778 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<879 unique tokens: ['aligned', 'appropriate', 'area', 'average', 'button']...> from 80 documents (total 2406 corpus positions)\", 'datetime': '2024-10-11T04:21:22.778421', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:22,866 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:22,868 - INFO - Sample of sampled data: ['great cut fit length perfect like weight skirt overall good season', 'drew shirt beautiful silver gold embroidery front shirt folded store make sense hung fewer people would try shirt sheer front sheer back bug many clothes made day cheaply made thin cloth forced layer camisole something else order wear public cant wear sheer clothes', 'pant really pretty color feel nice fit great really shrink washing received lot compliment first time wore', 'dress thick cotton material like sweatshirt hoping wear wedding tunic best bell part sleeve also stick awkwardly fabric', 'im love dress first tried petite size store dont enormous shoulder think petite would fit someone range im trying say dress pretty long cut beautiful pattern perfectly complementary ive reading marie kondos book one spark joy']\n","2024-10-11 04:21:22,887 - INFO - 에폭 1/5, 손실: 215.8808\n","2024-10-11 04:21:22,896 - INFO - 에폭 2/5, 손실: 210.1895\n","2024-10-11 04:21:22,906 - INFO - 에폭 3/5, 손실: 204.3967\n","2024-10-11 04:21:22,914 - INFO - 에폭 4/5, 손실: 198.4060\n","2024-10-11 04:21:22,924 - INFO - 에폭 5/5, 손실: 194.4470\n","2024-10-11 04:21:22,929 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:22,933 - INFO - built Dictionary<876 unique tokens: ['cut', 'fit', 'good', 'great', 'length']...> from 80 documents (total 2321 corpus positions)\n","2024-10-11 04:21:22,934 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<876 unique tokens: ['cut', 'fit', 'good', 'great', 'length']...> from 80 documents (total 2321 corpus positions)\", 'datetime': '2024-10-11T04:21:22.934766', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:23,012 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:23,013 - INFO - Sample of sampled data: ['purchased dress redorange color impressed quality fabric waist sat bit higher picture look much like empire waist', 'cute print love mix color sweater look great jean throw tshirt set', 'coat cool cut classic well fit ive wearing jacket every day since purchasing day ago already begun slightly pill worn jacket pilling quickly basic wear', 'love shirt although see tank work great wear work button back sewn really well come far enough short pound tight neck kept otherwise would fit fine since blousy shirt would tight shoulder armpit', 'shirt awful anything pretty there reason main photo model arm crossed waist run good top get body garment run straight yet pleat even make manage expand little get lovely detailed hem rein left bit poof effect making rounder wrong way one im lazy send back awful']\n","2024-10-11 04:21:23,028 - INFO - 에폭 1/5, 손실: 216.6847\n","2024-10-11 04:21:23,035 - INFO - 에폭 2/5, 손실: 212.2335\n","2024-10-11 04:21:23,044 - INFO - 에폭 3/5, 손실: 209.5912\n","2024-10-11 04:21:23,051 - INFO - 에폭 4/5, 손실: 205.5369\n","2024-10-11 04:21:23,058 - INFO - 에폭 5/5, 손실: 202.3315\n","2024-10-11 04:21:23,063 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:23,067 - INFO - built Dictionary<865 unique tokens: ['bit', 'color', 'dress', 'empire', 'fabric']...> from 80 documents (total 2357 corpus positions)\n","2024-10-11 04:21:23,067 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<865 unique tokens: ['bit', 'color', 'dress', 'empire', 'fabric']...> from 80 documents (total 2357 corpus positions)\", 'datetime': '2024-10-11T04:21:23.067122', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:23,133 - INFO - Analyzing stability for domain: news\n","2024-10-11 04:21:23,133 - INFO - Original data type: <class 'list'>\n","2024-10-11 04:21:23,134 - INFO - Processed data type: <class 'list'>\n","2024-10-11 04:21:23,135 - INFO - Sample of processed data: ['new startup offering certification testing distribution existing opensource software could become dell software industry', 'sir richard branson hope new company first send adventuresome tourist space branson founder airline entertainment telecom holding company virgin group announced monday', 'welfare authority solomon island reacted outrage local soccer fan reportedly offered eightyearold son bait bet solomon clash australia', 'halftime monday night man wearing kansa city jersey put nice move ran field unfortunately chief real', 'one police officer shot dead un peacekeeper haitian riot police took holdout militant loyal ousted president jeanbertrand aristide']\n","2024-10-11 04:21:23,139 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:23,141 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:27,240 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:27,241 - INFO - Sample of sampled data: ['sir richard branson hope new company first send adventuresome tourist space branson founder airline entertainment telecom holding company virgin group announced monday', 'since late sam snead golf tournament turned american time fijian already claimed victory month since reached age fair speculate vijay singh know', 'new york uneasy investor sold stock mostly lower tuesday oil price climbed per barrel creating new worry rising energy cost would curb consumer spending corporate profit', 'ellen simon new york ap ibm corp claimed unofficial bragging right tuesday owner world fastest supercomputer', 'free standard group announce tuesday availability linux standard base lsb standard support almost global linux distribution vendor']\n","2024-10-11 04:21:27,246 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:27,246 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:31,555 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:31,558 - INFO - built Dictionary<1047 unique tokens: ['adventuresome', 'airline', 'announced', 'branson', 'company']...> from 80 documents (total 1423 corpus positions)\n","2024-10-11 04:21:31,559 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1047 unique tokens: ['adventuresome', 'airline', 'announced', 'branson', 'company']...> from 80 documents (total 1423 corpus positions)\", 'datetime': '2024-10-11T04:21:31.559325', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:31,752 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:31,753 - INFO - Sample of sampled data: ['pakistan president pervez musharraf took power bloodless coup ground could provide stable democracy strongly hinting step army chief end year promised', 'astana kazakhstan reuters russia curtly told united state stay business wednesday u criticism echoed european union president vladimir putin plan radical change boost kremlin power', 'sir richard branson hope new company first send adventuresome tourist space branson founder airline entertainment telecom holding company virgin group announced monday', 'los angeles cbsmw surging demand emerging economy rising commodity price worldwide casting daylight coalmining stock', 'welfare authority solomon island reacted outrage local soccer fan reportedly offered eightyearold son bait bet solomon clash australia']\n","2024-10-11 04:21:31,757 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:31,757 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:35,723 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:35,727 - INFO - built Dictionary<1050 unique tokens: ['army', 'bloodless', 'chief', 'could', 'coup']...> from 80 documents (total 1467 corpus positions)\n","2024-10-11 04:21:35,728 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1050 unique tokens: ['army', 'bloodless', 'chief', 'could', 'coup']...> from 80 documents (total 1467 corpus positions)\", 'datetime': '2024-10-11T04:21:35.728146', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:35,907 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:35,908 - INFO - Sample of sampled data: ['baghdad reuters iraq belief weekend massacre army recruit could inside job source close interim prime minister iyad allawi told reuters monday', 'reuters iran looked set avoid reportedto united nation security council monday afterreaffirming commitment deal meant reassure theworld trying build nuclear bomb', 'truck parked yashwanthpur bangalore saturday following indefinite strike called allindia motor transport congress', 'three congressman asking general accounting office investigate irregularity voting machine presidential election dont anticipate change election outcome kim zetter', 'mark amp spencer reporting fourth straight quarter falling sale say food sale slipped slightly last two week september clothing steady']\n","2024-10-11 04:21:35,912 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:35,912 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:40,372 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:40,375 - INFO - built Dictionary<1043 unique tokens: ['allawi', 'army', 'baghdad', 'belief', 'close']...> from 80 documents (total 1440 corpus positions)\n","2024-10-11 04:21:40,376 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1043 unique tokens: ['allawi', 'army', 'baghdad', 'belief', 'close']...> from 80 documents (total 1440 corpus positions)\", 'datetime': '2024-10-11T04:21:40.376838', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:40,552 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:40,552 - INFO - Sample of sampled data: ['sure quarterback controversy boston college nothing new head coach tom brien two choice two senior paul peterson quinton porter', 'london president general pervez musharraf succeeded persuading british prime minister tony blair severity kashmir palestine dispute', 'intel ibm ntt docomo launched security technology mobile device claim bolster mcommerce service', 'saudi security force killed wanted militant near scene deadly shootout thursday official say militant killed gunbattle friday northern town buraida hour one', 'haiti interim prime minister sunday accused ousted president jeanbertrand aristide directing wave violence exile']\n","2024-10-11 04:21:40,556 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:40,557 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:44,545 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:44,549 - INFO - built Dictionary<1043 unique tokens: ['boston', 'brien', 'choice', 'coach', 'college']...> from 80 documents (total 1433 corpus positions)\n","2024-10-11 04:21:44,550 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1043 unique tokens: ['boston', 'brien', 'choice', 'coach', 'college']...> from 80 documents (total 1433 corpus positions)\", 'datetime': '2024-10-11T04:21:44.550517', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:44,736 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:44,737 - INFO - Sample of sampled data: ['new startup offering certification testing distribution existing opensource software could become dell software industry', 'since late sam snead golf tournament turned american time fijian already claimed victory month since reached age fair speculate vijay singh know', 'web site visitor clicked banner ad number popular european web site weekend may infected computer variant bofra worm expert said today', 'ap insurgent hammered central baghdad sunday one intense mortar rocket barrage ever heart capital heralding day violence killed nearly people nationwide security appeared spiral control', 'new york reuters dollar mostly lower tuesday weighed report showing u current account deficit ballooned new record second quarter']\n","2024-10-11 04:21:44,741 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:44,742 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:48,715 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:48,719 - INFO - built Dictionary<1067 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 80 documents (total 1467 corpus positions)\n","2024-10-11 04:21:48,720 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1067 unique tokens: ['become', 'certification', 'could', 'dell', 'distribution']...> from 80 documents (total 1467 corpus positions)\", 'datetime': '2024-10-11T04:21:48.720059', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:48,901 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:48,901 - INFO - Sample of sampled data: ['tiger wood married swedish model elin nordegren exclusive resort barbados sunset ceremony reportedly cost million according witness', 'page brin schmidt hold one third company stock still retain current holding san francisco reuters google inc', 'yahoo named dr usama fayyad chief data officer senior vice president strategic data solution group fayyad responsible yahoo', 'music industry magazine soon publishing list bestselling ring tone according source', 'afp large increase number foreign seaman jumping ship new zealand blamed immigration racket prompted government threat ban overseas fishing crew according report']\n","2024-10-11 04:21:48,906 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:48,906 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:52,918 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:52,921 - INFO - built Dictionary<1040 unique tokens: ['according', 'barbados', 'ceremony', 'cost', 'elin']...> from 80 documents (total 1426 corpus positions)\n","2024-10-11 04:21:52,923 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1040 unique tokens: ['according', 'barbados', 'ceremony', 'cost', 'elin']...> from 80 documents (total 1426 corpus positions)\", 'datetime': '2024-10-11T04:21:52.923372', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:53,107 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:53,108 - INFO - Sample of sampled data: ['sir richard branson hope new company first send adventuresome tourist space branson founder airline entertainment telecom holding company virgin group announced monday', 'sometimes help open atlas stare moment morning checking southwestern asia map national geographic atlas world handsome volume way', 'telstra relaunched section website allows customer see current past network reliability country region', 'truck parked yashwanthpur bangalore saturday following indefinite strike called allindia motor transport congress', 'open source development lab upgraded key linux kernel development tool scalable test platform new feature improve simulation enterprise data center linux kernel']\n","2024-10-11 04:21:53,112 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:53,112 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:21:57,551 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:21:57,554 - INFO - built Dictionary<1054 unique tokens: ['adventuresome', 'airline', 'announced', 'branson', 'company']...> from 80 documents (total 1456 corpus positions)\n","2024-10-11 04:21:57,555 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1054 unique tokens: ['adventuresome', 'airline', 'announced', 'branson', 'company']...> from 80 documents (total 1456 corpus positions)\", 'datetime': '2024-10-11T04:21:57.555550', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:21:57,741 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:21:57,743 - INFO - Sample of sampled data: ['faisalabad pakistan took slender first inning lead sri lanka end second day play first test home side reached ahead sri lanka earlier lost last three wicket faisalabad', 'ap insurgent hammered central baghdad sunday one intense mortar rocket barrage ever heart capital heralding day violence killed nearly people nationwide security appeared spiral control', 'warrant placing former chilean dictator augusto pinochet house arrest charge murder kidnapping suspended appeal lawyer', 'washington reuters concerned health official began investigating went wrong british vaccine plant half u flu shot made american jostled nowscarce immunization friday', 'boston red sox buried decade futility anguish week maryland football program slain mighty dragon']\n","2024-10-11 04:21:57,748 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:21:57,748 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:01,676 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:01,680 - INFO - built Dictionary<1067 unique tokens: ['ahead', 'day', 'earlier', 'end', 'faisalabad']...> from 80 documents (total 1452 corpus positions)\n","2024-10-11 04:22:01,681 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1067 unique tokens: ['ahead', 'day', 'earlier', 'end', 'faisalabad']...> from 80 documents (total 1452 corpus positions)\", 'datetime': '2024-10-11T04:22:01.681990', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:01,817 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:01,818 - INFO - Sample of sampled data: ['belarus electoral commission announced sunday referendum approved lifting constitutional ban third consecutive term president lukashenko', 'ap video posted monday web site showed beheading man identified american civil engineer eugene armstrong militant group led abu musab alzarqawi claimed responsibility slaying said another hostage either american briton would killed hour', 'microsofts legal fight eu antitrust penalty enters second day focus turn medium player', 'ap tokyo stock opened slightly higher tuesday following wall street modest gain dollar japanese yen', 'zurich reuters credit suisse plan focus investment banking activity highmargin business float insurer winterthur longawaited revamp aimed boosting earnings power europe thlargest bank']\n","2024-10-11 04:22:01,823 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:01,823 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:05,755 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:05,759 - INFO - built Dictionary<1044 unique tokens: ['announced', 'approved', 'ban', 'belarus', 'commission']...> from 80 documents (total 1423 corpus positions)\n","2024-10-11 04:22:05,760 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1044 unique tokens: ['announced', 'approved', 'ban', 'belarus', 'commission']...> from 80 documents (total 1423 corpus positions)\", 'datetime': '2024-10-11T04:22:05.760505', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:05,950 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:05,951 - INFO - Sample of sampled data: ['belarus electoral commission announced sunday referendum approved lifting constitutional ban third consecutive term president lukashenko', 'reuters iran looked set avoid reportedto united nation security council monday afterreaffirming commitment deal meant reassure theworld trying build nuclear bomb', 'though bea system signed licensing deal worth million added new customer quarter licensing revenue dropped million', 'police launched investigation claim birmingham dwight yorke racially abused prior game blackburn', 'faisalabad pakistan took slender first inning lead sri lanka end second day play first test home side reached ahead sri lanka earlier lost last three wicket faisalabad']\n","2024-10-11 04:22:05,954 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:05,955 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:10,381 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:10,386 - INFO - built Dictionary<1061 unique tokens: ['announced', 'approved', 'ban', 'belarus', 'commission']...> from 80 documents (total 1465 corpus positions)\n","2024-10-11 04:22:10,386 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1061 unique tokens: ['announced', 'approved', 'ban', 'belarus', 'commission']...> from 80 documents (total 1465 corpus positions)\", 'datetime': '2024-10-11T04:22:10.386488', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:10,578 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:10,578 - INFO - Sample of sampled data: ['zurich reuters credit suisse plan focus investment banking activity highmargin business float insurer winterthur longawaited revamp aimed boosting earnings power europe thlargest bank', 'ap video posted monday web site showed beheading man identified american civil engineer eugene armstrong militant group led abu musab alzarqawi claimed responsibility slaying said another hostage either american briton would killed hour', 'srinagar india reuters suicide bomber rammed car packed explosive army convoy indian kashmir saturday killing four soldier civilian wounding police said', 'ap navy put least january decision contract replace aging marine one presidential helicopter fleet giving prospective contractor time lobby prized job', 'conocophillips buy percent oao lukoil russia billion may raise stake expanding access world largest oil gas producing country energy price surge']\n","2024-10-11 04:22:10,588 - INFO - 에폭 1/5, 손실: 124.1130\n","2024-10-11 04:22:10,594 - INFO - 에폭 2/5, 손실: 122.0353\n","2024-10-11 04:22:10,600 - INFO - 에폭 3/5, 손실: 120.1347\n","2024-10-11 04:22:10,605 - INFO - 에폭 4/5, 손실: 118.6782\n","2024-10-11 04:22:10,610 - INFO - 에폭 5/5, 손실: 116.8574\n","2024-10-11 04:22:10,614 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:10,617 - INFO - built Dictionary<1065 unique tokens: ['activity', 'aimed', 'bank', 'banking', 'boosting']...> from 80 documents (total 1460 corpus positions)\n","2024-10-11 04:22:10,618 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1065 unique tokens: ['activity', 'aimed', 'bank', 'banking', 'boosting']...> from 80 documents (total 1460 corpus positions)\", 'datetime': '2024-10-11T04:22:10.618324', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:10,853 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:10,854 - INFO - Sample of sampled data: ['chief organisation american state accused corruption costa rica quits two week job', 'net phone service retailer push misleading product consumer sipphone charge', 'reuters hewlettpackard co theworlds numbertwo pc maker said friday launched yuan computer china turning heat theintensely competitive market', 'microsofts legal fight eu antitrust penalty enters second day focus turn medium player', 'belarus electoral commission announced sunday referendum approved lifting constitutional ban third consecutive term president lukashenko']\n","2024-10-11 04:22:10,864 - INFO - 에폭 1/5, 손실: 122.2037\n","2024-10-11 04:22:10,869 - INFO - 에폭 2/5, 손실: 120.3375\n","2024-10-11 04:22:10,876 - INFO - 에폭 3/5, 손실: 118.6064\n","2024-10-11 04:22:10,881 - INFO - 에폭 4/5, 손실: 116.8982\n","2024-10-11 04:22:10,886 - INFO - 에폭 5/5, 손실: 114.6947\n","2024-10-11 04:22:10,889 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:10,892 - INFO - built Dictionary<1054 unique tokens: ['accused', 'american', 'chief', 'corruption', 'costa']...> from 80 documents (total 1442 corpus positions)\n","2024-10-11 04:22:10,892 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1054 unique tokens: ['accused', 'american', 'chief', 'corruption', 'costa']...> from 80 documents (total 1442 corpus positions)\", 'datetime': '2024-10-11T04:22:10.892626', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:11,116 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:11,117 - INFO - Sample of sampled data: ['mark amp spencer reporting fourth straight quarter falling sale say food sale slipped slightly last two week september clothing steady', 'halftime monday night man wearing kansa city jersey put nice move ran field unfortunately chief real', 'patriot safety rodney harrison voted dirtiest player football recent poll conducted sport illustrated current former nfl player surprised', 'txu corp txun quote profile research monday raised percent dividend slashed two year ago boosted earnings forecast increased', 'northern irish drug maker warner chilcott plc received bid approach worth penny per share value company billion pound']\n","2024-10-11 04:22:11,128 - INFO - 에폭 1/5, 손실: 129.7968\n","2024-10-11 04:22:11,133 - INFO - 에폭 2/5, 손실: 127.9143\n","2024-10-11 04:22:11,139 - INFO - 에폭 3/5, 손실: 125.8677\n","2024-10-11 04:22:11,144 - INFO - 에폭 4/5, 손실: 124.2765\n","2024-10-11 04:22:11,150 - INFO - 에폭 5/5, 손실: 122.3087\n","2024-10-11 04:22:11,154 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:11,157 - INFO - built Dictionary<1040 unique tokens: ['amp', 'clothing', 'falling', 'food', 'fourth']...> from 80 documents (total 1434 corpus positions)\n","2024-10-11 04:22:11,158 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1040 unique tokens: ['amp', 'clothing', 'falling', 'food', 'fourth']...> from 80 documents (total 1434 corpus positions)\", 'datetime': '2024-10-11T04:22:11.158297', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:11,414 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:11,415 - INFO - Sample of sampled data: ['washington reuters amtrak another financial hole posting billion operating loss last fiscal year receiving far less requested federal subsidy influential transportation watchdog said sunday', 'new delhi indian security team ruled chittagong venue second test match well first three onedayers bangladesh', 'chief organisation american state accused corruption costa rica quits two week job', 'page brin schmidt hold one third company stock still retain current holding san francisco reuters google inc', 'toshiba corporation quottoshiba quot lt ahref quothttpmatsushitacojp quot target quotnew quot gtmatsushita electric industrial co']\n","2024-10-11 04:22:11,426 - INFO - 에폭 1/5, 손실: 134.1112\n","2024-10-11 04:22:11,432 - INFO - 에폭 2/5, 손실: 131.9221\n","2024-10-11 04:22:11,438 - INFO - 에폭 3/5, 손실: 129.3842\n","2024-10-11 04:22:11,444 - INFO - 에폭 4/5, 손실: 127.5346\n","2024-10-11 04:22:11,449 - INFO - 에폭 5/5, 손실: 125.1806\n","2024-10-11 04:22:11,453 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:11,456 - INFO - built Dictionary<1057 unique tokens: ['amtrak', 'another', 'billion', 'far', 'federal']...> from 80 documents (total 1479 corpus positions)\n","2024-10-11 04:22:11,457 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1057 unique tokens: ['amtrak', 'another', 'billion', 'far', 'federal']...> from 80 documents (total 1479 corpus positions)\", 'datetime': '2024-10-11T04:22:11.457266', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:11,684 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:11,685 - INFO - Sample of sampled data: ['three congressman asking general accounting office investigate irregularity voting machine presidential election dont anticipate change election outcome kim zetter', 'new delhi indian security team ruled chittagong venue second test match well first three onedayers bangladesh', 'indianapolisbased drug manufacturer eli lilly eliminating u job order streamline operation become competitive', 'sudan decided postpone decision expel head two british aid agency oxfam save child citing administrative difficulty humanitarian ground', 'voter switzerland backed new law permitting research stem cell human embryo catholic church influential green party opposed legislation saying involved taking human life']\n","2024-10-11 04:22:11,695 - INFO - 에폭 1/5, 손실: 123.0060\n","2024-10-11 04:22:11,701 - INFO - 에폭 2/5, 손실: 121.6335\n","2024-10-11 04:22:11,706 - INFO - 에폭 3/5, 손실: 119.5777\n","2024-10-11 04:22:11,712 - INFO - 에폭 4/5, 손실: 118.2950\n","2024-10-11 04:22:11,718 - INFO - 에폭 5/5, 손실: 116.7528\n","2024-10-11 04:22:11,722 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:11,724 - INFO - built Dictionary<1047 unique tokens: ['accounting', 'anticipate', 'asking', 'change', 'congressman']...> from 80 documents (total 1420 corpus positions)\n","2024-10-11 04:22:11,724 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1047 unique tokens: ['accounting', 'anticipate', 'asking', 'change', 'congressman']...> from 80 documents (total 1420 corpus positions)\", 'datetime': '2024-10-11T04:22:11.724616', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:11,938 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:11,939 - INFO - Sample of sampled data: ['indianapolisbased drug manufacturer eli lilly eliminating u job order streamline operation become competitive', 'gold medalwinning marlon devonish say men xm olympic relay triumph put british sprinting back map devonish darren campbell jason gardener mark lewisfrancis edged american', 'senior aide yasser arafat said early sunday ailing palestinian leader comatose still intensive care adding confusion fragile health', 'state effectively shut marysvillebased company allegedly misled consumer effectiveness breastenlargement weightloss sexualdysfunction product marketed web site', 'nasa broken genesis capsule stuck utah desert shuttle assembly building battered hurricane cape canaveral u space agency defended budget mission wednesday']\n","2024-10-11 04:22:11,951 - INFO - 에폭 1/5, 손실: 131.1854\n","2024-10-11 04:22:11,956 - INFO - 에폭 2/5, 손실: 128.9000\n","2024-10-11 04:22:11,961 - INFO - 에폭 3/5, 손실: 126.8825\n","2024-10-11 04:22:11,967 - INFO - 에폭 4/5, 손실: 124.5560\n","2024-10-11 04:22:11,972 - INFO - 에폭 5/5, 손실: 121.9211\n","2024-10-11 04:22:11,975 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:11,978 - INFO - built Dictionary<1064 unique tokens: ['become', 'competitive', 'drug', 'eli', 'eliminating']...> from 80 documents (total 1445 corpus positions)\n","2024-10-11 04:22:11,980 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1064 unique tokens: ['become', 'competitive', 'drug', 'eli', 'eliminating']...> from 80 documents (total 1445 corpus positions)\", 'datetime': '2024-10-11T04:22:11.980840', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:12,202 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:12,202 - INFO - Sample of sampled data: ['despite slight seasonal dip software maker surpasses earnings expectation yearoveryear growth come strong', 'los angeles cbsmw surging demand emerging economy rising commodity price worldwide casting daylight coalmining stock', 'terrorist insurgent stepping attack oil gas operation overseas effort disrupt jittery energy market destabilize government scare foreign worker analyst said', 'consequence massive meltdown northern ice would dramatic according study lowlying coastal area florida louisiana could flooded sea', 'chief organisation american state accused corruption costa rica quits two week job']\n","2024-10-11 04:22:12,214 - INFO - 에폭 1/5, 손실: 124.8210\n","2024-10-11 04:22:12,219 - INFO - 에폭 2/5, 손실: 122.7584\n","2024-10-11 04:22:12,225 - INFO - 에폭 3/5, 손실: 120.8358\n","2024-10-11 04:22:12,231 - INFO - 에폭 4/5, 손실: 118.7587\n","2024-10-11 04:22:12,237 - INFO - 에폭 5/5, 손실: 116.5130\n","2024-10-11 04:22:12,240 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:12,243 - INFO - built Dictionary<1044 unique tokens: ['come', 'despite', 'dip', 'earnings', 'expectation']...> from 80 documents (total 1429 corpus positions)\n","2024-10-11 04:22:12,244 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1044 unique tokens: ['come', 'despite', 'dip', 'earnings', 'expectation']...> from 80 documents (total 1429 corpus positions)\", 'datetime': '2024-10-11T04:22:12.244781', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:12,459 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:12,460 - INFO - Sample of sampled data: ['reuters german business software giant sap starting see silver lining potentiallinkup rival oracle peoplesoft german sunday newspaper welt sonntag reported', 'google executive long conceded one great fear overtaken advanced internet search technology', 'dusty mangum kick yard field goal time expires texas behind quarterback vince young edge michigan', 'sir richard branson hope new company first send adventuresome tourist space branson founder airline entertainment telecom holding company virgin group announced monday', 'web site visitor clicked banner ad number popular european web site weekend may infected computer variant bofra worm expert said today']\n","2024-10-11 04:22:12,470 - INFO - 에폭 1/5, 손실: 121.4534\n","2024-10-11 04:22:12,475 - INFO - 에폭 2/5, 손실: 118.7985\n","2024-10-11 04:22:12,481 - INFO - 에폭 3/5, 손실: 116.8565\n","2024-10-11 04:22:12,485 - INFO - 에폭 4/5, 손실: 114.7721\n","2024-10-11 04:22:12,492 - INFO - 에폭 5/5, 손실: 112.7170\n","2024-10-11 04:22:12,496 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:12,500 - INFO - built Dictionary<1062 unique tokens: ['business', 'german', 'giant', 'lining', 'newspaper']...> from 80 documents (total 1459 corpus positions)\n","2024-10-11 04:22:12,500 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1062 unique tokens: ['business', 'german', 'giant', 'lining', 'newspaper']...> from 80 documents (total 1459 corpus positions)\", 'datetime': '2024-10-11T04:22:12.500044', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:12,725 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:12,726 - INFO - Sample of sampled data: ['google warned thursday increased competition maturing company would result quotinevitable quot slowing growth', 'one police officer shot dead un peacekeeper haitian riot police took holdout militant loyal ousted president jeanbertrand aristide', 'baghdad reuters iraq belief weekend massacre army recruit could inside job source close interim prime minister iyad allawi told reuters monday', 'terrorist insurgent stepping attack oil gas operation overseas effort disrupt jittery energy market destabilize government scare foreign worker analyst said', 'los angeles cbsmw surging demand emerging economy rising commodity price worldwide casting daylight coalmining stock']\n","2024-10-11 04:22:12,736 - INFO - 에폭 1/5, 손실: 114.6587\n","2024-10-11 04:22:12,741 - INFO - 에폭 2/5, 손실: 112.7245\n","2024-10-11 04:22:12,746 - INFO - 에폭 3/5, 손실: 110.6866\n","2024-10-11 04:22:12,752 - INFO - 에폭 4/5, 손실: 108.8013\n","2024-10-11 04:22:12,758 - INFO - 에폭 5/5, 손실: 106.6969\n","2024-10-11 04:22:12,762 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:12,765 - INFO - built Dictionary<1055 unique tokens: ['company', 'competition', 'google', 'growth', 'increased']...> from 80 documents (total 1433 corpus positions)\n","2024-10-11 04:22:12,766 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1055 unique tokens: ['company', 'competition', 'google', 'growth', 'increased']...> from 80 documents (total 1433 corpus positions)\", 'datetime': '2024-10-11T04:22:12.766996', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:12,992 - INFO - Sampled data type: <class 'list'>\n","2024-10-11 04:22:12,993 - INFO - Sample of sampled data: ['ap utah jazz activated point guard carlos arroyo injured list tuesday placed rookie kris humphries tendinitis knee', 'los angeles reuters freddie mac u mortgage finance company said wednesday may face civil action security exchange commission possible violation security law', 'intel ibm ntt docomo launched security technology mobile device claim bolster mcommerce service', 'new delhi indian security team ruled chittagong venue second test match well first three onedayers bangladesh', 'boston red sox buried decade futility anguish week maryland football program slain mighty dragon']\n","2024-10-11 04:22:13,003 - INFO - 에폭 1/5, 손실: 125.7085\n","2024-10-11 04:22:13,009 - INFO - 에폭 2/5, 손실: 123.3605\n","2024-10-11 04:22:13,014 - INFO - 에폭 3/5, 손실: 121.5137\n","2024-10-11 04:22:13,019 - INFO - 에폭 4/5, 손실: 119.5240\n","2024-10-11 04:22:13,024 - INFO - 에폭 5/5, 손실: 117.5943\n","2024-10-11 04:22:13,028 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:13,031 - INFO - built Dictionary<1055 unique tokens: ['activated', 'ap', 'arroyo', 'carlos', 'guard']...> from 80 documents (total 1449 corpus positions)\n","2024-10-11 04:22:13,031 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1055 unique tokens: ['activated', 'ap', 'arroyo', 'carlos', 'guard']...> from 80 documents (total 1449 corpus positions)\", 'datetime': '2024-10-11T04:22:13.031765', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:13,243 - INFO - 토픽 품질 시각화 시작\n","2024-10-11 04:22:13,878 - INFO - 일관성 안정성 평가 시작\n","2024-10-11 04:22:13,883 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:13,883 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:18,612 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:18,626 - INFO - built Dictionary<2505 unique tokens: ['across', 'address', 'addressed', 'advance', 'aggregate']...> from 80 documents (total 9955 corpus positions)\n","2024-10-11 04:22:18,626 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2505 unique tokens: ['across', 'address', 'addressed', 'advance', 'aggregate']...> from 80 documents (total 9955 corpus positions)\", 'datetime': '2024-10-11T04:22:18.626525', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:18,779 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:18,779 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:23,676 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:23,689 - INFO - built Dictionary<2379 unique tokens: ['account', 'advertise', 'amongst', 'analysed', 'analysis']...> from 80 documents (total 9439 corpus positions)\n","2024-10-11 04:22:23,690 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2379 unique tokens: ['account', 'advertise', 'amongst', 'analysed', 'analysis']...> from 80 documents (total 9439 corpus positions)\", 'datetime': '2024-10-11T04:22:23.690107', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:23,834 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:23,835 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:28,964 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:28,977 - INFO - built Dictionary<2509 unique tokens: ['achieve', 'addition', 'adjust', 'adopt', 'also']...> from 80 documents (total 9873 corpus positions)\n","2024-10-11 04:22:28,977 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2509 unique tokens: ['achieve', 'addition', 'adjust', 'adopt', 'also']...> from 80 documents (total 9873 corpus positions)\", 'datetime': '2024-10-11T04:22:28.977977', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:29,131 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:29,131 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:34,347 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:34,360 - INFO - built Dictionary<2479 unique tokens: ['account', 'analysis', 'analytics', 'analyze', 'application']...> from 80 documents (total 9959 corpus positions)\n","2024-10-11 04:22:34,360 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2479 unique tokens: ['account', 'analysis', 'analytics', 'analyze', 'application']...> from 80 documents (total 9959 corpus positions)\", 'datetime': '2024-10-11T04:22:34.360152', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:34,515 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:34,516 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:39,303 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:39,318 - INFO - built Dictionary<2521 unique tokens: ['achieve', 'ambient', 'analytics', 'andor', 'avoid']...> from 80 documents (total 9858 corpus positions)\n","2024-10-11 04:22:39,318 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2521 unique tokens: ['achieve', 'ambient', 'analytics', 'andor', 'avoid']...> from 80 documents (total 9858 corpus positions)\", 'datetime': '2024-10-11T04:22:39.318006', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:39,453 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:39,454 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:43,425 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:43,430 - INFO - built Dictionary<856 unique tokens: ['casual', 'clear', 'come', 'could', 'day']...> from 80 documents (total 2243 corpus positions)\n","2024-10-11 04:22:43,431 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<856 unique tokens: ['casual', 'clear', 'come', 'could', 'day']...> from 80 documents (total 2243 corpus positions)\", 'datetime': '2024-10-11T04:22:43.430699', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:43,444 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:43,445 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:47,448 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:47,452 - INFO - built Dictionary<877 unique tokens: ['bit', 'burlap', 'decided', 'discount', 'fit']...> from 80 documents (total 2377 corpus positions)\n","2024-10-11 04:22:47,453 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<877 unique tokens: ['bit', 'burlap', 'decided', 'discount', 'fit']...> from 80 documents (total 2377 corpus positions)\", 'datetime': '2024-10-11T04:22:47.453540', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:47,590 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:47,590 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:52,552 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:52,556 - INFO - built Dictionary<900 unique tokens: ['anything', 'around', 'back', 'baggy', 'boxy']...> from 80 documents (total 2408 corpus positions)\n","2024-10-11 04:22:52,557 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<900 unique tokens: ['anything', 'around', 'back', 'baggy', 'boxy']...> from 80 documents (total 2408 corpus positions)\", 'datetime': '2024-10-11T04:22:52.557767', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:52,691 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:52,692 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:22:57,028 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:22:57,033 - INFO - built Dictionary<878 unique tokens: ['body', 'came', 'cleavage', 'comfortable', 'delicate']...> from 80 documents (total 2350 corpus positions)\n","2024-10-11 04:22:57,034 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<878 unique tokens: ['body', 'came', 'cleavage', 'comfortable', 'delicate']...> from 80 documents (total 2350 corpus positions)\", 'datetime': '2024-10-11T04:22:57.034326', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:22:57,166 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:22:57,167 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:23:01,434 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:01,439 - INFO - built Dictionary<898 unique tokens: ['arm', 'burgundy', 'caught', 'color', 'compliment']...> from 80 documents (total 2465 corpus positions)\n","2024-10-11 04:23:01,440 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<898 unique tokens: ['arm', 'burgundy', 'caught', 'color', 'compliment']...> from 80 documents (total 2465 corpus positions)\", 'datetime': '2024-10-11T04:23:01.440541', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:01,578 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:23:01,579 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:23:06,492 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:06,496 - INFO - built Dictionary<1068 unique tokens: ['awaited', 'company', 'creation', 'despite', 'end']...> from 80 documents (total 1463 corpus positions)\n","2024-10-11 04:23:06,497 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1068 unique tokens: ['awaited', 'company', 'creation', 'despite', 'end']...> from 80 documents (total 1463 corpus positions)\", 'datetime': '2024-10-11T04:23:06.497268', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:06,694 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:23:06,694 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:23:11,118 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:11,122 - INFO - built Dictionary<1068 unique tokens: ['afp', 'australian', 'bin', 'bodyguard', 'controversial']...> from 80 documents (total 1459 corpus positions)\n","2024-10-11 04:23:11,122 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1068 unique tokens: ['afp', 'australian', 'bin', 'bodyguard', 'controversial']...> from 80 documents (total 1459 corpus positions)\", 'datetime': '2024-10-11T04:23:11.122320', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:11,312 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:23:11,313 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:23:15,515 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:15,519 - INFO - built Dictionary<1048 unique tokens: ['brin', 'company', 'current', 'francisco', 'google']...> from 80 documents (total 1425 corpus positions)\n","2024-10-11 04:23:15,519 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1048 unique tokens: ['brin', 'company', 'current', 'francisco', 'google']...> from 80 documents (total 1425 corpus positions)\", 'datetime': '2024-10-11T04:23:15.519115', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:15,650 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:23:15,651 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:23:20,044 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:20,048 - INFO - built Dictionary<1045 unique tokens: ['amtrak', 'another', 'billion', 'far', 'federal']...> from 80 documents (total 1435 corpus positions)\n","2024-10-11 04:23:20,049 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1045 unique tokens: ['amtrak', 'another', 'billion', 'far', 'federal']...> from 80 documents (total 1435 corpus positions)\", 'datetime': '2024-10-11T04:23:20.049632', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:20,191 - INFO - Use pytorch device_name: cpu\n","2024-10-11 04:23:20,192 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n","2024-10-11 04:23:24,664 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:24,668 - INFO - built Dictionary<1057 unique tokens: ['ap', 'dollar', 'following', 'gain', 'higher']...> from 80 documents (total 1449 corpus positions)\n","2024-10-11 04:23:24,669 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1057 unique tokens: ['ap', 'dollar', 'following', 'gain', 'higher']...> from 80 documents (total 1449 corpus positions)\", 'datetime': '2024-10-11T04:23:24.669468', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:24,887 - INFO - 에폭 1/5, 손실: 710.8398\n","2024-10-11 04:23:24,894 - INFO - 에폭 2/5, 손실: 700.8131\n","2024-10-11 04:23:24,902 - INFO - 에폭 3/5, 손실: 690.6794\n","2024-10-11 04:23:24,909 - INFO - 에폭 4/5, 손실: 680.4312\n","2024-10-11 04:23:24,917 - INFO - 에폭 5/5, 손실: 671.1164\n","2024-10-11 04:23:24,935 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:24,945 - INFO - built Dictionary<2515 unique tokens: ['accurate', 'achieving', 'actual', 'aggregated', 'among']...> from 80 documents (total 10070 corpus positions)\n","2024-10-11 04:23:24,946 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2515 unique tokens: ['accurate', 'achieving', 'actual', 'aggregated', 'among']...> from 80 documents (total 10070 corpus positions)\", 'datetime': '2024-10-11T04:23:24.946955', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:25,539 - INFO - 에폭 1/5, 손실: 698.1338\n","2024-10-11 04:23:25,548 - INFO - 에폭 2/5, 손실: 686.8043\n","2024-10-11 04:23:25,555 - INFO - 에폭 3/5, 손실: 676.7747\n","2024-10-11 04:23:25,572 - INFO - 에폭 4/5, 손실: 665.7970\n","2024-10-11 04:23:25,581 - INFO - 에폭 5/5, 손실: 655.2686\n","2024-10-11 04:23:25,602 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:25,615 - INFO - built Dictionary<2408 unique tokens: ['addition', 'advanced', 'analysis', 'based', 'big']...> from 80 documents (total 9333 corpus positions)\n","2024-10-11 04:23:25,616 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2408 unique tokens: ['addition', 'advanced', 'analysis', 'based', 'big']...> from 80 documents (total 9333 corpus positions)\", 'datetime': '2024-10-11T04:23:25.616053', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:26,220 - INFO - 에폭 1/5, 손실: 702.5435\n","2024-10-11 04:23:26,227 - INFO - 에폭 2/5, 손실: 691.9806\n","2024-10-11 04:23:26,235 - INFO - 에폭 3/5, 손실: 680.8214\n","2024-10-11 04:23:26,241 - INFO - 에폭 4/5, 손실: 671.9343\n","2024-10-11 04:23:26,251 - INFO - 에폭 5/5, 손실: 660.4054\n","2024-10-11 04:23:26,269 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:26,279 - INFO - built Dictionary<2523 unique tokens: ['aim', 'analyse', 'analysis', 'analytical', 'application']...> from 80 documents (total 9894 corpus positions)\n","2024-10-11 04:23:26,280 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2523 unique tokens: ['aim', 'analyse', 'analysis', 'analytical', 'application']...> from 80 documents (total 9894 corpus positions)\", 'datetime': '2024-10-11T04:23:26.280528', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:26,879 - INFO - 에폭 1/5, 손실: 710.6022\n","2024-10-11 04:23:26,886 - INFO - 에폭 2/5, 손실: 698.8163\n","2024-10-11 04:23:26,894 - INFO - 에폭 3/5, 손실: 688.9982\n","2024-10-11 04:23:26,903 - INFO - 에폭 4/5, 손실: 678.7755\n","2024-10-11 04:23:26,911 - INFO - 에폭 5/5, 손실: 670.0857\n","2024-10-11 04:23:26,927 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:26,940 - INFO - built Dictionary<2419 unique tokens: ['addition', 'amount', 'analysis', 'analyst', 'analytics']...> from 80 documents (total 9589 corpus positions)\n","2024-10-11 04:23:26,941 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2419 unique tokens: ['addition', 'amount', 'analysis', 'analyst', 'analytics']...> from 80 documents (total 9589 corpus positions)\", 'datetime': '2024-10-11T04:23:26.941939', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:27,528 - INFO - 에폭 1/5, 손실: 700.5130\n","2024-10-11 04:23:27,536 - INFO - 에폭 2/5, 손실: 688.6036\n","2024-10-11 04:23:27,543 - INFO - 에폭 3/5, 손실: 678.8676\n","2024-10-11 04:23:27,550 - INFO - 에폭 4/5, 손실: 669.0225\n","2024-10-11 04:23:27,558 - INFO - 에폭 5/5, 손실: 660.8549\n","2024-10-11 04:23:27,573 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:27,584 - INFO - built Dictionary<2466 unique tokens: ['actionable', 'activity', 'add', 'additional', 'adopted']...> from 80 documents (total 9712 corpus positions)\n","2024-10-11 04:23:27,585 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<2466 unique tokens: ['actionable', 'activity', 'add', 'additional', 'adopted']...> from 80 documents (total 9712 corpus positions)\", 'datetime': '2024-10-11T04:23:27.585347', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:28,185 - INFO - 에폭 1/5, 손실: 218.0556\n","2024-10-11 04:23:28,190 - INFO - 에폭 2/5, 손실: 214.2511\n","2024-10-11 04:23:28,196 - INFO - 에폭 3/5, 손실: 210.6997\n","2024-10-11 04:23:28,202 - INFO - 에폭 4/5, 손실: 207.3733\n","2024-10-11 04:23:28,207 - INFO - 에폭 5/5, 손실: 204.4571\n","2024-10-11 04:23:28,212 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:28,216 - INFO - built Dictionary<881 unique tokens: ['accordian', 'also', 'back', 'cant', 'clingy']...> from 80 documents (total 2377 corpus positions)\n","2024-10-11 04:23:28,217 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<881 unique tokens: ['accordian', 'also', 'back', 'cant', 'clingy']...> from 80 documents (total 2377 corpus positions)\", 'datetime': '2024-10-11T04:23:28.217286', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:28,802 - INFO - 에폭 1/5, 손실: 217.1663\n","2024-10-11 04:23:28,807 - INFO - 에폭 2/5, 손실: 213.7750\n","2024-10-11 04:23:28,812 - INFO - 에폭 3/5, 손실: 210.8396\n","2024-10-11 04:23:28,819 - INFO - 에폭 4/5, 손실: 207.0969\n","2024-10-11 04:23:28,826 - INFO - 에폭 5/5, 손실: 204.2689\n","2024-10-11 04:23:28,831 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:28,835 - INFO - built Dictionary<877 unique tokens: ['absolutely', 'add', 'also', 'back', 'beautiful']...> from 80 documents (total 2396 corpus positions)\n","2024-10-11 04:23:28,836 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<877 unique tokens: ['absolutely', 'add', 'also', 'back', 'beautiful']...> from 80 documents (total 2396 corpus positions)\", 'datetime': '2024-10-11T04:23:28.836938', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:29,434 - INFO - 에폭 1/5, 손실: 209.0463\n","2024-10-11 04:23:29,439 - INFO - 에폭 2/5, 손실: 205.1145\n","2024-10-11 04:23:29,444 - INFO - 에폭 3/5, 손실: 202.1749\n","2024-10-11 04:23:29,450 - INFO - 에폭 4/5, 손실: 199.2405\n","2024-10-11 04:23:29,457 - INFO - 에폭 5/5, 손실: 196.3409\n","2024-10-11 04:23:29,461 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:29,465 - INFO - built Dictionary<896 unique tokens: ['athletic', 'close', 'comfortable', 'could', 'dont']...> from 80 documents (total 2399 corpus positions)\n","2024-10-11 04:23:29,465 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<896 unique tokens: ['athletic', 'close', 'comfortable', 'could', 'dont']...> from 80 documents (total 2399 corpus positions)\", 'datetime': '2024-10-11T04:23:29.465631', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:30,039 - INFO - 에폭 1/5, 손실: 222.0381\n","2024-10-11 04:23:30,045 - INFO - 에폭 2/5, 손실: 218.7136\n","2024-10-11 04:23:30,051 - INFO - 에폭 3/5, 손실: 215.4670\n","2024-10-11 04:23:30,057 - INFO - 에폭 4/5, 손실: 212.0770\n","2024-10-11 04:23:30,066 - INFO - 에폭 5/5, 손실: 209.6488\n","2024-10-11 04:23:30,071 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:30,075 - INFO - built Dictionary<860 unique tokens: ['arrived', 'big', 'bluishgrayish', 'boy', 'classic']...> from 80 documents (total 2341 corpus positions)\n","2024-10-11 04:23:30,076 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<860 unique tokens: ['arrived', 'big', 'bluishgrayish', 'boy', 'classic']...> from 80 documents (total 2341 corpus positions)\", 'datetime': '2024-10-11T04:23:30.076009', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:30,650 - INFO - 에폭 1/5, 손실: 216.2890\n","2024-10-11 04:23:30,656 - INFO - 에폭 2/5, 손실: 212.6722\n","2024-10-11 04:23:30,662 - INFO - 에폭 3/5, 손실: 209.4754\n","2024-10-11 04:23:30,670 - INFO - 에폭 4/5, 손실: 206.7689\n","2024-10-11 04:23:30,675 - INFO - 에폭 5/5, 손실: 203.7162\n","2024-10-11 04:23:30,681 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:30,685 - INFO - built Dictionary<897 unique tokens: ['almost', 'bag', 'color', 'everything', 'fabric']...> from 80 documents (total 2403 corpus positions)\n","2024-10-11 04:23:30,685 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<897 unique tokens: ['almost', 'bag', 'color', 'everything', 'fabric']...> from 80 documents (total 2403 corpus positions)\", 'datetime': '2024-10-11T04:23:30.685886', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:31,258 - INFO - 에폭 1/5, 손실: 123.2179\n","2024-10-11 04:23:31,264 - INFO - 에폭 2/5, 손실: 121.0019\n","2024-10-11 04:23:31,269 - INFO - 에폭 3/5, 손실: 119.0887\n","2024-10-11 04:23:31,275 - INFO - 에폭 4/5, 손실: 117.2505\n","2024-10-11 04:23:31,282 - INFO - 에폭 5/5, 손실: 115.5349\n","2024-10-11 04:23:31,286 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:31,289 - INFO - built Dictionary<1043 unique tokens: ['drifted', 'jupiter', 'kilometre', 'king', 'million']...> from 80 documents (total 1433 corpus positions)\n","2024-10-11 04:23:31,290 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1043 unique tokens: ['drifted', 'jupiter', 'kilometre', 'king', 'million']...> from 80 documents (total 1433 corpus positions)\", 'datetime': '2024-10-11T04:23:31.290693', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:31,836 - INFO - 에폭 1/5, 손실: 122.6391\n","2024-10-11 04:23:31,841 - INFO - 에폭 2/5, 손실: 120.4765\n","2024-10-11 04:23:31,847 - INFO - 에폭 3/5, 손실: 118.5179\n","2024-10-11 04:23:31,854 - INFO - 에폭 4/5, 손실: 116.6971\n","2024-10-11 04:23:31,860 - INFO - 에폭 5/5, 손실: 114.7881\n","2024-10-11 04:23:31,866 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:31,869 - INFO - built Dictionary<1065 unique tokens: ['annette', 'chen', 'easygoing', 'feisty', 'immensely']...> from 80 documents (total 1449 corpus positions)\n","2024-10-11 04:23:31,870 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1065 unique tokens: ['annette', 'chen', 'easygoing', 'feisty', 'immensely']...> from 80 documents (total 1449 corpus positions)\", 'datetime': '2024-10-11T04:23:31.870163', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:32,462 - INFO - 에폭 1/5, 손실: 122.0554\n","2024-10-11 04:23:32,468 - INFO - 에폭 2/5, 손실: 119.9042\n","2024-10-11 04:23:32,473 - INFO - 에폭 3/5, 손실: 118.3232\n","2024-10-11 04:23:32,477 - INFO - 에폭 4/5, 손실: 116.5847\n","2024-10-11 04:23:32,482 - INFO - 에폭 5/5, 손실: 115.1029\n","2024-10-11 04:23:32,485 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:32,489 - INFO - built Dictionary<1044 unique tokens: ['aristide', 'dead', 'haitian', 'holdout', 'jeanbertrand']...> from 80 documents (total 1421 corpus positions)\n","2024-10-11 04:23:32,490 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1044 unique tokens: ['aristide', 'dead', 'haitian', 'holdout', 'jeanbertrand']...> from 80 documents (total 1421 corpus positions)\", 'datetime': '2024-10-11T04:23:32.490223', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:33,023 - INFO - 에폭 1/5, 손실: 118.7489\n","2024-10-11 04:23:33,028 - INFO - 에폭 2/5, 손실: 117.0072\n","2024-10-11 04:23:33,033 - INFO - 에폭 3/5, 손실: 114.9857\n","2024-10-11 04:23:33,039 - INFO - 에폭 4/5, 손실: 113.0781\n","2024-10-11 04:23:33,043 - INFO - 에폭 5/5, 손실: 111.0034\n","2024-10-11 04:23:33,047 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:33,050 - INFO - built Dictionary<1060 unique tokens: ['city', 'conference', 'david', 'developer', 'interface']...> from 80 documents (total 1428 corpus positions)\n","2024-10-11 04:23:33,051 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1060 unique tokens: ['city', 'conference', 'david', 'developer', 'interface']...> from 80 documents (total 1428 corpus positions)\", 'datetime': '2024-10-11T04:23:33.051846', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:33,611 - INFO - 에폭 1/5, 손실: 127.3017\n","2024-10-11 04:23:33,617 - INFO - 에폭 2/5, 손실: 125.2848\n","2024-10-11 04:23:33,623 - INFO - 에폭 3/5, 손실: 122.9717\n","2024-10-11 04:23:33,630 - INFO - 에폭 4/5, 손실: 121.4799\n","2024-10-11 04:23:33,635 - INFO - 에폭 5/5, 손실: 119.4385\n","2024-10-11 04:23:33,638 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n","2024-10-11 04:23:33,641 - INFO - built Dictionary<1052 unique tokens: ['announced', 'approved', 'ban', 'belarus', 'commission']...> from 80 documents (total 1446 corpus positions)\n","2024-10-11 04:23:33,641 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1052 unique tokens: ['announced', 'approved', 'ban', 'belarus', 'commission']...> from 80 documents (total 1446 corpus positions)\", 'datetime': '2024-10-11T04:23:33.641634', 'gensim': '4.3.3', 'python': '3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n","2024-10-11 04:23:34,195 - INFO - 결과 출력 시작\n","2024-10-11 04:23:34,197 - INFO - \n","=== 결과 분석 ===\n","2024-10-11 04:23:34,198 - INFO - \n","모델별 평균 성능:\n","2024-10-11 04:23:34,203 - INFO -           Coherence      NPMI    U_Mass\n","Model                                  \n","BERTopic   0.927448  0.194207 -1.347731\n","VAE        0.913589  0.410559 -1.362113\n","2024-10-11 04:23:34,206 - INFO - \n","도메인별 평균 성능:\n","2024-10-11 04:23:34,207 - INFO -          Coherence      NPMI    U_Mass\n","Domain                                \n","academy   0.916360  0.143591 -1.325519\n","media     0.936465  0.242973 -1.462386\n","news      0.908731  0.520585 -1.276862\n","2024-10-11 04:23:34,209 - INFO - \n","일치도 분석 결과 (Spearman 상관계수):\n","2024-10-11 04:23:34,209 - INFO - Coherence vs NPMI: -0.3714\n","2024-10-11 04:23:34,210 - INFO - Coherence vs U_Mass: -0.2571\n","2024-10-11 04:23:34,210 - INFO - NPMI vs U_Mass: 0.2000\n","2024-10-11 04:23:34,212 - INFO - \n","안정성 분석 결과:\n","2024-10-11 04:23:34,214 - INFO - Model     Metric   \n","BERTopic  Coherence    0.411402\n","          NPMI         0.137160\n","          U_Mass      -0.089333\n","VAE       Coherence    0.017257\n","          NPMI         0.233681\n","          U_Mass      -0.067606\n","Name: CV, dtype: float64\n","2024-10-11 04:23:34,215 - INFO - \n","일관성 안정성 평가 결과:\n","2024-10-11 04:23:34,215 - INFO -       Model   Domain  Coherence_Stability  NPMI_Stability  UMass_Stability  \\\n","0  BERTopic  academy             0.003166        0.134439        -0.097859   \n","1  BERTopic    media             0.500010             NaN              NaN   \n","2  BERTopic     news             0.010819        0.287139        -0.116826   \n","3       VAE  academy             0.012053        0.170406        -0.054366   \n","4       VAE    media             0.022263        0.054116        -0.043888   \n","5       VAE     news             0.009696        0.049849        -0.028416   \n","\n","   Mean_Coherence  Mean_NPMI  Mean_UMass  \n","0        0.937677   0.056262   -1.048896  \n","1        0.749545        NaN         NaN  \n","2        0.912068   0.413926   -1.333544  \n","3        0.920516   0.354415   -1.369553  \n","4        0.915355   0.411456   -1.318978  \n","5        0.924633   0.568520   -1.179797  \n","2024-10-11 04:23:34,220 - INFO - \n","최고 성능 모델:\n","2024-10-11 04:23:34,224 - INFO -     Domain     Model  Coherence\n","0  academy  BERTopic   0.936603\n","3    media       VAE   0.940231\n","4     news  BERTopic   0.913042\n","2024-10-11 04:23:34,226 - INFO - \n","분석 완료. 결과를 확인하고 해석하세요.\n","2024-10-11 04:23:34,226 - INFO - 모든 분석 완료\n"]}],"source":["# Cell 1: 모델 실행, 평가 지표 실행, 기타 결과 분석\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from gensim import models, corpora\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.preprocessing import MinMaxScaler\n","from gensim.models.coherencemodel import CoherenceModel\n","import time\n","import json\n","from nltk.corpus import stopwords\n","from math import log\n","from itertools import combinations\n","from tqdm import tqdm\n","import logging\n","from collections import Counter, defaultdict\n","import gensim\n","from gensim import corpora\n","from scipy.sparse import csr_matrix\n","from gensim.utils import simple_preprocess\n","from gensim.corpora import Dictionary\n","from transformers import BertTokenizer, BertModel\n","from bertopic import BERTopic\n","import seaborn as sns\n","from scipy import stats\n","import os\n","import re\n","import matplotlib\n","from tabulate import tabulate\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import MDS\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# NLTK 데이터 다운로드\n","import nltk\n","nltk.download('punkt', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","\n","# 로깅 설정\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# stop_words 정의\n","stop_words = set(stopwords.words('english'))\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained('bert-base-uncased')\n","\n","def load_data(file_path, sample_size=100):\n","    try:\n","        df = pd.read_csv(file_path, header=None, names=['text'])\n","    except FileNotFoundError:\n","        logging.error(f\"File not found: {file_path}\")\n","        return []\n","    except Exception as e:\n","        logging.error(f\"Error loading file {file_path}: {e}\")\n","        return []\n","    texts = df['text'].astype(str)\n","    if len(texts) > sample_size:\n","        texts = texts.sample(n=sample_size, random_state=42)\n","    print(f\"Loaded {len(texts)} texts from {file_path}\")\n","    return texts.tolist()\n","\n","def load_all_datasets():\n","    datasets = {\n","        'academy': {\n","            'business': load_data('data/academy/business.csv')\n","        },\n","        'media': {\n","            'clothing_review': load_data('data/media/clothing_review.csv')\n","        },\n","        'news': {\n","            'agnews': load_data('data/news/agnews.csv')\n","        }\n","    }\n","    return datasets\n","\n","class VAE(nn.Module):\n","    def __init__(self, input_dim, hidden_dim=50, latent_dim=None):\n","        if latent_dim is None:\n","            raise ValueError(\"latent_dim must be specified\")\n","        super(VAE, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc21 = nn.Linear(hidden_dim, latent_dim)  \n","        self.fc22 = nn.Linear(hidden_dim, latent_dim)  \n","        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n","        self.fc4 = nn.Linear(hidden_dim, input_dim)\n","\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.sigmoid(self.fc4(h3))\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","def vae_loss(recon_x, x, mu, logvar):\n","    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    return BCE + KLD\n","\n","def extract_vae_topics(vae_model, vectorizer, num_topics, top_n=10):\n","    with torch.no_grad():\n","        latent_vectors = torch.eye(num_topics).to(vae_model.fc3.weight.device)\n","        decoder_output = vae_model.decode(latent_vectors)\n","        decoder_output = decoder_output.cpu().numpy()\n","\n","    feature_names = vectorizer.get_feature_names_out()\n","    topics = []\n","    for topic_distribution in decoder_output:\n","        top_indices = topic_distribution.argsort()[-top_n:][::-1]\n","        topic_words = [feature_names[i] for i in top_indices]\n","        topics.append(topic_words)\n","    return topics\n","\n","def perform_vae_topic_modeling(data, num_topics, num_epochs=5, hidden_dim=50):\n","    data = [str(doc) for doc in data if isinstance(doc, str) and len(doc) > 0]\n","\n","    # TfidfVectorizer 사용\n","    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n","    doc_term_matrix = vectorizer.fit_transform(data)\n","\n","    # MinMaxScaler를 사용하여 0-1 사이로 정규화\n","    scaler = MinMaxScaler()\n","    normalized_matrix = scaler.fit_transform(doc_term_matrix.toarray())\n","\n","    vocab_size = len(vectorizer.get_feature_names_out())\n","    input_dim = vocab_size\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    vae_model = VAE(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=num_topics).to(device)\n","    optimizer = torch.optim.Adam(vae_model.parameters(), lr=1e-3)\n","\n","    batch_size = 64\n","    data_loader = DataLoader(normalized_matrix.astype(np.float32), batch_size=batch_size, shuffle=True)\n","\n","    vae_model.train()\n","    for epoch in range(num_epochs):\n","        train_loss = 0\n","        for batch in data_loader:\n","            batch = batch.to(device)\n","            optimizer.zero_grad()\n","            recon_batch, mu, logvar = vae_model(batch)\n","            loss = vae_loss(recon_batch, batch, mu, logvar)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","        logging.info(f\"에폭 {epoch+1}/{num_epochs}, 손실: {train_loss / len(data_loader.dataset):.4f}\")\n","\n","    topics = extract_vae_topics(vae_model, vectorizer, num_topics)\n","    return vae_model, topics\n","\n","def perform_bertopic_modeling(data):\n","    if isinstance(data, dict):\n","        data = list(data.values())[0]\n","    elif isinstance(data, pd.DataFrame):\n","        data = data['text'].tolist() if 'text' in data.columns else data.values.flatten().tolist()\n","    elif isinstance(data, pd.Series):\n","        data = data.tolist()\n","    elif isinstance(data, np.ndarray):\n","        data = data.flatten().tolist()\n","    elif isinstance(data, list):\n","        pass\n","    else:\n","        raise ValueError(f\"Unsupported data format for BERTopic modeling: {type(data)}\")\n","\n","    # 데이터가 문자열 리스트인지 확인\n","    if not all(isinstance(item, str) for item in data):\n","        raise ValueError(\"All items in the data must be strings\")\n","\n","    try:\n","        bertopic_model = BERTopic(language=\"english\", calculate_probabilities=True)\n","        topics, _ = bertopic_model.fit_transform(data)\n","        \n","        num_topics = len(bertopic_model.get_topics())\n","        topic_words = []\n","        for i in range(num_topics):\n","            topic = bertopic_model.get_topic(i)\n","            if topic:\n","                words = [word for word, _ in topic[:10]]  # 상위 10개 단어만 추출\n","                topic_words.append(words)\n","        \n","        return bertopic_model, topic_words, num_topics\n","    except AttributeError as e:\n","        logging.error(f\"BERTopic 모델링 중 오류 발생: {e}\")\n","        return None, None, None\n","\n","def perform_vae_topic_modeling(data, num_topics, num_epochs=5, hidden_dim=50):\n","    try:\n","        # 데이터 전처리\n","        data = [str(doc) for doc in data if isinstance(doc, str) and len(doc) > 0]\n","        vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n","        doc_term_matrix = vectorizer.fit_transform(data)\n","\n","        # MinMaxScaler를 사용하여 0-1 사이로 정규화\n","        scaler = MinMaxScaler()\n","        normalized_matrix = scaler.fit_transform(doc_term_matrix.toarray())\n","\n","        # VAE 모델 초기화 및 학습\n","        input_dim = doc_term_matrix.shape[1]\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        vae_model = VAE(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=num_topics).to(device)\n","        optimizer = torch.optim.Adam(vae_model.parameters(), lr=1e-3)\n","\n","        batch_size = 64\n","        data_loader = DataLoader(normalized_matrix.astype(np.float32), batch_size=batch_size, shuffle=True)\n","\n","        vae_model.train()\n","        for epoch in range(num_epochs):\n","            train_loss = 0\n","            for batch in data_loader:\n","                batch = batch.to(device)\n","                optimizer.zero_grad()\n","                recon_batch, mu, logvar = vae_model(batch)\n","                loss = vae_loss(recon_batch, batch, mu, logvar)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss += loss.item()\n","            logging.info(f\"에폭 {epoch+1}/{num_epochs}, 손실: {train_loss / len(data_loader.dataset):.4f}\")\n","\n","        topics = extract_vae_topics(vae_model, vectorizer, num_topics)\n","        return vae_model, topics\n","    except Exception as e:\n","        logging.error(f\"VAE 모델링 중 오류 발생: {e}\")\n","        return None, None\n","\n","def calculate_coherence(topics, tokenizer, bert_model):\n","    \"\"\"\n","    Calculate the coherence score for given topics using BERT embeddings.\n","\n","    Args:\n","    topics (list): List of topic word lists.\n","    tokenizer (BertTokenizer): BERT tokenizer.\n","    bert_model (BertModel): Pre-trained BERT model.\n","\n","    Returns:\n","    float: Average coherence score across all topics.\n","    \"\"\"\n","    coherence_scores = []\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    bert_model.to(device)\n","    bert_model.eval()\n","\n","    for topic_words in topics:\n","        inputs = tokenizer(topic_words, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","        with torch.no_grad():\n","            outputs = bert_model(**inputs)\n","        embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] 토큰의 임베딩 사용\n","\n","        num_words = len(topic_words)\n","        if num_words < 2:\n","            coherence_scores.append(0)\n","            continue\n","\n","        pairwise_similarities = []\n","        for i in range(num_words):\n","            for j in range(i + 1, num_words):\n","                cosine_sim = torch.nn.functional.cosine_similarity(embeddings[i], embeddings[j], dim=0)\n","                pairwise_similarities.append(cosine_sim.item())\n","\n","        coherence = np.mean(pairwise_similarities)\n","        coherence_scores.append(coherence)\n","\n","    final_coherence = np.mean(coherence_scores) if coherence_scores else 0\n","    return final_coherence\n","\n","def process_metrics(domain, model_type, topics, data, metrics_list, tokenizer, bert_model):\n","    tokenized_data = [simple_preprocess(doc) for doc in data]\n","    dictionary = Dictionary(tokenized_data)\n","    corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n","\n","    coherence = calculate_coherence(topics, tokenizer, bert_model)\n","    npmi = calculate_npmi(topics, corpus, dictionary)\n","    umass = calculate_umass(topics, corpus, dictionary)\n","\n","    metrics_list.append({\n","        'Domain': domain,\n","        'Model': model_type,\n","        'Coherence': coherence,\n","        'NPMI': npmi,\n","        'U_Mass': umass\n","    })\n","\n","    logging.info(f\"Coherence: {coherence:.4f}, NPMI: {npmi:.4f}, U_Mass: {umass:.4f}\")\n","    \n","    return [metrics_list[-1]]  # 마지막에 추가된 메트릭을 리스트로 반환\n","\n","def calculate_npmi(topics, corpus, dictionary, top_n=10):\n","    # 토픽에서 사용된 모든 단어의 집합 생성\n","    topic_words_set = set()\n","    for topic in topics:\n","        topic_words_set.update(topic[:top_n])\n","\n","    # 단어를 ID로 매핑\n","    word2id = {word: dictionary.token2id[word] for word in topic_words_set if word in dictionary.token2id}\n","    id2word = {id: word for word, id in word2id.items()}\n","\n","    # 단어와 단어 쌍의 문서 빈도 계산\n","    total_docs = len(corpus)\n","    word_doc_freq = defaultdict(int)\n","    pair_doc_freq = defaultdict(int)\n","\n","    for doc in corpus:\n","        doc_word_ids = set([id for id, _ in doc])\n","        topic_word_ids_in_doc = doc_word_ids.intersection(set(word2id.values()))\n","\n","        for word_id in topic_word_ids_in_doc:\n","            word_doc_freq[word_id] += 1\n","\n","        for word_id1, word_id2 in combinations(topic_word_ids_in_doc, 2):\n","            pair = tuple(sorted((word_id1, word_id2)))\n","            pair_doc_freq[pair] += 1\n","\n","    # NPMI 계산\n","    npmi_scores = []\n","    for topic in topics:\n","        topic_word_ids = [word2id[word] for word in topic[:top_n] if word in word2id]\n","        if len(topic_word_ids) < 2:\n","            continue\n","        pair_npmi_scores = []\n","        for word_id1, word_id2 in combinations(topic_word_ids, 2):\n","            pair = tuple(sorted((word_id1, word_id2)))\n","            co_doc_count = pair_doc_freq.get(pair, 0)\n","            if co_doc_count == 0:\n","                continue\n","            p_w1_w2 = co_doc_count / total_docs\n","            p_w1 = word_doc_freq[word_id1] / total_docs\n","            p_w2 = word_doc_freq[word_id2] / total_docs\n","\n","            pmi = np.log(p_w1_w2 / (p_w1 * p_w2) + 1e-12)\n","            npmi = pmi / (-np.log(p_w1_w2 + 1e-12))\n","            pair_npmi_scores.append(npmi)\n","        if pair_npmi_scores:\n","            npmi_scores.append(np.mean(pair_npmi_scores))\n","\n","    return np.mean(npmi_scores) if npmi_scores else float('nan')\n","\n","def calculate_umass(topics, corpus, dictionary, top_n=10):\n","    # 토픽에서 사용된 모든 단어의 집합 생성\n","    topic_words_set = set()\n","    for topic in topics:\n","        topic_words_set.update(topic[:top_n])\n","\n","    # 단어를 ID로 매핑\n","    word2id = {word: dictionary.token2id[word] for word in topic_words_set if word in dictionary.token2id}\n","\n","    # 단어와 단어 쌍의 빈도 계산\n","    word_counts = defaultdict(int)\n","    pair_counts = defaultdict(int)\n","\n","    for doc in corpus:\n","        doc_word_ids = set([id for id, _ in doc])\n","        topic_word_ids_in_doc = doc_word_ids.intersection(set(word2id.values()))\n","\n","        for word_id in topic_word_ids_in_doc:\n","            word_counts[word_id] += 1\n","\n","        for word_id1, word_id2 in combinations(topic_word_ids_in_doc, 2):\n","            pair = tuple(sorted((word_id1, word_id2)))\n","            pair_counts[pair] += 1\n","\n","    # U_Mass 계산\n","    umass_scores = []\n","    for topic in topics:\n","        topic_word_ids = [word2id[word] for word in topic[:top_n] if word in word2id]\n","        if len(topic_word_ids) < 2:\n","            continue\n","        pair_umass_scores = []\n","        for i, word_id1 in enumerate(topic_word_ids):\n","            for word_id2 in topic_word_ids[:i]:\n","                pair = tuple(sorted((word_id1, word_id2)))\n","                co_occurrence = pair_counts.get(pair, 0) + 1  # 스무딩을 위해 +1\n","                word2_count = word_counts[word_id2] + 1  # 스무딩을 위해 +1\n","                umass = np.log(co_occurrence / word2_count)\n","                pair_umass_scores.append(umass)\n","        if pair_umass_scores:\n","            umass_scores.append(np.mean(pair_umass_scores))\n","\n","    return np.mean(umass_scores) if umass_scores else float('nan')\n","\n","# 일치도 분석 함수 (계속)\n","def analyze_agreement(metrics_df):\n","    metrics = ['Coherence', 'NPMI', 'U_Mass']\n","    correlations = {}\n","    for i in range(len(metrics)):\n","        for j in range(i+1, len(metrics)):\n","            metric1, metric2 = metrics[i], metrics[j]\n","            spearman_corr, _ = stats.spearmanr(metrics_df[metric1], metrics_df[metric2])\n","            correlations[f'{metric1} vs {metric2}'] = spearman_corr\n","    \n","    print(\"\\n일치도 분석 결과 (Spearman 상관계수):\")\n","    for pair, corr in correlations.items():\n","        print(f\"{pair}: {corr:.4f}\")\n","    \n","    return correlations\n","\n","# 안정성 분석 함수\n","def analyze_stability(datasets, model_types, n_runs=10, sample_ratio=0.8):\n","    stability_results = []\n","    \n","    for domain, domain_datasets in datasets.items():\n","        # 각 도메인에서 첫 번째 데이터셋만 사용\n","        data = next(iter(domain_datasets.values()))\n","        \n","        logging.info(f\"Analyzing stability for domain: {domain}\")\n","        logging.info(f\"Original data type: {type(data)}\")\n","        \n","        # 데이터 형식 확인 및 변환\n","        if isinstance(data, pd.DataFrame):\n","            data = data['text'].tolist() if 'text' in data.columns else data.values.flatten().tolist()\n","        elif isinstance(data, pd.Series):\n","            data = data.tolist()\n","        elif isinstance(data, np.ndarray):\n","            data = data.flatten().tolist()\n","        elif isinstance(data, list):\n","            pass\n","        else:\n","            raise ValueError(f\"Unsupported data format for domain {domain}: {type(data)}\")\n","        \n","        logging.info(f\"Processed data type: {type(data)}\")\n","        logging.info(f\"Sample of processed data: {data[:5]}\")  # 처음 5개 항목 출력\n","        \n","        # BERTopic으로 초기 토픽 수 결정\n","        _, _, num_topics = perform_bertopic_modeling(data)\n","        \n","        for model_type in model_types:\n","            metric_values = {\n","                'Coherence': [],\n","                'NPMI': [],\n","                'U_Mass': []\n","            }\n","            \n","            for _ in range(n_runs):\n","                sampled_data = np.random.choice(data, size=int(len(data) * sample_ratio), replace=False)\n","                sampled_data = sampled_data.tolist()  # numpy array를 리스트로 변환\n","                \n","                logging.info(f\"Sampled data type: {type(sampled_data)}\")\n","                logging.info(f\"Sample of sampled data: {sampled_data[:5]}\")  # 처음 5개 항목 출력\n","                \n","                if model_type == 'BERTopic':\n","                    model, topics, _ = perform_bertopic_modeling(sampled_data)\n","                elif model_type == 'VAE':\n","                    model, topics = perform_vae_topic_modeling(sampled_data, num_topics)\n","                else:\n","                    raise ValueError(f\"Unsupported model type: {model_type}\")\n","                \n","                if model is None or topics is None:\n","                    logging.warning(f\"Model or topics is None for {model_type} in domain {domain}\")\n","                    continue\n","                \n","                tokenized_data = [simple_preprocess(doc) for doc in sampled_data]\n","                dictionary = Dictionary(tokenized_data)\n","                corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n","                \n","                coherence = calculate_coherence(topics, tokenizer, bert_model)\n","                npmi = calculate_npmi(topics, corpus, dictionary)\n","                umass = calculate_umass(topics, corpus, dictionary)\n","                \n","                metric_values['Coherence'].append(coherence)\n","                metric_values['NPMI'].append(npmi)\n","                metric_values['U_Mass'].append(umass)\n","            \n","            for metric, values in metric_values.items():\n","                cv = np.std(values) / np.mean(values) if np.mean(values) != 0 else float('nan')\n","                stability_results.append({\n","                    'Domain': domain,\n","                    'Model': model_type,\n","                    'Metric': metric,\n","                    'CV': cv\n","                })\n","    \n","    return pd.DataFrame(stability_results)\n","\n","# 개선된 토픽 품질 시각화 함수\n","def visualize_topic_quality(metrics_df):\n","        \n","    metrics = ['Coherence', 'NPMI', 'U_Mass']\n","    metrics_df = metrics_df.dropna(subset=metrics)\n","    \n","    scaler = StandardScaler()\n","    scaled_metrics = scaler.fit_transform(metrics_df[metrics])\n","    \n","    mds = MDS(n_components=2, random_state=42)\n","    mds_coords = mds.fit_transform(scaled_metrics)\n","    \n","    plt.figure(figsize=(12, 8))\n","    scatter = plt.scatter(mds_coords[:, 0], mds_coords[:, 1], \n","                          c=metrics_df['Coherence'], cmap='viridis', \n","                          s=50, alpha=0.6)\n","    plt.colorbar(scatter, label='Coherence')\n","    plt.title('MDS Visualization of Topic Quality')\n","    plt.xlabel('MDS Dimension 1')\n","    plt.ylabel('MDS Dimension 2')\n","    plt.savefig('mds_topic_quality.png')\n","    plt.close()\n","\n","    # 상관관계 히트맵\n","    corr_matrix = metrics_df[metrics].corr(method='spearman')\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n","    plt.title('Correlation Heatmap of Coherence Metrics')\n","    plt.tight_layout()\n","    plt.savefig('correlation_heatmap.png')\n","    plt.close()\n","\n","    # 지표별 토픽 순위 변화 그래프\n","    plt.figure(figsize=(12, 6))\n","    for metric in metrics:\n","        plt.plot(range(len(metrics_df)), metrics_df[metric].rank(ascending=False), label=metric)\n","    plt.xlabel('Topics')\n","    plt.ylabel('Rank')\n","    plt.title('Topic Ranks by Different Metrics')\n","    plt.legend()\n","    plt.savefig('topic_ranks_comparison.png')\n","    plt.close()\n","\n","    # 토픽 품질 분포 비교\n","    plt.figure(figsize=(12, 6))\n","    for metric in metrics:\n","        sns.kdeplot(metrics_df[metric], label=metric)\n","    plt.xlabel('Metric Value')\n","    plt.ylabel('Density')\n","    plt.title('Distribution of Topic Quality Metrics')\n","    plt.legend()\n","    plt.savefig('topic_quality_distribution.png')\n","    plt.close()\n","\n","def analyze_llm_results(llm_df):\n","    llm_df['LLM_Avg_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.mean([s for s in scores if s is not None]))\n","    llm_df['LLM_Std_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.std([s for s in scores if s is not None]))\n","    llm_df['LLM_Median_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.median([s for s in scores if s is not None]))\n","\n","    print(\"\\nLLM 평가 결과:\")\n","    print(llm_df[['Domain', 'Model', 'LLM_Avg_Score', 'LLM_Std_Score', 'LLM_Median_Score']])\n","\n","def llm_auto_metric_correlation(metrics_df, llm_df):\n","    merged_df = pd.merge(metrics_df, llm_df, on=['Domain', 'Model'])\n","\n","    metric_names = ['Coherence', 'NPMI', 'U_Mass']\n","    for metric in metric_names:\n","        valid_idx = merged_df['LLM_Avg_Score'].notnull()\n","        pearson_corr, p_value_pearson = stats.pearsonr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n","        spearman_corr, p_value_spearman = stats.spearmanr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n","        print(f\"\\nLLM 평가 점수와 {metric}의 상관관계:\")\n","        print(f\"Pearson: 상관계수 = {pearson_corr:.4f}, p-value = {p_value_pearson:.4f}\")\n","        print(f\"Spearman: 상관계수 = {spearman_corr:.4f}, p-value = {p_value_spearman:.4f}\")\n","\n","def verify_llm_consistency(topics, documents, n_repeats=5):\n","    all_scores = []\n","    for _ in range(n_repeats):\n","        scores, _ = llm_evaluation(topics, documents)\n","        all_scores.append(scores)\n","    all_scores = np.array(all_scores)\n","    std_scores = np.std(all_scores, axis=0)\n","    avg_std = np.mean(std_scores)\n","    cv_scores = std_scores / np.mean(all_scores, axis=0)\n","    avg_cv = np.mean(cv_scores)\n","    print(f\"\\nLLM 평가의 평균 표준편차: {avg_std:.4f}\")\n","    print(f\"LLM 평가의 평균 변동계수(CV): {avg_cv:.4f}\")\n","\n","def analyze_llm_feedback(llm_df):\n","    all_words = []\n","    for feedbacks in llm_df['LLM_Feedbacks']:\n","        for feedback in feedbacks:\n","            words = feedback.lower().split()\n","            all_words.extend([word for word in words if word not in stop_words])\n","\n","    word_freq = Counter(all_words)\n","    print(\"\\n피드백에서 가장 자주 등장하는 키워드:\")\n","    for word, count in word_freq.most_common(10):\n","        print(f\"{word}: {count}\")\n","\n","    coherence_keywords = ['coherent', 'consistent', 'related', 'connected', 'meaningful']\n","    print(\"\\n일관성 관련 키워드 빈도:\")\n","    for keyword in coherence_keywords:\n","        print(f\"{keyword}: {word_freq[keyword]}\")\n","\n","    positive_keywords = ['good', 'great', 'excellent', 'well', 'clear']\n","    negative_keywords = ['poor', 'bad', 'unclear', 'confusing', 'unrelated']\n","    \n","    positive_count = sum(word_freq[word] for word in positive_keywords)\n","    negative_count = sum(word_freq[word] for word in negative_keywords)\n","    \n","    print(f\"\\n긍정적 피드백 키워드 수: {positive_count}\")\n","    print(f\"부정적 피드백 키워드 수: {negative_count}\")\n","\n","    relationship_keywords = ['related', 'similar', 'overlapping', 'connected', 'distinct']\n","    print(\"\\n토픽 간 관계 관련 키워드 빈도:\")\n","    for keyword in relationship_keywords:\n","        print(f\"{keyword}: {word_freq[keyword]}\")\n","\n","    quality_keywords = ['coherent', 'meaningful', 'interpretable', 'clear', 'specific']\n","    print(\"\\n토픽 품질 관련 키워드 빈도:\")\n","    for keyword in quality_keywords:\n","        print(f\"{keyword}: {word_freq[keyword]}\")\n","\n","    scores = [score for scores in llm_df['LLM_Scores'] for score in scores if score is not None]\n","    print(\"\\n일관성 점수 분포:\")\n","    print(f\"평균: {np.mean(scores):.2f}\")\n","    print(f\"중앙값: {np.median(scores):.2f}\")\n","    print(f\"표준편차: {np.std(scores):.2f}\")\n","    print(f\"최소값: {np.min(scores):.2f}\")\n","    print(f\"최대값: {np.max(scores):.2f}\")\n","\n","    print(\"\\n모델별 평균 일관성 점수:\")\n","    for model in llm_df['Model'].unique():\n","        model_scores = [score for scores, m in zip(llm_df['LLM_Scores'], llm_df['Model']) \n","                        for score in scores if score is not None and m == model]\n","        print(f\"{model}: {np.mean(model_scores):.2f}\")\n","\n","def visualize_llm_results(llm_df):\n","    plt.figure(figsize=(12, 6))\n","    sns.boxplot(x='Model', y='LLM_Avg_Score', data=llm_df)\n","    plt.title('모델별 LLM 평가 점수 분포')\n","    plt.savefig('llm_model_score_distribution.png')\n","    plt.close()\n","\n","    plt.figure(figsize=(12, 6))\n","    sns.scatterplot(x='Model', y='LLM_Avg_Score', data=llm_df)\n","    plt.title('모델별 LLM 평가 점수')\n","    plt.legend()\n","    plt.savefig('llm_model_score.png')\n","    plt.close()\n","\n","\n","def evaluate_coherence_stability(models, domains, datasets, n_runs=5):\n","    stability_results = []\n","    \n","    for model in models:\n","        for domain, data in zip(domains, datasets):\n","            # data가 딕셔너리인 경우 적절히 처리\n","            if isinstance(data, dict):\n","                data = list(data.values())[0]\n","            elif isinstance(data, pd.DataFrame):\n","                data = data['text'].tolist()\n","            elif not isinstance(data, list):\n","                raise ValueError(f\"Unsupported data format for domain {domain}\")\n","\n","            coherence_scores = []\n","            npmi_scores = []\n","            umass_scores = []\n","\n","            for _ in range(n_runs):\n","                # 데이터 샘플링 (예: 80%의 데이터 사용)\n","                sampled_data = np.random.choice(data, size=int(len(data) * 0.8), replace=False)\n","\n","                if model == 'BERTopic':\n","                    _, topics, _ = perform_bertopic_modeling(sampled_data)\n","                elif model == 'VAE':\n","                    _, topics = perform_vae_topic_modeling(sampled_data, num_topics=10)  # num_topics는 적절히 조정\n","                else:\n","                    raise ValueError(f\"Unsupported model type: {model}\")\n","\n","                # 토큰화된 데이터 준비\n","                tokenized_data = [simple_preprocess(doc) for doc in sampled_data]\n","                dictionary = Dictionary(tokenized_data)\n","                corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n","\n","                # 일관성 메트릭 계산\n","                coherence = calculate_coherence(topics, tokenizer, bert_model)\n","                npmi = calculate_npmi(topics, corpus, dictionary)\n","                umass = calculate_umass(topics, corpus, dictionary)\n","\n","                coherence_scores.append(coherence)\n","                npmi_scores.append(npmi)\n","                umass_scores.append(umass)\n","\n","            # 안정성 계산 (변동 계수 사용)\n","            coherence_stability = np.std(coherence_scores) / np.mean(coherence_scores)\n","            npmi_stability = np.std(npmi_scores) / np.mean(npmi_scores)\n","            umass_stability = np.std(umass_scores) / np.mean(umass_scores)\n","\n","            stability_results.append({\n","                'Model': model,\n","                'Domain': domain,\n","                'Coherence_Stability': coherence_stability,\n","                'NPMI_Stability': npmi_stability,\n","                'UMass_Stability': umass_stability,\n","                'Mean_Coherence': np.mean(coherence_scores),\n","                'Mean_NPMI': np.mean(npmi_scores),\n","                'Mean_UMass': np.mean(umass_scores)\n","            })\n","\n","    return pd.DataFrame(stability_results)\n","\n","def print_results(metrics_df, agreement_results, stability_df, stability_results):\n","    logging.info(\"\\n=== 결과 분석 ===\")\n","    \n","    # 모델별 성능 평가에서 지표 간 평가의 차이 분석 \n","    logging.info(\"\\n모델별 지표 평균 성능:\")\n","    logging.info(metrics_df.groupby('Model')[['Coherence', 'NPMI', 'U_Mass']].mean())\n","    logging.info(\"\\n도메인별 지표 평균 성능:\")\n","    logging.info(metrics_df.groupby('Domain')[['Coherence', 'NPMI', 'U_Mass']].mean())\n","\n","    # 지표 간 상관관계 분석을 통해 새로운 지표의 새로운 영역 측정 가능성 판단 \n","    logging.info(\"\\n 지표 간 일치도 분석 결과 (Spearman 상관계수):\")\n","    for pair, corr in agreement_results.items():\n","        logging.info(f\"{pair}: {corr:.4f}\")\n","    \n","    # 일관성 지표가 안정적으로 측정되는지 확인 \n","    logging.info(\"\\n일관성지표 안정성 개별 결과:\")\n","    logging.info(stability_results)\n","    logging.info(\"\\n 일관성지표 안정성 전체 결과:\")\n","    logging.info(stability_df.groupby(['Model', 'Metric'])['CV'].mean())\n","\n","    logging.info(\"\\n분석 완료. 결과를 확인하고 해석하세요.\")\n","\n","def process_datasets(datasets):\n","    all_metrics = []\n","    bertopic_results = {}\n","    vae_results = {}\n","    \n","    for domain, domain_datasets in datasets.items():\n","        for dataset_name, data in domain_datasets.items():\n","            # BERTopic 모델링\n","            bertopic_model, bertopic_topics, num_topics = perform_bertopic_modeling(data)\n","            bertopic_results[domain] = {\n","                'num_topics': num_topics,\n","                'topics': bertopic_topics\n","            }\n","            \n","            # BERTopic 메트릭 계산\n","            bertopic_metrics = process_metrics(domain, 'BERTopic', bertopic_topics, data, [], tokenizer, bert_model)\n","            all_metrics.extend(bertopic_metrics)\n","            \n","            # VAE 모델링\n","            vae_model, vae_topics = perform_vae_topic_modeling(data, num_topics)\n","            vae_results[domain] = {\n","                'num_topics': num_topics,  # VAE는 BERTopic의 토픽 수를 사용합니다\n","                'topics': vae_topics\n","            }\n","            \n","            # VAE 메트릭 계산\n","            vae_metrics = process_metrics(domain, 'VAE', vae_topics, data, [], tokenizer, bert_model)\n","            all_metrics.extend(vae_metrics)\n","    \n","    return all_metrics, bertopic_results, vae_results\n","\n","def main():\n","    try:\n","        logging.info(\"데이터셋 로딩 시작\")\n","        datasets = load_all_datasets()\n","        \n","        logging.info(\"토픽 모델링 및 메트릭 계산 시작\")\n","        all_metrics, bertopic_topics = process_datasets(datasets)\n","        \n","        logging.info(\"BERTopic 결과 출력\")\n","        for domain, result in bertopic_results.items():\n","            print(f\"\\n도메인: {domain}\")\n","            print(f\"BERTopic 토픽 수: {result['num_topics']}\")\n","            print(\"BERTopic 토픽:\")\n","            for i, topic in enumerate(result['topics']):\n","                print(f\"  토픽 {i+1}: {', '.join(topic[:10])}\")  # 각 토픽의 상위 10개 단어만 출력\n","        \n","        logging.info(\"\\nVAE 결과 출력\")\n","        for domain, result in vae_results.items():\n","            print(f\"\\n도메인: {domain}\")\n","            print(f\"VAE 토픽 수: {result['num_topics']}\")\n","            print(\"VAE 토픽:\")\n","            for i, topic in enumerate(result['topics']):\n","                print(f\"  토픽 {i+1}: {', '.join(topic[:10])}\")  # 각 토픽의 상위 10개 단어만 출력\n","        \n","        logging.info(\"메트릭 분석 시작\")\n","        metrics_df = pd.DataFrame(all_metrics)\n","        metrics_df.to_csv('topic_modeling_metrics.csv', index=False)\n","        \n","        logging.info(\"일치도 분석 시작\")\n","        agreement_results = analyze_agreement(metrics_df)\n","        \n","        logging.info(\"안정성 분석 시작\")\n","        stability_df = analyze_stability(datasets, ['BERTopic', 'VAE'])\n","        \n","        logging.info(\"토픽 품질 시각화 시작\")\n","        visualize_topic_quality(metrics_df)\n","        \n","        logging.info(\"일관성 안정성 평가 시작\")\n","        stability_results = evaluate_coherence_stability(['BERTopic', 'VAE'], list(datasets.keys()), list(datasets.values()))\n","        \n","        logging.info(\"결과 출력 시작\")\n","        print_results(metrics_df, agreement_results, stability_df, stability_results)\n","        \n","        logging.info(\"모든 분석 완료\")\n","    except Exception as e:\n","        logging.error(f\"메인 함수 실행 중 예상치 못한 오류 발생: {e}\")\n","        raise\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Cell 2: LLM 평가 관련 함수와 실행 코드\n","\n","import openai\n","from tenacity import retry, stop_after_attempt, wait_random_exponential\n","\n","@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))\n","def call_openai_api(prompt: str, max_tokens: int = 3000) -> str:\n","    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","    full_response = \"\"\n","    while True:\n","        try:\n","            response = openai.ChatCompletion.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\n","                        \"role\": \"system\",\n","                        \"content\": \"You are an expert in topic modeling and text analysis. Your task is to evaluate the coherence of topics based on provided documents.\"\n","                    },\n","                    {\n","                        \"role\": \"user\",\n","                        \"content\": prompt + (\"\\n\\nContinue from: \" + full_response if full_response else \"\")\n","                    }\n","                ],\n","                temperature=0,\n","                max_tokens=max_tokens,\n","                top_p=1,\n","                frequency_penalty=0.1,\n","                presence_penalty=0.1,\n","            )\n","            chunk = response.choices[0].message['content']\n","            full_response += chunk\n","\n","            if response.choices[0].finish_reason != \"length\":\n","                break\n","\n","            prompt = \"Continue the previous response:\"\n","        except openai.error.RateLimitError:\n","            print(\"Rate limit exceeded. Retrying...\")\n","            time.sleep(60)\n","        except openai.error.AuthenticationError:\n","            print(\"Authentication error. Check your API key.\")\n","            raise\n","        except Exception as e:\n","            print(f\"Unexpected error: {e}\")\n","            raise\n","\n","    return full_response\n","\n","def llm_evaluation(topics, documents, model=\"gpt-4o-mini\"):\n","    scores = []\n","    feedbacks = []\n","\n","    if not isinstance(documents, list):\n","        documents = list(documents)\n","\n","    prompt = f\"\"\"\n","Evaluate the following topics based on their coherence. Coherence is an important metric for assessing the quality of topic modeling:\n","\n","1. Coherence measures how semantically related the words within each topic are.\n","2. It is typically calculated by considering the co-occurrence probabilities of word pairs within the topic.\n","3. Higher coherence scores indicate that the words in a topic are closely related and form a meaningful theme.\n","4. Lower coherence scores suggest that the topic may be less meaningful or coherent.\n","\n","Please evaluate the following topics. For each topic, provide a coherence score on a scale of 1-10 and explain your reasoning:\n","\n","{topics}\n","\n","When evaluating, consider:\n","1. How semantically related are the words within each topic?\n","2. How clear and interpretable is the topic?\n","3. Do the words in the topic represent a consistent theme or concept?\n","\n","Please respond for each topic in the following format:\n","Topic X: [score]\n","Reason: [explanation]\n","\"\"\"\n","\n","    try:\n","        evaluation = call_openai_api(prompt)\n","\n","        # Updated parsing logic to extract structured responses\n","        topic_evaluations = re.findall(r\"Topic \\d+:.*?(?=Topic \\d+:|$)\", evaluation, re.DOTALL)\n","        for eval in topic_evaluations:\n","            score_match = re.search(r'Topic (\\d+):\\s*(\\d+)', eval)\n","            reason_match = re.search(r'Reason:\\s*(.*)', eval, re.DOTALL)\n","            if score_match and reason_match:\n","                topic_score = int(score_match.group(2))\n","                if 1 <= topic_score <= 10:\n","                    scores.append(topic_score)\n","                    feedbacks.append(reason_match.group(1).strip())\n","                else:\n","                    print(f\"Invalid score (not between 1 and 10): {eval}\")\n","            else:\n","                print(f\"Could not extract score or reason: {eval}\")\n","\n","    except Exception as e:\n","        print(f\"Unexpected error: {e}\")\n","        raise\n","\n","    return scores, feedbacks\n","\n","def run_llm_evaluation(metrics_df, datasets, sample_size=100, chunk_size=10):\n","    llm_results = []\n","    actual_sample_size = min(sample_size, len(metrics_df))\n","    \n","    for index, row in tqdm(metrics_df.sample(n=actual_sample_size, random_state=42).iterrows(), total=actual_sample_size):\n","        domain = row['Domain']\n","        model_type = row['Model']\n","        \n","        logging.info(f\"LLM 평가 진행 중 - 도메인: {domain}, 모델: {model_type}\")\n","\n","        try:\n","            # 각 도메인에서 첫 번째 데이터셋만 사용\n","            data = next(iter(datasets[domain].values()))\n","            \n","            if model_type == 'BERTopic':\n","                model, topics, num_topics = perform_bertopic_modeling(data)\n","            elif model_type == 'VAE':\n","                # num_topics는 BERTopic에서 생성된 토픽 수를 사용\n","                model, topics = perform_vae_topic_modeling(data, num_topics)\n","            else:\n","                continue\n","            \n","            scores, feedbacks = llm_evaluation(topics, data)\n","\n","            result = {\n","                'Domain': domain,\n","                'Model': model_type,\n","                'LLM_Scores': scores,\n","                'LLM_Feedbacks': feedbacks\n","            }\n","            llm_results.append(result)\n","\n","            if len(llm_results) % chunk_size == 0:\n","                save_results_chunk(llm_results[-chunk_size:])\n","                \n","        except Exception as e:\n","            logging.error(f\"Error processing {domain} - {model_type}: {str(e)}\")\n","            continue\n","\n","    if len(llm_results) % chunk_size != 0:\n","        save_results_chunk(llm_results[-(len(llm_results) % chunk_size):])\n","\n","    llm_df = pd.DataFrame(llm_results)\n","    return llm_df\n","\n","def save_results_chunk(results_chunk):\n","    with open('llm_evaluation_results.json', 'a') as f:\n","        for result in results_chunk:\n","            json.dump(result, f)\n","            f.write('\\n')\n","\n","# LLM 평가 실행\n","logging.info(\"LLM 평가 시작\")\n","metrics_df = pd.read_csv('topic_modeling_metrics.csv')\n","\n","# datasets 재로드\n","datasets = load_all_datasets()\n","\n","# bertopic_topics 재생성\n","_, bertopic_topics = process_datasets(datasets)\n","\n","llm_df = run_llm_evaluation(metrics_df, datasets)\n","analyze_llm_results(llm_df)\n","visualize_llm_results(llm_df)\n","\n","logging.info(\"LLM 평가와 자동 메트릭 상관관계 분석 시작\")\n","llm_auto_metric_correlation(metrics_df, llm_df)\n","\n","logging.info(\"LLM 평가 일관성 검증 시작\")\n","verify_llm_consistency(bertopic_topics, next(iter(datasets.values()))[0])\n","\n","logging.info(\"LLM 피드백 분석 시작\")\n","analyze_llm_feedback(llm_df)\n","\n","logging.info(\"LLM 평가 완료\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN1HMc8DJjEA0c4VoVpICAu","gpuType":"T4","mount_file_id":"1A2KBLTvWLDpZRfvqTW6X-K99HG5QCvQ-","provenance":[]},"kernelspec":{"display_name":"topic","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
