{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1063,"status":"ok","timestamp":1727057748640,"user":{"displayName":"이석민","userId":"04944220183600189812"},"user_tz":-540},"id":"V3SgyTuekJk0"},"outputs":[],"source":["# 필요한 모듈 import\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import gensim\n","from gensim import models, corpora, matutils\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.cluster import KMeans\n","from gensim.models.coherencemodel import CoherenceModel \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import openai\n","import os\n","import re\n","import json\n","import time\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from scipy.stats import pearsonr, spearmanr, f_oneway, kruskal\n","from tenacity import retry, stop_after_attempt, wait_random_exponential\n","from bertopic import BERTopic\n","from transformers import BertTokenizer, BertModel \n","from math import log\n","from itertools import combinations\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터셋 선정 함수\n","\n","def load_data(file_path, sample_size=80):\n","    df = pd.read_csv(file_path, header=None, names=['text'])\n","    texts = df['text'].astype(str)\n","\n","    # 샘플링\n","    if len(texts) > sample_size:\n","        texts = texts.sample(n=sample_size, random_state=42)\n","\n","    print(f\"Loaded {len(texts)} texts from {file_path}\")\n","    return texts.tolist()\n","\n","\n","# 데이터셋 로드\n","datasets = {\n","    'academy': {\n","        'business': load_data('data/academy/business.csv'),\n","        'ACL': load_data('data/academy/ACL.csv'),\n","        'covid': load_data('data/academy/covid.csv')\n","    },\n","    'media': {\n","        'clothing_review': load_data('data/media/clothing_review.csv'),\n","        'vaccine_tweets': load_data('data/media/vaccine_tweets.csv'),\n","        'reddit_comments': load_data('data/media/reddit_comments.csv')\n","    },\n","    'news': {\n","        'newsgroups': load_data('data/news/20newsgroups.csv'),\n","        'agnews': load_data('data/news/agnews.csv'),\n","        'Huffpost': load_data('data/news/Huffpost.csv')\n","    }\n","}\n","\n","\n","# VAE 모델 정의\n","class VAE(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, latent_dim):\n","        super(VAE, self).__init__()\n","\n","        # Encoder\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc21 = nn.Linear(hidden_dim, latent_dim)\n","        self.fc22 = nn.Linear(hidden_dim, latent_dim)\n","\n","        # Decoder\n","        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n","        self.fc4 = nn.Linear(hidden_dim, input_dim)\n","\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5*logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps*std\n","\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.sigmoid(self.fc4(h3))  # Changed to sigmoid\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","\n","def vae_loss(recon_x, x, mu, logvar):\n","    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    return BCE + KLD\n","\n","\n","def perform_topic_modeling(data, num_topics, model_type):\n","    # Ensure all data is of type string\n","    data = [str(doc) for doc in data if isinstance(doc, str) or pd.notna(doc)]\n","\n","    # Check if num_topics is greater than the number of documents\n","    if num_topics > len(data):\n","        print(f\"Adjusting num_topics from {num_topics} to {len(data)}\")\n","        num_topics = len(data)  # Adjust to the number of documents\n","\n","    # Common vectorizer\n","    vectorizer = CountVectorizer(max_df=0.95, min_df=1, stop_words='english')\n","    doc_term_matrix = vectorizer.fit_transform(data)\n","\n","    # GPU usage setting\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    if model_type == 'LDA':\n","        # Create corpus and dictionary for LDA\n","        corpus = matutils.Sparse2Corpus(doc_term_matrix, documents_columns=False)\n","        id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n","\n","        # Create LDA model\n","        lda_model = models.LdaMulticore(\n","            corpus=corpus,\n","            id2word=id2word,\n","            num_topics=num_topics,\n","            workers=2,  # Number of cores to use\n","            passes=10,\n","            random_state=42\n","        )\n","\n","        return lda_model, vectorizer\n","\n","    elif model_type == 'BERTopic':\n","        # Create BERTopic model\n","        bertopic_model = BERTopic(nr_topics=num_topics)\n","        \n","        # Ensure documents is a Series\n","        if not isinstance(data, pd.Series):\n","            data = pd.Series(data)\n","        \n","        bertopic_topics, _ = bertopic_model.fit_transform(data)\n","\n","        return bertopic_model, None  # BERTopic uses its own vectorizer\n","\n","    elif model_type == 'VAE':\n","        # VAE part\n","        input_dim = doc_term_matrix.shape[1]\n","        hidden_dim = 256\n","        latent_dim = num_topics\n","\n","        vae_model = VAE(input_dim, hidden_dim, latent_dim).to(device)\n","        optimizer = torch.optim.Adam(vae_model.parameters(), lr=1e-3)\n","\n","        # VAE training\n","        num_epochs = 2  # 10\n","        batch_size = 128\n","\n","        for epoch in range(num_epochs):\n","            for i in range(0, doc_term_matrix.shape[0], batch_size):\n","                batch = torch.FloatTensor(doc_term_matrix[i:i+batch_size].toarray()).to(device)\n","                batch = batch / batch.max()  # Normalize batch to between 0 and 1\n","\n","                optimizer.zero_grad()\n","                recon_batch, mu, logvar = vae_model(batch)\n","                loss = vae_loss(recon_batch, batch, mu, logvar)\n","                loss.backward()\n","                optimizer.step()\n","\n","        # Extract topic words from latent vectors\n","        from sklearn.cluster import KMeans\n","\n","        latent_vectors = []\n","        doc_term_matrix = vectorizer.transform(data)\n","        with torch.no_grad():\n","            for i in range(0, doc_term_matrix.shape[0], 128):\n","                batch = torch.FloatTensor(doc_term_matrix[i:i+128].toarray()).to(device)\n","                mu, logvar = vae_model.encode(batch)\n","                z = vae_model.reparameterize(mu, logvar)\n","                latent_vectors.append(z.cpu().numpy())\n","\n","        latent_vectors = np.vstack(latent_vectors)\n","        kmeans = KMeans(n_clusters=num_topics, random_state=42).fit(latent_vectors)\n","\n","        topics = [[] for _ in range(num_topics)]\n","        for idx, label in enumerate(kmeans.labels_):\n","            doc = data[idx]\n","            topics[label].extend(doc.split())\n","\n","        # Extract top 10 words for each topic\n","        topics = [list(pd.Series(words).value_counts().index[:10]) for words in topics]\n","\n","        # Return VAE model, vectorizer, and topic words\n","        return vae_model, vectorizer, topics\n","\n","\n","# 평가 지표 계산 함수들 \n","def calculate_npmi(topic_words_with_weights, texts, top_n=10):\n","    # 단어들만 추출하고, 문자열인지 확인\n","    topic_words = [word for word, _ in topic_words_with_weights[:top_n] if isinstance(word, str)]\n","    \n","    if not topic_words:\n","        return 0  # 토픽 단어가 없으면 0 반환\n","\n","    vectorizer = CountVectorizer(vocabulary=topic_words)\n","    doc_word_matrix = vectorizer.fit_transform(texts)\n","    \n","    word_doc_counts = doc_word_matrix.sum(axis=0).A1  # 각 단어의 문서 내 등장 횟수\n","    doc_count = len(texts)\n","    \n","    npmi_scores = []\n","    for i, word1 in enumerate(topic_words):\n","        for j, word2 in enumerate(topic_words):\n","            if i < j:\n","                idx1 = i\n","                idx2 = j\n","                co_doc_count = doc_word_matrix[:, idx1].multiply(doc_word_matrix[:, idx2]).nnz\n","                if co_doc_count == 0:\n","                    continue  # 공출현 빈도가 0이면 건너뜁니다.\n","\n","                p_w1 = word_doc_counts[idx1] / doc_count\n","                p_w2 = word_doc_counts[idx2] / doc_count\n","                p_w1_w2 = co_doc_count / doc_count\n","\n","                pmi = log(p_w1_w2 / (p_w1 * p_w2) + 1e-12)\n","                npmi = pmi / (-log(p_w1_w2 + 1e-12))\n","                npmi_scores.append(npmi)\n","\n","    if npmi_scores:\n","        return np.mean(npmi_scores)\n","    else:\n","        return 0  # 계산된 NPMI 점수가 없으면 0 반환\n","\n","def calculate_cv(topic_words_with_weights, texts, top_n=10):\n","    # 단어들만 추출하고, 문자열인지 확인\n","    topic_words = [word for word, _ in topic_words_with_weights[:top_n] if isinstance(word, str)]\n","    \n","    if not topic_words:\n","        return 0  # 토픽 단어가 없으면 0 반환\n","\n","    # 각 단어의 컨텍스트 벡터를 구하기 위해 모든 문서에 대해 단어-문서 행렬을 생성합니다.\n","    vectorizer = CountVectorizer()\n","    doc_word_matrix = vectorizer.fit_transform(texts)\n","    vocabulary = vectorizer.get_feature_names_out()\n","    word2id = {word: idx for idx, word in enumerate(vocabulary)}\n","\n","    total_documents = len(texts)\n","    word_doc_counts = doc_word_matrix.toarray().sum(axis=0)\n","\n","    # NPMI 행렬 계산\n","    npmi_matrix = np.zeros((len(topic_words), len(topic_words)))\n","    for i, word1 in enumerate(topic_words):\n","        for j, word2 in enumerate(topic_words):\n","            if i <= j:\n","                continue  # 대각선 및 대칭 행렬이므로 절반만 계산\n","\n","            idx1 = word2id.get(word1)\n","            idx2 = word2id.get(word2)\n","\n","            if idx1 is None or idx2 is None:\n","                continue  # 단어가 사전에 없으면 건너뜁니다.\n","\n","            co_occur_count = doc_word_matrix[:, idx1].multiply(doc_word_matrix[:, idx2]).nnz\n","            if co_occur_count == 0:\n","                continue  # 공출현 빈도가 0이면 건너뜁니다.\n","\n","            p_w1 = word_doc_counts[idx1] / total_documents\n","            p_w2 = word_doc_counts[idx2] / total_documents\n","            p_w1_w2 = co_occur_count / total_documents\n","\n","            pmi = log(p_w1_w2 / (p_w1 * p_w2) + 1e-12)\n","            npmi = pmi / (-log(p_w1_w2 + 1e-12))\n","            npmi_matrix[i, j] = npmi\n","\n","    # Coherence 점수 계산\n","    cv_scores = []\n","    for i in range(len(topic_words)):\n","        for j in range(len(topic_words)):\n","            if i <= j:\n","                continue  # 대각선 및 대칭 행렬이므로 절반만 사용\n","            npmi_value = npmi_matrix[i, j]\n","            if npmi_value != 0:\n","                cv_scores.append(npmi_value)\n","\n","    if cv_scores:\n","        return np.mean(cv_scores)\n","    else:\n","        return 0  # 계산된 C_V 점수가 없으면 0 반환\n","\n","def calculate_coherence(model, data, tokenizer, bert_model, model_type, vectorizer=None, num_topics=10, topics=None):\n","    coherence_scores = []\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    if model_type == 'LDA':\n","        topics = []\n","        for i in range(num_topics):\n","            topic_terms = model.show_topic(i, topn=10)\n","            topic_words = [word for word, _ in topic_terms]\n","            topics.append(topic_words)\n","\n","    elif model_type == 'BERTopic':\n","        topics = []\n","        for i in range(num_topics):\n","            topic_info = model.get_topic(i)\n","            if topic_info:\n","                topic_words = [word for word, _ in topic_info]\n","                topics.append(topic_words)\n","\n","    elif model_type == 'VAE':\n","        # VAE의 경우 이미 추출한 토픽 단어를 사용\n","        topics = topics\n","    else:\n","        raise ValueError(\"Invalid model type\")\n","\n","    for topic_words in topics:\n","        # 토픽 단어들을 문장 형태로 변환하여 문맥을 고려한 임베딩 계산\n","        sentences = [\"The topic is about \" + word for word in topic_words]\n","        inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","\n","        with torch.no_grad():\n","            outputs = bert_model(**inputs)\n","\n","        # 문장 임베딩은 last_hidden_state의 [CLS] 토큰 벡터 사용\n","        sentence_embeddings = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n","\n","        # 단어 쌍의 조합 생성 (중복 없이)\n","        pairs = list(combinations(range(len(topic_words)), 2))\n","\n","        if not pairs:\n","            coherence_scores.append(0)\n","            continue\n","\n","        # 코사인 유사도 계산\n","        embeddings1 = sentence_embeddings[[i for i, j in pairs]]\n","        embeddings2 = sentence_embeddings[[j for i, j in pairs]]\n","        cosine_similarities = torch.nn.functional.cosine_similarity(embeddings1, embeddings2, dim=1)\n","\n","        # coherence 점수는 코사인 유사도의 평균값\n","        coherence = cosine_similarities.mean().item()\n","        coherence_scores.append(coherence)\n","\n","    if coherence_scores:\n","        return np.mean(coherence_scores)\n","    else:\n","        return 0\n","\n","def calculate_evaluation_metrics(model, data, model_type, vectorizer, num_topics, topics=None):\n","    # BERT 모델 로드\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    bert_model = BertModel.from_pretrained('bert-base-uncased')\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    bert_model = bert_model.to(device)\n","\n","    # Coherence 계산\n","    coherence = calculate_coherence(model, data, tokenizer, bert_model, model_type, vectorizer, num_topics, topics)\n","\n","    # NPMI 계산\n","    if model_type == 'LDA':\n","        topic_words_with_weights = model.show_topic(0, topn=10)\n","    elif model_type == 'BERTopic':\n","        topic_words_with_weights = model.get_topic(0)\n","    elif model_type == 'VAE':\n","        topic_words_with_weights = [(word, 1.0) for word in topics[0]]  # 첫 번째 토픽 사용\n","    else:\n","        topic_words_with_weights = []\n","\n","    npmi = calculate_npmi(topic_words_with_weights, data)\n","\n","    # C_V 계산\n","    cv = calculate_cv(topic_words_with_weights, data)\n","\n","    return coherence, npmi, cv\n","\n","# BERT 모델 로드\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained('bert-base-uncased')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","bert_model = bert_model.to(device)\n","\n","# 평가 지표 결과 저장을 위한 데이터프레임 초기화\n","metrics_list = []\n","\n","# 계산 시간 저장을 위한 딕셔너리 초기화\n","computation_times = {}\n","\n","# 모델 유형 및 토픽 수 설정\n","model_types = ['LDA', 'BERTopic', 'VAE']\n","\n","# 토픽 수를 2와 4로 고정\n","num_topics_list = [2, 4]\n","\n","# 계산 시간 저장을 위한 딕셔너리 초기화\n","computation_times = {}\n","\n","def get_top_words(model, vectorizer, num_words=5):\n","    if isinstance(model, models.LdaMulticore):\n","        return [dict(model.show_topic(topicid, topn=num_words)) for topicid in range(2)]\n","    elif isinstance(model, BERTopic):\n","        return [dict(model.get_topic(i)[:num_words]) for i in range(2)]\n","    elif isinstance(model, VAE):\n","        # VAE의 경우, 디코더의 가중치를 사용하여 단어의 중요도를 계산\n","        feature_names = vectorizer.get_feature_names_out()\n","        word_importance = model.fc4.weight.data.cpu().numpy()\n","        top_words = []\n","        for i in range(2):\n","            top_indices = word_importance[i].argsort()[-num_words:][::-1]\n","            top_words.append({feature_names[j]: word_importance[i][j] for j in top_indices})\n","        return top_words\n","\n","def process_datasets(datasets):\n","    results = []\n","    for category, category_datasets in datasets.items():\n","        for dataset_name, data in category_datasets.items():\n","            print(f\"Processing {category} - {dataset_name}\")\n","            for model_type in ['LDA', 'BERTopic', 'VAE']:\n","                try:\n","                    model, vectorizer = perform_topic_modeling(data, num_topics=2, model_type=model_type)\n","                    top_words = get_top_words(model, vectorizer)\n","                    for topic_id, words in enumerate(top_words):\n","                        results.append({\n","                            'Category': category,\n","                            'Dataset': dataset_name,\n","                            'Model': model_type,\n","                            'Topic': f'Topic {topic_id + 1}',\n","                            'Words': ', '.join(list(words.keys()))\n","                        })\n","                except Exception as e:\n","                    print(f\"Error processing {category} - {dataset_name} - {model_type}: {str(e)}\")\n","    return pd.DataFrame(results)\n","\n","if __name__ == '__main__':\n","    # 토픽 모델링 및 지표 계산\n","    for domain, domain_datasets in datasets.items():\n","        for dataset_name, data in domain_datasets.items():\n","            print(f\"\\nProcessing {domain} - {dataset_name}\")\n","            for model_type in model_types:\n","                for num_topics in num_topics_list:\n","                    print(f\"\\nModel: {model_type}, Num Topics: {num_topics}\")\n","                    try:\n","                        start_time = time.time()\n","                        if model_type == 'VAE':\n","                            model, vectorizer, topics = perform_topic_modeling(data, num_topics, model_type)\n","                        else:\n","                            model, vectorizer = perform_topic_modeling(data, num_topics, model_type)\n","                            topics = None  # VAE가 아닌 경우\n","                        topic_modeling_time = time.time() - start_time\n","\n","                        start_time = time.time()\n","                        coherence = calculate_coherence(model, data, tokenizer, bert_model, model_type, vectorizer, num_topics, topics)\n","                        coherence_time = time.time() - start_time\n","\n","                        # 토픽 단어 및 가중치 추출\n","                        if model_type == 'LDA':\n","                            topic_words_with_weights = model.show_topic(0, topn=10)\n","                        elif model_type == 'BERTopic':\n","                            topic_words_with_weights = model.get_topic(0)\n","                        elif model_type == 'VAE':\n","                            # VAE의 경우 추출한 토픽 단어를 사용\n","                            topic_words_with_weights = [(word, 1.0) for word in topics[0]]  # 첫 번째 토픽 사용\n","                        else:\n","                            topic_words_with_weights = []\n","\n","                        start_time = time.time()\n","                        npmi = calculate_npmi(topic_words_with_weights, data)\n","                        npmi_time = time.time() - start_time\n","\n","                        start_time = time.time()\n","                        cv = calculate_cv(topic_words_with_weights, data)\n","                        cv_time = time.time() - start_time\n","\n","                        # 결과 저장\n","                        metrics_list.append({\n","                            'Domain': domain,\n","                            'Dataset': dataset_name,\n","                            'Model': model_type,\n","                            'Num_Topics': num_topics,\n","                            'Coherence': coherence,\n","                            'NPMI': npmi,\n","                            'C_V': cv\n","                        })\n","\n","                        computation_times[f\"{domain}_{dataset_name}_{model_type}_{num_topics}\"] = {\n","                            'Topic Modeling': topic_modeling_time,\n","                            'Coherence': coherence_time,\n","                            'NPMI': npmi_time,\n","                            'C_V': cv_time\n","                        }\n","\n","                        print(f\"Coherence: {coherence:.4f}\")\n","                        print(f\"NPMI: {npmi:.4f}\")\n","                        print(f\"C_V: {cv:.4f}\")\n","\n","                    except Exception as e:\n","                        print(f\"Error processing {domain} - {dataset_name} - {model_type} - {num_topics}: {str(e)}\")\n","                        continue\n","\n","    # metrics_df 생성\n","    metrics_df = pd.DataFrame(metrics_list)\n","\n","    print(\"\\n--- Existing metrics calculation completed ---\\n\")\n","\n","    # 새로운 토픽 모델링 결과 출력\n","    print(\"\\n--- Starting new topic modeling for top words ---\\n\")\n","    results_df = process_datasets(datasets)\n","    \n","    # 결과 출력\n","    for category in results_df['Category'].unique():\n","        print(f\"\\n{category.upper()}\")\n","        for dataset in results_df[results_df['Category'] == category]['Dataset'].unique():\n","            print(f\"\\n{dataset}\")\n","            subset = results_df[(results_df['Category'] == category) & (results_df['Dataset'] == dataset)]\n","            print(subset[['Model', 'Topic', 'Words']].to_string(index=False))\n","\n","    # 결과를 CSV 파일로 저장 (선택사항)\n","    results_df.to_csv('topic_modeling_top_words.csv', index=False)\n","\n","    print(\"\\n--- New topic modeling completed ---\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import Counter\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","\n","# 상관관계 분석 함수\n","def correlation_analysis(metrics_df):\n","    from scipy.stats import pearsonr, spearmanr\n","\n","    # 지표 목록\n","    metric_names = ['Coherence', 'NPMI', 'C_V']\n","\n","    # 모델별, 토픽 수별로 상관관계 계산\n","    for model in metrics_df['Model'].unique():\n","        for num_topics in metrics_df['Num_Topics'].unique():\n","            subset = metrics_df[(metrics_df['Model'] == model) & (metrics_df['Num_Topics'] == num_topics)]\n","            if len(subset) < 2:\n","                continue  # 상관계수를 계산하기 위한 데이터가 충분하지 않으면 건너뜀\n","            print(f\"\\n상관관계 분석 - 모델: {model}, 토픽 수: {num_topics}\")\n","            for i in range(len(metric_names)):\n","                for j in range(i+1, len(metric_names)):\n","                    metric1 = metric_names[i]\n","                    metric2 = metric_names[j]\n","                    pearson_corr, _ = pearsonr(subset[metric1], subset[metric2])\n","                    spearman_corr, _ = spearmanr(subset[metric1], subset[metric2])\n","                    print(f\"{metric1} vs {metric2} - Pearson: {pearson_corr:.4f}, Spearman: {spearman_corr:.4f}\")\n","\n","# 일관성 분석 함수\n","def consistency_analysis(metrics_df):\n","    metric_names = ['Coherence', 'NPMI', 'C_V']\n","\n","    # 지표별 변동 계수 계산\n","    for metric in metric_names:\n","        cv = metrics_df[metric].std() / metrics_df[metric].mean()\n","        print(f\"{metric}의 변동 계수 (전체): {cv:.4f}\")\n","\n","    # 모델별, 토픽 수별로 변동 계수 계산\n","    for model in metrics_df['Model'].unique():\n","        for num_topics in metrics_df['Num_Topics'].unique():\n","            subset = metrics_df[(metrics_df['Model'] == model) & (metrics_df['Num_Topics'] == num_topics)]\n","            if len(subset) < 2:\n","                continue\n","            print(f\"\\n일관성 분석 - 모델: {model}, 토픽 수: {num_topics}\")\n","            for metric in metric_names:\n","                cv = subset[metric].std() / subset[metric].mean()\n","                print(f\"{metric}의 변동 계수: {cv:.4f}\")\n","\n","# 계산 시간 비교 함수\n","def computation_time_analysis(comp_times_df):\n","    # 수치형 열만 선택하여 평균 계산\n","    numeric_columns = ['Topic_Modeling_Time', 'Coherence_Time', 'NPMI_Time', 'C_V_Time']\n","    avg_times = comp_times_df.groupby(['Model', 'Num_Topics'])[numeric_columns].mean().reset_index()\n","\n","    print(\"\\n계산 시간 비교:\")\n","    print(avg_times[['Model', 'Num_Topics', 'Topic_Modeling_Time', 'Coherence_Time', 'NPMI_Time', 'C_V_Time']])\n","\n","    # 계산 시간 시각화 (예시)\n","    sns.barplot(data=avg_times, x='Num_Topics', y='Topic_Modeling_Time', hue='Model')\n","    plt.title('모델별 토픽 수에 따른 토픽 모델링 시간')\n","    plt.show()\n","\n","# 계산 시간 데이터프레임 생성\n","comp_times_list = []\n","for key, times in computation_times.items():\n","    parts = key.split('_')\n","    domain = parts[0]\n","    model = parts[-2]\n","    num_topics = parts[-1]\n","    comp_times_list.append({\n","        'Domain': domain,\n","        'Model': model,\n","        'Num_Topics': int(num_topics),\n","        'Topic_Modeling_Time': times['Topic Modeling'],\n","        'Coherence_Time': times['Coherence'],\n","        'NPMI_Time': times['NPMI'],\n","        'C_V_Time': times['C_V']\n","    })\n","\n","comp_times_df = pd.DataFrame(comp_times_list)\n","\n","# 도메인 간 지표 성능 비교 함수\n","def domain_performance_analysis(metrics_df):\n","    metric_names = ['Coherence', 'NPMI', 'C_V']\n","    from scipy.stats import f_oneway, kruskal\n","\n","    for metric in metric_names:\n","        print(f\"\\n도메인 간 {metric} 성능 비교\")\n","        data_per_domain = [metrics_df[metrics_df['Domain'] == domain][metric] for domain in metrics_df['Domain'].unique()]\n","        # ANOVA 검정\n","        f_stat, p_value = f_oneway(*data_per_domain)\n","        print(f\"ANOVA 결과 - F-statistic: {f_stat:.4f}, p-value: {p_value:.4f}\")\n","        # Kruskal-Wallis 검정\n","        h_stat, p_value = kruskal(*data_per_domain)\n","        print(f\"Kruskal-Wallis 결과 - H-statistic: {h_stat:.4f}, p-value: {p_value:.4f}\")\n","\n","# 토픽 단어 추출 함수\n","def extract_topics(model_type, model, num_topics, topics=None):\n","    extracted_topics = []\n","    if model_type == 'LDA':\n","        for i in range(num_topics):\n","            topic_terms = model.show_topic(i, topn=10)\n","            topic_words = [word for word, _ in topic_terms]\n","            extracted_topics.append(topic_words)\n","    elif model_type == 'BERTopic':\n","        for i in range(num_topics):\n","            topic_info = model.get_topic(i)\n","            if topic_info:\n","                topic_words = [word for word, _ in topic_info]\n","                extracted_topics.append(topic_words)\n","    elif model_type == 'VAE':\n","        # VAE의 경우 이미 추출한 토픽 단어를 사용\n","        extracted_topics = topics\n","    return extracted_topics\n","\n","# LLM 평가 수행 함수\n","from tenacity import retry, stop_after_attempt, wait_random_exponential\n","\n","def call_openai_api(prompt: str, max_tokens: int = 3000) -> str:\n","    client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n","    full_response = \"\"\n","    while True:\n","        try:\n","            response = client.chat.completions.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\n","                        \"role\": \"system\",\n","                        \"content\": \"You are an expert in topic modeling and text analysis. Your task is to evaluate the coherence of topics based on provided documents.\"\n","                    },\n","                    {\n","                        \"role\": \"user\",\n","                        \"content\": prompt + (\"\\n\\nContinue from: \" + full_response if full_response else \"\")\n","                    }\n","                ],\n","                temperature=0,\n","                max_tokens=max_tokens,\n","                top_p=1,\n","                frequency_penalty=0.1,\n","                presence_penalty=0.1,\n","            )\n","            chunk = response.choices[0].message.content\n","            full_response += chunk\n","            \n","            if not response.choices[0].finish_reason == \"length\":\n","                break\n","            \n","            prompt = \"Continue the previous response:\"\n","        except openai.error.RateLimitError:\n","            print(\"Rate limit exceeded. Retrying...\")\n","            raise\n","        except openai.error.AuthenticationError:\n","            print(\"Authentication error. Check your API key.\")\n","            raise\n","        except Exception as e:\n","            print(f\"Unexpected error: {e}\")\n","            raise\n","\n","    return full_response\n","\n","@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))\n","def llm_evaluation(topics, documents, model=\"gpt-4o-mini\"):\n","    api_key = os.environ.get('OPENAI_API_KEY')\n","    if not api_key:\n","        raise ValueError(\"OpenAI API key not found in environment variables\")\n","\n","    openai.api_key = api_key\n","\n","    scores = []\n","    feedbacks = []\n","\n","    if not isinstance(documents, list):\n","        documents = list(documents)\n","\n","    for topic_words in topics:\n","        topic = ', '.join(topic_words)\n","        docs_sample = documents[:3]\n","        prompt = f\"\"\"\n","주어진 토픽과 관련 문서를 평가해주세요. 다음 기준에 따라 1-10 척도로 점수를 매겨주세요:\n","일관성: 토픽 내 단어들이 의미적으로 얼마나 연관되어 있는가?\n","\n","토픽: {topic}\n","관련 문서 샘플:\n","{docs_sample}\n","\n","일관성에 대해 1-10 점수를 매기고, 간단한 설명을 덧붙여주세요.\n","\"\"\"\n","        try:\n","            evaluation = call_openai_api(prompt, max_tokens=500)\n","            match = re.search(r'(\\d+)', evaluation)\n","            if match:\n","                topic_score = int(match.group(1))\n","                scores.append(topic_score)\n","                feedbacks.append(evaluation)\n","            else:\n","                print(f\"점수를 추출할 수 없습니다: {evaluation}\")\n","        except openai.error.RateLimitError:\n","            print(\"Rate limit exceeded. Retrying...\")\n","            raise\n","        except openai.error.AuthenticationError:\n","            print(\"Authentication error. Check your API key.\")\n","            raise\n","        except Exception as e:\n","            print(f\"Unexpected error: {e}\")\n","            raise\n","\n","    return scores, feedbacks\n","\n","\n","def run_llm_evaluation(metrics_df, datasets, sample_size=100):\n","    llm_results = []\n","    # 샘플 사이즈를 고정\n","    actual_sample_size = sample_size\n","\n","    for index, row in metrics_df.sample(n=actual_sample_size, random_state=42).iterrows():\n","        domain = row['Domain']\n","        dataset_name = row['Dataset']\n","        model_type = row['Model']\n","        num_topics = row['Num_Topics']\n","        print(f\"\\nLLM 평가 진행 중 - 도메인: {domain}, 데이터셋: {dataset_name}, 모델: {model_type}, 토픽 수: {num_topics}\")\n","\n","        data = datasets[domain][dataset_name]\n","\n","        if model_type == 'VAE':\n","            model, _, topics = perform_topic_modeling(data, num_topics, model_type)\n","        else:\n","            model, _ = perform_topic_modeling(data, num_topics, model_type)\n","            topics = None\n","\n","        topics = extract_topics(model_type, model, num_topics, topics)\n","\n","        scores, feedbacks = llm_evaluation(topics, data)\n","\n","        result = {\n","            'Domain': domain,\n","            'Dataset': dataset_name,\n","            'Model': model_type,\n","            'Num_Topics': num_topics,\n","            'LLM_Scores': scores,\n","            'LLM_Feedbacks': feedbacks\n","        }\n","        llm_results.append(result)\n","\n","        # 중간 결과 저장\n","        import json\n","        with open('llm_evaluation_results.json', 'a') as f:\n","            json.dump(result, f)\n","            f.write('\\n')\n","\n","    llm_df = pd.DataFrame(llm_results)\n","    return llm_df\n","\n","\n","def analyze_llm_results(llm_df):\n","    llm_df['LLM_Avg_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.mean([s for s in scores if s is not None]))\n","    llm_df['LLM_Std_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.std([s for s in scores if s is not None]))\n","    llm_df['LLM_Median_Score'] = llm_df['LLM_Scores'].apply(lambda scores: np.median([s for s in scores if s is not None]))\n","\n","    print(\"\\nLLM 평가 결과:\")\n","    print(llm_df[['Domain', 'Model', 'Num_Topics', 'LLM_Avg_Score', 'LLM_Std_Score', 'LLM_Median_Score']])\n","\n","def llm_auto_metric_correlation(metrics_df, llm_df):\n","    merged_df = pd.merge(metrics_df, llm_df, on=['Domain', 'Dataset', 'Model', 'Num_Topics'])\n","\n","    metric_names = ['Coherence', 'NPMI', 'C_V']\n","    for metric in metric_names:\n","        valid_idx = merged_df['LLM_Avg_Score'].notnull()\n","        pearson_corr, p_value_pearson = pearsonr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n","        spearman_corr, p_value_spearman = spearmanr(merged_df.loc[valid_idx, metric], merged_df.loc[valid_idx, 'LLM_Avg_Score'])\n","        print(f\"\\nLLM 평가 점수와 {metric}의 상관관계:\")\n","        print(f\"Pearson: 상관계수 = {pearson_corr:.4f}, p-value = {p_value_pearson:.4f}\")\n","        print(f\"Spearman: 상관계수 = {spearman_corr:.4f}, p-value = {p_value_spearman:.4f}\")\n","\n","\n","def verify_llm_consistency(topics, documents, n_repeats=5):\n","    all_scores = []\n","    for _ in range(n_repeats):\n","        scores, _ = llm_evaluation(topics, documents)\n","        all_scores.append(scores)\n","    all_scores = np.array(all_scores)\n","    std_scores = np.std(all_scores, axis=0)\n","    avg_std = np.mean(std_scores)\n","    cv_scores = std_scores / np.mean(all_scores, axis=0)\n","    avg_cv = np.mean(cv_scores)\n","    print(f\"\\nLLM 평가의 평균 표준편차: {avg_std:.4f}\")\n","    print(f\"LLM 평가의 평균 변동계수(CV): {avg_cv:.4f}\")\n","\n","def analyze_llm_feedback(llm_df):\n","    # 피드백에서 자주 등장하는 키워드 추출\n","    all_words = []\n","    for feedbacks in llm_df['LLM_Feedbacks']:\n","        for feedback in feedbacks:\n","            words = feedback.lower().split()\n","            all_words.extend([word for word in words if word not in stop_words])\n","\n","    word_freq = Counter(all_words)\n","    print(\"\\n피드백에서 가장 자주 등장하는 키워드:\")\n","    for word, count in word_freq.most_common(10):\n","        print(f\"{word}: {count}\")\n","\n","def visualize_llm_results(llm_df):\n","    plt.figure(figsize=(12, 6))\n","    sns.boxplot(x='Model', y='LLM_Avg_Score', data=llm_df)\n","    plt.title('모델별 LLM 평가 점수 분포')\n","    plt.show()\n","\n","    plt.figure(figsize=(12, 6))\n","    sns.scatterplot(x='Num_Topics', y='LLM_Avg_Score', hue='Model', data=llm_df)\n","    plt.title('토픽 수에 따른 LLM 평가 점수')\n","    plt.show()\n","\n","\n","# def visualize_results(metrics_df):\n","#     # 모델별 Coherence 비교\n","#     plt.figure(figsize=(12, 6))\n","#     sns.boxplot(x='Model', y='Coherence', data=metrics_df)\n","#     plt.title('Model Coherence Comparison')\n","#     plt.show()\n","\n","#     # 모델별 NPMI 비교\n","#     plt.figure(figsize=(12, 6))\n","#     sns.boxplot(x='Model', y='NPMI', data=metrics_df)\n","#     plt.title('Model NPMI Comparison')\n","#     plt.show()\n","\n","#     # 모델별 C_V 비교\n","#     plt.figure(figsize=(12, 6))\n","#     sns.boxplot(x='Model', y='C_V', data=metrics_df)\n","#     plt.title('Model C_V Comparison')\n","#     plt.show()\n","\n","#     # 토픽 수에 따른 Coherence 변화\n","#     plt.figure(figsize=(12, 6))\n","#     sns.lineplot(x='Num_Topics', y='Coherence', hue='Model', data=metrics_df)\n","#     plt.title('Coherence vs Number of Topics')\n","#     plt.show()\n","\n","# if __name__ == '__main__':\n","#     # metrics_df 생성\n","#     metrics_df = pd.DataFrame(metrics_list)\n","\n","#     # 상관관계 분석 수행\n","#     correlation_analysis(metrics_df)\n","\n","#     # 일관성 분석 수행\n","#     consistency_analysis(metrics_df)\n","\n","#     # # 계산 시간 비교 수행\n","#     # computation_time_analysis(comp_times_df)\n","\n","#     # 도메인 간 성능 비교 수행\n","#     domain_performance_analysis(metrics_df)\n","\n","#     # LLM 평가 수행\n","#     llm_df = run_llm_evaluation(metrics_df, datasets)\n","\n","#     # LLM 평가 결과 분석\n","#     analyze_llm_results(llm_df)\n","\n","#     # LLM 평가와 새 평가지표 간 상관관계 분석\n","#     llm_auto_metric_correlation(metrics_df, llm_df)\n","\n","#     # LLM 평가의 일관성 검증 (예시로 첫 번째 토픽 사용)\n","    # topics = extract_topics('LDA', lda_model, 5)\n","    # documents = datasets['academy']['business']\n","    # verify_llm_consistency(topics, documents)\n","\n","    # LLM 피드백 분석\n","    # analyze_llm_feedback(llm_df)\n","\n","    # 결과 시각화\n","    # visualize_results(metrics_df)\n","    # visualize_llm_results(llm_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def visualize_results(metrics_df):\n","    metrics = ['Coherence', 'NPMI', 'C_V']\n","    \n","    # 모델별 성능 비교 및 토픽 수에 따른 성능 변화\n","    for metric in metrics:\n","        plt.figure(figsize=(12, 6))\n","        sns.boxplot(x='Model', y=metric, data=metrics_df)\n","        plt.title(f'Model {metric} Comparison')\n","        plt.show()\n","\n","        plt.figure(figsize=(12, 6))\n","        sns.lineplot(x='Num_Topics', y=metric, hue='Model', data=metrics_df)\n","        plt.title(f'{metric} vs Number of Topics')\n","        plt.show()\n","\n","    # 도메인별 성능 비교\n","    for metric in metrics:\n","        plt.figure(figsize=(12, 6))\n","        sns.boxplot(x='Domain', y=metric, data=metrics_df)\n","        plt.title(f'{metric} Comparison by Domain')\n","        plt.show()\n","\n","    # 상관관계 분석\n","    correlation_matrix = metrics_df[metrics].corr()\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n","    plt.title('Correlation between Evaluation Metrics')\n","    plt.show()\n","\n","\n","def summarize_results(metrics_df, llm_df):\n","    # 자동 평가 지표 요약\n","    print(\"\\n자동 평가 지표 요약:\")\n","    print(metrics_df.describe())\n","\n","    # LLM 평가 지표 요약\n","    if llm_df is not None:\n","        print(\"\\nLLM 평가 지표 요약:\")\n","        print(llm_df.describe())\n","\n","    # 모델별 평균 점수 계산\n","    model_metrics = metrics_df.groupby('Model').mean()\n","    print(\"\\n모델별 평균 점수:\")\n","    print(model_metrics)\n","\n","    # 도메인별 평균 점수 계산\n","    domain_metrics = metrics_df.groupby('Domain').mean()\n","    print(\"\\n도메인별 평균 점수:\")\n","    print(domain_metrics)\n","\n","    # LLM 평가와 자동 평가 지표 간의 상관관계 분석\n","    if llm_df is not None:\n","        combined_df = pd.merge(metrics_df, llm_df, on=['Domain', 'Dataset', 'Model', 'Num_Topics'])\n","        correlation_matrix = combined_df.corr()\n","        plt.figure(figsize=(10, 8))\n","        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n","        plt.title('Correlation between LLM and Automatic Evaluation Metrics')\n","        plt.show()\n","\n","# 메인 실행 코드\n","if __name__ == '__main__':\n","    # 평가 지표 결과 저장을 위한 데이터프레임 초기화\n","    metrics_list = []\n","\n","    # 계산 시간 저장을 위한 딕셔너리 초기화\n","    computation_times = {}\n","\n","    # 모델 유형 및 토픽 수 설정\n","    model_types = ['LDA', 'BERTopic', 'VAE']\n","    num_topics_list = [2, 4, 6, 8, 10]\n","\n","    # 토픽 모델링 및 지표 계산\n","    for domain, domain_datasets in datasets.items():\n","        for dataset_name, data in domain_datasets.items():\n","            print(f\"\\nProcessing {domain} - {dataset_name}\")\n","            for model_type in model_types:\n","                for num_topics in num_topics_list:\n","                    print(f\"\\nModel: {model_type}, Num Topics: {num_topics}\")\n","                    try:\n","                        start_time = time.time()\n","                        if model_type == 'VAE':\n","                            model, vectorizer, topics = perform_topic_modeling(data, num_topics, model_type)\n","                        else:\n","                            model, vectorizer = perform_topic_modeling(data, num_topics, model_type)\n","                            topics = None  # VAE가 아닌 경우\n","                        topic_modeling_time = time.time() - start_time\n","\n","                        start_time = time.time()\n","                        coherence, npmi, c_v = calculate_evaluation_metrics(model, data, model_type, vectorizer, num_topics, topics)\n","                        evaluation_time = time.time() - start_time\n","\n","                        # 결과 저장\n","                        metrics_list.append({\n","                            'Domain': domain,\n","                            'Dataset': dataset_name,\n","                            'Model': model_type,\n","                            'Num_Topics': num_topics,\n","                            'Coherence': coherence,\n","                            'NPMI': npmi,\n","                            'C_V': c_v\n","                        })\n","\n","                        computation_times[f\"{domain}_{dataset_name}_{model_type}_{num_topics}\"] = {\n","                            'Topic Modeling': topic_modeling_time,\n","                            'Evaluation': evaluation_time\n","                        }\n","\n","                        print(f\"Coherence: {coherence:.4f}\")\n","                        print(f\"NPMI: {npmi:.4f}\")\n","                        print(f\"C_V: {c_v:.4f}\")\n","\n","                    except Exception as e:\n","                        print(f\"Error processing {domain} - {dataset_name} - {model_type} - {num_topics}: {str(e)}\")\n","                        continue\n","\n","    # metrics_df 생성\n","    metrics_df = pd.DataFrame(metrics_list)\n","    \n","    # 상관관계 분석 실행\n","    correlation_analysis(metrics_df)\n","\n","    # LLM 평가 실행 (선택적)\n","    llm_df = llm_evaluation(metrics_df, datasets)\n","\n","    # LLM 평가 결과 분석\n","    analyze_llm_results(llm_df)\n","\n","    # LLM 평가와 자동 평가 지표 간의 상관관계 분석\n","    llm_auto_metric_correlation(metrics_df, llm_df)\n","\n","    # LLM 평가의 일관성 검증\n","    verify_llm_consistency(topics, documents)\n","\n","    # 결과 종합 및 해석\n","    summarize_results(metrics_df, llm_df)\n","\n","    # 결과 분석 및 시각화 함수 실행\n","    visualize_results(metrics_df)\n","\n","    print(\"실험 완료\")"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN1HMc8DJjEA0c4VoVpICAu","gpuType":"T4","mount_file_id":"1A2KBLTvWLDpZRfvqTW6X-K99HG5QCvQ-","provenance":[]},"kernelspec":{"display_name":"topic","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
