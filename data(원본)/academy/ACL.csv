text
online petition costeffective way citizen collectively engage policymakers democracy predicting popularity petition commonly measured signature count based textual content utility policymakers well posting petition work model task using cnn regression auxiliary ordinal regression objective demonstrate effectiveness proposed approach using uk u government petition datasets
language model trained largescale corpus generate remarkably fluent result opendomain dialogue however personabased dialogue generation task consistency coherence also key factor great challenge language model existing work mainly focus valuable data filtering model structure modifying objective function designing improvement limited hard generalize type pretrained language model however find language model produce consistent coherent response consider enough generation thus problem lay largescale response generation target response selection work simple effective twostage simoap strategy proposed ie oversampling postevaluation oversampling stage take largescale response existing trained model efficiently via offtheshelf distilling compressing method postevaluation stage selects good response based multiple welldesigned evaluation metric largescale candidate experimental result show proposed plugin simoap strategy improves backbone model outperforms baseline strategy automatic human evaluation
paper propose srlnlp new approach data augmentation drawing analogy image text processing superresolution learning method based using highresolution image overcome problem low resolution image technique common usage image processing image low resolution noisy never used nlp therefore propose first adaptation method text classification evaluate effectiveness urgency detection tweet posted crisis situation challenging task message scarce highly imbalanced show strategy efficient compared competitive stateoftheart data augmentation technique several benchmark datasets two language
generative model increasingly used various application text generation commonsense reasoning questionanswering effective globally model must aware account local sociocultural context making necessary benchmark evaluate model cultural familiarity since training data llm webbased web limited representation information capture knowledge present within community web thus model exacerbate inequity semantic misalignment stereotype web growing call communitycentered participatory research method nlp work respond call using participatory research method introduce dosa first communitygenerated dataset social artifact engaging participant different indian geographic subculture use gamified framework relies collective sensemaking collect name description artifact description semantically align shared sensibility individual culture next benchmark four popular llm find show significant variation across regional subculture ability infer artifact
embedding layer transforming input word real vector key component deep neural network used natural language processing however vocabulary large corresponding weight matrix enormous precludes deployment limited resource setting introduce novel way parameterizing embedding layer based tensor train decomposition allows compressing model significantly cost negligible drop even slight gain performance evaluate method wide range benchmark natural language processing analyze tradeoff performance compression ratio wide range architecture mlps lstms transformer
cloze test play essential role language assessment help language learner improve skill paper propose novel task called cloze quality estimation cqe zeroshot task evaluating whether cloze test sufficient highquality language assessment based two important factor reliability validity taken first step creating new dataset named cela cqe task includes english cloze test corresponding evaluation quality annotated native english speaker includes instance aspect reliability validity respectively tested baseline evaluation method dataset showing method could contribute cqe task task still challenging
natural language communication machine human still constrained article address gap natural language understanding action specifically understanding command propose new method commonsense inference grounding highlevel natural language command specific action command execution robotic system method allows build knowledge base consists large set commonsense inference preliminary result presented
jager computational framework defined start parallel word list related language infer corresponding vocabulary shared protolanguage sigtyp shared task closely related main difference reconstructed protoform unknown word extant language system described reimplementation tool used mentioned paper adapted current task
contextualised word representation model successfully used capturing different word usage may attractive alternative representing idiomaticity language paper propose probing measure assess expected linguistic property noun compound especially related idiomatic meaning dependence context sensitivity lexical choice readily available standard widely used representation constructed noun compound sens dataset contains noun compound paraphrase context neutral context informative naturalistic sentence two language english portuguese result obtained using four type probing measure model like elmo bert variant indicate idiomaticity yet accurately represented contextualised model
training deep neural network dnns weak supervision attracted increasing research attention significantly reduce annotation cost however label weak supervision noisy high capacity dnns enables easily overfit label noise resulting poor generalization recent method leverage selftraining build noiseresistant model teacher trained weak supervision used provide highly confident label teaching student nevertheless teacher derived framework may fitted substantial amount noise therefore produce incorrect pseudolabels high confidence leading severe error propagation work propose meta selfrefinement msr noiseresistant learning framework effectively combat label noise weak supervision instead relying fixed teacher trained noisy label encourage teacher refine pseudolabels training step msr performs meta gradient descent current minibatch maximize student performance clean validation set extensive experimentation eight nlp benchmark demonstrates msr robust label noise setting outperforms stateoftheart method accuracy f score
describe deployed scalable system organizing published scientific literature heterogeneous graph facilitate algorithmic manipulation discovery resulting literature graph consists node representing paper author entity various interaction eg authorship citation entity mention reduce literature graph construction familiar nlp task eg entity extraction linking point research challenge due difference standard formulation task report empirical result task method described paper used enable semantic feature urlwwwsemanticscholarorg
goal evaluate usefulness unsupervised representation learning technique detecting stance fake news therefore examine several pretrained language model respect performance two fake news related data set consisting instance headline associated news article stance article towards respective headline specifically aim understand much hyperparameter tuning necessary finetuning pretrained architecture well transfer learning work specific case stance detection sensitive model change hyperparameters like batch size learning rate schedule sequence length well freezing technique result indicate computationally expensive autoregression approach xlnet yanget al outperformed bertbased model notably roberta liu et al learning rate seems important hyperparameter experiment different freezing technique indicate evaluated architecture already learned powerful language representation pose good starting point finetuning
intent detection key component modern goaloriented dialog system accomplish user task predicting intent user text input three primary challenge designing robust accurate intent detection model first typical intent detection model require large amount labeled data achieve high accuracy unfortunately practical scenario common find small unbalanced noisy datasets secondly even large training data intent detection model see different distribution test data deployed real world leading poor accuracy finally practical intent detection model must computationally efficient training single query inference used continuously retrained frequently benchmark intent detection method variety datasets result show watson assistant intent detection model outperforms commercial solution comparable large pretrained language model requiring fraction computational resource training data watson assistant demonstrates higher degree robustness training test distribution differ
transforming natural language question sql query crucial precise data retrieval electronic health record ehr database significant challenge process detecting rejecting unanswerable question request information outside database scope exceed system capability paper introduce novel texttosql framework focus standardizing structure question templated format framework begin finetuning gptturbo powerful large language model llm detailed prompt involving table schema ehr database system approach show promising result ehrsql benchmark dataset part clinicalnlp shared task although finetuning gpt achieves third place development set struggled diverse question test set framework improve system adaptability achieve fourth position official leaderboard ehrsql challenge
report design characteristic last minute corpus recording data collection taken woz experiment allows investigate user interact companion system mundane situation need planning replanning strategy change resulting corpus distinguished respect aspect size eg number subject length session number channel total length record well quality eg balancedness cohort well designed scenario standard based transcript psychological questionnaire accompanying indepth interview
modification foreign loanword undergo adapted japanese subject much study linguistics scholarly interest topic attributed fact japanese loanword undergo complex series phonological adaptation something puzzling scholar decade previous study japanese loanword accommodation focused specific phonological phenomenon limited scope current study leverage computational method provide complete description sound change occur adopting english word japanese investigate developed parallel corpus english transcription respective japanese equivalent word used develop widecoverage finite state transducer based phonological grammar mimic behavior japanese adaption process developing rule goal accounting completely large number borrowing analyzing form mistakenly generated system discovered internal inconsistency inside loanword phonology japanese language something arguably underestimated previous study result investigation suggests multiple dimension shape output form current japanese loanword dimension include orthography phonetics historical change
paper describe submission germeval shared task text complexity assessment german text address problem predicting complexity german sentence continuous scale many related work still rely handcrafted statistical feature neural network emerged stateoftheart natural language processing task therefore investigate complement feature relevant text complexity prediction german propose finetuned german distilbert model enriched statistical text feature achieved fourth place shared task rmse competition test data
paper describe submission wmt metric shared task metric focus computing contextual syntactic equivalence along lexical morphological semantic similarity intent capture fluency context mt output along adequacy fluency captured using syntactic similarity context captured using sentence similarity leveraging sentence embeddings final sentence translation score weighted combination three similarity score syntactic similarity b lexical morphological semantic similarity c contextual similarity paper outline two improved version mee ie mee mee additionally report experiment language pair ende enru zhen wmt testset depict correlation human assessment
reproducibility nlp research drawn increased attention last year several tool guideline metric introduced address concern regard problem however much work still remains ensure widespread adoption effective reproducibility standard work review reproducibility exploring neural text simplification model nisioi et al evaluating three main aspect data software artifact automatic evaluation discus challenge issue faced process furthermore explore adequacy current reproducibility standard code trained model docker container environment used training evaluation made publicly available
adapterbased tuning recently arisen alternative finetuning work adding lightweight adapter module pretrained language model prlm updating parameter adapter module learning downstream task add trainable parameter per new task allowing high degree parameter sharing prior study shown adapterbased tuning often achieves comparable result finetuning however existing work focus parameterefficient aspect adapterbased tuning lacking investigation effectiveness paper study latter first show adapterbased tuning better mitigates forgetting issue finetuning since yield representation less deviation generated initial prlm empirically compare two tuning method several downstream nlp task setting demonstrate adapterbased tuning outperforms finetuning lowresource crosslingual task robust overfitting less sensitive change learning rate
disambiguation potentially idiomatic expression involves determining sense potentially idiomatic expression given context eg determining make hay investment bank made hay takeover shone used figurative sense enables automatic interpretation idiomatic expression important application like machine translation sentiment analysis work present unsupervised approach english make use literalisations idiom sens improve disambiguation based lexical cohesion graphbased method sporleder li experimental result show literalisation carry novel information performance fall short stateoftheart unsupervised method
paper describes comprehensive annotation study japanese judgment document civil case aim build annotated corpus designed legal judgment prediction ljp especially tort annotation scheme contains annotation whether tort accepted judge well corresponding rationale explainability purpose annotation scheme extract decision rationale characterlevel moreover scheme capture explicit causal relation judge decision corresponding rationale allowing multiple decision document obtain highquality annotation developed annotation scheme legal expert confirmed reliability agreement study krippendorffs alpha metric result annotation study suggests proposed annotation scheme produce dataset japanese ljp reasonable reliability
recent study machine translation support fact multimodel system perform better individual model paper describe hindi english statistical machine translation system improve baseline using multiple translation model considered phrase based well hierarchical model enhanced baseline using regression model system trained textual well syntactic feature extracted source target aforementioned translation system show significant improvement baseline system automatic well human evaluation proposed methodology quite generic easily extended language pair well
pretrained language model demonstrated extraordinary capability language generation however realworld task often require controlling distribution generated text order mitigate bias promote fairness achieve personalization existing technique controlling distribution generated text work quantified distribution require predefined category proportion distribution existing corpus following desired distribution however many important distribution personal preference unquantified work tackle problem generating text following arbitrary distribution quantified unquantified proposing nano fewshot humanintheloop training algorithm continuously learns human feedback nano achieves stateoftheart result single topicattribute well quantified distribution control compared previous work also show nano able learn unquantified distribution achieves personalization capture difference different individual personal preference high sample efficiency
cognet knowledge base integrates three type knowledge linguistic knowledge world knowledge commonsense knowledge paper propose information extraction toolkit called cogie bridge connecting raw text cognet cogie three feature versatile knowledgegrounded extensible first cogie versatile toolkit rich set functional module including named entity recognition entity typing entity linking relation extraction event extraction framesemantic parsing second knowledgegrounded toolkit cogie ground extracted fact cognet leverage different type knowledge enrich extracted result third extensibility owing design threetier architecture cogie plugandplay toolkit developer also extensible programming framework researcher release openaccess online system visually extract information text source code datasets pretrained model publicly available github short instruction video
large language model llm demonstrated stateoftheart accuracy across various task however latency inference large gpu memory consumption llm restrict deployment performance recently efficient attempt quantize llm yet inference large batch size long sequence still issue computebound finegrained quantization method showcased proficiency achieving lowbit quantization llm requiring fp data type linear layer computation timeconsuming dealing large batch size long sequence paper introduce method called flattenquant significantly reduces maximum value tensor flattening larger channel tensor achieve low bit pertensor quantization minimal accuracy loss experiment show flattenquant directly use bit achieve linear layer calculation llm remaining layer using bit bit matrix multiplication introduced flattenquant method effectively address computebound caused large matrix calculation work achieves mboxtimes speedup mboxtimes memory reduction llm negligible loss accuracy
primary limitation north korean english translation lack parallel corpus therefore high translation accuracy achieved address problem propose zeroshot approach using south korean data remarkably similar north korean data train neural machine translation model tokenizing south korean text character level decomposing character phoneme demonstrate method effectively learn north korean english translation improve bleu score point comparison baseline
postediting common use case machine translation human evaluation postedits mqm error annotation reveal treasure trove insight help inform engine training quality improvement strategy however manual workflow get costly fast enterprise scale insight never get discovered acted upon mt team scale process efficient way across dozen language multiple translation tool postediting done applying risk modeling maximize return investment costly human evaluation well share strategy learnt work automating human evaluation workflow world best machine translation team corporates government lsps
smile fundamental facial expression successful humanagent communication growing number publication domain present opportunity future research design informed scoping review extant literature semiautomated review expedites first step toward mapping virtual human vh smile research paper contributes overview status quo vh smile research identifies research stream cluster analysis identifies prolific author field provides evidence full scoping review needed synthesize finding expanding domain vh smile research enable collaboration provide full access refined vh smile dataset key word author word cloud well interactive evidence map
large language model llm considered judge high efficiency evaluate quality answer generated candidate model however judgment may influenced complex scenario inherent bias raising concern reliability study aim bridge gap introducing four unexplored factor examining performance llm judge namely answer quantity inducing statement judging strategy judging style additionally introduce new dimension question difficulty provide comprehensive understanding llm judgment across varying question intricacy employ chatgpt gpt gemini claude judge conduct experiment vicuna benchmark mtbench study reveals llm judging ability susceptible influence four factor analyzing newly proposed dimension question difficulty highly necessary also provide valuable insight optimizing llm performance judge enhancing reliability adaptability across diverse evaluation scenario
paper present solution team inno semeval task detection propaganda technique news article goal second subtask classify textual segment correspond one given propaganda technique news article dataset tested pure transformerbased model optimized learning scheme ability distinguish propaganda technique model showed overall f score validation set test set accordingly nonzero f score class set
paper empirically evaluates performance different stateoftheart distributional model nominal lexical semantic classification task consider model exploit various type distributional feature thereby provide different representation nominal behavior context experiment presented work demonstrate advantage disadvantage model considered analysis also considers combined strategy found capable leveraging bottleneck model especially large robust data available
paper describes system submitted offenseval semeval task identifying categorizing offensive language social medium nitagartalanlpteam twitter annotated dataset english tweet provided task organizer train individual model best result obtained using ensemble model composed six different classifier ensemble model produced macroaveraged fscores subtasks b c respectively paper highlight overall low predictive nature various linguistic feature surface level count feature well limitation traditional machine learning approach compared deep learning counterpart
abstract meaning representation amr semantic formalism capture core meaning utterance substantial work developing amr corpus english recently across language though limited size existing datasets cost collecting annotation prohibitive engineering scientific question mind introduce massiveamr dataset texttograph annotation currently largest diverse kind amr graph informationseeking utterance mapped typologically diverse language describe built resource unique feature reporting experiment using large language model multilingual amr sparql parsing well applying amrs hallucination detection context knowledge base question answering result shedding light persistent issue using llm structured parsing
dialogue state tracking estimate user goal request given dialogue context essential part taskoriented dialogue system paper propose globallocally selfattentive dialogue state tracker glad learns representation user utterance previous system action globallocal module model us global module share parameter estimator different type called slot dialogue state us local module learn slotspecific feature show significantly improves tracking rare state glad obtains joint goal accuracy request accuracy woz state tracking task outperforming prior work dstc task model obtains joint goal accuracy request accuracy outperforming prior work
paper present germeval shared task text complexity assessment german text text form integral part exchanging information interacting world correlating quality experience life text complexity one factor affect reader understanding text mapping body text mathematical unit quantifying degree readability basis complexity assessment readability might influenced representation target text complexity reader task designed task text regression participant developed model predict complexity piece text german learner range shared task organized two phase development test phase among participant registered shared task ten team submitted result test data
largescale pretrained transformer model demonstrated stateoftheart sota performance variety nlp task nowadays numerous pretrained model available different model flavor different language easily adapted one downstream task however limited number model available dialogue task particular goaloriented dialogue task addition available pretrained model trained general domain language creating mismatch pretraining language downstream domain launguage contribution present csbert bert model pretrained million dialogue customer service domain evaluate csbert several downstream customer service dialogue task demonstrate indomain pretraining advantageous compared pretrained model zeroshot experiment well finetuning experiment especially lowresource data setting
phonological segment borrowing process language acquire new contrastive speech sound result borrowing new word language despite fact phonological segment borrowing documented many world language date largescale quantitative study phenomenon paper present segbo novel crosslinguistic database borrowed phonological segment describe data aggregation pipeline resulting language sample also present two short case study based database first deal impact large colonial language sound system world language second deal universal borrowing domain rhotic consonant
present creation englishswedish framenetbased grammar grammatical framework aim research make existing framenets computationally accessible multilingual natural language application via common semantic grammar api facilitate porting grammar language paper describe abstract syntax semantic grammar focusing automatic extraction possibility extracted shared abstract syntax textasciitilde annotated sentence berkeley framenet bfn textasciitilde annotated sentence swedish framenet swefn abstract syntax defines framespecific valence pattern cover example bfn swefn belonging shared set frame side result provide unified method comparing semantic syntactic valence pattern across framenets
text anomaly detection tad crucial task aim identify text deviate significantly norm within corpus despite importance various domain tad remains relatively underexplored natural language processing article present systematic evaluation tad algorithm corpus using multiple text representation including monolingual multilingual sbert performance algorithm compared based three criterion degree supervision theoretical basis architecture used result demonstrate semisupervised method utilizing weak label outperform unsupervised method semisupervised method using negative sample training additionally explore application tad technique hate speech detection result provide valuable insight future tad research guide selection suitable algorithm detecting text anomaly different context
introduce enhancing perception framework large language model llm designed streamline timeintensive task typically undertaken professional factcheckers crafting explanation fake news study investigates effectiveness enhancing llm explanation conversational refinement compare various questioner agent including stateoftheart llm like gpt claude palm american participant acting human questioner based history refinement conversation generate comprehensive summary explanation evaluated effectiveness initial refined summary explanation across news claim involving american participant measuring selfreported belief change regarding real fake claim receiving explanation finding reveal context fake news explanation undergone conversational refinementwhether gpt human questioner ask diverse detailoriented questionswere significantly effective initial unrefined explanation summary explanation moreover refined explanation achieved level effectiveness comparable expertwritten explanation result highlight potential automatic explanation refinement llm debunking fake news claim
retrieving proper domain knowledge external database lie heart endtoend taskoriented dialog system generate informative response existing system blend knowledge retrieval response generation optimize direct supervision reference response leading suboptimal retrieval performance knowledge base becomes largescale address propose decouple knowledge retrieval response generation introduce multigrained knowledge retriever maker includes entity selector search relevant entity attribute selector filter irrelevant attribute train retriever propose novel distillation objective derives supervision signal response generator experiment conducted three standard benchmark small largescale knowledge base demonstrate retriever performs knowledge retrieval effectively existing method code made publicly available urlhttpsgithubcommaker
paper present crosslingual extension neural tensor network model knowledge base completion exploit multilingual synset babelnet translate english triple language augment reference knowledge base crosslingual triple project monolingual embeddings different language shared multilingual space use network initialization ie initial concept embeddings train network triple crosslingually augmented knowledge base result wordnet link prediction show leveraging crosslingual information yield significant gain exploiting monolingual triple
paper describes znlp system bucc shared task system identifies parallel sentence pair chineseenglish comparable corpus translating wordbyword chinese sentence english using search engine solr select nearparallel sentence using svm classifier identify true parallel sentence previous result obtains fscore resp test training set
named entity recognition ner wellknown problem natural language processing nlp community key component different nlp application including information extraction question answering information retrieval literature several arabic ner datasets different named entity tag however due data concept drift always need new data ner nlp application paper first introduce wassem webbased annotation platform arabic nlp application wassem used manually annotate textual data variety nlp task text classification sequence classification word segmentation second introduce covid arabic named entity recognition caraner dataset caraner token distributed sentence randomly extracted saudi arabian newspaper article published dataset labeled five annotator five namedentity tag namely person title location organization miscellaneous caraner corpus available download free evaluate corpus finetuning four bertbased arabic language model caraner corpus best model arabertvlarge f macro measure
lexicon generally record list lexeme noncompositional multiword expression propose build lexicon compositional word combination namely secondary discourse connective secondary discourse connective play function primary discourse connective latter either lexeme noncompositional multiword expression paper defines primary secondary connective explains possible build lexicon compositional one could organized also put forward utility lexicon discourse annotation parsing finally open discussion construction signal discourse relation two span text
work perform first largescale analysis discourse medium dialog impact generative modeling dialog turn focus interrogative pattern use external knowledge discourse analysis help u understand mode persuasion entertainment information elicitation setting limited manual review small corpus introduce interviewa largescale k conversation medium dialog dataset collected news interview transcriptswhich allows u investigate pattern scale present dialog model leverage external knowledge well dialog act via auxiliary loss demonstrate model quantitatively qualitatively outperforms strong discourseagnostic baseline dialog modelinggenerating specific topical response interviewstyle conversation
neural machine translation nmt shown remarkable progress past year production system deployed endusers field moving rapidly become unclear element nmt architecture significant impact translation quality work present largescale analysis sensitivity nmt architecture common hyperparameters report empirical result variance number several hundred experimental run corresponding gpu hour wmt english german translation task experiment provide practical insight relative importance factor embedding size network depth rnn cell type residual connection attention mechanism decoding heuristic part contribution also release opensource nmt framework tensorflow make easy others reproduce result perform experiment
recent advance optical character recognition ocr handwritten text recognition htr led accurate textrecognition historical document digital humanity heavily profit development still struggle whenchoosing plethora ocr system available one hand defining workflow project hand work present approach build ground truth historical germanlanguage newspaper published black letter wealso report used systematically evaluate performance different ocr engine additionally used ground truthto make informed estimate much data necessary achieve highquality ocr result outcome experimentsshow htr architecture successfully recognise black letter text ground truth size newspaper page suffices toachieve good ocr accuracy moreover model perform equally well data seen training mean thatadditional manual correction diverging data superfluous
counterfactual statement describing event occur consequents studied area including problemsolving affect management behavior regulation people counterfactual thinking tend perceive life event personally meaningful nevertheless counterfactuals studied computational linguistics create counterfactual tweet dataset explore approach detecting counterfactuals using rulebased supervised statistical approach combined rulebased statistical approach yielded best result f outperforming either approach used alone
bengali lowresource language lack tool resource profane obscene textual content detection lexicon exists detecting obscenity bengali social medium text study introduces bengali obscene lexicon consisting bengali term considered filthy slang profane obscene semiautomatic methodology presented developing profane lexicon leverage obscene corpus word embedding partofspeech po tagger developed lexicon achieves coverage around obscene profane content detection evaluation dataset experimental result imply developed lexicon effective identifying obscenity bengali social medium content
code summarization aim automatically generate natural language description source code become essential task software development better program understanding abstract syntax tree ast represents syntax structure source code helpful utilized together sequence code token improve quality code summary recent work code summarization attempted capture sequential structural information source code considered less property source code consists multiple code block paper propose blocsum block scopebased source code summarization via shared block representation utilizes blockscope information representing various structure code block propose shared block position embedding effectively represent structure code block merge code astfurthermore develop variant asts learn rich information block global dependency source code prove approach perform experiment two realworld datasets java dataset python dataset demonstrate effectiveness blocsum various experiment including ablation study human evaluation
codemixing cm frequently observed phenomenon social medium platform multilingual society india increase codemixed content platform provides good amount data studying various aspect codemixing lack automated text analysis tool make study difficult overcome tool language identifier partsofspeech po tagger named entity recognition ner analysing codemixed data developed one important tool event detection important information retrieval task used identify critical fact occurring vast stream unstructured text data available event detection text hard problem social medium data add informal nature codemixed kannadaenglish data complicates problem due wordlevel mixing lack structure incomplete information work tried address problem proposed guideline annotation event kannadaenglish cm data provided baseline careful feature selection
paper present vaccination corpus corpus text related online vaccination debate annotated three layer information perspective attribution claim opinion additionally event related vaccination debate also annotated corpus contains document internet reflect different view vaccination compiled study language online debate final goal experimenting methodology extract contrast perspective framework vaccination debate
paper describes system semeval task emocontext focused contextual detection emotion dataset round dialogue final system used neural network pretrained elmo word embeddings po tag input grus hidden unit attention mechanism capture representation dialogue svm classifier used learned network representation perform task multiclass classification system yielded microaveraged f score three emotion class improving baseline approximately
referring expression comprehension task ground text representation onto object scene crucial task indoor household robot augmented reality device localize object referred user instruction however existing indoor referring expression comprehension datasets typically cover larger object class easy localize chair table door often overlook small object cooking tool office supply based recently proposed diverse highresolution scene dataset arkitscenes construct arkitscenerefer dataset focusing small dailyuse object frequently appear realworld indoor scene arkitscenerefer contains k object indoor scene significantly larger existing referring datasets cover diverse object class lvis dataset empirical experiment stateoftheart referring expression comprehension model observed task difficulty localization diverse small object class
paper describes shared task finegrained event classification newslike text snippet shared task divided three subtasks classification text snippet reporting sociopolitical event class vast amount training data exists although exhibiting different structure style visavis test data b enhancement generalized zeroshot learning problem additional event type introduced advance without training data unseen class c extension introduced additional event type announced shortly prior evaluation phase reported shared task focus classification event english text organized part workshop challenge application automated extraction sociopolitical event text case colocated aclijcnlp conference four team participated task best performing system three aforementioned subtasks achieved weighted f score respectively
lysfastparse team present bistcovington neural implementation covington algorithm nonprojective dependency parsing bidirectional lstm approach kiperwasser goldberg used train greedy parser dynamic oracle mitigate error propagation model participated conll ud shared task spite using ensemble method using baseline segmentation po tagging parser obtained good result macroaverage la uas big treebanks category language ranking th team treebanks category la uas ranked th th gap big category mainly due poor performance four parallel pud treebanks suggesting suffixed treebanks eg spanishancora perform poorly crosstreebank setting occur corresponding unsuffixed treebank eg spanish changing obtain th best la among run official unofficial code made available urlhttpsgithubcomconlludlysfastparse
lexical resource dictionary gazetteer often used auxiliary data task partofspeech induction namedentity recognition however discriminative training lexical feature requires annotated data reliably estimate lexical feature weight may result overfitting lexical feature expense feature generalize better paper investigate robust approach stipulate lexicon result assumed generative process practically mean may treat lexical resource observation proposed generative model lexical resource provide training data generative model without requiring separate data estimate lexical feature weight evaluate proposed approach two setting partofspeech induction lowresource namedentity recognition
deep learning approach sentiment classification fully exploit sentiment linguistic knowledge paper propose multisentimentresource enhanced attention network mean alleviate problem integrating three kind sentiment linguistic knowledge eg sentiment lexicon negation word intensity word deep neural network via attention mechanism using various type sentiment resource mean utilizes sentimentrelevant information different representation subspace make effective capture overall semantics sentiment negation intensity word sentiment prediction experimental result demonstrate mean robust superiority strong competitor
linguistic complexity research actively developing field increasing number text analysis tool created use natural language processing technique automatic extraction quantifiable measure linguistic complexity tool designed analyse one language ctap open source linguistic complexity measurement tool capable processing multiple language making crosslingual comparison possible although originally developed english architecture extended support multilingual analysis present italian component ctap describe implementation compare existing linguistic complexity tool italian offering general text length statistic feature lexical syntactic morphosyntactic complexity including measure lexical frequency lexical diversity lexical syntactical variation partofspeech density ctap currently comprehensive linguistic complexity measurement tool italian one allowing comparison italian text multiple language within one tool
recent year witnessed rise success pretraining technique visuallyrich document understanding however existing method lack systematic mining utilization layoutcentered knowledge leading suboptimal performance paper propose ernielayout novel document pretraining solution layout knowledge enhancement whole workflow learn better representation combine feature text layout image specifically first rearrange input sequence serialization stage present correlative pretraining task reading order prediction learn proper reading order document improve layout awareness model integrate spatialaware disentangled attention multimodal transformer replaced region prediction task pretraining phase experimental result show ernielayout achieves superior performance various downstream task setting new stateoftheart key information extraction document image classification document question answering datasets code model publicly available paddlenlp
natural language processing increasingly moved modeling document word toward studying people behind language move working data user community level presented field different characteristic linguistic data paper empirically characterize various lexical distribution different level analysis showing feature decidedly sparse nonnormal messagelevel traditional nlp follow central limit theorem become much lognormal even normal user countylevels finally demonstrate modeling lexical feature correct level analysis lead marked improvement common social scientific prediction task
named entity recognition ner attracted substantial amount research recently several neural networkbased model proposed achieved high performance however little research finegrained ner fgner hundred named entity category must recognized especially nonenglish language still open question whether model robust across various setting proper model varies depending language number named entity category size training datasets paper first present empirical comparison fgner model english japanese demonstrates lstmcnncrf hovy one stateoftheart method english ner also work well english fgner work well japanese language large number character type tackle problem propose method improve neural networkbased japanese fgner performance removing cnn layer utilizing dictionary category embeddings experiment result show proposed method improves japanese fgner fscore
recent work proposes family contextual embeddings significantly improves accuracy sequence labelers noncontextual embeddings however definite conclusion whether build better sequence labelers combining different kind embeddings various setting paper conduct extensive experiment task datasets language study accuracy sequence labeling various embedding concatenation make three observation concatenating embedding variant lead better accuracy richresource crossdomain setting condition lowresource setting concatenating contextual subword embeddings contextual character embeddings hurt accuracy extremely lowresource setting based conclusion concatenating additional similar contextual embeddings lead improvement hope conclusion help people build stronger sequence labelers various setting
existing approach machine translation mt mostly translate given text source language target language without explicitly referring information indispensable producing proper translation includes information textual element modality text document also extradocument nonlinguistic information norm skopos design better translation production workflow need distinguish translation issue could resolved existing texttotext approach beyond end conducted analytic assessment mt output taking englishtojapanese news translation task case study first example translation issue revision collected twostage postediting pe method performing minimal pe obtain translation attainable based given textual information performing full pe obtain truly acceptable translation referring information necessary collected revision example manually analyzed revealed dominant issue information indispensable resolving finegrained style specification terminology domainspecific knowledge reference document delineating clear distinction translation texttotext mt ultimately attain
order better understand rationale behind model behavior recent work exploited providing interpretation support inference prediction however existing method tend provide humanunfriendly interpretation prone suboptimal performance due oneside promotion ie either inference promotion interpretation vice versa paper propose multilevel mutual promotion mechanism selfevolved inference sentencelevel interpretation mpii specifically modellevel propose stepwise integration mechanism jointly perform deeply integrate inference interpretation autoregressive manner optimizationlevel propose adversarial fidelity regularization improve fidelity inference interpretation adversarial mutual information training strategy extensive experiment nli cqa task reveal proposed mpii approach significantly outperform baseline model inference performance interpretation quality
phonological process contextdependent sound change natural language present unsupervised approach learning humanreadable description phonological process collection related utterance approach build upon technique programming language community called constraintbased program synthesis contribute novel encoding learning problem boolean satisfiability constraint enables data efficiency fast inference evaluate system textbook phonology problem datasets literature show achieves high accuracy interactive speed
paper introduce chineseenglish simultaneous translation system participating autosimultrans simultaneous translation translation quality delay important order reduce translation delay cut streaminginput source sentence segment translate segment full sentence received order obtain highquality translation pretrain translation model adequate corpus finetune model domain adaptation sentence length adaptation experimental result evaluation data show system performs better baseline system
voice dictation increasingly important text input modality existing system allow dictation editingbyvoice restrict command language flat template invoked trigger word work study feasibility allowing user interrupt dictation spoken editing command openended natural language introduce new task dataset tertius experiment system support flexibility realtime system must incrementally segment classify span speech either dictation command interpret span command experiment using large pretrained language model predict edited text alternatively predict small textediting program experiment show natural tradeoff model accuracy latency smaller model achieves endstate accuracy second latency larger model achieves endstate accuracy second latency
paper present mdp policy learning agent learn strategic behaviorhow play board gamesduring multimodal dialogue policy trained offline simulation dialogue carried formal language agent temporary belief state dialogue persistent knowledge store represented extensiveform game tree well agent learns new game dialogue simulated partner evaluated well play game given dialoguefinal knowledge state policy training control simulated dialogue partner level informativeness responding question agent learns best trained policy match current dialogue partner informativeness also present novel data collection training natural language module human subject engaged dialogue baseline system rated system language skill average result confirm human dialogue partner also vary informativeness
though majority vote among annotator typically used ground truth label machine learning annotator disagreement task hate speech detection may reflect systematic difference opinion across group noise thus crucial problem hate speech detection determining statement offensive demographic group target group may small fraction annotator pool construct model predicts individual annotator rating potentially offensive text combine information predicted target group text predict rating target group member show gain across range metric including raising performance baseline predicting individual annotator rating predicting variance among annotator provides metric model uncertainty downstream find annotator rating predicted using demographic information well opinion online content noninvasive question annotator online experience minimize need collect demographic information predicting annotator opinion
assessing quality argument complex highly subjective task influenced heterogeneous factor eg prior belief annotator topic domain application crucial impact downstream task eg argument retrieval generation argument mining social science community devoted plenty attention resulting wide variety argument quality dimension large number annotated resource work aim better understanding different aspect argument quality relate practical point view employ adapterfusion pfeiffer et al multitask learning framework improve prediction individual quality dimension injecting knowledge related dimension b efficient modular c serve analysis tool investigate relation different dimension conduct experiment datasets quality dimension find majority dimension learned weighted combination quality aspect dimension adapter fusion improves quality prediction last show benefit approach improving performance extrinsic outofdomain task prediction moderator intervention deliberative forum
social medium additional context often present form annotation metadata post author mention hashtags hyperlink refer annotation nontextual unit ntus posit ntus provide social context beyond textual semantics leveraging unit enrich social medium text representation work construct ntucentric social heterogeneous network coembed ntus principally integrate ntu embeddings large pretrained language model finetuning additional unit add context noisy shorttext social medium experiment show utilizing ntuaugmented text representation significantly outperforms existing textonly baseline relative point many downstream task highlighting importance context social medium nlp also highlight including ntu context initial layer language model alongside text better using text embedding generated work lead generation holistic general purpose social medium content embedding
hownet
language modelbased pretrained representation become ubiquitous natural language processing shown significantly improve performance neural model great variety task however remains unclear useful general model handling noncanonical text article focusing user generated content ugc study ability bert perform lexical normalisation contribution simple framing lexical normalisation token prediction task enhancing architecture carefully finetuning show bert competitive lexical normalisation model without need ugc resource aside training sentence best knowledge first work done adapting analysing ability model handle noisy ugc data
multilingualism cultural cornerstone europe firmly anchored european treaty including full language equality however language barrier impacting business crosslingual crosscultural communication still omnipresent language technology lts powerful mean break barrier last decade seen various initiative created multitude approach technology tailored europe specific need still immense level fragmentation time ai become increasingly important concept european information communication technology area year ai including many opportunity synergy also misconception overshadowing every topic present overview european lt landscape describing funding programme activity action challenge different country regard lt including current state play industry lt market present brief overview main ltrelated activity eu level last ten year develop strategic guidance regard four key dimension
primary research focus lie domain text style transfer tst fascinating area within natural language processing nlp tst involves transfor mation text desired style approximately preserving underlying content research also driven goal incorporating tst technique nlp system particularly within realm dia logue system intrigued concept stylized dialog response generation aim enhance versatility adaptability dialog system generat ing text response specific style attribute ad vancing understanding tst integration dialogue system research seek contribute broader field humancomputer interaction development robust versatile dialogue system enhanced style transfer capability facili tate engaging personalized conversational experience
research extraction idiomatic multiword expression mwes focused acquisition mwe type present work investigate whether text instance potentially idiomatic mwe actually used idiomatically given context inspired dataset provided cook et al manually analysed instance potentially idiomatic prepositionnoun verb triple frequent pattern among german mwes identify token level idiomatic v literal us dataset sentence provided along morphosyntactic property describe data extraction annotation step discus quantitative result europarl german newspaper corpus discus relationship idiomaticity morphosyntactic fixedness address issue ambiguity literal idiomatic use mwes data show europarl particularly well suited mwe extraction mwes corpus indeed used idiomatically
discovering finegrained category coarsely labeled data practical challenging task bridge gap demand finegrained analysis high annotation cost previous work mainly focus instancelevel discrimination learn lowlevel feature ignore semantic similarity data may prevent model learning compact cluster representation paper propose textitdenoised neighborhood aggregation dna selfsupervised framework encodes semantic structure data embedding space specifically retrieve textitknearest neighbor query positive key capture semantic similarity data aggregate information neighbor learn compact cluster representation make finegrained category separatable however retrieved neighbor noisy contain many falsepositive key degrade quality learned embeddings cope challenge propose three principle filter false neighbor better representation learning furthermore theoretically justify learning objective framework equivalent clustering loss capture semantic similarity data form compact finegrained cluster extensive experiment three benchmark datasets show method retrieve accurate neighbor accuracy improvement outperform stateoftheart model large margin average improvement three metric code data available httpsgithubcomlackeldna
advance deep neural model automatic speech recognition asr yielded dramatic improvement asr quality resourcerich language english asr achieving word error rate comparable human transcriber vast majority world language however lack quantity data necessary approach level accuracy paper use four popular asr toolkits train asr model eleven language limited asr training resource eleven widely spoken language africa asia south america one endangered language central america three critically endangered language north america find single architecture consistently outperforms difference performance far appear related particular feature datasets characteristic language finding important implication future research asr underresourced language asr system language abundant existing medium available speaker may derive benefit simply collecting large amount additional acoustic textual training data community using asr support endangered language documentation effort easily collect data might instead focus exploring multiple architecture hyperparameterizations optimize performance within constraint available data resource
morphological analysis lexical normalization ln important task japanese usergenerated text ugt evaluate compare different maln system constructed publicly available japanese ugt corpus corpus comprises sentence annotated morphological normalization information along category information classified frequent ugtspecific phenomenon experiment corpus demonstrated low performance existing maln method nongeneral word nonstandard form indicating corpus would challenging benchmark research ugt
paper present result graphbased method performing knowledgebased word sense disambiguation wsd technique exploit structural property graph underlying chosen knowledge base method general sense tied particular knowledge base work applied multilingual central repository mcr evaluation performed senseval allwords task main contribution paper twofold evaluated separate combined performance type relation mcr thus indirectly validated content mcr potential wsd obtain stateoftheart result fact yield best result obtained using publicly available data
importance multiword expression mwes language learning well established mwe research evaluated various downstream task syntactic parsing machine translation application computerassisted language learning less explored paper investigates selection mwes graded vocabulary list widely used language teacher student list recommend language acquisition sequence optimize learning efficiency automatically generate list using difficultygraded corpus mwes extracted based semantic compositionality evaluate list ability facilitate text comprehension learner experimental result show proposed method generates higherquality list baseline using collocation measure
nonreferential function language setting group boundary identity construction regulation social proximity rarely found place language technology creation process nevertheless importance postulated literature multiple method include social information large language model llm cover group property gender age geographic relation professional characteristic combination group social characteristic individual feature agent natural artificial play role social interaction studied generated language article explores orchestration prompt engineering retrievalaugmented generation technique linguistic feature social proximity distance language generated llm study us immediacydistance model literature analyse language generated llm different recipient research reveals kinship term almost way displaying immediacy llmmade conversation
document modeling essential variety natural language understanding task propose use external information improve document modeling problem framed sentence extraction develop framework composed hierarchical document encoder attentionbased extractor attention external information evaluate model extractive document summarization external information image caption title document answer selection external information question show model consistently outperforms strong baseline term informativeness fluency cnn document summarization achieves stateoftheart result answer selection wikiqa newsqa
ongoing covid pandemic brought online education forefront pedagogical discussion make increased interest sustainable postpandemic era online course must built strong pedagogical foundation long history pedagogic research many principle framework model available help teacher model cover different teaching perspective constructive alignment feedback learning environment paper discus designed implemented online natural language processing nlp course following constructive alignment adhering pedagogical principle ltu examining course analyzing student evaluation form show met goal successfully delivered course furthermore discus additional benefit resulting current mode delivery including increased reusability course content increased potential collaboration university lastly also discus improve current course design
previous existing visual question answering vqa system commonly use graph neural networksgnns extract visual relationship semantic relation spatial relation however study use gnns typically ignore importance relation simply concatenate output multiple relation encoders paper propose novel layer architecture fuse multiple visual relation attention mechanism address issue specifically develop model us question embedding joint embedding encoders obtain dynamic attention weight regard type question using learnable attention weight proposed model efficiently use necessary visual relation feature given question experimental result vqa dataset demonstrate proposed model outperforms existing graph attention networkbased architecture additionally visualize attention weight show proposed model assigns higher weight relation relevant question
prior knowledge item characteristic difficulty response time without pretesting item substantially save time cost highstandard test development using variety machine learning ml algorithm present study explored several nonlinguistic feature cohmetrix index along mpnet word embeddings predict difficulty response time sample medical test item prediction task contribution embeddings model already containing feature found extremely limited moreover comparison feature importance score across two prediction task revealed cohesionbased feature strongest predictor difficulty prediction response time primarily dependent lengthrelated feature
capturing discriminative attribute sharedtask tenth task conjoint semeval task predict word capture distinguishing attribute one word another use glove word embedding pretrained openly sourced corpus task base representation initially established varied dimension representation evaluated based validation score two model first svm based classifier second one dimension cnn model score used develop representation vector combination considering various distance measure measure correspond offset vector concatenated feature mainly improve upon fscore best accuracy feature tuned validation score achieve highest fscore evaluation narrowed two representation classified cnn model total dimension length final submission two latter feature representation delivered best fscore per result
paper explains talpupc participation gendered pronoun resolution sharedtask st acl workshop gender bias natural language processing implemented two model mask language modeling using pretrained bert adjusted work classification problem proposed solution based word probability original bert model using common english name replace original test name
multimodal sarcasm detection aim identify whether given sample multimodal information ie text image sarcastic received increasing attention due rapid growth multimodal post modern social medium however mainstream model process input modality holistic manner resulting redundant unrefined information moreover representation different modality entangled one common latent space perform complex crossmodal interaction neglecting heterogeneity distribution gap different modality address issue propose novel framework dmmd short disentangled multigrained multimodal distilling multimodal sarcasm detection conduct multigrained knowledge distilling ie intrasubspace intersubspace based disentangled multimodal representation concretely representation modality disentangled explicitly modalityagnosticspecific subspace transfer crossmodal knowledge conducting intrasubspace knowledge distilling selfadaptive pattern also apply mutual learning regularize underlying intersubspace consistency extensive experiment commonly used benchmark demonstrate efficacy dmmd cuttingedge method encouragingly visualization result indicate multimodal representation display meaningful distributional pattern hope helpful community multimodal knowledge transfer
automatic speech recognition asr come significant advancement course several decade transitioning rulebased method statistical approach ultimately use endtoend ee framework phenomenon continues progression machine learning deep learning methodology ee approach asr demonstrated predominant success case resourceful language larger annotated corpus however accuracy quite low lowresourced language nepali regard languagespecific tool tokenizers seem play vital role improving performance ee model lowresourced language like nepali paper propose pronunciationaware syllable tokenizer nepali language improves result ee model experiment confirm introduction proposed tokenizer yield better performance character error rate cer compared languageindependent tokenizers
paper focus text detoxification ie automatically converting toxic text nontoxic text task contributes safer respectful online communication considered text style transfer tst task text style change content preserved present three approach knowledge transfer similar task ii multitask learning approach combining sequencetosequence modeling various toxicity classification task iii delete reconstruct approach support research utilize dataset provided dementieva et al contains multiple version detoxified text corresponding toxic text experiment selected best variant expert human annotator creating dataset toxic sentence paired single appropriate detoxified version additionally introduced small hindi parallel dataset aligning part english dataset suitable evaluation purpose result demonstrate approach effectively balance text detoxification preserving actual content maintaining fluency
annotator fungible demographic life experience background contribute label data however nlp recently considered annotator identity might influence decision present popquorn potatoprolific dataset questionanswering offensiveness text rewriting politeness rating demographic nuance popquorn contains annotation annotator drawn representative sample regarding sex age race u population series analysis show annotator background play significant role judgment work show background previously considered nlp eg education meaningful considered study suggests understanding background annotator collecting label demographically balanced pool crowd worker important reduce bias datasets dataset annotator background annotation interface available urlhttpsgithubcomjiaxinpeipotatoprolificdataset
dialogue model often enriched extensive external knowledge provide informative response retrievalaugmented pipeline nevertheless retrievalaugmented approach rely finely annotated retrieval training data knowledgegrounded response generation data making costly transfer tackle challenge paper proposed retrievalfree approach kidg automatically turning knowledge document simulated multiturn dialogue multidocument traversal algorithm simulated knowledgeintensive dialogue constructed kidg one domain easily used train enhance pretrained dialogue model knowledge wrt domain without costly annotation conduct extensive experiment comparing retrievalaugmented model variety retrievalfree model found dialogue model enhanced data simulated kidg largely outperform stateoftheart retrievalfree method achieves comparable performance compared retrievalaugmented method better cheaper domain transfer
recent year witnessed surge publication aimed tracing temporal change lexical semantics using distributional method particularly predictionbased word embedding model however vein research lack cohesion common terminology shared practice established area natural language processing paper survey current state academic research related diachronic word embeddings semantic shift detection start discussing notion semantic shift continue overview existing method tracing timerelated shift word embedding model propose several ax along method compared outline main challenge emerging subfield nlp well prospect possible application
translation produced mt system automatically assigned number reflects mt system confidence quality describe design confidence index focus contribution source analysis play crucial role many mt system including various problematic area source analysis identified impact overall confidence index given describe two method training confidence index one handtuning heuristic linear regression analysis
many machine reading natural language understanding task require reading supporting text order answer question example question answering supporting text newswire wikipedia article natural language inference premise seen supporting text hypothesis question providing set useful primitive operating single framework related task would allow expressive modelling easier model comparison replication end present jack reader jack framework machine reading allows quick model prototyping component reuse evaluation new model existing datasets well integrating new datasets applying growing set implemented baseline model jack currently supporting limited three task question answering natural language inference link prediction developed aim increasing research efficiency code reuse
quality machine translation mt improves research improving discourse automatic translation becomes viable resulted increase amount work discourse mt however many existing model metric yet integrate insight part due evaluation methodology based largely matching single reference time mt increasingly used pipeline task semantic element translation process need properly integrated task moreover order take mt another level need judge output based single reference translation based notion fluency adequacy ideally reference source text
paper present system us convolutional neural network long shortterm memory cnnlstm model complete task cnnlstm model two combined part cnn extract local ngram feature within tweet lstm composes feature capture longdistance dependency across tweet additionally used three model cnn lstm bilstm baseline algorithm introduced model showed good performance experimental result
paper present nlipt first portuguese dataset compiled native language identification nli task identifying author first language based second language writing dataset includes student essay written learner european portuguese native speaker following l chinese english spanish german russian french japanese italian dutch tetum arabic polish korean romanian swedish nlipt includes original student text four different type annotation po finegrained po constituency parses dependency parses nlipt used nli also research several topic field second language acquisition educational nlp discus possible application dataset present result obtained first lexical baseline system portuguese nli
data availability bottleneck early stage development new capability intelligent artificial agent investigate use text generation technique augment training data popular commercial artificial agent across category functionality goal faster development new functionality explore variety encoderdecoder generative model synthetic training data generation propose using conditional variational autoencoders approach requires direct optimization work well limited data significantly outperforms previous controlled text generation technique generated data used additional training sample extrinsic intent classification task leading improved performance absolute fscore lowresource case validating usefulness approach
paper introduces reflectsumm novel summarization dataset specifically designed summarizing student reflective writing goal reflectsumm facilitate developing evaluating novel summarization technique tailored realworld scenario little training data potential implication opinion summarization domain general educational domain particular dataset encompasses diverse range summarization task includes comprehensive metadata enabling exploration various research question supporting different application showcase utility conducted extensive evaluation using multiple stateoftheart baseline result provide benchmark facilitating research area
recent development machine translation speech translation opening opportunity computerassisted translation tool extended automation function subtitling tool recently adapted postediting providing automatically generated subtitle featuring machine translation also automatic segmentation synchronisation professional subtitlers think postediting automatically generated subtitle work conduct survey collect subtitlers impression feedback use automatic subtitling workflow finding show despite current limitation stemming mainly speech processing error automatic subtitling seen rather positively potential future
multimodal fusion address problem analyzing spoken word multimodal context including visual expression prosodic cue even multimodal model lead performance improvement often unclear whether bimodal trimodal interaction learned whether modality processed independently propose multimodal residual optimization mro separate unimodal bimodal trimodal interaction multimodal model improves interpretability multimodal interaction quantified inspired occam razor main intuition mro simpler unimodal contribution learned learning complex bimodal trimodal interaction example bimodal prediction learn correct mistake residual unimodal prediction thereby letting bimodal prediction focus remaining bimodal interaction empirically observe mro successfully separate unimodal bimodal trimodal interaction degrading predictive performance complement empirical result human perception study observe mro learns multimodal interaction align human judgment
scarcity data technological limitation resourcepoor language developing country like india pose threat development sophisticated nlu system healthcare assess current status various stateoftheart language model healthcare paper study problem initially proposing two different healthcare datasets indian healthcare query intentwebmd mg ihqidwebmd ihqidmg one real world indian hospital query data english multiple indic language hindi bengali tamil telugu marathi gujarati annotated query intent well entity aim detect query intent corresponding entity perform extensive experiment set model various realistic setting explore two scenario based access english data less costly access target language data expensive analyze context specific practical relevancy empirical analysis result expressed term overall fscore show approach practically useful identify intent entity
well annotated corpus shown great value linguistic nonlinguistic research supporting machinelearning many nonresearch activity including language teaching minority language annotated corpus help understanding language usage norm among native nonnative speaker providing valuable information lexicography teaching helping combat decline speaker number time minority language suffer fewer available language resource majority language far lessdeveloped annotation tooling date little work semantic annotation irish paper report progress date building standard toolset semantic annotation irish including novel method evaluation semantic annotation small corpus irish language data manually annotated semantic tag manually checked semantic type tagging framework developed using existing technology using semantic lexicon built variety source semantic disambiguation method added view increasing accuracy framework tested using manually tagged corpus resulting lexical coverage almost tag accuracy development ongoing part larger corpus development project plan include expansion manually tagged corpus expansion lexicon exploration disambiguation method first semantic tagger irish knowledge hoped research form sound basis semantic annotation irish corpus future
instructional video make learning knowledge efficient providing detailed multimodal context procedure instructiona unique challenge posed instructional video keyobject degeneracy single modality fails sufficiently capture key object referred procedure machine system degeneracy disturb performance downstream task dense video captioning leading generation incorrect caption omitting key object repair degeneracy propose retrievalbased framework augment model representation presence keyobject degeneracy validate effectiveness generalizability proposed framework baseline using modality keyobject degeneracy
understanding narrative requires reading line turn requires interpreting likely cause effect event even mentioned explicitly paper introduce cosmos qa largescale dataset problem require commonsensebased reading comprehension formulated multiplechoice question stark contrast existing reading comprehension datasets question focus factual literal understanding context paragraph dataset focus reading line diverse collection people everyday narrative asking question might possible reason would happened require reasoning beyond exact text span context establish baseline performance cosmos qa experiment several stateoftheart neural architecture reading comprehension also propose new architecture improves competitive baseline experimental result demonstrate significant gap machine human performance pointing avenue future research commonsense machine comprehension dataset code leaderboard publicly available urlhttpswilburonegithubiocosmos
automatic categorization support ticket fundamental tool modern business request commonly composed concise textual description noisy filled technical jargon paper test effectiveness pretrained lm classification issue related software bug first test several strategy produce single ticketwise representation starting bertgenerated word embeddings showcase simple yet effective way build multilevel classifier categorization document two hierarchically dependent label experiment public bug dataset compare result standard bertbased traditional svm classifier finding suggest embedding strategy hierarchical label dependency considerably impact classification accuracy
paper describes submission team hadtubingen semeval task offenseval identifying categorizing offensive language social medium participated three subtasks subtask offensive language identification subtask b automatic categorization offense type subtask c offense target identification baseline model used long shortterm memory recurrent neural network lstm identify categorize offensive tweet task experimented external database postprocessing step enhance result made model best macroaverage f score obtained subtasks b c respectively
paper study new task federated learning fl semantic parsing multiple client collaboratively train one global model without sharing semantic parsing data leveraging data multiple client fl paradigm especially beneficial client little training data develop datahungry neural semantic parser propose evaluation setup study task repurpose widelyused singledomain texttosql datasets client form realistic heterogeneous fl setting collaboratively train global model standard fl algorithm suffer high client heterogeneity realistic setup propose novel loss reduction adjusted reweighting lorar mechanism adjusts client contribution global model update based training loss reduction round intuition larger loss reduction away current global model client local optimum larger weight client get applying lorar three widely adopted fl algorithm fedavg fedopt fedprox observe performance improved substantially average absolute gain macroavg client smaller datasets enjoy larger performance gain addition global model converges faster almost client
paper report obtained result two constituency parser trained bultreebank hpsgbased treebank bulgarian reduce data sparsity problem propose using brown word clustering offline clustering map word treebank create classbased treebank observation show class outnumber po tag result better since approach add another dimension abstraction comparison lemma coarsegrained representation used training statistical parser
paper give overview recent development german reference corpus dereko term growth maximising relevant corpus stratum metadata legal issue current future research interface due recent acquisition new license dereko grown factor four first half mostly area newspaper text presently contains billion word token stratum like fictional text web corpus particular cmc text spoken conceptually written text also increased significantly report newly acquired corpus led major increase principle strategy behind corpus acquisition activity solution emerging legal organisational technical challenge
comparative knowledge eg steel stronger heavier styrofoam essential component world knowledge yet understudied prior literature paper harvest dramatic improvement knowledge capability language model largescale comparative knowledge base ease acquisition comparative knowledge much higher extremescale model like gpt compared considerably smaller weaker counterpart gpt even powerful model exempt making error thus ask extent model different scale able generate valid diverse comparative knowledgewe introduce neurocomparatives novel framework comparative knowledge distillation overgenerated language model gptvariants llama followed stringent filtering generated knowledge framework acquires comparative knowledge everyday object producing corpus comparison entity pair x larger diverse existing resource moreover human evaluation show neurocomparatives outperform existing resource term validity absolute improvement acquired neurocomparatives lead performance improvement five downstream taskswe find neurosymbolic manipulation smaller model offer complementary benefit currently dominant practice prompting extremescale language model knowledge distillation
propose straightforward vocabulary adaptation scheme extend language capacity multilingual machine translation model paving way towards efficient continual learning multilingual machine translation approach suitable largescale datasets applies distant language unseen script incurs minor degradation translation performance original language pair provides competitive performance even case possess monolingual data new language
keyphrase generation task consisting generating set word phrase highlight main topic document datasets keyphrase generation biomedical domain meet expectation term size training generative model paper introduce kpbiomed first largescale biomedical keyphrase generation dataset collected pubmed abstract train release several generative model conduct series experiment showing using large scale datasets improves significantly performance present absent keyphrase generation dataset model available online
standard english malaysian english exhibit notable difference posing challenge natural language processing nlp task malaysian english experiment using stateoftheart named entity recognition ner solution malaysian english news article highlight handle morphosyntactic variation malaysian english unfortunately existing datasets mainly based standard english sufficient enhance nlp task malaysian english best knowledge annotated dataset used improve model address issue constructed malaysian english news men dataset contains news article manually annotated entity relation finetuned spacy ner tool validated dataset tailormade malaysian english could significantly improve performance ner malaysian english paper present effort acquire data annotation methodology detailed analysis annotated dataset ensure quality annotation measured interannotator agreement iaa disagreement resolved subject matter expert adjudication rigorous quality check developed dataset entity relation instance finally discus spacy finetuning setup analysis ner performance unique dataset contribute significantly advancement nlp research malaysian english allowing researcher accelerate progress particularly ner relation extraction
introduce constituency parser based bilstm encoder adapted recent work cross huang b kiperwasser goldberg incorporate lower level character bilstm ballesteros et al plank et al model two important interface constituency parsing auxiliary task supervised word level partofspeech po morphological tagging ii functional label prediction spmrl dataset parser obtains stateoftheart result constituency parsing without requiring either predicted po morphological tag output labelled dependency tree
stateoftheart lstm language model trained large corpus learn sequential contingency impressive detail shown acquire number nonlocal grammatical dependency success investigate whether supervision hierarchical structure enhances learning range grammatical dependency question previously addressed subjectverb agreement using controlled experimental method psycholinguistics compare performance wordbased lstm model versus recurrent neural network grammar rnngs dyer et al represent hierarchical syntactic structure use neural control deploy lefttoright processing two class nonlocal grammatical dependency englishnegative polarity licensing fillergap dependenciestested range configuration using training data model find rnng outperforms lstm type grammatical dependency even learns many island constraint fillergap dependency structural supervision thus provides data efficiency advantage purely stringbased training neural language model acquiring humanlike generalization nonlocal grammatical dependency
great practical value study multidomain neural machine translation nmt mainly focus using mixeddomain parallel sentence construct unified model allows translation switch different domain intuitively word sentence related domain varying degree exert disparate impact multidomain nmt modeling based intuition paper devote distinguishing exploiting wordlevel domain context multidomain nmt end jointly model nmt monolingual attentionbased domain classification task improve nmt follows based sentence representation produced domain classifier adversarial domain classifier generate two gating vector use construct domainspecific domainshared annotation later translation prediction via different attention model utilize attention weight derived targetside domain classifier adjust weight target word training objective enabling domainrelated word greater impact model training experimental result chineseenglish englishfrench multidomain translation task demonstrate effectiveness proposed model source code paper available github urlhttpsgithubcomdeeplearnxmuwdcnmt
variational encoderdecoder ved encodes source information set random variable using neural network turn decoded target data using another neural network natural language processing sequencetosequence seqseq model typically serve encoderdecoder network combined traditional deterministic attention mechanism variational latent space may bypassed attention model thus becomes ineffective paper propose variational attention mechanism ved attention vector also modeled gaussian distributed random variable result two experiment show without loss quality proposed method alleviates bypassing phenomenon increase diversity generated sentence
many realworld application require making multiple prediction text finetuning large pretrained language model downstream task cause computational burden inference time due several time forward pass amortize computational cost freezing language model building lightweight model downstream task based fixed text representation common solution accordingly learn fixed general text representation generalize well unseen downstream task becomes challenge previous work shown generalizability representation improved finetuning pretrained language model source task multitasking way work propose prefixbased method learn fixed text representation source task learn taskspecific prefix source task independently combine get final representation experimental result show prefixbased training performs better multitasking training update text representation smaller computational cost multitasking training
paper present first phase ongoing spacebank project attempt create linguistic resource annotating reasoning spatial information text spacebank spatial counterpart timebank electronic resource temporal semantics reasoning paper focus building ontology lexicalized spatial concept textual occurrence concept ontology annotated using spaceml language briefly described spacebank designed integrated timebank spatiotemporal model textual information
segmentation problem one fundamental challenge associated name entity recognition ner task aim reduce boundary error detecting sequence entity word considerable number advanced approach proposed exhibit performance deterioration entity become longer inspired previous work multitask strategy used solve segmentation problem design similarity based auxiliary classifier sac distinguish entity word nonentity word unlike conventional classifier sac us vector indicate tag therefore sac calculate similarity word tag compute weighted sum tag vector considered useful feature ner task empirical result used verify rationality sac structure demonstrate sac model potential performance improvement baseline approach
describe national research council canada nrc neural machine translation system germanupper sorbian supervised track shared task unsupervised mt low resource supervised mt model ensemble transformer model built using combination bpedropout lexical modification backtranslation
paper explore use nlp system assist work security force monitor sfm sfm creates data organizational structure command personnel operation police army security force assist human right researcher journalist litigator work help identify bring account specific unit personnel alleged committed abuse human right international criminal law paper present nlp system extract english language news report name security force unit biographical detail personnel infers formal relationship published alongside paper system code training dataset find experimental nlp system performs task fair good level performance sufficient justify development live workflow give insight whether performance translates saving time resource would make effective technical intervention
pretrained seqseq model achieved stateoftheart result grammatical error correction task however model still suffer prediction bias due unidirectional decoding thus propose bidirectional transformer reranker btr reestimates probability candidate sentence generated pretrained seqseq model btr preserve seqseqstyle transformer architecture utilizes bertstyle selfattention mechanism decoder compute probability target token using masked language modeling capture bidirectional representation target context guiding reranking btr adopts negative sampling objective function minimize unlikelihood inference btr give final result comparing reranked top result original one acceptance threshold experimental result show reranking candidate pretrained seqseq model tbase btr top tbase could yield f score conll bea test set respectively yield gleu score jfleg corpus improvement point compared original tbase furthermore reranking candidate tlarge btr top tbase improved original tlarge point bea test set
established crossdocument coreference resolution cdcr datasets contain eventcentric coreference chain event entity identity relation datasets establish strict definition coreference relation across related test typically ignore anaphora vague contextdependent loose coreference relation paper qualitatively quantitatively compare annotation scheme ecb cdcr dataset identity coreference relation newswcl cdcr dataset mix loose contextdependent strict coreference relation propose phrasing diversity metric pd encounter diversity full phrase unlike previously proposed metric allows evaluate lexical diversity cdcr datasets higher precision analysis show coreference chain newswcl lexically diverse ecb annotating newswcl lead lower intercoder reliability discus different task cdcr datasets create cdcr model ie lexical disambiguation lexical diversity finally ensure generalizability cdcr model propose direction cdcr evaluation combine cdcr datasets multiple annotation scheme focus various property coreference chain
short paper compare existing value system approach nlp hci collecting narrative data building parallel discussion shed light challenge facing popular nlp dataset type discus relation widelyused narrativebased hci research method highlight point nlp method broaden qualitative narrative study particular point towards contextuality positionality dataset size open research design central point difference window collaboration studying narrative use case narrative work contributes larger conversation regarding possibility bridging nlp hci speculative mixedmethods
introduce instructabsa instruction learning paradigm aspectbased sentiment analysis absa subtasksour method introduces positive negative neutral example training sample instruction tune model tkinstruct absa subtasks yielding significant performance improvement experimental result sem eval datasets demonstrate instructabsa outperforms previous stateoftheart sota approach term extraction ate sentiment classificationatsc sentiment pair extraction aspe subtasksin particular instructabsa outperforms previous stateoftheart sota rest ate subtask point rest atsc subtask point lapt aope subtask point surpassing x larger modelswe get competitive result aooe aope aoste acosqe subtasks indicating strong generalization ability subtasks exploring sample efficiency reveals train data required get competitive result instruction tuning approach lastly assess quality instruction observe instructabsas performance experience decline textasciitilde adding misleading example
nonautoregressive approach aim improve inference speed translation model requiring single forward pas generate output sequence instead iteratively producing predicted token consequently translation quality still tends inferior autoregressive counterpart due several issue involving output token interdependence work take step back revisit several technique proposed improving nonautoregressive translation model compare combined translation quality speed implication thirdparty testing environment provide novel insight establishing strong baseline using length prediction ctcbased architecture variant contribute standardized bleu chrf ter score using sacrebleu four translation task crucially missing inconsistency use tokenized bleu lead deviation bleu point opensourced code integrated fairseq reproducibility
paper introduce two advancement automatic keyphrase extraction ake space keygames pke keygames unsupervised ake framework employ concept evolutionary game theory consistent labelling problem ensure consistent classification candidate keyphrase nonkeyphrase pke python based pipeline built top existing pke library standardize various ake step namely candidate extraction evaluation ensure truly systematic comparable performance analysis ake model experiment section compare performance keygames across three publicly available datasets inspec semeval duc result quoted existing stateoftheart model well performance reproduced using pke result show keygames outperforms stateoftheart system generalizing better input document different domain length pkes preprocessing brings improvement several system quoted performance well
paper present methodology development taskbased evaluation phonological model improve accuracy cognate terminology identification may potentially used application transliteration improving characterbased nmt terminology translation remains bottleneck mt especially underresourced language domain automated identification cognate term address problem proposed phonological model explicitly represent distinctive phonological feature character acoustic type eg vowel consonant voiced unvoiced sonant place manner articulation closedopen frontback vowel plosive fricative labial dental glottal consonant advantage representation explicate information character internal structure rather treat elementary atomic unit comparison placing grapheme feature space provides additional information articulatory pronunciationbased acoustic soundbased distance similarity article present experimental result using proposed phonological model extracting cognate terminology phonologically aware levenshtein edit distance top cognate ranking metric outperforms baseline characterbased levenshtein project resource released urlhttpsgithubcombogdanbabychcognatesphonology
computational literary study challenging task predicting quality readerappreciation narrative text confounded volatile definition quality vast feature space may considered modeling paper explore two different type feature set stylistic feature one hand semantic feature conduct experiment corpus english language literary novel published th th century using goodreads rating proxy readerappreciation examining potential approach find type book predictable one model may indicate text different prominent characteristic stylistic complexity certain narrative progression sentimentlevel
current chinese social medium text summarization model based encoderdecoder framework although generated summary similar source text literally low semantic relevance work goal improve semantic relevance source text summary chinese social medium summarization introduce semantic relevance based neural model encourage high semantic similarity text summary model source text represented gated attention encoder summary representation produced decoder besides similarity score representation maximized training experiment show proposed model outperforms baseline system social medium corpus
recent work linear text segmentation shown new stateoftheart result nearly every year time however recent advance include variety different element make difficult evaluate individual component proposed method bring improvement task generally actually work linear text segmentation moreover evaluating text segmentation notoriously difficult use metric pk widely used existing literature present specific problem complicates fair comparison segmentation model work draw number existing work assess stateoftheart linear text segmentation investigating architecture feature work best task present three model representative variety approach compare existing method inspect element composing give complete picture technique successful might case time highlight specific feature pk bias result report result using different setting give future literature comprehensive set baseline result future development hope work serve solid foundation foster research area overcoming taskspecific difficulty evaluation setting providing new stateoftheart result
natural language processing nlp application named entity recognition ner lowresource corpus benefit recent advance development large language model llm still need larger annotated datasets research article introduces methodology generating translated version annotated datasets crosslingual annotation projection freely available github link httpsgithubcomjamilprogcrosslingualbertannotationprojection leveraging language agnostic bertbased approach efficient solution increase lowresource corpus human effort using already available open data resource quantitative qualitative evaluation often lacking come evaluating quality effectiveness semiautomatic data generation strategy evaluation crosslingual annotation projection approach showed effectiveness high accuracy resulting dataset practical application methodology present creation french annotated resource semantic information medical entity detection frasimed annotated corpus comprising synthetic clinical case french corpus available researcher practitioner develop refine french natural language processing nlp application clinical field httpszenodoorgrecord making largest open annotated corpus linked medical concept french
practical lexical function plf model model computational distributional semantics attempt strike balance expressivity learnability predicting phrase meaning show competitive result investigate well plf carry free word order language given build observation predicateargument combination harder recover free word order language evaluate variant plf croatian using new lexical substitution dataset find plf work well croatian english demonstrate strength lie modeling verb free word order affect less robust plf variant
free text field within electronic health record ehrs contain valuable clinical information often missed conducting research using ehr database one type information medication always available structured field especially mental health record use case require medication information also generally require associated temporal information eg current past attribute eg dose route frequency purpose study develop corpus medication annotation mental health record aim provide complete picture behind mention medication health record including additional contextual information around create resource use developing evaluating application extraction medication ehr text thus far analysis temporal information related medication mentioned sample mental health record conducted purpose analysis understand complexity medication mention associated temporal information free text ehrs specific focus mental health domain
paper present implementation machine translation mt lambani lowresource indian tribal language english highresource universal language lambani spoken nomadic tribe indian state karnataka similarity lambani various indian language implement englishlambani mt system followed transfer learning approach englishkannada parent mt model implementation performance englishlambani mt system discussed paper since lambani influenced various language explored possibility getting better mt performance using parent model associated related indian language specifically experimented englishgujarati englishmarathi additional parent model compare performance three different englishlambani mt system derived three parent language model observation presented paper additionally also explore effect freezing encoder layer decoder layer change performance
training testing many possible parameter model architecture stateoftheart machine translation automatic speech recognition system cumbersome task usually require long pipeline command reaching preprocessing training data postprocessing evaluating output
recently characterword lattice structure proved effective chinese named entity recognition ner incorporating word information however since lattice structure complex dynamic latticebased model hard fully utilize parallel computation gpus usually low inference speed paper propose flat flatlattice transformer chinese ner convert lattice structure flat structure consisting span span corresponds character latent word position original lattice power transformer welldesigned position encoding flat fully leverage lattice information excellent parallel ability experiment four datasets show flat outperforms lexiconbased model performance efficiency
paper introduces dataset resource build valpal database verb valency pattern alternation adding number ancient language completely absent valpal number new feature enable direct comparison diachronic synchronic verb valpal contains basic frame ideally possible valency alternation allowed verb eg passive causative reflexive etc order enable comparison among alternation additional level added alternation class overcomes issue comparing language specific alternation added individual contributor valpal valpal main aim typological comparison data collection variously carried using questionnaire secondary source largely drawing native speaker intuition contributor working ancient language entail methodological change data extracted corpus led rethinking notion valency usagebased feature verb planning future addition corpus data modern language database show impact ancient language theoretical reflection
increasingly large percentage natural language processing nlp task center around generation text probabilistic language model despite trend technique improving specifying preference generated text rely mostly intuitionbased heuristic lack unified presentation motivation practical implementation success pitfall practitioner must therefore choose somewhat blindly generation algorithmslike topp sampling beam searchwhich lead wildly different result time language generation research continues criticize improve standard toolbox adding entropy state field tutorial provide centralized cohesive discussion critical consideration choosing generate language model cover wide range empiricallyobserved problem like degradation hallucination repetition corresponding proposed algorithmic solution recent research like topp sampling successor discus subset algorithm unified light stochastic generation strategy framed locally adapting probability model avoid failure case finally cover method controlled generation go beyond ensuring coherence ensure text exhibit specific desired property aim nlp practitioner researcher leave tutorial unified framework use evaluate contribute latest research language generation
describe ulfri system used subtask semeval task patronizing condescending language detection model based roberta model modified two way injecting additional knowledge coreference named entity dependency relation sentiment leveraging task uncertainty using soft label monte carlo dropout threshold optimization find injection additional knowledge helpful uncertainty management mechanism lead small consistent improvement final system based finding achieves f online evaluation ranking th system
paper demonstrates multilingual pretraining multilingual finetuning critical facilitating crosslingual transfer zeroshot translation neural machine translation nmt model tested source language unseen supervised training following idea present sixt strong manytoenglish nmt model support source language trained parallel dataset six source language sixt initializes decoder embedding full encoder xlmr large train encoder decoder layer simple twostage training strategy sixt achieves impressive performance manytoenglish translation significantly outperforms criss mm two strong multilingual nmt system average gain bleu respectively additionally sixt offer set model parameter finetuned unsupervised task demonstrate adding sixt initialization outperforms stateoftheart explicitly designed unsupervised nmt model sitextlesstextgreateren netextlesstextgreateren average bleu applied zeroshot crosslingual abstractive summarization produce average performance gain rougel mbartft conduct detailed analysis understand key ingredient sixt including multilinguality auxiliary parallel data positional disentangled encoder crosslingual transferability encoder
conduct largescale systematic study evaluate existing evaluation method natural language generation context generating online product review compare humanbased evaluator variety automated evaluation procedure including discriminative evaluator measure well machinegenerated text distinguished humanwritten text well word overlap metric assess similar generated text compare humanwritten reference determine extent different evaluator agree ranking dozen stateoftheart generator online product review find human evaluator correlate well discriminative evaluator leaving bigger question whether adversarial accuracy correct objective natural language generation general distinguishing machinegenerated text challenging even human evaluator human decision correlate better lexical overlap find lexical diversity intriguing metric indicative assessment different evaluator postexperiment survey participant provides insight evaluate improve quality natural language generation system
authorship attribution task identifying author given text key finding representation differentiate author existing approach typically use manually designed feature capture datasets content style approach datasetdependent yield inconsistent performance across corpus work propose learn authorspecific representation finetuning pretrained generic language representation contrastive objective contrax show contrax learns representation form highly separable cluster different author advance stateoftheart multiple human machine authorship attribution benchmark enabling improvement crossentropy finetuning however find contrax improves overall accuracy cost sacrificing performance author resolving tension important direction future work best knowledge first integrate contrastive learning pretrained language model finetuning authorship attribution
work present detailed analysis translation error perceived reader comprehensibility andor adequacy issue main finding good comprehensibility similarly good fluency mask number adequacy error major adequacy error fully comprehensible thus fully misleading reader accept incorrect information another major adequacy error perceived almost comprehensible thus potentially misleading also vast majority omission hidden comprehensibility analysis misleading translation revealed frequent error type ambiguity mistranslation noun phrase error wordbyword translation untranslated word subjectverb agreement spelling error source text however none error type appears exclusively misleading translation also frequent fully incorrect incomprehensible inadequate discarded correct incomprehensible adequate translation deeper analysis needed potentially detect underlying phenomenon specifically related misleading translation
gwap design might tremendous effect popularity course also quality data collected paper comparison undertaken two gwaps building term association list namely jeuxdemots quicky goose comparing game design cohen kappa associative list various configuration computed order assess likeness difference data provide
present result shared task dialect msa translation tackle challenge posed diverse arabic dialect machine translation covering gulf egyptian levantine iraqi maghrebi dialect task offer sentence msa dialect finetuning alongside blind test sentence leveraging gpt stateoftheart language model method achieved bleu score endeavor hold significant implication neural machine translation nmt system targeting lowresource langu age linguistic variation additionally negative experiment involving finetuning arat language left behind nllb using madar dataset resulted bleu score respectively future direction include expanding dataset incorporate arabic dialect exploring alternative nmt architecture enhance translation capability
despite subjective nature many nlp task nlu evaluation focused using majority label presumably high agreement ground truth less attention paid distribution human opinion collect chaosnli dataset total annotation study collective human opinion oftused nli evaluation set dataset created collecting annotation per example example snli mnli example nli analysis reveals high human disagreement exists noticeable amount example datasets stateoftheart model lack ability recover distribution human label model achieve nearperfect accuracy subset data high level human agreement whereas barely beat random guess data low level human agreement compose common error made stateoftheart model evaluation set question validity improving model performance old metric lowagreement part evaluation datasets hence argue detailed examination human agreement future data collection effort evaluating model output distribution collective human opinion
cope covid pandemic many jurisdiction introduced new altered existing legislation even though new rule often communicated public news article remains challenging layperson learn currently allowed forbidden since news article typically reference underlying law investigate automated approach extract legal claim news article match claim corresponding applicable law examine feasibility two task concerning claim covidrelated law berlin germany task create make publicly available data set report result initial experiment obtain promising result transformerbased model achieve f claim extraction f law matching albeit conceptual limitation furthermore discus challenge current machine learning approach legal language processing ability complex legal reasoning task
word embeddings trained largescale historical corpus illuminate human bias stereotype perpetuate social inequality embeddings often trained separate vector space model defined according different attribute interest paper introduce single unified dynamic embedding model learns attributespecific word embeddings apply novel datasettalk radio show around usto analyze perception refugee validate model benchmark dataset apply two corpus talk radio show averaging million word produced one month across station city finding suggest dynamic word embeddings capable identifying nuanced difference public discourse contentious topic suggesting usefulness tool better understanding public perceives engages different issue across time geography dimension
composition model distributional semantics used construct phrase representation representation word composition model typically situated two end spectrum either small number parameter compose phrase way perform wordspecific composition cost far larger number parameter paper propose transformation weighting transweight composition model consistently outperforms existing model nominal compound adjectivenoun phrase adverbadjective phrase english german dutch transweight drastically reduces number parameter needed compared best model literature composing similar word way
paper introduces upgrade training corpus linguistic annotation modern standard slovene enhancement span size corpus depth annotation layer revised suk corpus building predecessor ssjk doubled size containing million token expansion integrates three preexisting openaccess datasets undergone automatic tagging meticulous manual review across multiple annotation layer represented varying proportion layer span tokenization segmentation lemmatization multexteast morphology universal dependency jossyn syntax semantic role labeling named entity recognition newly incorporated coreference paper illustrates annotation process layer also presenting result new classlastanza annotation tool trained suk corpus data one fundamental language resource modern slovene suk corpus call constant development outlined concluding section
paper address task utterance level emotion recognition conversation using commonsense knowledge propose cosmic new framework incorporates different element commonsense mental state event causal relation build upon learn interaction interlocutor participating conversation current stateoftheart method often encounter difficulty context propagation emotion shift detection differentiating related emotion class learning distinct commonsense representation cosmic address challenge achieves new stateoftheart result emotion recognition four different benchmark conversational datasets code available urlhttpsgithubcomdeclarelabconvemotion
nepal script also known prachalit script widely used script nepal bhasa native language kathmandu valley nepal derived brahmi script nepal script developed th century extensively used till th century replaced devanagari script numerous ancient manuscript inscription document written nepal script still available containing immense knowledge architecture art astrology ayurveda literature music tantrism etc preserve revive nepal bhasa digitizing document play crucial role paper present work text recognition nepal script implementation includes nepal script text recognizer based crnn ctc architecture aided line word segmentation leveraging carefully curated dataset encompasses handwritten printed text nepal script work achieved cer wer dataset used work available nepal script text dataset kaggle paper explores associated challenge due complex nature script conjuncts modifier variation current state script
paper present mediqa shared task organized aclbionlp workshop shared task motivated need develop relevant method technique gold standard inference entailment medical domain application improve domain specific information retrieval question answering system mediqa includes three task natural language inference nli recognizing question entailment rqe question answering qa medical domain team participated challenge achieving accuracy nli task rqe task qa task paper describe task datasets participant approach result hope shared task attract research effort textual inference question entailment question answering medical domain
codemixing phenomenon using multiple language utterance frequently used pattern communication social medium site facebook twitter etc sentiment analysis monolingual text wellstudied task codemixing add challenge analyzing sentiment text various platform social medium online gaming forum product review etc present candidate sentence generation selection based approach top bilstm based neural classifier classify hinglish codemixed text one three sentiment class positive negative neutral proposed candidate sentence generation selection based approach show improvement system performance compared bilstm based neural classifier extend proposed method solve problem codemixing textual data humordetection intent classification etc
lexical resemblance among group language indicate language could genetically related ie could descended common ancestral language however resemblance arise chance hence need always imply underlying genetic relationship many test significance based permutation wordlists word similarity measure appeared past determine statistical significance relationship demonstrate although existing test may work well bilateral comparison ie pair language either infeasible design prone yield false positive applied group language language family end inspired molecular phylogenetics propose likelihood ratio test determine given language related based proportion invariant character site aligned wordlists applied tree inference evaluate language family show proposed test solves problem false positive finally demonstrate test support existence macro language family nostratic macromayan
word embedding model glove rely cooccurrence statistic learn vector representation word meaning may similarly expect cooccurrence statistic used capture rich information relationship different word existing approach modeling relationship based manipulating pretrained word vector paper introduce novel method directly learns relation vector cooccurrence statistic end first introduce variant glove explicit connection word vector pmi weighted cooccurrence vector show relation vector naturally embedded resulting vector space
paper discusses problem utilising multiply annotated data training biomedical information extraction system two corpus annotated entity relation containing number multiply annotated document used train named entity recognition relation extraction system several method automatically combining multiple annotation produce single annotation compared none produce better result simply picking one annotated version random also shown adding extra singly annotated document produce faster performance gain adding extra multiply annotated document
paper describes alvis annotation format discusses problem encountered indexing large collection document topic specific search engine paper exemplified biological domain medline abstract developing specialized search engine biologist one alvis case study alvis principle linguistic annotation based existing work standard proposition made choice standoff annotation rather inserted markup annotation encoded xml element form linguistic subsection document record
personal noun ie common noun denoting human being play important role manifesting gender gender stereotype text especially language grammatical gender like german automatically detecting extracting personal noun thus interest myriad different task minimizing gender bias language model researching gender stereotype genderfair language complicated morphological heterogeneity homonymy personal nonpersonal noun restrict lexiconbased approach paper introduce classifier created finetuning transformer model detects personal noun german although phenomenon like homonymy metalinguistic us still problematic model able classify personal noun robust accuracy fscore
paper describes system attended semeval task affect tweet predicts emotional intensity use group lstm attention model transfer learning sentiment classification data source data semeval task transfer model structure consists source domain target domain additionally try new dropout applied lstms group lstm system ranked th subtask emotion intensity regression also show various result different architecture source target transfer model
ontolexlemon collection rdf vocabulary specifying verbalization ontology natural language beyond original scope ontolexlemon well predecessor monnet lemon found application linguistic linked open data cloud represent interlink language resource semantic web unfortunately generic ontology rdf editor considered inconvenient use ontolexlemon complex design pattern peculiarity including indirection reification subtle integrity constraint perception led development dedicated editor trading flexibility rdf combining different model feature already available existing rdf editor direct streamlined editing ontolexlemon pattern paper investigate benefit gained extending already existing rdf editor vocbench capability closely tailored ontolexlemon challenge extension implies outcome investigation twofold vertical assessment new editor ontolexlemon broader scope rdf editor design new perspective flexibility extensibility characteristic editor meet order cover new core modeling vocabulary ontolexlemon represents use case
huge amount textual conversation occur online every day multiple conversation take place concurrently interleaved conversation lead difficulty following ongoing discussion also extracting relevant information simultaneous message conversation disentanglement aim separate intermingled message detached conversation however existing disentanglement method rely mostly handcrafted feature dataset specific hinders generalization adaptability work propose endtoend online framework conversation disentanglement avoids timeconsuming domainspecific feature engineering design novel way embed whole utterance comprises timestamp speaker message text propose custom attention mechanism model disentanglement pointing problem effectively capturing interutterance interaction endtoend fashion also introduce jointlearning objective better capture contextual information experiment ubuntu irc dataset show method achieves stateoftheart performance link conversation prediction task
domain adaption widely adapted crossdomain sentiment analysis transfer knowledge source domain target domain whereas method proposed assumption target test domain known making fail generalize well unknown test data always available practice paper focus problem domain generalization crossdomain sentiment analysis specifically propose backdoor adjustmentbased causal model disentangle domainspecific domaininvariant representation play essential role tackling domain shift first rethink crossdomain sentiment analysis task causal view model causalandeffect relationship among different variable learn invariant feature representation remove effect domain confounders eg domain knowledge using backdoor adjustment series experiment many homologous diverse datasets show great performance robustness model comparing stateoftheart domain generalization baseline
many learning task require substantial skill training ideally student might benefit human expert teacher trainer hand throughout human expertise remains scarce resource secondbest solution could skill training computerbased selftraining system vision computer tutor currently motivates increasing effort worldwide manner field including computerassisted language learning call pointed hincks along growth call area come growing need empirical evidence call system beneficial effect point reiterated chapelle defines goal computer assisted second language research gathering evidence effect call instructional design paper present result field test pronunciation training system enables immigrant others selftrain pronunciation skill single danish word
extraction lexical set corpus digital signal processing dsp detailed general set direct elt application contribution specialized set investigated illustrate possibility actually using result intelligent textprocessing
semisupervised bootstrapping technique relationship extraction text iteratively expand set initial seed instance due lack labeled data key challenge bootstrapping semantic drift false positive instance added iteration following iteration contaminated introduce brex new bootstrapping method protects contamination highly effective confidence assessment achieved using entity template seed jointly opposed one previous work expanding entity template parallel mutually constraining fashion iteration introducing higherquality similarity measure template experimental result show brex achieves f v better state art four relationship
recent year language resource acquired theweb released data improve performance application several nlp task although language resource based web page unit useful nlp task application knowledge acquisition document retrieval document summarization language resource released far paper propose data format result web page processing search engine infrastructure make possible share approximately million japanese web data obtaining web data nlp researcher enabled begin processing immediately without analyzing web page
large senseannotated datasets increasingly necessary training deep supervised system word sense disambiguation however gathering highquality senseannotated data many instance possible laborious expensive task led proliferation automatic semiautomatic method overcoming socalled knowledgeacquisition bottleneck short survey present overview senseannotated corpus annotated either manually semiautomatically currently available different language featuring distinct lexical resource inventory sens ie wordnet wikipedia babelnet furthermore provide reader general statistic dataset analysis specific feature
demo deal problem capturing omitted argument relation extraction given proper knowledge base entity interest paper introduces concept salient entity use information deduce omitted entity paragraph allows improving relation extraction quality main idea compute salient entity construct graph given information identifying entity without parsing rank standard graph measure embed context sentence
focusing recognition multiword expression mwes address problem recording mwes wordnet fact mwes recorded lexical database could doubt considered lexicalised eg element wordnet taxonomy quantifier phrase certain collocation paper use crossencoder approach improve earlier method distinguishing lexicalised nonlexicalised mwes found wordnet using customdesigned rulebased statistical approach achieve fmeasure class lexicalised word combination close easily beating two baseline random majority class one language model also prof better featurebased logistic regression model
idea density id measure rate idea elementary predication expressed utterance text lower id found associated increased risk developing alzheimers disease ad snowdon et al engelman et al id used two different version propositional idea density pid count expressed idea applied text semantic idea density sid count predefined information content unit naturally applicable normative domain picture description task paper develop depid novel dependencybased method computing pid version depidr enables exclude repeating ideasa feature characteristic ad speech conduct first comparison automatically extracted pid sid diagnostic classification task two different ad datasets covering closedtopic freerecall domain sid performs better normative dataset adding pid lead small significant improvement fscore freetopic dataset pid performs better sid expected v fscore adding feature derived word embedding clustering underlying automatic sid increase result considerably leading fscore
outline issue decision involved creating pennstyle treebank middle low german mlg form part corpus historical low german chlg attestation mlg rich syntax language remains relatively understudied development syntactically annotated corpus language facilitate future study strong empirical basis building recent work indicates syntactically mlg occupies position right within west germanic paper describe background corpus process text selected included particular focus decision involved syntactic annotation corpus specifically practical linguistic reason adopting penn annotation scheme stage annotation process adapted penn scheme syntactic feature specific mlg also discus issue data uncertainty major issue building corpus underresearched language stage like mlg novel way capture uncertainty annotation
text style transfer without parallel data achieved practical success however scenario less data available method may yield poor performance paper examine domain adaptation text style transfer leverage massively available data domain data may demonstrate domain shift impedes benefit utilizing data training address challenge propose simple yet effective domain adaptive text style transfer model enabling domainadaptive information exchange proposed model presumably learn source domain distinguish stylized information generic content information ii maximally preserve content information iii adaptively transfer style domainaware manner evaluate proposed model two style transfer task sentiment formality multiple target domain limited nonparallel data available extensive experiment demonstrate effectiveness proposed model compared baseline
automated shortanswer grading key help close automation loop largescale computerised testing education wide range feature different level linguistic processing proposed far investigate relative importance different type feature across range standard corpus language skill content assessment context english german find feature lexical text similarity dependency level often suffice approximate fullmodel performance feature derived semantic processing particularly benefit linguistically varied answer content assessment corpus
describe adapt system iwpt shared task parsing enhanced universal dependency language implement pipeline approach using udpipe udpipefuture provide initial level annotation enhanced dependency graph either produced graphbased semantic dependency parser built basic tree using small set heuristic result show majority language semantic dependency parser successfully applied task parsing enhanced dependency unfortunately ensure connected graph part pipeline approach competition submission relied lastminute fix pas validation script harmed official evaluation score significantly submission ranked eighth official evaluation macroaveraged coarse ela f treebank average later implemented graphconnecting fix resulted score language average treebank average would placed fourth competition evaluation
information extraction unstructured text play vital role field natural language processing although extensive research information extraction task ie entity linking coreference resolution relation extraction data available continuous coherent evaluation information extraction task comprehensive framework given task performed evaluated different dataset analyzing effect previous task next task single dataset throughout information extraction process impossible paper aim propose korean information extraction initiative point promote research field presenting crowdsourcing data collected four information extraction task corpus training evaluation result task stateoftheart model machine learning data korean information extraction first kind plan continuously increase data volume test result serve initiative result korean information extraction task expected serve comparison target various study korean information extraction using data collected study
paper author present notion userfriendly translation describe method achieving within pragmaticsbased approach machine translation approach relies modeling belief participant translation process source language speaker addressee translator target language addressee translation choice may vary according belief ascribed various participant particular userfriendly choice based belief ascribed tl addressee
paper describes system developed shared task hero villain victim dissecting harmful meme semantic role labelling entity organised framework second workshop combating online hostile post regional language emergency situation constraint present ensemble approach combining transformerbased model linguistic information presence irony implicit sentiment associated target named entity ensemble system obtains promising classification score resulting third place finish competition
reading movement time precious cue follow reader strategy track underlying effort text processing date many approach devised simplify text overcome difficulty stemming sentence obscure ambiguous deserving clarification legal domain ensuring clarity norm regulation utmost importance full understanding document lie foundation core social obligation right task requires determining utterance text excerpt difficult sort reader investigation aim present work propose preliminary study based eyetracking data reader focus individuating different reader profile predicting reading time reader
cultural fit widely believed affect success individual group belong yet remains elusive poorly measured construct recent research draw computational linguistics measure cultural fit overlook asymmetry cultural adaptation contrast develop directed dynamic measure cultural fit based linguistic alignment estimate influence one person word use anothers distinguishes two enculturation mechanism internalization selfregulation use measure trace employee enculturation trajectory large multiyear corpus corporate email find pattern alignment first six month employment predictive individual downstream outcome especially involuntary exit predictive analysis suggest referential alignment play overlooked role linguistic alignment
semantic role labeling srl task identifying predicate labeling argument span semantic role even though semanticrole formalism built upon constituent syntax syntactic constituent labeled argument eg framenet propbank recent work syntaxaware srl relies dependency representation syntax contrast show graph convolutional network gcns used encode constituent structure inform srl system node spangcn correspond constituent computation done stage first initial node representation produced composing word representation first last word constituent second graph convolution relying constituent tree performed yielding syntacticallyinformed constituent representation finally constituent representation decomposed back word representation used input srl classifier evaluate spangcn alternative including model using gcns dependency tree show effectiveness standard english srl benchmark conll conll framenet
thanks success object detection technology retrieve object specified class even huge image collection however current stateoftheart object detector faster rcnn handle prespecified class addition large amount positive negative visual sample required training paper address problem openvocabulary object retrieval localization target object specified textual query eg word phrase first propose queryadaptive rcnn simple extension faster rcnn adapted openvocabulary query transforming text embedding vector object classifier localization regressor discriminative training propose negative phrase augmentation npa mine hard negative sample visually similar query time semantically mutually exclusive query proposed method retrieve localize object specified textual query one million image second high precision
researcher traditionally recruited native speaker provide annotation widely used benchmark datasets language recruiting native speaker difficult would help get learner language annotate data paper investigate whether language learner contribute annotation benchmark datasets carefully controlled annotation experiment recruit language learner provide two type additional resource dictionary machinetranslated sentence perform minitests measure language proficiency target three language english korean indonesian four nlp task sentiment analysis natural language inference named entity recognition machine reading comprehension find language learner especially intermediate advanced language proficiency able provide fairly accurate label help additional resource moreover show data annotation improves learner language proficiency term vocabulary grammar implication finding broadening annotation task include language learner open opportunity build benchmark datasets language difficult recruit native speaker
present adaptation rnn sequence model problem multilabel classification text target set label sequence previous rnn model define probability sequence set attempt obtain set probability afterthought network design including prespecifying label order relating sequence probability set probability ad hoc way formulation derived principled notion set probability sum probability corresponding permutation sequence set provide new training objective maximizes set probability new prediction objective find probable set test document new objective theoretically appealing give rnn model freedom discover best label order often natural one different among document develop efficient procedure tackle computation difficulty involved training prediction experiment benchmark datasets demonstrate outperform stateoftheart method task
evolution language follows rule gradual change grammar vocabulary lexical semantic shift take place time resulting diachronic linguistic gap considerable amount text written language different era creates obstacle natural language processing task word segmentation machine translation although chinese language long history previous chinese natural language processing research primarily focused task within specific era therefore propose crossera learning framework chinese word segmentation cws crosswise us switchmemory sm module incorporate eraspecific linguistic knowledge experiment four corpus different era show performance corpus significantly improves analysis also demonstrate sm effectively integrate knowledge era neural network
paper report several software implementation developed within prague arabic dependency treebank project concerned arabic natural language processing try guide reader essential task note solution designed used well point thirdparty computational system research community might exploit future work field
paper present first electronic speech corpus maaloula aramaic endangered western neoaramaic variety spoken syria word corpus available four format transcription lemmatized transcription audio file timealigned phonetic transcription sqlite database transcription file digitized corrected version authentic transcription taperecorded narrative coming fieldwork trip conducted published early arnold b contain annotation except informative tagging eg mark loanword misspoken word lemmatized version file word form followed lemma angled bracket timealigned textgrid annotation consist four tier sentence level tier word level tier segment level tier textgrid file downloadable together audio file original source audio data see arnold sqlite database enables user access data level token type lemma sentence narrative speaker corpus available scientific community urlhttpsdoiorgzenodo
unified sequence labeling articulates different sequence labeling problem named entity recognition relation extraction semantic role labeling etc generalized sequencetosequence format open opportunity make maximum utilization large language model knowledge toward structured prediction unfortunately requires formatting specialized augmented format unknown base pretrained language model plms necessitating finetuning target format significantly bound usefulness datalimited setting finetuning large model properly generalize target format address challenge leverage plm knowledge effectively propose fishdip sampleaware dynamic sparse finetuning strategy selectively focus fraction parameter informed feedback highly regressing example finetuning process leveraging dynamism sparsity approach mitigates impact welllearned sample prioritizes underperforming instance improvement generalization across five task sequence labeling demonstrate fishdip smoothly optimize model low resource setting offering upto performance improvement full finetuning depending target evaluation setting also compared incontext learning parameterefficient finetuning approach fishdip performs comparably better notably extreme lowresource setting source code fishdip available urlhttpsgithubcompsunlpgroupfishdip
manual evaluation essential judge progress automatic text summarization however conduct survey recent summarization system paper reveals little agreement perform evaluation study conduct two evaluation experiment two aspect summary linguistic quality coherence repetitiveness compare likerttype ranking annotation show best choice evaluation method vary one aspect another survey also find study parameter overall number annotator distribution annotator annotation item often fully reported subsequent statistical analysis ignores grouping factor arising one annotator judging multiple summary using evaluation experiment show total number annotator strong impact study power current statistical analysis method inflate type error rate eightfold addition highlight purpose system comparison current practice eliciting multiple judgement per summary lead less powerful reliable annotation given fixed study budget
automated reporting potential assist radiologist timeconsuming procedure generating text radiology report existing approach generate report directly radiology image however observe resulting report exhibit realistic style lack clinical accuracy therefore propose twostep pipeline subdivides problem factual triple extraction followed freetext report generation first step comprises supervised extraction clinically relevant structured information image expressed triple form entity relation entity second step triple input condition generation radiology report particular focus work chest xray cxr radiology report generation proposed framework show stateoftheart result mimiccxr dataset according standard text generation metric employ bleu meteor rouge clinical accuracy metric recall precision f assessed using chexpert labeler also giving reduction total number error reduction critical clinical error assessed expert human evaluation future solution easily integrate advanced model architecture improve triple extraction report generation applied complex image captioning task found medical domain
paper describes system used participating subtasks message polarity classification b topicbased message polarity classification according twopoint scale semeval task sentiment analysis twitter used several feature sentiment lexicon nlp technique maximum entropy classifier system
paper present multipurpose system wordnet wn development named hydra hydra application data editing validation well data retrieval synchronization wordnet different language use modal language wordnet representation wordnet relational database concurrent access among main advantage
paper explores battery unsupervised technique used order create large highquality corpus textual inference application system recognizing textual entailment te textual contradiction tc show possible automatically generate set positive negative instance textual entailment contradiction textual corpus greater precision describe generated million te pair corresponding set tc pair document found gb aquaint newswire corpus
effectively managing offensive content crucial social medium platform encourage positive online interaction however addressing offensive content codemixed dravidian language face challenge current moderation method focus flagging entire comment rather pinpointing specific offensive segment limitation stem lack annotated data accessible system designed identify offensive language section address shared task present dataset comprising kannadaenglish codemixed social comment encompassing offensive comment paper outline dataset utilized algorithm result obtained system participating shared task
annotated clinical text corpus essential machine learning study model predict care process disease progression however study describe necessary experimental design annotation guideline annotation phase make replication reuse adoption challenging using clinical question sepsis designed semantic annotation guideline capture sepsis sign clinical text clinical question aid guideline design application evaluation method incrementally evaluates change guideline testing resulting annotated corpus using clinical question additionally method us interannotator agreement judge annotator compliance quality guideline show method combined controlled design increment simple allows development measurable improvement purposebuilt semantic annotation guideline believe approach useful incremental design semantic annotation guideline general
work aim developing unsupervised abstractive summarization system multidocument setting design paraphrastic sentence fusion model jointly performs sentence fusion paraphrasing using skipgram word embedding model sentence level model improves information coverage time abstractiveness generated sentence conduct experiment humangenerated multisentence compression datasets evaluate system several newly proposed machine translation mt evaluation metric furthermore apply sentence level model implement abstractive multidocument summarization system document usually contain related set sentence also propose optimal solution classical summary length limit problem addressed past research document level summary conduct experiment datasets two different domain eg news article user review well suited multidocument abstractive summarization experiment demonstrate method bring significant improvement stateoftheart method
present first largescale corpus based verification dowtys seminal theory protoroles result demonstrate need feasibility propertybased annotation scheme semantic relationship opposed currently dominant notion categorical role
large language model llm demon strated remarkable performance wide range natural language task however model continue grow size face sig nificant challenge term computational cost additionally llm often lack efficient domainspecific understanding par ticularly crucial specialized field aviation healthcare boost domain specific understanding propose kitlm novel knowledge base integration approach language model relevant informa tion infusion integrating pertinent knowl edge performance lan guage model greatly enhanced model size requirement also significantly reduced achieving comparable performance proposed knowledgeinfused model surpasses performance gptturbo stateoftheart knowledge infusion method skill achieving time improvement exact match score metaqa kitlm showed similar performance boost avi ation domain aeroqa drastic perfor mance improvement kitlm exist ing method attributed infusion relevant knowledge mitigating noise addition release two curated datasets accelerate knowledge infusion research specialized field aeroqa new bench mark dataset designed multihop question answering within aviation domain b aviation corpus dataset constructed unstructured text extracted national transportation safety board report search contributes advancing field domainspecific language understanding showcase potential knowledge infusion technique improving performance
opportunity machine learning natural language processing research growing volume textual data although little research done trend extraction youtube comment sentiment analysis intriguing issue poor consistency quality material found purpose work use machine learning technique algorithm sentiment analysis youtube comment pertaining popular theme finding demonstrate sentiment analysis capable giving clear picture actual event affect public opinion study aim make easier academic find highquality sentiment analysis research publication data normalisation method used clean annotated corpus citation sentence study classification system utilising one machine learning algorithmknearest neighbour knn na ive bayes svc support vector machine randomforestis built metric like fscore correctness score used assess correctness system
paper describe neural machine translation nmt system submitted kangwon national university hyundai knuhyundai team translation task th workshop asian translation wat participated task aspec jpc included chinesejapanese englishjapanese koreantextgreaterjapanese submitted transformerbased nmt system built using following method relative positioning method pairwise relationship input element b backtranslation multisource translation data augmentation c righttoleft rlreranking model robust error propagation autoregressive architecture decoder checkpoint ensemble model selected top three model best validation bilingual evaluation understudy bleu reported translation result two aforementioned task performed well task ranked first term bleu score jpc subtasks participated
dramatic increase use social medium platform information sharing also fueled steep growth online abuse simple yet effective way abusing individual community creating meme often integrate image short piece text layered top harmful element rampant use threat online safety hence necessary develop efficient model detect flag abusive meme problem becomes challenging lowresource setting eg bengali meme ie image bengali text embedded absence benchmark datasets ai model could trained paper bridge gap building bengali meme dataset setup effective benchmark implement several baseline model classifying abusive meme using dataset observe multimodal model use textual visual information outperform unimodal model bestperforming model achieves macro f score finally perform qualitative error analysis misclassified meme bestperforming textbased imagebased multimodal model
propose hybrid model hybride hybridw meme analysis semeval task involves sentiment classification subtask humor classification subtask b scale semantic class subtask c hybrid model consists blstm cnn text image processing respectively hybride provides equal weight blstm cnn performance hybridw provides weightage based performance blstm cnn validation set performance macro f hybrid model subtask hybride hybridw subtask b hybride hybridw subtask c hybride hybridw
paper describe publicly available multilingual evaluation corpus phraselevel sentiment analysis used evaluate real world application industrial context corpus contains data english german internet forum post focusing automotive domain major topic corpus connecting using cellphone toin car presented corpus contains different type annotation object eg car new cellphone feature eg address book sound quality phraselevel polarity eg best possible automobile big problem post annotated least four different annotator annotation retained original form reliability annotation evaluated interannotator agreement score besides corpus data format provide comprehensive corpus statistic corpus one first lexical resource focusing real world application analyze voice customer crucial various industrial use case
bilinear diagonal model knowledge graph embedding kge distmult complex balance expressiveness computational efficiency representing relation diagonal matrix although perform well predicting atomic relation composite relation relation path modeled naturally product relation matrix product diagonal matrix commutative hence invariant order relation paper propose new bilinear kge model called blockhole based block circulant matrix blockhole relation matrix noncommutative allowing composite relation modeled matrix product model parameterized way cover spectrum ranging diagonal full relation matrix fast computation technique developed basis duality fourier transform circulant matrix
existing parsing algorithm lexicalized tree grammar ltg formalism ltag tig dtg adaptation algorithm initially dedicated context free grammar cfg really take account fact use context free rule partial parsing tree try combine moreover lexicalization raise important problem multiplication structure problem exist cfg paper present parsing technique ltg taking account two fundamental feature approach focus robust pratical purpose parsing algorithm result extended partial parsing global parsing fails interesting average complexity compared others bottomup algorithm
numerical question answering task answering question require numerical capability previous work introduce general adversarial attack numerical question answering systematically exploring numerical capability specific topic paper propose conduct numerical capability diagnosis series numerical question answering system datasets series numerical capability highlighted corresponding dataset perturbation designed empirical result indicate existing system severely challenged perturbation eg graphtree experienced absolute accuracy drop extra perturbation asdiva bart experienced accuracy drop language perturbation numerical subset drop counteracting approach also investigate effectiveness applying perturbation data augmentation relieve system lack robust numerical capability experiment analysis empirical study demonstrated numerical question answering robust numerical capability still large extent open question discus future direction numerical question answering summarize guideline future dataset collection system design
corpus oral informatizado da lingua galega corilga project aim building corpus oral language galician primarily designed study linguistic variation change project currently development periodically enriched new contribution longterm goal speech recording enriched phonetic syllabic morphosyntactic lexical sentence elancomplaint annotation way speed process annotation use automatic speechrecognitionbased tool tailored application therefore corilga repository enhanced automatic alignment tool available administrator repository aligns speech orthographic transcription event transcription partial one available speech recognizer galician used generate word phonetic segmentation recognized output may contain error manually corrected administrator assisting task tool also provides elan tier confidence measure recognized word paper description main fact corilga corpus speech alignment recognition tool described developed using kaldi toolkit
finetuned pretrained transformer achieve state art passage reranking unfortunately make prediction remains vastly unexplained especially endtoend inputtooutput level little known token layer passage precisely contribute final prediction paper address gap leveraging recently developed information bottleneck attribution iba framework bertbased model passage reranking quantitatively demonstrate framework veracity extracting attribution map perform detailed tokenwise analysis prediction made overall find bert still care exact token matching reranking cl token mainly gather information prediction last layer topranked passage robust token removal bert finetuned msmarco positional bias towards start passage
paper focus lexicalsemantic relation german wordnet germanet shown wordnet suffer relatively small number relation lexical object assumed application nlp ir particular relying word sense disambiguation boosted higher relational density lexical resource report research experiment lexical acquisition new type relation large annotated german newspaper corpus ie relation verbal head predicate nominal head argument investigate insertion instance relation german wordnet germanet affect overall structure wordnet well neighbourhood node connected instance new relation
present pixie manually annotated dataset preference classification comprising sentence drawn app review unlike previous study preference classification pixie contains implicit omitting entity compared indirect lacking comparative linguistic cue comparison find transformerbased pretrained model finetuned pixie achieve weighted average f score outperform existing stateoftheart preference classification model
paper present brief description morphosyntactic feature ancash quechua majority variety central quechua language family qi purpose building corpus annotated according universal dependency ud schema creation corpus two objective quechua linguistics open possibility systematic linguistic study comparison language also enables development syntactic parser would first nlp tool quechua language family ud project adding quechua agglutinative language rich morphology make possible point possible shortcoming universal annotation schema fuel discussion adapt schema specific feature language similar typology first step towards work first gather digitise available linguistic resource thus creating first bilingual sentencealigned digital corpus ancash quechua spanish identifying linguistic feature fully described ud schema proposed annotation solution built initial corpus around twenty sentence making freely available
work introduce generative model plc generating lambek categorial grammarlcg sequents also introduce simple method numerically estimate model parameter annotated corpus compare model probabilistic contextfree grammar pcfgs show plc simultaneously assigns higher probability common corpus greater coverage
word embeddings learned using distributional hypothesis eg glove wordvec capture affective dimension valence arousal dominance present inherently word present novel retrofitting method updating embeddings word affective meaning learns nonlinear transformation function map pretrained embeddings affective vector space representation learning setting investigate word embeddings capacity cluster emotionbearing word affective embeddings learned method achieve better intercluster intracluster distance word emotion evaluated different cluster quality metric downstream task sentiment analysis sarcasm detection simple classification model viz svm attention net learned using affective embeddings perform better pretrained counterpart improvement fscore benchmark furthermore difference performance pronounced limited data setting
learned without exploration local model structured prediction task subject exposure bias trained without detailed guidance active imitation learning ail also known nlp dynamic oracle learning general technique working around issue allowing exploration different output training time ail requires oracle feedback oracle algorithm given partial candidate solution gold annotation find correct minimum loss next output produce paper describes general finite state technique deriving oracle technique describe also efficient greatly expand task ail used
paper present bootstrapping effort producing first large freely available croatian automatic speech recognition asr dataset hour size obtained parliamentary transcript recording parlamint corpus bootstrapping approach dataset building relies commercial asr system initial data alignment building multilingualtransformerbased asr system initial data full data alignment experiment resulting dataset show difference spoken content parliamentary transcript present textasciitilde word also word error rate bestperforming asr system interestingly finetuning transformer model either normalized original data show difference performance model pretrained subset raw speech data consisting slavic language show perform better pretrained wider set language public release data model code paving way forward preparation multimodal corpus croatian parliamentary proceeding well development similar free datasets model corpus underresourced language
logovista e translation system translates english text spanish member lecs family translation tool us engine logovista ej engine development ten year heavily linguistic rulebased includes large highly annotated english dictionary contains detailed syntactic semantic domain information binary parser produce multiple parses sentence rule contextfree english grammar synthesis file rule convert parsed english structure spanish structure main task involved developing new language pair include addition targetlanguage translation dictionary addition rule synthesis file system modular design allows work carried linguist independent engineer
story generated neural language model shown promise grammatical stylistic consistency however generated story still lacking common sense reasoning eg often contain sentence deprived world knowledge propose simple multitask learning scheme achieve quantitatively better common sense reasoning language model leveraging auxiliary training signal datasets designed provide common sense grounding combined twostage finetuning pipeline method achieves improved common sense reasoning stateoftheart perplexity writingprompts fan et al story generation dataset
although shapley value shown highly effective identifying harmful training instance dataset size model complexity constraint limit ability apply shapleybased data valuation finetuning large pretrained language model address propose tsdshapley algorithm reduces computational cost shapleybased data valuation efficient samplingbased method aggregate shapley value computed subset valuation entire training set value transfer method leverage value information extracted simple classifier trained using representation target language model experiment applying tsdshapley select data finetuning bertbased language model benchmark natural language understanding nlu datasets show tsdshapley outperforms existing data selection method tsdshapley filter finetuning data increase language model performance compared training full finetuning dataset
copy mechanism employed sequence sequence seqseq model generate reproduction word input output framework operating lexical type level fail provide explicit alignment record token copied require contiguous token sequence input span copied individually present model explicit tokenlevel copy operation extend copying entire span model provides hard alignment span input output allowing nontraditional application seqseq like information extraction demonstrate approach nested named entity recognition achieving near stateoftheart accuracy order magnitude increase decoding speed
paper demonstrates stateoftheart endtoend multilingual english russian ukrainian knowledge extraction system perform entity discovery linking relation extraction event extraction coreference extract aggregate knowledge element across multiple language document well provides visualization result along three dimension temporal displayed event timeline spatial displayed event heatmap relational displayed entityrelation network system support user analysis causal sequence event complex situation also integrate wide range human moral value measure independently derived regionbased survey event heatmap system publicly available docker container live demo
argument mining typically researched specific corpus belonging concrete language domain independently research work human argumentation however domain languagedependent linguistic feature determine content structure argument also deploying argument mining system textitin wild might able control feature therefore important aspect thoroughly investigated argument mining literature robustness system variation language domain paper present complete analysis across three different language three different domain allow u better understanding leverage scarce available corpus design argument mining system robust natural language variation
developing topic model critical question asked well model work applied setting standard performance evaluation topic interpretability us automated measure modeled human evaluation test dissimilar applied usage model generalizability remains question paper probe issue validity topic model evaluation assess informative coherence measure specialized collection used applied setting informed literature propose four understanding interpretability evaluate using novel experimental framework reflective varied applied setting including human evaluation using open labeling typical applied research evaluation show specialized collection standard coherence measure may inform appropriate topic model optimal number topic current interpretability performance validation method challenged mean confirm model quality absence ground truth data
identifying relevant persona knowledge conversational system critical grounded dialogue response generation however grounding mostly researched isolation practical multicontext dialogue task introduced recent work define persona knowledge dual context identification task identify persona knowledge jointly given dialogue could elevated importance complex multicontext dialogue setting develop novel grounding retrieval method utilizes context dialogue simultaneously method requires less computational power via utilizing neural qa retrieval model introduce novel nullpositive rank test measure ranking performance semantically dissimilar sample ie hard negative relation data augmentation
prior work semantic parsing shown conventional seqseq model fail compositional generalization task limitation led resurgence method model alignment sentence corresponding meaning representation either implicitly latent variable explicitly taking advantage alignment annotation take second direction propose tpol twostep approach first translates input sentence monotonically reorder obtain correct output achieved modular framework comprising translator reorderer component test approach two popular semantic parsing datasets experiment show mean monotonic translation tpol learn reliable lexicological pattern aligned data significantly improving compositional generalization conventional seqseq model well approach exploit gold alignment
debate motion proposal tabled uk parliament contain information stated policy preference member parliament propose key analysis subsequent speech given response attempt automatically label debate motion code preexisting coding scheme developed political scientist annotation analysis political party manifesto develop annotation guideline task applying code debate motion two level granularity produce dataset manually labelled example evaluate annotation process reliability utility labelling scheme finding interannotator agreement comparable study conducted manifesto data moreover test variety way automatically labelling motion code ranging similarity matching neural classification method evaluate gold standard label experiment note established supervised baseline always able improve simple lexical heuristic time detect clear evident benefit employing bert stateoftheart deep language representation model even classification scenario different label limited amount training data
diverse machine translation aim generating various target language translation given source language sentence leverage linear relationship sentence latent space introduced mixup training propose novel method mixdiversity generate different translation input sentence linearly interpolating different sentence pair sampled training corpus decoding improve faithfulness diversity translation propose two simple effective approach select diverse sentence pair training corpus adjust interpolation weight pair correspondingly moreover controlling interpolation weight method achieve tradeoff faithfulness diversity without additional training required previous method experiment wmt enro wmt ende wmt zhen conducted show method substantially outperforms previous diverse machine translation method
task automatically generating sentential description image content become increasingly popular recent year resulting development largescale image description datasets proposal various metric evaluating image description generation system however much work done analyse understand datasets metric paper propose using leaveoneout cross validation loocv process mean analyse multiply annotated humanauthored image description datasets various evaluation metric ie evaluating one image description humanauthored description image evaluation process affords various insight image description datasets evaluation metric variation image description within across datasets also metric capture compute analyse human upperbound performance ii ranked correlation metric pair across datasets iii lowerbound performance comparing set description describing one image another sentence describing image interesting observation made evaluation metric image description datasets conclude crossvalidation method extremely useful assessing gaining insight image description datasets evaluation metric image description
identifying unknown novel user intent never appeared training set challenging task dialogue system paper present twostage method detecting unknown intent use bidirectional long shortterm memory bilstm network margin loss feature extractor margin loss learn discriminative deep feature forcing network maximize interclass variance minimize intraclass variance feed feature vector densitybased novelty detection algorithm local outlier factor lof detect unknown intent experiment two benchmark datasets show method yield consistent improvement compared baseline method
development artificial intelligence ai digital humanity ancient chinese resource language technology also developed grown become increasingly important part study historiography traditional chinese culture order promote research automatic analysis technology ancient chinese conduct various experiment ancient chinese word segmentation partofspeech po tagging task evahan shared task model word segmentation po tagging task jointly sequence tagging problem addition perform series training strategy based provided ancient chinese pretrained model enhance model performance concretely employ several augmentation strategy including continual pretraining adversarial training ensemble learning alleviate limited amount training data imbalance po label extensive experiment demonstrate proposed model achieve considerable performance ancient chinese word segmentation po tagging task keywords ancient chinese word segmentation partofspeech tagging adversarial learning continuing pretraining
work present improvement largescale arabic french statistical machine translation system period three year development includes better preprocessing training data additional genrespecific tuning different domain namely newswire text broadcast news transcript improved domaindependent language model starting early prototype participated second cesta evaluation system upgraded achieve favorable bleu score text audio setting result compared system based freely available moses toolkit show significant gain term translation quality bleu absolute translation speed time faster comparable configuration setting
present tool provides automated feedback student studying spanish writing feedback given four category topic development coherence writing convention essay organization tool made freely available via google doc addon small user study thirdlevel student mexico show student found tool generally helpful plan continue using work improve writing skill
pragmatic study people exchange meaning use language paper describe experience regard text belonging large contemporary corpus written language order verify us change flexibility meaning proper name pn matter fact building lexical semantic database italwordnet iwn considerable set pn inserted studied give prominence polysemy pn shifting moving one class another example extensibility language possibility change considering meaning dynamic process many example sense shifting phenomenon evidenced textual corpus comparing percentage regarding text belonging two different period time increasing use pn sense extension verified evidence could confirm tendency consider derived extended sens salient prevailing base sens confirming gradual fixation meaning time object study progress observe us sense extension also examining detail freshly coined example taking account relationship meta representational capacity human creativity way linguistic dynamic activate meaning potential word
present system natural language inference us dynamic semantics converter abstract syntax tree coq type combine finegrainedness dynamic semantics system powerfulness stateoftheart proof assistant like coq evaluate system section fracas test suite excluding section first system complete run anaphora ellipsis section fracas better overall accuracy previous system
propose method aggregate organize large multisource dataset news article collection major story automatically name visualize story working system approach able run online new article added processing million news article news source extracting major story span several year visual interface consists lane timeline annotated information deemed important story including extracted quotation working system allows user search navigate year story information
recent research highlighted natural language processing nlp system exhibit bias againstafrican american speaker error often caused poor representation linguistic feature unique african american english aae due relatively low probability occurrence many feature present workflow overcome issue case habitual habitual isomorphic therefore ambiguous form uninflected found aae general american english gae creates clear challenge bias nlp technology overcome scarcity employ combination rulebased filter data augmentation generate corpus balanced habitual nonhabitual instance balanced corpus train unbiased machine learning classifier demonstrated corpus aae transcribed text achieving f score classifying habitual
trained webscale imagetext pair visionlanguage model vlms clip recognize image common object zeroshot fashion however underexplored use clip zeroshot recognition highly specialized concept eg specie bird plant animal scientific name written latin greek indeed clip performs poorly zeroshot specie recognition prompt use scientific name eg photo lepus timidus scientific name latin name usually included clip training set improve performance explore using largelanguage model llm generate description eg specie color shape additionally use prompt however method improves marginally instead motivated translate scientific name eg lepus timidus common english name eg mountain hare use prompt find common name likely included clip training set prompting achieves textasciitilde time higher accuracy benchmarking datasets finegrained specie recognition
advance machine reading comprehension mrc rely heavily collection large scale humanannotated example form question paragraph answer triple contrast human typically able generalize example relying deeper underlying world knowledge linguistic sophistication andor simply superior deductive power paper focus teaching machine reading comprehension using small number semistructured explanation explicitly inform machine answer span correct extract structured variable rule explanation compose neural module teacher annotate instance training downstream mrc model use learnable neural module soft logic handle linguistic variation overcome sparse coverage module jointly optimized mrc model improve final performance squad dataset proposed method achieves f score supervision explanation comparable plain supervised learning using labeled instance yielding x speed
knowledge graph kg directed labeled graph representing entity relationship prior work focus supervised semisupervised approach require large amount annotated data unsupervised approach need labeled training data existing method either generate many redundant relation require manual mapping extracted relation known schema address limitation propose unsupervised method kg generation requires neither labeled data manual mapping predefined relation schema instead method leverage sentencelevel semantic similarity automatically generating relation pair entity proposed method outperforms two baseline system evaluated four datasets
explore concept hybrid grammar formalize generalize range existing framework dealing discontinuous syntactic structure covered discontinuous phrase structure nonprojective dependency structure technically hybrid grammar related synchronous grammar one grammar component generates linear structure another generates hierarchical structure coupling lexical element component together discontinuous structure result several type hybrid grammar characterized also discus grammar induction treebanks main advantage existing framework ability hybrid grammar separate discontinuity desired structure time complexity parsing permit exploration large variety parsing algorithm discontinuous structure different property confirmed reported experimental result show wide variety running time accuracy frequency parse failure
natural language processing nlp algorithm become successful still struggle applied outofdistribution example paper propose controllable generation approach order deal domain adaptation da challenge given input text example docogen algorithm generates domaincounterfactual textual example dcon similar original aspect including task label domain changed desired one importantly docogen trained using unlabeled example multiple domain nlp task label parallel pair textual example domaincounterfactuals required show docogen generate coherent counterfactuals consisting multiple sentence use dcons generated docogen augment sentiment classifier multilabel intent classifier da setup respectively sourcedomain labeled data scarce model outperforms strong baseline improves accuracy stateoftheart unsupervised da algorithm
work presented article take place field opinion mining aim particularly finding polarity text relying machine learning method context focus studying various strategy adapting statistical classifier new domain training data exist one several domain study show precisely selftraining procedure consisting enlarging initial training corpus text target domain reliably classified classifier successful stable strategy tested domain moreover strategy get better result case blitzer et al method evaluation corpus simple
present model predicts individual user dialog system understand produce utterance based user group contrast previous work user group specified beforehand learned training evaluate two referring expression generation task experiment show model identify user group learn effectively talk dynamically assign unseen user correct group interact system
work using artificial language training input shown lstms capable inducing stacklike data structure required represent contextfree certain mildly contextsensitive language formal language class correspond theory hierarchical structure natural language present suite experiment probing whether neural language model trained linguistic data induce stacklike data structure deploy incrementally predicting word study two natural language phenomenon center embedding sentence syntactic island constraint fillergap dependency order properly predict word structure model must able temporarily suppress certain expectation recover expectation later essentially pushing popping expectation stack result provide evidence model successfully suppress recover expectation many case fully recover previous grammatical state
several problem applying grammatical error correction gec writing support system one handling sentence middle input till date performance gec incomplete sentence wellknown hence analyze performance model incomplete sentence another problem correction speed speed slow usability system limited user experience degraded therefore study also focus nonautoregressive nar model widely studied fast decoding method perform gec japanese traditional autoregressive recent nar model analyze accuracy speed
working problem natural language processing find situation traditional measurement descriptive complexity ineffective describing behaviour algorithm easy see model use often general framework difficulttodefine task embedded framework power typically use complexity measure worstcase running time drastically overestimate cost running algorithm particular make apparently tractable problem seem npcomplete using empirical study evaluate performance necessary incomplete method dealing mismatch since study longer act guarantee good performance paper use statistical measure entropy give updated analysis complexity npcomplete probable sentence problem pcfgs applied word sense disambiguation inference task bound running time error simple search algorithm allowing much faster search npcompleteness problem would suggest
paper present huawei translation service center hwtscs submission iwslt formality control task provides two training scenario supervised zeroshot containing two language pair set constrained unconstrained condition train formality control model four language pair two condition respectively submit corresponding translation result effort divided two front enhancing general translation quality improving formality control capability according different requirement formality control task use multistage pretraining method train bilingual multilingual neural machine translation nmt model basic model improve general translation quality base model relatively high level premise affecting general translation quality basic model little possible adopt domain adaptation rerankingbased transductive learning method improve formality control capability model
root tb multilingual text corpus developed training bloom currently largest language model explicitly accompanied commensurate data governance effort continuation effort present root search tool search engine entire root corpus offering fuzzy exact search capability root largest corpus date investigated way root search tool opensourced available hugging face space urlhttpshuggingfacecospacesbigsciencedatarootssearch describe implementation possible use case tool
prevalent use reference evaluating texttotext generation known bias estimate quality henceforth low coverage bias lcb paper show overcoming lcb grammatical error correction gec evaluation attained rescaling increasing number reference feasible range contrary previous suggestion due longtailed distribution valid correction sentence concretely show lcb incentivizes gec system avoid correcting even generate valid correction consequently existing system obtain comparable superior performance compared human making targeted change input similar effect text simplification support claim
different general document recognised ease people understand biomedical text eminently varied owing highly technical nature biomedical document variance reader domain knowledge however existing biomedical document summarization system paid little attention readability control leaving user summary incompatible level expertisein recognition urgent demand introduce new task readability controllable summarization biomedical document aim recognise user readability demand generate summary better suit need technical summary expert plain language summary pls laymento establish task construct corpus consisting biomedical paper technical summary plss written author benchmark multiple advanced controllable abstractive extractive summarization model based pretrained language model plms prevalent controlling generation techniquesmoreover propose novel masked language model mlm based metric variant effectively evaluate readability discrepancy lay technical summariesexperimental result automated human evaluation show though current control technique allow certain degree readability adjustment generation performance existing controllable summarization method far desirable task
according psychological learning theory important principle governing language acquisition cooccurrence example perceive language brain seems unconsciously analyze store cooccurrence pattern word language production cooccurrence pattern reproduced applicability principle particularly obvious case word association evidence associative response people typically come upon presentation stimulus word often word frequently cooccur thus possible predict response looking cooccurrence data work presented along line however differs previous work investigates direction response stimulus rather viceversa also deal case several response known result indicate possible predict stimulus word response help several response given
counternarrative generation ie generation factbased response hate speech aim correcting discriminatory belief demonstrated effective method combat hate speech however effectiveness limited resourceintensive nature dataset construction process focus primary language alleviate problem propose korean hate speech counter punch khscp costeffective counternarrative generation method korean language end release first counternarrative generation dataset korean pose two research question question propose effective augmentation method investigate reasonability large language model overcome data scarcity lowresource environment leveraging existing resource regard conduct several experiment verify effectiveness proposed method result reveal applying preexisting resource improve generation performance significant margin deep analysis experiment work proposes possibility overcoming challenge generating counternarratives lowresource environment
social medium becoming popular vast short noisy message produced million user hot event happens developing social summarization system becomes critical people quickly grasp core essential information however publicly available highquality large scale social summarization dataset rare constructing corpus easy expensive since short text complex social characteristic paper construct tweetsum new eventoriented dataset social summarization original data collected twitter contains real world hot event total tweet user event four expert summary also annotation quality evaluation addition collect additional social signal ie user relation hashtags user profile establish user relation network event besides detailed dataset description show performance several typical extractive summarization method tweetsum establish baseline research release dataset public
present robust neural abstractive summarization system crosslingual summarization construct summarization corpus document automatically translated three lowresource language somali swahili tagalog using machine translation new york time summarization corpus train three languagespecific abstractive summarizers evaluate document originally written source language well fourth unseen language arabic system achieve significantly higher fluency standard copyattention summarizer automatically translated input document well comparable content selection
opinionated text often involves attribute authorship location influence sentiment expressed different aspect posit structural semantic correspondence prevalent opinionated text especially associated attribute crucial accurately revealing latent aspect sentiment structure however recognized existing approach propose trait unsupervised probabilistic model discovers aspect sentiment text associate different attribute end trait infers leverage structural semantic correspondence using markov random field show empirically incorporating attribute explicitly trait significantly outperforms stateoftheart baseline generating attribute profile accord intuition shown via visualization yielding topic greater semantic cohesion
bilingual speaker often freely mix language however bilingual conversation language choice speaker coordinated much one speaker choice language affect speaker paper formulate codechoice linguistic style show speaker indeed sensitive accommodating others codechoice find saliency markedness language context directly affect degree accommodation observed importantly discover accommodation codechoices persists several conversational turn also propose alternative interpretation conversational accommodation retrieval problem show difference accommodation characteristic codechoices based markedness context
data augmentation effective way improve performance many neural text generation model however current data augmentation method need define choose proper data mapping function map original sample augmented sample work derive objective formulate problem data augmentation text generation task without use augmented data constructed specific mapping function proposed objective efficiently optimized applied popular loss function text generation task convergence rate guarantee experiment five datasets two text generation task show approach approximate even surpass popular data augmentation method
nespole speechtospeech machine translation research system designed provide fully functional speechtospeech capability within realworld setting common user involved ecommerce application project funded jointly european commission u nsf nespole system us clientserver architecture allow common user browsing webpage internet connect seamlessly realtime agent service provider using videoconferencing channel speechtospeech translation service mediating conversation shared web page annotated image supported via whiteboard application available enhance communication
extending semantic parser codeswitched input challenging problem primarily due lack supervised training data work introduce cst new data augmentation technique finetunes model using small seed set mboxapprox utterance generate codeswitched utterance english utterance show cst generates high quality codeswitched data intrinsically per human evaluation extrinsically comparing baseline model trained without data augmentation model trained augmented data empirically observe using cst one achieve semantic parsing performance using x less labeled data aid research area also releasing hinglishtop largest human annotated codeswitched semantic parsing dataset date containing k human annotated hindienglish hinglish codeswitched utterance b k cst generated codeswitched utterance topv dataset human evaluation show human annotated data well cst generated data good quality
present work us bidirectional encoder representation transformer bert process sentence entity indicate whether two named entity present sentence related constituting binary classification problem developed portuguese language considering financial domain exploring deep linguistic representation identify relation entity without using lexicalsemantic resource result experiment show accuracy prediction
generating opendomain conversational response desired style usually suffers lack parallel data style meanwhile using monolingual stylistic data increase style intensity often lead expense decreasing content relevance paper propose disentangle content style latent space diluting sentencelevel information style representation combining desired style representation response content representation obtain stylistic response approach achieves higher bertbased style intensity score comparable bleu score compared baseline human evaluation result show approach significantly improves style intensity maintains content relevance
paper present novel unsupervised algorithm word sense disambiguation wsd document level algorithm inspired widelyused approach field genetics whole genome sequencing known shotgun sequencing technique proposed wsd algorithm based three main step first bruteforce wsd algorithm applied short context window word selected document order generate short list likely sense configuration window second step local sense configuration assembled longer composite configuration based suffix prefix matching resulted configuration ranked length sense word chosen based voting scheme considers top k configuration word appears compare algorithm stateoftheart unsupervised wsd algorithm demonstrate better performance sometimes large margin also show algorithm yield better performance common sense mc baseline one data set moreover algorithm small number parameter robust parameter tuning unlike bioinspired method give deterministic solution involve random choice
paper present novel annotation approach capture claim premise argument relation studentwritten persuasive peer review business model german language propose annotation scheme based annotation guideline allows model claim premise well support attack relation capturing structure argumentative discourse studentwritten peer review conduct annotation study three annotator persuasive essay evaluate annotation scheme obtained interrater agreement argument component argumentative relation indicates proposed annotation scheme successfully guide annotator moderate agreement finally present freely available corpus persuasive studentwritten peer review business model annotation guideline encourage future research design development argumentative writing support system student
generative model recently experienced surge popularity due development efficient training algorithm increasing computational power model adversarial generative network gans successfully used various area computer vision medical imaging style transfer natural language generation adversarial net recently shown yield result imagetotext task given set image one provide corresponding text description paper take similar approach propose imagetoemoji architecture trained data social network used score given picture using ideogram show empirical result algorithm data obtained influential instagram account
continual pretraining urgent adapting pretrained model multitude domain task fastevolving world practice continually pretrained model expected demonstrate greater capacity finetuned pretrained domain also nondecreasing performance unseen one work first investigate anytime finetuning effectiveness existing continual pretraining approach concluding unanimously decreased performance unseen domain end propose promptguided continual pretraining method train hypernetwork generate domainspecific prompt agreement disagreement loss agreement loss maximally preserve generalization pretrained model new domain disagreement one guard exclusiveness generated hidden state domain remarkably prompt hypernetwork alleviate domain identity finetuning promote knowledge transfer across domain method achieved improvement two realworld datasets including domain shift temporal shift respectively demonstrating efficacy
contribution explores subgroup text structuring expression form preposition demonstrative pronoun thus devoted aspect interaction coreference relation relation signaled discourse connective dc text demonstrative pronoun typically signal referential link antecedent whereas whole expression carry discourse meaning sense discourse connective describe property phrasesexpressions regard antecedent position among textstructuring language mean feature typical connective function compared nonconnective function analysis carried czech data approx sentence prague dependency treebank directly syntactic tree explore characteristic phrasesexpressions discovered two project manual annotation coreference relation nedoluzhko et al discourse connective scope meaning mladova et al
prior study addressing targetoriented conversational task lack crucial notion intensively studied context goaloriented artificial intelligence agent namely planning study propose task targetguided opendomain conversation planning tgcp task evaluate whether neural conversational agent goaloriented conversation planning ability using tgcp task investigate conversation planning ability existing retrieval model recent strong generative model experimental result reveal challenge facing current technology
global crisis language endangerment deepens indigenous community continued seek new mean preserving promoting passing language future generation many community modern language technology hold promise accelerating process however cultural disciplinary divide documentary linguist computational linguist indigenous community posed ongoing challenge development deployment nlp application support documentation revitalization indigenous language paper discus main barrier collaboration group encountered well notable initiative recent year bring group closer together follow specific recommendation build upon effort calling increased opportunity awarenessbuilding skillstraining computational linguistics tailored specific need documentary linguist indigenous community member see essential step move forward era nlpassisted language revitalization
text classification wellstudied versatile building block many nlp application yet existing approach require either large annotated corpus train model using large language model base require carefully crafting prompt well using long context fit many example result possible endusers build classifier address issue propose novel approach fewshot text classification using llm rather fewshot example llm prompted description salient feature class description coauthored user llm interactively user annotates fewshot example llm asks relevant question user answer example question answer summarized form classification prompt experiment show approach yield high accuracy classifier within performance model trained significantly larger datasets using training set additionally study participant show endusers able build classifier suit specific need personalized classifier show average accuracy higher stateoftheart approach
phone call still one primary preferred channel senior express need ask question inform potential problem health insurance plan alignment healthis nextgeneration consumercentric organization providing variety medicare advantage product senior combine proprietary technology platform ava hightouch clinical model provide senior care high quality low cost accompanied vastly improved consumer experience member ability connect member service concierge team wide variety everchanging reason different channel phone email message strive provide excellent member experience ensure member getting help information need every touch ideally even reach u requires ongoing monitoring reason contacting u ensuring agent equipped right tool information serve member coming proactive strategy eliminate need call possible developed nlpbased dynamic call reason tagging reporting pipeline optimized humanintheloop approach enable accurate call reason reporting monitoring ability see highlevel trend well drill granular subreasons system produce precision better recall tagging call proper reason also consistently achieved net promoter score np score illustrates high consumer satisfaction
event argument extraction long studied sequential prediction problem extractivebased method tackling argument isolation although recent work proposes generationbased method capture crossargument dependency require generating postprocessing complicated target sequence template motivated observation recent pretrained language model capability learning demonstration propose retrievalaugmented generative qa model rgqa event argument extraction retrieves similar qa pair augments prompt current example context decodes argument answer approach outperforms substantially prior method across various setting ie fully supervised domain transfer fewshot learning finally propose clusteringbased sampling strategy jointenc conduct thorough analysis different strategy influence fewshot learning performance
broader disclosive transparencytruth clarity communication regarding function ai systemsis widely considered desirable unfortunately nebulous concept difficult define quantify problematic previous work demonstrated possible tradeoff negative consequence disclosive transparency confusion effect much information cloud reader understanding system description mean disclosive transparency subjective nature rendered deep study problem remedy difficult improve state affair introduce neural language modelbased probabilistic metric directly model disclosive transparency demonstrate correlate user expert opinion system transparency making valid objective proxy finally demonstrate use metric pilot study quantifying relationship transparency confusion user perception corpus real nlp system description
empirically study effectiveness machinegenerated fake news detector understanding model sensitivity different synthetic perturbation test time current machinegenerated fake news detector rely provenance determine veracity news experiment find success detector limited since rarely sensitive semantic perturbation sensitive syntactic perturbation also would like opensource code believe could useful diagnostic tool evaluating model aimed fighting machinegenerated fake news
covid pandemic worst pandemic strike world century crucial stemming tide sarscov virus communicating vulnerable population mean protect end collaborator forming translation initiative covid tico made test development data available ai mt researcher different language order foster development tool resource improving access information covid language addition highresourced pivot language team targeting lesser resourced language particular language africa south asia southeast asia whose population may vulnerable spread virus data translated language represented meaning testing development done pairing language set team converting test development data translation memory tmxs used localizers language
mongolian question answer matching task challenging since mongolian kind lowresource language complex morphological structure lead data sparsity work propose interactive mongolian question answer matching model imqamm based attention mechanism mongolian question answering system key part model interactive information enhancement maxmean pooling matching interactive information enhancement contains sequence enhancement multicast attention sequence enhancement aim provide subsequent encoder enhanced sequence representation multicast attention designed generate scalar feature multiple attention mechanism maxmean pooling matching obtain matching vector aggregation moreover introduce mongolian morpheme representation better learn semantic feature model experimented mongolian corpus contains questionanswer pair various category law domain experimental result demonstrate proposed mongolian question answer matching model significantly outperforms baseline model
paper present new approach evaluation error analysis interpretation supervised unsupervised paraphrase identification pi system evaluation framework make use pi corpus annotated linguistic phenomenon provide better understanding interpretation performance various pi system approach allows qualitative evaluation comparison pi model using human interpretable category require modification training objective system place additional burden developer replicate several popular supervised unsupervised pi system using evaluation framework show system performs differently respect set linguistic phenomenon make qualitatively different kind error linguistic phenomenon challenging others across system
textual information significantly enhances performance pretrained language model plms knowledge graph completion kgc static noisy nature existing corpus collected wikipedia article synset definition often limit potential plmbased kgc model surmount challenge introduce textitcontextualization distillation strategy versatile pluginandplay approach compatible discriminative generative kgc framework method begin instructing large language model llm transform compact structural triplet contextrich segment subsequently introduce two tailored auxiliary tasksreconstruction contextualizationallowing smaller kgc model assimilate insight enriched triplet comprehensive evaluation across diverse datasets kgc technique highlight efficacy adaptability approach revealing consistent performance enhancement irrespective underlying pipeline architecture moreover analysis make method explainable provides insight generate highquality corpus kgc well selection suitable distillation task
paper addressed problem structured sentiment analysis using biaffine semantic dependency parser large pretrained language model publicly available translation model monolingual setup considered training single treebank ii relaxing setup training treebanks coming different language adequately processed crosslingual language model zeroshot setup given target treebank relied wordlevel translation available treebanks language get noisy unlikelygrammatical annotated data release much license allow ii merging translated treebanks obtain training data postevaluation phase also trained crosslingual model simply merged english treebanks use wordlevel translation yet obtained better result according official result ranked th th monolingual crosslingual setup
emojis become essential component digital communication emojis especially smiley face emojis heart emojis considered one conveying emotion paper two function emoji usage discussed across two language taiwanese mandarin english first function discussed sentiment enhancement sentiment modification multilingual language model adopted seeing probability distribution text sentiment relative entropy used quantify degree change result support previous research emojis frequentlyused positive context smiley tend used expressing emotion prove languageindependent nature emojis
local model recently attained astounding performance entity disambiguation ed generative extractive formulation promising research direction however previous work far limited study using textual representation candidate wikipedia title although certainly effective strategy present critical issue especially title sufficiently informative distinguishable one another paper address limitation investigate extent expressive textual representation mitigate evaluate approach thoroughly standard benchmark ed find extractive formulation particularly wellsuited representation report new state art benchmark consider strongly improve generalization capability unseen pattern release code data model checkpoint urlhttpsgithubcomsapienzanlpextend
paper give overview evaluation campaign result internationalworkshop spoken language translation iwslt workshop focused translation spontaneous speech recorded real situation feasability pivotlanguagebased translation approach translation direction english chinese vice versa challenge task chinese english english spanish pivot task arabic chinese spanish english standard btec task total research group building mt engine participated year event automatic subjective evaluation carried order investigate impact spontaneity aspect field data experiment automatic speech recognition asr machine translation mt system performance well robustness stateoftheart mt system towards speechtospeech translation real environment
model production quantified referring expression qres identify collection visual item address task propose method perceptual cost pruning consists two step determine subset quantity information perceived given time limit apply preference order based reg algorithm eg incremental algorithm reduced set information demonstrate method successfully improves humanlikeness ia qre generation task successfully model humangenerated language case
knowledge base kb require constant updating reflect change world represent general purpose kb often done relation extraction task predicting kb relation expressed text mentioning entity known kb one way improve use kb embeddings kbe link prediction however despite clear connection kbe little done toward properly unifying model systematically help close gap framework unifies learning kbe model leading significant improvement stateoftheart code available urlhttpsgithubcombillyinnhrere
auxiliary information multiple source demonstrated effective zeroshot finegrained entity typing zfet however lack comprehensive understanding make better use existing information source affect performance zfet paper empirically study three kind auxiliary information context consistency type hierarchy background knowledge eg prototype description type propose multisource fusion model msf targeting source performance obtains absolute gain stateoftheart baseline bbn wiki respectively regard macro f score importantly discus characteristic merit demerit information source provide intuitive understanding complementarity among
chainofthought cot technique guide large language model llm decompose complex task multistep reasoning intermediate step natural language form briefly cot enables llm think step step however although many natural language understanding nlu task also require thinking step step llm perform less well smallscale masked language model mlms migrate cot llm mlms propose chainofthought tuning cott twostep reasoning framework based prompt tuning implement stepbystep thinking mlms nlu task perspective cot cotts twostep framework enables mlms implement task decomposition cotts prompt tuning allows intermediate step used natural language form thereby success cot extended nlu task mlms verify effectiveness cott conduct experiment two nlu task hierarchical classification relation extraction result show cott outperforms baseline achieves stateoftheart performance
neural network model oftentimes restricted limited labeled instance resort advanced architecture feature cutting edge performance propose build recurrent neural network multiple semantically heterogeneous embeddings within selftraining framework framework make use labeled unlabeled social medium data operates basic feature scalable generalizable method establish stateoftheart result crossdomain clinical temporal relation extraction task
akkadian eastsemitic language spoken ancient mesopotamia language attested hundred thousand cuneiform clay tablet several akkadian text corpus contain transliterated text paper investigate automated phonological transcription transliterated corpus phonological transcription provides linguistically appealing form represent akkadian transcription normalized according grammatical description given dialect explicitly show akkadian rendering sumerian logogram cuneiform text mark inflection logogram inflected form need inferred sentence context best knowledge first documented attempt automatically transcribe akkadian using contextaware neural network model able automatically transcribe syllabic token near human performance recall logogram transcription remains challenging recall
traditionally context feature used word sense disambiguation based collocation statistic use minimal syntactic semantic information corpus pattern analysis technique producing knowledgerich context feature capture sense distinction involves identifying sensecarrying context pattern using derived context feature discriminate unseen instance stage require manual seeding paper show automate inducing sensediscriminating context feature sensetagged corpus
research progressing fast manner field offensive hate speech abusive sarcastic data tackling hate speech woman urgent really needed give respect lady life paper describes system used identifying misogynous content using image text system developed team techssn us transformer model detect misogynous content text convolutional neural network model image data various model like bert albert xlnet cnn explored combination albert cnn ensemble model provides better result rest system developed task competition semeval
among mental health disease depression one severe often lead suicide fourth leading cause death middle east middle east egypt highest percentage suicidal death due important identify depression suicidal ideation arabic culture lack awareness regarding importance diagnosing living mental health disease however noted last couple year people world including arab citizen tend express feeling openly social medium twitter popular platform designed enable expression emotion short text picture video paper aim predict depression depression suicidal ideation due tendency people treat social medium personal diary share deepest thought social medium platform social data contain valuable information used identify user psychological state create aradepsu dataset scrapping tweet twitter manually labelling expand diversity user tweet adding neutral label neutral dataset include three class depressed suicidal neutral train aradepsu dataset different transformer model find bestperforming model marbert accuracy precision recall fscore value
attempt develop sampleefficient interpretable algorithm researcher explored myriad mechanism collecting exploiting feature feedback auxiliary annotation provided training test instance highlight salient evidence example include bounding box around object salient span text despite intuitive appeal feature feedback delivered significant gain practical problem assessed iid holdout set however recent work counterfactually augmented data suggest alternative benefit supplemental annotation beyond interpretability lessening sensitivity spurious pattern consequently delivering gain outofdomain evaluation speculate existing method incorporating feature feedback delivered negligible insample performance gain may nevertheless provide outofdomain benefit experiment addressing sentiment analysis show feature feedback method perform significantly better various natural outofdomain datasets despite comparable indomain evaluation contrast performance natural language inference remains comparable finally compare task feature feedback help
reduce task spanbased propbankstyle semantic role labeling srl syntactic dependency parsing approach motivated empirical analysis show three common syntactic pattern account srl annotation english chinese data based observation present conversion scheme pack srl annotation dependency tree representation joint label permit highly accurate recovery back original format representation allows u train statistical dependency parser tackle srl achieve competitive performance current state art finding show promise syntactic dependency tree encoding semantic role relation within syntactic domain locality point potential integration syntactic method semantic role labeling future
improve performance neural machine translation nmt lowresource language lrl one effective strategy leverage parallel data related highresource language hrl however multilingual data found beneficial nmt model translate lrl target language one translate lrls paper aim improve effectiveness multilingual transfer nmt model translate lrl designing better decoder word embedding extending upon generalpurpose multilingual encoding method soft decoupled encoding wang et al propose decsde efficient character ngram based embedding specifically designed nmt decoder experiment show decsde lead consistent gain bleu translation english four different language
metaphor essential element human cognition often used express idea emotion might difficult express using literal language processing metaphoric language challenging task wide range application ranging text simplification psychotherapy despite variety approach trying process metaphor still need better model mimic human cognition exploiting fewer resource paper present approach based distributional semantics identify metaphor phraselevel investigated use different word embeddings model identify verbnoun pair verb used metaphorically several experiment conducted show performance proposed approach benchmark datasets
paper present method longsumm shared task generating long summary scientific document task generatelong summary given set scientific paper provided organizer explore main approach task extractive approach using bertbased summarization model two stage model additionally includes abstraction step using bart new multitasking approach incorporating document structure summarizer found new multitasking approach outperforms two method large margin among participant shared task best model rank top according rouge score staying competitive term rouge
idiomatic expression ie processing comprehension challenged pretrained language model ptlms meaning noncompositional unlike prior work enable ie comprehension finetuning ptlms sentence containing y work construct iekg commonsense knowledge graph figurative interpretation y extends established atomic converting ptlms knowledge model km encode infer commonsense knowledge related ie use experiment show various ptlms converted km iekg verify quality iekg ability trained km automatic human evaluation application natural language understanding show ptlm injected knowledge iekg exhibit improved ie comprehension ability generalize y unseen training
aspectbased sentiment analysis absa finegrained task recently using graph convolutional network gcns model syntactic information become popular topic addition growing consensus exists enhance sentence representation using contrastive learning however modeling syntactic information incorrect syntactic structure may introduce additional noise meanwhile believe contrastive learning implicitly introduce label information priori therefore propose clpgcn integrates contrastive learning cooperative learning prompt gcn specifically alleviate noise modeling syntactic information propose maskaware aspect information filter combine prompt information template aspect information filter syntactic information besides propose promptbased contrastive learning cooperative learning utilise label information one hand construct prompt containing label contrastive learning model focus taskrelevant feature hand cooperative learning extract label information aligning input sample representation output distribution label sample extensive experiment three datasets demonstrate method significantly improves model performance compared traditional contrastive learning method moreover clpgcn outperforms stateoftheart method source code final model publicly available github
metaphor detection challenging task nlp domain emergence transformerbased language model difficulty lie subtle semantic nuance required detect metaphor scarcity labeled data explore fewshot setup metaphor detection also introduce new question answering data enhance classifier trained small amount data formulate classification task questionanswering one train questionanswering model perform extensive experiment shot several architecture report result several strong baseline thus answer question posed title definite yes
contribution part wider research project term variation german concentrate computational aspect framebased model term meaning representation technical field focus role frame sense framebased terminology semantic interface concept covered domain ontology domainspecific terminology particular describe method performing framebased corpus annotation framebased term extraction aim contribution discus capacity model automatically acquire semantic knowledge suitable terminographic information tool specialised dictionary applicability specialised language
paper propose beginning formal framework modeling narrative textitqua narrative framework affords ability discus key quality story communication including flow information narrator reader evolution reader story model time reader uncertainty demonstrate applicability computational narratology giving explicit algorithm measuring accuracy information conveyed reader along two novel measurement story coherence
language modeling bert consists two phase unsupervised pretraining unlabeled text ii finetuning specific supervised task present method leverage second phase fullest applying extensive number parallel classifier head enforced orthogonal adaptively eliminating weaker head training conduct extensive inter intradataset evaluation showing method improves generalization ability bert sometimes leading gain accuracy result highlight importance proper finetuning procedure especially relatively smallersized datasets code attached supplementary
online relevance matching essential task ecommerce product search boost utility search engine ensure smooth user experience previous work adopts either classical relevance matching model transformerstyle model address however ignore inherent bipartite graph structure ubiquitous ecommerce product search log inefficient deploy online paper design efficient knowledge distillation framework ecommerce relevance matching integrate respective advantage transformerstyle model classical relevance matching model especially core student model framework propose novel method using korder relevance modeling experimental result largescale realworld data size million show proposed method significantly improves prediction accuracy term human relevance judgment deploy method jdcom online search platform ab testing result show method significantly improves business metric price sort mode default sort mode
machine translation natural candidate problem reinforcement learning human feedback user provide quick dirty rating candidate translation guide system improve yet current neural machine translation training focus expensive humangenerated reference translation describe reinforcement learning algorithm improves neural machine translation system simulated human feedback algorithm combine advantage actorcritic algorithm mnih et al attentionbased neural encoderdecoder architecture luong et al algorithm welldesigned problem large action space delayed reward b effectively optimizes traditional corpuslevel machine translation metric c robust skewed highvariance granular feedback modeled actual human behavior
address problem duplicate question detection dqd lowresource domainspecific community question answering forum multiview framework mvdase combine ensemble sentence encoders via generalized canonical correlation analysis using unlabeled data experiment ensemble includes generic domainspecific averaged word embeddings domainfinetuned bert universal sentence encoder evaluate mvdase cqadupstack corpus additional lowresource stack exchange forum combining strength different encoders significantly outperform bm singleview system well recent supervised domainadversarial dqd method
data synthesis promising way train small model little labeled data one approach data synthesis leverage rich knowledge large language model synthesize pseudo training example small model making possible achieve data compute efficiency time however key challenge data synthesis synthesized dataset often suffers large distributional discrepancy real task data distribution thus paper propose synthesis step step data synthesis framework shrink distribution gap iteratively extrapolating error made small model trained synthesized dataset small realworld validation dataset using large language model extensive experiment multiple nlp task show approach improves performance small model reducing gap synthetic dataset real data resulting significant improvement compared several baseline improvement compared zerogen compared goldgen improvement compared small model trained humanannotated data
providing plausible response question challenging critical goal language based humanmachine interaction explanation challenging require many different form abstract knowledge reasoning previous work either relied humancurated structured knowledge base detailed domain representation generate satisfactory explanation also often limited ranking preexisting explanation choice work contribute underexplored area generating natural language explanation general phenomenon automatically collect large datasets explanationphenomenon pair allow u train sequencetosequence model generate natural language explanation compare different training strategy evaluate performance using automatic score human rating demonstrate strategy sufficient generate highly plausible explanation general opendomain phenomenon compared model trained different datasets
paper describes parsu ukrainianenglish bidirectional mt system lingvistica co parsu translates m word html file well screen help feature easytomaster dictionary updating program permit user customize system mean running subjectarea oriented text mt engine parsu marketed ukraine north america
sentiment classification valuable literary analysis sentiment crucial literary narrative example used investigate hypothesis literary analysis thcentury scandinavian novel writing female author period characterized negative sentiment paper show order enable datadriven analysis hypothesis create manually annotated dataset sentencelevel sentiment annotation novel period use train evaluate various sentiment classification method find pretrained multilingual language model outperform model trained modern danish well classifier based lexical resource finally classifierassisted corpus analysis confirm literary hypothesis regarding author gender shed light temporal development trend dataset trained model useful future analysis historical danish norwegian literary text
language representation model bert could effectively capture contextual semantic information plain text proved achieve promising result lot downstream nlp task appropriate finetuning however existing language representation model explicitly handle coreference essential coherent understanding whole discourse address issue present corefbert novel language representation model capture coreferential relation context experimental result show compared existing baseline model corefbert achieve significant improvement consistently various downstream nlp task require coreferential reasoning maintaining comparable performance previous model common nlp task source code experiment detail paper obtained urlhttpsgithubcomthunlpcorefbert
communicating human challenging ai requires shared understanding world complex semantics eg metaphor analogy time multimodal gesture eg pointing finger arrow diagram investigate challenge context iconary collaborative game drawing guessing based pictionary pose novel challenge research community iconary guesser try identify phrase drawer drawing composing icon drawer iteratively revise drawing help guesser response backandforth often us canonical scene visual metaphor icon composition express challenging word making ideal test mixing language visualsymbolic communication ai propose model play iconary train game human player model skillful player able employ world knowledge language model play word unseen training
paper summarizes latest final version iso standard semantic annotation framework part dialogue act compared preliminary version iso dis described bunt et al final version additionally includes concept annotating rhetorical relation dialogue unit defines fullblown compositional semantics dialogue act markup language diaml resulting sideeffect different treatment functional dependence relation among dialogue act feedback dependence relation specifies optimally transparent xmlbased reference format representation diaml annotation based systematic application notion ideal concrete syntax describe difference briefly discus design implementation incremental method dialogue act recognition prof usability iso standard automatic dialogue annotation
class imbalance problem cause machine learning model produce undesirable performance minority class well whole dataset using data augmentation technique increase number sample one way tackle problem introduce novel counterfactual data augmentation verb replacement identification medical claim addition investigate impact method compare data augmentation technique showing proposed method result significant relative improvement minority class
recent work problem latent tree learning made possible train neural network learn parse sentence use resulting parse interpret sentence without exposure groundtruth parse tree training time surprisingly model often perform better sentence understanding task model use parse tree conventional parser paper aim investigate latent tree learning model learn replicate two model shared codebase find one model outperforms conventional treestructured model sentence classification ii parsing strategy especially consistent across random restarts iii parses produce tend shallower standard penn treebank ptb parses iv resemble ptb semantic syntactic formalism author aware
quadratic computational memory complexity large transformer limited scalability long document summarization paper propose hepos novel efficient encoderdecoder attention headwise positional stride effectively pinpoint salient information source conduct systematic study existing efficient selfattentions combined hepos able process ten time token existing model use full attention evaluation present new dataset govreport significantly longer document summary result show model produce significantly higher rouge score competitive comparison including new stateoftheart result pubmed human evaluation also show model generate informative summary fewer unfaithful error
aim position paper establish initial approach automatic classification digital image outsider art style painting specifically explore whether possible classify nontraditional artistic style using feature used classifying traditional style research question motivated two fact first art historian state nontraditional style influenced factor outside world art second study shown several artistic style confound certain classification technique following current approach style prediction paper utilises deep learning method encode image feature preliminary experiment provided motivation think case traditional style outsider art computationally modelled objective mean using training datasets cnn model nevertheless result conclusive due lack large available dataset outsider art therefore end paper mapped future line action include compilation large dataset outsider art image creation ontology outsider art
explosion biomedical literature uncontrolled creation abbreviation present special challenge human reader computer application developed annotated corpus dutch medical text experimented two approach abbreviation detection resolution corpus composed abstract two medical journal low country approximately percent ntvg percent tvg abbreviation corresponding full form abstract first approach patternbased system consists two step abbreviation detection definition matching system average fscore detection defined undefined abbreviation average fscore obtained definition second approach svmbased classifier used preprocessed data set leading average fscore abbreviation definition average fscore obtained
paper describes alboradaia corpus disordered speech acquired recent year research different speech technology handicapped like automatic speech recognition pronunciation assessment contains hour speech young impaired speaker nearly hour unimpaired agematched peer whose collaboration possible joint work different educational assistive institution furthermore extra resource provided corpus including result perceptual humanbased labeling lexical mispronunciation made impaired speaker corpus used achieve result different task like analysis speech production impaired child acoustic lexical adaptation asr study speech proficiency impaired speaker finally full corpus freely available research community restriction maintaining data resource research purpose keeping privacy speaker speech data
paper investigates problemsolving capability large language model llm evaluating performance stumper unique singlestep intuition problem pose challenge human solver easily verifiable compare performance four stateoftheart llm davinci davinci gptturbo gpt human participant finding reveal newgeneration llm excel solving stumper surpass human performance however human exhibit superior skill verifying solution problem research enhances understanding llm cognitive ability provides insight enhancing problemsolving potential across various domain
collecting annotating taskoriented dialog data difficult especially highly specific domain require expert knowledge time informal communication channel instant messenger increasingly used work led lot workrelevant information disseminated channel need postprocessed manually employee alleviate problem present texprax messaging system collect annotate problem cause solution occur workrelated chat texprax us chatbot directly engage employee provide lightweight annotation conversation ease documentation work comply data privacy security regulation use endtoend message encryption give user full control data various advantage conventional annotation tool evaluate texprax userstudy german factory employee ask colleague solution problem arise daily work overall collect taskoriented german dialogue containing sentence sentencelevel expert annotation data analysis also reveals realworld conversation frequently contain instance codeswitching varying abbreviation entity dialect nlp system able handle
recent advancement large language model llm garnered widespread acclaim remarkable emerging capability however issue hallucination parallelly emerged byproduct posing significant concern recent endeavor made identify mitigate different type hallucination limited emphasis nuanced categorization hallucination associated mitigation method address gap offer finegrained discourse profiling hallucination based degree orientation category along offering strategy alleviation define two overarching orientation hallucination factual mirage fm ii silver lining sl provide comprehensive understanding orientation subcategorized intrinsic extrinsic three degree severity mild ii moderate iii alarming also meticulously categorize hallucination six type acronym ambiguity ii numeric nuisance iii generated golem iv virtual voice v geographic erratum vi time wrap furthermore curate hallucination elicitation hilt publicly available dataset comprising sample generated using contemporary llm along human annotation aforementioned category finally establish method quantifying offer comparative spectrum allows u evaluate rank llm based vulnerability producing hallucination propose hallucination vulnerability index hvi amidst extensive deliberation policymaking regulating ai development utmost importance assess measure llm vulnerable towards hallucination firmly believe hvi hold significant value tool wider nlp community potential serve rubric airelated policymaking conclusion propose two solution strategy mitigating hallucination
paper present team bert ensemble designed nadi subtask sentiment analysis abdulmageed et al twitter sentiment analysis one language processing nlp task provides method understand perception emotion public around specific topic common research approach focus obtaining tweet sentiment analyzing lexical syntactic feature used multiple pretrained arabicbert model simple average ensembling chose bestperforming ensemble training dataset ran development dataset system ranked rd subtask macropnfscore
present paper describes corpus query lingua franca iso cqlf specification designed iso technical committee subcommittee language resource management purpose facilitating comparison property corpus query language overview motivation endeavour present aim general architecture cqlf intended multipart specification concentrate basic metamodel provides frame part fit
paper measure variation embedding space trained different regional variety english controlling instability embeddings previous work shown possible distinguish similar variety language paper experiment two followup question first variety represented training data systematically influence resulting embedding space training paper show difference embeddings across variety significantly higher baseline instability second dialectbased variation spread equally throughout lexicon paper show specific part lexicon particularly subject variation taken together experiment confirm embedding space significantly influenced dialect represented training data finding implies semantic variation across dialect addition previouslystudied lexical syntactic variation
paper propose generalizable dialog generation approach adapts multiturn reasoning one recent advancement field document comprehension generate response answer taking current conversation session context document current query question major idea represent conversation session memory upon attentionbased memory reading mechanism performed multiple time user query properly extended contextual clue optimal response stepbystep generated considering speaker one conversation limited one separate single memory used document comprehension different group speakerspecific topic opinion embedding namely utilize query memory response memory unified memory following time sequence conversation session experiment japanese sentence round conversation modeling show impressive result multiturn reasoning produce diverse acceptable response stateoftheart singleturn nonreasoning baseline
world data stored relational database accessing requires specialized knowledge structured query language sql putting reach many people recent research thread natural language processing nlp aim alleviate problem automatically translating natural language question sql query proposed solution great start lack robustness easily generalize method require high quality description database table column widely used training dataset wikisql heavily biased towards using description part question work propose solution problem entirely eliminate need column description relying solely content augment wikisql dataset paraphrasing column name reduce bias show accuracy existing method drop trained augmented columnagnostic dataset method reach state art accuracy relying column content
paper present enhanced dependency parsing approach using transformer encoders coupled simple yet powerful ensemble algorithm take advantage tree graph dependency parsing two type transformer encoders compared multilingual encoder languagespecific encoders dependency tree parsing dtp approach generates primary dependency form tree whereas dependency graph parsing dgp approach handle primary secondary dependency form graph since dgp guarantee generated graph acyclic ensemble algorithm designed add secondary arc predicted dgp primary arc predicted dtp result show model using multilingual encoder outperform one using language specific encoders language ensemble model generally show higher labeled attachment score enhanced dependency ela dtp dgp model result best model rank third place macroaverage ela language
beam search optimization wiseman rush resolve many issue neural machine translation however method lack principled stopping criterion learn stop training model naturally prefers longer hypothesis testing time practice since use raw score instead probabilitybased score propose novel ranking method enables optimal beam search stop ping criterion introduce structured prediction loss function penalizes suboptimal finished candidate produced beam search training experiment neural machine translation synthetic data real language germanenglish chineseenglish demonstrate pro posed method lead better length bleu score
emotion recognition conversation important empathetic dialogue system understand user emotion generate appropriate emotional response however previous research focus modeling conversational context primarily based textual modality simply utilizing multimodal information feature concatenation order exploit multimodal information contextual information effectively propose multimodal directed acyclic graph mmdag network injecting information flow inside modality across modality dag architecture experiment iemocap meld show model outperforms stateoftheart model comparative study validate effectiveness proposed modality fusion method
word representation important aspect natural language processing nlp representation trained using large corpus either independent static embeddings part deep contextualized model word embeddings useful struggle rare unknown word large body work done estimating rare unknown word however method focus static embeddings model focused contextualized representation work propose spruce rareunknown embedding architecture focus contextualized representation architecture us subword attention embedding postprocessing combined contextualized model produce high quality embeddings demonstrate technique lead improved performance intrinsic downstream task
paper investigate capability convolutional neural network recognize sign language video frame six basic ekman facial expression fear disgust surprise sadness happiness anger along neutral class given limited amount annotated facial expression data sign language domain started model pretrained generalpurpose facial expression datasets applied various machine learning technique finetuning data augmentation class balancing well image preprocessing reach better accuracy model evaluated using kfold crossvalidation get accurate conclusion experimentally demonstrated finetuning pretrained model along data augmentation horizontally flipping image image normalization help providing best accuracy sign language dataset best setting achieves satisfactory classification accuracy comparable stateoftheart system generic facial expression recognition experiment performed using different combination abovementioned technique based two different architecture namely mobilenet efficientnet deemed architecture seem equally suitable purpose finetuning whereas class balancing discouraged
paper study task improving cohesion coherence longform text generated language model end propose rstgen framework utilises rhetorical structure theory rst classical language theory control discourse structure semantics topic generated text firstly demonstrate model ability control structural discourse semantic feature generated text open generation evaluation experiment two challenging longform text task argument generation story generation evaluation using automated metric metric high correlation human evaluation show model performs competitively existing model offering significantly control generated text alternative method
lexical semantic change detection also known semantic shift tracing task identifying word changed meaning time unsupervised semantic shift tracing focal point semeval particularly challenging given unsupervised setup work propose identify cluster among different occurrence target word considering representative different word meaning disagreement obtained cluster naturally allow quantify level semantic shift per target word four target language leverage idea clustering performed contextualized bertbased embeddings word occurrence obtained result show approach performs well measured separately per language overall surpass provided semeval baseline
disentangling underlying factor contributing expression emotion multimodal data challenging may accelerate progress toward many realworld application paper describe approach solving semeval task subtask focused identifying utterancelevel emotion cause using text available multimodal friend television series dataset propose disjointly model emotion detection causal span detection borrowing paradigm popular question answering qa train model experiment find contextual utterance target utterance play crucial role emotion classification b emotion established detecting causal span resulting emotion using qabased technique yield promising result
stateoftheart system deep question answering proceed follows initial document retrieval selects relevant document processed neural network order extract final answer yet exact interplay component poorly understood especially concerning number candidate document retrieved show choosing static number document used prior research suffers noiseinformation tradeoff yield suboptimal result remedy propose adaptive document retrieval model learns optimal candidate number document retrieval conditional size corpus query report extensive experimental result showing adaptive approach outperforms stateoftheart method multiple benchmark datasets well context corpus variable size
ecommerce domain search query refinement reformulates malformed query canonicalized form preprocessing operation term splitting term merging unfortunately relevant research rather limited english particular severe lack study search query refinement japanese language furthermore attempt ever made apply refinement method data improvement downstream nlp task realworld scenariosthis paper present novel query refinement approach japanese language experimental result show method achieves significant improvement point comparison bertcrf baseline experiment also conducted measure beneficial impact query refinement named entity recognition ner downstream task evaluation indicate proposed query refinement method contributes better data quality leading performance boost ecommerce specific ner task point compared search query data preprocessed mecab popularly adopted japanese tokenizer
multiturn response selection aim retrieve response dialogue context candidate pool negative sampling key retrieval performance however previous method negative sample tend yield false negative due onetomany property opendomain dialogue detrimental optimization process deal problem propose sequential variational ladder autoencoder capture diverse onetomany transition pattern multiple characteristic opendomain dialogue learned transition logic thus assist identifying potential positive disguise meanwhile propose trigger framework adjust negative sampling training process scope false negative dynamically update according model capacity extensive experiment two benchmark verify effectiveness approach
similar phrasebased machine translation hierarchical system produce large proportion phrase supposedly junk useless actual translation hierarchical case however amount extracted rule order magnitude bigger paper investigate several soft constraint extraction hierarchical phrase whether help additional score decoding prune unneeded phrase show method help best
documentlevel relation extraction docre involves identifying relation entity distributed multiple sentence within document existing method focus building heterogeneous document graph model internal structure entity external interaction entity however two drawback existing method one hand anaphor play important role reasoning identify relation entity ignored method hand method achieve crosssentence entity interaction implicitly utilizing document sentence intermediate node approach difficulty learning finegrained interaction entity across different sentence resulting suboptimal performance address issue propose anaphorassisted aa framework docre task experimental result widelyused datasets demonstrate model achieves new stateoftheart performance
study examine benefit incorporating discourse information documentlevel temporal dependency parsing specifically evaluate effectiveness integrating highlevel discourse profiling information describes discourse function sentence surfacelevel sentence position information temporal dependency graph tdg parsing unexpectedly result suggest simple sentence position information particularly encoded using novel sentenceposition embedding method performs best perhaps rely noisy modelgenerated feature input proposed system surpasses current stateoftheart tdg parsing system performance furthermore aim broaden discussion relationship temporal dependency parsing discourse analysis given substantial similarity shared two task argue discourse analysis result merely regarded additional input feature temporal dependency parsing instead adopting advanced discourse analysis technique research insight lead effective comprehensive approach temporal information extraction task
growing demand automatic assessment spoken english proficiency system need handle large variation input data owing wide range candidate skill level l error asr candidate poor match training data set undermining validity predicted grade high stake test essential system grade well also provide measure uncertainty prediction enabling rejection human grader previous work examined gaussian process gp grader though successful scale well large data set deep neural network dnn may also used provide uncertainty using montecarlo dropout mcd paper proposes novel method yield uncertainty compare gps dnns mcd proposed approach explicitly teach dnn low uncertainty training data high uncertainty generated artificial data experiment conducted data business language testing service bulats proposed approach found outperform gps dnns mcd uncertaintybased rejection whilst achieving comparable grading performance
though recently increased interest pretrained language model encode different linguistic feature still lack systematic comparison language different morphology syntax paper using bert example pretrained model compare three typologically different language english korean russian encode morphology syntax feature across different layer particular contrast language differ particular aspect flexibility word order head directionality morphological type presence grammatical gender morphological richness across four different task
machine translation mt system progress rapid pace question adequacy linger study focus negation universal core property human language significantly affect semantics utterance investigate whether translating negation issue modern mt system using translation direction test bed thorough analysis find indeed presence negation significantly impact downstream quality case resulting quality reduction also provide linguistically motivated analysis directly explains majority finding release annotation code replicate analysis urlhttpsgithubcommosharafhossainnegationmt
bayesian approach reconstructing evolutionary history language rely tree model assumes language descended common ancestor underwent modification time however assumption violated different extent due contact factor understanding degree assumption violated crucial validating accuracy phylolinguistic inference paper propose simple sanity check projecting reconstructed tree onto space generated principal component analysis using synthetic real data demonstrate method effectively visualizes anomaly particularly form jogging
socalled standard form contract ie contract drafted unilaterally one party like term condition online shop term service social network cornerstone modern economy processing therefore significant practical value often sheer size contract allows drafting party hide unfavourable term party paper compare different approach automatically classifying topic clause standard form contract based dataset clause contract collected german english online shop annotated based taxonomy clause topic developed together legal expert show comparison seven approach simple keyword matching transformer language model bert performed best fscore however much simpler computationally cheaper model like logistic regression also achieved similarly good result
paper present result systematic experimentation impact duplicate question detection different type question across number established approach novel superior one used address language processing task study permit gain novel insight different level robustness diverse detection method respect different condition application including one approximate real usage scenario
aim motivate provide specification unificationbased natural language processing system grammar expressed term principle constrain linguistic representation using typed feature structure multiple inheritance linguistic representation definite attributevalue logic clause express constraint develop bare essential required implementation parser generator headdriven phrase structure grammar hpsg formalism pollard sag
paper leverage existence dual subtitle source parallel data dual subtitle present viewer two language simultaneously generally aligned segment level remove need automatically perform alignment desirable extracted parallel data contain alignment error present previous work aligns different subtitle file movie present simple heuristic detect extract dual subtitle show million sentence pair extracted mandarinenglish language pair also show extracting data source viable solution improving machine translation system domain subtitle
famous laurelyanny phenomenon reference audio clip elicits dramatically different response different listener original clip roughly half population hears word laurel half hears yanny common polyperceivable audio clip paper apply ml technique study prevalence polyperceivability spoken language devise metric correlate polyperceivability audio clip use efficiently find new laurelyannytype example validate result human experiment result suggest polyperceivable example surprisingly prevalent natural language existing textgreater english word
judgement communicative agent evolve course interaction individual judged testimonial reliability ideological trustworthiness paper combine theory social meaning persona theory reliability within gametheoretic view communication giving formal model involving interactional history repeated game model way evaluating social meaning trustworthiness
several attempt define plausible motivation chitchat dialogue agent lead engaging conversation work explore new direction agent specifically focus discovering information interlocutor formalize approach defining quantitative metric propose algorithm agent maximize validate idea human evaluation system outperforms various baseline demonstrate metric indeed correlate human judgment engagingness
finegrained entity typing task assigning finegrained semantic type entity mention propose neural architecture learns distributional semantic representation leverage greater amount semantic context document sentence level information prior work find additional context improves performance improvement gained utilizing adaptive classification threshold experiment show approach without reliance handcrafted feature achieves stateoftheart result three benchmark datasets
medical document possible entity interest contains discontiguous sequence word also overlap another entity entity structure intrinsically hard recognize due large space possible entity combination work propose neural twostage approach recognizing discontiguous overlapping entity decomposing problem two subtasks first detects overlapping span either form entity present segment discontiguous entity based representation segmental hypergraph next learns combine segment discontiguous entity classifier filter incorrect combination segment two neural component designed subtasks respectively learned jointly using shared encoder text model achieves stateoftheart performance standard dataset even absence external feature previous method used
describe system developed wnut shared task identification informative covid english tweet bert highly performant model natural language processing task increased berts performance classification task finetuning bert concatenating embeddings tweetspecific feature training support vector machine svm classification henceforth called bert compared performance suite machine learning model used twitter specific data cleaning pipeline wordlevel tfidf extract feature nonbert model bert top performing model fscore
distant supervision d strong way expand datasets enhancing relation extraction model often suffers high label noise current work based attention reinforcement learning gan blackbox model neither provide meaningful interpretation sample selection d stability different domain contrary work proposes novel modelagnostic instance sampling method d influence function namely reif method identifies favorableunfavorable instance bag based dynamic instance sampling design fast influence sampling algorithm reduces computational complexity mathcalomn mathcalo analyzing robustness selected sampling function experiment show simply sampling favorable instance training reif able win series baseline complicated architecture also demonstrate reif support interpretable instance selection
paper present upappliedcls contribution germeval shared task particular participated subtasks engaging comment classification factclaiming comment classification acceptable result obtained using unigrams linguistic feature combination traditional machine learning model show task transformer model trained finetuned bert embeddings yield best result
paper introduces shared task summrizing document several creative domain namely literary text movie script television script summarizing creative document requires making complex literary interpretation well understanding nontrivial temporal dependency text containing varied style plot development narrative structure pose unique challenge yet underexplored text summarization system shared task introduce four subtasks corresponding datasets focusing summarizing book movie script primetime television script daytime soap opera script detail process curating datasets task well metric used evaluation submission part creativesumm workshop coling shared task attracted submission total discus submission baseline subtask paper along direction facilitating future work
abusive text reaching interest scientific social community automatically detect onequestion gaining interest natural language processing community main contribution paper toevaluate quality recently developed spanish database cyberbullying prevention purpose trainingclassifiers detecting abusive short text compare classical machine learning technique use advanced model contextual word embeddings particular case classification abusive shorttexts spanishlanguage contextual word embeddings use bidirectional encoder representation transformer bert proposed end show bert mostly outperforms classical technique far beyond experimentalimpact research project aim planting seed innovative technological tool high potentialsocial impact aiming part initiative artificial intelligence social good
task financial analysis primarily encompasses two key area stock trend prediction corresponding financial question answering currently machine learning deep learning algorithm mldl widely applied stock trend prediction leading significant progress however method fail provide reason prediction lacking interpretability reasoning process also integrate textual information financial news report meanwhile large language model llm remarkable textual understanding generation ability due scarcity financial training datasets limited integration realtime knowledge llm still suffer hallucination unable keep latest information tackle challenge first release alphafin datasets combining traditional research datasets realtime financial data handwritten chainofthought cot data positive impact training llm completing financial analysis use alphafin datasets benchmark stateoftheart method called stockchain effectively tackling financial analysis task integrates retrievalaugmented generation rag technique extensive experiment conducted demonstrate effectiveness framework financial analysis
present inria approach suggestion mining task semeval task consists two subtasks suggestion mining singledomain subtask crossdomain subtask b setting used support vector machine algorithm trained handcrafted feature function word sentiment feature digit verb subtask handcrafted feature subtask b best run archived fscore subtask ranked top ten submission subtask b fscore
taskoriented dialogue system often assist user personal confidential matter reason developer system generally prohibited observing actual usage know system failing need training data new functionality work study way realistic user utterance generated synthetically help increase linguistic functional coverage system without compromising privacy actual user end propose twostage differentially private dp generation method first generates latent semantic parses generates utterance based parses proposed approach improves mauve x parse tree functiontype overlap x relative current approach private synthetic data generation improving fluency semantic coverage validate approach realistic domain adaptation task adding new functionality private user data semantic parser show overall gain point accuracy new feature
present design system making sense conflicting rule expressed fragment prominent controlled natural language ace yet extended mean expressing defeasible rule form normality assumption approach describe ultimately based answersetprogramming asp simulating existential quantification using skolemization manner resembling translation asp recently formalized context asp discus advantage approach building existing ace interface rulesystems acerules
distantly supervised named entity recognition dsner efficiently reduces labor cost meanwhile intrinsically suffers label noise due strong assumption distant supervision typically wrongly labeled instance comprise number incomplete inaccurate annotation prior denoising work concerned one kind noise fail fully explore useful information training set address issue propose robust learning paradigm named selfcollaborative denoising learning scdl jointly train two teacherstudent network mutuallybeneficial manner iteratively perform noisy label refinery network designed exploit reliable label via self denoising two network communicate explore unreliable annotation collaborative denoising extensive experimental result five realworld datasets demonstrate scdl superior stateoftheart dsner denoising method
proposal describes new way visualise resource lremap communitybuilt repository language resource description us lremap represented forcedirected graph resource paper author node analysis visual representation underlying graph used study community gather around lr lr used research
prior study found woman selfpromote less men due gender stereotype study built bertbased nlp model predict whether congressional tweet show selfpromotion used model examine whether gender gap selfpromotion exists among congressional tweet analyzing million congressional tweet july march controlling number factor include political party chamber age number term congress number daily tweet number follower found woman congress actually perform selfpromotion twitter indicating reversal traditional gender norm woman selfpromote less men
pretrained multilingual transformer achieved great success crosslingual transfer learning current method typically activate crosslingual transferability multilingual transformer finetuning endtask data however method perform crosslingual transfer endtask data unavailable work explore whether crosslingual transferability activated without endtask data propose crosslingual transfer method named pluginx pluginx disassembles monolingual multilingual transformer submodules reassembles multilingual endtask model representation adaptation pluginx finally performs crosslingual transfer plugandplay style experimental result show pluginx successfully activates crosslingual transferability multilingual transformer without accessing endtask data moreover analyze crossmodel representation alignment affect crosslingual transferability
last five year research relation extraction witnessed extensive progress many new dataset release time setup clarity decreased contributing increased difficulty reliable empirical evaluation taille et al paper provide comprehensive survey datasets revisit task definition adoption community find crossdataset crossdomain setup particularly lacking present empirical study scientific relation classification across two datasets despite large data overlap analysis reveals substantial discrepancy annotation annotation discrepancy strongly impact relation classification performance explaining large drop crossdataset evaluation variation within subdomains exists impact relation classification limited degree overall study call rigour reporting setup evaluation across multiple test set
social medium play great role news dissemination includes good bad news however study show news general significant impact mental stature influence bad news ideal situation would tool help filter type news want consume paper provide basis tool work focus twitter release manually annotated dataset containing tweet different topical category tweet annotated good bad label also investigate various machine learning system feature evaluate performance newly generated dataset also perform comparative analysis sentiment showing sentiment alone enough distinguish good bad news
personalized response selection system generally grounded persona however correlation exists persona empathy system explore well also contradictory offtopic response selected faithfulness conversation context plunge paper attempt address issue proposing suite fusion strategy capture interaction persona emotion entailment information utterance ablation study personachat dataset show incorporating emotion entailment improves accuracy response selection combine fusion strategy conceptflow encoding train bertbased model outperforms previous method margin larger original persona revised persona term hit top accuracy achieving new stateoftheart performance personachat dataset
realworld scenario naturally occurring datasets reference summary noisy may contain information inferred source text large news corpus removing low quality sample shown reduce model hallucination yet smaller andor noisier corpus filtering detrimental performance improve reference quality retaining data propose new approach selectively rewrite unsupported reference sentence better reflect source data automatically generate synthetic dataset positive negative revision corrupting supported sentence learn revise reference sentence contrastive learning intensity revision treated controllable attribute inference diverse candidate overgeneratedthenrescored balance faithfulness abstraction test method extract noisy reference publicly available mimiciii discharge summary task hospitalcourse summarization vary data model trained according metric human evaluation model trained revised clinical reference much faithful informative fluent model trained original filtered data
recent study show neural natural language processing nlp model vulnerable backdoor attack injected backdoor model perform normally benign example produce attackerspecified prediction backdoor activated presenting serious security threat realworld application since existing textual backdoor attack pay little attention invisibility backdoor easily detected blocked work present invisible backdoor activated learnable combination word substitution show nlp model injected backdoor lead nearly attack success rate whereas highly invisible existing defense strategy even human inspection result raise serious alarm security nlp model requires research resolved data code paper released urlhttpsgithubcomthunlpbkdatklws
spoken dialogue system dialogue state tracker dst component track state conversation updating distribution value associated slot tracked current user turn using interaction much previous work relied modeling natural order conversation using distance based offset approximation time work hypothesize leveraging wallclock temporal difference turn crucial finergrained control dialogue scenario develop novel approach applies time mask based wallclock time difference associated slot embeddings empirically demonstrate proposed approach outperforms existing approach leverage distance offset internal benchmark dataset well dstc
work transformer trained masked language modeling mlm objective use original bert model fixed masking rate propose instead dynamically schedule masking rate throughout training find linearly decreasing masking rate course pretraining improves average glue accuracy bertbase bertlarge respectively compared fixed rate baseline gain come exposure high low masking rate regime providing benefit setting result demonstrate masking rate scheduling simple way improve quality masked language model achieving x speedup pretraining bertbase well pareto improvement bertlarge
active learning iterative construction classification model targeted labeling enabling significant labeling cost saving research active learning carried transformerbased language model transformer became popular despite practical importance comparably paper investigated transformer combined active learning date attributed fact using stateoftheart query strategy transformer induces prohibitive runtime overhead effectively nullifies even outweighs desired cost saving reason revisit uncertaintybased query strategy largely outperformed particularly suited context finetuning transformer extensive evaluation connect transformer experiment previous research assessing performance five widely used text classification benchmark active learning transformer several uncertaintybased approach outperform wellknown prediction entropy query strategy thereby challenging status popular uncertainty baseline active learning text classification
introduce sparta novel neural retrieval method show great promise performance generalization interpretability opendomain question answering unlike many neural ranking method use dense vector nearest neighbor search sparta learns sparse representation efficiently implemented inverted index resulting representation enables scalable neural retrieval require expensive approximate vector search lead better performance dense counterpart validated approach opendomain question answering openqa task retrieval question answering reqa task sparta achieves new stateoftheart result across variety opendomain question answering task english chinese datasets including open squad cmrc etc analysis also confirms proposed method creates human interpretable representation allows flexible control tradeoff performance efficiency
planning goaloriented dialogue often requires simulating future dialogue interaction estimating task progress many approach thus consider training neural network perform lookahead search algorithm search monte carlo tree search mcts however training often require abundant annotated data creates challenge faced noisy annotation lowresource setting introduce gdpzero approach using openloop mcts perform goaloriented dialogue policy planning without model training gdpzero prompt large language model act policy prior value function user simulator system model tree search evaluate gdpzero goaloriented task persuasionforgood find response preferred chatgpt time rated persuasive chatgpt interactive evaluation
study aim build automatic system detection plagiarized spoken response context assessment english speaking proficiency nonnative speaker classification model trained distinguish plagiarized nonplagiarized response two different type feature texttotext content similarity measure commonly used task plagiarism detection written document speaking proficiency measure specifically designed spontaneous speech extracted using automated speech scoring system experiment first conducted large data set drawn operational english proficiency assessment across multiple year best classifier heavily imbalanced data set resulted fscore plagiarized class system validated operational response collected single administration assessment achieved recall result indicate proposed system potentially used improve validity human automated assessment nonnative spoken english
paper summarizes result test suite evaluation main focus morphology language pair english tofrom german look translation morphologically complex word deen evaluatewhether english noun phrase translated compound v phrase german furthermore investigate preservation morphological feature gender ende pronoun translation number morphosyntacticallycomplex structure deen result indicate system able interpret linguistic structure obtain relevant information also translation becomes challenging increasing complexity seen example translating word negation nonconcatenative property morecomplex case pronoun translation task
neural machine translation nmt shown great success new alternative traditional statistical machine translation model multiple language early nmt model based sequencetosequence learning encodes sequence source word vector space generates another sequence target word vector nmt model sentence simply treated sequence word without internal structure article focus role syntactic structure source sentence propose novel endtoend syntactic nmt model call treetosequence nmt model extending sequencetosequence model sourceside phrase structure proposed model attention mechanism enables decoder generate translated word softly aligning phrase well word source sentence empirically compared proposed model sequencetosequence model various setting chinesetojapanese englishtojapanese translation task experimental result suggest use syntactic structure beneficial training data set small effective using bidirectional encoder size training data set increase benefit using syntactic tree tends diminish
seqseq language generation model trained offline multiple domain sequential fashion often suffer catastrophic forgetting lifelong learning proposed handle problem however existing work experience replay elastic weighted consolidation requires incremental memory space work propose innovative framework rmrdsethat leverage recall optimization mechanism selectively memorize important parameter previous task via regularization us domain drift estimation algorithm compensate drift different domain embedding space design enable model trained current task keeping memory previous task avoid much additional data storage furthermore rmrdse combined existing lifelong learning approach experiment two seqseq language generation task paraphrase dialog response generation show thatrmrdse outperforms sota model considerable margin reduces forgetting greatly
investigation lexical change predominantly focused generic language evolution suited detecting shift particular domain hate speech study introduces task identifying change lexical semantics related hate speech within historical text present interdisciplinary approach brings together nlp history yielding pilot dataset comprising thcentury early modern english religious writing protestant reformation provide annotation semantic shift hatefulness data thereby combine task lexical semantic change detection hate speech detection framework resulting dataset facilitate evaluation applied method advancing analysis hate speech evolution
paper describes submission system alibaba wmt shared news translation task participated translation direction including english russian english turkish direction english chinese system based google transformer model architecture integrated recent feature academic research also employed technique proven effective past wmt year bpe back translation data selection model ensembling reranking industrial scale morphologicallyrich language also incorporated linguistic knowledge neural network translation task participated resulting system achieved best case sensitive bleu score direction notably english russian system outperformed second reranked system bleu score
science technology innovation sti policy evolved past decade progressing towards policy aligned sustainable development integrating social economic environmental dimension new policy environment need keep track innovation conception science research emerged argumentation mining interdisciplinary nlp field give rise required technology study present first stidriven multidisciplinary corpus scientific abstract annotated argumentative unit au sustainable development goal sdgs set united nation un au sentence conveying claim reported author original research evidence provided support also present set strong bertbased neural baseline achieving fscore claim evidence identification evaluated fold crossvalidation demonstrate effectiveness model experiment different test set showing comparable performance across various sdg policy domain dataset model publicly available research purpose
success endtoend speechtotext translation st often achieved utilizing source transcript eg pretraining automatic speech recognition asr machine translation mt task introducing additional asr mt data unfortunately transcript sometimes available since numerous unwritten language exist worldwide paper aim utilize large amount targetside monolingual data enhance st without transcript motivated remarkable success back translation mt develop back translation algorithm st btst synthesize pseudo st data monolingual target data ease challenge posed shorttolong generation onetomany mapping introduce selfsupervised discrete unit achieve back translation cascading targettounit model unittospeech model synthetic st data achieve average boost bleu mustc ende enfr ene datasets experiment show method especially effective lowresource scenario
evaluate ability large language model llm provide propbank semantic role label annotation across different realization verb transitive intransitive middle voice construction order assess metalinguistic capability llm well ability glean capability incontext learning evaluate model zeroshot setting setting given three example another verb used transitive intransitive middle voice construction finally setting given example well correct sense roleset information find zeroshot knowledge propbank annotation almost nonexistent largest model evaluated gpt achieves best performance setting given example correct roleset prompt demonstrating larger model ascertain metalinguistic capability incontext learning however even setting simpler task human propbank annotation model achieves accuracy marking numbered argument correctly ensure transparency reproducibility publicly release dataset model response
present analysis number coreference phenomenon englishcroatian human machine translation aim shed light difference way structurally different language make use discourse information provide insight discourseaware machine translation system development phenomenon automatically identified parallel data using annotation produced parser word alignment tool enabling u pinpoint pattern interest language make analysis finegrained including three corpus pertaining three different register second step create test set challenging linguistic construction use evaluate performance three mt system show smt nmt system struggle handling discourse phenomenon even though nmt tends perform somewhat better smt providing overview pattern frequently occurring actual language use well pointing weakness current mt system commonly mistranslate hope contribute effort resolving issue discourse phenomenon mt application
article present extended version polemo corpus consumer review domain medicine hotel product school current version polemo contains review sentence text sentence manually annotated sentiment scheme give total annotation obtained high value positive specific agreement text sentence polemo publicly available creative common copyright license explored recent deep learning approach recognition sentiment bidirectional long shortterm memory bilstm bidirectional encoder representation transformer bert
semisupervised learning efficient way improve performance natural language processing system work propose parassl scheme generate candidate utterance using paraphrasing method semisupervised learning order perform paraphrase generation context dialog system automatically extract paraphrase pair create paraphrase corpus using data build paraphrase generation system perform onetomany generation followed validation step select utterance good quality paraphrasebased semisupervised learning applied five functionality natural language understanding system proposed method semisupervised learning using paraphrase generation require user utterance applied prior releasing new functionality system experiment show achieve relative slot error reduction without access user utterance leveraging live traffic utterance
text image machine translation timt translates source language text image target language text attracted intensive attention recent year although endtoend timt model directly generates target translation encoded text image feature efficient architecture lack recognized source language information resulting decrease translation performance paper propose novel crossmodal crosslingual interactive model ccim incorporate source language information synchronously generating source language target language result interactive attention mechanism two language decoder extensive experimental result shown interactive decoder significantly outperforms endtoend timt model faster decoding speed smaller model size cascade model
pretrained language model plms language model pretrained largescaled corpus selfsupervised fashion plms fundamentally changed natural language processing community past year tutorial aim provide broad comprehensive introduction two perspective plms work use nlp task first part tutorial show insightful analysis plms partially explain exceptional downstream performance second part first focus emerging pretraining method enable plms perform diverse downstream task illustrates one apply plms downstream task different circumstance circumstance include finetuning plms data scarcity using plms parameter efficiency believe attendee different background would find tutorial informative useful
automated news credibility factchecking scale require accurate prediction news factuality medium bias paper introduces large sentencelevel dataset titled factnews composed sentence expertly annotated according factuality medium bias definition proposed allsides use factnews assess overall reliability news source formulating two text classification problem predicting sentencelevel factuality news reporting bias medium outlet experiment demonstrate biased sentence present higher number word compared factual sentence besides predominance emotion hence finegrained analysis subjectivity impartiality news article showed promising result predicting reliability entire medium outlet finally due severity fake news political polarization brazil lack research portuguese dataset baseline proposed brazilian portuguese
sentence embeddings encode information relating usage idiom sentence paper report set experiment combine probing methodology input masking analyse sentence idiomatic information taken form take result indicate berts idiomatic key primarily found within idiomatic expression also draw information surrounding context also bert distinguish disruption sentence caused word missing incongruity caused idiomatic usage
paper describe submission multilingual indic language translation wtask multiindicmt team name nict task involves translation indic language english viceversa objective task explore utility multilingual approach using variety indomain outofdomain parallel monolingual corpus given recent success multilingual nmt pretraining decided explore pretraining mbart model large monolingual corpus collection covering language task followed multilingual finetuning small indomain corpus firstly observed small amount pretraining followed finetuning small bilingual corpus yield large gain pretraining used furthermore multilingual finetuning lead gain translation quality significantly outperforms strong multilingual baseline rely pretraining
many natural language processing nlp task document commonly modeled bag word using term frequencyinverse document frequency tfidf vector one major shortcoming frequencybased tfidf feature vector ignores word order carry syntactic semantic relationship among word document paper proposes novel distributed vector representation document labeled dvlstm derived result adapting long shortterm memory recurrent neural network language model document dvlstm expected capture highlevel sequential information document current document representation fail evaluated document genre classification brown corpus bnc baby corpus result show dvlstm significantly outperforms tfidf vector paragraph vector pvdm case combination may improve classification performance
neural machine translation nmt known extremely challenging lowresource language lrl complex morphology work deal nmt specific lrl called manipurimeeteilon highly agglutinative language word extensive suffixation limited prefixation work study discusses impact approach mitigate issue nmt involving agglutinative lrl strictly lowresource setting research work experimented several method technique including subword tokenization tuning selfattentionbased nmt model utilization monolingual corpus iterative backtranslation embeddingbased sentence filtering back translation research work strictly low resource setting training sentence showed remarkable result bleu score manipuri english translation
wordnet play important role linguistics also natural language processing nlp paper report major result project aim construct wordnet vietnamese language propose twophase approach construction vietnamese wordnet employing available language resource ensuring vietnamese specific linguistic cultural characteristic also give statistical result analysis show characteristic wordnet
since first half th century readability formula widely employed automatically predict readability unseen text article formula text characteristic composed evaluated context large dutch english corpus describe behaviour formula text characteristic mean correlation matrix principal component analysis test methodological validity formula mean collinearity test correlation matrix principal component analysis show formula described paper strongly correspond regardless language designed furthermore collinearity test reveals shortcoming methodology used create existing readability formula lead u conclude new readability prediction method needed finally make suggestion come cleaner methodology present web application help u collect data compile new gold standard readability prediction
semantic dependency parsing sdp semantic relation form directed acyclic graph rather tree propose new iterative predicate selection ip algorithm sdp ip algorithm combine graphbased transitionbased parsing approach order handle multiple semantic head word train ip model using combination multitask learning taskspecific policy gradient training trained way ip achieves new state art semeval task datasets furthermore observe policy gradient training learns easyfirst strategy
growing interest language developed agent interacting emergentcommunication setting earlier study focused agent symbol usage rather representation visual input paper consider referential game lazaridou et al investigate representation agent develop evolving interaction find agent establish successful communication inducing visual representation almost perfectly align surprisingly capture conceptual property object depicted input image conclude care developing languagelike communication system must pay attention visual semantics agent associate symbol use
paper present datalitmt project conducted th koln university applied science project develops learning resource teaching data literacy translationspecific form professional machine translation mt literacy student translation specialised communication programme ba level discus need data literacy teaching translationspecialised communication context present three theoretical pillar project consisting professional mt literacy framework mtspecific data literacy framework competence matrix derived framework give overview learning resource developed part project
thanks success goaloriented negotiation dialogue system study negotiation dialogue gained momentum term humanhuman negotiation support dialogue system however field suffers paucity available negotiation corpus hinders development make difficult test new methodology novel negotiation setting share humanhuman negotiation dialogue dataset job interview scenario feature increased complexity term number possible solution utility function test proposed corpus using breakdown detection task humanhuman negotiation support also introduce dialogue actbased breakdown detection method focusing dialogue flow applicable various corpus result show proposed method feature comparable detection performance textbased approach existing corpus better result proposed dataset
speech emotion recognition become increasingly important recent year due potential application healthcare customer service personalization dialogue system however major issue field lack datasets adequately represent basic emotional state across various language family datasets covering slavic language rare need address research gap paper present development nemo novel corpus emotional speech polish dataset comprises hour sample recorded participation nine actor portraying six emotional state anger fear happiness sadness surprise neutral state text material used carefully selected represent phonetics polish language adequately corpus freely available term creative common license cc byncsa
task entity recognition traditionally modelled sequence labelling task however usually requires large amount finegrained data annotated token level turn expensive cumbersome obtain work aim circumvent requirement wordlevel annotated data achieve propose novel architecture entity recognition corpus containing weak binary presenceabsence label relatively easier obtain show proposed weakly supervised model trained solely multilabel classification task performs reasonably well task entity recognition despite access tokenlevel ground truth data
present iqmt framework machine translation evaluation inside qarla iqmt offer common workbench existing evaluation metric utilized combined provides measure evaluate quality set similarity metric king ii measure evaluate quality translation using set similarity metric queen iii measure evaluate reliability test set jack first release iqmt package freely available public use current version includes set metric different wellknown metric family allows user supply metric future release working design new metric able capture linguistic aspect translation beyond lexical one
visionlanguage navigation vln challenging task due large searching space environment address problem previous work proposed method finetuning large model pretrained largescale datasets however conventional finetuning method require extra humanlabeled navigation data lack selfexploration capability environment hinders generalization unseen scene improve ability fast crossdomain adaptation propose promptbased environmental selfexploration probe selfexplore environment sampling trajectory automatically generates structured instruction via largescale crossmodal pretrained model clip method fully utilizes knowledge learned clip build indomain dataset selfexploration without human labeling unlike conventional approach finetuning introduce prompt tuning achieve fast adaptation language embeddings substantially improves learning efficiency leveraging prior knowledge automatically synthesizing trajectoryinstruction pair environment without human supervision instruction prompt tuning model adapt diverse visionlanguage navigation task including vln reverie qualitative quantitative result show probe significantly improves generalization ability navigation model
increasing acknowledgement enhanced quality achievable machine translation new possibility emerged translation visavis division labour human machine translation process acceptability lower quality language exchange efficiency paper present survey four cohort postgraduate student translation university macau see perceived trainee awareness preparedness kept pace possibility found trainee across year generally lack confidence perceived awareness hesitant employing mt show definite reservation reconsidering issue quality division labour size respondent small interesting note awareness preparedness mentioned found similar across four year implication training technology fully integrated translation process order provide trainee templateframework handle diverse situation particularly require offering translation lower quality short turnaround time focus chineseenglish translation discussion may find resonance language pair keywords translator training computerassisted translation machine translation translation pedagogy chineseenglish translation
predicting difficulty domainspecific vocabulary important task towards better understanding domain enhance communication lay people expert investigate german closed noun compound focus interaction compoundbased lexical feature frequency productivity terminologybased feature contrasting domainspecific general language across word representation classifier prediction experiment complement insight classification using manually designed feature characterise termhood compound formation b compound constituent word embeddings find broad binary distinction easy v difficult generallanguage compound frequency sufficient finegrained fourclass distinction crucial include contrastive termhood feature compound constituent feature
solving math word problem challenging task requires accurate natural language understanding bridge natural language text math expression motivated intuition human generates equation given problem text paper present neural approach automatically solve math word problem operating symbol according semantic meaning text paper view process generating equation bridge semantic world symbolic world proposed neural math solver based encoderdecoder framework proposed model encoder designed understand semantics problem decoder focus tracking semantic meaning generated symbol deciding symbol generate next preliminary experiment conducted dataset mathk model significantly outperforms stateoftheart single model best nonretrievalbased model accuracy demonstrating effectiveness bridging symbolic semantic world math word problem
word meaning notoriously difficult capture synchronically diachronically paper describe creation largest resource graded contextualized diachronic word meaning annotation four different language based human semantic proximity judgment describe detail multiround incremental annotation process choice clustering algorithm group usage sens possible diachronic synchronic us dataset
one main characteristic social medium data use nonstandard language since nlp tool trained traditional text material performance drop applied social medium data one way overcome first perform text normalization work apply text normalization noisy english dutch text coming different social medium genre text message message board post tweet consider normalization task machine translation problem test two leading paradigm statistical neural machine translation smt explore added value varying background corpus training language model nmt look data augmentation since parallel datasets working limited size result reveal relying smt perform normalization beneficial use background corpus close genre normalizing regarding nmt find translation normalization coming model far perfect lowresource language like dutch adding additional training data work better artificially augmenting data
paper report systematic approach deriving universal dependency lfg structure conversion start stepwise transformation cstructure combining partofspeech po information embedding path determine true head dependency structure paper discusses several issue faced existing algorithm applied wolof present strategy used account issue experimental evaluation indicated approach able generate correct output case leading substantial improvement conversion accuracy compared previous model
recent time detection hatespeech offensive abusive language online medium become important topic nlp research due exponential growth social medium propagation message well impact misogyny detection even though play important part hatespeech detection received attention paper describe classification system submitted semeval task mami multimedia automatic misogyny identification shared task aimed identify misogynous content multimodal setting analysing meme image together textual caption end propose two model based pretrained uniter model one enhanced image sentiment classifier whereas second leverage vocabulary graph convolutional network vgcn additionally explore ensemble using aforementioned model best model reach fscore subtask subtask b positioning team upper third leaderboard release code experiment model github
finegrained entity typing fget task assigning finegrained type hierarchy entity mention text taxonomy type evolves continuously desirable entity typing system able recognize novel type without additional training work proposes zeroshot entity typing approach utilizes type description available wikipedia build distributed semantic representation type training system learns align entity mention corresponding type representation known type test time new type incorporated system given wikipedia description evaluate approach figer public benchmark entity tying dataset existing test set figer cover small portion finegrained type create new test set manually annotating portion noisy training data experiment demonstrate effectiveness proposed method recognizing novel type present training data
social medium meant entertainment provides platform sharing information news fact event digital age activist numerous user seen vocal regarding human right violation social medium however voice often reach targeted audience concerned human right organization work aimed detecting factual post social medium violation human right part world end product research seen useful asset different peacekeeping organization could exploit monitor realtime circumstance incident relation violation human right chose one popular microblogging website twitter investigation used supervised learning algorithm order build human right violation identification hrvi model able identify tweet relation incident human right violation manually create data set one contribution research found classification model trained goldstandard dataset performed excellently classifying factual tweet human right violation achieving accuracy upto holdout test set
block diagram popular representing workflow process model understanding block diagram generating summary extremely useful document summarization also assist people inferring key insight block diagram without requiring lot perceptual cognitive effort paper propose novel task converting block diagram image text presenting framework called blosum framework extract contextual meaning image form triplet help language model summary generation also introduce new dataset complex computerized block diagram explain dataset preparation process later analyze additionally showcase generalization model test method publicly available handwritten block diagram datasets evaluation different metric demonstrates effectiveness approach outperforms method technique
opinion mining natural language processing technique extract subjective information natural language text estimate opinion query large data collection opinion retrieval system retrieves subjective relevant information query useful present opinion retrieval system retrieves subjective queryrelevant tweet twitter useful source obtaining realtime opinion system outperforms previous opinion retrieval system provides subjective information twitter author hashtags describe subjective tendency
sequencetosequence stateoftheart system dialogue state tracking dst use full dialogue history input represent current state list slot generate entire state scratch dialogue turn approach inefficient especially number slot large conversation long propose diable new task formalisation simplifies design implementation efficient dst system allows one easily plug play large language model represent dialogue state table formalise dst table manipulation task turn system update previous state generating table operation based dialogue context extensive experimentation multiwoz datasets demonstrates diable outperforms strong efficient dst baseline ii x time efficient current stateoftheart method retaining competitive joint goal accuracy iii robust noisy data annotation due table operation approach
paper integrate spanrelated information pretrained encoder entity relation extraction task instead using generalpurpose sentence encoder eg existing universal pretrained model introduce span encoder span pair encoder pretraining network make easier import intraspan interspan information pretrained model learn encoders devise three customized pretraining objective different perspective target token span span pair particular span encoder trained recover random shuffling token span span pair encoder trained predict positive pair sentence negative pair different sentence using contrastive loss experimental result show proposed pretraining method outperforms distantly supervised pretraining achieves promising performance two entity relation extraction benchmark datasets ace scierc
event extraction aim identify event trigger predefined event type argument specific role challenging task nlp traditional approach formulate task classification problem event type argument role taken golden label approach fail model rich interaction among event type argument different role generalize new type role work proposes new paradigm formulates event extraction multiturn question answering approach mqaee cast extraction task series reading comprehension problem extract trigger argument successively given sentence history answer embedding strategy adopted model question answering history multiturn process new formulation mqaee make full use dependency among argument event type generalizes well new type new argument role empirical result ace show mqaee outperforms current stateoftheart pushing final f argument extraction also good generalization ability achieving competitive performance new event type even trained sample
training process scientific ner model commonly performed two step pretraining language model selfsupervised task huge data ii finetune training small labelled data success strategy depends relevance data domain task however gap found practice target domain specific small propose novel framework introduce prefine tuning step pretraining finetuning construct corpus selecting sentence unlabeled document relevant labelled training data instead predicting token random span prefine tuning task predict token entity candidate identified text mining method prefine tuning automatic lightweight corpus size much smaller pretraining data achieve better performance experiment seven benchmark demonstrate effectiveness
contrastive languageimage pretraining clip demonstrated great zeroshot performance matching image text however still challenging adapt visionlanguage pretrained model like clip compositional image text matching challenging image text matching task requiring model understanding compositional word concept visual component towards better compositional generalization zeroshot image text matching paper study problem causal perspective erroneous semantics individual entity essentially confounders cause matching failure therefore propose novel trainingfree compositional clip model comclip comclip disentangles input image subject object action subimages composes clip vision encoder text encoder perform evolving matching compositional text embedding subimage embeddings way comclip mitigate spurious correlation introduced pretrained clip model dynamically evaluate importance component experiment four compositional imagetext matching datasets winoground vlchecklist svo comvg two general imagetext retrieval datasets flickk mscoco demonstrate effectiveness plugandplay method boost zeroshot inference ability clip slip blip even without training finetuning code found httpsgithubcomericailabcomclip
research statistical machine translation smt largely driven formal translation task translating informal text much challenging paper focus smt informal genre dialogue rarely addressed date concretely investigate effect dialogue act speaker gender text register smt quality translating fictional dialogue first create release corpus multilingual movie dialogue annotated four dialoguespecific aspect measuring translation performance variable find bleu fluctuation category often significantly larger randomly expected following finding hypothesize show smt fictional dialogue benefit adaptation towards dialogue act register finally find male speaker harder translate use vulgar language female speaker vulgarity often preserved translation
poststroke speech language deficit aphasia significantly impact patient quality life many mild symptom remain undiagnosed majority receive intensive dos therapy recommended due healthcare cost andor inadequate service automatic speech recognition asr may help overcome difficulty improving diagnostic rate providing feedback tailored therapy however performance often unsatisfactory due high variability speech error scarcity training datasets study assessed performance whisper recently released endtoend model patient poststroke aphasia pwa tuned hyperparameters achieve lowest word error rate wer aphasic speech wer significantly higher pwa compared agematched control v p demonstrated worse wer related severe aphasia measured expressive overt naming spontaneous speech production receptive written spoken comprehension language assessment stroke lesion size affect performance whisper linear mixed model accounting demographic factor therapy duration time since stroke confirmed worse whisper performance left hemispheric frontal lesionswe discus implication finding future asr improved pwa
neural topic model ntm use variational autoencoder framework producing k topic limited size encoders output topic interpreted selection top activated word via weight reconstructed vector decoder directly connected neuron paper present modelfree twostage process reinterpret ntm derive insight state trained model firstly building original information trained ntm generate pool potential candidate composite topic exploiting possible cooccurrences within original set topic decouples strict interpretation topic original ntm followed combinatorial formulation select final set composite topic evaluate coherence diversity large external corpus lastly employ user study derive insight reinterpretation process
mixedinitiative system one allows interactivity system user system reasoning present observation task translating web page user suggest interactive approach problem may desirable aim interact user requesting translation challenge determine circumstance user able take initiative direct processing system able take initiative solicit input user fact envision need support interactive translation web page world wide web becomes accessible people varying need ability throughout world
automatic evaluation metric indispensable evaluating generated text date metric focused almost exclusively content selection aspect system output ignoring linguistic quality aspect altogether bridge gap proposing gruen evaluating grammaticality nonredundancy focus structure coherence generated text gruen utilizes bertbased model class syntactic semantic contextual feature examine system output unlike existing evaluation metric require human reference input gruen referenceless requires system output besides advantage unsupervised deterministic adaptable various task experiment seven datasets four language generation task show proposed metric correlate highly human judgment
introduce first expert annotated corpus facebook comment hausa hate speech detection corpus titled hausahate comprises comment extracted western african facebook page manually annotated three hausa native speaker also nlp expert corpus annotated using two different layer first labeled comment according binary classification offensive versus nonoffensive offensive comment also labeled according hate speech target race gender none lastly baseline model using finetuned llm hausa hate speech detection presented highlighting challenge hate speech detection task indigenous language africa well future advance
rise usage social medium placed central position news dissemination consumption greatly increase potential proliferation rumour misinformation effort mitigate spread rumour tackle related task identifying stance support deny query comment social medium post unlike previous work impose inductive bias capture platform specific user behavior bias coupled social medium finetuning bert allow better language understanding thus yielding f score semeval task rumour stance detection
news medium often strive minimize explicit moral language news article yet article dense moral value expressed reported event however value reflected intricate dynamic among participating entity moral event far challenging nlp system detect including llm study phenomenon annotate new dataset moral event consisting structured event annotation news article diverse u medium across political spectrum propose moka moral event extraction framework moral knowledge augmentation leverage knowledge derived moral word moral scenario produce structural representation moralitybearing event experiment show moka outperforms competitive baseline across three moral event understanding task analysis show even ostensibly nonpartisan medium engage selective reporting moral event
propose morphologically informed model named entity recognition based lstmcrf architecture combine word embeddings bilstm character embeddings partofspeech po tag morphological information previous work focused learning raw word input using word character embeddings show morphologically rich language bulgarian access po information contributes performance gain detailed morphological information thus show named entity recognition need coarsegrained po tag time benefit simultaneously using po information different granularity evaluation result standard dataset show sizeable improvement stateoftheart bulgarian ner
expressing opinion emotion social medium becomes frequent activity daily life people express opinion various target via social medium also interested know opinion target automatically identifying sentiment text also strength opinion enormous help people organization willing use information goal paper present rulebased approach german sentiment analysis proposed model provides finegrained annotation german text represents sentiment strength input text using two score positive negative score show text contains positive negative opinion well strength positive negative opinion aim german opinion dictionary word prepared compared opinion dictionary german also introduce new dataset german sentiment analysis dataset contains short text social medium german celebrity annotated three annotator result show proposed unsupervised model outperforms supervised machine learning technique moreover new dictionary performs better german opinion dictionary
one core component modern spoken dialogue system belief tracker estimate user goal every step dialogue however current approach difficulty scaling larger complex dialogue domain due dependency either spoken language understanding model require large amount annotated training data b handcrafted lexicon capturing linguistic variation user language propose novel neural belief tracking nbt framework overcomes problem building recent advance representation learning nbt model reason pretrained word vector learning compose distributed representation user utterance dialogue context evaluation two datasets show approach surpasses past limitation matching performance stateoftheart model rely handcrafted semantic lexicon outperforming lexicon provided
research project incorporating spoken data require either selection existing speech corpus plan record new data case recording need transcribed make accessible analysis underestimating effort transcribing risky automatic speech recognition asr hold promise considerably reduce transcription effort however study far attempted evaluate potential present paper compare effort manual transcription v correction asroutput took recording corpus varying setting interview colloquial talk dialectal historic compared two method creating orthographic transcript transcribing scratch v correcting automatically created transcript ii evaluated influence corpus characteristic correcting efficiency result suggest selected data transcription convention transcribing correcting still take equally long time realtime average complex primary data time spent correction despite impressive latest development speech technology real help conversation analyst dialectologists asr system seem require even improvement need sufficient appropriate data training system
present legoeval opensource toolkit enables researcher easily evaluate dialogue system line code using online crowdsource platform amazon mechanical turk compared existing toolkits legoeval feature flexible task design providing python api map commonly used reactjs interface component researcher personalize evaluation procedure easily builtin page playing lego block thus legoeval provides fast consistent method reproducing human evaluation result besides flexible task design legoeval also offer easy api review collected data
investigate distributional property present tagset examining different mapping various current partofspeech tagsets looking english german italian corpus given importance distributional information present simple model evaluating tagset mapping capture distribution specifically utilizing notion frame capture local context addition accuracy metric capturing internal quality tagset introduce way evaluate external quality tagset mapping ensure mapping retains linguistically important information original tagset although mapping evaluate motivated linguistic concern also explore automatic bottomup way define mapping illustrate better distributional mapping possible comparing initial evaluation po tagging result find distributional tagsets sometimes result worse accuracy underscring need carefully define property tagset
assessing company sustainable development go beyond financial metric inclusion environmental social governance esg factor becoming increasingly vital mlesg shared task series seek pioneer discussion newsdriven esg rating drawing inspiration msci esg rating guideline second edition mlesg emphasizes impact type identification offering datasets four language chinese english french japanese team registered participated official evaluation paper present comprehensive overview mlesg detailing dataset specific summarizing performance outcome participating team
one major research interest political science always study political discourse parliamentary debate literature review offer overview prominent research method used political science studying political discourse identify commonality difference political science corpusdriven approach show parliamentary corpus corpusbased approach could successfully integrated political science research
generative feature matching network gfmn approach training stateoftheart implicit generative model image performing moment matching feature pretrained neural network paper present new gfmn formulation effective sequential data experimental result show effectiveness proposed method seqgfmn three distinct generation task english unconditional text generation classconditional text generation unsupervised text style transfer seqgfmn stable train outperforms various adversarial approach text generation text style transfer
present elq fast endtoend entity linking model question us biencoder jointly perform mention detection linking one pas evaluated webqsp graphquestions extended annotation cover multiple entity per question elq outperforms previous state art large margin f respectively fast inference time exampless single cpu elq useful downstream question answering system proofofconcept experiment demonstrate using elq significantly improves downstream qa performance graphretriever
longrunning goal clinical nlp community extraction important variable trapped clinical note however roadblock included dataset shift general domain lack public clinical corpus annotation work show large language model instructgpt ouyang et al perform well zero fewshot information extraction clinical text despite trained specifically clinical domain whereas text classification generation performance already studied extensively model additionally demonstrate leverage tackle diverse set nlp task require structured output including span identification tokenlevel sequence classification relation extraction due dearth available data evaluate system introduce new datasets benchmarking fewshot clinical information extraction based manual reannotation casi dataset moon et al new task clinical extraction task studied gpt system significantly outperform existing zero fewshot baseline
queryfocused summary foreignlanguage retrieved document help user understand whether document actually relevant query term standard approach problem first translate source document perform extractive summarization find relevant snippet however crosslingual setting query term necessarily appear translation relevant document work show constrained machine translation constrained postediting improve human relevance judgment including query term summary translation appears source document also present several strategy selecting certain document regeneration yield improvement
era large amount data generated daily various field biomedical field among others linguistic resource exploited various task natural language processing moreover increasing number biomedical document available language english able extract information natural language free text resource method tool needed variety language paper present creation monero corpus gold standard biomedical corpus romanian annotated part speech tag named entity monero comprises morphologically annotated token entity annotation belonging four entity semantic group corresponding umls semantic group
deep reinforcement learning drl successfully applied dialogue policy taskoriented dialogue system however one challenge existing drlbased dialogue policy method unstructured stateaction representation without ability learn relationship dialogue state action alleviate problem propose graphstructured dialogue policy framework taskoriented dialogue system specifically use unsupervised approach construct two different bipartite graph generate userrelated knowledgerelated subgraphs based matching dialogue substates bipartite graph node variant graph convolutional network employed encode dialogue subgraphs use bidirectional gated cycle unit bgru selfattention mechanism obtain highlevel historical state representation employ neural network highlevel current state representation two state representation joined learn action value dialogue policy experiment implemented different drl algorithm demonstrate proposed framework significantly improves effectiveness stability dialogue policy
various scenario conference oral presentation company manager talk politician speech individual often contemplate potential question may arise presentation common practice prompt research question addressed study extent model generate multiple question based given presentation transcript investigate conduct pilot exploration using earnings conference call transcript serve regular meeting professional investor company manager experiment different task setting method evaluate result various perspective finding highlight incorporating key point retrieval technique enhances accuracy diversity generated question
automatic evaluation metric crucial development generative system recent year pretrained language model plm based metric bertscore commonly adopted various generation task however demonstrated plms encode range stereotypical societal bias leading concern fairness plms metric end work present first systematic study social bias plmbased metric demonstrate popular plmbased metric exhibit significantly higher social bias traditional metric sensitive attribute namely race gender religion physical appearance age socioeconomic status indepth analysis suggests choosing paradigm matching regression generation metric greater impact fairness choosing plms addition develop debiasing adapter injected plm layer mitigating bias plmbased metric retaining high performance evaluating text generation
fewshot text classification aim classify input whose label example previous study overlooked semantic relevance label representation therefore easily confused label relevant address problem propose method generates distinct label representation embed information specific label method applicable conventional fewshot classification model experimental result show method significantly improved performance fewshot text classification across model datasets
number paper recently argued favor using artificially generated language investigate inductive bias linguistic model develop model lowresource language underrepresented typology promise artificial language come caveat artificial language sufficiently reflective natural language using proxy may lead inaccurate conclusion paper take step towards increasing realism artificial language introducing variant indexed grammar draw weight hierarchical pitmanyor process show framework generates language emulate statistic natural language corpus better current approach directly formulating weighted contextfree grammar
paper introduces easytree dynamic graphical tool dependency tree annotation built javascript using popular data visualization library easytree allows annotator construct label tree entirely manipulating graphic export corresponding data json format human user thus able annotate intuitive way without compromising machinecompatibility output easytree number feature assist annotator including colorcoded partofspeech indicator optional translation display also customized suit wide range project partofspeech category edge label many setting edited within gui system also utilizes utf encoding properly handle lefttoright righttoleft script providing userfriendly annotation tool aim reduce time spent transforming data learning use software improve user experience annotator make annotation approachable even inexperienced user unlike existing solution easytree built entirely standard web technologiesjavascript html cssmaking ideal webbased annotation effort including crowdsourcing effort
often assumed topic model benefit use manually curated stopword list constructing list timeconsuming often subject user judgment kind word important model application although stopword removal clearly affect word type appear probable term topic argue improvement superficial topic inference benefit little practice removing stopwords beyond frequent term removing corpusspecific stopwords model inference transparent produce similar result removing word prior inference
finetuning large pretrained language model various downstream task whole parameter prohibitively expensive hence parameterefficient finetuning attracted attention optimizes taskspecific parameter frozen pretrained model work focus prefix tuning optimizes continuous prefix vector ie pseudo token inserted transformer layer based observation learned syntax semantics representation varies lot different layer argue adaptive prefix tailored layer fixed one enabling finetuning effective efficient thus propose adaptive prefix tuning apt adjust prefix term finegrained token level coarsegrained layer level gate mechanism experiment superglue ner datasets show effectiveness apt addition taking gate probing validate efficiency effectiveness variable prefix
paper aim investigate coordination interlocutor behavior different emotional segment conversational coordination interlocutor tendency speaker predict adjust accordingly ongoing conversation order find coordination investigated lexical similarity speaker emotional segment correlation interlocutor using psycholinguistic feature linguistic style psychological process personal concern among others relation interlocutor turntaking behavior competitiveness study degree coordination different emotional segment conducted experiment using real dyadic conversation collected call center agent emotional state include empathy customer emotional state include anger frustration finding suggest coordination occurs interlocutor inside anger segment little coordination observed agent empathic even though increase amount noncompetitive overlap observed found significant difference anger frustration segment term turntaking behavior however length pause significantly decrease preceding segment anger increase preceding segment frustration
neural machine translation model rely pair parallel sentence assuming syntactic information automatically learned attention mechanism work investigate different approach incorporate syntactic knowledge transformer model also propose novel parameterfree dependencyaware selfattention mechanism improves translation quality especially long sentence lowresource scenario show efficacy approach wmt englishgerman englishturkish wat englishjapanese translation task
largescale grammarbased parsing system nowadays increasingly rely independently developed specialized component preprocessing input however different tool make conflicting assumption basic property tokenization make linguistic annotation gathered preprocessing available deep parsing hybrid nlp system need establish coherent mapping two universe basic assumption token best described attribute value matrix avms may arbitrarily complex propose powerful resourcesensitive rewrite formalism chart mapping allows u mediate token description delivered shallow preprocessing component input expected grammar furthermore propose novel way unknown word treatment generic lexical entry instantiated licensed particular token avm chart mapping used give grammar writer full control item eg native v generic lexical item enter syntactic parsing discus several us original idea report early experience new machinery
deep nlp model shown brittle input perturbation recent work shown data augmentation using counterfactuals ie minimally perturbed input help ameliorate weakness focus task creating counterfactuals question answering present unique challenge related world knowledge semantic diversity answerability address challenge develop retrievegeneratefilterrgf technique create counterfactual evaluation training data minimal human supervision using opendomain qa framework question generation model trained original task data create counterfactuals fluent semantically diverse automatically labeled data augmentation rgf counterfactuals improves performance outofdomain challenging evaluation set existing method reading comprehension opendomain qa setting moreover find rgf data lead significant improvement model robustness local perturbation
adversarial attack alter nlp model prediction perturbing testtime input however much less understood whether prediction manipulated small concealed change training data work develop new data poisoning attack allows adversary control model prediction whenever desired trigger phrase present input instance insert poison example sentiment model training set cause model frequently predict positive whenever input contains james bond crucially craft poison example using gradientbased procedure mention trigger phrase also apply poison attack language modeling apple iphone trigger negative generation machine translation iced coffee mistranslated hot coffee conclude proposing three defense mitigate attack cost prediction accuracy extra human annotation
paper describes system submitted semeval task capturing discriminative attribute system built upon simple idea measuring attribute word similarity two semantically similar word based extended word embedding method wordnet instead computing similarity attribute semantically similar word using standard word embeddings propose novel method combine word context embeddings better measure similarity model simple effective achieves average f score test set
despite evergrowing number word representation model introduced large number language lack standardized technique provide insight captured model insight would help community get estimate downstream task performance well design informed neural architecture avoiding extensive experimentation requires substantial computational resource researcher access recent development nlp use simple classification task also called probing task test single linguistic feature partofspeech existing study mostly focus exploring linguistic information encoded continuous representation english text however typological perspective morphologically poor english rather outlier information encoded word order function word english often stored subword morphological level language address introduce typelevel probing task case marking possession word length morphological tag count pseudoword identification language present reusable methodology creation evaluation test multilingual setting challenging lack resource lower quality tool difference among language present experiment several diverse multilingual word embedding model relate probing task performance diverse set language range five classic nlp task postagging dependency parsing semantic role labeling named entity recognition natural language inference find number probing test significantly high positive correlation downstream task especially morphologically rich language show test used explore word embeddings blackbox neural model linguistic cue multilingual setting release probing data set evaluation suite linspector urlhttpsgithubcomukplablinspector
paper give guideline create update propbank frameset file using dedicated editor cornerstone propbank corpus argument verb predicate annotated semantic role relation predicate propbank annotation also requires choice sense id predicate thus predicate propbank exists corresponding frameset file showing expected predicate argument structure sense related predicate since propbank annotation based predicate argument structure defined frameset file important keep file consistent simple read well easy update frameset file written xml difficult edit using simple text editor therefore helpful develop userfriendly editor cornerstone specifically customized create edit frameset file cornerstone run platform independently light enough run x application support multiple language arabic chinese english hindi korean
numerous type social bias identified pretrained language model plms various intrinsic bias evaluation measure proposed quantifying social bias prior work relied human annotated example compare existing intrinsic bias evaluation measure however approach easily adaptable different language amenable large scale evaluation due cost difficulty recruiting human annotator overcome limitation propose method compare intrinsic gender bias evaluation measure without relying humanannotated example specifically create multiple biascontrolled version plms using varying amount male v female gendered sentence mined automatically unannotated corpus using genderrelated word list next biascontrolled plm evaluated using intrinsic bias evaluation measure rank correlation computed bias score gender proportion used finetune plms computed experiment multiple corpus plms repeatedly show correlation reported proposed method require human annotated example comparable computed using human annotated example prior work
paper describes uuhardmeier system submitted discomt shared task crosslingual pronoun prediction system ensemble convolutional neural network combined sourceaware ngram language model
stateoftheart keyphrase generation method generally depend large annotated datasets limiting performance domain limited annotated data overcome challenge design dataoriented approach first identifies salient information using retrievalbased corpuslevel statistic learns taskspecific intermediate representation based pretrained language model using largescale unlabeled document introduce salient span recovery salient span prediction denoising training objective condense intraarticle interarticle knowledge essential keyphrase generation experiment multiple keyphrase generation benchmark show effectiveness proposed approach facilitating lowresource keyphrase generation zeroshot domain adaptation method especially benefit generation absent keyphrases approaching performance model trained large training set
readability metric standard flesch kincaid grade level fkgl common european framework reference language cefr exist guide teacher educator properly assess complexity educational material administering classroom use study select diverse set open closedsource instructiontuned language model investigate performance writing story completion simplifying narrativestasks teacher performusing standardguided prompt controlling text readability extensive finding provide empirical proof globally recognized model like chatgpt may considered less effective may require refined prompt generative task compared opensourced model bloomz flantwhich shown promising result
human knowledge collectively encoded roughly language spoken around world distributed equally across language hence informationseeking question answering qa system adequately serve speaker language need operate crosslingually work investigate capability multilingually pretrained language model crosslingual qa find explicitly aligning representation across language posthoc finetuning step generally lead improved performance additionally investigate effect data size well language choice finetuning step also releasing dataset evaluating crosslingual qa system
current language model achieve low perplexity resulting generation still suffer toxic response repetitiveness contradiction standard language modeling setup fails address issue paper introduce new architecture director consists unified generatorclassifier language modeling classification head output token training conducted jointly using standard language modeling data data labeled desirable undesirable sequence experiment several setting show model competitive training decoding speed compared standard language model yielding superior result avoiding undesirable behavior maintaining generation quality also outperforms existing model guiding approach term accuracy efficiency code made publicly available
continual language learning cll multilingual translation inevitable new language required translated due lack unified generalized benchmark evaluation existing method greatly influenced experimental design usually big gap industrial demand work propose first continual language learning evaluation benchmark clle multilingual translation clle consists chinesecentric corpus cn two cll task closedistance language continual learning task language family continual learning task designed real disparate demand different existing translation benchmark clle considers several restriction cll including domain distribution alignment content overlap language diversity balance corpus furthermore propose novel framework cometa based constrained optimization metalearning alleviate catastrophic forgetting dependency history training data using metamodel retain important parameter old language experiment prove clle challenging cll benchmark proposed method effective compared strong baseline due construction corpus task designing evaluation method independent centric language also construct release englishcentric corpus en facilitate academic research
contrastive learning extensively studied sentence embedding learning assumes embeddings different view sentence closer constraint brought assumption weak good sentence representation also able reconstruct original sentence fragment therefore paper proposes informationaggregated contrastive learning framework learning unsupervised sentence embeddings termed infocseinfocse force representation cl position aggregate denser sentence information introducing additional masked language model task welldesigned network evaluate proposed infocse several benchmark datasets wrt semantic text similarity sts task experimental result show infocse outperforms simcse average spearman correlation bertbase bertlarge achieving stateoftheart result among unsupervised sentence representation learning method
developing online questionanswering system medical domain natural language inference nli model play central role question matching intention detection however model best datasets manually selecting tuning model timeconsuming thus experiment automatically optimizing model architecture task hand via neural architecture search na first formulate novel architecture search space based previous na literature supporting crosssentence attention crossattn modeling second propose modify enas method accelerate stabilize search result conduct extensive experiment two medical nli task result show system easily outperform classical baseline model compare different na method demonstrate approach provides best result
explore idea compressing prompt used condition language model show compressed prompt retain substantive amount information original prompt severely compressed prompt finegrained information lost abstract information general sentiment retained surprisingly parameter useful context decodetime algorithm controllability toxicity reduction find complex prompt effectively compressed single token guide generation also show compressed prompt largely compositional constructed used control independent aspect generated text
sustaining coherent engaging narrative requires dialogue storytelling agent understandhow persona speaker listener ground narrative specifically agent must infer persona listener produce statement cater interest must also learn maintain consistent speaker persona throughout narrative counterpart feel involved realistic conversation story however persona diverse complex entail large quantity rich interconnected world knowledge challenging robustly represent general narrative system eg singer good singing may attended conservatoire work construct new largescale persona commonsense knowledge graph peacok containing textasciitildek humanvalidated persona fact knowledge graph schematizes five dimension persona knowledge identified previous study human interactive behaviour distils fact schema existing commonsense knowledge graph largescale pretrained language model analysis indicates peacok contains rich precise world persona inference help downstream system generate consistent engaging narrative
model large number parameter prone overfitting often fail capture underlying input distribution introduce emix data augmentation method us interpolation word embeddings hidden layer representation construct virtual example show emix show significant improvement previously used interpolation based regularizers data augmentation technique also demonstrate proposed method robust sparsification highlight merit proposed methodology performing thorough quantitative qualitative assessment
bias research nlp seek analyse model social bias thus helping nlp practitioner uncover measure mitigate social harm analyse body work us prompt template assess bias language model draw measurement modelling framework create taxonomy attribute capture bias test aim measure measurement carried applying taxonomy bias test illustrate qualitatively quantitatively core aspect bias test conceptualisation operationalisations frequently unstated ambiguous carry implicit assumption mismatched analysis illuminates scope possible bias type field able measure reveals type yet underresearched offer guidance enable community explore wider section possible bias space better close gap desired outcome experimental design bias evaluating language model broadly
recent work compositional distributional semantics showed bialgebras model generalised quantifier natural language technique requires working vector space power set base therefore computationally costly possible overcome computational hurdle working fuzzy generalised quantifier paper show compositional notion semantics natural language guided grammar extends binary many valued setting instantiate fuzzy computation import vector representation word predicate learnt large scale compositional distributional semantics interpret fuzzy set analyse performance toy inference dataset
continual relation extraction aim learn constantly emerging relation avoiding forgetting learned relation existing work store small number typical sample retrain model alleviating forgetting however repeatedly replaying sample may cause overfitting problem conduct empirical study existing work observe performance severely affected analogous relation address issue propose novel continual extraction model analogous relation specifically design memoryinsensitive relation prototype memory augmentation overcome overfitting problem also introduce integrated training focal knowledge distillation enhance performance analogous relation experimental result show superiority model demonstrate effectiveness distinguishing analogous relation overcoming overfitting
increasing number communication platform offer variety way connecting two interlocutor resurgence chatbased dialog system system typically known textitchatbots successfully applied range consumer enterprise application key technology chatbots robust natural language understanding nlu significantly influence impact efficacy conversation ultimately userexperience nlu far perfect paper illustrates role textitunderspecification impact successful dialog completion
paper describes builder entry named strawman sentencelevel sentiment analysis task build break shared task first workshop building linguistically generalizable nlp system goal builder provide automated sentiment analyzer would serve target breaker whose goal find pair minimallydiffering sentence break analyzer
recognizing metaphor identifying sourcetarget mapping important task metaphorical text pose big challenge machine reading address problem automatically acquire metaphor knowledge base isa knowledge base billion web page using knowledge base develop inference mechanism recognize explain metaphor text knowledge first purely datadriven approach probabilistic metaphor acquisition recognition explanation result show significantly outperforms stateoftheart method recognizing explaining metaphor
fillintheblank exercise student presented carrier sentence one word hidden multiplechoice list includes correct answer several inappropriate option called distractors propose automatically generate distractors using roundtrip neural machine translation carrier sentence translated english another pivot language back distractors produced aligning original sentence roundtrip translation show using hundred translation given sentence allows u generate rich set challenging distractors using multiple pivot language produce diverse set candidate distractors evaluated real corpus cloze exercise checked manually validity demonstrate proposed method significantly outperforms two strong baseline
wavvec stateoftheart speech recognition model map speech audio waveform latent representation largest version wavvec contains million parameter hence inference latency wavvec bottleneck production leading high cost significant environmental footprint improve wavvecs applicability production setting explore multiple model compression method borrowed domain large language model using teacherstudent approach distilled knowledge original wavvec model student model time faster time smaller original model importantly student model time energy efficient original model term co emission increase performance accomplished degradation word error rate wer quantized model time smaller original model degradation wer best knowledge first work compress wavvec
aim distributional semantics model similarity meaning word via word occur thereby relies distributional hypothesis implying similar word similar context deducing meaning distribution word interesting done automatically large amount freely available raw text convenience current stateoftheartmodels distributional semantics operate raw text although successful attempt integrate kind ofeg syntacticinformation improve distributional semantic model contrast less attention paid semantic information research community one reason extraction semantic information raw text complex elaborate matter great part yet satisfyingly solved recently however successful attempt integrate certain kind semantic information ie coreference two basically different kind information contributed coreference respect distribution word identified focus one examine general potential improve distributional semantic model well certain specific hypothesis
despite ubiquity word embeddings trained skipgram negative sampling sgns remain poorly understood find vector position simply determined semantic similarity rather occupy narrow cone diametrically opposed context vector show geometric concentration depends ratio positive negative example neither theoretically empirically inherent related embedding algorithm
transformer brought remarkable improvement performance neural machine translation nmt system could surprisingly vulnerable noise work try investigate noise break transformer exist solution deal issue large body work nmt literature analyzing behavior conventional model problem noise transformer relatively understudied context motivated introduce novel datadriven technique called target augmented finetuning taft incorporate noise training idea comparable wellknown finetuning strategy moreover propose two novel extension original transformer controlled denoising cd dualchannel decoding dcd modify neural architecture well training process handle noise one important characteristic technique impact training phase impose overhead inference time evaluated technique translate englishgerman pair direction observed model higher tolerance noise specifically perform deterioration entire test word infected noise
applying neural model injected indomain user product information learn review representation unseen anonymous user incurs obvious obstacle contentbased recommender system generalization indomain classifier existing model train extra plaintext model unseen domain without incorporating historical user product information schema make unseen anonymous user dissociate recommender system simultaneously learn review representation existing unseen user study proposed switch knowledge distillation domain generalization generalizationswitch gswitch model initially applied inject user product information flexibly encoding domaininvariant domainspecific feature turning status model introduced switch knowledge distillation learn robust review representation performed well either existing anonymous unseen user empirical experiment conducted imdb yelp yelp masking user test data unseen anonymous user comparative result indicate proposed method enhances generalization capability several existing baseline model reproducibility code paper available urlhttpsgithubcomyoyoyundgrrr
bridging research humancomputer interaction natural language processing developing quickly year however still lack formative guideline understand humanmachine interaction nlp loop researcher crossing two field talk human may imply user labor regarding human user human control machine used tool achieve human goal considering human laborer machine control human used resource achieve machine goal systematic literature review thematic analysis present interaction framework understanding humanmachine relationship nlp framework propose four type humanmachine interaction humanteacher machinelearner machineleading humanleading humanmachine collaborator analysis show type interaction fixed change across task relationship human machine develops also discus implication framework future nlp humanmachine relationship
riveter provides complete easytouse pipeline analyzing verb connotation associated entity text corpus prepopulate package connotation frame sentiment power agency demonstrated usefulness capturing social phenomenon gender bias broad range corpus decade lexical framework foundational tool computational social science digital humanity natural language processing facilitating multifaceted analysis text corpus working verbcentric lexica specifically requires natural language processing skill reducing accessibility researcher organizing language processing pipeline providing complete lexicon score visualization entity corpus providing functionality user target specific research question riveter greatly improves accessibility verb lexica facilitate broad range future research
aim paper argue coherent universal dependency approach core v noncore distinction demonstrate inconsistency current version ud respect mostly resulting preservation argumentadjunct dichotomy despite declared avoidance distinction propose relatively conservative modification ud free problem
present quest open source framework translation quality estimation quest provides wide range feature extractor source translation text external resource tool go simple languageindependent feature advanced linguistically motivated feature include feature rely information translation system feature oblivious way translation produced addition provides wrapper wellknown machine learning toolkit scikitlearn including technique feature selection model building well parameter optimisation also present web interface functionality nonexpert user using interface quality prediction internal feature framework obtained without installation toolkit building prediction model interface also provides ranking method multiple translation given source text according predicted quality
paper present university alberta system result sigmorphon task multilingual graphemetophoneme conversion following previous sigmorphon shared task define lowresource setting training instance experiment three transduction approach standard lowresource setting well related task phonemetographeme conversion propose method synthesizing training data using combination diverse model
paper update progress made principle project year action funded european commission connecting europe facility cef programme principle focus collecting highquality language resource croatian icelandic irish norwegian identified lowresource language especially building effective machine translation mt system report initial achievement project ongoing activity aimed promoting uptake neural mt lowresource language project
making informed choice pretrained language model lm critical performance yet environmentally costly widely underexplored field computer vision begun tackle encoder ranking promising foray natural language processing however lack coverage linguistic task structured prediction propose probing rank lm specifically parsing dependency given language measuring degree labeled tree recoverable lm contextualized embeddings across typologically architecturally diverse lmlanguage pair probing approach predicts best lm choice time using order magnitude less compute training full parser within study identify analyze one recently proposed decoupled lmrembertand find strikingly contains less inherent dependency information often yield best parser full finetuning without outlier approach identifies best lm case
position paper yrrsds
contrastive learning achieved impressive success generation task militate exposure bias problem discriminatively exploit different quality reference existing work mostly focus contrastive learning instancelevel without discriminating contribution word keywords gist text dominant constrained mapping relationship hence work propose hierarchical contrastive learning mechanism unify hybrid granularity semantic meaning input text concretely first propose keyword graph via contrastive correlation positivenegative pair iteratively polish keyword representation construct intracontrasts within instancelevel keywordlevel assume word sampled node sentence distribution finally bridge gap independent contrast level tackle common contrast vanishing problem propose intercontrast mechanism measure discrepancy contrastive keyword node respectively instance distribution experiment demonstrate model outperforms competitive baseline paraphrasing dialogue generation storytelling task
recognizing language ambiguous text become main challenge language identification lid using multilingual application user language preference regarded external knowledge lid nevertheless current study consider interpersonal variation due lack user annotated training data fill gap introduce preferenceaware lid propose novel unsupervised learning strategy concretely construct pseudo training set user extracting training sample standard lid corpus according hisher historical language distribution besides contribute first user labeled lid test set called ulid experimental result reveal model incarnate user trait significantly outperforms existing lid system handling ambiguous text code benchmark released
given incomplete event chain script learning aim predict missing event support series nlp application existing work well represent heterogeneous relation capture discontinuous event segment common event chain address issue introduce heterogeneousevent heterevent graph network particular employ unique word individual event node graph explore three kind edge based realistic relation eg relation wordandword wordandevent eventandevent also design message passing process realize information interaction among homo heterogeneous node discontinuous event segment could explicitly modeled finding specific path corresponding node graph experimental result onestep multistep inference task demonstrate ensemble model hetereventwe outperform existing baseline
concept represent group different instance sharing common property essential information knowledge representation conventional knowledge embedding method encode entity concept instance relation vector low dimensional semantic space equally ignoring difference concept instance paper propose novel knowledge graph embedding model named transc differentiating concept instance specifically transc encodes concept knowledge graph sphere instance vector semantic space use relative position model relation concept instance ieinstanceof relation concept subconcepts ie subclassof evaluate model link prediction triple classification task dataset based yago experimental result show transc outperforms stateoftheart method capture semantic transitivity instanceof subclassof relation code datasets obtained urlhttpsgithubcomdavidlvxintransc
address problem extractive question answering using documentlevel distant supervision pairing question relevant document answer string compare previously used probability space distant supervision assumption assumption correspondence weak answer string label possible answer mention span show assumption interact different configuration provide complementary benefit demonstrate multiobjective model efficiently combine advantage multiple assumption outperform best individual formulation approach outperforms previous stateoftheart model point f triviaqawiki point rougel narrativeqa summary
build goaloriented dialogue system generate response given knowledge base identifying relevant piece information grounded vital number document knowledge base large retrieval approach typically used identify top relevant document however prior work simply us entire dialogue history guide retrieval rather exploiting dialogue topical structure work examine importance building proper contextualized dialogue history documentlevel topic shift present result suggest excluding irrelevant turn dialogue history eg excluding turn grounded document current turn lead better retrieval result also propose cascading approach utilizing topical nature knowledgegrounded conversation manipulate dialogue history used input retrieval model
news recommendation aim predict click behavior based user behavior effectively model user representation key recommending preferred news existing work mostly focused improvement supervised finetuning stage however still lack plmbased unsupervised pretraining method optimized user representation work propose unsupervised pretraining paradigm two task ie user behavior masking user behavior generation towards effective user behavior modeling firstly introduce user behavior masking pretraining task recover masked user behavior based contextual behavior way model could capture much stronger comprehensive user news reading pattern besides incorporate novel auxiliary user behavior generation pretraining task enhance user representation vector derived user encoder use pretrained user modeling encoder obtain news user representation downstream finetuning evaluation realworld news benchmark show significant performance improvement existing baseline
team silpnlp participated semeval task multiconer ii work made system monolingual track leveraging advantage track knowledge chose transformerbased pretrained model strong crosslingual transferability hence model trained two stage first stage multilingual learning track second finetuning individual track work highlight knowledge track transferred individual track baseline language model crosslingual feature system positioned top track scoring macro f score hindi track th rank macro f score bangla track th rank
relation extraction task show promising performance extracting relation two entity mentioned sentence given sufficient annotation available training annotation would laborintensive obtain practice existing work adopts data augmentation technique generate pseudoannotated sentence beyond limited annotation technique neither preserve semantic consistency original sentence rulebased augmentation adopted preserve syntax structure sentence expressing relation using seqseq model resulting less diverse augmentation work propose dedicated augmentation technique relational text named gda us two complementary module preserve semantic consistency syntax structure adopt generative formulation design multitasking solution achieve synergy furthermore gda adopts entity hint prior knowledge generative model augment diverse sentence experimental result three datasets lowresource setting showed gda could bring textit f improvement compared augmentation technique
paper present ocwikidisc new freely available corpus occitan well language identification experiment occitan done part corpus building process occitan regional language spoken mainly south france part spain italy exhibit rich diatopic variation standardized still lowresourced especially come large downloadable corpus introduce ocwikidisc corpus extracted talk page associated occitan wikipedia version corpus restrictive language filtering contains k user message total k token language filtering performed based language identification experiment five offtheshelf tool including new fasttexts language identification model meta ai language left behind initiative released july
masked language model mlms bert revolutionized field natural language understanding past year however existing pretrained mlms often output anisotropic distribution token representation occupies narrow subset entire representation space token representation ideal especially task demand discriminative semantic meaning distinct token work propose tacl tokenaware contrastive learning novel continual pretraining approach encourages bert learn isotropic discriminative distribution token representation tacl fully unsupervised requires additional data extensively test approach wide range english chinese benchmark result show tacl brings consistent notable improvement original bert model furthermore conduct detailed analysis reveal merit innerworkings approach
timeoffset interaction application toia allow simulating conversation people previously recorded relevant video utterance played response interacting user toias great potential preserving crossgenerational crosscultural history online teaching simulated interview etc current toias exist niche context involving high production cost democratizing toia present different challenge creating appropriate prerecordings designing different user story creating simple online interface experimentation opensource toia usercentered timeoffset interaction application make available everyone want interact people prerecordings create prerecordings
focus problem capturing declarative knowledge entity learned parameter language model introduce new modelentities expert eaethat access distinct memory entity mentioned piece text unlike previous effort integrate entity knowledge sequence model eaes entity representation learned directly text show eaes learned representation capture sufficient knowledge answer triviaqa question dr villain played roger delgado anthony ainley eric robert outperforming encodergenerator transformer model x parameter task according lama knowledge probe eae contains factual knowledge similar sized bert well previous approach integrate external source entity knowledge eae associate parameter specific entity need access fraction parameter inference time show correct identification representation entity essential eaes performance
clinical trial critical drug development constructing appropriate eligibility criterion ie inclusionexclusion criterion patient recruitment essential trial success proper design clinical trial protocol consider similar precedent trial eligibility criterion ensure sufficient patient coverage paper present method named autotrial aid design clinical eligibility criterion using language model allows controllable generation instruction via hybrid discrete neural prompting scalable knowledge incorporation via incontext learning explicit reasoning chain provide rationale understanding output experiment k clinical trial verify autotrial generates highquality criterion text fluent coherent high accuracy capturing relevant clinical concept target trial noteworthy method much smaller parameter size gain around winning rate gpt baseline via human evaluation
science communication layperson term essential reach general population also maximize impact underlying scientific research hence good science blog journalistic review research article wellread critical conveying science scientific blogging go beyond traditional research summary offering expert platform articulate finding layperson term bridge gap intricate research comprehension general public policymakers researcher amid rapid expansion scientific data accelerating pace research credible science blog serve vital artifact evidencebased information general nonexpert audience however writing scientific blog even short lay summary requires significant time effort intrigued textitwhat process writing scientific blog based given paper could semiautomated produce first draft paper introduce novel task artificial intelligence aibased science blog generation research article leverage idea presentation science blog share symbiotic relationship aim clarify elucidate complex scientific concept rely visuals figure aid comprehension motivation textitcreate new dataset science blog using presentation transcript corresponding slide create dataset containing paper presentation transcript figure annotated nearly paper propose multimodal attention model generate blog text select relevant figure explain research article layperson term essentially science blog experimental result respect automatic human evaluation metric show effectiveness proposed approach usefulness proposed dataset
discus impact data bias abusive language detection show classification score popular datasets reported previous work much lower realistic setting bias reduced bias notably observed datasets created focused sampling instead random sampling datasets higher proportion implicit abuse affected datasets lower proportion
paper dissect influence several targetside dependencybased extension hierarchical machine translation including dependency language model lm pursue nonrestrictive approach prohibit production hypothesis malformed dependency structure since many question remained open previous related work offer indepth analysis influence language model order impact dependencybased restriction search space information gained dependency tree building decoding application nonrestrictive approach together integrated dependency lm scoring novel contribution yield significant improvement two largescale translation task language pair chineseenglish germanfrench
following describe system developed semeval task finetuned bert checkpoint qatar living forum dump used checkpoint train number model handin subtask consists finetuned classifier bert checkpoint subtask b first classifier deciding whether comment factual nonfactual factual retrieve intraforum evidence using evidence classifier deciding comment veracity trained classifier rating crawled qatarlivingcom
paper present comparison linguistic knowledge encoded internal representation contextual language model bert contextualindependent one wordvec use wide set probing task corresponds distinct sentencelevel feature extracted different level linguistic annotation show although bert capable understanding full context word input sequence implicit knowledge encoded aggregated sentence representation still comparable contextualindependent model also find bert able encode sentencelevel property even within singleword embeddings obtaining comparable even superior result obtained sentence representation
tackle problem context reconstruction chinese dialogue task replace pronoun zero pronoun referring expression referent noun sentence processed isolation without context following standard decomposition context reconstruction task referring expression detection coreference resolution propose novel endtoend architecture separately jointly accomplishing task key feature model include po position encoding using cnns novel pronoun masking mechanism one perennial problem building model paucity training data address augmenting previouslyproposed method generate large amount realistic training data combination data better model yield accuracy higher stateoftheart method coreference resolution endtoend context reconstruction
chartbased model shown great potential unsupervised grammar induction running recursively hierarchically requiring onmbox timecomplexity recursive transformer based differentiable tree rd make possible scale large language model pretraining even complex tree encoder introducing heuristic pruning methodhowever rulebased pruning process suffers local optimum slow inference paper propose unified rd method overcomes issue use topdown unsupervised parser modelguided pruning method also enables parallel encoding inference parser cast parsing split point scoring task first scoring split point given sentence using highestscoring one recursively split span two part reverse order split considered order pruning encoder optimize unsupervised parser minimizing kullbackleibler distance tree probability parser rd modelour experiment show fastrd significantly improves grammar induction quality achieves competitive result downstream task
paper describes system created wassa implicit emotion shared task goal task predict emotion given tweet certain emotion word removed removed word textitsad textithappy textitdisgusted textitangry textitafraid synonym one proposed system based deeplearning method use bidirectional long shortterm memory bilstm word embeddings input pretrained deepmoji model pretrained emojivec emoji embeddings also used additional input system achieves macro f score rank th
word embeddings advanced state art nlp across numerous task understanding content dense neural representation utmost interest computational semantics community propose focus relating opaque word vector humanreadable definition found dictionary problem naturally divide two subtasks converting definition embeddings converting embeddings definition task conducted multilingual setting using comparable set embeddings trained homogeneously
recent year knowledge graph embedding becomes pretty hot research topic artificial intelligence play increasingly vital role various downstream application recommendation question answering however existing method knowledge graph embedding make proper tradeoff model complexity model expressiveness make still far satisfactory mitigate problem propose lightweight modeling framework achieve highly competitive relational expressiveness without increasing model complexity framework focus design scoring function highlight two critical characteristic facilitating sufficient feature interaction preserving symmetry antisymmetry property relation noteworthy owing general elegant design scoring function framework incorporate many famous existing method special case moreover extensive experiment public benchmark demonstrate efficiency effectiveness framework source code data found urlhttpsgithubcomwentaoxuseek
recently dynamic early exiting attracted much attention since accelerate inference speed pretrained model ptms however previous work early exiting neglected intermediate exit architectural design work propose novel framework learned exit comparisonbased early exiting leco improve ptms early exiting performance first fully uncover potential multiexit bert design novel search space intermediate exit employ idea differentiable neural architecture search dna design proper exit architecture different intermediate layer automatically second propose simpleyeteffective comparisonbased early exiting mechanism cobee help ptms achieve better performance speedup tradeoff extensive experiment show leco achieves sota performance multiexit bert training dynamic early exiting
research carried still progress aimed construction three specialized lexicon organized database relational type three database contain term belonging specialized knowledge field maritime terminology technicalnautical maritime transport domain taxation law labour law union labour rule respectively eurowordnetitalwordnet model firstly used structure terminological database maritime domain methodology experimented construction applied construct next database consists management corpus specialized language ii use generic database identify extract set candidate term codified terminological database three specialized resource described highlighting various kind lexical semantic relation linking term others within single terminological database generic resource wordnet italwordnet construction specialized lexicon carried framework different project seen first nucleus organized network generic specialized lexicon purpose making meaning term clearer cognitive point view
alarming spread fake news social medium together impossibility scaling manual fact verification motivated development natural language processing technique automatically verify veracity claim approach perform claimevidence classification without providing insight claim trustworthy propose instead modelagnostic framework consists two module span extractor identifies crucial information connecting claim evidence classifier combine claim evidence extracted span predict veracity claim show span informative classifier improving performance robustness tested several stateoftheart model fever dataset enhanced classifier consistently achieve higher accuracy also showing reduced sensitivity artifact claim
present molt selfsupervised learning framework pretraining model vast amount unlabeled natural language text molecule string molt allows new useful challenging analog traditional visionlanguage task molecule captioning textbased de novo molecule generation altogether translation molecule language explore first time since molt pretrains model singlemodal data help overcome chemistry domain shortcoming data scarcity furthermore consider several metric including new crossmodal embeddingbased metric evaluate task molecule captioning textbased molecule generation result show moltbased model able generate output molecule caption many case high quality
paper discusses measure impact online content localized machine translation meeting business need commercial user ie reducing volume telephone call call center call deflection address various design conceptual practical issue encountered proving value machine translation conclude approach give best result one reconciles enduser human evaluation feedback web call center data
article present lexicon arabic verb exploit levins verbclasses levin basic development procedure used schuler verb lexicon current state class contain verb frame providing information verb root deverbal form verb participle thematic role subcategorisation frame syntactic semantic description verb taxonomy available xml format ported mysql yaml json accessed either arabic character buckwalter transliteration
pretrained language model ptlms shown perform well natural language task many prior work leveraged structured commonsense present form entity linked labeled relation knowledge graph kg assist ptlms retrieval approach use kg separate static module limit coverage since kg contain finite knowledge generative method train ptlms kg triple improve scale knowledge obtained however training symbolic kg entity limit applicability task involving natural language text ignore overall context mitigate propose commonsense contextualizer coseco conditioned sentence input make generically usable task generating knowledge relevant overall context input text train coseco propose novel dataset comprising sentence commonsense knowledge pair knowledge inferred coseco diverse contain novel entity present underlying kg augment generated knowledge multichoice qa openended commonsense reasoning task leading improvement current best method csqa arc qasc obqa datasets also demonstrate applicability improving performance baseline model paraphrase generation task
ecommerce environment useroriented questionanswering qa text pair could carry rich sentiment information study propose novel taskmethod address qa sentiment analysis particular create highquality annotated corpus speciallydesigned annotation guideline qastyle sentiment classification basis propose threestage hierarchical matching network explore deep sentiment information qa text pair first segment question answer text sentence construct number qsentence asentence unit qa text pair leveraging qa bidirectional matching layer proposed approach learn matching vector qsentence asentence unit finally characterize importance generated matching vector via selfmatching attention layer experimental result comparing number stateoftheart baseline demonstrate impressive effectiveness proposed approach qastyle sentiment classification
paper present adaptation abstract meaning representation amr framework european portuguese adaptation referred lexicalized meaning representation lmr deemed necessary address specific challenge posed grammar language well various linguistic issue raised current version amr annotation guideline aspect stemmed use notation similar amr represent real text legal domain enabling use natural language processing nlp application context several aspect amr significantly simplified eg representation multiword expression named entity temporal expression others introduced effort made maintain representation scheme compatible possible standard amr notation
large size pretrained network make difficult deploy multiple task storageconstrained setting diff pruning enables parameterefficient transfer learning scale well new task approach learns taskspecific diff vector extends original pretrained parameter diff vector adaptively pruned training differentiable approximation lnorm penalty encourage sparsity number task increase diff pruning remains parameterefficient requires storing small diff vector task since require access task training attractive ondevice deployment setting task arrive stream even different provider diff pruning match performance finetuned baseline glue benchmark modifying pretrained model parameter per task scale favorably comparison popular pruning approach
japanesetoenglish translation zero pronoun japanese pose challenge since model need infer produce corresponding pronoun target side english sentence however although fully resolving zero pronoun often need discourse context case local context within sentence give clue inference zero pronoun study propose data augmentation method provides additional training signal translation model learn correlation local context zero pronoun show proposed method significantly improves accuracy zero pronoun translation machine translation experiment conversational domain
modeling make request persuasive eliciting desired response reader critical study propaganda behavioral economics advertising yet current model cant quantify persuasiveness request extract successful persuasive strategy building theory persuasion propose neural network quantify persuasiveness identify persuasive strategy advocacy request semisupervised hierarchical neural network model supervised number people persuaded take action partially supervised sentence level humanlabeled rhetorical strategy method outperforms several baseline uncovers persuasive strategy offering increased interpretability persuasive speech application situation documentlevel supervision partial sentence supervision
paper document ubc linguistics team approach sigmorphon graphemetophoneme shared task concentrating lowresource setting system expand baseline model simple modification informed syllable structure error analysis indepth investigation testset prediction show best model rectifies significant number mistake compared baseline prediction besting submission result validate view careful error analysis conjunction linguistic knowledge lead effective computational modeling
discus methodology dealing annotation semantically hard delineate ie sloppy named entity type illustrate sloppiness entity treat example medical domain namely pathological phenomenon based experience iterative guideline refinement propose carefully characterize thematic scope annotation positive negative coding list allow alternative short v long mention span annotation short span account canonical entity mention eg standardized disease name long span cover descriptive text snippet contain entityspecific elaboration eg anatomical location observational detail etc using stratified approach evidence increasing annotation performance provided kappabased interannotator agreement measurement several iterative annotation round using continuously refined guideline latter reflects increasing understanding sloppy entity class perspective guideline writer user annotator given data gathered evidence deal sloppiness controlled manner expect interannotator agreement value around pathojen pathological phenomenon corpus currently development lab
many natural formal language contain word symbol require matching counterpart making expression wellformed combination opening closing bracket typical example construction due commonness ability follow rule important language modeling currently recurrent neural network rnns extensively used task investigate whether capable learning rule opening closing bracket applying synthetic dyck language consist different type bracket provide analysis statistical property language baseline show strength limit elmanrnns grus lstms experiment random sample language term perplexity prediction accuracy rnns get close theoretical baseline case
writing summary human tend choose content one two sentence merge single summary sentence however mechanism behind selection one multiple source sentence remain poorly understood sentence fusion assumes multisentence input yet sentence selection method work single sentence combination thus crucial gap sentence selection fusion support summarizing compressing single sentence fusing pair paper attempt bridge gap ranking sentence singleton pair together unified space proposed framework attempt model human methodology selecting either single sentence pair sentence compressing fusing sentence produce summary sentence conduct extensive experiment single multidocument summarization datasets report finding sentence selection abstraction
neural machine translation nmtsystems still trained using maximum likelihood estimation recent work demonstrated optimizing system directly improve evaluation metric bleu significantly improve final translation accuracy however training bleu limitation doesnt assign partial credit limited range output value penalize semantically correct hypothesis differ lexically reference paper introduce alternative reward function optimizing nmt system based recent work semantic similarity evaluate four disparate language translated english find training proposed metric result better translation evaluated bleu semantic similarity human evaluation also optimization procedure converges faster analysis suggests proposed metric conducive optimization assigning partial credit providing diversity score bleu
nowadays spread misinformation prominent problem society research focus aiding automatic identification misinformation analyzing persuasive strategy employed textual document introduce novel annotation scheme encompassing common persuasive writing tactic achieve objective additionally provide dataset health misinformation thoroughly annotated expert utilizing proposed scheme contribution includes proposing new task annotating piece text persuasive writing strategy type evaluate finetuning promptengineering technique pretrained language model bert family generative large language model gpt family using persuasive strategy additional source information evaluate effect employing persuasive strategy intermediate label context misinformation detection result show strategy enhance accuracy improve explainability misinformation detection model persuasive strategy serve valuable insight explanation enabling model even human make informed decision regarding trustworthiness information
existing opendomain dialogue generation model usually trained mimic gold response training set using crossentropy loss vocabulary however good response need resemble gold response since multiple possible response given prompt work hypothesize current model unable integrate information multiple semantically similar valid response prompt resulting generation generic uninformative response address issue propose alternative endtoend classification vocabulary learn pair relationship prompt response regression task latent space instead novel dialog generation model representation semantically related sentence close latent space human evaluation showed learning task continuous space generate response relevant informative
many automatic semantic relation extraction tool extract subjectpredicateobject triple unstructured text however large quantity triple merely represent background knowledge explore using full text biomedical publication create training corpus informative important semantic triple based notion main contribution article summarized abstract corpus used train deep learning classifier identify important triple suggest importance ranking semantic triple could also generated
present dialogue generation model directly capture variability possible response given input reduces boring output issue deterministic dialogue model experiment show model generates diverse output baseline model also generates consistently acceptable output sampling deterministic encoderdecoder model
example ambiguous english construction polish equivalent discussed term correlation respective phrasemarker representation transformational analysis shown example investigation reveal interesting fact mt therefore carried pair language given mt program constructed phrasemarker english construction set onetoone correspondence phrasemarker polish equivalent construction whatever particular transformational analysis construction taken account ambiguous phrasemarker representation used syntactical model mt algorithm good result phrasemarker english construction set onetomany correspondence phrasemarkers polish equivalent according transformational analysis construction ambiguous phrasestructure representation resolved term transformational analysis possible assign corresponding phrase structure representation polish equivalent tentative scheme syntactical recognition provided multiply ambiguous adjectival construction english proved belong latter case mean introducing information obtained transformational analysis construction
text classification significant branch natural language processing many application including document classification sentiment analysis unsurprisingly text classification concerned runtime algorithm many depend size corpus vocabulary due bagofwords representation although many study examined effect preprocessing technique vocabulary size accuracy none examined method affect model runtime fill gap provide comprehensive study examines preprocessing technique affect vocabulary size model performance model runtime evaluating ten technique four model two datasets show individual method reduce runtime loss accuracy combination method trade accuracy reduction runtime furthermore combination preprocessing technique even provide reduction runtime simultaneously improving model accuracy
previous work event detection ed considered datasets small number event type ie type work present first study finegrained ed fed evaluation dataset involves much finegrained event type ie type propose novel method transform semcor dataset word sense disambiguation large highquality dataset fed extensive evaluation current ed method conducted demonstrate challenge generated datasets fed calling research effort area
ecommerce search engine use customer behavior signal augment lexical matching improve search relevance many ecommerce company like amazon alibaba ebay etc operate multiple country country specific store however customer behavior data sparse newer store compensate sparsity behavioral data low traffic store search engine often use crosslisted product form however crosslisting across store uniform many case sparse paper develop model identify duplicate nearduplicate product across store model used unify product catalog worldwide improve product metadata case use nearduplicate product across multiple improve search relevance capture product similarity hierarchy develop approach integrates retrieval ranking task across multiple language single step based novel hierarchical ranked multi similarity hrms loss combine multisimilarity m loss hierarchical triplet loss learn hierarchical metric space method outperforms strong baseline term catalog coverage precision mapping also show via online ab test product mapping found method successful improving search quality low traffic store measured rate search least one click significantly improving cold start product engagement measured new product click significantly established store
multitask learning selftraining two common way improve machine learning model performance setting limited training data drawing heavily idea two approach suggest transductive auxiliary task selftraining training multitask model combination main auxiliary task training data ii test instance auxiliary task label singletask version model previously generated perform extensive experiment combination language task result average transductive auxiliary task selftraining improves absolute accuracy pure multitask model dependency relation tagging semantic tagging
many existing speech translation benchmark focus nativeenglish speech highquality recording condition often match condition reallife usecases paper describe speech translation system multilingual track iwslt focus translation scientific conference talk test condition feature accented input speech terminologydense content task requires translation language varying amount resource absence training data target domain use retrievalbased approach knnmt effective adaptation bleu speech translation also use adapter easily integrate incremental training data data augmentation show match performance retraining observe cascaded system easily adaptable towards specific target domain due separate module cascaded speech system outperforms endtoend counterpart scientific talk translation although performance remains similar ted talk
present memorybased model context dependent semantic parsing previous approach focus enabling decoder copy modify parse previous utterance assuming dependency current previous parses work propose represent contextual information using external memory learn context memory controller manages memory maintaining cumulative meaning sequential user utterance evaluate approach three semantic parsing benchmark experimental result show model better process contextdependent information demonstrates improved performance without using taskspecific decoder
propose segmental neural language model combine generalization power neural network ability discover wordlike unit latent unsegmented character sequence contrast previous segmentation model treat word segmentation isolated task model unifies word discovery learning word fit together form sentence conditioning model visual context word meaning ground representation nonlinguistic modality experiment show unconditional model learns predictive distribution better character lstm model discovers word competitively nonparametric bayesian word segmentation model modeling language conditional visual context improves performance
paper describes process building newspaper corpus annotated event described specific document main difference corpus built part tdt initiative document annotated topic specific event describe additionally document gathered sixteen source document corpus annotated corresponding event annotation process consists browsing searching step experiment performed threshold could used browsing step yielding result browse document pair loss relevant document pair statistical analysis annotated corpus undertaken showing event described document event reported many document interannotator agreement measure show high agreement concerning grouping document event cluster show much lower agreement concerning number event document organized initial experiment described giving baseline research corpus
statistical machine translation smt highly inflected lowresource language suffers problem low bitext availability exacerbated large inflectional paradigm translating english rich source inflection high chance poorly estimated outofvocabulary oov present source languageagnostic system automatically constructing phrase pair foreignlanguage inflection morphological analysis using manually constructed datasets including wiktionary demonstrate utility phrase table improving translation english finnish czech turkish simulated lowresource setting finding substantial gain translation quality report bleu simulated lowresource setting bleu moderateresource setting release morphologicallymotivated translation model ten thousand inflection language
one key task finegrained sentiment analysis product review extract product aspect feature user expressed opinion paper focus supervised aspect extraction using deep learning unlike highly sophisticated supervised deep learning model paper proposes novel yet simple cnn model employing two type pretrained embeddings aspect extraction generalpurpose embeddings domainspecific embeddings without using additional supervision model achieves surprisingly good result outperforming stateoftheart sophisticated existing method knowledge paper first report double embeddings based cnn model aspect extraction achieve good result
establishing retrievalbased dialogue system select appropriate response prebuilt index gained increasing attention recent common practice construct twostage pipeline fast retriever eg biencoder firststage recall followed smart response reranker eg crossencoder precise ranking however existing study either optimize retriever reranker independent way distill knowledge pretrained reranker retriever asynchronous way leading suboptimal performance module thus open question remains train better combination best world end present cooperative training response retriever reranker whose parameter dynamically optimized groundtruth label well listwise supervision signal result two module learn evolve together throughout training experimental result two benchmark demonstrate superiority method
efficiency key property foster inclusiveness reduce environmental cost especially era llm work provide comprehensive evaluation efficiency mt evaluation metric approach involves replacing computationintensive transformer lighter alternative employing linear quadratic approximation alignment algorithm top llm representation evaluate six referencefree referencebased metric across three mt datasets examine lightweight transformer addition look training efficiency metric like comet utilizing adapter result indicate tinybert provides optimal balance quality efficiency b cpu speedup substantial gpu c wmd approximation yield efficiency gain reducing quality adapter enhance training efficiency regarding backward pas speed memory requirement well case metric quality finding help strike balance evaluation speed quality essential effective nlg system furthermore research contributes ongoing effort optimize nlg evaluation metric minimal impact performance knowledge comprehensive analysis different aspect efficiency mt metric conducted far
uniform information density uid hypothesis posit preference among language user utterance structured information distributed uniformly across signal implication language production well explored hypothesis potentially make prediction language comprehension linguistic acceptability well unclear uniformity linguistic signalor lack thereofshould measured linguistic unit eg sentence language level uniformity hold investigate facet uid hypothesis using reading time acceptability data reading time result generally consistent previous work also consistent weakly superlinear effect surprisal would compatible uids prediction acceptability judgment find clearer evidence nonuniformity information density predictive lower acceptability explore multiple operationalizations uid motivated different interpretation original hypothesis analyze scope pressure towards uniformity exerted explanatory power subset proposed operationalizations suggests strongest trend may regression towards mean surprisal across language rather phrase sentence documenta finding support typical interpretation uid namely byproduct language user maximizing use hypothetical communication channel
paper enumerates sigtyp shared task prediction typological feature performed kmipanlinguaiitkgp team task entailed prediction missing value particular language provided name language family genus location term latitude longitude coordinate name country spoken set featurevalue pair available part fulfillment aforementioned task team submitted kind system rulebased one hybrid system one rulebased system generated best performance test set system constrained sense additional dataset information provided organiser used developing system
recent progress pretraining language model large corpus resulted significant performance gain many nlp task large model acquire linguistic knowledge pretraining help improve performance downstream task via finetuning assess kind knowledge acquired language model commonly probed querying fill blank style cloze question existing probing datasets mainly focus knowledge relation word entity introduce wdlmpro word definition language model probing evaluate word understanding directly using dictionary definition word experiment three popular pretrained language model struggle match word definition indicates understand many word poorly new probing task difficult challenge could help guide research lm future
definition extraction important task nature language processing used identify term definition related term task contains sentence classification task ie classify whether contains definition sequence labeling task ie find boundary term definition paper describes system bertatde sentence classification task subtask sequence labeling task subtask definition extraction semeval task use bert solve multidomain problem including uncertainty term boundary different area different way definite domain related term use bert bilstm attention subtask best result achieved f eighteenth place subtask subtask use bert bilstm crf sequence labeling achieve macroaveraged f
crosslingual summarization aim help people efficiently grasp core idea document written foreign language modern text summarization model generate highly fluent often factually inconsistent output received heightened attention recent research however factual consistency crosslingual summarization investigated yet paper propose crosslingual factuality dataset collecting human annotation reference summary well generated summary model summary level sentence level furthermore perform finegrained analysis observe generated summary reference summary contain factual error characteristic different monolingual summarization existing evaluation metric monolingual summarization require translation evaluate factuality crosslingual summarization perform differently different task level finally adapt monolingual factuality metric initial step towards automatic evaluation summarization factuality crosslingual setting dataset code available urlhttpsgithubcomkitefactcls
paper present fairy tale corpus semantically organized tagged proposed method us latent semantic mapping represent story topn itemtoitem recommendation algorithm define cluster similar story story placed one cluster story cluster related concept result manually evaluated regarding grouping perceived human judge evaluation resulted precision recall fmeasure using tfidf word frequency method topic languageindependent contrary traditional clustering method automatically defines number cluster based set document method used setup traditional clustering classification resulting corpus used recommendation purpose although also used emotion extraction semantic role extraction meaning extraction text classification among others
purpose paper present empirical study gender bias text current research field focused detecting correcting gender bias existing machine learning model rather approaching issue dataset level underlying motivation create dataset could enable machine learn differentiate bias writing nonbias writing taxonomy proposed structural contextual gender bias manifest text methodology proposed fetch one type structural gender bias gender generalization explore imdb movie review dataset different corpus project gutenberg filtering irrelevant sentence remaining pool candidate sentence sent human validation total judgment made sentence quality check randomly selected sentence obtain accuracy sentence sentence labeled gender generalization interrater reliability amongst labelers
automatic essay grading aeg process machine assign grade essay written response topic called prompt zeroshot aeg train system grade essay written new prompt present training data paper describe solution problem zeroshot automatic essay grading using cognitive information form gaze behaviour experiment show using gaze behaviour help improving performance aeg system especially provide new essay written response new prompt scoring average almost percentage point qwk
given untrimmed video natural language query natural language video localization nlvl aim identify video moment described query address task existing method roughly grouped two group proposeandrank model first define set handdesigned moment candidate find bestmatching one proposalfree model directly predict two temporal boundary referential moment frame currently almost proposeandrank method inferior performance proposalfree counterpart paper argue performance proposeandrank model underestimated due predefined manner handdesigned rule hard guarantee complete coverage targeted segment densely sampled candidate moment cause redundant computation degrade performance ranking process end propose novel model termed lpnet learnable proposal network nlvl fixed set learnable moment proposal position length proposal dynamically adjusted training process moreover boundaryaware loss proposed leverage framelevel information improve performance extensive ablation two challenging nlvl benchmark demonstrated effectiveness lpnet existing stateoftheart method
paper examines challenging problem learning representation entity relation complex multirelational knowledge graph propose hitter hierarchical transformer model jointly learn entityrelation composition relational contextualization based source entity neighborhood proposed model consists two different transformer block bottom block extract feature entityrelation pair local neighborhood source entity top block aggregate relational information output bottom block design masked entity prediction task balance information relational context source entity experimental result show hitter achieves new stateoftheart result multiple link prediction datasets additionally propose simple approach integrate hitter bert demonstrate effectiveness two freebase factoid question answering datasets
large language model llm chatgpt prone generate hallucination ie content conflict source verified factual knowledge understand type content extent llm apt hallucinate introduce hallucination evaluation large language model halueval benchmark large collection generated humanannotated hallucinated sample evaluating performance llm recognizing hallucination generate sample propose chatgptbased twostep framework ie samplingthenfiltering besides also hire human labelers annotate hallucination chatgpt response empirical result suggest chatgpt likely generate hallucinated content specific topic fabricating unverifiable information ie user query moreover existing llm face great challenge recognizing hallucination text experiment also prove hallucination recognition improved providing external knowledge adding reasoning step
present corpus timealigned spoken data wikipedia article well pipeline allows generate corpus many language initiative create sustain spoken wikipedia version many language hence data freely available grows time used automatic corpus creation pipeline automatically downloads aligns data resulting german corpus currently total h audio align h full sentence another h sentence missing word english corpus consists h align h full sentence h missing word result publically available
large language model llm demonstrated impressive capability generating fluent text well tendency reproduce undesirable social bias work investigates whether llm reproduce moral bias associated political group united state instance broader capability herein termed moral mimicry work explores hypothesis gpt opt family transformerbased llm using tool moral foundation theory work show llm indeed moral mimic prompted liberal conservative political identity model generate text reflecting corresponding moral bias study also explores relationship moral mimicry model size similarity human llm moral word use
today widespread use large language model llm significant achievement various text domain generating summary translation however still room development improvement evaluating output llm paper propose innovative scoring system assesses quality summary translation using multiple metric also enhance llm performance scoring task assigning different role effectively making act expert test four role study teacher proofreader travel writer internet troll comparing advantage disadvantage role scoring task research result demonstrate emphasizing llm multilingual capability strict standard identity effectively boost performance additionally imbuing llm critical thinking ability enhances performance translation task compared milder llm identity summary show assigning different identity llm influence performance scoring task believe research contribute use llm scoring purpose
pretraining technique working well natural language processing pretrain decoder effectively use neural machine translation nmt still remains tricky issue main reason crossattention module encoder decoder pretrained combined encoderdecoder model work well finetuning stage input decoder crossattention come unknown encoder output paper propose better pretraining method nmt defining semantic interface semface pretrained encoder pretrained decoder specifically propose two type semantic interface including clsemface regard crosslingual embeddings interface vqsemface employ vector quantized embeddings constrain encoder output decoder input languageindependent space conduct massive experiment six supervised translation pair three unsupervised pair experimental result demonstrate proposed semface effectively connect pretrained encoder decoder achieves significant improvement bleu point two task respectively compared previous pretrainingbased nmt model
back translation bt one significant technology nmt research field existing attempt bt share common characteristic employ either beam search random sampling generate synthetic data backward model seldom work study role synthetic data performance bt motivates u ask fundamental question kind synthetic data contributes bt performancethrough theoretical empirical study identify two key factor synthetic data controlling backtranslation nmt performance quality importance furthermore based finding propose simple yet effective method generate synthetic data better trade factor yield better performance bt run extensive experiment wmt deen ende ruen benchmark task employing proposed method generate synthetic data bt model significantly outperforms standard bt baseline ie beam sampling based method data generation prof effectiveness proposed method
anglicism challenge german speech recognition due irregular pronunciation compared native german word automatically generated pronunciation dictionary often contain incorrect phoneme sequence anglicism work propose multitask sequencetosequence approach graphemetophoneme conversion improve phonetization anglicism extended graphemetophoneme model classification task distinguish anglicism native german word approach model learns generate different pronunciation depending classification result used model create supplementary anglicism pronunciation dictionary added existing german speech recognition model tested special anglicism evaluation set improved recognition anglicism compared baseline model reducing word error rate relative anglicism error rate relative experiment show multitask learning help solving challenge anglicism german speech recognition
quotation extraction aim extract quotation written text three component quotation textitsource refers holder quotation textitcue trigger word textitcontent main body existing solution quotation extraction mainly utilize rulebased approach sequence labeling model rulebased approach often lead low recall sequence labeling model well handle quotation complicated structure paper propose textbfcontext textbfformerlabel textbfenhanced textbfnet quotation extraction able extract complicated quotation component variable length complicated structure two public datasets one proprietary dataset show achieves stateoftheart performance complicated quotation extraction
orange silicon valley hosted lowresource machine translation mt competition monetary prize goal competition raise awareness challenge lowresource mt domain improve mt algorithm data strategy support mt expertise development region people speak bambara lowresource language participant built bambara french french bambara machine translation system using data provided organizer additional data resource shared amongst competitor paper detail team different approach motivation ongoing work bambara broader lowresource machine translation domain
emotion recognition highresource language progressed significantly however resourceconstrained language bengali advanced notably due lack large benchmark datasets besides need bengali language processing tool make emotion recognition task challenging complicated therefore developed largest dataset paper consisting almost k bengali text six basic emotion conducted experiment dataset establish baseline performance applying machine learning deep learning transformerbased model emotion classifier experimental result demonstrate model achieved promising performance bengali emotion recognition
pregroup calculus used representation free word order language sanskrit hungarian using construction called precyclicity however restricted word order alternation handled paper aim introducing formally expressing three method representing word order alternation pregroup representation language paper describes word order alternation pattern hindi creates basic pregroup representation language shortcoming correct reduction ungrammatical sentence due current apparatus highlighted aforementioned method invoked grammatically accurate representation restricted word order alternation replicability method explained representation adverb prepositional phrase english
growing effort nlp aim build datasets human explanation however remains unclear whether datasets serve intended goal problem exacerbated fact term explanation overloaded refers broad range notion different property ramification goal provide overview diversity explanation discus human limitation providing explanation ultimately provide implication collecting using human explanation nlpinspired prior work psychology cognitive science group existing human explanation nlp three category proximal mechanism evidence procedure three type differ nature implication resultant explanation instance procedure considered explanation psychology connects rich body work learning instruction diversity explanation evidenced proxy question needed annotator interpret answer input assigned label finally giving explanation may require different often deeper understanding prediction cast doubt whether human provide valid explanation task
reply suggestion system represent staple component many instant messaging email system however requirement produce set reply rather individual reply make task poorly suited outofthebox retrieval architecture consider individual messagereply similarity result system often rely additional postprocessing module diversify output however approach ultimately bottlenecked performance initial retriever practice struggle present sufficiently diverse range option downstream diversification module leading suggestion less relevant user paper consider novel approach radically simplifies pipeline autoregressive texttotext retrieval model learns smart reply task endtoend dataset message reply set pair obtained via bootstrapping empirical result show method consistently outperforms range stateoftheart baseline across three datasets corresponding improvement relevance improvement diversity compared best baseline approach make code publicly available
last decade method web corpus construction evaluation web corpus actively researched prominently wacky initiative provided theoretical result set web corpus selected european language present software toolkit web corpus construction set siginificantly larger corpus billion token built using software first discus data collected ensure biased towards certain host describe software toolkit performs basic cleanup well boilerplate removal simple connected text detection well shingling remove duplicate corpus finally report evaluation result corpus built far example wrt amount duplication contained text typegenre distribution applicable compare corpus wacky corpus since inappropriate view compare web corpus traditional balanced corpus use method applied wacky initiative show introduced incremental improvement
task concept prerequisite chain learning automatically determine existence prerequisite relationship among concept pair paper frame learning prerequisite relationship among concept unsupervised task access labeled concept pair training propose model called relationalvariational graph autoencoder rvgae predict concept relation within graph consisting concept resource node result show unsupervised approach outperforms graphbased semisupervised method baseline method term prerequisite relation prediction accuracy f score method notably first graphbased model attempt make use deep learning representation task unsupervised prerequisite learning also expand existing corpus total english natural language processing nlprelated lecture slide file manual concept pair annotation topic
ideally metric evaluating abstract system summary represent extent systemgenerated summary approximates semantic inference conceived reader using humanwritten reference summary previous approach relied upon word syntactic subsequence overlap evaluate systemgenerated summary metric evaluate summary semantic inference level work introduce metric semantic similarity abstractive summarization ssa leverage natural language inference paraphrasing technique frame novel approach evaluate system summary semantic inference level ssa based upon weighted composition quantity representing level agreement contradiction independence paraphrasing optionally rouge score systemgenerated humanwritten summary
seaap segmentador e etiquetador automatico para analise prosodica automatic segmentation labelling prosodic analysis toolkit application performs audio segmentation labelling create textgrid file used launch prosodic analysis using praat paper want describe improved functionality tool achieved adding dialectometric analysis module using r script dialectometric analysis includes computing correlation among f curve obtains prosodic distance among different variable interest location speaker structure etc dialectometric analysis requires large database order adequately computed automatic segmentation labelling create thanks procedure less costly manual alternative thus integration tool seaap allows propose distribution geoprosodic area mean quantitative method completes traditional dialectological point view current version seaap toolkit capable analysing galician spanish brazilian portuguese data hence distance several prosodic linguistic variety measured present
despite increasingly good quality machine translation mt system mt output require correction automatic postediting ape model introduced perform correction without human intervention however system able fully automate postediting pe process moreover numerous translation tool translation memory tm largely benefit translator input humancomputer interaction hci remains limited come pe researchinprogress paper discusses ape model suggests could improved interactive scenario previously done mt creation interactive mt imt system based hypothesis pe would benefit hci two methodology proposed suggest traditional batch learning setting optimal pe instead online technique recommended train update pe model fly via either real simulated interaction translator
automatic taxonomy completion aim attach emerging concept appropriate pair hypernym hyponym existing taxonomy existing method suffer overfitting leafonly problem caused imbalanced leaf nonleaf sample training newly initialized classification head besides leverage subtasks namely attaching concept hypernym hyponym auxiliary supervision representation learning yet neglect effect subtask result final prediction address aforementioned limitation propose tacoprompt collaborative multitask prompt learning method selfsupervised taxonomy completion first perform triplet semantic matching using prompt learning paradigm effectively learn nonleaf attachment ability imbalanced training sample second design result context relate final prediction subtask result contextual approach enhancing promptbased multitask learning third leverage twostage retrieval reranking approach improve inference efficiency experimental result three datasets show tacoprompt achieves stateoftheart taxonomy completion performance code available httpsgithubcomcyclexutacoprompt
dialogue act well studied linguistics attracted computational linguistics research long time constitute basis everyday conversation identified communicative goal given utterance eg asking information stating fact expressing opinion agreeing disagreeing even constituting deep understanding dialogue automatic dialogue act labeling task relevant wide range application humancomputer humanhuman interaction present qualitative analysis lexicon dialogue act explore relationship communicative goal utterance affective content well salience specific word class speech act experiment described paper fit scope research study whose longterm goal build unsupervised classifier simply exploit lexical semantics utterance automatically annotate dialogue proper speech act
using incontext learning icl data generation technique selfinstruct wang et al followup alpaca taori et al train strong conversational agent small amount human supervision one limitation approach resort large language model around b parameter also proprietary nonpublic explore application technique language model much smaller around bb parameter permissive license find selfinstruct approach less effective size propose new icl method draw two main idea categorization simplification icl template make prompt learning easier lm b ensembling multiple lm output help select highquality synthetic example algorithm leverage selfinstruct seed task employ separate pipeline instruction require input instruction empirical investigation different lm show proposed method yield higherquality instruction tuning data selfinstruct improves performance vanilla instructiontuned lm significant margin smaller instructiontuned lm generate useful example larger untuned counterpart
address task predicting causally related event story according standard evaluation framework choice plausible alternative copa present neural encoderdecoder model learns predict relation adjacent sequence story mean modeling causality explore approach using different method extracting representing sequence pair well different model architecture also compare impact different training datasets model particular demonstrate usefulness corpus previously applied copa rocstories corpus stateoftheart result establish new reference point system evaluated copa one particularly informative future neuralbased approach
data augmentation method commonly used computer vision speech however domain dealing textual data technique common existing method rely rephrasing ie new sentence generated changing source sentence preserving meaning argue task opposable class positive negative sentiment analysis might beneficial also invert source sentence reversing meaning generate example opposing class method use somewhat similar intuition exist space adversarial learning always applicable text classification experiment even detrimental resulting classifier accuracy propose evaluate two reversalbased method nli task recognising type simple logical expression description plaintext form gathering dataset mturk show simple heuristic using notion negating main verb potential also boost existing stateoftheart rephrasingbased approach
paper discusses information extraction used understand manage dialogue eufunded companion project discussed respect senior companion one two application development eufunded companion project last year research humancomputer dialogue system increased much attention focused applying learning method improving key part dialogue system namely dialogue manager since dialogue manager dialogue system relies heavily quality semantic interpretation user utterance research companion project focus improve semantic interpretation combine knowledge knowledge base increase performance dialogue manager traditionally semantic interpretation user utterance handled natural language understanding module embodies variety natural language processing technique sentence splitting full parsing paper discus use variety nlu process particular information extraction key part nlu module order improve performance dialogue manager hence overall dialogue system
text classification aim mapping document set predefined category supervised machine learning model shown great success area require large number labeled document reach adequate accuracy particularly true number target category ten hundred work explore unsupervised approach classify document category simply described label proposed method inspired way human proceeds situation draw textual similarity relevant word document dictionary keywords category reflecting semantics lexical field novelty method hinge enrichment category label combination human expertise language model generic domain specific experiment standard corpus show proposed method increase fscore relying solely human expertise also par simple supervised approach thus provides practical alternative situation low cost text categorization needed illustrate application operational risk incident classification
paper study effect wordlevel linguistic annotation underresourced neural machine translation incomplete evidence literature study cover eight language pair different training corpus size two architecture three type annotation dummy tag linguistic information partofspeech tag morphosyntactic description tag consist part speech morphological feature linguistic annotation interleaved input output stream single tag placed word order measure performance scenario use automatic evaluation metric perform automatic error classification experiment show general sourcelanguage annotation helpful morphosyntactic description outperform part speech language pair contrary word annotated target language partofspeech tag systematically outperform morphosyntactic description tag term automatic evaluation metric even though use morphosyntactic description tag improves grammaticality output provide detailed analysis reason behind result
embeddings word concept capture syntactic semantic regularity language however seen limited use tool study characteristic different corpus relate one another introduce textessence interactive system designed enable comparative analysis corpus using embeddings textessence includes visual neighborbased similaritybased mode embedding analysis lightweight webbased interface propose new measure embedding confidence based nearest neighborhood overlap assist identifying highquality embeddings corpus analysis case study covid scientific literature illustrates utility system textessence found urlhttpstextessencegithubio
digital image collection library curatorial institution grow rapidly create new descriptive metadata subject matter search browsing climb computational linguistics metadata building project designed address dilemma involved computer scientist linguist librarian art librarian climb project followed iterative evaluation model next phase project emerged result evaluation assembling suite text processing tool used extracting metada conducted formative evaluation thirteen participant using survey varied order type four condition respondent would propose select image search term result formative evaluation led u conclude climb toolkit would work best main function propose term user review implementing prototype toolkit using browser interface conducted evaluation ten expert user found toolkit habitable remained consistently satisfied throughout lengthy evaluation selected large number term per image
present work towards building infrastructure documenting endangered language focus uralic language particular infrastructure consists tool write dictionary entry structured xml format dictionary foundation rulebased nlp tool fsts also work actively towards enhancing dictionary tool using latest stateoftheart neural model generating training data rule lexica
accurate estimation covariance matrix critical component many application finance including portfolio optimization sample covariance suffers curse dimensionality number observation order lower number variable tends case portfolio optimization portfolio manager choose thousand stock using historical daily return guide investment decision address issue past work proposed linear covariance shrinkage regularize estimated matrix effective proposed method relied solely historical price data thus ignored company fundamental data work propose utilise semantic similarity derived textual description knowledge graph improve covariance estimation rather using semantic similarity directly biased estimator covariance employ shrinkage target resulting covariance estimator leverage semantic similarity recent price history readily adapted broad range financial security effectiveness approach demonstrated period including diverse market condition compared covariance shrinkage prior art
study interpretability issue taskoriented dialogue system paper previously neuralbased taskoriented dialogue system employ implicit reasoning strategy make model prediction uninterpretable human obtain transparent reasoning process introduce neurosymbolic perform explicit reasoning justifies model decision reasoning chain since deriving reasoning chain requires multihop reasoning taskoriented dialogue existing neurosymbolic approach would induce error propagation due onephase design overcome propose twophase approach consists hypothesis generator reasoner first obtain multiple hypothesis ie potential operation perform desired task hypothesis generator hypothesis verified reasoner valid one selected conduct final prediction whole system trained exploiting raw textual dialogue without using reasoning chain annotation experimental study two public benchmark datasets demonstrate proposed approach achieves better result also introduces interpretable decision process
propose new largescale nearly million question ultralongcontext word average document length reading comprehension dataset using gpt summarized scene handcurated fiction book project gutenberg resulted approximately scenelevel summary per book created number reading comprehension question based summary including three type multiplechoice scene recognition question well freeform narrative reconstruction question total question dataset order magnitude larger closest alternative crucially question known retention demand indicating longterm memory needed answer aid longterm memory performance evaluation validate data four smallscale experiment one human labelers three existing language model show question adequately represent source material used diagnose model memory capacity trivial modern language model even memory demand exceed model context length lastly provide code used expand dataset minimal human labor
paper introduce dependency treebank spoken second language l english annotated part speech penn po tag syntactic dependency universal dependency evaluate degree use treebank training data affect po ud annotation accuracy l web text l written text l spoken text compared model trained l text
given document source language crosslingual summarization cl aim generating concise summary different target language unlike monolingual summarization m naturally occurring sourcelanguage document paired targetlanguage summary rare collect largescale cl data existing datasets typically involve translation creation however translated text distinguished text originally written language ie translationese paper first confirm different approach constructing cl datasets lead different degree translationese systematically investigate translationese affect cl model evaluation performance appears source document target summary detail find translationese document summary test set might lead discrepancy human judgment automatic evaluation translationese training set would harm model performance realworld application though machinetranslated document involve translationese useful building cl system lowresource language specific training strategy lastly give suggestion future cl research including dataset model development hope work could let researcher notice phenomenon translationese cl take account future
investigate problem efficiently incorporating highorder feature neural graphbased dependency parsing instead explicitly extracting highorder feature intermediate parse tree develop powerful dependency tree node representation capture highorder information concisely efficiently use graph neural network gnns learn representation discus several new configuration gnns updating aggregation function experiment ptb show parser achieves best uas la ptb among system without using external resource
adaptive training approach widely used sequencetosequence model commonly reweigh loss different target token based prior eg word frequency however consider variation learning difficulty different training step overly emphasize learning difficult onehot label making learning deterministic suboptimal response present tokenlevel selfevolution training se simple effective dynamic training method fully wisely exploit knowledge data se focus dynamically learning underexplored token forward pas adaptively regularizes training introducing novel tokenspecific label smoothing approach empirically se yield consistent significant improvement three task ie machine translation summarization grammatical error correction encouragingly achieve averaging bleu improvement three machine translation task analysis confirm besides improving lexical accuracy se enhances generation diversity model generalization
recent year witnessed increasing interest developing interpretable model natural language processing nlp existing model aim identifying input feature word phrase important model prediction neural model developed nlp however often compose word semantics hierarchical manner interpretation word phrase faithfully explain model decision text classification article proposes novel hierarchical interpretable neural text classifier called hint automatically generate explanation model prediction form labelassociated topic hierarchical manner model interpretation longer word level built topic basic semantic unit experimental result review datasets news datasets show proposed approach achieves text classification result par existing stateoftheart text classifier generates interpretation faithful model prediction better understood human interpretable neural text classifier
propose novel geolocation prediction model using complex neural network geolocation prediction social medium attracted many researcher use information various type model unifies text metadata user network representation attention mechanism overcome previous ensemble approach evaluation using two open datasets proposed model exhibited maximum increase accuracy maximum increase accuracy previous model analyzed several intermediate layer model revealed state capture statistical characteristic datasets
stateoftheart pretrained language model tend perform capability applied outofthebox task require understanding working number usually referred numeracy recent work suggests two main reason popular tokenisation algorithm limited expressiveness number common pretraining objective target numeracy approach address shortcoming usually require architectural change pretraining scratch paper propose new extended pretraining approach called arithmeticbased pretraining jointly address one extended pretraining step without requiring architectural change pretraining scratch arithmeticbased pretraining combine contrastive learning improve number representation novel extended pretraining objective called inferable number prediction task improve numeracy experiment show effectiveness arithmeticbased pretraining three different task require improved numeracy ie reading comprehension drop dataset inferenceontables infotabs dataset tabletotext generation wikibio scigen datasets
eventrelated potentialserpssecond languagelnative languagellnlpathltextgreaterlllpathltextgreaterlllthe revised hierarchical modelrhm
relation extraction task identifying semantic relation realworld entity mentioned text despite significant progress research remaining challenge concern lack training data datahungry deep learning model cost annotation difficulty task among hindrance collect largescale dataset different domain address limitation propose novel framework automatically generate labeled data framework present pretrained language model gpt data generation addition optimize generated sample model introduce meta learning approach allow gpt model updated training process particular leverage feedback model improve data generation gpt propose novel reward function update gpt model reinforce seeking promote similarity loss function gradient computed generated data meta development set conduct extensive experiment two benchmark datasets produce stateoftheart performance
model natural language understanding often rely question answering logical inference benchmark challenge evaluate performance system informative taskoriented evaluation assess broader semantic ability human part linguistic competence speaking interpreting language define competencebased cb question generation focus query lexical semantic knowledge involving implicit argument subevent structure verb present method generate question dataset english cooking recipe use implementing generation method primary experiment show even large pretrained language model perform poorly cb question provided additional contextualized semantic information data source code available http githubcombrandeisllccompqg
recent study show word embedding model often underestimate similarity similar word overestimate similarity distant word result word similarity result obtained embedding model inconsistent human judgment manifold learningbased method widely utilized refine word representation reembedding word vector original embedding space new refined semantic space method mainly focus preserving local geometry information performing weighted locally linear combination word neighbor twice however reconstruction weight easily influenced different selection neighboring word whole combination process timeconsuming paper propose two novel word representation refinement method leveraging isometry feature mapping local tangent space respectively unlike previous method first method corrects pretrained word embeddings preserving global geometry information word instead local geometry information word neighbor second method refines word representation aligning original refined embedding space based local tangent space instead performing weighted locally linear combination twice experimental result obtained standard semantic relatedness semantic similarity task show method outperform various stateoftheart baseline word representation refinement
pretrained language model bert successfully applied wide range natural language processing task also achieved impressive performance document reranking task recent work indicate pretraining language model taskspecific datasets finetuning help improve reranking performance however pretraining task like masked language model next sentence prediction based context document instead encouraging model understand content query document reranking task paper propose new selfsupervised joint training framework sjtf selfsupervised method called masked query prediction mqp establish semantic relation given query positive document framework randomly mask token query encodes masked query paired positive document us linear layer decoder predict masked token addition mqp used jointly optimize model supervised ranking objective finetuning stage without extra pretraining stage extensive experiment m marco passage ranking trec robust datasets show model trained framework obtain significant improvement compared original model
bibliographical metadata collection describing premodern object suffer incompleteness inaccuracy hamper identification literary work addition title often contain voluminous descriptive text adhere contemporary title convention paper explores several nlp approach greater textual length title leveraged enhance descriptive information
effective approach design automated question answering qa system efficiently retrieve answer precomputed database containing questionanswer pair one main challenge design lack trainingtesting data existing resource limited size topic either consider answer questionquestion similarity quality annotation process fill gap introduce novel opendomain annotated resource train evaluate model task resource consists input question question paired similar questionanswer pair resulting total annotated example binary label associated pair indicates relevance respect input question furthermore report extensive experimentation test quality property resource respect various key aspect qa system including answer relevance training strategy model input configuration
research document gender difference nonverbal behavior negotiation outcome woman tend smile often men men generally perform better economic negotiation context among nonverbal behavior smiling serve various social function rewarding appeasing others conveying dominance could therefore extremely useful economic negotiation however smiling hardly studied negotiation context examine link smiling gender negotiation outcome analyze corpus video recording participant dyad mock salary negotiation test whether woman smile men amount smiling predict economic negotiation outcome consistent existing literature woman smiled men significant relationship smiling negotiation outcome gender predict negotiation performance exploratory analysis showed expected negotiation outcome strongly correlated actual outcome tended higher men woman implication gender pay gap future research discussed
existing study tend extract sentiment element generative manner order avoid complex modeling despite effectiveness ignore importance relationship sentiment element could crucial making large pretrained generative model suboptimal modeling sentiment knowledge therefore introduce two pretraining paradigm improve generation model exploring graph pretraining targeting strengthen model capturing element relationship specifically first employ elementlevel graph pretraining paradigm designed improve structure awareness generative model design task decomposition pretraining paradigm make generative model generalizable robust various irregular sentiment quadruple extensive experiment show superiority proposed method validate correctness motivation
present system zeroshot crosslingual offensive language hate speech classification system trained english datasets tested task detecting hate speech offensive social medium content number language without additional training experiment show impressive ability model generalize english language however expected gap performance tested crosslingual model monolingual model best performing model offensive content classifier available online rest api
word embedding essential neural network model various natural language processing task since word embedding usually considerable size order deploy neural network model edge device effectively compressed study proposing blockwise lowrank approximation method word embedding called groupreduce even structure effective property behind concept blockwise word embedding compression sufficiently explored motivated improve groupreduce term word weighting structuring word weighting propose simple yet effective method inspired term frequencyinverse document frequency method novel differentiable method based construct discriminative word embedding compression algorithm experiment demonstrate proposed algorithm effectively find word weight competitor case addition show proposed algorithm act like framework successful cooperation quantization
much work gone developing language model increasing size recently begun examine pernicious behaviour could lead harming marginalised group following lin et al rooting work psychological research prompt two masked language model mlms different specialisation english spanish statement questionnaire developed measure stigma determine treat physical mental illness equally model find statistically significant difference treatment physical mental illness across latent construct measured questionnaire thus likely associate mental illness stigma examine training data data retrieved domain using computational implementation stereotype content model scm fiske et al fraser et al interpret questionnaire result based scm value reflected data observe model behaviour largely explained distribution mention illness according scm value
paper discus submission dialdoc subtask subtask requires system extract knowledge faqtype document vital reply user query conversational setting experiment pretraining bertbased questionanswering model different qa datasets mrqa well conversational qa datasets like coqa quac result show model pretrained coqa quac perform better counterpart pretrained mrqa datasets result also indicate adding pretraining data necessarily result improved performance final model ensemble albertxl pretrained coqa quac independently chosen answer highest average probability score achieves fscore official testset
proactively offer social medium user safe online experience need system detect harmful post promptly alert platform moderator order guarantee enforcement consistent policy moderator provided detailed guideline contrast stateoftheart model learn abuse labeled example result base prediction spurious cue presence group identifier unreliable work introduce concept policyaware abuse detection abandoning unrealistic expectation system reliably learn phenomenon constitute abuse inspecting data alone propose machinefriendly representation policy moderator wish enforce breaking collection intent slot collect annotate dataset english post slot show architecture intent classification slot filling used abuse detection providing rationale model decision
paper describes neural machine translation system iiithyderabad gujaratienglish news translation shared task wmt system basedon encoderdecoder framework attention mechanism experimented multilingual neural mt model experiment show multilingual neural machine translation leveraging parallel data related language pair help significant bleu improvement upto low resource language pair like gujaratienglish
social medium provides timely yet challenging data source adverse drug reaction adr detection existing dictionarybased semisupervised learning approach intrinsically limited coverage maintainability layman health vocabulary paper introduce data augmentation approach leverage variational autoencoders learn highquality data distribution large unlabeled dataset subsequently automatically generate large labeled training set small set labeled sample allows efficient socialmedia adr detection low training retraining cost adapt change emergence informal medical layman term extensive evaluation performed twitter reddit data show approach match performance fullysupervised approach requiring training data
demonstrate deployed conversational ai system act host smartbuilding university campus system combine opendomain social conversation taskbased conversation regarding navigation building live resource update eg available computer event building able demonstrate system several platform google home device android phone furhat robot
text speech corpus training tale telling robot designed recorded annotated aim corpus study expressive storytelling behaviour help designing expressive prosodic coverbal variation artificial storyteller set child tale french serf basis work tale annotation principle scheme described together corpus description term coverage interannotator agreement automatic analysis new tale help corpus machine learning discussed metric evaluation automatic annotation method discussed speech corpus hour tale recorded aligned annotated corpus used predicting expressive prosody child tale level sentence
abstract meaning representation amr shown useful many downstream task work explore use amr legal logical reasoning specifically investigate amr help capture logical relationship multiple choice question answering mcqa task propose neural architecture utilize linearised amr graph combination pretrained language model model able outperform textonly baseline correctly solve different instance text model suggesting complementary ability error analysis reveals amr parsing quality prominent challenge especially regarding input multiple sentence conduct theoretical analysis logical relation represented amr conclude might helpful logical statement others
risk prediction essential task financial market merger acquisition call provide key insight claim made company executive restructuring financial firm extracting vocal textual cue call help model risk associated financial activity aid analysis call curate dataset conference call transcript corresponding audio recording time period ranging introduce manet baseline architecture take advantage multimodal multispeaker input forecast financial risk associated call empirical result prove task challenging proposed architecture performing marginally better strong bertbased baseline release dataset benchmark model motivate future research challenging problem domain
many data set eg review forum news etc exist parallelly multiple language cover content linguistic difference make impossible use traditional bagofwordbased topic model model either singlelanguage suffer huge extremely sparse vocabulary issue addressed transfer learning paper introduce zeroshot crosslingual topic model model learns topic one language english predicts unseen document different language italian french german portuguese evaluate quality topic prediction document different language result show transferred topic coherent stable across language suggests exciting future research direction
emotion processing always great challenge given fact emotion triggered cause event cause event integral part emotion paper construct chinese emotion cause corpus first step towards automatic inference causeemotion correlation corpus focus five primary emotion namely happiness sadness fear anger surprise annotated emotion cause event based proposed annotation scheme corpus data show emotion expressed cause cause mostly occur corresponding emotion verb also examine correlation emotion cause event term linguistic cue causative verb perception verb epistemic marker conjunction preposition others result show group linguistic cue serf indicator marking cause event different structure emotional construction believe emotion cause corpus useful resource automatic emotion cause detection well emotion detection classification
present clireval easytouse toolkit evaluating machine translation mt proxy task crosslingual information retrieval clir contrary project name might suggest clireval actually require annotated clir dataset instead automatically transforms translation reference used mt evaluation synthetic clir dataset set standard search engine elasticsearch computes various information retrieval metric eg mean average precision treating translation document retrieved idea gauge quality mt impact document translation approach clir case study run clireval metric shared task wmt extrinsic metric intended replace popular intrinsic metric bleu result suggest clireval competitive many language pair term correlation human judgment quality clireval publicly available urlhttpsgithubcomssunclireval
recent year witnessed proliferation offensive content online fake news propaganda misinformation disinformation initially mostly textual content time image video gained popularity much easier consume attract attention spread text result researcher started leveraging different modality combination thereof tackle online multimodal offensive content study offer survey stateoftheart multimodal disinformation detection covering various combination modality text image speech video social medium network structure temporal information moreover study focused factuality others investigated harmful content two component definition disinformation factuality ii harmfulness equally important typically studied isolation thus argue need tackle disinformation detection taking account multiple modality well factuality harmfulness framework finally discus current challenge future research direction
current paper explores use multiview learning search result clustering websnippet represented using multiple view apart textual view cued semantic syntactic information complimentary view extracted image contained websnippets also utilized current framework single consensus partitioning finally obtained consulting two individual view deployment multiobjective based clustering technique several objective function including value cluster quality measure measuring goodness partitioning obtained using different view agreementdisagreement index quantifying amount oneness among multiple view generating partitioning optimized simultaneously using amosa order detect number cluster automatically concept variable length solution vast range permutation operator introduced clustering process finally set alternative partitioning obtained final pareto front proposed multiview based multiobjective technique experimental result proposed approach several benchmark test datasets src respect different performance metric evidently establish power visual textbased view achieving better search result clustering
depression become common health problem impacting million individual globally workplace stress unhealthy lifestyle increased recent year leading increase number people experiencing depressive symptom spread epidemic exacerbated problem early detection precise prediction depression critical early intervention support individual risk however due social stigma associated illness many people afraid consult healthcare specialist making early detection practically impossible result alternative strategy depression prediction investigated one analyzing user social medium posting behaviour organizer ltediranlp carried shared task encourage research area team participated shared task secured st rank macro f score f article provides summary model presented shared task
many parallel corpus publicly accessible data copyright data privacy competitive differentiation reason trained translation model increasingly available open platform work propose method called continual knowledge distillation take advantage existing translation model improve one model interest basic idea sequentially transfer knowledge trained model distilled model extensive experiment chineseenglish germanenglish datasets show method achieves significant consistent improvement strong baseline homogeneous heterogeneous trained model setting robust malicious model
human gaze data offer cognitive information reflects natural language comprehension indeed augmenting language model human scanpaths proven beneficial range nlp task including language understanding however applicability approach hampered abundance text corpus contrasted scarcity gaze data although model generation humanlike scanpaths reading developed potential synthetic gaze data across nlp task remains largely unexplored develop model integrates synthetic scanpath generation scanpathaugmented language model eliminating need human gaze data since model error gradient propagated throughout part model scanpath generator finetuned downstream task find proposed model outperforms underlying language model achieves performance comparable language model augmented real human gaze data code publicly available
typologically diverse benchmark increasingly created track progress achieved multilingual nlp linguistic diversity data set typically measured number language language family included sample measure consider structural property included language paper propose assessing linguistic diversity data set reference language sample mean maximising linguistic diversity long run represent language set feature apply version jaccard index suitable comparing set measure addition feature extracted typological data base propose automatic textbased measure used mean overcoming wellknown problem data sparsity manually collected feature diversity score interpretable term linguistic feature identify type language represented data set using method analyse range popular multilingual data set ud bible mbert xtreme xglue xnli xcopa tydiqa xquad addition ranking data set find example polysynthetic language missing almost
context paper translator wishing develop dictionary purpose machineaided translation mat description given way lexical item running text statistically patterned depending whether socalled type left unaltered extracted text whether immediately mapped onto corresponding dictionary lookup form lemma purpose statistical analysis obvious course translation purpose necessary establish appropriate entrypoints mat dictionary secondary problem two dimension assist machineassisted translator considerable extent one factor degree homogeneity greater better text wish process translator specialising certain subject area type discourse advantage wish use mat system second factor socalled multiword unit although language multiword unit semantically atomic particularly important english even english technical terminology frequency study multiword unit although generate large listing type useful mat machineassisted translator faced need view work consisting two distinct mode dictionary elaboration text transaction second mode course provides important feedback guide first one thing clear translator must lexicographer great extent least time software house realise commercial value static data general bilingual highfrequency dictionary ana potential constellation carefully designed delineated bilingual glossary technical terminology
polarization continues rise among public news medium increasing attention devoted detecting medium bias recent work nlp community however identify bias level individual article however article comprises multiple sentence vary ideological bias paper aim identify sentence within article illuminate explain overall bias entire article show understanding discourse role sentence telling news story well relation nearby sentence reveal ideological leaning author even sentence appears merely neutral particular consider using functional news discourse structure pdtb discourse relation inform bias sentence identification distill auxiliary knowledge two type discourse structure bias sentence identification system experimental result benchmark datasets show incorporating global functional discourse structure local rhetorical discourse relation effectively increase recall bias sentence identification well increase precision
parallel corpus key developing good machine translation system however abundant parallel data hard come especially language low number speaker rich morphology exacerbates data sparsity problem imperative accurate alignment filtering method help make available maximising number correctly translated segment corpus minimising noise removing incorrect translation segment containing extraneous data paper set research plan improving alignment filtering method parallel text lowresource setting propose effective unsupervised alignment method tackle alignment problem moreover propose strategy supplement stateoftheart model automatically extracted information using basic nlp tool effectively handle rich morphology
contextaware neural machine translation nmt incorporates contextual information surrounding text improve translation quality documentlevel machine translation many existing work contextaware nmt focused developing new model architecture incorporating additional context shown promising result however existing work rely crossentropy loss resulting limited use contextual information paper propose corefcl novel data augmentation contrastive learning scheme based coreference source contextual sentence corrupting automatically detected coreference mention contextual sentence corefcl train model sensitive coreference inconsistency experimented method common contextaware nmt model two documentlevel translation task experiment method consistently improved bleu compared model englishgerman englishkorean task also show method significantly improves coreference resolution englishgerman contrastive test suite
propose unsupervised approach sarcasm generation based nonsarcastic input sentence method employ retrieveandedit framework instantiate two major characteristic sarcasm reversal valence semantic incongruity context could include shared commonsense world knowledge speaker listener prior work sarcasm generation predominantly focus context incongruity show combining valence reversal semantic incongruity based commonsense knowledge generates sarcasm higher quality human evaluation show system generates sarcasm better human time better reinforced hybrid baseline time
age social news important understand type reaction evoked news source various level credibility present work seek better understand user react trusted deceptive news source across two popular different social medium platform end develop model classify user reaction one nine type answer elaboration question etc measure speed type reaction trusted deceptive news source twitter post reddit comment show significant difference speed type reaction trusted deceptive news source twitter far smaller difference reddit
paper present wikipediabased approach develop resource legal domain establish mapping legal domain ontology lkif hoekstra et al wikipediabased ontology yago suchanek et al populate lkif moreover use mention entity wikipedia text train specific named entity recognizer classifier find classifier work well wikipedia could expected performance decrease corpus judgment european court human right however tool used preprocess human annotation resort technique called curriculum learning aimed overcome problem overfitting learning increasingly complex concept however find particular setting method work best learning specific general concept way round
paper present method constructing specific type language resource conveniently applicable analysis trending topic timeannotated textual data specifically method consists building cooccurrence network online content new york time article conform key word selected user eg arab spring within network burstiness particular node key word edge cooccurrence relation computed service deployed network facilitates exploration underlying text order identify trending topic using graph structure network one assess also broader context trending event limit information overload user filter edge node displayed burstiness score show presumably important one paper give detail proposed method including stepbystep walk plenty real data example report specific application method topic arab spring make language resource applied therein publicly available experimentation last least outline methodology ongoing evaluation method
investigate issue arise process developing universal dependency ud treebank korean japanese begin addressing typological characteristic korean japanese korean japanese agglutinative headfinal language principle word segmentation language different english make difficult apply ud guideline following typological characteristic two language issue ud application review application upos deprel scheme two language annotation principle aux adj det adp part discussed upos scheme annotation principle case aux iobj obl discussed deprel scheme
conducting coordinated set repeat run human evaluation experiment nlp discovered flaw every single experiment selected inclusion via systematic process squib describe type flaw discovered include coding error eg loading wrong system output evaluate failure follow standard scientific practice eg ad hoc exclusion participant response mistake reported numerical result eg reported number matching experimental data problem widespread would worrying implication rigor nlp evaluation experiment currently conducted discus researcher reduce occurrence flaw including preregistration better code development practice increased testing piloting postpublication addressing error
recent advancement natural language processing large language model llm gpt suggested approach artificial general intelligence yet still dispute whether llm possess similar reasoning ability human study evaluates gpt various llm judging profoundness mundane motivational pseudoprofound statement found significant statementtostatement correlation llm human irrespective type statement prompting technique used however llm systematically overestimate profoundness nonsensical statement exception tkinstruct uniquely underestimate profoundness statement fewshot learning prompt opposed chainofthought prompting draw llm rating closer human furthermore work provides insight potential bias induced reinforcement learning human feedback rlhf inducing increase bias overestimate profoundness statement
trained model automatically transliterate judeoarabic text arabic script enabling arabic reader access writing employ recurrent neural network rnn combined connectionist temporal classification ctc loss deal unequal inputoutput length obligates adjustment training data avoid input sequence shorter corresponding output also utilize pretraining stage different loss function improve network converge since single source parallel text available training take advantage possibility generating data synthetically train model capability memorize word output language also utilizes context distinguishing ambiguity transliteration obtain improvement baseline character error achieving error best configuration measure contribution context learning also tested wordshuffled data error rise
introduce synthetic dialogue generation framework velocidapter address corpus availability problem dialogue comprehension velocidapter augments datasets simulating synthetic conversation taskoriented dialogue domain requiring small amount bootstrapping work new domain evaluate efficacy framework taskoriented dialogue comprehension dataset mrcwoz curate annotating question slot restaurant taxi hotel domain multiwoz dataset zang et al run experiment within lowresource setting pretrain model squad finetuning either small original data synthetic data generated framework velocidapter show significant improvement using transformerbased bertbase bidaf base model show framework easy use novice user conclude velocidapter greatly help training taskoriented dialogue especially lowresourced emerging domain
neurosymbolic n model knowledge graph completion kgc combine benefit symbolic model interpretable inference distributed representation parameter sharing high accuracy several n model exist kg static fact limited work temporal kgc tkgc kg fact associated time interval response propose novel n model tkgc called neustip performs link prediction time interval prediction tkg neustip learns temporal rule allen predicate ensure temporal consistency neighboring predicate rule body design unique scoring function evaluates confidence candidate answer performing link time interval prediction utilizing learned rule empirical evaluation two time interval based tkgc datasets show model show competitive performance link prediction establishes new state art time prediction
paper describes creation process statistic official united nation parallel corpus first parallel corpus composed united nation document published original data creator parallel corpus presented consists manually translated un document last year six official un language arabic chinese english french russian spanish corpus freely available download liberal license apart pairwise aligned document fully aligned subcorpus six official un language distributed provide baseline bleu score mosesbased smt system trained full data language pair involving english possible translation direction sixway subcorpus
model increasing size complexity hunt sota increase performance make difference production use case maybe benefit smaller faster model outweigh slight performance gain also equally good performance across language multilingual task important sota result single one present biggest unified multilingual collection sentiment analysis datasets use assess model highquality sentiment datasets raw datasets collected language included result internally annotated datasets deeply evaluate multiple setup including finetuning transformerbased model measuring performance compare result numerous dimension addressing imbalance language coverage dataset size finally present best practice working massive collection datasets model multilingual perspective
previous work mainly focus improving crosslingual transfer nlu task multilingual pretrained encoder mpe improving performance supervised machine translation bert however underexplored whether mpe help facilitate crosslingual transferability nmt model paper focus zeroshot crosslingual transfer task nmt task nmt model trained parallel dataset one language pair offtheshelf mpe directly tested zeroshot language pair propose sixt simple yet effective model task sixt leverage mpe twostage training schedule get improvement position disentangled encoder capacityenhanced decoder using method sixt significantly outperforms mbart pretrained multilingual encoderdecoder model explicitly designed nmt average improvement bleu zeroshot anytoenglish test set across source language furthermore much less training computation cost training data model achieves better performance anytoenglish test set criss mm two strong multilingual nmt baseline
abstract meaning representation amr sentencelevel meaning representation based predicate argument structure one challenge find amr parsing capture structure complex sentence express relation predicate knowing core part sentence structure advance may beneficial task paper present list dependency pattern english complex sentence construction designed amr parsing dedicated pattern matcher occurrence complex sentence construction retrieved input sentence subordinators semantic ambiguity deal problem training classification model data derived amr wikipedia corpus establishing new baseline future work developed complex sentence pattern corresponding amr description made public
textitauthorship analysis also known stylometry essential aspect natural language processing nlp long time likewise recent advancement large language model llm made authorship analysis increasingly crucial distinguishing humanwritten aigenerated text however authorship analysis task primarily focused textitwritten text considering textitspoken text thus introduce largest benchmark spoken text sf hansenunderlinehuman underlineand ai underlinespoken tunderlineext beunderlinenchmark sf hansen encompasses meticulous curation existing speech datasets accompanied transcript alongside creation novel aigenerated spoken text datasets together comprises human datasets aigenerated spoken text created using prominent llm chatgpt palm vicunab evaluate demonstrate utility sf hansen perform authorship attribution aa author verification av humanspoken datasets conducted human v ai text detection using stateoftheart sota model sota method character ngram transformerbased model exhibit similar aa av performance humanspoken datasets compared written one much room improvement aigenerated spoken text detection sf hansen benchmark available httpshuggingfacecodatasetshansenrepohansen
paper describe attempt reproduce single human evaluation quality criterion human evaluation conducted paper neuralreg endtoend approach referring expression generation particular paper describes approach challenge involved reproducing human evaluation done original author paper result obtained insight gained attempting particular reproduction insight hope enable refinement human evaluation documented author enable better reproduction nlp experiment future
human learn multiple language know fact one language answer question another language understand also answer codemix cm question question contain language behavior attributed unique learning ability human task aim study machine achieve demonstrate effectively machine answer cm question work adopt two phase approach candidate generation candidate reranking answer question propose tripletsiamesehybrid cnn tshcnn rerank candidate answer show experiment simplequestions dataset network trained english question provided dataset noisy hindi translation question answer englishhindi cm question effectively without need translation english backtransliterated cm question outperform lexical sentence level translated counterpart accuracy respectively highlighting efficacy approach resource constrained setting
answer sentence ranking answer extraction two key challenge question answering traditionally treated isolation ie independent task article explain task related core common quantity propose simple intuitive joint probabilistic model address via joint computation taskspecific application quantity experiment two trec datasets joint model substantially outperforms stateoftheart system task
provide overview mslr shared task multidocument summarization literature review shared task hosted third scholarly document processing sdp workshop coling task provided data consisting gold summary extracted review paper along group input abstract synthesized summary split two subtasks total six team participated making public submission cochrane subtask m subtask top scoring system reported point rougel improvement cochrane subtask though performance improvement consistently reported across automated evaluation metric qualitative examination result also suggests inadequacy current evaluation metric capturing factuality consistency task significant work needed improve system performance importantly develop better method automatically evaluating performance task
present first rulebased l grammar checker lule sami releasing lule sami grammar checker direct consequence language revitalization primary intention therefore support language user writing confidence use language release version tool m word googledocs corrects six grammatical error type benefit user selection error type based frequency error quality tool successful error correction phonetically syntactically motivated copula error reach precision
paper present approach tosemeval task shroom sharedtask hallucination related observableovergeneration mistake aim determine weather ai generated text semanticallycorrect incorrect work comparative study large language model llmsin context task shedding light ontheir effectiveness nuance present asystem leverage pretrained llm suchas labse distiluse binary classification given sentence hallucinationor hallucination class evaluatingthe model output reference correct text moreover beyond utilizing labeleddatasets methodology integrates syntheticlabel creation unlabeled datasets followedby prediction test label
much biomedical healthcare data encoded discrete symbolic form text medical code wealth expertcurated biomedical domain knowledge stored knowledge base ontology lack reliable method learning knowledge representation limited usefulness machine learning application textbased representation learning significantly improved recent year advance natural language processing attempt learn biomedical concept embeddings far lacking recent family model called knowledge graph embeddings shown promising result general domain knowledge graph explore capability biomedical domain train several stateoftheart knowledge graph embedding model snomedct knowledge graph provide benchmark comparison existing method indepth discussion best practice make case importance leveraging multirelational nature knowledge graph learning biomedical knowledge representation embeddings code material made available community
explorative study tested laurea uas student n ability verbalize skill study unit digital analytics consumer insight study unit student listed skill unaided afterwards help careerbot ai service finding indicate intervention increased quantity quality skill verbalized relevant learning objective generic st century skill
construct linguistic complexity widely used language learning research several text analysis tool created automatically analyze linguistic complexity however index supported several existing chinese text analysis tool limited different different research purpose ctap opensource linguistic complexity measurement extraction tool prompt research purpose although originally developed english unstructured information management uima framework used allows integration language study integrated chinese component ctap describing index set incorporated comparing three linguistic complexity tool chinese index set includes four level linguistic complexity index character level word level sentence level discourse level far ctap implemented automatic calculation complexity characteristic four language aiming help linguist without nlp background study language complexity
pretrained language model making profound impact life ever exhibit promising performance variety general domain natural language processing nlp task however work focus chinese financial nlp task comprisea significant portion social communication end propose finbart pretrainedseqseq language model chinese financial communication task experiment show thatfinbart outperforms baseline model series downstream task including text classification sequence labeling text generation pretrain model customer servicecorpora result show model outperforms baseline model achieves promisingperformance various real world customer service text mining task
existing approach knowledge base question answering kbqa focus specific underlying knowledge base either inherent assumption approach evaluating different knowledge base requires nontrivial change however many popular knowledge base share similarity underlying schema leveraged facilitate generalization across knowledge base achieve generalization introduce kbqa framework based stage architecture explicitly separate semantic parsing knowledge base interaction facilitating transfer learning across datasets knowledge graph show pretraining datasets different underlying knowledge base nevertheless provide significant performance gain reduce sample complexity approach achieves comparable stateoftheart performance lcquad dbpedia webqsp freebase simplequestions wikidata metaqa wikimovieskg
investigate kind structural knowledge learned neural network encoders transferable processing natural language design textitartificial language structural property mimic natural language pretrain encoders data see much performance encoder exhibit downstream task natural languageour experimental result show pretraining artificial language nesting dependency structure provides knowledge transferable natural languagea followup probing analysis indicates success transfer related amount encoded contextual information transferred knowledge textitpositionaware context dependence languageour result provide insight neural network encoders process human language source crosslingual transferability recent multilingual language model
describe system semeval task semantic textual relatedness investigate correlation semantic relatedness semantic similarity specifically test two hypothesis similarity special case relatedness semantic relatedness preserved translation experiment variety approach based explicit semantics downstream application contextual embeddings large language model llm well ensemble method find empirical support theoretical insight addition best ensemble system yield highly competitive result number diverse category code data available github
semantic relation often signaled prepositional possessive markingbut extreme polysemy bedevils analysis automatic interpretation introduce new annotation scheme corpus task disambiguation preposition possessive english unlike previous approach annotation comprehensive respect type token marker use broadly applicable supersense class rather finegrained dictionary definition unite preposition possessive class inventory distinguish marker lexical contribution role mark context predicate scene strong interannotator agreement rate well encouraging disambiguation result established supervised method speak viability scheme task
multilingual language model improve nlp performance lowresource language leveraging higherresource language also reduce average performance language curse multilinguality show another problem multilingual model grammatical structure higherresource language bleed lowerresource language phenomenon call grammatical structure bias show bias via novel method comparing fluency multilingual model fluency monolingual spanish greek model testing preference two carefullychosen variable grammatical structure optional pronoundrop spanish optional subjectverb ordering greek find multilingual bert biased toward englishlike setting explicit pronoun subjectverbobject ordering default spanish gerek setting compared monolingual control language model case study hope bring light finegrained way multilingual model biased encourage linguisticallyaware fluency evaluation
automatically analyzing event large amount text crucial situation awareness decision making previous approach treat event extraction one size fit ontology defined priori resulted extraction model built extracting type ontology approach easily adapted new event type new domain interest accommodate personalized eventcentric information need paper introduces fewshot event mention retrieval emr task given usersupplied query consisting handful event mention return relevant event mention found corpus formulation enables query example drastically lower bar specifying eventcentric information need retrieval setting also enables fuzzy search present evaluation framework leveraging existing event datasets ace also develop siamese network approach show performs better adhoc retrieval model fewshot emr setting
paper describes approach semeval semantic textual similarity multilingual word similarity task former test approach english spanish use linguisticallyrich set feature move lexical semantic feature particular try take advantage recent abstract meaning representation smatch measure although without state art result introduce semantic structure textual similarity analyze impact regarding word similarity target english language combine wordnet information word embeddings without matching best system approach proved simple effective
previous research argumentation online discussion largely focused examining individual comment neglected interactive nature discussion line previous work represent individual comment sequence semantic argumentative unit type however intuitively necessary dialogical argumentation address opposing viewpoint extend model clustering type sequence different argument arrangement pattern representing discussion sequence pattern sequence pattern symbolic representation argumentation strategy capture overall structure discussion using novel approach conduct indepth analysis strategy discussion online discussion forum change view show discussion model effective persuasiveness prediction outperforming llmbased classifier data result provide valuable insight argumentation dynamic online discussion presented prediction procedure practical importance writing assistance persuasive text generation system
neural language model including transformerbased model pretrained large corpus became common way represent text various task including recognition textual semantic relation eg crossdocument structure theory pretrained model usually fine tuned downstream task obtained vector used input deep neural classifier linguistic knowledge obtained resource tool utilised paper compare universal approach combination rich graphbased linguistically motivated sentence representation typical neural network classifier applied task recognition cst relation polish representation describes selected level sentence structure including description lexical meaning basis wordnet plwordnet synset connected sumo concept obtained result show case difficult relation medium size training corpus semantically enriched text representation lead significantly better result
modeling hypernymy poodle isa dog important generalization aid many nlp task entailment relation extraction question answering supervised learning labeled hypernym source wordnet limit coverage model addressed learning hypernym unlabeled text existing unsupervised method either scale large vocabulary yield unacceptably poor accuracy paper introduces distributional inclusion vector embedding dive simpletoimplement unsupervised method hypernym discovery via perword nonnegative vector embeddings preserve inclusion property word context experimental evaluation comprehensive previous literature awareevaluating datasets using multiple existing well newly proposed scoring functionswe find method provides double precision previous unsupervised method highest average performance using much compact word representation yielding many new stateoftheart result
linguistic data consortium ldc created various annotated linguistic data variety common task evaluation program project create shared linguistic resource majority annotated linguistic data created highly customized annotation tool developed ldc annotation graph toolkit agtk used primary infrastructure annotation tool development ldc recent year thanks direct feedback annotation task designer annotator inhouse annotation tool development ldc entered new mature productive phase paper describes recent addition ldcs annotation tool newly developed significantly improved since last report fourth international conference language resource evaluation conference tool either directly based agtk share common philosophy agtk tool
extractive summarization aim select set salient sentence source document form summary context information considered one key factor task meanwhile also exist pattern factor identify sentence importance sentence position certain ngram token however pattern information effective specific datasets domain generalized like context information exists limited data case current extractive summarization model may suffer performance drop transferring new dataset paper attempt apply disentangled representation learning extractive summarization separate two key factor task context pattern better generalization ability lowresource setting achieve propose two group loss encoding disentangling sentence representation context representation pattern representation case either use context information zeroshot setting finetune pattern information fewshot setting experimental result three summarization datasets different domain show effectiveness proposed approach
largescale pretrained language model significantly improved writing assistance functionality autocomplete complex controllable writing assistant yet explored leverage advance language modeling build interactive writing assistant generates rephrases text according finegrained author specification user provide input intentguided assistant iga form text interspersed tag correspond specific rhetorical directive eg adding description contrast rephrasing particular sentence finetune language model dataset heuristicallylabeled author intent allows iga fill tag generated text user subsequently edit liking series automatic crowdsourced evaluation confirm quality iga generated output smallscale user study demonstrates author preference iga baseline method creative writing task release dataset code demo spur research aiassisted writing
application textual entailment plagiarism detection document clustering rely notion semantic similarity usually approached dimension reduction technique like lda embeddingbased neural approach present scenario semantic similarity enough devise neural approach learn semantic relatedness scenario text spotting wild text image eg street sign advertisement bus destination must identified recognized goal improve performance vision system leveraging semantic information rationale text spotted often related image context appears word pair deltaairplane quartersparking similar clearly related show learning wordtoword wordtosentence relatedness score improve performance text spotting system point outperforming measure benchmark dataset
present evaluation pas datatotext system generates dutch soccer report match statistic automatically tailored towards fan one club evaluation paper consists two study intrinsic humanbased evaluation system output described first study study found compared humanwritten text computergenerated text rated slightly lower stylerelated text component fluency clarity slightly higher term correctness given information furthermore result first study showed tailoring accurately recognized case participant struggled correctly identifying whether text written human computer second study investigated tailoring affect perceived text quality result garnered lack result might due negative preconception computergenerated text found first study
paper present adaio team system entry building educational application bea shared task generating ai teacher response educational dialogue task aim assess performance stateoftheart generative model ai teacher producing suitable response within studentteacher dialogue system comprises evaluating various baseline model using openai gpt designing diverse prompt prompt openai model teacher response generation challenge system achieved second place employing fewshot promptbased approach openai textdavinci model result highlight fewshot learning capability largelanguage model particularly openais gpt role ai teacher
crucial step extractive document summarization learning crosssentence relation explored plethora approach intuitive way put graphbased neural network complex structure capturing intersentence relationship paper present heterogeneous graphbased neural network extractive summarization hetersumgraph contains semantic node different granularity level apart sentence additional node act intermediary sentence enrich crosssentence relation besides graph structure flexible natural extension singledocument setting multidocument via introducing document node knowledge first one introduce different type node graphbased neural network extractive document summarization perform comprehensive qualitative analysis investigate benefit code released github
paper address epistemological ethical break perspectivism nlp first propose consider data annotation point view scientific management annotation work part automation process inherent nlp order ideologically situate perspectivist paradigm analyze concept perspectivism particular truth finally based analysis formulate set proposal aimed overcoming observed limitation corpus annotation general perspectivism particular
present attractrepel algorithm improving semantic quality word vector injecting constraint extracted lexical resource attractrepel facilitates use constraint mono crosslingual resource yielding semantically specialized crosslingual vector space evaluation show method make use existing crosslingual lexicon construct highquality vector space plethora different language facilitating semantic transfer high lowerresource one effectiveness approach demonstrated stateoftheart result semantic similarity datasets six language next show attractrepelspecialized vector boost performance downstream task dialogue state tracking dst across multiple language finally show crosslingual vector space produced algorithm facilitate training multilingual dst model brings performance improvement
present experiment word segmentation akkadian cuneiform ancient writing system language used millennium ancient near east best knowledge first study kind applied either akkadian language cuneiform writing system logosyllabic writing system cuneiform structurally resembles eastern asian writing system employ word segmentation algorithm originally developed chinese japanese describe result rulebased algorithm dictionarybased algorithm statistical machine learning approach result may indicate possible promising step cuneiform word segmentation create improve natural language processing area
text simplification process reducing lexical syntactic complexity text attempting preserve information content recently emerged important research area hold promise enhancing text readability benefit broader audience well increasing performance application work focus syntactic complexity reduction deal task corpusbased acquisition syntactic simplification rule french language show datadriven manual acquisition simplification rule complemented semiautomatic detection syntactic construction requiring simplification provide first comprehensive set syntactic simplification rule french whose size comparable similar resource exist english brazilian portuguese unlike manuallybuilt resource resource integrates larger list lexical cue signaling simplifiable construction useful informing practical system
paper present novel method nested named entity recognition layered method method extends prior secondbest path recognition method explicitly excluding influence best path method maintains set hidden state time step selectively leverage build different potential function recognition level addition demonstrate recognizing innermost entity first result better performance conventional outermost entity first scheme provide extensive experimental result ace ace genia datasets show effectiveness efficiency proposed method
paper proposes semantics ab modeltheoretic interpretation annotation structure provides language absr represents textitsemantic form possibly lambdafree typetheoretic firstorder logic semantic compositionality representation language introduces two operator oplus oslash subtypes conjunctive distributive composition semantic form ab also introduces small set logical predicate represent semantic form simplified format use absr illustrated annotation structure conform iso standard semantic annotation isotimeml isospace
conventional success textual classification relies annotated data new paradigm pretrained language model plms still requires labeled data downstream task however realworld application label noise inevitably exists training data damaging effectiveness robustness generalization model constructed data recently remarkable achievement made mitigate dilemma visual data explore textual data fill gap present selfmix simple yet effective method handle label noise text classification task selfmix us gaussian mixture model separate sample leverage semisupervised learning unlike previous work requiring multiple model method utilizes dropout mechanism single model reduce confirmation bias selftraining introduces textual level mixup training strategy experimental result three text classification benchmark different type text show performance proposed method outperforms strong baseline designed textual visual data different noise ratio noise type anonymous code available urlhttpsgithubcomnoiselearningselfmix
paper describes hypernym discovery system participation semeval task aim discover best set candidate hypernym input concept entity given search space predefined vocabulary introduce neural network architecture concerned task empirically study various neural network model build representation latent space word phrase evaluated model include convolutional neural network longshort term memory network gated recurrent unit recurrent convolutional neural network also explore different embedding method including word embedding sense embedding better performance
goal metalearning learn adapt new task labeled example inspired recent progress large language model propose textitincontext tuning ict recasts task adaptation prediction simple sequence prediction problem form input sequence concatenate task instruction labeled incontext example target input predict metatrain model learn incontext example finetune pretrained language model lm predict target label given input sequence collection taskswe benchmark method two collection text classification task lama binaryclfs compared maml adapts model gradient descent method leverage inductive bias pretrained lm perform pattern matching outperforms maml absolute average aucroc score binaryclfs gaining advantage increasing model size compared nonfinetuned incontext learning ie prompting raw lm incontext tuning metatrains model learn incontext example binaryclfs ict improves average aucroc score absolute reduces variance due example ordering x example choice x
recent work training neural retriever opendomain question answering openqa employed supervised unsupervised approach however remains unclear unsupervised supervised method used effectively neural retriever work systematically study retriever pretraining first propose approach unsupervised pretraining inverse cloze task masked salient span followed supervised finetuning using questioncontext pair approach lead absolute gain point previous best result top retrieval accuracy natural question triviaqa datasets next explore two approach endtoend training reader retriever component openqa model differ manner reader ingests retrieved document experiment demonstrate effectiveness approach obtain stateoftheart result natural question dataset obtain top retrieval accuracy improvement point recent dpr model also achieve good result answer extraction outperforming recent model like realm rag point
technology enhancing wellbeing healthcare vigilance monitoring rise however despite patient interest technology suffer low adoption one hypothesis limited adoption loss human interaction central doctorpatient encounter paper seek address limitation via conversational agent adopts one aspect inperson doctorpatient interaction human avatar facilitate medical grounded question answering akin inperson scenario doctor may point human body patient may point body express condition additionally agent multiple interaction mode may give option patient use agent medical question answering also engage conversation general topic current event avatar multiple interaction mode could help improve adherence present high level overview design agent marie bot wellbeing also report implementation detail early prototype present preliminary result
observing damage done rapid propagation fake news various sector like politics finance automatic identification fake news using linguistic analysis drawn attention research community however method largely developed english low resource language remain focus risk spawned fake manipulative news confined language work propose annotated dataset mboxapprox k news used building automated fake news detection system low resource language like bangla additionally provide analysis dataset develop benchmark system state art nlp technique identify bangla fake news create system explore traditional linguistic feature neural network based method expect dataset valuable resource building technology prevent spreading fake news contribute research low resource language dataset source code publicly available urlhttpsgithubcomrowanfakenews
one basic task computational language documentation cld identify word boundary unsegmented phonemic stream several unsupervised monolingual word segmentation algorithm exist literature challenged realworld cld setting small amount available data possible remedy take advantage gloss translation foreign well resourced language often exist data paper explore compare way exploit neural machine translation model perform unsupervised boundary detection bilingual information notably introducing new loss function jointly learning alignment segmentation experiment actual underresourced language mboshi show technique effectively control output segmentation length
term extensively exist specific domain term translation play critical role domainspecific machine translation mt task however challenging task translate correctly huge number preexisting term endless new term achieve better term translation quality necessary inject external term knowledge underlying mt system fortunately plenty term translation knowledge parenthetical sentence internet paper propose simple straightforward effective framework improve term translation learning parenthetical sentence framework includes focused web crawler parenthetical sentence filter acquiring parenthetical sentence including bilingual term pair term translation knowledge extractor extracting bilingual term translation candidate probability learner generating term translation table mt decoder extensive experiment demonstrate proposed framework significantly improves translation quality term sentence
paper propose carefully evaluate sequence labeling framework solely utilizes sparse indicator feature derived dense distributed word representation proposed model obtains near stateofthe art performance partofspeech tagging named entity recognition variety language model relies thousand sparse codingderived feature without applying modification word representation employed different task proposed model favorable generalization property retains average po tagging accuracy trained total available training data ie sentence per language
background transformerbased language model shown strong performance many natural language processing nlp task masked language model mlms attract sustained interest adapted different language subdomains training finetuning specific corpus remaining lighter modern large language model mlms recently several mlms released biomedical domain french experiment suggest outperform standard french counterpart however systematic evaluation comparing model corpus available objective paper present evaluation masked language model biomedical french task clinical named entity recognition material method evaluate biomedical model camembertbio drbert compare standard french model camembert flaubert fralbert well multilingual mbert using three publically available corpus clinical named entity recognition french evaluation setup relies goldstandard corpus released corpus developer result result suggest camembertbio outperforms drbert consistently flaubert offer competitive performance fralbert achieves lowest carbon footprint conclusion first benchmark evaluation biomedical masked language model french clinical entity recognition compare model performance consistently nested entity recognition using metric covering performance environmental impact
discourse analysis long known fundamental natural language processing research present insight discourselevel topic chain dtc parsing aim discovering new topic investigating topic evolve time within article address lack data contribute new discourse corpus dtcstyle dependency graph annotated upon news article particular ensure high reliability corpus utilizing twostep annotation strategy build data filtering annotation low confidence score based annotated corpus introduce simple yet robust system automatic discourselevel topic chain parsing
recent year machine translation become successful highresource language pair also sparked new interest research automatic translation lowresource language including indigenous language however latter deeply related ethnic cultural group speak used speak data collection modeling deploying machine translation system thus result new ethical question must addressed motivated first survey existing literature ethical consideration documentation translation general natural language processing indigenous language afterward conduct analyze interview study shed light position community leader teacher language activist regarding ethical concern automatic translation language result show inclusion different degree native speaker community member vital performing better ethical research indigenous language
propose generative framework simultaneous machine translation conventional approach use fixed number source word translate learn dynamic policy number source word reinforcement learning formulate simultaneous translation structural sequencetosequence learning problem latent variable introduced model read translate action every time step integrated consider possible translation policy reparameterised poisson prior used regularise policy allows model explicitly balance translation quality latency experiment demonstrate effectiveness robustness generative framework achieves best bleu score given different average translation latency benchmark datasets
fincausal shared task focus causality detection factual data financial analysis financial data fact dont provide much explanation variability data paper aim propose efficient method classify data one financial cause many model used classify data svm model gave fscore bert specific finetuning achieved best result fscore
investigate task outofdomain ood text classification aim extending classification model trained multiple source domain unseen target domain recent study shown learning invariant representation enhance performance ood generalization however inherent disparity data distribution across different domain pose challenge achieving effective invariance learning study address issue employing memory augmentation specifically augment original feature space using keyvalue memory employ metalearningbased approach enhance quality invariant representation experimental result sentiment analysis natural language inference task show effectiveness memorybased method invariance learning leading stateoftheart performance six datasets
increasing concern regulation data privacy sparsity necessitate study privacypreserving decentralized learning method natural language processing nlp task federated learning fl provides promising approach large number client eg personal device organization collaboratively learn shared global model benefit client allowing user keep data locally despite interest studying fl method nlp task systematic comparison analysis lacking literature herein present fednlp benchmarking framework evaluating federated learning method four different task formulation text classification sequence tagging question answering seqseq propose universal interface transformerbased language model eg bert bart fl method eg fedavg fedopt etc various noniid partitioning strategy extensive experiment fednlp provide empirical comparison fl method help u better understand inherent challenge direction comprehensive analysis point intriguing exciting future research aimed developing fl method nlp task
paper discusses effort develop full automatic speech recognition asr system scottish gaelic starting point limited resource building asr technology important documenting revitalising endangered language enables existing resource enhanced automatic subtitle transcription improves accessibility user turn encourages continued use language paper explain many difficulty faced collecting minority language data speech recognition novel crosslingual approach alignment training data used overcome one difficulty way demonstrate majority language resource bootstrap development lowerresourced language technology use kaldi speech recognition toolkit develop several gaelic asr system report final wer improvement original model
data augmentation effective approach tackle overfitting many previous work proposed different data augmentation strategy nlp noise injection word replacement backtranslation etc though effective missed one important characteristic languagecompositionality meaning complex expression built subpart motivated propose compositional data augmentation approach natural language understanding called treemix specifically treemix leverage constituency parsing tree decompose sentence constituent substructure mixup data augmentation technique recombine generate new sentence compared previous approach treemix introduces greater diversity sample generated encourages model learn compositionality nlp data extensive experiment text classification scan demonstrate treemix outperforms current stateoftheart data augmentation method
rapidly changing social medium content call robust generalisable abuse detection model however stateoftheart supervised model display degraded performance evaluated abusive comment differ training corpus investigate performance supervised model crosscorpora abuse detection improved incorporating additional information topic model latter infer latent topic mixture unseen sample particular combine topical information representation model tuned classifying abusive comment performance analysis reveals topic model able capture abuserelated topic transfer across corpus result improved generalisability
despite recent achievement natural language understanding reasoning commonsense knowledge still represents big challenge ai system name suggests common sense related perception human derive experience rather literary education recent work nlp computer vision field made effort making knowledge explicit using written language visual input respectively premise latter source fit better characteristic commonsense acquisition work explore extent description realworld scene sufficient learn common sense different daily situation drawing upon visual information answer script knowledge question
present attempt using rd party observer gaze get measure appropriate segment dialogue speaker change method step away current dependency speaker turn talkspurts towards general view speaker change show rd party observer indeed largely look thing speaker captured utilized provide insight human communication addition result also suggest might difference distribution rd party observer gaze depending informationrich utterance
promptbased finetuning pretrained model proven effective many natural language processing task fewshot setting general domain however tuning prompt biomedical domain investigated thoroughly biomedical word often rare general domain quite ubiquitous biomedical context dramatically deteriorates performance pretrained model downstream biomedical application even finetuning especially lowresource scenario propose simple yet effective approach helping model learn rare biomedical word tuning prompt experimental result show method achieve improvement biomedical natural language inference task without extra parameter training step using fewshot vanilla prompt setting
text corpus steadily increasing overall size even large corpus designed represent global population demographic example recent work shown existing english gigaword corpus overrepresent innercircle variety u uk correct implicit geographic demographic bias paper us countrylevel population demographic guide construction gigaword web corpus resulting corpus explicitly match groundtruth geographic distribution language thus equally representing language user around world important ensures speaker underresourced language variety ie indian english algerian french represented corpus also derivative resource like word embeddings
natural language understanding important task modern dialogue system becomes important rapid extension dialogue system functionality work present approach zeroshot transfer learning task intent classification slotfilling based pretrained language model use deep contextualized model feeding utterance natural language description user intent get text embeddings embeddings used small neural network produce prediction intent slot probability architecture achieves new stateoftheart result two zeroshot scenario one single language new skill adaptation another one crosslingual adaptation
paper present rulebased method multiword term extraction relies extensive lexical resource form electronic dictionary finitestate transducer modelling various syntactic structure multiword term technology used lemmatization extracted multiword term unavoidable highly inflected language order pas extracted data evaluator subsequently terminological edictionaries database approach illustrated corpus serbian text mining domain containing simple word form extracted lemmatized multiword term filtered order reject falsely offered lemma ranked introducing measure combine linguistic statistical information cvalue tscore llr keynes mean average precision retrieval mwu form range mean average precision lemma production range evaluation showed distinct multiword form evaluated proper multiword unit among associated correct lemma
emotional aspect play vital role making human communication rich dynamic experience introduce automated system daily life becomes increasingly important incorporate emotion provide natural interaction possible achieve said incorporation rich set labeled emotional data prerequisite however japanese existing emotion database still limited unimodal bimodal corpus since emotion expressed speech also visually time essential include multiple modality observation paper present first audiovisual emotion corpus japanese collected native speaker corpus contains minute annotated transcribed material performed preliminary emotion recognition experiment corpus achieved accuracy five class emotion
paper present new method intent recognition complex dialog management low resource situation complex dialog management required target domain real world mixed initiative food ordering agent customer individual customer utterance may contain multiple intent refer food item complex structure example customer might say get deluxe burger large fry oh put extra mayo burger would approach task multilevel sequence labeling problem constraint limited real training data traditional method like hmm memm crf newer method like dnn bilstm use homogeneous feature set newer method perform better also require considerably data previous research done pseudodata synthesis obtain required amount training data propose use knn learner heterogeneous feature set used windowed word ngrams po tag ngrams pretrained word embeddings feature experiment perform comparison using pseudodata real world data also perform semisupervised selftraining obtain additional labeled data order better model real world scenario instead using massive pseudodata show less data size achieve better result method annotating real world data achieve labeled bracketed fscores three level sequence labeling level longer word span previous level overall achieve f comparison two previous system memm dnnelmo achieved respectively
audit report window financial health company hence gauging coverage various audit aspect important paper aim determining audit report coverage classification sentence multiple domain specific class weakly supervised setting employ rulebased approach automatically create training data bertbased multilabel classifier devise ensemble combine rule based classifier approach employ two novel way improve ensemble generalization active learning based approach ii llm based review demonstrate proposed approach outperform several baseline show utility proposed approach measure audit coverage large dataset k audit report
multilingual spoken language understanding slu consists two subtasks namely intent detection slot filling improve performance two subtasks propose use consistency regularization based hybrid data augmentation strategy consistency regularization enforces predicted distribution example semantically equivalent augmentation consistent conduct experiment massive dataset fulldataset zeroshot setting experimental result demonstrate proposed method improves performance intent detection slot filling task system ranked st mmnlu competition fulldataset setting
relational structure schema linking schema encoding validated key component qualitatively translating natural language sql query however introducing structural relation come price often result specialized model structure largely prohibits using large pretrained model texttosql address problem propose rasat transformer seqseq architecture augmented relationaware selfattention could leverage variety relational structure inheriting pretrained parameter model effectively model incorporate almost type existing relation literature addition propose introducing coreference relation multiturn scenario experimental result three widely used texttosql datasets covering singleturn multiturn scenario shown rasat could achieve competitive result three benchmark achieving stateoftheart execution accuracy ex spider iex sparc iex cosql
introduce wikilingua largescale multilingual dataset evaluation crosslingual abstractive summarization system extract article summary pair language wikihow high quality collaborative resource howto guide diverse set topic written human author create goldstandard articlesummary alignment across language aligning image used describe howto step article set baseline study evaluate performance existing crosslingual abstractive summarization method dataset propose method direct crosslingual summarization ie without requiring translation inference time leveraging synthetic data neural machine translation pretraining step method significantly outperforms baseline approach cost efficient inference
describe first experimental result datadriven semantic parsing tree rewriting grammar trgs semantic frame several theoretical paper previously discussed approach modeling frame semantics context trgs first datadriven implementation parser experiment tree wrapping grammar twg grammar formalism closely related tree adjoining grammar tag developed formalizing typologically inspired linguistic theory role reference grammar rrg use transformerbased multitask architecture predict semantic supertags decoded rrg tree augmented semantic feature structure present experiment sentence different genre english data also discus compositional semantic analysis using twg several linguistic phenomenon
article present model generated run submitted rilis team vardial evaluation campaign particularly binary classification dialect subtask moldavian v romanian crossdialect topic identification mrc task team proposed majority votebased model five supervised machine learning model trained forty manuallycrafted feature one three submitted run ranked second binary classification subtask performance term macrof measure two run ranked third fourth respectively
paper describes system developed lia semeval evaluation campaign goal task identify sentiment polarity tweet system ensemble deep neural network dnn model convolutional neural network cnn recurrent neural network long shortterm memory rnnlstm initialize input representation dnn different set embeddings trained large datasets ensemble dnns combined using scorelevel fusion approach system ranked nd semeval obtained average recall
present experimental framework entity mention detection two different classifier combined exploit data redundancy attained annotation large text corpus well number pattern extracted automatically corpus order recognize proper name nominal pronominal mention exploit information given mention recognized within corpus annotated also given mention occurring external unannotated corpus system first evaluated evalita evaluation campaign obtaining good result current version used number application one hand used livememories project aim scaling content extraction technique towards large scale extraction multimedia source hand used annotate corpus italian wikipedia thus providing easy access syntactic semantic annotation natural language processing information retrieval community moreover web service version system available system going integrated textpro suite nlp tool
perform corpus analysis develop representation knowledge reasoning used interpret indirect speech act indirect speech act isa utterance whose intended meaning different literal meaning focus speech act slight change situational contextual information switch dominant intended meaning utterance direct indirect viceversa computationalize various contextual feature influence speaker belief belief influence intended meaning choice surface form utterance axiomatize domaingeneral pattern reasoning involved implement proofofconcept architecture using answer set programming model presented contribution cognitive science psycholinguistics representational decision justified existing theoretical work
age large transformer language model linguistic evaluation play important role diagnosing model ability limitation natural language understanding however current evaluation method show significant shortcoming particular provide insight well language model capture distinct linguistic skill essential language understanding reasoning thus fail effectively map aspect language understanding remain challenging existing model make hard discover potential limitation model datasets paper introduce curriculum new format nli benchmark evaluation broadcoverage linguistic phenomenon curriculum contains collection datasets cover type major linguistic phenomenon evaluation procedure diagnosing well language model capture reasoning skill distinct type linguistic phenomenon show linguisticphenomenadriven benchmark serve effective tool diagnosing model behavior verifying model learning quality addition experiment provide insight limitation existing benchmark datasets stateoftheart model may encourage future research redesigning datasets model architecture learning objective
unprecedented performance llm requires comprehensive accurate evaluation argue llm evaluation benchmark need comprehensive systematic end propose zhujiu benchmark following strength multidimensional ability coverage comprehensively evaluate llm across ability dimension covering task especially also propose new benchmark focus knowledge ability llm multifaceted evaluation method collaboration use different yet complementary evaluation method comprehensively evaluate llm ensure authority accuracy evaluation result comprehensive chinese benchmark zhujiu pioneering benchmark fully assesses llm chinese also providing equally robust evaluation ability english avoiding potential data leakage avoid data leakage construct evaluation data specifically task evaluate current mainstream llm conduct indepth discussion analysis result zhujiu benchmark openparticipation leaderboard publicly released urlhttpwwwzhujiubenchmarkcom also provide demo video urlhttpsyoutubeqypkjlic
several method proposed classifying long textual document using transformer however lack consensus benchmark enable fair comparison among different approach paper provide comprehensive evaluation relative efficacy measured various baseline diverse datasets term accuracy well time space overhead datasets cover binary multiclass multilabel classification task represent various way information organized long text eg information critical making classification decision beginning towards end document result show complex model often fail outperform simple baseline yield inconsistent performance across datasets finding emphasize need future study consider comprehensive baseline datasets better represent task long document classification develop robust model
three problem existing popular datatotext datasets first largescale datasets either contain noise lack real application scenario second datasets close real application relatively small size last current datasets bias english language leaving language underexploredto alleviate limitation paper present cat pragmatic chinese answertosequence dataset large scale high quality dataset aim generate textual description answer practical tableqa system bridge structural gap input sql table establish better semantic alignment propose unified graph transformation approach establish joint encoding space two hybrid knowledge resource convert task graphtotext problem experiment result demonstrate effectiveness proposed method analysis cat attests high quality challenge dataset
neural language model analyzed linguistic extralinguistic knowledge via probing particular interest following question much language model trained form learn meaning recent work demonstrated via probing classifier setting simple procedural text meaning mean underlying world state language model nontrivial performance world state tracking however proposed evaluation based model prediction show differing result suggesting model either capturing world state using result change model access world state explore alternate setting access underlying world state training investigate way baking state knowledge along primary task language modeling proposed approach allow state probing inference simply via text prompt avoiding probing classifier machinery term performance show baking state knowledge training lead significant improvement state tracking performance text generation quality
adversarial training shown impressive success learning bilingual dictionary without parallel data mapping monolingual embeddings shared space however recent work shown superior performance nonadversarial method challenging language pair work revisit adversarial autoencoder unsupervised word translation propose two novel extension yield stable training improved result method includes regularization term enforce cycle consistency input reconstruction put target encoders adversary corresponding discriminator extensive experimentation european noneuropean lowresource language show method robust achieves better performance recently proposed adversarial nonadversarial approach
time one crucial factor realworld question answering qa problem however language model difficulty understanding relationship time specifier number since existing qa datasets include sufficient time expression address issue propose timecontext aware question answering tcqa framework suggest timecontext dependent span extraction tcse task build timecontext dependent data generation framework model training moreover present metric evaluate time awareness qa model using tcse tcse task consists question four sentence candidate classified correct incorrect based time context model trained extract answer span sentence correct time context model trained tcqa outperforms baseline model fscore timeqa dataset dataset code available httpsgithubcomsonjbintcqa
recent research natural language processing nlp achieved impressive performance task machine translation mt news classification questionanswering highresource language however performance mt leaf much desired lowresource language due smaller size available parallel corpus language corpus available nlp ethiopian language suffers issue due unavailability publicly accessible datasets nlp task including mt help research community foster research ethiopian language introduce ethiomt new parallel corpus language also create new benchmark collecting dataset betterresearched language ethiopia evaluate newly collected corpus benchmark dataset ethiopian language using transformer finetuning approach
variational autoencoder vae widely used generative model approximate model posterior latent variable combining amortized variational inference deep neural network however paired strong autoregressive decoder vae often converges degenerated local optimum known posterior collapse previous approach consider kullbackleibler divergence kl individual datapoint propose let kl follow distribution across whole dataset analyze sufficient prevent posterior collapse keeping expectation kls distribution positive propose batch normalizedvae bnvae simple effective approach set lower bound expectation regularizing distribution approximate posterior parameter without introducing new model component modifying objective approach avoid posterior collapse effectively efficiently show proposed bnvae extended conditional vae cvae empirically approach surpasses strong autoregressive baseline language modeling text classification dialogue generation rival complex approach keeping almost training time vae
opendomain question answering odqa aim answer question without explicitly providing specific background document task becomes notably challenging zeroshot setting data available train tailored retrievalreader modelswhile recent large language model llm like gpt demonstrated effectiveness zeroshot odqa using direct prompting method method still fall short fully harnessing potential llm implicitly invokedin paper propose selfprompting framework explicitly utilize massive knowledge encoded parameter llm strong instruction understanding ability concretely prompt llm step step generate multiple pseudo qa pair background passage explanation entirely scratchthese generated element utilized incontext learning experimental result show method significantly surpasses previous stateoftheart zeroshot method three widelyused odqa datasets even achieves comparable performance various customized finetuned model full training data code available httpsgithubcomlockonnselfprompting
paper evaluates impact various event extraction system automatic pathway curation using popular mtor pathway quantify impact training data set well different machine learning classifier show improve quality automatically extracted pathway
trust implicit many online text conversationsstriking new friendship asking tech support trust betrayed deception study language dynamic deception negotiationbased game diplomacy seven player compete world domination forging breaking alliance study player diplomacy community gather message annotated sender intended truthfulness receiver perceived truthfulness unlike existing datasets capture deception longlasting relationship interlocutor strategically combine truth lie advance objective model us power dynamic conversational context predict lie occurs nearly well human player
rerunning metricbased evaluation straightforward result closer humanbased evaluation especially code model checkpoint made available original author brief report effort rerun metricbased evaluation set multiaspect controllable text generation ctg technique show however rerun evaluation always produce result original result reveal error orginal work
paper introduces artelingo new benchmark dataset designed encourage work diversity across language culture following artemis collection k artwork wikiart emotion label englishonly caption artelingo add another annotation arabic chinese plus k spanish evaluate culturaltransfer performance k artwork annotation language diversity make possible study similarity difference across language culture investigate captioning task find diversity improves performance baseline model artelingo publicly available wwwartelingoorg standard split baseline model hope work help ease future research multilinguality culturallyaware ai
present b rex dialogue agent book recommendation b rex aim exploit cognitive ease natural dialogue excitement whimsical persona order engage user might enjoy using common interface finding new book b rex succeeds making book recommendation good quality based information revealed user dialogue
phonogenres speaking style typified acoustic image associated type language activity causing prosodic phonostylistic variation communication present large speech corpus hour french extending previous work goldman et al simon et al greater number complementary repertoire considered phonogenres corpus available segmentation phonetic syllabic word level well manual annotation segmentation annotation achieved semiautomatically set praat implemented tool manual step phonogenres also described reduced set situational dimension lucci koch oesterreichers preliminary acoustic study joining rhythmical comparative measurement dellwo goldman et al prosoreport report acoustic difference phonogenres
interruption detection new yet challenging task field speech processing article present comprehensive study automatic speech interruption detection definition task assembly specialized corpus development initial baseline system provide three main contribution firstly define task taking account nuanced nature interruption within spontaneous conversation secondly introduce new corpus conversational data annotated interruption facilitate research domain corpus serf valuable resource evaluating advancing interruption detection technique lastly present first baseline system use speech processing method automatically identify interruption speech promising result article derivate theoretical notion interruption build simplification notion based overlapped speech detection finding serve foundation research field also provide benchmark assessing future advancement automatic speech interruption detection
present first openly available multimodal metaphor annotated corpus corpus consists video including audio subtitle annotated expert furthermore present method detecting metaphor new dataset based textual content video method achieves high fscore metaphorical label also experiment modality multimodal method however method outperform textbased model error analysis identify case video could help disambiguating metaphor however visual cue subtle model capture data available zenodo
crosslingual phrase retrieval aim retrieve parallel phrase among language current approach deal textual modality lack multimodal data resource exploration multimodal crosslingual phrase retrieval mxpr paper create first mxpr data resource propose novel approach mxpr explore effectiveness multimodality mxpr data resource built marrying benchmark dataset textual crosslingual phrase retrieval wikimedia common medium store containing tremendous text related image built resource phrase pair textual benchmark dataset equipped related image based novel data resource introduce strategy bridge gap different modality multimodal relation generation large multimodal pretrained model consistency training experiment benchmarked dataset covering eight language pair show mxpr approach deal multimodal phrase performs significantly better pure textual crosslingual phrase retrieval
recently automatic trivia fact extraction attracted much research interest modern search engine begun provide trivia fact information entity motivate user engagement paper propose new unsupervised algorithm automatically mine trivia fact given entity unlike previous study proposed algorithm target single wikipedia article leverage hierarchical structure via topdown processing thus proposed algorithm offer two distinctive advantage incur high computation time provides domainindependent approach extracting trivia fact experimental result demonstrate proposed algorithm time faster existing method considers wikipedia category human evaluation demonstrates proposed algorithm mine better trivia fact regardless target entity domain outperforms existing method
character identification task entity linking find global entity personal mention multiparty dialogue task first two season popular tv show friend annotated comprising total dialogue mention entity personal mention detected nominal referring certain character show entity collected list character two season show task challenging requires identification character mentioned may active conversation among participant four submitted system output showed strength different aspect task thorough analysis distributed datasets system output comparative study also provided facilitate momentum create opensource project task publicly release larger cleaner dataset hoping support researcher enhanced modeling
paper describes system submitted ana team semeval task emocontext propose novel hierarchi cal lstms contextual emotion detection hrlce model classifies emotion utterance given conversational con text result show task hrcle outperforms recent stateof theart text classification framework bert combine result generated bert hrcle achieve overall score ranked th final leader board competition among team
language identification word level kannadaenglish text paper de scribe system paper colikanglish shared task goal task identify different language used coli kanglish dataset distributed different category including kannada en glish mixedlanguage location name others codemix compiled coli kanglish organizer post social medium use two classification technique knn svm achieve fscore place third nine competitor
wide applicability adaptability generative large language model llm enabled rapid adoption pretrained model perform many task model often finetuned improve performance various downstream application however lead issue violation model license model theft copyright infringement moreover recent advance show generative technology capable producing harmful content exacerbates problem accountability within model supply chain thus need method investigate model trained piece text generated pretrained base model paper take first step address open problem tracing back origin given finetuned llm corresponding pretrained base model consider different knowledge level attribution strategy find correctly trace back fine tuned model best method
generative conversational agent known suffer problem like inconsistency hallucination big challenge studying issue remains evaluation properly reflected common text generation metric like perplexity bleu alternative implicit method like semantic similarity nli label misguided specific token decisive work propose consistest factual consistency benchmark including wh yn question based personachat along hybrid evaluation pipeline aim get best symbolic subsymbolic method using focusing pretrained generative model like bart provide detailed statistic analysis model consistency affected variation question context
promoting multilingual south africa government encouraging people speak one language order comply initiative people choose learn language speak home language african language mostly chosen spoken majority country population word language many possible sens phenomenon tends pose problem people want learn language article argues african wordnet may best tool address problem sense discrimination focus argument primary sense word hand part body lexicalized three indigenous language spoken south africa namely tshivena sesotho sa leboa isizulu brief historical background african wordnet provided followed definition word hand three language analysis word context lastly primary sense word hand across three language discussed
research focus development readability formula latin text muchneeded tool assess difficulty latin text educational setting study take comprehensive approach exploring linguistic variable including lexical morphological syntactical discourserelated factor capture multifaceted nature text difficulty study incorporates corpus latin text assessed difficulty evaluation used establish basis model research utilizes natural language processing tool derive linguistic predictor resulting multiple linear regression model explains variance text difficulty model precision enhanced adding variable larger corpus already provides valuable insight readability latin text offer opportunity examine different text genre content influence text accessibility additionally formula focus objective text difficulty pave way future research personal predictor particularly educational context
research present pilot experiment distil monolingual model jointly trained model language mbert demonstrate possible target language outperform original model even basic distillation setup evaluate methodology language varying amount resource language family
paper first describes experiment construct englishchinese parallel corpus applying uplug word alignment tool corpus finally produce evaluate englishchinese word list stockholm englishchinese parallel corpus sec created downloading englishchinese parallel corpus chinese web site containing law text manually translated chinese english parallel corpus contains chinese character equivalent chinese word corresponding english corpus contains english word however chinese writing utilize delimiters mark word boundary carry word segmentation preprocessing step chinese corpus moreover since parallel corpus downloaded internet corpus noisy regarding alignment corresponding translated sentence therefore used hour manually work align sentence english chinese parallel corpus performing automatic word alignment using uplug word alignment uplug carried english chinese nine respondent evaluated resulting englishchinese word list frequency equal three obtained accuracy percent
social medium offer accessible avenue individual diverse background circumstance share unique perspective experience study focus experience low carbohydrate diet motivated recent research clinical trial elucidates diet promising health benefit given lack suitable annotated dataset domain first define annotation schema reflects interest healthcare professional manually annotate data reddit social network finally benchmark effectiveness several classification approach based statistical support vector machine svm classifier pretrainthenfinetune roberta classifier offtheshelf chatgpt api annotated dataset annotation script used download reddit post publicly available urlhttpsdatacsiroaucollectioncsiro
abstractive summarization model often generate inconsistent summary containing factual error hallucinated content recent work focus correcting factual error generated summary via postediting correction model trained using adversarial nonfactual summary constructed using heuristic rule injecting error however generating nonfactual summary using heuristic often generalize well actual model error work propose generate hard representative synthetic example nonfactual summary infilling language model data train robust factcorrection model postedit summary improve factual consistency quantitative qualitative experiment two popular summarization datasets cnndm xsumwe show approach vastly outperforms prior method correcting erroneous summary modelfacteditimproves factuality score textasciitilde point cnndm textasciitilde point xsum average across multiple summarization model producing factual summary maintaining competitive summarization quality
finetuning parameter large language model llm requires significant computational resource timeconsuming recent parameterefficient tuning method adapter tuning prefix tuning lora allow updating small subset parameter large language model however save approximately training memory requirement due problem gradient computation backpropagation still necessary method paper proposes novel parameterefficient tuning method llm without calculating gradient leveraging discernible similarity parameterefficient module task learned large small language model put forward strategy transferring parameterefficient module originally derived small language model much larger one ensure smooth effective adaptation process introduce bridge model guarantee dimensional consistency also stimulating dynamic interaction model demonstrate effectiveness method using gpt series language model superglue benchmark method achieves comparable performance finetuning parameterefficient tuning large language model without needing gradientbased optimization additionally method achieves x memory reduction compared parameterefficient tuning
language model lm trained collection document written individual human agent achieve specific goal outside world training lm access text document direct evidence internal state agent produced thema fact often used argue lm incapable modeling goaldirected aspect human language production comprehension lm trained text learn anything relationship language use argue lm model communicative intention specific narrow sense performing next word prediction given textual context lm infer represent property agent likely produced context representation turn influence subsequent lm generation way agent communicative intention influence language survey finding recent literature showing thateven today nonrobust errorprone modelslms infer use representation finegrained communicative intention highlevel belief goal despite limited nature training data thus serve building block system communicate act intentionally
paper present approach semeval task detect online persuasion technique multilingual setup classification system based robertabase model trained predominantly english label persuasion technique across different language system able significantly surpass baseline performance language english georgian greek however wrong assumption single classification system trained predominantly english could generalize well language negatively impacted score language paper provide description reasoning behind development final model conclusion may drawn performance future work
named entity recognition ner fundamental nlp task wide range practical application performance stateoftheart ner method depends high quality manually anotated datasets still exist language work aim remedy situation slovak introducing wikigoldsk first sizable human labelled slovak ner dataset benchmark evaluating stateoftheart multilingual pretrained language model comparing existing silverstandard slovak ner dataset also conduct fewshot experiment show training sliverstandard dataset yield better result enable future work based slovak ner release dataset code well trained model publicly permissible licensing term urlhttpsgithubcomnaiveneuronwikigoldsk
incorporation data augmentation method grammatical error correction task attracted much attention however existing data augmentation method mainly apply noise token lead lack diversity generated error view propose new data augmentation method apply noise latent representation sentence editing latent representation grammatical sentence generate synthetic sample various error type combining predefined rule method greatly improve performance robustness existing grammatical error correction model evaluate method public benchmark gec task achieves stateoftheart performance conll fce benchmark
order preserve wordorder information nonautoregressive setting transformer architecture tend include positional knowledge instance adding positional encoding token embeddings several modification proposed sinusoidal positional encoding used original transformer architecture include instance separating position encoding token embeddings directly modifying attention weight based distance word pair first show surprisingly modification tend improve monolingual language model none result better multilingual language model answer sinusoidal encoding explicitly designed facilitate compositionality allowing linear projection arbitrary time step higher variance multilingual training distribution requires higher compression case compositionality becomes indispensable learned absolute positional encoding eg mbert tend approximate sinusoidal embeddings multilingual setting complex positional encoding architecture lack inductive bias effectively learn crosslingual alignment word sinusoidal positional encoding designed monolingual application particularly useful multilingual language model
work present informationtheoretic operationalisation crosslinguistic nonarbitrariness new idea small crosslinguistic association form meaning word instance claimed blasi et al word tongue likely chance contain phone l controlling influence language family geographic proximity within large conceptaligned crosslingual lexicon extend method previously used detect within language nonarbitrariness pimentel et al measure crosslinguistic association find significant effect nonarbitrariness unsurprisingly small less average according informationtheoretic estimate also provide conceptlevel analysis show quarter concept considered work exhibit significant level crosslinguistic nonarbitrariness sum paper provides new method detect crosslinguistic association scale confirms effect minor
paper describes university cape town submission constrained track wmt shared task largescale machine translation evaluation african language system single multilingual translation model translates english south south east african language well specific pair african language used several technique suited lowresource machine translation mt including overlap bpe backtranslation synthetic training data generation adding translation direction training result show value technique especially direction little bilingual training data available
paper present intelmo easytouse library help model developer adopt userfaced interactive interface article realtime rss source language model library categorizes common nlp task provides default style pattern streamlining process creating interface minimal code modification ensuring intuitive user experience moreover intelmo employ multigranular hierarchical abstraction provide developer finegrained flexible control user interface intelmo active development document available urlhttpsintelmogithubio
article interested problem linguistic content speech corpus depending target task phonological linguistic content corpus controlled collecting set sentence cover preset description phonological attribute constraint overall duration small possible goal classically achieved greedy algorithm however guarantee optimality desired cover recent work lagrangianbased algorithm called lamscp used extract covering diphonemes large corpus french giving better result greedy algorithm propose keep comparing algorithm term shortest duration stability robustness achieving multirepresented diphoneme triphoneme covering covering correspond large scale optimization problem corpus english experiment lamscp improves greedy result percent
vision language navigation task requires agent navigate environment based natural language instruction one key challenge task ground instruction current visual information agent perceives existing work employ soft attention individual word locate instruction required next action however different word different function sentence eg modifier convey attribute verb convey action syntax information like dependency phrase structure aid agent locate important part instruction hence paper propose navigation agent utilizes syntax information derived dependency tree enhance alignment instruction current visual scene empirically agent outperforms baseline model use syntax information roomtoroom dataset especially unseen environment besides agent achieves new stateoftheart roomacrossroom dataset contains instruction language english hindi telugu also show agent better aligning instruction current visual information via qualitative visualization
paper relates challenge morphological tagging lemmatization morphologically rich language example german latin focus question practitioner expect using stateoftheart solution box moreover contrast older method implementation po tagging examine degree recent effort tagger development reflected improved accuracy cost term training processing time also conduct indomain v outdomain evaluation outdomain evaluation particularly insightful distribution data tagged user typically differ distribution tagger trained furthermore two lemmatization technique evaluated finally compare pipeline tagging v tagging approach acknowledges dependency inflectional category
large language model llm demonstrated great potential domainspecific application law domain however recent dispute gpts law evaluation raise question concerning performance realworld legal task systematically investigate competency law design practical baseline solution based llm test task legal judgment prediction solution llm work alone answer open question coordinate information retrieval ir system learn similar case solve simplified multichoice question show similar case multichoice option namely label candidate included prompt help llm recall domain knowledge critical expertise legal reasoning additionally present intriguing paradox wherein ir system surpasses performance llmir due limited gain acquired weaker llm powerful ir system case role llm becomes redundant evaluation pipeline easily extended task facilitate evaluation domain code available httpsgithubcomsrhthulmcompevallegal
although corpus size well known factor affect performance many nlp task many language large freely available corpus still scarce paper describe one effort build large corpus brazilian portuguese brwac generated following web corpus kool initiative indirectly assess quality resulting corpus examined impact corpus origin specific task identification multiword expression association measure standard corpus focusing nominal compound expression obtained corpus comparable quality indicate corpus origin impact task
dialogue summarization drawn much attention recently especially customer service domain agent could use dialogue summary help boost work quickly knowing customer issue service progress application require summary contain perspective single speaker clear topic flow structure neither available existing datasets therefore paper introduce novel chinese dataset customer service dialogue summarization csds csds improves abstractive summary two aspect addition overall summary whole dialogue roleoriented summary also provided acquire different speaker viewpoint summary sum topic separately thus containing topiclevel structure dialogue define task csds generating overall summary different roleoriented summary given dialogue next compare various summarization method csds experiment result show existing method prone generate redundant incoherent summary besides performance becomes much worse analyzing performance roleoriented summary topic structure hope study could benchmark chinese dialogue summarization benefit study
paper present ndc treebank spoken norwegian dialect bokmaal variety norwegian consists dialect recording made digitised segmented transcribed subsequently annotated morphological syntactic analysis nature spoken data give rise various challenge segmentation annotation follow earlier effort norwegian particular lia treebank spoken dialect transcribed nynorsk variety norwegian annotation principle ensure interusability resource developed spoken language parser basis annotated material report accuracy test set across dialect holding single dialect
welldesigned diagnostic task played key role studying failure neural net nns generalize systematically famous example include scan compositional table lookup ctl introduce ctl new diagnostic dataset based composition unary symbolic function original ctl used test length generalization productivity ctl designed test systematicity nns capability generalize unseen composition known function ctl split function group test performance group element composed way seen training show recent ctlsolving transformer variant fail ctl simplicity task design allows finegrained control task difficulty well many insightful analysis example measure much overlap group needed tested nns learning compose also visualize learned symbol representation output function different group compatible case success case failure result provide insight failure case reported complex composition natural language domain code public
paper present usage relate platform translation task involving romanian language using platform possible perform text speech data translation either single document entire corpus furthermore platform successfully used international project create new resource useful romanian language translation
paper study improve deep learning approach textual entailment incorporating lexical entailment relation wordnet idea embed lexical entailment knowledge contained wordnet speciallylearned word vector call entailment vector present standard neural network model novel settheoretic model learn entailment vector word pair known lexical entailment relation derived wordnet incorporate entailment vector decomposable attention model textual entailment evaluate model sick snli dataset find using special entailment word vector significantly improve performance textual entailment compared baseline us standard wordvec vector final performance model close state art method rely manuallycrafted rule extensive syntactic feature
active learning important technique lowresource sequence labeling task however current active sequence labeling method use queried sample alone iteration inefficient way leveraging human annotation propose simple effective data augmentation method improve label efficiency active sequence labeling method seqmix simply augments queried sample generating extra labeled sequence iteration key difficulty generate plausible sequence along tokenlevel label seqmix address challenge performing mixup sequence tokenlevel label queried sample furthermore design discriminator sequence mixup judge whether generated sequence plausible experiment named entity recognition event detection task show seqmix improve standard active sequence labeling method term f score code data seqmix found urlhttpsgithubcomrzzhangseqmix
given knowledge base kb containing noisy fact common noun generic tree produce oxygen animal live forest consider problem inferring additional fact precision similar starting kb kb capture general knowledge world crucial various application question answering different commonly studied named entity kb freebase generic kb involve quantification complex underlying regularity tend incomplete violate commonly used locally closed world assumption lcwa show existing kb completion method struggle new task present first approach successful result demonstrate external information relation schema entity taxonomy used appropriately surprisingly powerful tool setting first simple yet effective knowledge guided tensor factorization approach achieves stateoftheart result two generic kb precise science doubling size precision second novel taxonomy guided submodular active learning method collecting annotation rare entity eg oriole bird x effective inferring new fact multiple active learning baseline
since language model pretraining learn contextualized word representation proposed pretrained language model made success many natural language processing task helpful use individual contextualized representation selfattention layer initialize parameter downstream task yet unfortunately use pretrained language model emotion recognition conversation studied enough firstly use electra stateoftheart pretrained language model validate performance emotion recognition conversation furthermore propose contextual augmentation pretrained language model emotion recognition conversation consider previous utterance also conversationrelated information speaker speech act topic classify information based information related propose position word corresponding information entire input sequence validate proposed method conduct experiment dailydialog dataset contains abundant annotated information conversation experiment show proposed method achieves stateoftheart f score dataset significantly improves performance
aspectbased sentiment analysis absa extensively studied recent year typically involves four fundamental sentiment element including aspect category aspect term opinion term sentiment polarity existing study usually consider detection partial sentiment element instead predicting four element one shot work introduce aspect sentiment quad prediction asqp task aiming jointly detect sentiment element quad given opinionated sentence reveal comprehensive complete aspectlevel sentiment structure propose novel paraphrase modeling paradigm cast asqp task paraphrase generation process one hand generation formulation allows solving asqp endtoend manner alleviating potential error propagation pipeline solution hand semantics sentiment element fully exploited learning generate natural language form extensive experiment benchmark datasets show superiority proposed method capacity crosstask transfer proposed unified paraphrase modeling framework
paper analyzes data amazon alexa prize socialbot grand challenge order better understand difference humancomputer interaction hci socialbot setting conventional humantohuman interaction find socialbots new genre hci still negotiating norm guide interaction setting present several notable pattern user behavior toward socialbots important implication guiding future work development conversational agent
although framenet recognized one finegrained lexical database coverage lexical unit still limited tackle issue propose twostep frame induction process set lexical unit yet present berkeley framenet data release first remove fit existing semantic frame framenet assign remaining lexical unit correct frame also present semisupervised deep embedded clustering anomaly detection sdecad modelan algorithm map highdimensional contextualized vector representation lexical unit lowdimensional latent space better frame prediction us reconstruction error identify lexical unit evoke frame framenet sdecad outperforms stateoftheart method step frame induction process empirical result also show definition provide contextual information representing characterizing frame membership lexical unit
preliminary analysis us deep lstm neural network fasttext embeddings predict population rate depression reddit order estimate effect covid mental health find year year depression rate reddit suggesting million person increase number depressed american billion increase depression related spending finding suggests utility nlp approach longitudinal publichealth surveillance
explore pretraining unidirectional language model b token largest curated corpus ukrainian ubertext enrich document text surrounding weakly structured metadata title tag publication year enabling metadataconditioned text generation textconditioned metadata prediction time pretrain gpt small medium large model single gpu reporting training time bpc bruk bertscore title news future next venture formatting po ner datasets instruction train lowrank attention adapter performing task constrained text generation release model community urlhttpsgithubcomprogerukb
paper present rationale dedicated corpus spoken maltese korpus talmalti mitkellem kmm corpus spoken maltese based concept goldstandard core collection core collection designed cater wide variety user need possible whilst respecting basic principle governing corpus design representativeness balance delivering high quality term audio quality annotation overview provided composition current core corpus around hour data human annotation effort involved also carry small qualitative analysis output maltese asr system compare human annotator output initial result promising showing asr robust enough generate firstpass text annotator work thus reducing human effort consequently cost involved
emotioncause pair extraction ecpe task aim pair emotion corresponding cause documentsecpe important task developing humanlike response however previous ecpe research conducted based news article different characteristic compared dialogue address issue propose pairrelationship guided mixtureofexperts prgmoe model considers dialogue feature eg speaker informationprgmoe automatically learns relationship utterance advises gating network incorporate dialogue feature evaluation yielding substantial performance improvement employ new ecpe dataset english dialogue dataset emotioncause pair document news article also propose cause type classification classifies emotioncause pair according type cause detected emotion reproducing result make available code data
patronizing condescending language pcl everywhere rarely focus use medium towards vulnerable community accurately detecting pcl form difficult task due limited labeled data subtle paper describe system detecting language submitted semeval task patronizing condescending language detection approach us ensemble pretrained language model data augmentation optimizing threshold detection experimental result evaluation dataset released competition host show work reliably able detect pcl achieving f score binary classification task macro f score finegrained multilabel detection task
describe parbleu parchrf paresim augment baseline metric automatically generated paraphrase produced prism thompson post multilingual neural machine translation system build recent work studying improve bleu using diverse automatically paraphrased reference bawden et al extending experiment multilingual setting wmt metric shared task three base metric compare capacity exploit additional synthetic reference find gain possible using additional automatically paraphrased reference although systematic however segmentlevel correlation particularly english improved three metric even higher number paraphrased reference
study explores use large language model llm analyze text comment reddit user aiming achieve two primary objective firstly pinpoint critical excerpt support predefined psychological assessment suicidal risk secondly summarize material substantiate preassigned suicidal risk level work circumscribed use opensource llm run locally thereby enhancing data privacy furthermore prioritizes model low computational requirement making accessible individual institution operating limited computing budget implemented strategy relies carefully crafted prompt grammar guide llm text completion despite simplicity evaluation metric show outstanding result making valuable privacyfocused costeffective approach work part computational linguistics clinical psychology clpsych shared task
present efficient model selection method using boosting transitionbased constituency parsing designed exploring highdimensional search space defined large set feature template example typically case parsing morphologically rich language method remove need manually define heuristic constraint often imposed current stateoftheart selection method experiment french show method efficient also capable producing compact stateoftheart model
describe ttics model submission wmtslt task sign language translation swissgerman sign language dsgs german model consists id backbone image encoding transformerbased encoderdecoder model sequence modeling id pretrained isolated sign recognition using wlasl dataset model based rgb image alone rely preextracted human pose explore different strategy model training paper system achieves bleu score chrf score official test set
devastating outbreak covid vaccine one crucial line defense mass infection global pandemic given protection provide vaccine becoming mandatory certain social professional setting paper present classification model detecting covid vaccination related search query machine learning model used generate search insight covid vaccination proposed method combine leverage advancement modern stateoftheart sota natural language understanding nlu technique pretrained transformer traditional dense feature propose novel approach considering dense feature memory token model attend show new modeling approach enables significant improvement vaccine search insight vsi task improving strong wellestablished gradientboosting baseline relative improvement f score precision
despite recent advance coherence modelling model including stateoftheart neural one evaluated either contrived proxy task standard order discrimination benchmark task require special expert annotation moreover evaluation conducted small newswire corpus address shortcoming paper propose four generic evaluation task draw different aspect coherence lexical document level applied corpus designing task aim capturing coherencespecific property correct use discourse connective lexical cohesion well overall temporal causal consistency among event participant story importantly proposed task either rely automaticallygenerated data data annotated purpose hence alleviating need annotation specifically targeted task coherence modelling perform experiment several existing stateoftheart neural model coherence task across large corpus different domain including newswire dialogue well narrative instructional text finding point strong need revisiting common practice development evaluation coherence model
decompose multimodal translation two subtasks learning translate learning visually grounded representation multitask learning framework translation learned attentionbased encoderdecoder grounded representation learned image representation prediction approach improves translation performance compared state art multik dataset furthermore equally effective train image prediction task external m coco dataset find improvement train translation model external news commentary parallel text
report result sr shared task second edition multilingual surface realisation task organised part emnlp workshop multilingual surface realisation sr shared task comprised two track different level complexity shallow track input full ud structure word order information removed token lemmatised b deep track additionally functional word morphological information removed shallow track offered eleven deep track three language system evaluated automatically using range intrinsic metric b human judge term readability meaning similarity report present evaluation result along description sr track data evaluation method full description participating system please see separate system report elsewhere volume
semantic theory cant th r hofmann nl information science donald e walker han karlgren martin kay cal science education new journal annual history computing bernard caller new england research application center linguafranca document search llba demonstration interactive search llba nfaisunesco indexing education kit symposium computer assisted learning j j mathews linguistic institute conference symposium data base usability responsiveness dr allen baiter conference internal auditing eugene shaeffer conference briefly noted k preston jr nsf award computer science ajcl description ajcl page format ajcl opaque card format afips washington newsletter
paper present amara corpus online educational content new parallel corpus educational video subtitle multilingually aligned language ie monolingual corpus parallel corpus corpus includes resourcerich language english arabic resourcepoor language hindi thai paper describe gathering validation preprocessing large collection parallel communitygenerated subtitle furthermore describe methodology used prepare data machine translation task additionally provide documentlevel jointly aligned development test set language pair designed tuning testing machine translation system provide baseline result task highlight challenge face building machine translation system educational content
peer review constitutes core component scholarly publishing yet demand substantial expertise training susceptible error bias various application nlp peer reviewing assistance aim support reviewer complex process lack clearly licensed datasets multidomain corpus prevent systematic study nlp peer review remedy introduce nlpeer first ethically sourced multidomain corpus k paper k review report five different venue addition new datasets paper draft cameraready version peer review nlp community establish unified data representation augment previous peer review datasets include parsed structured paper representation rich metadata versioning information complement resource implementation analysis three reviewing assistance task including novel guided skimming task work pave path towards systematic multifaceted evidencebased study peer review nlp beyond data code publicly available
documentlevel relation extraction docre aim extract relation among entity pair document work introduce logic constraint docre addressing issue opacity weak logic original docre model however focus forward logic constraint rule mined work often suffer pseudo rule high standardconfidence low support paper proposes bidirectional constraint beta rulesbcbr novel logic constraint framework bcbr first introduces new rule miner model rule beta contribtion forward reverse logic constraint constructed based beta rule finally bcbr reconstruct rule consistency loss bidirectional constraint regulate output docre model experiment show bcbr outperforms original docre model term relation extraction performance textasciitilde f score logical consistencytextasciitilde logic score furthermore bcbr consistently outperforms two logic constraint framework
hierarchical text classification htc focus classifying one text multiple label organized hierarchical taxonomy due wide involution realistic scenario htc attracts longterm attention industry academia however high cost hierarchical multilabel annotation make htc suffer data scarcity problem view difficulty balancing controllability multiple structural label text diversity automatically generating highquality data htc challenging underexplored fill blank propose novel data generation framework tailored htc achieve label controllability text diversity extracting highquality semanticlevel phraselevel hierarchical label information experimental result three benchmark demonstrate compared existing data augmentation method data generated method bring significant performance improvement several strong htc model extensive analysis confirms improvement yielded proposed method correlate enhancement label controllability text diversity
paper describe approach analysis spoken language translation combine phraselevel grammarbased parsing automatic domain action classification job analyzer transform utterance shallow semantic taskoriented interlingua representation goal hybrid approach provide accurate realtime analysis improve robustness portability new domain language
paper present model arabic morphological disambiguation based recurrent neural network rnn train long shortterm memory lstm cell several configuration embedding level model various morphological feature experiment show model outperform stateoftheart system without explicit use feature engineering however adding learning feature morphological analyzer model space possible analysis provides additional improvement make use resulting morphological model scoring ranking analysis morphological analyzer morphological disambiguation result show significant gain accuracy across several evaluation metric system result absolute increase stateoftheart full morphological analysis accuracy relative error reduction relative error reduction outofvocabulary word
show contextfree grammar new grammar constructed generates regular language construction differs existing method approximation use pushdown automaton avoided allows better insight generated language affected new method also attractive computational viewpoint
definition extraction task automatically extract term definition text recent year attracts wide interest nlp researcher paper describes unixlong team system semeval task defteval extracting termdefinition pair free text goal task extract definition word level bio tag relation task challenging due free style text especially definition term range across several sentence lack explicit verb phrase propose joint model train task definition extraction word level bio tagging simultaneously design creative format input bert capture location information entity definition adjust result bert rule finally apply tagid rootid bio tag predict relation achieve macroaveraged f score rank first official test set relation extraction subtask
describe approach semeval task detection persuasion technique multimodal content meme system combine pretrained multimodal model clip chained classifier also propose enrich data data augmentation technique submission achieves rank term fmicro fmacro test set
language model long prolific area study field natural language processing nlp one newer kind language model used word embeddings vector space representation vocabulary learned nonsupervised neural network based context word appear widely used downstream task many area study nlp area usually use vector model feature processing textual data paper present evaluation newly released model portuguese langauage trained corpus composed billion token first evaluation presented intrinsic task wes correctly build semantic syntactic relation second evaluation presented extrinsic task model used two downstream task named entity recognition semantic similarity sentence result show diverse comprehensive corpus often outperform larger less textually diverse corpus batch training may cause quality loss model
hierarchical text classification htc complex subtask multilabel text classification characterized hierarchical label taxonomy data imbalance bestperforming model aim learn static representation combining document hierarchical label information however relevance document section vary based hierarchy level necessitating dynamic document representation address propose higen textgenerationbased framework utilizing language model encode dynamic text representation introduce levelguided loss function capture relationship text label name semantics approach incorporates taskspecific pretraining strategy adapting language model indomain knowledge significantly enhancing performance class limited example furthermore present new valuable dataset called enzyme designed htc comprises article pubmed goal predicting enzyme commission ec number extensive experiment enzyme dataset widely recognized wos nyt datasets methodology demonstrates superior performance surpassing existing approach efficiently handling data mitigating class imbalance release code dataset httpsgithubcomviditjainhigen
paper present latexnumeric highprecision fullyautomated scalable framework extracting ecommerce numeric attribute unstructured product text like product description past work attribute extraction scalable rely manually curated training data either without use active learning rely distant supervision training data generation removing dependency manual label one issue distant supervision lead incomplete training annotation due missing attribute value matching propose multitask learning architecture deal missing label training data leading f improvement numeric attribute stateoftheart singletask architecture multitask architecture benefit numeric nonnumeric attribute present automated technique improve numeric attribute extraction model numeric attribute require list unit alias better matching distant supervision propose automated algorithm alias creation using unstructured text attribute value leading f improvement extensive experiment real world datasets numeric attribute across product category english marketplace show latexnumeric achieves high fscore without manual intervention making suitable practical application finally show improvement languageagnostic latexnumeric achieves f improvement nonenglish language
language model read biomedical text explain biomedical mechanism discussed work introduce biomedical mechanism summarization task biomedical study often investigate mechanism behind one entity eg protein chemical affect another biological context abstract publication often include focused set sentence present relevant supporting statement regarding relationship associated experimental evidence concluding sentence summarizes mechanism underlying relationship leverage structure create summarization task input collection sentence main entity abstract output includes relationship sentence summarizes mechanism using small amount manually labeled mechanism sentence train mechanism sentence classifier filter large biomedical abstract collection create summarization dataset k instance also introduce conclusion sentence generation pretraining task k instance benchmark performance large biodomain language model find pretraining task help improves performance best model produce acceptable mechanism output instance show task present significant challenge biomedical language understanding summarization
clinical named entity recognition ner essential extracting important medical insight clinical narrative given challenge obtaining expert training datasets realworld clinical application related data protection regulation lack standardised entity type work represents collaborative initiative aimed building german clinical ner system focus addressing obstacle effectively response challenge training data scarcity propose conditional relevance learning crl approach lowresource transfer learning scenario crl effectively leverage pretrained language model domainspecific open resource enabling acquisition robust base model tailored clinical ner task particularly face changing label set flexibility empowers implementation multilayered semantic annotation msa schema ner system capable organizing diverse array entity type thus significantly boosting ner system adaptability utility across various clinical domain case study demonstrate ner system applied overcome resource constraint comply data privacy regulation lacking prior training indomain data feedback expert user respective domain essential identifying area system refinement future work focus integration expert feedback improve system performance specific clinical context
describe arabicenglish englisharabic statistical machine translation system developed qatar computing research institute iwslt evaluation campaign spoken language translation used one phrasebased two hierarchical decoder exploring various setting thereof experimented three domain adaptation method various arabic word segmentation scheme combining output several system yielded gain bleu point baseline also describe specialized normalization scheme evaluating arabic output adopted iwslt evaluation campaign
sentence order prediction task finding correct order sentence randomly ordered document correctly ordering sentence requires understanding coherence respect chronological sequence event described text documentlevel contextual understanding commonsense knowledge centered around event often essential uncovering coherence predicting exact chronological order paper introduce stack framework based graph neural network temporal commonsense knowledge model global information predict relative order sentence graph network accumulates temporal evidence using knowledge past future formulates sentence ordering constrained edge classification problem report result five different datasets empirically show proposed method naturally suitable order prediction implementation work available urlhttpsgithubcomdeclarelabsentenceordering
work present unsupervised method selecting filter threshold value opusfilter parallel corpus cleaning toolbox method cluster sentence pair noisy clean category us feature noisy cluster center filtering parameter approach utilizes feature importance analysis disregard filter differentiate clean noisy data randomly sampled subset given corpus used filter selection ineffective filter run full corpus use set automatic evaluation metric assess quality translation model trained data filtered method data filtered opusfilters default parameter trained model cover englishgerman englishukrainian direction proposed method outperforms default parameter translation direction almost evaluation metric
nowadays neural network play important role task relation classification designing different neural architecture researcher improved performance large extent comparison traditional method however existing neural network relation classification usually shallow architecture eg onelayer convolutional neural network recurrent network may fail explore potential representation space different abstraction level paper propose deep recurrent neural network drnns relation classification tackle challenge propose data augmentation method leveraging directionality relation evaluated drnns semeval task achieve fscore outperforming previous stateoftheart recorded result
aspectbased sentiment analysis absa aim identify term multiword expression mwes sentiment expressed sentiment polarity associated development supervised model forefront research area however training model requires availability manually annotated datasets expensive timeconsuming furthermore available annotated datasets tailored specific domain language text type work address notable challenge current stateoftheart absa research propose hybrid approach aspect based sentiment analysis using transfer learning approach focus generating weaklysupervised annotation exploiting strength large language model llm traditional syntactic dependency utilise syntactic dependency structure sentence complement annotation generated llm may overlook domainspecific aspect term extensive experimentation multiple datasets performed demonstrate efficacy hybrid method task aspect term extraction aspect sentiment classification
hierarchical text classification important yet challenging task due complex structure label hierarchy existing method ignore semantic relationship text label make full use hierarchical information end formulate textlabel semantics relationship semantic matching problem thus propose hierarchyaware label semantics matching network himatch first project text semantics label semantics joint embedding space introduce joint embedding loss matching learning loss model matching relationship text semantics label semantics model capture textlabel semantics matching relationship among coarsegrained label finegrained label hierarchyaware manner experimental result various benchmark datasets verify model achieves stateoftheart result
chinese word segmentation cws undoubtedly important basic task natural language processing previous work focus textual modality often audio video utterance news broadcast facetoface dialogue textual acoustic visual modality normally exist end attempt combine multimodality mainly converted text actual voice information perform cws paper annotate new dataset cws containing text audio moreover propose timedependent multimodal interactive model based transformer framework integrate multimodal information word sequence labeling experimental result three different training set show effectiveness approach fusing text audio
probe pretrained transformer language model bridging inference first investigate individual attention head bert observe attention head higher layer prominently focus bridging relation incomparison lower middle layer also specific attention head concentrate consistently bridging importantly consider language model whole second approach bridging anaphora resolution formulated masked token prediction task ofcloze test formulation produce optimistic result without finetuning indicates pretrained language model substantially capture bridging inference investigation show distance anaphorantecedent context provided language model play important role inference
semisupervised text classificationbased paradigm sstc typically employ spirit selftraining key idea train deep classifier limited labeled text iteratively predict unlabeled text pseudolabels training however performance largely affected accuracy pseudolabels may significant realworld scenario paper present rankaware negative training rnt framework address sstc learning noisy label setting alleviate noisy information adapt reasoning uncertaintybased approach rank unlabeled text based evidential support received labeled text moreover propose use negative training train rnt based concept input instance belong complementary label complementary label randomly selected label except label ontarget intuitively probability true label serving complementary label low thus provides less noisy information training resulting better performance test data finally evaluate proposed solution various text classification benchmark datasets extensive experiment show consistently overcomes stateoftheart alternative scenario achieves competitive performance others code rnt publicly available github
conventional technique detecting online hate speech rely availability sufficient number annotated instance costly time consuming reason zeroshot fewshot detection offer attractive alternative paper explore zeroshot detection approach based natural language inference nli model since performance model approach depends heavily choice hypothesis goal determine factor affect quality detection conducted set experiment three nli model four hate speech datasets demonstrate zeroshot nlibased approach competitive approach require supervised learning yet highly sensitive choice hypothesis addition experiment indicate result set hypothesis different modeldata pair positively correlated correlation higher different datasets using model different model using dataset result suggest find hypothesis work well specific model domain specific type hate speech use hypothesis model also within different domain another model might require different suitable hypothesis order demonstrate high performance
paper explores task involving analysis emotion trigger within dialogue annotate utterance emotion identify trigger focusing binary labeling emphasize clear guideline replicability conduct thorough analysis including multiple system run experiment highlight effective technique simplifying complexity detailing clear methodology study contributes advancing emotion analysis trigger identification within dialogue system
internet meme become ubiquitous social medium network today due popularity also widely used mode expression spread disinformation online meme consist mixture text image require multimodal approach automatic analysis paper describe contribution semeval detection persuasian technique text image task propose multimodal learning system incorporates memebeddings viz joint text vision feature combining compact bilinear pooling automatically identify rhetorical psychological disinformation technique experimental result show proposed system constantly outperforms competition baseline achieves nd best macro fscore th best micro fscore participant
although multilingual language model exhibit impressive crosslingual transfer capability unseen language performance downstream task impacted script disparity language used multilingual model pretraining data using transliteration offer straightforward yet effective mean align script resourcerich language target language thereby enhancing crosslingual transfer capability however mixed language approach suboptimal since subset language benefit crosslingual transfer remainder impeded work focus maltese semitic language substantial influence arabic italian english notably written latin script present novel dataset annotated wordlevel etymology use dataset train classifier enables u make informed decision regarding appropriate processing token maltese language contrast indiscriminate transliteration translation mixing processing pipeline transliterate word arabic origin thereby resulting text mixture script finetune processed data four downstream task show conditional transliteration based word etymology yield best result surpassing finetuning raw maltese maltese processed nonselective pipeline
study present novel evaluation framework imagecaptioning model integrate statistical analysis common evaluation metric utilizing two popular datasets fashiongen amazon contrasting dataset variation evaluate four model videollava blip coca vitgpt approach reveals comparative strength model offering insight adaptability applicability realworld scenario also contributes field providing comprehensive evaluation method considers statistical significance practical relevance guide selection model specific application specifically propose rank score new evaluation metric designed ecommerce image search application employ clip score quantify dataset variation offer holistic view model performance
abstract meaning representation amr parsing aim abstracting away syntactic realization sentence denote meaning canonical form ideal paraphrase detection problem one required specify whether two sentence meaning show naive use amr paraphrase detection necessarily useful turn describe technique based latent semantic analysis combination amr parsing significantly advance stateoftheart result paraphrase detection microsoft research paraphrase corpus best result transductive setting accuracy f measure
knowledge lifeblood plethora application search recommender system natural language understanding thanks effort field semantic web linked open data growing number interlinked knowledge base supporting development advanced knowledgebased application unfortunately large number domainspecific application knowledge base unavailable paper present resource consisting large knowledge graph linking italian cultural heritage entity defined arco ontology concept defined wellknown knowledge base ie dbpedia getty gvp ontology describe methodology adopted semiautomatic resource creation provide indepth analysis resulting interlinked graph
sequencetosequence seqseq model achieved tremendous success text generation task however guarantee always generate sentence without grammatical error paper present preliminary empirical study whether much automatic grammatical error correction help improve seqseq text generation conduct experiment across various seqseq text generation task including machine translation formality style transfer sentence compression simplification experiment show stateoftheart grammatical error correction system improve grammaticality generated text bring taskoriented improvement task target sentence formal style
tutorial provides nontechnical introduction machine translation review whole scope mt outlining briefly history major application area today describing various kind mt technique inventedfrom direct replacement transfer holy grail interlingua briefly outline newest statisticsbased technique provides introduction difficult question mt evaluation topic include history development mt theoretical foundation mt traditional modern mt technique newest mt research thorny question evaluating mt system
key point analysis kpa one essential task building opinion summarization system capable generating key point collection argument toward particular topic furthermore kpa allows quantifying coverage summary counting matched argument aim creating highquality summary necessary indepth understanding individual argument well universal semantic specified context paper introduce promising model named matching statement mt incorporates discussed topic information argumentskey point comprehension fully understand meaning thus accurately performing ranking retrieving bestmatch key point input argument approach achieved th place track quantitative summarization key point analysis shared task ibm yielding competitive performance rd th strict relaxed mean average precision respectively
wordnet facilitated important research natural language processing usefulness somewhat limited relatively small lexical coverage paraphrase database ppdb cover time word lack semantic structure wordnet would make directly useful downstream task present method mapping word ppdb wordnet synset accuracy mapping also lay important groundwork incorporating wordnet relation ppdb increase utility semantic reasoning application
consider value replacing andor combining stringbasedmethods syntaxbased method phrasebased statistical machine translation pbsmt also consider relative merit using constituencyannotated v dependencyannotated training data automatically derive two subtreealigned treebanks dependencybased constituencybased parallel englishfrench corpus extract syntactically motivated word phrasepairs automatically measure pbsmt quality result show combining stringbased syntaxbased word phrasepairs improve translation quality irrespective type syntactic annotation furthermore using dependency annotation yield greater translation quality constituency annotation pbsmt
emerging trend use large language model llm reason complex goal orchestrate set pluggable tool apis accomplish goal functionality could among use case used build personal assistant knowledge worker impressive demo llm used autonomous agent tool composition solution ready missioncritical enterprise setting example brittle input change produce inconsistent result input use case many open problem exciting area nlp research trust explainability consistency reproducibility adherence guardrail policy best practice composable tool design need new metric benchmark vision paper illustrates example llmbased autonomous agent reason compose tool highlight case fail survey recent effort space lay research challenge make solution viable enterprise
intimacy essential element human relationship language crucial mean conveying textual intimacy analysis reveal social norm different context serve benchmark testing computational model ability understand social information paper propose novel weaklabeling strategy data augmentation text regression task called wader wader us data augmentation address problem data imbalance data scarcity provides method data augmentation crosslingual zeroshot task benchmark performance stateoftheart pretrained multilingual language model using wader analyze use sampling technique mitigate bias data optimally select augmentation candidate result show wader outperforms baseline model provides direction mitigating data imbalance scarcity text regression task
natural language processing nlp model gained substantial attention recent year research opened new path tackling humancomputer design hcd perspective natural language focus developing humancentered corpus specifically personabased corpus particular healthcare domain diabetes mellitus selfcare order follow hcd approach created persona model interpersonal interaction expert nonexpert user specific domain show hcd approach benefit language generation different perspective machine human contributing new direction lowresource context language english sensitive domain need promote effective communication essential
widespread adoption large language model llm across various region underscore urgent need evaluate alignment human value current benchmark however fall short effectively uncovering safety vulnerability llm despite numerous model achieving high score topping chart evaluation still significant gap llm deeper alignment human value achieving genuine harmlessness end paper proposes value alignment benchmark named flame encompasses common harmlessness principle unique morality dimension integrates specific chinese value harmony accordingly carefully design adversarial prompt incorporate complex scenario jailbreaking method mostly implicit malice prompting mainstream llm obtain model response rigorously annotate detailed evaluation finding indicate evaluated llm demonstrate relatively poor performance flame particularly safety fairness dimension also develop lightweight specified scorer capable scoring llm across multiple dimension efficiently evaluate new model benchmark complexity flame far exceeded existing benchmark setting new challenge contemporary llm highlighting need alignment llm benchmark publicly available httpsgithubcomaiflamesflames
pretrained multilingual language model become common tool transferring nlp capability lowresource language often adaptation work study performance extensibility interaction two adaptation vocabulary augmentation script transliteration evaluation partofspeech tagging universal dependency parsing named entity recognition nine diverse lowresource language uphold viability approach raising new question around optimally adapt multilingual model lowresource setting
empirical research natural language processing nlp adopted narrow set principle assessing hypothesis relying mainly pvalue computation suffers several known issue alternative proposal welldebated adopted field remain rarely discussed used within nlp community address gap contrasting various hypothesis assessment technique especially commonly used field evaluation based bayesian inference since statistical technique differ hypothesis support argue practitioner first decide target hypothesis choosing assessment method crucial common fallacy misconception misinterpretation surrounding hypothesis assessment method often stem discrepancy one would like claim versus method used actually assesses survey reveals issue omnipresent nlp research community step forward provide best practice guideline tailored nlp research well easytouse package bayesian assessment hypothesis complementing existing tool
crosslingual embeddings aim represent word multiple language shared vector space capturing semantic similarity across language crucial component scaling task multiple language transferring knowledge language rich resource lowresource language common approach learning crosslingual embeddings train monolingual embeddings separately language learn linear projection monolingual space shared space mapping relies small seed dictionary highquality generic seed dictionary pretrained crosslingual embeddings available many language pair little research perform specialised task paper investigate best practice constructing seed dictionary specific domain evaluate embeddings sequence labelling task curriculum vitae parsing show size bilingual dictionary frequency dictionary word domain corpus source data taskspecific v generic influence performance also show less training data available lowresource language construction bilingual dictionary matter demonstrate choice crucial zeroshot transfer learning case
neural text generation model likely suffer lowdiversity problem various decoding strategy trainingbased method proposed promote diversity exploiting contextual feature rarely consider incorporating syntactic structure clue work propose using linguistic annotation ie partofspeech po guide text generation detail introduce po guided softmax explicitly model two posterior probability nextpos ii nexttoken vocabulary target po po guided sampling strategy proposed address lowdiversity problem enriching diversity po extensive experiment human evaluation show compared existing stateoftheart method po guided softmax sampling posg generate diverse text maintaining comparable quality
sanskrit small word morpheme combined form compound word process known sandhi sandhi splitting process splitting given compound word constituent morpheme although rule governing word splitting exists language highly challenging identify location split compound word though existing sandhi splitting system incorporate predefined splitting rule low accuracy compound word might broken multiple way provide syntactically correct split research propose novel deep learning architecture called double decoder rnn ddrnn predicts location split accuracy ii predicts constituent word learning sandhi splitting rule accuracy outperforming stateofart additionally show generalization capability deep learning model showing competitive result problem chinese word segmentation well
despite welldeveloped cutedge representation learning language language representation model usually focus specific level linguistic unit work introduces universal language representation learning ie embeddings different level linguistic unit text quite diverse length uniform vector space propose training objective misad utilizes meaningful ngrams extracted large unlabeled corpus simple effective algorithm pretrained language model empirically verify well designed pretraining scheme may effectively yield universal language representation bring great convenience handling multiple layer linguistic object unified way especially model achieves highest accuracy analogy task different language level significantly improves performance downstream task glue benchmark question answering dataset
although fluency automatically generated abstractive summary improved significantly advanced method inconsistency remains summarization recognized issue addressed study propose methodology localizing inconsistency error summarization synthetic dataset contains variety factual error likely produced common summarizer created applying sentence fusion compression paraphrasing operation creating dataset automatically label erroneous phrase dependency relation inconsistent contribute detecting error adequately existing model rely dependency arclevel label subsequently synthetic dataset employed weak supervision train model called sumphrase jointly localizes error summary corresponding sentence source document empirical result demonstrate sumphrase model detect factual error summarization effectively existing weakly supervised method owing phraselevel labeling moreover joint identification errorcorresponding original sentence proven effective improving error detection accuracy
standard method multilabel text classification largely rely encoderonly pretrained language model whereas encoderdecoder model proven effective classification task study compare four method multilabel classification two based encoder two based encoderdecoder carry experiment four datasetstwo legal domain two biomedical domain two level label granularity always depart pretrained model result show encoderdecoder method outperform encoderonly method growing advantage complex datasets labeling scheme finer granularity using encoderdecoder model nonautoregressive fashion particular yield best performance overall study approach ablation better understand strength
large language model llm like chatgpt exhibited remarkable ability wide range natural language processing nlp task including various machine translation ability accomplished chat however model accessible restricted apis creates barrier new research advancement field therefore propose parrot framework enhance regulate translation ability chat based opensource llm eg llama humanwritten translation feedback data specifically parrot reformulates translation data instructionfollowing style introduces hint field incorporating extra requirement regulate translation process accordingly propose three instruction type finetuning parrot model including translation instruction contrastive instruction errorguided instruction experiment flores subset wmt test set suggest translation instruction improves translation performance vanilla llm significantly errorguided instruction lead improvement demonstrates importance learning lowquality translation annotated human also demonstrate potential automatic evaluation tool providing quality information translation constructing errorguided instruction direction lack human annotation data please refer github project implementation detail httpsgithubcomwxjiaoparrot
request usg national virtual translation center university maryland center advanced study language conducted study assessed role several factor mediating transcript usefulness translation task factor included source language mandarin modern standard arabic native speaker status translator transcript quality low moderate word error rate transcript functionality static dynamic using mandarin arabic translator half native speaker language broadcast news clip input study demonstrated translation environment provide dynamic transcript low moderate word error rate likely improve performance measured integrated speed accuracy score among nonnative speaker without decreasing performance among native speaker
causality detection identification centered identifying semantic cognitive connection sentence paper describe effort team ltrc causal news corpus event causality shared task th workshop challenge application automated extraction sociopolitical event text case shared task consisted two subtasks identifying sentence contains causality relation identifying span text correspond cause effect signal finetuned transformerbased model adapter subtasks bestperforming model obtained binary f score heldout data subtask macro f score heldout data subtask approach ranked third subtask fourth subtask paper describes experiment solution analysis detail
propose first lightlysupervised approach scoring argument persuasiveness key approach novel hypothesis lightlysupervised persuasiveness scoring possible explicitly modeling major error negatively impact persuasiveness evaluation new annotated corpus online debate argument approach rival fullysupervised counterpart performance four scoring metric using available training instance
rich diverse knowledge base kb foundational building block online knowledge sharing community stackoverflow quora application conversational assistant aka chatbots popular format knowledge base questionanswer pair faq question designed accurately match multitude query paper address problem automatic creation qabased knowledge base domainspecific longform textual content eg web article specifically consider problem question generation task generating question given paragraph text input goal achieve diversity fidelity generated question towards goal propose protege diverse question generation framework consists novel encoderdecoder based large language model llm architecture take variety prompt generate diverse set candidate question hillclimbing algorithm maximizes submodular objective function balance diversity fidelity experiment three popular public qa datasets demonstrate protege improves diversity fidelity diverse beam search promptbased baseline
present several experiment aiming measuring semantic compositionality nv expression basque approach based hypothesis compositionality related distributional similarity context nv expression compared context corresponding component mean different technique similarity measure usually used vector space model vsm latent semantic analysis lsa measure implemented lemur toolkit indri index tfidf okapi index kullbackleibler divergence using previous work cooccurrence technique baseline result point improvement using indri index kullbackleibler divergence slight improvement used combination cooccurrence measure tscore via rankaggregation work part project mwe extraction characterization using different technique aiming measuring property related idiomaticity institutionalization noncompositionality lexicosyntactic fixedness
significant progress recent year field natural language processing thanks introduction transformer architecture current stateoftheart model via large number parameter pretraining massive text corpus shown impressive result several downstream task many researcher studied previous nontransformer model understand actual behavior different scenario showing model taking advantage clue failure datasets slight perturbation input data severely reduce performance contrast recent model systematically tested adversarialexamples order show robustness severe stress condition reason work evaluates three transformerbased model roberta xlnet bert natural language inference nli question answering qa task know robust flaw predecessor result experiment reveal roberta xlnet bert robust recurrent neural network model stress test nli qa task nevertheless still fragile demonstrate various unexpected behavior thus revealing still room future improvement field
deep cnnlstm hybrid neural network proven improve accuracy optical character recognition ocr model different language paper examine extent network improve ocr accuracy rate swedish historical newspaper experimenting open source ocr engine calamari able show mixed deep cnnlstm hybrid model outperform previous model task character recognition swedish historical newspaper spanning achieved average character accuracy rate car new stateoftheart result th century swedish newspaper text data code model released ccby licence
paper present hierarchical graph network hgn multihop question answering aggregate clue scattered text across multiple paragraph hierarchical graph created constructing node different level granularity question paragraph sentence entity representation initialized pretrained contextual encoders given hierarchical graph initial node representation updated graph propagation multihop reasoning performed via traversing graph edge subsequent subtask eg paragraph selection supporting fact extraction answer prediction weaving heterogeneous node integral unified graph hierarchical differentiation node granularity enables hgn support different question answering subtasks simultaneously experiment hotpotqa benchmark demonstrate proposed model achieves new state art outperforming existing multihop qa approach
reproducibility generally regarded requirement form experimental science even reproduction research result recently beginning practiced acknowledged context reprolang shared task contribute trend reproducing work reported bohnet et al morphosyntactic tagging metabilstm model achieved stateoftheart result across wide range language done integrating sentencelevel singleword context synchronized training metamodel reproduction partially confirms main result paper term outperforming earlier model result reproduction improve earlier model morphological tagging task partofspeech tagging task furthermore even improve earlier model fail match fscores reported metabilstm model chose contact original author reproduction study uncertainty degree parallelism achieved original study reproduction limit value finding assessment reliability original result time however underscore relevance reproduction effort regard reproducibility interpretability finding discrepancy finding original result demonstrate room improvement many aspect reporting regarding reproducibility experiment addition suggest different reporting choice could improve interpretability result
paper provides new way improve efficiency reinforce training process apply task instance selection distant supervision modeling instance selection one bag sequential decision process reinforcement learning agent trained determine whether instance valuable construct new bag less noisy instance however unbiased method reinforce could usually take much time train paper adopts posterior regularization pr integrate domainspecific rule instance selection using reinforce experiment result show method remarkably improves performance relation classifier trained cleaned distant supervision dataset well efficiency reinforce training
automatically solving math word problem interesting research topic need bridge natural language description formal math equation previous study introduced endtoend neural network method approach efficiently consider important characteristic equation ie abstract syntax tree address problem propose treestructured decoding method generates abstract syntax tree equation topdown manner addition approach automatically stop decoding without redundant stop token experimental result show method achieves single model stateoftheart performance mathk largest dataset task
paper deal sentencelevel sentiment classification though variety neural network model proposed recently however previous model either depend expensive phraselevel annotation remarkably degraded performance trained sentencelevel annotation fully employ linguistic resource eg sentiment lexicon negation word intensity word paper propose simple model trained sentencelevel annotation also attempt model linguistic role sentiment lexicon negation word intensity word result show model able capture linguistic role sentiment word negation word intensity word sentiment expression
propose valse vision language structured evaluation novel benchmark designed testing generalpurpose pretrained vision language vl model visiolinguistic grounding capability specific linguistic phenomenon valse offer suite six test covering various linguistic construct solving requires model ground linguistic phenomenon visual modality allowing finegrained evaluation hitherto possible build valse using method support construction valid foil report result evaluating five widelyused vl model experiment suggest current model considerable difficulty addressing phenomenon hence expect valse serve important benchmark measure future progress pretrained vl model linguistic perspective complementing canonical taskcentred vl evaluation
paper describe new corpus named dirhalf realcorpus composed typical home automation speech interaction european portuguese recorded inescids spoken language system laboratory lf support activity distantspeech interaction robust home application dirha eufunded project corpus multimicrophone multiroom database real continuous audio sequence containing read phonetically rich sentence read spontaneous keyword activation sentence read spontaneous home automation command background noise condition controlled randomly recreated noise typically found home environment experimental validation corpus reported comparison result obtained simulated corpus using fully automated speech processing pipeline two fundamental automatic speech recognition task typical alwayslistening homeautomation scenario system activation voice command recognition attending result corpus presence overlapping voicelike noise shown main problem simulated sequence contain concurrent speaker result general challenging corpus real sequence performance drop drastically tv radio
promptbased method widely used fewshot named entity recognition ner paper first conduct preliminary experiment observe key affecting performance promptbased ner model capability detect entity boundary however existing model fail boost capability solve issue propose novel model parabart consists bart encoder specially designed parabiotic decoder specifically parabiotic decoder includes two bart decoder conjoint module two decoder responsible entity boundary detection entity type classification respectively connected conjoint module used replace unimportant token embeddings one decoder average embedding token present novel boundary expansion strategy enhance model capability entity type classification experimental result show parabart achieve significant performance gain stateoftheart competitor
explored effect domain knowledge parallel sentence filtering domain corpus model built sentence mined domain corpus without domain knowledge performed poorly whereas model performance improved bleu point average domain centric filtering used large language model selecting similar domain aligned sentence experiment show importance inclusion domain knowledge sentence selection methodology even initial comparable corpus domain
study reported aim investigating extent conceptual representational tool provided lexical model designed semantic representation general language may suit requirement knowledge modelling domainspecific perspective general linguistic ontology set semantic link allow classifying describing interconnecting word sens play central role structuring representing knowledge health medicine vocabulary taken case study investigation
dominant neural machine translation nmt model restricted make prediction according local context preceding word lefttoright manner although many previous study try incorporate global information nmt model still exist limitation effectively exploit bidirectional global context paper propose confidence based bidirectional global context aware cbbgca training framework nmt nmt model jointly trained auxiliary conditional masked language model cmlm training consists two stage multitask joint training confidence based knowledge distillation first stage sharing encoder parameter nmt model additionally supervised signal cmlm decoder contains bidirectional global context moreover second stage using cmlm teacher pertinently incorporate bidirectional global context nmt model unconfidentlypredicted target word via knowledge distillation experimental result show proposed cbbgca training framework significantly improves nmt model bleu score three largescale translation datasets namely wmt englishtogerman wmt chinesetoenglish wmt englishtofrench respectively
sequential sentence classification aim classify sentence document based context sentence appear existing work address problem using hierarchical sequence labeling network however ignore considering latent segment structure document contiguous sentence often coherent semantics paper proposed spanbased dynamic local attention model could explicitly capture structural information proposed supervised dynamic local attention introduce auxiliary task called spanbased classification explore spanlevel representation extensive experiment show model achieves better competitive performance stateoftheart baseline two benchmark datasets
grammar induction task learning set syntactic rule minimally annotated training data provides mean exploring longstanding question whether human rely innate knowledge acquire language various formalism available grammar induction categorial grammar provide appealing option due transparent interface syntax semantics however obtain competitive result previous categorial grammar inducer relied shortcut partofspeech annotation ad hoc bias term objective function ensure desirable branching behavior present categorial grammar inducer eliminates shortcut learns raw data rely biased objective function improvement achieved novel stochastic process used select set available syntactic category corpus english childdirected speech model attains recallhomogeneity large improvement previous categorial grammar inducer
paper present attempt build modern standard arabic msa sentencelevel simplification system experimented sentence simplification using two approach classification approach leading lexical simplification pipeline use arabicbert pretrained contextualised model well model fasttext word embeddings ii generative approach seqseq technique applying multilingual texttotext transfer transformer mt developed training corpus aligning original simplified sentence internationally acclaimed arabic novel saaq albambuu evaluate effectiveness method comparing generated simple sentence target simple sentence using bertscore evaluation metric simple sentence produced mt model achieve p r f via bertscore combining arabicbert fasttext achieves p r f addition report manual error analysis experiment
large language model particularly gpt able produce high quality summary ofgeneral domain news article zeroshot setting however unclear model similarly capable specialized domain biomedicine paper enlist domain expert individual medical training evaluate summary biomedical article generated gpt given supervision consider bothsingle multidocument setting former gpt tasked generating regular plainlanguage summary article describing randomized controlled trial thelatter assess degree gpt able synthesize evidence reported acrossa collection article design annotation scheme evaluating model output withan emphasis assessing factual accuracy generated summary find whilegpt able summarize simplify single biomedical article faithfully strugglesto provide accurate aggregation finding multiple document release datacode annotation used work
paper describes dataset composed two subcorpora two different source italian queereotypes corpus includes social medium text regarding lgbtqia individual behavior ideology event text collected facebook twitter annotated presence stereotype orthogonal dimension hate speech aggressiveness offensiveness irony one subcorpus stance resource developed natural language processing researcher together activist italian lgbtqia notforprofit organization creation dataset allows nlp community study stereotype marginalized group individual ultimately develop proper tool measure reduce online spread stereotype test robustness language resource performed mean fold crossvalidation experiment finally text classification experiment carried finetuned version alberto bertbased model pretrained italian tweet mbert obtaining good result task stereotype detection suggesting stereotype towards different target might share common trait
paper present approach improve robustness bert language model word substitutionbased adversarial attack leveraging adversarial perturbation selfsupervised contrastive learning create wordlevel adversarial attack generating hard positive onthefly adversarial example contrastive learning contrast previous work method improves model robustness without using labeled data experimental result show method improves robustness bert four different word substitutionbased adversarial attack combining method adversarial training give higher robustness adversarial training alone method improves robustness bert purely unlabeled data open possibility using large text datasets train robust language model word substitutionbased adversarial attack
rumor rampant era social medium conversation structure provide valuable clue differentiate real fake claim however existing rumor detection method either limited strict relation user response oversimplify conversation structure study substantially reinforces interaction user opinion alleviating negative impact imposed irrelevant post first represent conversation thread undirected interaction graph present claimguided hierarchical graph attention network rumor classification enhances representation learning responsive post considering entire social context attends post semantically infer target claim extensive experiment three twitter datasets demonstrate rumor detection method achieves much better performance stateoftheart method exhibit superior capacity detecting rumor early stage
paper describes university maryland submission duolingo shared task simultaneous translation paraphrase language education staple unlike standard machine translation task staple requires generating set output given input sequence aiming cover space translation produced language learner adapt neural machine translation model requirement generating nbest translation hypothesis model finetuned learner translation oversampled reflect distribution learner response b filtering hypothesis using featurerich binary classifier directly optimizes close approximation official evaluation metric combination system use two strategy achieves f score vietnamese portuguese respectively ranking nd th leaderboard
rapidly evolving landscape large language model llm introduction welldefined standardized evaluation methodology remains crucial challenge paper trace historical trajectory llm evaluation foundational question posed alan turing modern era ai research categorize evolution llm distinct period characterized unique benchmark evaluation criterion llm increasingly mimic humanlike behavior traditional evaluation proxy turing test become less reliable emphasize pressing need unified evaluation system given broader societal implication model analysis common evaluation methodology advocate qualitative shift assessment approach underscoring importance standardization objective criterion work serf call ai community collaboratively address challenge llm evaluation ensuring reliability fairness societal benefit
existing backdoor defense method effective limited trigger type defend different trigger type start classirrelevant nature poisoning process propose novel weakly supervised backdoor defense framework wedef recent advance weak supervision make possible train reasonably accurate text classifier using small number userprovided classindicative seed word seed word shall considered independent trigger therefore weakly supervised text classifier trained poisoned document without label likely backdoor inspired observation wedef define reliability sample based whether prediction weak classifier agree label poisoned training set improve result twophase sanitization iteratively refine weak classifier based reliable sample train binary poison classifier distinguishing unreliable sample reliable sample finally train sanitized model sample poison classifier predicts benign extensive experiment show wedef effective popular triggerbased attack eg word sentence paraphrase outperforming existing defense method
human frequently able read interpret emotion others directly taking verbal nonverbal signal humantohuman communication account infer even experience emotion mediated story computer however emotion recognition complex problem thought feeling root many behavioural response deeply entangled neurophysiological change within human emotion subjective often expressed subtle manner highly depending context example machine learning approach textbased sentiment analysis often rely incorporating sentiment lexicon language model capture contextual meaning paper explores enhance sentiment analysis using biofeedback human experiencing emotion reading text specifically record heart rate brain wave reader presented short text annotated emotion induce use physiological signal improve performance lexiconbased sentiment classifier find combination several biosignals improve ability textbased classifier detect presence sentiment text persentence level
model mbert xlmr shown success solving codemixed nlp task even though exposed text pretraining codemixed nlp model relied using synthetically generated data along naturally occurring data improve performance finetuning mbert data improves codemixed performance benefit using different type codemixed data arent clear paper study impact finetuning different type codemixed data outline change occur model finetuning finding suggest using naturally occurring codemixed data brings best performance improvement finetuning finetuning type codemixed text improves responsivity attention head codemixed text input
paper give overview ict statistical machine translation system evaluation campaign international workshop spoken language translation iwslt year evaluation participated chineseenglish transcript translation task developed three system based different technique formally syntaxbased system bruin extended phrasebased system confucius linguistically syntaxbased system lynx describe model three system compare performance detail set bruin primary system rank among primary result according official evaluation result
advanced abstractive dialogue summarizers lack generalization ability new domain existing research domain adaptation summarization generally rely largescale pretrainings explore lightweight finetuning method domain adaptation dialogue summarization paper propose efficient generalizable domainoriented prefixtuning model utilizes domain word initialized prefix module alleviate domain entanglement adopts discrete prompt guide model focus key content dialogue enhance model generalization conduct zeroshot experiment build domain adaptation benchmark two multidomain dialogue summarization datasets todsum qmsum adequate experiment qualitative analysis prove effectiveness method
present new factchecking benchmark checkcovid requires system verify claim covid news using evidence scientific article approach factchecking particularly challenging requires checking internet text written everyday language evidence journal article written formal academic language checkcovid contains expertannotated news claim coronavirus paired sentencelevel evidence scientific journal article veracity label includes extracted journalistwritten composed annotatorwritten claim experiment using factchecking specific system gpt respectively achieve f score task reveal difficulty automatically factchecking claim type importance indomain data good performance data model released publicly urlhttpsgithubcomposuercheckcovid
finetuning paradigm widely adopted train neural model tailored specific task however recent upsurge large language model llm characterized billion parameter introduced profound computational challenge finetuning process fueled intensive research parameterefficient finetuning peft technique usually involving training selective subset original model parameter one used approach adapter add trainable lightweight layer existing pretrained weight within context propose adakron adapterbased finetuning kronecker product particular leverage kronecker product combine output two small network resulting final vector whose dimension product dimension individual output allowing u train model original parameter evaluate adakron performing series experiment general language understanding evaluation glue benchmark achieving result ballpark recent stateoftheart peft method despite training fewer parameter
paper propose new scheme annotating response token rts triggering expression japanese multiparty conversation proposed scheme rts first identified classified according form subclassified according sequential position discourse deeply study context rts used scheme also provides procedure annotating triggering expression considered trigger listener production rts rts classified according whether particular object proposition speaker turn listener show positive aligned stance triggering expression identified speaker turn include surprising fact newsworthy thing opinion assessment focus response question repair initiation keywords narrative embedded proposition quoted others statement thought agreed upon assessed noticed illustrative application scheme present preliminary analysis distribution latency listener response triggering expression showing differs according rts form position
every fiscal quarter company hold earnings call company executive respond question analyst call analyst often change price target recommendation used equity search report help investor make deci sion paper examine analyst decision making behavior pertains language content earnings call identify set pragmatic feature analyst question correlate analyst precall investor recommendation also analyze degree semantic pragmatic feature earnings call complement market data predicting analyst postcall change price target result show earnings call moderately predictive analyst decision even though decision influenced number factor including private communication company executive market condition breakdown model error indicates disparate performance call different market sector
paper present submission sentencelevel mqm benchmark quality estimation shared task named unite unified translation evaluation specifically system employ framework unite combined three type input format training pretrained language model first apply pseudolabeled data example continuously pretraining phase notably reduce gap pretraining finetuning use data cropping rankingbased score normalization strategy finetuning phase use direct assessment da multidimensional quality metric mqm data past year wmt competition finally collect sourceonly evaluation result ensemble prediction generated two unite model whose backbone xlmr infoxlm respectively result show model reach st overall ranking multilingual englishrussian setting nd overall ranking englishgerman chineseenglish setting showing relatively strong performance year quality estimation competition
large language model llm generative ai emerged important area field natural language processing nlp llm considered key component several nlp task summarization questionanswering sentiment classification translation newer llm chatgpt bloomz several variant known train multilingual training data hence expected process generate text multiple language considering widespread use llm evaluating efficacy multilingual setting imperative work evaluate newest generative model chatgpt mt bloomz context indic language specifically consider natural language generation nlg application summarization questionanswering monolingual crosslingual setting observe current generative model limited capability generating text indic language zeroshot setting contrast generative model perform consistently better manual qualitybased evaluation indic language english language generation considering limited generation performance argue llm intended use zeroshot fashion downstream application
supplementary training intermediate labeleddata task stilt widely applied technique first finetunes pretrained language model intermediate task target task interest stilt able improve performance pretrained language model still unclear work previous research show intermediate task involving complex inference commonsense reasoning work especially well robertalarge paper discover improvement intermediate task could orthogonal containing reasoning complex skill simple realfake discrimination task synthesized gpt benefit diverse target task conduct extensive experiment study impact different factor stilt finding suggest rethinking role intermediate finetuning stilt pipeline
paper introduces surface construction labeling scl task expands coverage shallow semantic parsing ssp include frame triggered complex construction present deepcx neural transitionbased system scl test case approach apply deepcx task tagging causal language english relies wider variety construction typically addressed ssp report substantial improvement previous tagging effort causal language dataset also propose way deepcx could extended still difficult construction semantic domain appropriate datasets become available
nowadays meme considered one prominent form medium disseminate information social medium meme typically constructed multilingual setting using visuals text sometimes people use meme influence mass audience rhetorical psychological technique causal oversimplification namecalling smear challenging task identify technique considering meme multimodal characteristic address challenge semeval task introduced shared task focusing detecting persuasion technique multilingual meme paper present participation subtasks b use finetuned languageagnostic bert sentence embedding labse model extract effective contextual feature meme text address challenge identifying persuasion technique subtask subtask b finetune vision transformer xlmroberta extract effective contextual information meme image text data finally unify feature employ single feedforward linear layer top obtain prediction label experimental result semeval task benchmark dataset manifested potency proposed method subtasks b
paper present finding mlesg task focused classifying news snippet various language risk opportunity esg environmental social governance context experimented data augmentation translation facilitated large language model llm found augmenting english dataset help improve performance finetuning roberta model original data achieved top position english second place french task contrast could achieve comparable result french dataset solely using english translation securing third position french task marginal f difference secondplace model
automated completion open knowledge base open kb constructed triple form subject phrase relation phrase object phrase obtained via open information extraction open ie system useful discovering novel fact may directly present text however research open kb completion open kbc far limited resourcerich language like english using latest advance multilingual open ie construct first multilingual open kbc dataset called mokb containing fact wikipedia six language including english improvingthe previous open kb construction pipeline multilingual coreference resolution andkeeping entitylinked triple create dense open kb experiment several model task observe consistent benefit combining language help shared embedding space well translation fact also observe current multilingual model struggle remember fact seen language different script
procedural knowledge understanding pku underlies ability infer goalstep relation task visual goalstep inference address ability multimodal domain requires identify image represent step towards achieving textually expressed goal best existing method encode text image either independent encoders objectlevel multimodal encoders using blackbox transformer stand contrast early linguistically inspired method event representation focus capturing crucial information namely action participant learn stereotypical event sequence hence procedural knowledge work study various method effect pku injecting early shallow event representation nowadays multimodal deep learningbased model find early linguistically inspired method representing event knowledge contribute understand procedure combination modern visionandlanguage model future going explore complex structure event study exploit top large language model
pretrained largescale language model increasingly demonstrated high accuracy many natural language processing nlp task however limited weight storage computational speed hardware platform impeded popularity pretrained model especially era edge computing work propose efficient transformerbased largescale language representation using hardwarefriendly block structure pruning incorporate reweighted group lasso blockstructured pruning optimization besides significantly reduced weight storage computation proposed approach achieves high compression rate experimental result different model bert roberta distilbert general language understanding evaluation glue benchmark task show achieve x zero minor accuracy degradation certain task proposed method also orthogonal existing compact pretrained language model distilbert using knowledge distillation since x average compression rate achieved top distilbert zero minor accuracy degradation suitable deploy final compressed model resourceconstrained edge device
multival valence lexicon derived lexicon computational hpsg grammar norwegian spanish ga iso gaa altogether verb entry average valence type defined language lexical resource mapped onto common set discriminants common array value stored relational database linked web demo wiki presentation search discriminants syntactic argument structure sa functional specification situation type aspect subset language well verb type system grammar search result lexical entry satisfying discriminants entered exposing specification respective provenance grammar ga grammar lexicon turn converted ga toolbox lexicon aside creation multilingual valence resource converging converting existing resource paper also address tool creation resource part corpus annotation less resourced language
decade selfrespecting linguistic engineering initiative designed implemented custom representation various layer example morphological syntactic semantic analysis despite occasional effort harmonization even standardization field today blessed multitude way encoding exchanging linguistic annotation type level abstract syntax naming choice course file format large degree possible work within across design plurality conversion often may good reason divergent design reflecting difference use however likely abstract commonality across choice representation obscured superficial difference conversely obvious procedure tease apart actually constitute contentful v mere technical divergence study seek conceptually align three representation common type morphosyntactic analysis pinpoint view constitute contentful difference reflect underlying principle specific requirement led individual choice expect indepth understanding choice across design may led increased harmonization least informed design future representation
paper address task sign segmentation segmentmeaning mapping context sign language sl recognition aim give overview linguistic property sl coarticulation simultaneity make task complex better understanding sl structure necessary ground design development sl recognition segmentation methodology fundamental machine translation language based preliminary exploration proposal mapping segment meaning form agglomerate lexical nonlexical information introduced
approach presented enables japanese user knowledge english legal english generate patent claim english japaneseonly interface exploit highly determined structure patent claim merges natural language generation nlg machine translation mt technique resource realized autopat pctransfer application due tuned mt engine approach seen humanaided machine translation hamt system circumventing major obstacle fullscale japaneseenglish mt approach fully implemented large scale commercially released autumn
overcrowding emergency room major challenge faced hospital across united state overcrowding result longer wait time turn shown adversely affect patient satisfaction clinical outcome procedure reimbursement paper present research aim automatically predict discharge disposition patient received medical treatment emergency department make use corpus consists note containing patient complaint diagnosis information disposition entered health care provider use corpus develop model us complaint diagnosis information predict patient disposition show proposed model substantially outperforms baseline predicting common disposition type longterm goal research build model implemented realtime service application predict disposition patient arrive
attention mechanism proven effective many nlp task majority datadriven propose novel knowledgeattention encoder incorporates prior knowledge external lexical resource deep neural network relation extraction task furthermore present three effective way integrating knowledgeattention selfattention maximize utilization knowledge data proposed relation extraction system endtoend fully attentionbased experiment result show proposed knowledgeattention mechanism complementary strength selfattention integrated model outperform existing cnn rnn selfattention based model stateoftheart performance achieved tacred complex largescale relation extraction dataset
introduce ruse metric wmt metric shared task sentence embeddings capture global information captured local feature based character word ngrams although training sentence embeddings using smallscale translation datasets manual evaluation difficult sentence embeddings trained largescale data task improve automatic evaluation machine translation use multilayer perceptron regressor based three type sentence embeddings experimental result wmt wmt datasets show ruse metric achieves stateoftheart performance segment systemlevel metric task embedding feature
gender bias word embeddings gradually becomes vivid research field recent year study field aim measurement debiasing method english target language paper investigates gender bias static word embeddings unique perspective chinese adjective training word representation different model gender bias behind vector adjective assessed comparison produced result human scored data set demonstrate gender bias encoded word embeddings differentiates people attitude
early attempt process natural language mechanical mean machine date back thirty century first machine translation application known fifty view long history machine translation rather strange even midnineties technology used quite rarely daily work translator based eight year experience user machine translation starting logo changing metal discus reason translator still reluctant use machine translation everyday work
book hour bestseller late middle age renaissance historical invaluable treasure documenting devotional practice christian late middle age textual content scarcely studied manuscript nature length complex content first glance look standardized however study book hour raise important challenge image analysis often lavish ornamentation illegible painted initial linefillers etc abbreviated word multilingualism difficult address handwritten text recognition htr ii hierarchical entangled structure offer new field investigation text segmentation iii digital humanity textual content give opportunity historical analysis paper provide first corpus book hour consists latin transcription book hour generated handwritten text recognition htr like optical character recognition ocr handwritten printed text designed structural scheme book hour annotated manually two book hour according scheme lastly performed systematic evaluation main state art text segmentation approach
argument mining system often consider contextual information ie information outside argumentative discourse unit trained accomplish task argument component identification classification relation extraction however prior work carefully analyzed utility different contextual property contextaware model work show two different type contextual information local discourse context speaker context incorporated computational model classifying argument component multiparty classroom discussion find context type improve performance although improvement dependent context size position
investigate use extended context attentionbased neural machine translation base experiment translated movie subtitle discus effect increasing segment beyond single translation unit study use extended source language context well bilingual context extension model learn distinguish information different segment surprisingly robust respect translation quality pilot study observe interesting crosssentential attention pattern improve textual coherence translation least selected case
present kyotonmt opensource implementation neural machine translation paradigm implementation done python chainer easytouse deep learning framework
determining textual entailment text important many nlp task summarization question answering information extraction retrieval various method suggested based external knowledge source however resource always available language acquisition typically laborious costly distributional word representation word embeddings learned large corpus shown capture syntactic semantic word relationship model contributed improving performance several nlp task paper address problem textual entailment arabic employ traditional feature distributional representation crucially depend external resource process suggested approach yield state art performance standard data set arbte achieving accuracy compared state art
paper present quandho question answering data italian history italian question answering dataset created cover specific domain ie history italy first half xx century dataset includes question manually classified annotated lexical answer type set questionanswer pair resource freely available research purpose used retrain domain independent question answering system improve performance domain interest ongoing experiment development question classifier automatic tagger lexical answer type also presented
term extraction information extraction task root knowledge discovery platform developing term extractor able generalize across diverse potentially highly technical domain challenging annotation domain requiring indepth expertise scarce expensive obtain paper describe term extraction subsystem commercial knowledge discovery platform target highly technical field pharma medical material science able generalize across domain introduce fully unsupervised annotator ua extract term combining novel morphological signal subword tokenization termtotopic intraterm similarity metric computed using generaldomain pretrained sentenceencoders annotator used implement weaklysupervised setup transformermodels finetuned pretrained training data generated running ua large unlabeled corpus experiment demonstrate setup improve predictive performance decreasing inference latency cpu gpus annotator provide competitive baseline case annotation available
generative large language model llm gpt become increasingly effective versatile natural language processing nlp task one task lexical simplification stateoftheart method involve complex multistep process use deep learning nondeep learning process llama llm full research access hold unique potential adaption entire l pipeline paper detail process finetuning llama create lsllama performs comparably previous l baseline model lsbert unihd
empathy critical successful mental health support empathy measurement predominantly occurred synchronous facetoface setting may translate asynchronous textbased context million people use textbased platform mental health support understanding empathy context crucial work present computational approach understanding empathy expressed online mental health platform develop novel unifying theoreticallygrounded framework characterizing communication empathy textbased conversation collect share corpus k post response pair annotated using empathy framework supporting evidence annotation rationale develop multitask robertabased biencoder model identifying empathy conversation extracting rationale underlying prediction experiment demonstrate approach effectively identify empathic conversation apply model analyze k mental health interaction show user selflearn empathy time revealing opportunity empathy training feedback
unsupervised chinese word segmentation ucws made progress incorporating linguistic knowledge pretrained language model using parameterfree probing technique however approach suffer increased training time due need multiple inference using pretrained language model perform word segmentation work introduces novel way enhance ucws performance maintaining training efficiency proposed method integrates segmentation signal unsupervised segmental language model pretrained bert classifier pseudolabeling framework experimental result demonstrate approach achieves stateoftheart performance eight ucws task considerably reducing training time compared previous approach
pretrained multilingual language model lm successfully transformed multilingual sentence encoders s eg labse xmpnet via additional finetuning model distillation parallel data however remains unclear best leverage represent subsentence lexical item ie word phrase crosslingual lexical task work probe s amount crosslingual lexical knowledge stored parameter compare original multilingual lm also devise simple yet efficient method exposing crosslingual lexical knowledge mean additional finetuning inexpensive contrastive learning requires small amount word translation pair using bilingual lexical induction bli crosslingual lexical semantic similarity crosslingual entity linking lexical probing task report substantial gain standard benchmark eg precision point bli result indicate s labse rewired effective crosslingual lexical encoders via contrastive learning procedure possible expose crosslingual lexical knowledge compared using offtheshelf s way also provide effective tool harnessing covert multilingual lexical knowledge hidden multilingual sentence encoders
developed twostage machine translation mt system first stage consists automatically created patternbased machine translation system pbmt second stage consists standard phrasebased statistical machine translation smt system studied japaneseenglish simple sentence task first obtained english sentence japanese sentence using automatically created japaneseenglish patternbased machine translation call english sentence obtained way english second applied standard smt moses result mean translated english sentence english smt also conducted abx test clark compare output standard smt moses proposed system sentence experimental result indicated sentence output proposed system evaluated better output standard smt system whereas sentence output standard smt system thought better output proposed system mean proposed system functioned effectively japaneseenglish simple sentence task
despite success multilingual pretrained language model mplms task dependency parsing dep partofspeech po tagging coverage language still limited language remains unseen adapt mplms including unseen langs existing work considered transliteration vocabulary augmentation meanwhile consideration combining two surprisingly lacking understand identify complementary strength two hurdle realizing based observation propose scriptmix combining two strength overcoming hurdlespecifically scriptmix trained dualscript corpus combine strength b separate module avoid gradient conflict combining module properly also point limitation conventional method adapterfusion propose adapterfusion overcome empirically show scriptmix effective scriptmix improves po accuracy improves dep la score code publicly available
paper present airo learning tool designed use classroom home child risk developing dyslexia tool based clientserver architecture graphical auditive front end providing interaction learner nlprelated component located back end analysing pupil input deciding system response preparing speech synthesis feedback logging pupil performance etc airo software consists independent module easy maintenance eg upgrading didactics preparing airos language paper also report first test vivo november pupil aged subject completed airo session fourweek period subject pre posttested spelling reading experimental group significantly outperformed control group suggesting new itsupported teaching strategy may within reach collection airo resource language material software synthetic voice available open source lrec shall present demo airo learning tool
collecting highquality annotation natural language processing nlp task pose challenge gamified annotation system like gameswithapurpose gwap become popular tool data annotation gwaps effective must userfriendly produce highquality annotation ensure collected data usefulness paper investigates effectiveness gamified approach two specific study existing gwap designed collecting nlp coreference judgment first study involved preliminary usability testing using concurrent thinkaloud method gather openended feedback feedback crucial pinpointing design issue following conducted semistructured interview participant insight collected interview instrumental crafting player persona informed design improvement aimed enhancing user experience outcome research generalized benefit gwap implementation second study evaluated linguistic acceptability reliability data collected gwap finding indicate gwap produced reliable corpus accuracy cohens kappa
computational visual storytelling produce textual description event interpretation depicted sequence image text made possible advance crossdisciplinary approach natural language processing generation computer vision define computational creative visual storytelling one ability alter telling story along three aspect speak different environment produce variation based narrative goal adapt narrative audience aspect creative storytelling effect narrative yet explored visual storytelling paper present pipeline taskmodules object identification singleimage inferencing multiimage narration serve preliminary design building creative visual storyteller piloted design sequence image annotation task present analyze collected corpus describe plan towards automation
learning follow human instruction longpursued goal artificial intelligence task becomes particularly challenging prior knowledge employed language assumed relying handful example learn work past relied handcoded component manually engineered feature provide strong inductive bias make learning situation possible contrast seek establish whether knowledge acquired automatically neural network system two phase training procedure slow offline learning stage network learns general structure task fast online adaptation phase network learns language new given speaker controlled experiment show network exposed familiar instruction containing novel word model adapts efficiently new vocabulary moreover even human speaker whose language usage depart significantly artificial training language network still make use automatically acquired inductive bias learn follow instruction effectively
one key success ebmt removal boundary limiting potential translation memory bring ebmt fruition researcher developer go beyond selfimposed limitation traditional computing term almost old fashioned tm technology experiment shown probability finding exact match phrase level higher probability finding exact match current tm segment level outline implementation linguistically enhanced translation memory system phrasal lexicon implementing phrasal matching system take advantage huge underused resource available existing translation memory develops traditional tm sophisticated examplebased machine translation engine integrated hybrid mt solution yield significant improvement translation quality
recurrent neural network rnns shown capture various aspect syntax raw linguistic input previous experiment however learning happens unrealistic corpus reflect type amount data child would exposed paper remedy state affair training lstm realistically sized subset childdirected input behaviour network analysed time using novel methodology consists quantifying level grammatical abstraction model generated output babbling compared language exposed show lstm indeed abstract new structure learning proceeds
propose method us neural embeddings improve performance given ldastyle topic model method called neural embedding allocation nea deconstructs topic model lda otherwise interpretable vectorspace embeddings word topic document author learning neural embeddings mimic topic model demonstrate nea improves coherence score original topic model smoothing noisy topic number topic large furthermore show neas effectiveness generality deconstructing smoothing lda authortopic model recent mixed membership skipgram topic model achieve better performance embeddings compared several stateoftheart model
increasing number task supported machine learning model without forgetting previously learned task goal lifelong learning system work study mitigate effect catastrophic forgetting problem sequentially train multilingual neural machine translation model using minimal past information first describe catastrophic forgetting phenomenon function number task learned language pair ratio past data used learning new task next explore importance applying oversampling strategy scenario minimal amount past data available finally derive new loss function minimizes forgetting previously learned task actively reweighting past sample penalizing weight deviate much original model work suggests using minimal amount past data simple regularization function significantly mitigate effect catastrophic forgetting phenomenon without increasing computational cost
deep acoustic model represent linguistic information based massive amount data unfortunately regional language dialect resource mostly available however deep acoustic model might learned linguistic information transfer lowresource language study evaluate whether case task distinguishing lowresource dutch regional variety extracting embeddings hidden layer various wavvec model including new model pretrained andor finetuned dutch using dynamic time warping compute pairwise pronunciation difference averaged word individual dialect four regional language cluster resulting difference matrix four group compare gold standard partitioning basis comparing phonetic transcription result show acoustic model outperform traditional transcriptionbased approach without requiring phonetic transcription best performance achieved multilingual xlsr model finetuned dutch basis six second speech resulting clustering closely match gold standard
existing approach recipe generation unable create recipe user culinary preference incomplete knowledge ingredient specific dish propose new task personalized recipe generation help user expanding name incomplete ingredient detail complete naturaltext instruction aligned user historical preference attend technique recipelevel representation user previously consumed recipe fusing useraware representation attention fusion layer control recipe text generation experiment new dataset k recipe k interaction show model ability generate plausible personalized recipe compared nonpersonalized baseline
existing unsupervised document hashing method mostly established generative model due difficulty capturing long dependency structure method rarely model raw document directly instead model feature extracted textiteg bagofwords bog tfidf paper propose learn hash code bert embeddings observing tremendous success downstream task first try modify existing generative hashing model accommodate bert embeddings however little improvement observed code learned old bog tfidf feature attribute reconstruction requirement generative hashing enforce irrelevant information abundant bert embeddings also compressed code remedy issue new unsupervised hashing paradigm proposed based mutual information mi maximization principle specifically method first construct appropriate global local code document seek maximize mutual information experimental result three benchmark datasets demonstrate proposed method able generate hash code outperform existing one learned bog feature substantial margin
largescale pretraining fast becoming norm visionlanguage vl modeling however prevailing vl approach limited requirement labeled data use complex multistep pretraining objective present magma simple method augmenting generative language model additional modality using adapterbased finetuning building frozen train series vl model autoregressively generate text arbitrary combination visual textual input pretraining entirely endtoend using single language modeling objective simplifying optimization compared previous approach importantly language model weight remain unchanged training allowing transfer encyclopedic knowledge incontext learning ability language pretraining magma outperforms frozen openended generative task achieving state art result okvqa benchmark competitive result range popular vl benchmark pretraining number sample used train simvlm
automatic image annotation case deforestation paper aim present state art method used automatic annotation earth observation image deforestation detection interested various challenge field cover present state art method future research considering
performance neural machine translation nmt model relies heavily availability sufficient amount parallel data efficient effective way leveraging vastly available amount monolingual data yet found propose modify decoder neural sequencetosequence model enable multitask learning two strongly related task targetside language modeling translation decoder predicts next target word two channel targetside language model lowest layer attentional recurrent model conditioned source representation architecture allows joint training large amount monolingual moderate amount bilingual data improve nmt performance initial result news domain three language pair show moderate consistent improvement baseline trained bilingual data
huge amount multimedia information available nowadays make manual processing prohibitive requiring tool automatic labelling content paper describes framework assessing music detection tool framework consists database composed several hour radio recording include different type radio programme set evaluation measure evaluating performance music detection tool detail tool automatically detecting music audio stream application music information retrieval task presented well aim tool discard audio excerpt contain music order avoid unnecessary processing tool applies fingerprinting different acoustic feature extracted audio signal order remove perceptual irrelevancy support vector machine trained classifying fingerprint class music nomusic validity tool assessed proposed evaluation framework
research provides comparison linked open data resource dbpedia web corpus data resource google web ngrams google book ngrams noun compound bracketing large corpus statistical analysis often used noun compound bracketing goal introduce linked open data lod resource task show particularity performance task result obtained resource tested individually promising showing potential dbpedia included future hybrid system
emotion essential attribute human being perceiving understanding emotion humanlike manner central part developing emotional intelligence paper describes contribution lingjing team method workshop computational approach subjectivity sentiment social medium analysis wassa shared task emotion classification participant required predict seven emotion empathic response news story caused harm individual group others paper describes continual pretraining method masked language model mlm enhance deberta pretrained language model several training strategy designed improve final downstream performance including data augmentation supervised transfer childtuning training late fusion method extensive experiment emotional classification dataset show proposed method outperforms stateoftheart method demonstrating method effectiveness moreover submission ranked top metric evaluation phase emotion classification task
fact checking model automatic fake news detection based reasoning given claim associated evidence model aim estimate claim veracity based supporting refuting content within evidence model perform well generally assumed due model learned reason evidence regard claim paper investigate assumption reasoning exploring relationship importance claim evidence surprisingly find political fact checking datasets often highest effectiveness obtained utilizing evidence impact including claim either negligible harmful effectiveness highlight important problem constitutes evidence existing approach automatic fake news detection
recognizing textual entailment rte fundamentally important task natural language processing many application recently released stanford natural language inference snli corpus made possible develop evaluate deep neural network method rte task previous neural network based method usually try encode two sentence premise hypothesis send together multilayer perceptron get entailment type use lstmrnn link two sentence together using attention mechanic enhance model ability paper propose use reread mechanic mean read premise reading hypothesis read premise model get better understanding premise also affect understanding hypothesis contrary better understanding hypothesis also affect understanding premise alternative reread process model think better decision entailment type designed new lstm unit called reread lstm rlstm implement thinking process experiment show achieve result better current stateoftheart equivalent
paper describes progress made make mt system usable professional environment many year significant investment decided time ripe metal machine translation system better positioned market place two line action followed introducing system onto pc market using gmst concrete example reusing system component customized solution using aventinus project example multilingual information processing application line action farreaching consequence system development also create new opportunity improve system capability flexibility
work present evaluate usage interactive web interface browsing correcting lecture transcript experiment performed potential user without transcription experience provides u set example correction german lecture data user correction greatly improve comprehensibility transcript yet reduce wer precision user edits relatively low error inflection case compound rarely corrected nevertheless characteristic lecture data error highly specific term typically corrected providing valuable additional information
demonstrate interactive system help operation research practitioner convert mathematical formulation optimization problem tex document format solver modeling language practice manual translation cumbersome timeconsuming moreover requires indepth understanding problem description technical expertise produce modeling code thus proposed system texsolver help partially automate conversion help user build optimization model efficiently paper describe interface component hierarchical parsing system video demo walkthrough available online urlhttpbitlykuomx
present morphosyntacticallyannotated corpus western sierra puebla nahuatl conforms annotation guideline universal dependency project describe source text make corpus annotation process important annotation decision made throughout development corpus first indigenous language mexico added universal dependency project corpus offer good opportunity test clearly define annotation guideline mesoamerican linguistic area spontaneous elicited spoken data codeswitching
paper advocate complementary measure translation performance focus constrastive ability two system system version adequately translate source word motivated three main reason existing automatic metric sometimes show significant difference revealed finegrained focussed human evaluation metric based direct comparison system hypothesis corresponding reference translation thus ignoring input word actually translated metric take input hypothesis several system finegrained contrastive evaluation done indirectly proposal illustrated multisource machine translation scenario multiple translation source text available significant gain bleu point achieved experiment contrastive lexical evaluation shown provide new information help better analyse system performance
disinformation become increasingly relevant recent year political issue object research datasets training machine learning model especially language english sparse creation costly annotated datasets often binary multiclass label provide little information ground system classification propose novel textual dataset gerdisdetect german disinformation provide comprehensive analytical insight finegrained taxonomy guided annotation scheme required goal dataset instead providing direct assessment regarding true false provide wideranging semantic descriptor allow complex interpretation well inferred decisionmaking regarding information trustworthiness potentially critical article allows dataset also used task dataset collected first three month contains multilabel class toplevel category total article general view label offensive language label reporting style label writing style label extremism label baseline pretrained multilingual xlmr model around unlabeled news article finetuned category
eliciting feedback end user nlp model beneficial improving model however present model response user amenable corrected user feedback property user value understand trust response answer question analyzing effect rationale explanation generated qa model support answer specifically consider decomposed qa model first extract intermediate rationale based context question use solely rationale answer question rationale outline approach followed model answer question work considers various format rationale vary according welldefined property interest sample rationale language model using fewshot prompting two datasets perform two user study first present user incorrect answer corresponding rationale various format ask provide natural language feedback revise rationale measure effectiveness feedback patching rationale incontext learning second study evaluates well different rationale format enable user understand trust model answer correct find rationale format significantly affect easy user give feedback rationale model subsequently execute feedback addition format attribution context indepth reasoning significantly enhance userreported understanding trust model output
goal decoda project reduce development cost speech analytics system reducing need manual annotat ion project aim propose robust speech data mining tool framework callcenter monitoring evaluation mean weakl supervised method applicative framework project callcenter ratp paris public transport authority project tackle two important open issue development speech mining method spontaneous speech recorded callcenters robus tness extract relevant information noisy spontaneous speech message weak supervision reduce annotation effort needed train adapt recognition classification model paper describes decoda corpus collected ratp project present different annotation level performed corpus method used obtain well evaluation f quality annotation produced
conduct dependencybased head finalization statistical machine translation smt myanmar burmese although myanmar understudied language linguistically headfinal language similar syntax japanese korean applying efficient technique japanese korean processing myanmar natural idea approach combination two approach first headdriven phrase structure grammar hpsg based head finalization englishtojapanese translation second dependencybased preordering originally designed englishtokorean translation experiment chinese english frenchtomyanmar translation using statistical preordering approach comparison method experimental result show dependencybased head finalization able consistently improve baseline smt system different source language different segmentation scheme myanmar language
despite great importance latin language past relatively resource available today develop modern nlp tool language therefore evalatin shared task lemmatization partofspeech po tagging published lthala workshop work dealt second evalatin task po tagging since available latin word embeddings trained either inaccurate data trained several embeddings better data first step based embeddings trained several stateoftheart tagger used input ensemble classifier called lstmvoter able achieve best result crossgenre crosstime task without using additional annotated data closed modality meantime improved system achieved even better result classical crossgenre crosstime
work demonstrates using objective independence assumption modelling span probability p ae p p ae span starting position ending position ae adverse effect therefore propose multiple approach modelling joint probability p ae directly among propose compound objective composed joint probability still keeping objective independence assumption auxiliary objective find compound objective consistently superior equal assumption exact match additionally identified common error caused assumption independence manually checked counterpart prediction demonstrating impact compound objective real example finding supported via experiment three extractive qa model bidaf bert albert six datasets code individual result manual analysis available online
paper propose boost lowresource crosslingual document retrieval performance deep bilingual querydocument representation match query document source target language four component implemented term interactionbased deep neural network crosslingual word embeddings input including query likelihood score extra feature model effectively learns rerank retrieved document using small number relevance label lowresource language pair due shared crosslingual word embedding space model also directly applied another language pair without training label experimental result material dataset show model outperforms competitive translationbased baseline englishswahili englishtagalog englishsomali crosslingual information retrieval task
recent year focus ecommerce research better understanding relationship internet marketplace customer good service done examining information gleaned consumer information recommender system click rate way purchaser go making buying decision example paper take different approach examines company past ten year ecommerce giant amazon skymall wayfair groupon embroiled class action security lawsuit promulgated rule b short one security exchange commission main rule surrounding fraud lawsuit extremely expensive company damage company brand extensively shareholder left suffer consequence examined management discussion analysis market risk company using sentiment analysis selected financial measure found able predict outcome lawsuit dataset using sentiment tone alone recall using random forest classifier believe important contribution crossdomain implication potential open new area research ecommerce finance law settlement class action lawsuit dataset alone excess billion dollar aggregate
paper describes participation ustbprir team bioasq b question answering including document retrieval snippet retrieval concept retrieval task introduce different multimodal query processing strategy enrich query term assign different weight specifically sequential dependence model sdm pseudorelevance feedback prf fielded sequential dependence model fsdm divergence randomness model dfrm respectively performed different field pubmed article sentence extracted relevant article five terminology ontology mesh go jochem uniprot achieve better search performance preliminary result show system outperform others document snippet retrieval task first two batch
present approach generating natural language justification decision derived normbased reasoning assuming agent maximally satisfies set rule specified objectoriented temporal logic user ask factual question agent rule action extent agent violated rule well question require agent comparing actual behavior counterfactual trajectory respect rule produce naturalsounding explanation focus subproblem producing natural language clause statement fragment temporal logic describe embed clause explanatory sentence use human judgment evaluation testbed task compare approach variant term intelligibility mental model perceived trust
automated extraction ontological knowledge text corpus relevant task natural language processing paper focus problem finding hypernym relevant concept specific domain eg optical recording context concrete challenging application scenario patent processing end information available web exploited extraction method includes four main step firstly google search engine exploited retrieve possible instance isapatterns reported literature returned snippet filtered basis lexicosyntactic criterion eg candidate hypernym must expressed noun phrase without complex modifier filtering step candidate hypernym compatible target domain kept finally candidate ranking mechanism applied select one hypernym output algorithm extraction method evaluated concept optical recording domain moreover reliability isapatterns reported literature predictor isarelations assessed manually evaluating template instance remaining lexicosyntactic filtering concept domain extensive testing needed method appears promising especially portability across different domain
paper present submission huawei translation service center hwtsc wmt wordlevel autocompletion task propose endtoend autoregressive model bicontext based transformer solve current task model us mixture subword character encoding unit realize joint encoding human input context target side decoded sequence ensures full utilization information us one model solve four type data structure task training try using machine translation model pretrained model finetune task also add bertstyle mlm data finetuning stage improve model performance participate zhrightarrowen enrightarrowde derightarrowen direction win first place three track particularly outperform second place term accuracy zhrightarrowen enrightarrowde track result buttressed human evaluation well demonstrating effectiveness model
scholarly argumentation mining sam recently gained attention due potential help scholar rapid growth published scientific literature comprises two subtasks argumentative discourse unit recognition adur argumentative relation extraction challenging since require eg integration domain knowledge detection implicit statement disambiguation argument structure previous work focused dataset construction baseline method specific document section abstract result fulltext scholarly argumentation mining seen little progress work introduce sequential pipeline model combining adur fulltext sam provide first analysis performance pretrained language model plms subtasks establish new sota adur sciarg corpus outperforming previous best reported result large margin f also present first result thus full pipeline benchmark dataset detailed error analysis reveals noncontiguous adus well interpretation discourse connector pose major challenge data annotation need consistent
learner systematically prepare reading book interested paper explore computational linguistic method distributional semantics morphological clustering exercise generation combined graphbased learner model answer question conceptually practice based highly structured learner model concept network analysis learner guided efficiently explore targeted lexical space practice using multigap learning activity generated book sum approach combine computational linguistic method concept network analysis tutoring system support learner pursuing individual reading task goal
ca globalization team long term goal reaching fully loaded cost cent per word fully loaded cost include cost incurred translation localization qa engineering project management overall management translation budget gradually decreasing volume increasing machine translation becomes alternative source produce less paper describes ca technology try accomplish long term goal deployment mt system increase productivity less cost relatively short time
although pretrained named entity recognition ner model highly accurate modern corpus underperform historical text due difference language ocr error work develop new ner corpus sentence late medieval charter written mainly czech latin germanwe show start list known historical figure location unannotated corpus historical text use information retrieval technique automatically bootstrap nerannotated corpus using corpus train ner model achieves entitylevel precision recall manuallyannotated test dataset furthermore show using weighted loss function help combat class imbalance token classification task make easy others reproduce build upon work publicly release corpus model experimental code
although pretrained language model plms shown impressive performance textonly selfsupervised training found lack visual semantics commonsense existing solution often rely explicit image visual knowledge augmentation requiring timeconsuming retrieval generation also conduct augmentation whole input text without considering whether actually needed specific input task address issue propose novel visuallyaugmented finetuning approach generally applied various plms nlp task without using retrieved generated image namely vawi experimental result show approach consistently improve performance bert roberta bart different scale outperform several competitive baseline ten task code data publicly available urlhttpsgithubcomrucaiboxvawi
paper describes process data processing training automatic speech recognition asr system cook island maori cim indigenous language spoken approximately people south pacific transcribed four hour speech adult elderly speaker language prepared two experiment first trained three asr system one statistical kaldi two based deep learning deepspeech xlsrwavvec wavvec tied kaldi lowest character error rate cermboxpm slightly behind word error rate wermboxpm versus wermboxpm kaldi provides evidence deep learning asr system reaching performance statistical method small datasets work effectively extremely lowresource indigenous language like cim second experiment used wavvec train model heldout speaker performance decreased cermboxpm wermboxpm system still showed considerable learning intend use asr accelerate documentation cim using newly transcribed text improve asr also generate teaching language revitalization material trained model available license based kaitiakitanga license provides noncommercial use retaining control model indigenous community
present new formalism probabilistic feature grammar pfg pfgs combine best property several formalism including collins magerman charniak experiment comparable better performance pfgs generate feature one time probabilistically conditioning probability feature feature local context conditioning local efficient polynomial time parsing algorithm exist computing inside outside viterbi parses pfgs produce probability string making potentially useful language modeling precision recall result comparable state art word best reported without word
data scarcity longstanding crucial challenge hinders quick development taskoriented dialogue system across multiple domain taskoriented dialogue model expected learn grammar syntax dialogue reasoning decision making language generation absurdly small amount taskspecific data paper demonstrate recent progress language modeling pretraining transfer learning show promise overcome problem propose taskoriented dialogue model operates solely text input effectively bypass explicit policy language generation module building top transfertransfo framework wolf et al generative model pretraining radford et al validate approach complex multidomain taskoriented dialogue multiwoz dataset automatic human evaluation show proposed model par strong taskspecific neural baseline long run approach hold promise mitigate data scarcity problem support construction engaging eloquent taskoriented conversational agent
zeroshot paraphrase generation drawn much attention largescale highquality paraphrase corpus limited backtranslation also known pivotbased method typical end several work leverage different information pivot language semantic representation paper explore using visual information image pivot backtranslation different pipeline backtranslation method propose visual information guided zeroshot paraphrase generation vipg based paired imagecaption data jointly train image captioning model paraphrasing model leverage image captioning model guide training paraphrasing model automatic evaluation human evaluation show model generate paraphrase good relevancy fluency diversity image promising kind pivot zeroshot paraphrase generation
growing body research demonstrated inability nlp model generalize compositionally tried alleviate specialized architecture training scheme data augmentation among approach work study different approach training instance diverse structure propose modelagnostic algorithm subsampling set instance labeled instance pool structured output evaluating compositional template split traditional iid split semantic parsing datasets varying complexity show structurally diverse training using algorithm lead comparable better generalization prior algorithm datasetsplit type pair general find structural diversity consistently improve sample efficiency compared random train set moreover show structurally diverse sampling yield comprehensive test set lot challenging iid test set finally provide two explanation improved generalization diverse train set improved coverage output substructure reduction spurious correlation substructure
knowledge probing assesses degree language model lm successfully learned relational knowledge pretraining probing inexpensive way compare lm different size training configuration however previous approach rely objective function used pretraining lm thus applicable masked causal lm result comparing different type lm becomes impossible address propose approach us lm inherent ability estimate loglikelihood given textual statement carefully design evaluation dataset instance larger variant produce alternative statement relational fact one correct evaluate whether lm correctly assigns highest loglikelihood correct statement experimental evaluation common lm show proposed framework bear effectively probe knowledge across different lm type release bear datasets opensource framework implement probing approach research community facilitate evaluation development lm
joint entity relation extraction aim extract relation triplet plain text directly prior work leverage sequencetosequence seqseq model triplet sequence generation however seqseq enforces unnecessary order unordered triplet involves large decoding length associated error accumulation method introduce exposure bias may cause model overfit frequent label combination thus limiting generalization ability propose novel sequencetounorderedmultitree sequmtree model minimize effect exposure bias limiting decoding length three within triplet removing order among triplet evaluate model two datasets duie nyt systematically study exposure bias alters performance seqseq model experiment show stateoftheart seqseq model overfits datasets sequmtree show significantly better generalization code available urlhttpsgithubcomwindchimeranopenjere
lump team participation semeval task semantic textual similarity supervised model relies feature multilingual interlingual nature include lexical similarity crosslanguage explicit semantic analysis internal representation multilingual neural network interlingual word embeddings representation allow use large datasets language pair many instance better classify instance smaller language pair avoiding necessity translating single language hence deal language task arabic english spanish turkish
grammatical error correction gec aim correct error given sentence significant many downstream natural language understanding task recent work introduces idea grammatical error detection ged improve gec task performance contrast explicit multistage work propagate amplify problem misclassification ged module introduce convincing error type information propose endtoend framework paper leverage error type let information generation process first input text fed classification module obtain error type corresponding token introduce category information decoder input crossattention module two way respectively experiment various datasets show proposed method outperforms existing method clear margin
paper explore simple nonneural approach mapping orthography phonetic transcription lowresource context transfer data related language start baseline system focus effort data augmentation make three principal move first start hmmbased system novak et al second augment basic system recombining legal substring restricted fashion ryan hulden finally limit transfer data using training pair phonetic form share bigram target language
pragmatic nonliteral language understanding essential human communication present longstanding challenge artificial language model perform finegrained comparison language model human seven pragmatic phenomenon using zeroshot prompting expertcurated set english material ask whether model select pragmatic interpretation speaker utterance make similar error pattern human use similar linguistic cue human solve task find largest model achieve high accuracy match human error pattern within incorrect response model favor literal interpretation heuristicbased distractors also find preliminary evidence model human sensitive similar linguistic cue result suggest pragmatic behavior emerge model without explicitly constructed representation mental state however model tend struggle phenomenon relying social expectation violation
despite subjective nature semantic textual similarity sts pervasive disagreement sts annotation existing benchmark used averaged human rating gold standard averaging mask true distribution human opinion example low agreement prevents model capturing semantic vagueness individual rating represent work introduce usts first uncertaintyaware sts dataset chinese sentence pair label study collective human opinion sts analysis reveals neither scalar single gaussian fit set observed judgment adequately show current sts model capture variance caused human disagreement individual instance rather reflect predictive confidence aggregate dataset
lexical simplification l system substitute difficult word text simpler one make easier user understand typical l pipeline substitution ranking step determines best substitution set candidate current system consider user vocabulary proficiency always aim simplest candidate approach may overlook lesssimple candidate user understand semantically closer original word propose personalized approach substitution ranking identify candidate closest synonym noncomplex user experiment learner english different proficiency level show approach enhances semantic faithfulness output cost relatively small increase number complex word
paper describes participation research laboratory mind university milanobicocca semeval task related learning disagreement lewidi main goal identify level agreementdisagreement collection textual datasets different characteristic term style language task proposed approach grounded hypothesis disagreement annotator could grasped uncertainty model based several linguistic characteristic could prediction given gold label
paper describes model submitted nlpbfcai team kanglish shared task held icon proposed model used simple approach based word representation simple machine learning classification algorithm random forest support vector machine stochastic gradient descent multilayer perceptron imple mented submission rf securely ranked fifth among submission
reduce model size pretrained word embeddings factor preserving quality previous study direction created smaller word embedding model reconstructing pretrained word representation subwords allows store smaller number subword embeddings memory however previous study train reconstruction model using target word reduce model size extremely preserving quality inspired observation word similar meaning similar embeddings reconstruction training learns global relationship among word employed various model word embedding reconstruction experimental result word similarity benchmark show proposed method improves performance subwordbased reconstruction model
large language model llm demonstrated powerful capability natural language processing yet vast number parameter pose challenge deployment inference efficiency structured model pruning emerges viable approach reduce model size accelerate inference without requiring specialized operator library deployment however structured pruning often severely weakens model capabilitydespite repetitive finetuning restore capability certain extent impairs llm utility versatile problem solversto address issue propose novel structured pruning algorithm tailored llm derives importance different component namely row column parameter matrix based intermediate data dependency remove coupled component across different layer simultaneously preserve dependency relationship within remaining parameter avoiding significant performance degradation pruned model requires epoch finetuning restore performance ensuring model ability generalizeempirical evaluation llama vicuna chatglm demonstrate algorithm efficacy yielding parameter reduction retaining least original performance metric
reinforcement learning method dialog policy learning train centralized agent selects predefined joint action concatenating domain name intent type slot name centralized dialog agent suffers great many useragent interaction requirement due large action space besides designing concatenated action laborious engineer maybe struggled edge case solve problem model dialog policy learning problem novel multiagent framework part action led different agent framework reduces labor cost action template decrease size action space agent furthermore relieve nonstationary problem caused changing dynamic environment evolving agent policy introducing joint optimization process make agent exchange policy information concurrently independent experience replay buffer mechanism integrated reduce dependence gradient sample improve training efficiency effectiveness proposed framework demonstrated multidomain environment user simulator evaluation human evaluation
seek create agent act communicate agent pursuit goal towards end extend light urbanek et al largescale crowdsourced fantasy textgamewith dataset quest contain natural language motivation paired ingame goal human demonstration completing quest might require dialogue action introduce reinforcement learning system incorporates largescale language modelingbased commonsense reasoningbased pretraining imbue agent relevant prior leverage factorized action space action command dialogue balancing two conduct zeroshot evaluation using heldout human expert demonstration showing agent able act consistently talk naturally respect motivation
describe effort automated extraction sociopolitical event news scope workshop shared task organized language resource evaluation conference lrec believe event extraction study computational linguistics social political science support order enable large scale sociopolitical event information collection across source country language event consists regular research paper shared task event sentence coreference identification esci track submission reviewed five member program committee workshop attracted research paper related evaluation machine learning methodology language resource material conflict forecasting shared task participation report scope sociopolitical event information collection shown u volume variety data source event information collection approach related sociopolitical event need fill gap automated text processing technique requirement social political science
neural natural language generation nlg understanding nlu model costly require massive amount annotated data competitive recent data programming framework address bottleneck allowing human supervision provided set labeling function construct generative model synthesize weak label scale however labeling function difficult build scratch nlgnlu model often require complex rule set specified end propose novel data programming framework jointly construct labeled data language generation understanding task allowing annotator modify automaticallyinferred alignment rule set sequence label text instead writing rule scratch mitigate effect poor quality label propose duallyregularized denoising mechanism optimizing nlu nlg model two benchmark show framework generate highquality data come within bleu slot f humanlabeled data k instance labeled data sample outperforming benchmark annotation framework semisupervised approach
software production sign language much less common spoken language software usually relies humanoid avatar produce sign inevitably necessitates use animation one barrier use popular animation tool complexity steep learning curve hard master inexperienced user present pelgp authoring system feature avatar sign portuguese sign language animator designed specifically craft sign language animation using key frame method meant easy use learn user without animation skill conducted preliminary evaluation animator animated seven portuguese sign language sentence asked four sign language user evaluate quality evaluation revealed system spite simplicity indeed capable producing comprehensible message
compositional generalization fundamental trait human allowing u effortlessly combine known phrase form novel sentence recent work claimed standard seqtoseq model severely lack ability compositionally generalize paper focus oneshot primitive generalization introduced popular scan benchmark demonstrate modifying training distribution simple intuitive way enables standard seqtoseq model achieve nearperfect generalization performance thereby showing compositional generalization ability previously underestimated perform detailed empirical analysis phenomenon result indicate generalization performance model highly sensitive characteristic training data carefully considered designing benchmark future
work propose use linguistic annotation basis discourseaware semantic selfattention encoder employ reading comprehension narrative text extract relation discourse unit event argument well coreferring mention using available annotation tool empirical evaluation show investigated structure improve overall performance rougel especially intrasentential crosssentential discourse relation sentenceinternal semantic role relation longdistance coreference relation show dedicating selfattention head intrasentential relation relation connecting neighboring sentence beneficial finding answer question longer context finding encourage use discoursesemantic annotation enhance generalization capacity selfattention model reading comprehension
language model become increasingly integrated digital life personalized text generation ptg emerged pivotal component wide range application however bias inherent user written text often used ptg model training inadvertently associate different level linguistic quality user protected attribute model inherit bias perpetuate inequality generating text wrt user protected attribute leading unfair treatment serving user work investigate fairness ptg context personalized explanation generation recommendation first discus bias generated explanation fairness implication promote fairness introduce general framework achieve measurespecific counterfactual fairness explanation generation extensive experiment human evaluation demonstrate effectiveness method
despite recent advance abstractive summarization system still difficult determine whether generated summary factual consistent source text end latest approach train factual consistency classifier factually consistent inconsistent summary luckily former readily available reference summary existing summarization datasets however generating latter remains challenge need factually inconsistent yet closely relevant source text effective paper propose generate factually inconsistent summary using source text reference summary key information masked experiment seven benchmark datasets demonstrate factual consistency classifier trained summary generated using method generally outperform existing model show competitive correlation human judgment also analyze characteristic summary generated using method release pretrained model code urlhttpsgithubcomhwanheeleemfma
subwords become standard unit text nlp enabling efficient openvocabulary model algorithm like bytepair encoding bpe subword segmentation viewed preprocessing step applied corpus training lead suboptimal segmentation lowresource language complex morphology propose subword segmental language model sslm learns segment word trained autoregressive language modelling unifying subword segmentation language modelling model learns subwords optimise lm performance train model nguni language south africa lowresource agglutinative language subword information critical lm sslm outperforms existing approach bpebased model average across language furthermore outperforms standard subword segmenters unsupervised morphological segmentation also train model wordlevel sequence model resulting unsupervised morphological segmenter outperforms existing method large margin language result show learning subword segmentation effective alternative existing subword segmenters enabling model discover morphemelike subwords improve lm capability
although much effort recently devoted training highquality sentence embeddings still poor understanding capturing downstream task often based sentence classification commonly used evaluate quality sentence representation complexity task make however difficult infer kind information present representation introduce probing task designed capture simple linguistic feature sentence use study embeddings generated three different encoders trained eight distinct way uncovering intriguing property encoders training method
paraphrasing exists different granularity level lexical level phrasal level sentential level paper present decomposable neural paraphrase generator dnpg transformerbased model learn generate paraphrase sentence different level granularity disentangled way specifically model composed multiple encoders decoder different structure corresponds specific granularity empirical study show decomposition mechanism dnpg make paraphrase generation interpretable controllable based dnpg develop unsupervised domain adaptation method paraphrase generation experimental result show proposed model achieves competitive indomain performance compared stateoftheart neural model significantly better performance adapting new domain
paper evaluates hypothesis pictorial representation used effectively convey simple sentence across language barrier comparative evaluation show considerable amount understanding achieved using visual description information evaluation figure within comparable range obtained linguistic representation produced automatic machine translation system
study primarily aimed find machine learning classification algorithm could accurately classify l thesis statement writing performance high low using syntactic complexity index secondarily study aimed reveal syntactic complexity index classification algorithm gained largest amount information interacted l thesis statement writing performance data set study consisted highperforming lowperforming thesis statement written undergraduate learner english foreign language context experiment revealed locally weighted learning algorithm could classify l thesis statement writing performance accuracy baseline balancing data set via synthetic minority oversampling produced accuracy percentage stochastic gradient descent algorithm resulting slight increase kappa statistic imbalanced balanced data set seen number coordinate phrase coordinate phrase per tunit coordinate phrase per clause verb phrase per tunit variable classification algorithm gained largest amount information mannwhitney u test showed highperforming thesis statement larger amount coordinate phrase higher ratio coordinate phrase per tunit coordinate phrase per clause verb phrase per tunit ratio seen lower highperforming thesis statement lowperforming counterpart
existing dialog state tracking dst model trained dialog data random order neglecting rich structural information dataset paper propose use curriculum learning cl better leverage curriculum structure schema structure taskoriented dialog specifically propose modelagnostic framework called schemaaware curriculum learning dialog state tracking saclog consists preview module pretrains dst model schema information curriculum module optimizes model cl review module augments mispredicted data reinforce cl training show proposed approach improves dst performance transformerbased rnnbased dst model trippy trade achieves new stateoftheart result woz multiwoz
lexica distinguishing morphologically related form lexeme crucial many language technology yet building expensive propose frugal paradigm completion approach predicts related form morphological paradigm manually provided form possible induces typological information training us determine best source test time evaluate languageagnostic approach diverse language compared popular alternative approach reduces manual labor robust typological variation
paper present first attempt building multilingual neural machine translation framework unified approach information shared among language helpful translation individual language pair able employ attentionbased neural machine translation manytomany multilingual translation task approach require special treatment network architecture allows u learn minimal number free parameter standard way training approach shown effectiveness underresourced translation scenario considerable improvement bleu point addition point novel way make use monolingual data neural machine translation using approach bleuscore gain iwslt englishgerman translation task
noisy nonstandard input text cause disastrous mistranslation modern machine translation mt system growing research interest creating noiserobust mt system however yet publicly available parallel corpus naturally occurring noisy input translation thus previous work resorted evaluating synthetically created datasets paper propose benchmark dataset machine translation noisy text mtnt consisting noisy comment reddit urlwwwredditcom professionally sourced translation commissioned translation english comment french japanese well french japanese comment english order kk sentence per language pair qualitatively quantitatively examine type noise included dataset demonstrate existing mt model fail badly number noiserelated phenomenon even performing adaptation small training set indomain data indicates dataset provide attractive testbed method tailored handling noisy text mt
paper proposes adversarial training method multitask multilingual joint modeling needed utterance intent classification joint modeling common knowledge efficiently utilized among multiple task multiple language achieved introducing languagespecific network shared among different task taskspecific network shared among different language however shared network often specialized majority task language performance degradation must expected minor data set order improve invariance shared network proposed method introduces languagespecific task adversarial network taskspecific language adversarial network leveraged purging task language dependency shared network effectiveness adversarial training proposal demonstrated using japanese english data set three different utterance intent classification task
dialogue state tracking dialogue history crucial material utilization varies different model however matter dialogue history used existing model us consistent dialogue history entire state tracking process regardless slot updated apparently requires different dialogue history update different slot different turn therefore using consistent dialogue content may lead insufficient redundant information different slot affect overall performance address problem devise dicosdst dynamically select relevant dialogue content corresponding slot state updating specifically first retrieves turnlevel utterance dialogue history evaluates relevance slot combination three perspective explicit connection slot name relevance current turn dialogue implicit mention oriented reasoning perspective combined yield decision selected dialogue content fed state generator explicitly minimizes distracting information passed downstream state prediction experimental result show approach achieves new stateoftheart performance multiwoz multiwoz achieves superior performance multiple mainstream benchmark datasets including simm simr dstc
study problem generating interconnected question questionanswering style conversation compared previous work generate question based single sentence paragraph setting different two major aspect question highly conversational almost half refer back conversation history using coreference coherent conversation question smooth transition turn propose endtoend neural model coreference alignment conversation flow modeling coreference alignment modeling explicitly aligns coreferent mention conversation history corresponding pronominal reference generated question make generated question interconnected conversation history conversation flow modeling build coherent conversation starting questioning first sentence text passage smoothly shifting focus later part extensive experiment show system outperforms several baseline generate highly conversational question code implementation released urlhttpsgithubcomevangaoconversaionalqg
highlight simple failure mode stateoftheart machine reading system context align commonly shared belief example machine reading system fail answer textitwhat elizabeth want correctly context kingdom cough drop cried queen elizabeth biased cooccurrence statistic training data pretrained language model system predict textitmy kingdom rather textita cough drop argue bias analogous human belief bias present carefully designed challenge dataset english machine reading called autolocke quantify effect evaluation machine reading system autolocke show pervasiveness belief bias machine reading
large language model llm become increasingly accessible online thus easily used generate synthetic data technology rising capability llm application span across many domain increasing use automating task crucial understand fairness notion harboured model work aim explore consistency behaviour gpt gpt shortterm longterm scenario lens fairness additionally search optimal prompt template design equalized opportunity investigated study shortterm scenario german credit dataset intervention key feature recorded increase loan rejection rate gpt gpt longterm scenario ml fairness gym adding extra information environment prompt shown improvement prompt minimal information term final credit distribution however adding extra feature prompt increased profit rate compared baseline maximumreward classifier compromising grouplevel recall rate
pretrained language model plms attracted enormous attention past year unparalleled performance meanwhile soaring cost train plms well amazing generalizability jointly contributed fewshot finetuning prompting popular training paradigm natural language processing nlp model nevertheless existing study shown nlp model backdoored model behavior manipulated trigger token presentedin paper propose promptfix novel backdoor mitigation strategy nlp model via adversarial prompttuning fewshot settingsunlike existing nlp backdoor removal method rely accurate trigger inversion subsequent model finetuning promptfix keep model parameter intact utilizes two extra set soft token approximate trigger counteract respectively use soft token adversarial optimization eliminates need enumerate possible backdoor configuration enables adaptive balance trigger finding preservation performanceexperiments various backdoor attack validate effectiveness proposed method performance domain shift present show promptfixs applicability model pretrained unknown data source common case prompt tuning scenario
present cognitive computational model pronoun resolution reproduces human interpretation preference subject assignment strategy parallel function strategy model relies probabilistic pronoun resolution system trained corpus data factor influencing pronoun resolution represented feature weighted relative importance importance model give preference line psycholinguistic study demonstrate cognitive plausibility model running experimental item simulating antecedent choice reading time human participant model used new mean study pronoun resolution capture interaction preference
knowledge graph kg become increasingly important endow modern recommender system ability generate traceable reasoning path explain recommendation process however prior research rarely considers faithfulness derived explanation justify decisionmaking process best knowledge first work model evaluates faithfully explainable recommendation framework kg reasoning specifically propose neural logic reasoning explainable recommendation loger drawing interpretable logical rule guide pathreasoning process explanation generation experiment three largescale datasets ecommerce domain demonstrating effectiveness method delivering highquality recommendation well ascertaining faithfulness derived explanation
factual knowledge acquired pretraining stored parameter language model lm useful downstream task eg question answering textual inference however fact incorrectly induced become obsolete time present knowledgeeditor method used edit knowledge thus fix bug unexpected prediction without need expensive retraining finetuning besides computationally efficient knowledgeeditordoes require modification lm pretraining eg use metalearning approach train hypernetwork constrained optimization modify fact without affecting rest knowledge trained hypernetwork used predict weight update test time show knowledgeeditors efficacy two popular architecture knowledgeintensive task bert model finetuned factchecking ii sequencetosequence bart model question answering method changing prediction specific wording query tends result consistent change prediction also paraphrase show encouraged exploiting eg automaticallygenerated paraphrase training interestingly hypernetwork regarded probe revealing component need changed manipulate factual knowledge analysis show update tend concentrated small subset component source code available urlhttpsgithubcomnicoladecaoknowledgeeditor
domain adaptation important technology handle domain dependence problem sentiment analysis field existing method usually rely sentiment classifier trained source domain however performance may heavily decline distribution sentiment feature source target domain significant difference paper propose active sentiment domain adaptation approach handle problem instead source domain sentiment classifier approach adapts generalpurpose sentiment lexicon target domain help small number labeled sample selected annotated active learning mode well domainspecific sentiment similarity among word mined unlabeled sample target domain unified model proposed fuse different type sentiment information train sentiment classifier target domain extensive experiment benchmark datasets show approach train accurate sentiment classifier less labeled sample
computer vision cv natural language processing nlp recommender system recsys three prominent ai application traditionally developed independently resulting disparate modeling engineering methodology impeded ability field directly benefit others advancement recent development foundation model large language model emerged potential generalpurpose interface unifying different modality problem formulation light propose development multimodal foundation model mfm considering visual textual personalization modality p recommendation paradigm thus named vip visual p unify various modality recommendation task enable processing multiple modality shared architecture improved recommendation achieve introduce multimodal personalized prompt accommodate multiple modality shared format additionally propose parameterefficient training method foundation model involves freezing p backbone finetuning lightweight adapter resulting improved recommendation performance increased efficiency term training time memory usage code data vip available httpsgithubcomjeykigungvip
rising popularity llm public sphere become attractive tool one research without rely search engine specialized knowledge scientific field using llm source factual information lead one fall prey misinformation hallucination dreamed model paper examine gpt llm simulating large number potential research query evaluate many generated reference factually correct well existent
nlp application learner often rely annotated learner corpus thereby important annotation meaningful task consistent reliable present new longitudinal l learner corpus german handwritten text collected grade transcribed annotated target hypothesis strictly corrects orthographic error thereby tailored research tool development orthographic issue primary school corpus transcription target hypothesis evaluated conducted detailed interannotator agreement study task although achieved high agreement discussion case disagreement show even detailed guideline annotator differ different reason also considered working transcription target hypothesis corpus especially explicit guideline construction known
dependency parsing important fundamental natural language processing task analyzes syntactic structure input sentence illustrating syntactic relation word improve dependency parsing leveraging existing dependency parser extra data eg semisupervised learning demonstrated effective even though final parser trained inaccurate massive data paper propose frustratingly easy approach improve graphbased dependency parsing structureaware encoder pretrained autoparsed data predicting word dependency finetuned gold dependency tree differs usual pretraining process aim predict context word along dependency path experimental result analysis demonstrate effectiveness robustness approach benefit data even noise processed different parser approach outperforms strong baseline different setting different dependency standard model architecture used pretraining finetuning importantly analysis find k autoparsed sentence required obtain improvement pretraining vanilla bertlarge based parser without requiring extra parameter
paper proposes novel method inject custom terminology neural machine translation run time previous work mainly proposed modification decoding algorithm order constrain output include runtimeprovided target term effective constrained decoding method add however significant computational overhead inference step show paper brittle tested realistic condition paper approach problem training neural mt system learn use custom terminology provided input comparative experiment show method effective stateoftheart implementation constrained decoding also fast constraintfree decoding
current endtoend semantic role labeling mostly accomplished via graphbased neural model however firstorder model decision detecting predicateargument pair made isolation local feature paper present highorder refining mechanism perform interaction predicateargument pair based baseline graph model highorder refining module learns higherorder feature candidate pair via attention calculation later used update original token representation several iteration refinement underlying token representation enriched globally interacted feature highorder model achieves stateoftheart result chinese srl data including conll universal proposition bank meanwhile relieving longrange dependency issue
publicly available general purpose sentiment lexicon high resource language exist low resource language make difficult directly perform sentiment analysis task language objective work create general purpose sentiment lexicon igbo language determine sentiment document written igbo language without translate english language material used automatically translated lius lexicon manual addition igbo native word result work general purpose lexicon igbosentilex performance tested bbc igbo news channel returned average polarity agreement general purpose sentiment lexicon
paper present hallucination recognition model new experiment evaluation harmonee team winning submission semeval task shared task hallucination related observable overgeneration mistake shrooms two subtasks task challenged participant design system detect hallucination large language model llm output team harmonee proposes two architecture finetuning offtheshelf transformerbased model prompt tuning largescale large language model llm one submission finetuning approach outperformed submission modelaware subtask one submission prompttuning approach thbest submission leaderboard modelagnostic subtask system also include preprocessing systemspecific tuning postprocessing evaluation
recent application natural language processing technique suicidal ideation detection risk assessment frame detection assessment task text classification problem recent advance developed many model especially deep learning model boost predictive performancethough performance term aggregated evaluation score improving position paper urge better intention understanding required reliable suicidal risk assessment computational method paper reflects state natural language processing applied suicideassociated text classification task differentiates suicidal risk assessment intention understanding point potential limitation sentiment feature pretrained language model suicidal intention understandingbesides urge necessity sequential intention understanding risk assessment discusses critical issue evaluation uncertainty study lack benchmark
method presented incremental retraining smt system local phrase table created incrementally updated file translated postedited shown translation data within file higher value domainspecific data two technical domain withinfile data increase bleu score several full point furthermore strong recency effect documented nearby data within file greater value distant data also shown value translation data strongly correlated metric defined new occurrence ngrams finally argued incremental retraining prototype could serve basis practical system could interactively updated real time postediting setting based result interactive system potential dramatically improve translation quality
practical dialogue system user may input outofdomain ood query generalized intent discovery gid task aim discover ood intent ood query extend indomain ind classifier however gid considers one stage ood learning need utilize data previous stage joint training limit wide application reality paper introduce new task continual generalized intent discovery cgid aim continuously automatically discover ood intent dynamic ood data stream incrementally add classifier almost previous data thus moving towards dynamic intent recognition open world next propose method called prototypeguided learning replay distillation plrd cgid bootstrap new intent discovery class prototype balance new old intent data replay feature distillation finally conduct detailed experiment analysis verify effectiveness plrd understand key challenge cgid future research
present bidirectional longshort term memory network identifying offensive language twitter system developed context semeval task comprises three different subtasks namely offensive language detection b categorization offensive language c offensive language target identification used pretrained word embeddings tweet data including information emojis hashtags approach achieves good performance three subtasks
paper describes partial reproduction work titled generating fact checking explanation atanasova et al part reprohum element within repronlp shared task aimed reproducing finding nlp research related human evaluation task investigates whether nlp research becoming less reproducible time following instruction task organizer original author gathered relative ranking three factchecking explanation including gold standard output two model input based criterion coverage reproduction reanalysis original study raw result support initial finding showing similar pattern original work reproduction though observed slight variation original result finding align main conclusion drawn original author regarding effectiveness proposed model
paper present extension mategnome annotation scheme anaphora poesio account abstract anaphora danish italian abstract anaphora meant pronoun whose linguistic antecedent verbal phrase clause discourse segment extended scheme call dad annotation scheme allows annotate information abstract anaphora important investigate use see ia webber gundel et al navarretta navarretta influence automatic treatment intercoder agreement score obtained applying dad annotation scheme text dialogue two language given show information proposed scheme recognised reliable way
recently study neural dependency parser shown advantage traditional one wide variety language however graphbased neural dependency parsing system either count longterm memory attention mechanism implicitly capture highorder feature give global exhaustive inference algorithm order harness feature rich history parsing decision former might miss important feature specific headword prediction without help explicit structural information latter may suffer error propagation false early structural constraint used create feature making future prediction explore feasibility explicitly taking highorder feature account remaining main advantage global inference learning graphbased parsing proposed parser first form initial parse tree headmodifier prediction based firstorder factorization highorder feature grandparent sibling uncle defined initial tree used refine parse tree iterative fashion experimental result showed model called indp archived competitive performance existing benchmark parser english chinese datasets
work investigates neural machine translation nmt system translating english user review croatian serbian two similar morphologically complex language two type review used testing system imdb movie review amazon product review two type training data explored large outofdomain bilingual parallel corpus well small synthetic indomain parallel corpus obtained machine translation monolingual english amazon review target language automatic score human evaluation show using synthetic indomain corpus together selected subset outofdomain data best option separated result imdb amazon review indicate mt system perform differently different review type user review generally considered homogeneous genre nevertheless detailed research larger amount different review covering different domainstopics needed fully understand difference
well known rerankers built pretrained transformer model bert dramatically improved retrieval effectiveness many task however gain come substantial cost term efficiency noted many researcher work show possible retain benefit transformerbased rerankers multistage reranking pipeline first using featurebased learningtorank technique reduce number candidate document consideration without adversely affecting quality term recall applied m marco passage document ranking task able achieve level effectiveness mboxtimes increase efficiency furthermore technique orthogonal method focused accelerating transformer inference thus combined even greater efficiency gain higherlevel message work even though pretrained transformer dominate modern ir landscape still important role traditional ltr technique forget history
online platform become central democracy problem toxic content threatens free flow information enjoyment fundamental right effective policy response toxic content must grasp idiosyncrasy interconnectedness content moderation across fragmented online landscape report urge regulator legislator consider range platform moderation approach regulation particular call holistic processoriented regulatory approach account actor beyond handful dominant platform currently shape public debate
work present experiment lead creation bert electra based german language model gbert gelectra varying input training data model size presence whole word masking wwm able attain sota performance across set document classification named entity recognition ner task model base large size adopt evaluation driven approach training model result indicate adding data utilizing wwm improve model performance benchmarking existing german model show model best german model date trained model made publicly available research community
present simple yet effective method train named entity recognition ner model operates business telephone conversation transcript contain noise due nature spoken conversation artifact automatic speech recognition first finetune luke stateoftheart named entity recognition ner model limited amount transcript use teacher model teach smaller distilbertbased student model using large amount weakly labeled data small amount humanannotated data model achieves high accuracy also satisfying practical constraint inclusion commercial telephony product realtime performance deployed costeffective cpu rather gpus paper introduce finetunethendistill method entity recognition real world noisy data deploy ner model limited budget production environment generating pseudolabels using large teacher model pretrained typed text finetuned noisy speech text train smaller student model make student model x time faster reserving accuracy finding demonstrate proposed approach effective limited budget scenario alleviate need human labeling large amount noisy data
verbal communication companied rich nonverbal signal usage gesture pose facial expression facilitates information transmission verbal channel however computational study explored nonverbal channel finer theoretical lens extract gesture representation monologue video data train neural sequential model order study degree nonverbal signal effectively transmit information focus examining whether gesture demonstrate similar pattern entropy rate constancy erc found word predicted information theory positive result shown support assumption lead conclusion speaker indeed use simple gesture convey information enhances verbal communication production nonverbal information rationally organized
empathy encompassing understanding supporting others emotion perspective strengthens various social interaction including written communication healthcare education journalism detecting empathy using ai model relying selfassessed ground truth crowdsourcing challenging due inherent noise annotation end propose novel system named large language modelguided empathy llmgem prediction system rectifies annotation error based defined annotation selection threshold make annotation reliable conventional empathy prediction model eg bertbased pretrained language model plms previously demographic information often integrated numerically empathy detection model contrast llmgem leverage gpt llm convert numerical data semantically meaningful textual sequence enabling seamless integration plms experiment three newsempathy datasets involving people empathy level towards newspaper article achieve stateoftheart test performance using robertabased plm code evaluation publicly available httpsgithubcomhasanrakibulllmgemhttpsgithubcomhasanrakibulllmgem
clustering short text stream challenging task due unique property infinite length sparse data representation cluster evolution existing approach often exploit short text stream batch way however determine optimal batch size usually difficult task since priori knowledge topic evolve addition traditional independent word representation graphical model tends cause term ambiguity problem short text clustering therefore paper propose online semanticenhanced dirichlet model short sext stream clustering called osdm integrates wordoccurance semantic information ie context new graphical model cluster arriving short text automatically online way extensive result demonstrated osdm better performance compared many stateoftheart algorithm synthetic realworld data set
pretrained language model plms improved performance natural language understanding recent year model pretrained large corpus encode general prior knowledge natural language agnostic information characteristic downstream task often result overfitting finetuned low resource datasets taskspecific information limited paper integrate label information taskspecific prior selfattention component pretrained bert model experiment several benchmark realword datasets suggest proposed approach largely improve performance pretrained model finetuning small datasets
questionanswering qa data often encodes essential information many facet paper study natural question get supervision qa data task typically nonqa one example textitcan use qamr michael et al improve named entity recognition suggest simply pretraining bert often best option propose textitquestionanswer driven sentence encoding quase framework quase learns representation qa data using bert stateoftheart contextual language model particular observe need distinguish two type sentence encoding depending whether target task single multisentence input case resulting encoding shown easytouse plugin many downstream task work may point alternative way supervise nlp task
recent progress ai largely attributed large language model llm however escalating memory requirement introduce challenge machine learning ml researcher engineer addressing requires developer partition large model distribute across multiple gpus tpus necessitates considerable coding intricate configuration effort existing model parallel tool megatronlm deepspeed alpa tool require user expertise machine learning system mlsys creating bottleneck llm development particularly developer without mlsys background work present redcoast redco lightweight userfriendly tool crafted automate distributed training inference llm well simplify ml pipeline development design redco emphasizes two key aspect firstly automate model parallelism study identifies two straightforward rule generate tensor parallel strategy given llm integrating rule redco facilitates effortless distributed llm training inference eliminating need additional coding complex configuration demonstrate effectiveness applying redco set llm architecture gptj llama opt size b secondly propose mechanism allows customization diverse ml pipeline definition merely three function avoiding redundant formulaic code like multihost related processing mechanism prof adaptable across spectrum ml algorithm foundational language modeling complex algorithm like metalearning reinforcement learning result redco implementation exhibit significantly fewer line code compared official counterpart redcoast redco released apache license httpsgithubcomtanyuqianredco
output speech recognition system always ideal subsequent downstream processing part speaker often make mistake system would accomplish speech reconstruction spontaneous speech input output represent flawless fluent contentpreserving english message speaker intended convey cleaner speech transcript would allow accurate language processing needed nlp task machine translation conversation summarization often rely grammatical input recognizing supervised statistical method identify transform illformed area transcript require richly labeled resource built spontaneous speech reconstruction corpus small corpus reconstructed aligned conversational telephone speech transcription fisher conversational telephone speech corpus strassel walker annotated several level including string transformation predicateargument structure shared linguistic research community
development annotated corpus critical process development speech application multiple target language technology develop monolingual speech application reached satisfactory result term performance effort porting existing application source language target language still expensive task paper address problem creating multilingual aligned corpus evaluation context spoken language understanding slu porting task discus challenge manual creation multilingual corpus well present algorithm creation multilingual slu via statistical machine translation smt
traditional event detection classifies word phrase given sentence set prede fined event type limitation pre defined set prevents adaptation event detection model new event type study novel formulation event detec tion describes type via several keywords match context document fa cilitates operation model new type introduce novel featurebased attention mechanism convolutional neural network event detection new mulation extensive experiment demon strate benefit new formulation new type extension event detection well proposed attention mechanism problem
named entity recognition critical task natural language processing field existing method task exploit contextual information within sentence however performance recognizing entity limited ambiguous sentencelevel context usually unsatisfactory fortunately sentence document provide supplementary documentlevel context help recognize entity addition word contain wordlevel contextual information since usually different preference entity type relative position named entity paper propose unified framework incorporate multilevel context named entity recognition use taglm basic model capture sentencelevel context incorporate documentlevel context propose capture interaction sentence via multihead self attention network mine wordlevel context propose auxiliary task predict type word capture type preference jointly train model entity recognition auxiliary classification task via multitask learning experimental result several benchmark datasets validate effectiveness method
demonstrate javascript implementation convolutional neural network performs feedforward inference completely browser deployment mean model run completely client wide range device without making backend server request design useful application stringent latency requirement low connectivity evaluation show feasibility javascript deployment target furthermore inbrowser implementation enables seamless integration javascript ecosystem information visualization providing opportunity visually inspect neural network better understand inner working
unsupervised clustering widely used explore large corpus existing formulation neither consider user goal explain cluster meaning propose new task formulation goaldriven clustering explanation goalex represents goal explanation freeform language description example categorize error made summarization system input goalex corpus annotatorwritten comment systemgenerated summary goal description cluster comment based annotator think summary imperfect output text cluster explanation cluster mention summary miss important context information relates goal accurately explains comment belong cluster tackle goalex prompt language model corpus subset goal brainstorm list explanation representing cluster classify whether sample belongs cluster based explanation finally use integer linear programming select subset candidate cluster cover sample minimizing overlap automatic human evaluation corpus without label method produce accurate goalrelated explanation prior method
ojibwe language several dialect vary degree spoken written form present method using support vector machine classify two different dialect eastern southwestern ojibwe using small corpus text classification accuracy sentence level across fivefold cross validation sentencetrained model applied data set individual word code word level data set released openly github link inserted final version working demonstration notebook uploaded paper
human language evolved towards newer form communication social medium emojis ie ideogram bearing visual meaning play key role increasing body work aimed computational modeling emoji semantics currently little understanding make computational model represent predict given emoji certain way paper propose labelwise attention mechanism attempt better understand nuance underlying emoji prediction addition advantage term interpretability show proposed architecture improves standard baseline emoji prediction particularly well predicting infrequent emojis
scientific vocabulary set term designate scientific concept set lexical unit used several application ranging development terminological dictionary machine translation system development lexical database beyond even though automatic term recognition system exist since process still mainly done hand since generally yield accurate result although less time higher cost reason fairly low precision recall result obtained domain dependence existing tool lack available semantic knowledge needed validate result paper present method us wikipedia semantic knowledge resource validate term candidate set scientific text book used last three year high school mathematics health education ecology proposed method may applied domain language assuming minimal coverage wikipedia
ability identify resolve uncertainty crucial robustness dialogue system indeed confirmed empirically system utilise bayesian approach dialogue belief tracking however system consider confidence estimate difficulty scaling complex setting neural dialogue system hand rarely take uncertainty account therefore overconfident decision less robust moreover performance tracking task often evaluated isolation without consideration effect downstream policy optimisation propose use different uncertainty measure neural belief tracking effect measure downstream task policy optimisation evaluated adding selected measure uncertainty feature space policy training policy interaction user simulator human simulated user result show incorporating measure lead improvement performance robustness downstream dialogue policy highlight importance developing neural dialogue belief tracker take uncertainty account
submission describes development finegrained textchunking algorithm task comprehensive mwe segmentation task notably focus identification colloquial idiomatic language submission also includes thorough model evaluation context two recent shared task spanning different language many text domain including noisy usergenerated text evaluation exhibit presented model best overall purpose mwe segmentation opensource software released submission although link withheld purpose anonymity additionally author acknowledge existence preprint document arxivorg avoided maintain anonymity review
neural machine translation mt model obtain stateoftheart performance maintaining simple endtoend architecture however little known model learn source target language training process work analyze representation learned neural mt model various level granularity empirically evaluate quality representation learning morphology extrinsic partofspeech morphological tagging task conduct thorough investigation along several parameter wordbased v characterbased representation depth encoding layer identity target language encoder v decoder representation datadriven quantitative evaluation shed light important aspect neural mt system ability capture word structure
social medium text replete unusual capitalization pattern posit capitalizing token like performs two expressive function mark person socially mark certain part utterance salient others focusing gender sentiment illustrate using corpus tweet capitalization appears negative positive context used female compared male yet find gender use capitalization similar way expressing sentiment
analyse transformerbased language model learns rule chess text data recorded game show possible investigate model capacity available number training data influence learning success language model help chessspecific metric metric show game used training studied range offer significantly better result training time however model size show clear influence also interesting observe usual evaluation metric language model predictive accuracy perplexity give indication examination trained model reveals store information board state activation neuron group overall sequence previous move influence newlygenerated move
paper present multilingual euphemism detection shared task fourth workshop figurative language processing figlang held conjunction naacl participant invited attempt euphemism detection task four different language american english global spanish yoruba mandarin chinese given input text containing potentially euphemistic term pet determine use euphemistic present expanded datasets used shared task summarize team method finding analyze potential implication future research
retrievalaugmented generation rag method receiving increasing attention nlp community achieved stateoftheart performance many nlp downstream task compared conventional pretrained generation model rag method remarkable advantage easy knowledge acquisition strong scalability low training cost although existing rag model applied various knowledgeintensive nlp task opendomain qa dialogue system work focused retrieving unstructured text document wikipedia paper first elaborate current obstacle retrieving knowledge singlesource homogeneous corpus demonstrate evidence existing literature experiment provide multiple solution retrievalaugmented generation method across heterogeneous knowledge
last year microblogging platform twitter given rise deluge textual data used analysis informal communication million individual work propose informationtheoretic approach geographic language variation using corpus based twitter test model ten concept associated keywords detected spanish tweet geolocated spain employ dialectometric measure cosine similarity jensenshannon divergence quantify linguistic distance lexical level cell created uniform grid map done single concept general case taking account average considered variant latter permit analysis dialect naturally emerge data interestingly result reveal existence two dialect macrovarieties first group includes regionspecific speech spoken small town rural area whereas second cluster encompasses city tend use uniform variety since result obtained two different metric qualitatively agree work suggests social medium corpus efficiently used dialectometric analysis
paper present analysis different semantic relation extracted wordnet extended wordnet semcor respect role task knowledgebased word sense disambiguation experiment use algorithm test set different variant knowledge graph result show different set relation different impact result positive negative beneficial one discussed respect combination relation respect test set inclusion inference modest impact accuracy addition syntactic relation produce stable improvement baseline
key challenge topicfocused summarization determining information included summary problem known content selection work propose new method studying content selection topicfocused summarization called summary cloze task goal summary cloze task generate next sentence summary conditioned beginning summary topic reference document main challenge deciding information reference relevant topic partial summary included summary although cloze task address aspect traditional summarization problem narrow scope task allows u collect largescale datset nearly k summary cloze instance wikipedia report experimental result new dataset using various extractive model twostep abstractive model first extractively selects small number sentence abstractively summarizes result show topic partial summary help model identify relevant content task remains significant challenge
present recurrent neural network based system automatic quality estimation natural language generation nlg output jointly learns assign numerical rating individual output provide pairwise ranking two different output latter trained using pairwise hinge loss score two copy rating network use learning rank synthetic data improve quality rating assigned system synthesise training pair distorted system output train system rank less distorted one higher lead increase correlation human rating previous benchmark also establish state art dataset relative ranking ee nlg challenge dusek et al synthetic data lead accuracy increase base model
trend machine learning community adopt selfsupervised approach pretrain deep network selfsupervised representation learning ssl utilizes proxy supervised learning task example distinguishing part input signal distractors generating masked input segment conditioned unmasked one obtain training data unlabeled corpus bert gpt nlp simclr byol cv famous example direction approach make possible use tremendous amount unlabeled data available web train large network solve complicated task thus ssl potential scale current machine learning technology especially lowresourced underrepresented use case democratize technology recently selfsupervised approach speech processing also gaining popularity several workshop relevant topic hosted icml urlhttpsicmlsasgitlabio neurips urlhttpsneuripssasgithubio aaai urlhttpsaaaisasgithubio however previous tutorial similar topic based author best knowledge due growing popularity ssl shared mission area bringing speech language technology use case better quality scaling technology underrepresented language propose tutorial systematically survey latest ssl technique tool datasets performance achievement speech processing proposed tutorial highly relevant special theme acl language diversity one main focus tutorial leveraging ssl reduce dependence speech technology labeled data scale technology especially underrepresented language use case
polysemy phenomenon single word form possesses two related sens extremely ubiquitous part natural language analyzing sparked rich discussion linguistics psychology philosophy community alike scarce attention paid polysemy computational linguistics even scarcer attention toward quantifying polysemy paper propose novel unsupervised framework compute estimate polysemy score word multiple language infuse proposed quantification syntactic knowledge form dependency structure informs final polysemy score lexicon motivated recent linguistic finding suggest implicit relation syntax ambiguitypolysemy adopt graph based approach computing discrete ollivier ricci curvature graph contextual nearest neighbor test framework curated datasets controlling different sense distribution word typologically diverse language english french spanish effectiveness framework demonstrated significant correlation quantification expert human annotated language resource like wordnet observe point increase correlation coefficient compared previous quantification study english research leverage contextual language model syntactic structure empirically support widely held theoretical linguistic notion syntax intricately linked ambiguitypolysemy
leveraging representation pretrained transformerbased encoders achieves stateoftheart performance numerous nlp task larger encoders improve accuracy spoken language understanding slu challenging use given inference latency constraint online system especially cpu machineswe evaluate using larger parameter bert encoder share representation across language domain task slu compared using smaller parameter bert encoders language domain taskdecoupled finetuningrunning inference larger shared encoder gpu latency neutral reduces infrastructure cost compared running inference decoupled smaller encoders cpu machine larger shared encoder reduces semantic error rate test set representing user request voicecontrolled device tail test set average across four language
propose simple effective method machine translation evaluation require reference translation approach based grounding entity mention found source sentence candidate translation largescale multilingual knowledge base measuring recall grounded entity found candidate v found source approach achieves highest correlation human judgement language pair wmt benchmark evaluation without reference largest number win single evaluation method task language pair also achieve higher correlation human judgement bleu foster research release dataset containing million grounded entity mention across language pair wmt metric track data
distributional thesaurus useful many task natural language processing paper address problem building evaluating thesaurus help information retrieval ir concept two main contribution proposed first following work show ir tool concept used success build thesaurus several experiment evaluating directly result reference lexicon show ir model outperform stateoftheart system secondly use ir applicative framework indirectly evaluate generated thesaurus taskbased evaluation validates ir approach used build thesaurus moreover allows u compare result direct evaluation framework used literature observed difference bring evaluation habit question
celebrity among prolific user social medium promoting persona rallying follower activity closely tied genuine writing sample make worthy research subject many respect least profiling paper introduce webis celebrity corpus construction twitter feed verified account carefully linked respective wikidata item crawling cleansing resulting profile contain average word per profile piece personal information crossevaluation checked correct association twitter account wikidata item revealed error rate rendering profile highly reliable corpus comprises wide crosssection local global celebrity forming unique combination scale profile comprehensiveness label reliability establish state art profiling performance evaluating winning approach submitted pan gender prediction task transfer learning experiment outperformed deep learning approach also use exemplify celebrity occupation prediction first time
recently domain shift affect accuracy due difference data source target domain become serious issue using machine learning method solve natural language processing task additional pretraining finetuning using target domain corpus pretraining model bert bidirectional encoder representation transformer address issue however additional pretraining bert model difficult requires significant computing resource efficiently learning encoder classifies token replacement accurately electra pretraining model replaces bert pretraining method masked language modeling method called replaced token detection improves computational efficiency allows additional pretraining model practical extent herein propose method addressing computational efficiency pretraining model domain shift constructing electra pretraining model japanese dataset additional pretraining model downstream task using corpus target domain constructed pretraining model electra japanese conducted experiment document classification task using data japanese news article result show even model smaller pretrained model performs equally well
despite current diversity inclusion initiative academic community researcher nonnative command english still face significant obstacle writing paper english paper present langsmith editor assist inexperienced nonnative researcher write english paper especially natural language processing nlp field system suggest fluent academicstyle sentence writer based rough incomplete phrase sentence system also encourages interaction human writer computerized revision system experimental result demonstrated langsmith help nonnative englishspeaker student write paper english system available urlhttpsemnlpdemoeditorlangsmithcojp
present nondeterministic finitestate transducer act tokenizer normalizer free text input broadcoverage lfg german compare basic tokenizer used earlier version grammar sophisticated tokenizer use revised tokenizer increase coverage grammar term full parses sentence tiger corpus
natural language processing nlp research increasingly focusing use large language model llm popular one either fully partially closedsource lack access model detail especially regarding training data repeatedly raised concern data contamination among researcher several attempt made address issue limited anecdotal evidence trial error additionally overlook problem indirect data leaking modelsare iteratively improved using data coming user work conduct first systematic analysis work using openais gpt gpt prominently used llm today context data contamination analysing paper considering openais data usage policy extensively document amount data leaked model first year model release report model globally exposed sample benchmark time document number evaluation malpractice emerging reviewed paper unfair missing baseline comparison reproducibility issue release result collaborative project httpsleakllmgithubio researcher contribute effort
word embedding learning method require large number occurrence word accurately learn embedding however outofvocabulary oov word appear training corpus emerge frequently smaller downstream data recent work formulated oov embedding learning fewshot regression problem demonstrated metalearning improve result obtained however algorithm used modelagnostic metalearning maml known unstable perform worse large number gradient step used parameter update work propose use leap metalearning algorithm leverage entire trajectory learning process instead beginning end point thus ameliorates two issue experiment benchmark oov embedding learning dataset extrinsic evaluation leap performs comparably better maml go examine context beneficial learn oov embedding propose choice context may matter metalearning employed
modern deep model summarization attains impressive benchmark performance prone generating miscalibrated predictive uncertainty mean assign high confidence lowquality prediction leading compromised reliability trustworthiness realworld application probabilistic deep learning method common solution miscalibration problem however relative effectiveness complex autoregressive summarization task wellunderstood work thoroughly investigate different stateoftheart probabilistic method effectiveness improving uncertainty quality neural summarization model across three largescale benchmark varying difficulty using newly introduced evaluation protocol show probabilistic method consistently improve model generation uncertainty quality leading improved selective generation performance ie abstaining lowquality summary practice also reveal notable failure pattern probabilistic method widelyadopted nlp community eg deep ensemble monte carlo dropout cautioning importance choosing appropriate method data setting
sequencetosequence neural generation model achieved promising performance short text conversation task however tend generate genericdull response leading unsatisfying dialogue experience observe conversation task query could multiple response form ton mton relationship view total corpus objective function used standard sequencetosequence model dominated loss term generic pattern inspired observation introduce statistical reweighting method assigns different weight multiple response query train common neural generation model weight experimental result large chinese dialogue corpus show method improves acceptance rate generated response compared several baseline model significantly reduces number generated generic response
biased association challenge development classifier detecting toxic language hindering fairness accuracy potential solution investigate recently introduced debiasing method text classification datasets model applied toxic language detection focus lexical eg swear word slur identity mention dialectal marker specifically african american english comprehensive experiment establish existing method limited ability prevent biased behavior current toxicity detector propose automatic dialectaware data correction method proofofconcept despite use synthetic label method reduces dialectal association toxicity overall finding show debiasing model trained biased toxic language data effective simply relabeling data remove existing bias
present phobert two version phobertbase phobertlarge first public largescale monolingual language model pretrained vietnamese experimental result show phobert consistently outperforms recent best pretrained multilingual model xlmr conneau et al improves stateoftheart multiple vietnamesespecific nlp task including partofspeech tagging dependency parsing namedentity recognition natural language inference release phobert facilitate future research downstream application vietnamese nlp phobert model available urlhttpsgithubcomvinairesearchphobert
clinical natural language processing increasingly popular research area nlp community rise large language model llm impressive ability nlp task crucial pay attention clinical application sequence sequence generative approach llm widely used recent year part research clinical nlp recent advance field participated task mediqachat aclclinicalnlp workshop paper explain method finding well comment result limitation
present submission wmt multimodal translation task main feature submission applying selfattentive network instead recurrent neural network evaluate two method incorporating visual feature model first include image representation another input network second train model predict visual feature use auxiliary objective submission acquired textual multimodal additional data proposed method yield significant improvement recurrent network selfattentive textual baseline
learning rationale seek augment model prediction accuracy using humanannotated rationale ie subset input token justify chosen label often form intermediate multitask supervision intuitive idea proven elusive practice make two observation human rationale via empirical analysis maximizing rationale supervision accuracy necessarily optimal objective improving model accuracy human rationale vary whether provide sufficient information model exploit prediction building insight propose several novel loss function learning strategy evaluate effectiveness three datasets human rationale result demonstrate consistent improvement baseline label rationale accuracy including accuracy improvement multirc work highlight importance understanding property human explanation exploiting accordingly model training
present michael simple lightweight method automatic arabic dialect identification madar travel domain dialect identification michael us simple characterlevel feature order perform preprocessing free classification precisely character ngrams extracted original sentence used train multinomial naive bayes classifier system achieved official score accuracy textlessntextless showed much better result character gram accuracy
conventional neural machine translation nmt model benefit training additional agent eg dual learning bidirectional decoding one agent decod ing left right decoding opposite direction paper extend training framework multiagent sce nario introducing diverse agent teractive updating process training time agent learns advanced knowledge others work together improve translation quality experimental result nist chineseenglish iwslt german english wmt englishgerman largescale chineseenglish translation task indicate approach achieves absolute improvement strong baseline sys tems show competitive performance task
text style transfer tst performable approach latent space disentanglement cycleconsistency loss prototype editing etc prototype editing approach known quite successful tst involves two key phase masking source styleassociated token b reconstruction sourcestyle masked sentence conditioned target style follow similar transduction method transpose difficult direct source target tst task simpler stylemasked language model smlm task wherein similar bert citation goal model reconstruct source sentence stylemasked version arrive smlm mechanism naturally formulating prototype editing transduction method probabilistic framework tst resolve estimating hypothetical parallel dataset partially observed parallel dataset wherein domain assumed common latent stylemasked prior generate stylemasked prior use explainable attention choice attribution precise stylemasking step also introduce costeffective accurate attributionsurplus method determining position mask arbitrary attribution model time empirically show nongenerational approach well suite content preserving criterion task like tst even complex style like discourse manipulation model style mlm outperforms strong tst baseline par stateoftheart tst model use complex architecture order parameter
paper introduces approach annotating eye gaze considering social referential function multimodal humanhuman dialogue detecting interpreting temporal pattern gaze behavior cue natural human also mostly unconscious process however cue difficult conversational agent robot avatar process generate key factor recognize variant carry successful conversation misinterpretation lead total failure given interaction paper introduces annotation scheme eyegaze humanhuman dyadic interaction intended facilitate learning eyegaze pattern multimodal natural dialogue
work build question answering qa classification dataset social medium platform namely telegram public channel called askanythingethiopia channel k subscriber existed since may platform allows asking question belong various domain like politics economics health education since question posed mixedcode apply different strategy preprocess dataset question posted amharic english amharic latin script part preprocessing tool build latin ethiopic script transliteration tool collect k amharic k transliterated question develop deep learningbased question answering classifier attain high fscore different question class category datasets preprocessing script opensourced facilitate research amharic communitybased question answering
propose new sociallyimpactful task natural language processing news corpus extract name person killed police present newly collected police fatality corpus release publicly present model solve problem us embased distant supervision logistic regression convolutional neural network classifier model outperforms two offtheshelf event extractor system suggest candidate victim name case faster one major manuallycollected police fatality database
first name tao last name qi email taoqiqtgmailcom affiliation department electronic engineering tsinghua university first name suyu last name ge email gesymailstsinghuaeducn affiliation department electronic engineering tsinghua university first name chuhan last name wu email wuchmailstsinghuaeducn affiliation department electronic engineering tsinghua university first name yubo last name chen email chenybmailstsinghuaeducn affiliation department electronic engineering tsinghua university first name yongfeng last name huang email yfhuangmailtsinghuaeducn affiliation department electronic engineering tsinghua university toponym resolution important challenging task neural language processing field wide application emergency response social medium geographical event analysis toponym resolution roughly divided two independent step ie toponym detection toponym disambiguation order facilitate study toponym resolution semeval task proposed contains three subtasks ie toponym detection toponym disambiguation toponym resolution paper introduce system participated semeval task toponym detection approach use taglm basic model explore use various feature task word embeddings extracted pretrained language model po tag lexical feature extracted dictionary toponym disambiguation propose heuristic rulebased method using toponym frequency population system achieved strict macro f strict micro f overlap macro f overlap micro f toponym detection subtask
medical professional search published literature specifying type patient medical intervention outcome measure interest paper demonstrate feature encoding syntactic pattern improve performance stateoftheart sequence tagging model neural linear information extraction medically relevant category present analysis type pattern exploited semantic space induced ie distributed representation learned identified multitoken pattern show learned representation differ substantially constituent unigrams suggesting pattern capture contextual information otherwise lost
given question set candidate answer answer selection task identifying candidate answer question correctly important problem natural language processing application many area recently many deep learning based method proposed task produce impressive performance without relying feature engineering expensive external resource paper aim provide comprehensive review deep learning method applied answer selection
present pilot semeval task suggestion mining task consists subtasks b created labeled data feedback forum hotel review respectively subtask provides training test data domain subtask b evaluates system test dataset different domain available training data team participated shared task total member summarize problem definition benchmark dataset preparation method used participating team providing detail method used top ranked system dataset made freely available help advance research suggestion mining reproduce system submitted task
automated factchecking often presented epistemic tool factcheckers social medium consumer stakeholder use fight misinformation nevertheless paper thoroughly discus textithow document analysing highlycited paper annotating epistemic element related intended use ie mean end stakeholder find narrative leaving aspect common many paper propose inconsistent mean end feasibility suggested strategy rarely empirical backing argue vagueness actively hinders technology reaching goal encourages overclaiming limit criticism prevents stakeholder feedback accordingly provide several recommendation thinking writing use factchecking artefact
sanskrit classical language million extant manuscript fit digitisation available written printed scannedimage form however still considered lowresource language come available digital resource work release postocr text correction dataset containing around sentence million word different book text sanskrit known diverse term linguistic stylistic usage since sanskrit lingua francua discourse indian subcontinent millennium keeping mind release multidomain dataset area diverse astronomy medicine mathematics old century release multiple strong baseline benchmark task based pretrained seqseq language model find bestperforming model consisting byte level tokenization conjunction phonetic encoding bytslp yield point increase ocr output term word character error rate moreover perform extensive experiment evaluating model performance analyse common cause mispredictions graphemic lexical level code dataset publicly available httpsgithubcomayushbitspeocrsanskrit
text complexity analysis useful task education example help teacher select appropriate text student according educational level task requires analysis several text feature people mostly manually eg syntactic complexity word variety etc paper present tool useful complexity analysis called cohmetrixesp spanish version cohmetrix able calculate readability index analyse index behave corpus simple complex document also use feature complexity binary classifier text spanish experiment machine learning algorithm got fmeasure corpus contains tale kid adult fmeasure corpus text written student spanish foreign language
transformerbased model brought radical change neural machine translation key feature transformer architecture socalled multihead attention mechanism allows model focus simultaneously different part input however recent work shown attention head learn simple often redundant positional pattern paper propose replace one attention head encoder layer simple fixed nonlearnable attentive pattern solely based position require external knowledge experiment different data size multiple language pair show fixing attention head encoder side transformer training time impact translation quality even increase bleu score point lowresource scenario
text revision necessary process improve text quality process writer constantly edit text different edit intention identifying edit intention raw text always ambiguous work previous work revision system mainly focus editing text according one specific edit intention work aim build multiintent text revision system could revise text without explicit intent annotation system based prefixtuning first get prefix every edit intent train prefix transfer module enabling system selectively leverage knowledge various prefix according input text conduct experiment iterater dataset result show system outperforms baseline system significantly improve sari score improvement thrives learned editing intention prefix
talk present two nlp system developed helping disaster victim rescue worker aftermath largescale disaster disaana provides answer question short supply tokyo display location related answer map dsumm automatically summarizes large number disaster related report concerning specified area help rescue worker understand disaster situation macro perspective system publicly available web service aftermath kumamoto earthquake japanese government actually used disaana analyze situation
applying natural language processing nlp medical clinical text bring important social benefit mining valuable information unstructured text popular application purpose named entity recognition ner annotation policy existing clinical corpus standardized across clinical text different type paper present annotation guideline aimed covering medical document various type radiography interpretation report medical record furthermore annotation designed avoid burdensome requirement related medical knowledge thereby enabling corpus development without medical specialist achieve design feature specifically focus critical lung disease stabilize linguistic pattern corpus annotating around electronic medical record following annotation scheme demonstrated feasibility using ner task result suggest guideline applicable largescale clinical nlp project
work present minimal neural model constituency parsing based independent scoring label span show model compatible classical dynamic programming technique also admits novel greedy topdown inference algorithm based recursive partitioning input demonstrate empirically prediction scheme competitive recent work combined basic extension scoring model capable achieving stateoftheart singlemodel performance penn treebank f strong performance french treebank f
multihop inference explanation generation combine two fact make inference task focus generating explanation elementary science question task relevance explanation qa pair vital importance address task threestep framework proposed firstly vector distance two text utilized recall topk relevant explanation question reducing calculation consumption selection module employed choose relative fact autoregressive manner giving preliminary order retrieved fact thirdly adopt reranking module rerank retrieved candidate explanation relevance fact qa pair experimental result illustrate effectiveness proposed framework improvement ndcg official baseline
previous study question answering knowledge graph typically operated single knowledge graph kg kg assumed known priori lever aged similarly user query inference however assumption applicable realworld setting health care one need handle query new user unseen kg inference furthermore privacy concern high computational cost render infeasible query single kg information user answering specific user query concern motivate question answer ing setting personalized knowledge graph perkgqa user restricted access kg observe current stateoftheart kgqa method require learning prior node representation fare poorly propose two complementary approach pathcbr pathrgcn perkgqa former simple nonparametric technique employ casebased reasoning latter parametric approach using graph neural network proposed method circumvent learning prior representation generalize unseen kg outperform strong baseline academic internal dataset
paper present submission semeval task multigenerator multidomain multilingual blackbox machinegenerated text detection focusing detection machinegenerated text mgts english specifically approach relies combining embeddings robertabase diversity feature us resampled training set score th ranking subtask result show approach generalizable across unseen model domain achieving accuracy
instruction tuning potential stimulate enhance specific capability large language model llm however achieving right balance data crucial prevent catastrophic forgetting interference task address limitation enhance training flexibility propose mixtureofloras moa architecture novel parameterefficient tuning method designed multitask learning llm paper start individually training multiple domainspecific lora module using corresponding supervised corpus data lora module aligned expert design principle observed mixtureofexperts moe subsequently combine multiple loras using explicit routing strategy introduce domain label facilitate multitask learning help prevent interference task ultimately enhances performance individual task furthermore lora model iteratively adapted new domain allowing quick domainspecific adaptation experiment diverse task demonstrate superior robust performance promote wide application domainspecific llm
intelligent chatbot take dialogue sentiment prediction core tackle long dialogue sentiment prediction problem many realworld application current stateoftheart method usually employ attentionbased dialogue sentiment prediction model however conversation progress topic involved change sentiment become frequent lead sharp decline accuracy efficiency current method therefore propose multiround long dialogue sentiment prediction based multidimensional attention mldspma focus different topic particular mlsdpma leverage sliding window capture different topic traverse historical dialogue sliding window contextual dependency sentiment persistence sentiment infectivity characterized local attention cross fusion performed learn dialogue sentiment globally global attention proposed iteratively learn comprehensive sentiment historical dialogue finally integrate local attention conducted extensive experimental research publicly available dialogue datasets experimental result show compared current stateoftheart method model improves accuracy microf score
paper discus result iucl system nli shared task system explore variety phonetic algorithm generate feature native language identification feature contrasted one successful type feature nli character ngrams find although phonetic feature perform well character ngrams alone increase overall f score used together character ngrams
neural model shown several stateoftheart performance semantic role labeling srl however neural model require immense amount semanticrole corpus thus well suited lowresource language domain paper proposes semisupervised semantic role labeling method outperforms stateoftheart limited srl training corpus method based explicitly enforcing syntactic constraint augmenting training objective syntacticinconsistency loss component us srlunlabeled instance train jointobjective lstm conll english section proposed semisupervised training srllabeled data varying amount srlunlabeled data achieves f respectively pretrained model trained sota architecture elmo srllabeled data additionally using syntacticinconsistency loss inference time proposed model achieves f pretrained model srllabeled data respectively
describe vision current version natural language processing system aimed group decision making facilitation borrowing scientific field decision analysis essential role identify alternative criterion associated given decision keep track proposed expressed sentiment towards based information system help identify agreement dissent recommend alternative overall seek help group reach decision natural yet auditable fashion
traditional keyvalue memory neural network kvmemnns proved effective support shallow reasoning collection document domain specific question answering reading comprehension task however extending kvmemnns knowledge based question answering kbqa trivia properly decompose complex question sequence query memory update query representation support multihop reasoning memory paper propose novel mechanism enable conventional kvmemnns model perform interpretable reasoning complex question achieve design new query updating strategy mask previouslyaddressed memory information query representation introduce novel stop strategy avoid invalid repeated memory reading without strong annotation signal also enables kvmemnns produce structured query work semantic parsing fashion experimental result benchmark datasets show solution trained questionanswer pair provide conventional kvmemnns model better reasoning ability complex question achieve stateofart performance
large language model llm shown promising ability generate synthetic querydocument pair prompting demonstration enabled building better ir model especially task training data typically synthetic query generation qgen approach condition input context eg text document generate query relevant context condition qgen additionally relevance label eg relevant v irrelevant generate query across relevance bucket however find qgen approach suboptimal require model reason desired label input handful example work propose reduce burden llm generating query simultaneously different label hypothesize instead asking model generate say irrelevant query given input context asking model generate irrelevant query relative relevant query much simpler task extensive experimentation across nine ir datasets show synthetic query generated fashion translates better downstream performance
automation task community question answering cqa dominated machine learning approach whose performance often limited number training example starting neural sequence learning approach attention explore impact two data augmentation technique question ranking performance method swap reference question paraphrase training example automatically selected external datasets method shown lead substantial gain accuracy strong baseline improvement obtained changing model architecture mirror structure seen data
work propose new model aspectbased sentiment analysis contrast previous approach jointly model detection aspect classification polarity endtoend trainable neural network conduct experiment different neural architecture word representation recent germeval dataset able show considerable performance gain using joint modeling approach setting compared pipeline approach combination convolutional neural network fasttext embeddings outperformed best submission shared task establishing new state art
writing important element language learning increasing amount learner writing taking place online environment teacher provide valuable feedback commenting learner text however providing relevant feedback every issue every student timeconsuming address turn nlp subfield feedback comment generation task automatically generating explanatory note learner text goal enhancing learning outcome however freelygenerated comment may mix multiple topic seen training data even give misleading advice thesis proposal seek address issue categorizing comment constraining output noisy class describe annotation scheme feedback comment corpus using comment topic broader scope existing typology focused error correction outline plan experiment grouping clustering replacing particularly diverse category modular template comparing generation result using different linguistic feature model architecture original dataset versus newly annotated one paper present first two year master component research project fiveyear combined master phd program
recent literature shown large language model llm generally excellent fewshot reasoner solve text reasoning task however capability llm table reasoning task yet explored paper aim understanding well llm perform tablerelated task fewshot incontext learning specifically evaluated llm popular table qa fact verification datasets like wikitablequestion fetaqa tabfact feverous found llm competent complex reasoning table structure though model pretrained table corpus combined chain thought prompting llm achieve strong performance shot demonstration even par sota model show llm even competent generating comprehensive longform answer fetaqa tuned tlarge manually studied reasoning chain elicited llm found reasoning chain highly consistent underlying semantic form believe llm serve simple yet generic baseline future research code data released urlhttpsgithubcomwenhuchentablecot
review product service internet marketplace website contain rich amount information user often wish survey review review snippet perspective certain aspect resulted large body work aspect identification extraction corpus work evaluate newlyproposed neural model aspect extraction two practical task first extract canonical sentence various aspect review judged human evaluator alternative kmeans baseline remarkably well setting second experiment focus suitability recovered aspect distribution represent user review written set review reranking experiment find aspectbased profile largely capture notion user preference showing divergent user generate markedly different review ranking
coding emrs diagnosis procedure code indispensable task billing secondary data analysis monitoring health trend speed accuracy coding critical coding error could lead patientside financial burden misinterpretation patient wellbeing timely coding also needed avoid backlog additional cost healthcare facility paper present new neural network architecture combine idea fewshot learning matching network multilabel loss function convolutional neural network text classification significantly outperform stateoftheart model evaluation conducted using well known deidentified emr dataset mimic variety multilabel performance measure
search system often focused providing relevant result assuming corpus user need focus present however many corpus today reflect significant longitudinal collection ranging year web hundred year digitized newspaper book understanding temporal intent user retrieving relevant historical content become significant challenge common search feature query expansion leverage relationship term function well across time relationship vary temporally work introduce temporal relationship model extracted longitudinal data collection model support task identifying given two word relate present algorithmic framework task show application task query expansion achieving high gain
linguistic fieldworker collect archive metadata part language resource lr create often work resourceconstrained environment prevent using computer data entry situation linguist must complete timeconsuming errorprone digitization task limit quantity quality resource metadata produce thieberger berez margetts margetts paper describes method entering linguistic metadata mobile device using open data kit odk platform suite open source tool designed mobile data collection
generating highquality summary chat dialog often requires large labeled datasets propose method efficiently use unlabeled data extractive summarization customeragent dialog method frame summarization questionanswering problem use stateoftheart large language model llm generate pseudolabels dialog use pseudolabels finetune chat summarization model effectively transferring knowledge large llm smaller specialized model demonstrate method tweetsumm dataset show using original labelled data set achieve rougel whereas current stateoftheart trained entire training data set obtains rougel word worst case ie rougel still effectively retain performance using data
problem event extraction requires detecting event trigger extracting corresponding argument existing work event argument extraction typically relies heavily entity recognition preprocessingconcurrent step causing wellknown problem error propagation avoid issue introduce new paradigm event extraction formulating question answering qa task extract event argument endtoend manner empirical result demonstrate framework outperforms prior method substantially addition capable extracting event argument role seen training time ie zeroshot learning setting
scientific machine reading comprehension smrc aim facilitate understanding scientific text humanmachine interaction existing dataset significantly contributed field predominantly focus singleperspective questionanswer pair thereby overlooking inherent variation comprehension level among different reader address limitation introduce novel multiperspective scientific machine reading comprehension dataset scimrc incorporates perspective beginner student expert dataset comprises scientific paper questionanswer pair pair corresponding beginner student expert respectively extensive experiment conducted scimrc using pretrained model underscore importance considering diverse perspective smrc highlight challenging nature scientific machine comprehension task
main goal behind stateoftheart pretrained multilingual model multilingual bert xlmr enabling bootstrapping nlp application lowresource language zeroshot fewshot crosslingual transfer however due limited model capacity transfer performance weakest exactly lowresource language language unseen pretraining propose madx adapterbased framework enables high portability parameterefficient transfer arbitrary task language learning modular language task representation addition introduce novel invertible adapter architecture strong baseline method adapting pretrained multilingual model new language madx outperforms state art cross lingual transfer across representative set typologically diverse language named entity recognition causal commonsense reasoning achieves competitive result question answering code adapter available adapterhubml
paper describe team justers effort commonsense validation explanation comve task part semeval evaluate five pretrained transformerbased language model various size three proposed subtasks first two subtasks best accuracy level achieved model respectively placing team th th place respectively last subtask model reach bleu score human evaluation score placing team th rd place according two metric respectively latter away st place human evaluation score
codeswitching fluent alternation two language conversation bilingual large population speaker codeswitch communication little effort made develop tool codeswitching including partofspeech tagger paper propose approach po tagging codeswitched englishspanish data based recurrent neural network test model known monolingual benchmark demonstrate neural po tagging model par stateoftheart method next test codeswitched method miami bangor corpus english spanish conversation focusing two type experiment po tagging alone achieve accuracy joint partofspeech language id tagging achieves similar po tagging accuracy high language id accuracy finally show proposed model outperform stateoftheart codeswitched tagger
paper present domain adaptation method adopted huawei translation service center hwtsc train neural machine translation nmt system englishgerman ende language pair wmt biomedical translation task nmt system built deep transformer larger parameter size based biomedical nmt system trained last year leverage curriculum learning data diversification forward translation back translation transductive ensemble learning improve system performance overall believe submission achieve highly competitive result official final evaluation
social medium facilitated news consumption also led wide spread fake news news article social medium usually condensed full knowledge entity existing method fake news detection use external entity knowledge however majority method focus news entity information ignore structured knowledge among news entity address issue work propose knowledge graph enhanced language model kapalm novel model fuse coarse finegrained representation entity knowledge knowledge graph kg firstly identify entity news content link entity kg subgraph kg extracted provide structured knowledge entity kg fed graph neural network obtain coarsegrained knowledge representation subgraph pruned provide finegrained knowledge fed attentive graph graph pooling layer finally integrate coarse finegrained entity knowledge representation textual representation fake news detection experimental result two benchmark datasets show method superior stateoftheart baseline addition competitive fewshot scenario
significant challenge involved design implementation dialogbased tutoring system dbt ranging domain engineering natural language classification eventually instantiating adaptive personalized dialog strategy issue magnified implementing system scale across domain paper describe reflect design method decision assessment led successful deployment ai driven dbt currently used several hundred college level student practice selfregulated study diverse subject like sociology communication american government
goal smmh shared task release annotated social medium based health related datasets research community compare performance natural language processing machine learning system task involving datasets third execution smmh shared task cohosted emnlp comprised four subtasks subtasks involve annotated user post twitter tweet focus automatic classification tweet mentioning drug name ii automatic classification tweet containing report firstperson medication intake iii automatic classification tweet presenting selfreports adverse drug reaction adr detection iv automatic classification vaccine behavior mention tweet total team participated system run submitted task task task task
analogymaking narrative crucial human reasoning paper evaluate ability identify generate analogy constructing firstofitskind largescale storylevel analogy corpus storyanalogy contains k story pair diverse domain human annotation two similarity extended structuremapping theory design set test storyanalogy presenting first evaluation storylevel analogy identification generation interestingly find analogy identification task incredibly difficult sentence embedding model also recent large language model llm chatgpt llama chatgpt example achieved around accuracy multiplechoice question compared accuracy human furthermore observe data storyanalogy improve quality analogy generation llm finetuned flantxxl model achieves comparable performance zeroshot chatgpt
biomedical named entity often play important role many biomedical text mining tool however due incompleteness provided synonym numerous variation surface form normalization biomedical entity challenging paper focus learning representation biomedical entity solely based synonym entity learn incomplete synonym use modelbased candidate selection maximize marginal likelihood synonym present top candidate modelbased candidate iteratively updated contain difficult negative sample model evolves way avoid explicit preselection negative sample k candidate four biomedical entity normalization datasets three different entity type disease chemical adverse reaction model biosyn consistently outperforms previous stateoftheart model almost reaching upper bound dataset
describe parser english effectuated biologically plausible neuron synapsis implemented assembly calculus recently proposed computational framework cognitive function demonstrate device capable correctly parsing reasonably nontrivial sentence experiment entail rather simple sentence english result suggest parser extended beyond implemented several direction encompassing much language example present simple russian version parser discus handle recursion embedding polysemy
several study demonstrated language model user attribute personality built using facebook language social medium user conjunction response psychology questionnaire challenging apply model make general prediction attribute community personality distribution across u county requires potentially inavailability original training data privacy ethical regulation adapting facebook language model twitter language without retraining model adapting user countylevel collection tweet propose twostep algorithm target side domain adaptation tsda domain adaptation labeled twittercounty data available tsda corrects different word distribution facebook twitter varying word distribution across county adjusting target side word frequency change trained model made case predicting big five countylevel personality trait tsda outperforms stateoftheart domain adaptation method give countylevel prediction fewer extreme outlier higher yeartoyear stability higher correlation countylevel outcome
sarcasm form figurative language intended meaning sentence differs literal meaning pose serious challenge several natural language processing nlp application sentiment analysis opinion mining author profiling paper present participating system intended sarcasm detection task english arabic language system consists three deep learningbased model leveraging two existing pretrained language model arabic english participated subtasks official submission achieve best performance subtask arabic language rank second subtask b subtask c system ranked th th arabic english datasets respectively
tabletotext generation widely studied natural language processing community recent year give new perspective problem incorporating signal table well associated image generate relevant text table contain structured list fact image rich source unstructured visual information example tourism domain image used infer knowledge type landmark eg church architecture eg ancient roman composition eg white marble therefore paper introduce novel task visionaugmented tabletotext generation vistot defined follows given table associated image produce descriptive sentence conditioned multimodal input task present novel multimodal tabletotext dataset wikilandmarks covering unique world landmark also present competitive architecture namely vt generates accurate sentence conditioned image table pair extensive analysis experiment show visual cue image helpful inferring missing information incomplete sparse table ii strengthening importance useful information noisy table natural language generation make code data publicly available
present metagrammatical formalism textitgeneric rule give default interpretation grammar rule formalism introduces process textitdynamic binding interfacing level pure grammatical knowledge representation parsing level present approach nonconstituent coordination within categorial grammar reformulate generic rule reformulation contextfree parsable reduces drastically search space associated parsing task phenomenon
word embeddings recently imposed standard representing word meaning nlp semantic similarity word pair become common evaluation benchmark representation vector cosine typically used similarity metric paper report experiment rankbased metric performs comparably vector cosine similarity estimation outperforms recentlyintroduced challenging task outlier detection thus suggesting rankbased measure improve clustering quality
deep neural network huge language model becoming omnipresent natural language application known requiring large amount training data growing body work improve performance lowresource setting motivated recent fundamental change towards neural model popular pretrain finetune paradigm survey promising approach lowresource natural language processing discussion different dimension data availability give structured overview method enable learning training data sparse includes mechanism create additional labeled data like data augmentation distant supervision well transfer learning setting reduce need target supervision goal survey explain method differ requirement understanding essential choosing technique suited specific lowresource setting key aspect work highlight open issue outline promising direction future research
recently number usergenerated recipe internet increased recipe user generally supposed write title ingredient list step create dish however item ingredient list usergenerated recipe actually edible ingredient example heading comment kitchenware sometimes appear ingredient list user freely write list recipe noise make difficult computer use recipe variety task calorie estimation address issue propose noningredient detection method inspired neural sequence tagging model experiment annotated ingredient usergenerated recipe showed proposed method achieved f score
taskoriented dialogue tod system aim build dialogue system assist user accomplishing specific goal booking hotel restaurant traditional tod rely domainspecific apisdbs external factual knowledge generate response accommodate subjective user request egis wifi reliable restaurant good atmosphere address issue propose novel task subjectiveknowledgebased tod sktod also propose first corresponding dataset contains subjective knowledgeseeking dialogue context manually annotated response grounded subjective knowledge source evaluated existing tod approach find task pose new challenge aggregating diverse opinion multiple knowledge snippet hope task dataset promote research tod subjective content understanding code dataset available httpsgithubcomalexadstctrack
grounding natural language inference code vice versa researcher aim create programming assistant explain work coachable surface gap reasoning deduce automatically interesting property program syntax commonsense annotation alone without resorting static analysis much program logic behaviour captured natural language stimulate research direction attempt answer question propose htl dataset protocol annotating program natural language predicate finer granularity code comment without relying internal compiler representation dataset available following address httpsdoiorgzenodo
paper explore strategy detect evaluate counterfactual sentence describe system semeval task modeling causal reasoning language detecting counterfactuals use bert base model classification task build hybrid bert multilayer perceptron system handle sequence identification task experiment show introducing syntactic semantic feature little improving system classification task using type feature cascaded linear input finetune sequencedelimiting ability model ensures outperforms similarpurpose complex system like bilstmcrf second task system achieves f score task task
compositional generalisation cg nlp machine learning generally assessed mostly using artificial datasets important develop benchmark assess cg also realworld natural language task order understand ability limitation system deployed wild end genbench collaborative benchmarking task submission utilises distributionbased compositionality assessment dbca framework split europarl translation corpus training test set way test set requires compositional generalisation capacity specifically training test set divergent distribution dependency relation testing nmt system capability translating dependency trained fullyautomated procedure create natural language compositionality benchmark making simple inexpensive apply datasets language code data experiment available httpsgithubcomaaltospeechdbca
people understand produce language incrementally word word basis give rise many characteristic conversational phenomenon including long midsentence pause followed incremental clarification request icrs intended recover rest truncated turn see fig b c ability generate icrs important natural conversational ai system crucial accessibility user memory impairment paper collect release analyse sluicecr large corpus human produced icrs use corpus probe incremental processing capability number state art llm evaluating quality model generated icrs response incomplete question evaluation show ability generate contextually appropriate icrs emerges larger llm size prompted example icrs corpus also indicate autoregressive lm principle able understand generate language incrementally
large language model llm recently made significant stride complex reasoning task chainofthought technique despite progress reasoning often constrained intrinsic understanding lacking external insight address propose exchangeofthought eot novel framework enables crossmodel communication problemsolving drawing inspiration network topology eot integrates four unique communication paradigm memory report relay debate paper delf communication dynamic volume associated paradigm counterbalance risk incorrect reasoning chain implement robust confidence evaluation mechanism within communication experiment across diverse complex reasoning task demonstrate eot significantly surpasses established baseline underscoring value external insight enhancing llm performance furthermore show eot achieves superior result costeffective manner marking promising advancement efficient collaborative ai problemsolving
sentencelevel extractive summarization disproportionate ratio selected unselected sentence leading flatting summary feature maximizing accuracy imbalanced classification summarization inherent cant addressed common algorithm easily paper conceptualize singledocument extractive summarization rebalance problem present deep differential amplifier framework specifically first calculate amplify semantic difference sentence sentence apply residual unit second item differential amplifier deepen architecture finally compensate imbalance corresponding objective loss minority class boosted weighted crossentropy contrast previous approach model pay attention pivotal information one sentence instead informative context modeling recurrent transformer architecture demonstrate experimentally two benchmark datasets summarizer performs competitively stateoftheart method source code available github
many datasets contain personally identifiable information pii pose privacy risk individual pii masking commonly used redact personal information name address phone number text data modern pii masking pipeline involve machine learning algorithm however system may vary performance individual particular demographic group bear higher risk personal information exposed paper evaluate performance three offtheshelf pii masking system name detection redaction generate data using name template customer service domain find opensource robertabased system show fewer disparity commercial model test however system demonstrate significant difference error rate based demographic particular highest error rate occurred name associated black asianpacific islander individual
paper present turk bootstrap word sense inventory twsi lexical resource created crowdsourcing process using amazon mechanical turk urlhttpwwwmturkcom encompasses sense inventory lexical substitution highly frequent english common noun along sense large number senseannotated occurrence context given well weighted list substitution sense distinction motivated lexicographic consideration driven substitutability two usage belong sense substitution overlap considerably laying need resource data characterized term organization quantity briefly describe data used create system lexical substitution training supervised lexical substitution system smaller version resource resulted well acceptability lexical substitution provided system thus resource used set reliable enabling technology semantic natural language processing nlp discus briefly
present effective recipe train strong longcontext llm capable utilizing massive context window token model built continual pretraining llama checkpoint longer text sequence dataset long text upsampled perform extensive evaluation using language modeling synthetic context probing task wide range downstream benchmark across evaluation model achieve consistent improvement regularcontext task significant improvement longcontext task llama moreover costeffective instruction tuning procedure free expensive annotation presented model already surpass textttgptturboks overall performance longcontext benchmark alongside result provide indepth analysis individual component method delve llama position encoding discus key limitation modeling long data examine impact various design choice pretraining process including data mix training curriculum sequence length ablation result suggest abundant long text pretrain dataset textitnot key achieving strong performance empirically verify long context continual pretraining efficient similarly effective compared pretraining scratch long sequence
paper describes system submitted semeval task presupposed taxonomy evaluating neural network semantics zamparelli et al participated binary classification regression subtask target sentence classified according taxonomical relation subtask according acceptability judgment subtask approach subtasks based neural network bert model used separate model three language covered task english french italian second subtask used median averaging construct ensemble model ranked th group subtask fscore th group subtask rho
crystallization modeling method around transformer architecture boon practitioner simple wellmotivated architectural variation transfer across task scale increasing impact modeling research however emergence stateoftheart b parameter model large language model increasingly expensive accurately design train notably difficult evaluate modeling decision may impact emergent capability given capability arise mainly sheer scale alonein process building bloomthe big science large openscience openaccess multilingual language modelour goal identify architecture training setup make best use agpuhours budgetspecifically perform ablation study billionparameter scale comparing different modeling practice impact zeroshot generalizationin addition study impact various popular pretraining corpus zeroshot generalization also study performance multilingual model compare englishonly one finally consider scaling behaviour transformer choose target model size shape training setup model code opensourced httpshuggingfacecobigscience
paper present methodology outcome named entity recognition linking multilingual news benchmark leverage deep learning approach using finetuned transformer model detect mention person location organisation text linguistic linked open data use wikidata disambiguate mention link ontology entry show advantage combining approach building benchmark also finetuning detection model also insist several perspective research improve accuracy combining system go leveraging complementary approach
biomedical ner active research area today despite availability stateoftheart model standard ner task performance degrades biomedical data due oov entity challenge encountered specialized domain use flairner framework investigate effectiveness various contextual static embeddings ner spanish tweet particular capture complex disease mention
medical provider summary patient visit serf several critical purpose including clinical decisionmaking facilitating handoff provider reference patient effective summary required coherent accurately capture medically relevant information dialogue despite complexity patientgenerated language even minor inaccuracy visit summary example summarizing patient fever fever present detrimental outcome care patient paper tackle problem medical conversation summarization discretizing task several smaller dialogueunderstanding task sequentially built upon first identify medical entity affirmation within conversation serve building block study dynamically constructing fewshot prompt task conditioning relevant patient information use gpt backbone experiment also develop gptderived summarization metric measure performance reference summary quantitatively human evaluation study metric medical correctness show summary generated using approach clinically accurate outperform baseline approach summarizing dialog zeroshot singleprompt setting
present four kind machine translation system description ek english korean ke korean english jk japanese korean kj korean japanese among ek kj translation system published commercially system finished development paper describes structure function system figure translation result
entity linking semantic parsing shown crucial important application question answering document understanding task often require structured learning model make prediction multiple interdependent variable talk argue carefully designed structured learning algorithm play central role entity linking semantic parsing task particular present several new structured learning model entity linking jointly detect mention disambiguate entity well capture nontextual information show use staged search procedure building stateoftheart knowledge base question answering system finally time permit discus different supervision protocol training semantic parser value labeling semantic parses
texttosql parser map natural language question program executable table generate answer typically evaluated largescale datasets like spider yu et al argue existing benchmark fail capture certain outofdomain generalization problem significant practical importance matching domain specific phrase composite operation column study problem first propose synthetic dataset along repurposed traintest split squall dataset shi et al new benchmark quantify domain generalization column operation find existing stateoftheart parser struggle benchmark propose address problem incorporating prior domain knowledge preprocessing table schema design method consists two component schema expansion schema pruning method easily applied multiple existing base parser show significantly outperforms baseline parser domain generalization problem boosting underlying parser overall performance relative accuracy gain absolute new squall data split
paper introduces adaptor library transpose traditional modelcentric approach composed pretraining finetuning step objectivecentric approach composing training process application selected objective survey research direction benefit enhanced objectivecentric experimentation multitask training custom objective development dynamic training curriculum domain adaptation adaptor aim ease reproducibility research direction practice finally demonstrate practical applicability adaptor selected unsupervised domain adaptation scenario
present first attempt predicting quality translation produced human professional translator examine datasets annotated quality sentence wordlevel four language pair provide experiment prediction model datasets compare performance model model built machine translation highlighting number challenge estimating quality detecting error human translation
previous research shown learning multiple representation polysemous word improve performance word embeddings many task however lead another problem several vector word may actually point meaning namely pseudo multisense paper introduce concept pseudo multisense propose algorithm detect case consideration detected pseudo multisense case try refine existing word embeddings eliminate influence pseudo multisense moreover apply algorithm previous released multisense word embeddings tested artificial word similarity task analogy task result experiment show diminishing pseudo multisense improve quality word representation thus method actually efficient way reduce linguistic complexity
advance variational inference enable parameterisation probabilistic model deep neural network combine statistical transparency probabilistic modelling framework representational power deep learning yet due problem known posterior collapse difficult estimate model context language modelling effectively concentrate one model variational autoencoder argue important building block hierarchical probabilistic model language paper contributes sober view problem survey technique address novel technique extension model establish ranking technique perform systematic comparison using bayesian optimisation find many technique perform reasonably similar given enough resource still favourite named based convenience also make several empirical observation recommendation best practice help researcher interested exciting field
development fund essential finance climate change adaptation thus important part international climate policy ever absence common reporting practice make difficult assess amount distribution fund research questioned credibility reported figure indicating adaptation financing fact lower published figure suggest project claiming greater relevance climate change adaptation target referred overreported estimate realistic rate overreporting large data set time propose approach based stateoftheart text classification date assessment credibility relied small manually evaluated sample use sample data set train classifier accuracy mboxpm tenfold crossvalidation extrapolate larger data set identify overreporting additionally propose method incorporates evidence smaller higherquality data correct predicted rate using bayes theorem enables comparison different annotation scheme estimate degree overreporting climate change adaptation result support finding indicate extensive overreporting credible interval
paper present construction textbackslashemphderywator language tool recognition polish derivational relation built basis machine learning way following bootstrapping approach limited set derivational pair described manually linguist plwordnet used train textbackslashemphderivator tool intended applied semiautomated expansion plwordnet new instance derivational relation training process based construction two transducer working opposite direction one prefix one suffix internal stem alternation recognised recorded form mapping sequence stored together transducer raw result produced textbackslashemphderivator undergo next corpusbased morphological filtering set derivational relation defined plwordnet presented result test different derivational relation discussed problem necessary corpusbased semantic filtering analysed presented tool depends little extent handcrafted knowledge particular language namely table possible alternation morphological filtering rule must exchanged take longer couple working day
wordlevel quality score input source sentence provide useful feedback enduser translating unfamiliar target language recent approach either require training special wordscoring model based synthetic data require repeated invocation translation model propose simple approach based comparing difference probability two language model basic premise method reason well source word explained target sentence source language model approach provides five point higher f score significantly faster state art method three language pair also method require training new model release public dataset word omission mistranslation new language pair
online topic modeling ie topic modeling stochastic variational inference powerful efficient technique analyzing large datasets adagrad widelyused technique tuning learning rate online gradient optimization however two technique work well together show adagrad us accumulation previous gradient learning rate denominator online topic modeling magnitude gradient large cause learning rate shrink quickly parameter fully converge training end
name implies contextualized representation language typically motivated ability encode context aspect context captured representation introduce approach address question using representational similarity analysis rsa case study investigate degree verb embedding encodes verb subject pronoun embedding encodes pronoun antecedent fullsentence representation encodes sentence head word determined dependency parse case show berts contextualized embeddings reflect linguistic dependency studied bert encodes dependency greater degree encodes less linguisticallysalient control result demonstrate ability approach adjudicate hypothesis aspect context encoded representation language
paper present humanreadable resource mapping identifier various clinical knowledge base resource version umls metathesaurus enriched wordnet synset wikidata item clinical identifier snomed ct icd mapping spanish icd code description main goal presented resource provide semantic interoperability across clinical concept various knowledge base facilitate integration mapping tool side effect mapping enriches already annotated medical corpus entity recognition entity linking task new label experiment entity linking task using corpus annotated manually mapping method demonstrate semiautomatic way annotation may used create new label resource available english spanish although language umls may extracted new lexical resource publicly available
paper report reimplementation system detecting implicit positive meaning negated statement original regression experiment different positive interpretation per negation scored according likelihood convert score class report result regression classification task show baseline taking mean score frequent class hard beat class imbalance dataset error analysis indicates approach take information structure account ie information new contrastive may promising requires looking beyond syntactic semantic characteristic negated statement
paper study different way combining character wordlevel representation affect quality final word sentence representation provide strong empirical evidence modeling character improves learned representation word sentence level particularly useful representing less frequent word show featurewise sigmoid gating mechanism robust method creating representation encode semantic similarity performed reasonably well several word similarity datasets finally finding suggest properly capturing semantic similarity word level consistently yield improved performance downstream sentencelevel task
investigate impact using author context textual sarcasm detection define author context embedded representation historical post twitter suggest neural model extract representation experiment two tweet datasets one labelled manually sarcasm via tagbased distant supervision achieve stateoftheart performance second dataset one labelled manually indicating difference intended sarcasm captured distant supervision perceived sarcasm captured manual labelling
previous study introduced weaklysupervised paradigm solving math word problem requiring answer value annotation method search correct value equation candidate pseudo label search among narrow subspace enormous equation space address problem propose novel search algorithm combinatorial strategy comsearch compress search space excluding mathematically equivalent equation compression allows searching algorithm enumerate possible equation obtain highquality data investigate noise pseudo label hold wrong mathematical logic refer falsematching problem propose ranking model denoise pseudo label approach hold flexible framework utilize two existing supervised math word problem solver train pseudo label achieve stateoftheart performance weak supervision task
shared task accept challenge constructing model identify twitter user attempted suicide based tweet day adverse event occurrence explore multiple machine learning deep learning method identify person suicide risk based shortterm history tweet taking reallife applicability model account make design choice classifying tweet level voting tweetlevel suicide risk score ensemble classifier predict suicidal user day event truepositives rate meanwhile tweetlevel voting fall short sixmonthlong data number tweet weak suicidal ideation level weakens overall suicidal signal long term
endtoend model trained natural language inference nli datasets show low generalization outofdistribution evaluation set model tend learn shallow heuristic due dataset bias performance decrease dramatically diagnostic set measuring compositionality robustness simple heuristic existing solution problem employ dataset augmentation drawback applicable limited set adversary worst hurting model performance adversary included augmentation set instead proposed solution improve sentence understanding hence outofdistribution generalization joint learning explicit semantics show bert based model trained jointly english semantic role labeling srl nli achieves significantly higher performance external evaluation set measuring generalization performance
paper describe annotation compara currently largest postedited parallel corpus include portuguese describe motivation result far way corpus annotated also provide first grounded result syntactical ambiguity portuguese finally discus interesting problem connection
expansion social role nowadays fact due ability user interact discus exchange idea opinion form social network though social medium user online social environment play variety social role concept social role long used social science describe intersection behavioural meaningful structural attribute emerge regularly particular setting paper present new corpus social role online contentious discussion explore various behavioural attribute stubbornness sensibility influence ignorance create model social role distinguish among various social role participant assume setup annotate discussion drawn two different set corpus order ensure model social role signal hold general discus various criterion deciding value behavioural attribute define role
paper investigate importance social network information compared content information prediction twitter user occupational class show content information user tweet profile description user followerfollowing community user social network provide useful information classifying user occupational group study extend existing data set problem achieve significantly better performance using social network homophily fully exploited previous work analysis found using graph convolutional network exploit social homophily achieve competitive performance data set small fraction training data
evaluating factual consistency automatically generated summary essential progress adoption reliable summarization system despite recent advance existing factuality evaluation model robust especially prone entity relation error new domain propose factkba simple new approach factuality evaluation generalizable across domain particular respect entity relation factkb based language model pretrained using fact extracted external knowledge base introduce three type complementary factuality pretraining objective based entityspecific fact fact extracted auxiliary knowledge entity fact constructed compositionally knowledge base walk resulting factuality evaluation model achieves stateoftheart performance two indomain news summarization benchmark well three outofdomain scientific literature datasets analysis factkb show improved ability detect erroneous entity relation summary robust easily generalizable across domain
n paper investigate potential answer clustering semiautomatic scoring short answer question german foreign language use surface feature like word character ngrams cluster answer listening comprehension exercise per question simulate human grader label one answer per cluster propagating label member cluster investigate various way select single item labeled find choosing item closest centroid cluster lead improved simulated grading accuracy random item selection averaged question reduce teacher workload labeling different answer question still maintaining grading accuracy
image captioning multimodal problem drawn extensive attention natural language processing computer vision community paper present novel image captioning architecture better explore semantics available caption leverage enhance image representation caption generation model first construct captionguided visual relationship graph introduce beneficial inductive bias using weakly supervised multiinstance learning representation enhanced neighbouring contextual node textual visual feature generation model incorporates visual relationship using multitask learning jointly predicting word objectpredicate tag sequence perform extensive experiment mscoco dataset showing proposed framework significantly outperforms baseline resulting stateoftheart performance wide range evaluation metric code paper made publicly available
present corpus child childdirected speech european portuguese corpus result expansion already existing database santos includes around hour childadult interaction contains child utterance adult utterance corpus transcribed according childes system child language data exchange system using clan software macwhinney corpus represents valuable resource study lexical syntax discourse acquisition paper also show used existing partofspeech tagger trained written material genereux hendrickx mendes automatically lemmatize tag child childdirected speech generate line partofspeech information compatible clan interface show postagger trained analysis written language exploited treatment spoken material minimal effort small number written rule assisting statistical model
generating long form narrative story procedure multiple modality long standing dream artificial intelligence regard often crucial subtext derived surrounding context general seqseq training method render model shorthanded attempting bridge gap neighbouring context paper tackle problem using infilling technique involving prediction missing step narrative generating textual description sequence image also present new large scale visual procedure telling vipt dataset total procedure around k pairwise image textual description rich contextual dependency generating step using infilling technique demonstrates effectiveness visual procedure coherent text conclusively show meteor score procedure higher stateoftheart visual storytelling also demonstrate effect interposing new text missing image inference code dataset publicly available urlhttpsvisualnarrativesgithubiovisualnarratives
within natural language processing community english far resourcerich language emerging interest conducting translation via computational approach conform dialect creole language back standard english computational approach pave way leverage generic english language backbone beneficial various downstream task however practical online communication scenario use language variety often accompanied noisy usergenerated content making translation task challenging work introduce joint paraphrasing task creole translation text normalization singlish message shed light process language variety dialect formulate task three different linguistic dimension lexical level normalization syntactic level editing semantic level rewriting build annotated dataset singlishtostandard english message report performance perturbationresilient sequencetosequence model experimental result show model produce reasonable generation result improve performance downstream task like stance detection
many machine learningbased lowcode nocode application involve generating code interacts structured knowledge example one studied task area generating sql code natural language statement prior work show incorporating context information database schema table column name beneficial model performance task work present large pretraining dataset strategy learning representation text table sql code leverage entire context problem specifically build existing encoderdecoder architecture introducing multitask pretraining framework complement unique attribute diverse pretraining data work represents first study largescale pretraining encoderdecoder model interacting structured knowledge offer new stateoftheart foundation model texttosql generation validate approach experiment two sql task showing improvement existing method including percentage point improvement prior stateofthearts spider cosql
paper investigate mapping wordnet hyponymy relation feature vector aim model lexical knowledge way used input generic machinelearning model phrase entailment predictor propose two model first one leverage existing mapping word feature vector fasttext attempt classify vector within outside class second model fully supervised using solely wordnet ground truth map concept interval disjunction thereof first model approach quite attain state art performance second model achieve nearperfect accuracy
paper describes system proposed hulat research group universidad carlos iii de madrid ucm meaningcloud mc company solve fns shared task summarizing financial report present narrative extractive approach implement statistical model comprised different feature measure relevance sentence using combination statistical machine learning method key model performance accurate representation text since word embeddings used model trained summary training dataset therefore capture salient information report system code found urlhttpsgithubcomjaimebaldeonfns
paper introduce psychological approach collect humanspecific social knowledge text corpus using nlp technique often explicitly described shared among people call social knowledge focus social knowledge especially personality driving used language resource developed based psychological research method japanese personality dictionary word driving experience corpus sentence annotated behavior subjectivity using automatically extracted collocation personality descriptor drivingrelated behavior driving behavior subjectivity corpus sentence filtering obtained unique collocation evaluate collocation social knowledge designed four stepbystep crowdsourcing task resulted piece social knowledge include knowledge might difficult recall easy agree discus acquired social knowledge contribution implementation system
named entity recognition generally refers entity specific meaning unstructured text including name people place organization date time quantity proper noun word medical field may drug name organ name test item nutritional supplement etc purpose named entity recognition study search item unstructured input text study taking healthcare research purpose predicting named entity boundary category sentence based ten entity type explore multiple fundamental ner approach solve task include hidden markov model conditional random field random forest classifier bert prediction result significant fscore crf model achieved better result
despite advancement conversational ai language model encounter challenge handle diverse conversational task existing dialogue dataset collection often lack diversity comprehensiveness tackle issue introduce dialogstudio largest diverse collection dialogue datasets unified consistent format preserving original information collection encompasses data opendomain dialogue taskoriented dialogue natural language understanding conversational recommendation dialogue summarization knowledgegrounded dialogue making incredibly rich diverse resource dialogue research model trainingto enhance utility dialogstudio identify license dataset design external knowledge domainaware prompt selected dialogue facilitate instructionaware finetuning improve transparency support dataset taskbased research well language model pretraining datasets license code model associated dialogstudio made publicly accessible
propose framework modularize training neural language model use diverse form context eliminating need jointly train context withinsentence encoders approach contextual universal embeddings cue train lm one type contextual data adapts novel context type model consists pretrained neural sentence lm bertbased contextual encoder masked transfomer decoder estimate lm probability using sentenceinternal contextual evidence contextually annotated data unavailable model learns combine contextual sentenceinternal information using noisy oracle unigram embeddings proxy real context data introduced later used adapt small number parameter map contextual data decoder embedding space validate cue framework nytimes text corpus multiple metadata type lm perplexity lowered conditioning context bootstrapping contextual lm subset metadata training retains achievable gain training model initially proxy context retains perplexity gain adapting real context furthermore swap one type pretrained sentence lm another without retraining context encoders adapting decoder model overall obtain modular framework allows incremental scalable training contextenhanced lm
important assumption sociolinguistics cognitive psychology human being adjust language use interlocutor put simply often people talk write similar speech becomes accommodation often observed smallscale observational study experiment largescale longitudinal study systematically test whether accommodation occurs scarce use data large swedish online discussion forum show linguistic production user write subforum usually become similar time moreover result suggest trend tends stronger pair user actively interact pair interact data thus support accommodation hypothesis
semantic slot filling one major task spoken language understanding slu slot filling model trained precollected data crucial continually improve model deployment learn user new expression data amount grows becomes infeasible either store huge data repeatedly retrain model data fine tune model new data without forgetting old expression paper introduce novel progressive slot filling model progmodel progmodel consists novel context gate transfer previously learned knowledge small size expanded component meanwhile enables new component fast trained learn new data progmodel learns new knowledge using new data time meanwhile preserve previously learned expression experiment show progmodel need much less training time smaller model size outperform various model fine tuning competitor two benchmark datasets
conduct two experiment study effect context metaphor paraphrase aptness judgment first amt crowd source task speaker rank metaphorparaphrase candidate sentence pair short document context paraphrase aptness second train composite dnn predict human judgment first binary classifier mode gradient rating found mean human judgment dnns prediction adding document context compress aptness score towards center scale raising low outofcontext rating decreasing high outofcontext score offer provisional explanation compression effect
paper present system overview english hindi machineaided translation system named anglahindi betaversion made available internet free translation urlhttpanglahindiiitkacin anglahindi english hindi version anglabharti translation methodology developed author translation english indian language anglabharti pseudointerlingual rulebased translation methodology anglahindi besides using rulebases us examplebase statistic obtain acceptable accurate translation frequently encountered noun verb phrasals way limited hybridization rulebased examplebased approach incorporated
online abusive behavior affect million nlp community attempted mitigate problem developing technology detect abuse however current method largely focused narrow definition abuse detriment victim seek validation solution position paper argue community need make three substantive change expanding scope problem tackle subtle serious form abuse developing proactive technology counter inhibit abuse harm reframing effort within framework justice promote healthy community
several methodology recently proposed evaluate ability pretrained language model plms interpret negation article build gubelmann handschuh study modification plms prediction function polarity input english crucially test us selfcontained input ending masked position depending polarity verb input particular token either semantically ruled allowed masked position replicating gubelmann handschuh experiment uncovered flaw weaken conclusion drawn test thus propose improved version selfcontained neg test controlled systematic entirely based example forming minimal pair varying presence absence verbal negation english applying test roberta bert base large model show robertalarge show trend match expectation bertbase mostly insensitive negation tested model though significant number test instance top prediction remains token semantically forbidden context show much room improvement remains proper treatment negation phenomenon
paper describes system submission fact extraction verification fever shared task system us heuristicsbased approach evidence extraction modified version inference model parikh et al classification process broken three module potentially relevant document gathered based key phrase claim possible evidence sentence inside document extracted finally classifier discard evidence deemed irrelevant us remaining classify claim veracity system beat shared task baseline successful finding correct evidence evidence retrieval f development set
propose work novel acoustic phonetic study arabic people suffering language disability nonnative learner arabic language classify arabic continuous speech pathological healthy identify phoneme pose pronunciation problem case pathological speech main idea summarized comparing phonetic model reference arabic spoken language proper concerned speaker task use technique automatic speech processing like forced alignment artificial neural network ann basheer based test corpus containing speech sequence recorded different speaker healthypathological speech nativeforeign speaker attain classification rate algorithm used identifying phoneme pose pronunciation problem show high efficiency attain identification rate
dialport project urlhttpdialportorg funded national science foundation nsf cover group tool service aim fulfilling need dialog research community course six year several offering created including dialport portal dialcrowd paper describes contribution demoed sigdial including implementation prior study corresponding discovery location tool remain freely available community going forward
paper describes submission team department computational linguistics university zurich sigmorphon shared task morpheme segmentation inflection generation submission use characterlevel neural transducer operates traditional edit action model found particularly wellsuited lowresource setting using large data quantity difficult existing implementation could fully profit gpu acceleration efficiently implement minibatch training could tricky transitionbased system year submission ported neural transducer pytorch implemented true minibatch training allowed u successfully scale approach large data quantity conduct extensive experimentation report competitive result morpheme segmentation including sharing first place part challenge also demonstrate reducing sentencelevel morpheme segmentation wordlevel problem simple yet effective strategy additionally report strong result inflection generation overall best result large training set part best result lowresource learning trajectory part code publicly available
present paper us speech technology derived tool methodology test theory phonetic typology specifically look twoway laryngeal contrast voiced b g v z v voiceless p k f obstruent implemented european portuguese language suggested exhibit different voicing system sister romance language similar one found germanic language large european portuguese corpus force aligned using different combination parallel portuguese original italian romance language german germanic language acoustic phone model letting asr system choose best fitting one pronunciation variant b g v z produced either b g v z p k f obstruent consonant result support previous account literature european portuguese diverging traditional voicing system known romance language towards hybrid system stop fricative specified different voicing feature
podcasts shown recent rise popularity summarization podcasts practical benefit content provider consumer help people quickly decide whether listen podcast andor reduces cognitive load content provider write summary nevertheless podcast summarization face significant challenge including factual inconsistency summary respect input problem exacerbated speech disfluency recognition error transcript spoken language paper explore novel abstractive summarization method alleviate issue approach learns produce abstractive summary grounding summary segment specific region transcript allow full inspection summary detail conduct series analysis proposed approach large podcast dataset show approach achieve promising result grounded summary bring clear benefit locating summary transcript segment contain inconsistent information hence improve summarization quality term automatic human evaluation
transformerbased model achieved stateoftheart performance shortinput summarization however still struggle summarizing longer text paper present dyle novel dynamic latent extraction approach abstractive longinput summarization dyle jointly train extractor generator treat extracted text snippet latent variable allowing dynamic snippetlevel attention weight decoding provide adequate supervision propose simple yet effective heuristic oracle extraction well consistency loss term encourages extractor approximate averaged dynamic weight predicted generator evaluate method different longdocument longdialogue summarization task govreport qmsum arxiv experiment result show dyle outperforms existing method govreport qmsum gain rouge yielding strong result arxiv analysis show proposed dynamic weight provide interpretability generation process
contemporary debate filter bubble polarization public social medium raise question extent news medium past exhibited bias paper specifically examines bias related gender six dutch national newspaper measure bias related gender comparing local change word embedding model trained newspaper divergent ideological background demonstrate clear difference gender bias change within newspaper time relation theme sexuality leisure see bias moving toward woman whereas generally bias shift direction men despite growing female employment number feminist movement even though dutch society became less stratified ideologically depillarization found increasing divergence gender bias religious socialdemocratic one hand liberal newspaper methodologically paper illustrates word embeddings used examine historical language change future work investigate finetuning deep contextualized embedding model elmo might used similar task greater contextual information
recent year witnessed great progress different task natural language understanding using machine learning question answering one task used search engine social medium platform improved user experience arabic language holy quran sacred text billion people across world arabic challenging language natural language processing nlp due complex structure article describe attempt osact quran qa shared task question answering challenge holy quran arabic propose ensemble learning model based arabic variant bert model addition perform postprocessing enhance model prediction system achieves partial reciprocal rank prr score official test set
paradigm pretraining followed finetuning become standard procedure nlp task known problem domain shift pretraining downstream corpus previous work tried mitigate problem additional pretraining either downstream corpus large enough manually curated unlabeled corpus similar domain paper address problem case downstream corpus small additional pretraining propose tadpole task adapted pretraining framework based data selection technique adapted textitdomain adaptation formulate data selection anomaly detection problem unlike existing method work well downstream corpus limited size result scalable efficient unsupervised technique eliminates need manual data curation evaluate framework eight task across four different domain biomedical computer science news movie review compare performance competitive baseline technique area domain adaptation framework outperforms baseline method small datasets less k training example get gain performance additional pretraining step compared originally pretrained model also compliment technique data augmentation known boosting performance downstream corpus small highest performance achieved data augmentation combined task adapted pretraining
largescale pretraining taskspecific fine tuning standard methodology many task computer vision natural language processing recently multitude method proposed pretraining vision language berts tackle challenge intersection two key area ai model categorized either singlestream dualstream encoders study difference two category show unified single theoretical framework conduct controlled experiment discern empirical difference five vision language berts experiment show training data hyperparameters responsible difference reported result also reveal embedding layer play crucial role massive model
social medium platform grow volume hate speech negative sentiment expressed towards particular social group paper describe approach semeval task involving detection classification online sexism abuse directed towards woman finegrained categorisation intended facilitate development nuanced understanding ideology process online sexism expressed experiment several approach involving language model finetuning classspecific adapter pseudolabelling bestperforming model involve training adapter specific subtask category combined via fusion layer using weighted loss function addition performing naive pseudolabelling large quantity unlabelled data successfully outperform baseline model subtasks placing th task rd task band th task c
challenging yet relevant task automated essay scoring aes continuously gain attention multiple discipline year advent pretrained large language model bert finetuning model become dominant technique various natural language processing nlp task several study finetune bert aes task utilize final pooled output last layer berts multilayer architecture encodes hierarchical linguistic information believe improve overall essay scoring performance leveraging information intermediate layer study diverge canonical finetuning paradigm exploring different combination model output single multilayer pooling strategy well architecture modification taskspecific component model using hybrid pooling strategy experimental result show best essay representa tion combined simple architectural modification outperforms average qwk score basic finetuned bert default output asap aes dataset suggesting effectiveness aes task potentially longtext task
video content social medium platform constitutes major part communication people allows everyone share story however someone unable consume video either due disability network bandwidth severely limit participation communication automatically telling story using multisentence description video would allow bridging gap learn evaluate model introduce videostory new largescale dataset video description new challenge multisentence video description videostory caption dataset complementary prior work contains k video posted publicly social medium platform amounting hour video k sentence temporally aligned video
fake news detection challenging problem due tremendous realworld political social impact recent fake news detection work focus learning news feature news propagation graph npg however little attention paid issue authenticity relationship topology imbalance structure npg trick existing method thus lead incorrect prediction result tackle issue paper propose novel topology imbalance relation inauthenticity aware hierarchical graph attention network trhgan identify fake news social medium specifically design new topology imbalance smoothing strategy measure topology weight node besides adopt hierarchicallevel attention mechanism graph convolutional learning adaptively identify authenticity relationship assigning appropriate weight experiment realworld datasets demonstrate trhgan significantly outperforms stateoftheart method
present nonautoregressive system submission wmt efficient translation shared task system used helcl et al attempt provide fair comparison nonautoregressive autoregressive model submission effort establish solid baseline along sound evaluation methodology particularly term measuring decoding speed model layer transformer model trained connectionist temporal classification knowledgedistilled dataset strong autoregressive teacher model
research paper delf adversarial robustness evaluation chinese gaokao reading comprehension gcrc advrobust chinese reading comprehension task havegained significant attention recent year previous method proven effective thischallenging dataset focus exploring prompt engineering impact model reading comprehension ability experiment using chatglm gpt gpt wediscovered correlation prompt llm reading comprehension ability found thatprompt engineering improves performance model team submitted result ofour system evaluation ranked first three index total score keywords llm prompt chinese reading comprehension
multilingual language model mbert seen impressive crosslingual transfer variety language many language remain excluded model paper analyse effect pretraining monolingual data lowresource language included mbert maltese range pretraining set ups conduct evaluation newly pretrained model three morphosyntactic task dependency parsing partofspeech tagging namedentity recognition one semantic classification task sentiment analysis also present newly created corpus maltese determine effect pretraining data size domain downstream performance result show using mixture pretraining domain often superior using wikipedia text also find fraction corpus enough make significant leap performance wikipediatrained model pretrain compare two model new corpus monolingual bert model trained scratch bertu pretrained multilingual bert mbertu model achieve stateoftheart performance task despite new corpus considerably smaller typically used corpus highresourced language average bertu outperforms performs competitively mbertu largest gain observed higherlevel task
realworld impact polarization toxicity online sphere marked end beginning year negative way semeval task toxic span detection based novel annotation subset jigsaw unintended bias dataset first language toxicity detection task dedicated identifying toxicitylevel span task participant automatically detect character span short comment render message toxic model considers applying virtual adversarial training semisupervised setting finetuning process several transformerbased model ie bert roberta combination conditional random field approach lead performance improvement robust model enabling u achieve fscore official submission fscore tuning postevaluation
paper describes notre dame natural language processing group ndnlp submission wngt shared task hayashi et al investigated impact autosizing murray chiang murray et al transformer network vaswani et al goal substantially reducing number parameter model method able eliminate model parameter suffering decrease bleu
neural network common tool nlp always clear architecture use given task different task different language different training condition affect neural network perform capsule network capsnets relatively new architecture nlp due novelty capsnets used nlp task however usefulness still mostly untested paper compare three neural network architectureslstm cnn capsneton part speech tagging task compare architecture high lowresource training condition find architecture consistently performs best analysis show capsnet performs nearly well complex lstm certain training condition others capsnet almost always outperforms cnn also find capsnet implementation show faster prediction time lstm scottish gaelic spanish highlighting effect choice language model
american sign language asl well signed language different class sign eg lexical sign fingerspelled sign classifier construction different internal structural property continuous sign recognition accuracy improved use distinct recognition strategy well different training datasets class sign strategy applied continuous signing video need segmented part corresponding particular class sign paper present multiple instance learningbased segmentation system accurately label video frame continuous utterance including different subject publicly accessible ncslgr corpus neidle vogler system us novel feature descriptor derived motion shape statistic region high local motion system require hand tracker
emergence social medium made difficult recognize analyze misinformation effort popular messaging software telegram developed medium disseminating political message misinformation particularly light conflict ukraine paper introduce sizable corpus telegram post containing prorussian propaganda benign political text evaluate corpus applying natural language processing nlp technique task text classification corpus finding indicate overall accuracy confirmed source propagandist opposition unconfirmed source method successfully identify categorize pro russian propaganda post highlight consequence research comprehending political communication propaganda social medium
chinese idiom cheng yu seen five thousand year history culture china meanwhile contain large number scientific achievement ancient china however existing chinese online idiom dictionary limited function scientific exploration paper first construct chinese idiom knowledge graph extracting domain dynasty associating idiom based idiom knowledge graph propose science toolkit ancient china stac aiming support scientific exploration stac toolkit idiom navigator help user explore overall scientific progress idiom perspective visualization tool idiom card idiom qa shorten action path avoid thinking interrupted user reading writing current stac toolkit deployed httpdemostac
comparis rolling mt program locale limited support outofthebox language pair limited support customization leading online company switzerland content go swiss standard german dech frch itch enuk even best generic mt engine perform poorly many dont even offer customization language pair without english would result unusable raw mt high pe effort needed custom machine translation reasonable cost sustainable effort evaluated selfserve machine translation machine translation quality estimation tool like modelfront integration option translation management system tmses using new tool existing asset tm custom mt new ai tool launched successful inhouse mt program productivity gain iterative improvement also defined launched service tier light mtpe transcreation
semantic representation form directed acyclic graph dag introduced recent year model need probabilistic model dag one model attracted attention dag automaton studied probabilistic model show dag automaton made useful probabilistic model nearly universal strategy assigning weight transition problem affect singlerooted multirooted unboundeddegree variant dag automaton appears pervasive affect planar variant problematic reason
lateral thinking essential breaking away conventional thought pattern finding innovative solution problem despite language model often struggle reasoning task require lateral thinking paper present system semeval task brainteaser challenge requires language model answer brain teaser question typically involve lateral reasoning scenario framework based large language model incorporates zeroshot prompting method integrates conceptualization automatically detected instance question also transform task question answering declarative format enhance discriminatory ability large language model zeroshot evaluation result chatgpt indicate approach outperforms baseline including zeroshot fewshot prompting chainofthought reasoning additionally system rank ninth official leaderboard demonstrating strong performance
prepositional phrase pp attachment classical problem nlp language like english suffer structural ambiguity work solve problem help another language free ambiguity using parse tree parallel sentence language word alignment formulate optimization framework encourages agreement parse tree two language solve using novel dual decomposition dd based algorithm experiment englishhindi language pair show promising improvement baseline
ai becomes integral life need transparency responsibility grows natural language explanation nles vital clarifying reasoning behind ai decision evaluating human judgment complex resourceintensive due subjectivity need finegrained rating study explores alignment chatgpt human assessment across multiple scale ie binary ternary likert scale sample data instance three nle datasets collect human annotation informativeness clarity score text quality measurement conduct paired comparison experiment different range subjectivity score baseline come human annotation result show chatgpt aligns better human coarsegrained scale also paired comparison dynamic prompting ie providing semantically similar example prompt improve alignment research advance understanding large language model capability assess text explanation quality different configuration responsible ai development
without proper safeguard large language model readily follow malicious instruction generate toxic content risk motivates safety effort redteaming largescale feedback learning aim make model helpful harmless however tension two objective since harmlessness requires model refuse comply unsafe prompt thus helpful recent anecdotal evidence suggests model may struck poor balance even clearly safe prompt refused use similar language unsafe prompt mention sensitive topic paper introduce new test suite called xstest identify exaggerated safety behaviour systematic way xstest comprises safe prompt across ten prompt type wellcalibrated model refuse comply unsafe prompt contrast model application refuse describe xstests creation composition use test suite highlight systematic failure mode stateoftheart language model well general challenge building safer language model
describe university edinburgh bengalileftrightarrowhindi constrained system submitted wmt news translation task submitted ensemble transformer model built largescale backtranslation finetuned subset training data retrieved based similarity target domain
lowresource machine translation lrmt pose substantial challenge due scarcity parallel training data paper introduces new method improve transfer embedding layer parent model child model lrmt utilizing trained token embeddings parent model highresource vocabulary approach involves projecting token shared semantic space measuring semantic similarity token lowresource highresource language measure utilized initialize token representation child model lowresource vocabulary evaluated approach three benchmark datasets lowresource language pair myanmarenglish indonesianenglish turkishenglish experimental result demonstrate method outperforms previous method regarding translation quality additionally approach computationally efficient leading reduced training time compared prior work
paper experimentally compare two automatic evaluator red bleu determine close evaluation result automatic evaluator average evaluation result human evaluator following atr standard mt evaluation paper give several cautionary remark intended prevent mt developer drawing misleading conclusion using automatic evaluator addition paper report way using automatic evaluator result agree human evaluator
paper describes system semeval task hyperpartisan news detection build existing deep learning approach sentence classification based convolutional neural network modifying original model additional layer increase expressiveness finally building ensemble multiple version model obtain accuracy f score main test dataset also report additional experiment incorporating handcrafted feature cnn using feature extractor linear svm
paper derives integer linear programming ilp formulation obtain oracle summary compressive summarization paradigm term rouge oracle summary essential reveal upper bound performance paradigm experimental result duc dataset showed rouge score compressive oracle significantly higher extractive oracle stateoftheart summarization system result reveal compressive summarization promising paradigm encourage u continue research produce informative summary
implicit discourse relation classification great challenge due lack connective strong linguistic cue motivates use annotated implicit connective improve recognition propose feature imitation framework implicit relation network driven learn another neural network access connective thus encouraged extract similarly salient feature accurate classification develop adversarial model enable adaptive imitation scheme competition implicit network rival feature discriminator method effectively transfer discriminability connective implicit feature achieves stateoftheart performance pdtb benchmark
paper present dilton system solves simple arithmetic word problem dilton us deep neural based model solve math word problem dilton divide question two part worldstate query worldstate query processed separately two different network finally network merged predict final operation report first deep learning approach prediction operation two number dilton learns predict operation accuracy corpus primary school question
present fincausal shared task causality detection financial document associated fincausal dataset discus participating system result two subtasks proposed binary classification task task relation extraction task task total team submitted run across two task contributed system description paper workshop associated joint workshop financial narrative processing multiling financial summarisation fnpfns held th international conference computational linguistics coling barcelona spain september
develop computational model discover potential cause depression analysing topic usergenerated text show prominent cause cause evolve time also highlight difference cause student low high neuroticism study demonstrate topic reveal valuable clue cause contributing depressed mood identifying cause significant impact improving quality depression care thereby providing greater insight patient state pertinent treatment recommendation hence study significantly expands ability discover potential factor trigger depression making possible increase efficiency depression treatment
work define task teaser generation provide evaluation benchmark baseline system process generating teaser teaser short reading suggestion article illustrative includes curiosityarousing element entice potential reader read particular news item teaser one main vehicle transmitting news social medium user compile novel dataset teaser systematically accumulating tweet selecting conform teaser definition compared number neural abstractive architecture task teaser generation overall best performing system see et al seqseq pointer network
much research done texttoimage synthesis little work done explore usage linguistic structure input text information even important story visualization since input explicit narrative structure need translated image sequence visual story prior work domain shown ample room improvement generated image sequence term visual quality consistency relevance paper first explore use constituency parse tree using transformerbased recurrent architecture encoding structured input second augment structured input commonsense information study impact external knowledge generation visual story third also incorporate visual structure via bounding box dense captioning provide feedback charactersobjects generated image within dual learning setup show offtheshelf densecaptioning model trained visual genome improve spatial structure image different target domain without needing finetuning train model endtoend using intrastory contrastive loss word image subregions show significant improvement visual quality finally provide analysis linguistic visuospatial information
many recent study shown model trained datasets natural language inference nli possible make correct prediction merely looking hypothesis completely ignoring premise work manage derive adversarial example term hypothesisonly bias explore eligible way mitigate bias specifically extract various phrase hypothesis artificial pattern training set show strong indicator specific label figure hard easy instance original test set whose label opposite consistent indication also set baseline including pretrained model bert roberta xlnet competitive nonpretrained model infersent dam esim apart benchmark baseline also investigate two debiasing approach exploit artificial pattern modeling mitigate hypothesisonly bias downsampling adversarial training believe method treated competitive baseline nli debiasing task
paper describes system resolver submitted conll shared task crossframework meaning representation parsing mrp system implement transitionbased parser directed acyclic graph dag tree preprocessor novel crossframework variablearity resolve action generalizes five different representation although ranked low competition shown current limitation potential including variablearity action mrp concluded direction improvement future
extractive method proven effective automatic document summarization previous work perform task identifying informative content sentence level however unclear whether performing extraction sentence level best solution work show unnecessity redundancy issue exist extracting full sentence extracting subsentential unit promising alternative specifically propose extracting subsentential unit based constituency parsing tree neural extractive model leverage subsentential information extract presented extensive experiment analysis show extracting subsentential unit performs competitively comparing full sentence extraction evaluation automatic human evaluation hopefully work could provide inspiration basic extraction unit extractive summarization future research
natural language understanding nlu natural language generation nlg task hold strong dual relationship nlu aim predicting semantic label based natural language utterance nlg opposite prior work mainly focused exploiting duality model training order obtain model better performance however regarding fastgrowing scale model current nlp area sometimes may difficulty retraining whole nlu nlg model better address issue paper proposes leverage duality inference stage without need retraining experiment three benchmark datasets demonstrate effectiveness proposed method nlu nlg providing great potential practical usage
process knowledge acquisition viewed questionanswer game student teacher student typically start asking broad openended question drilling specific hintikka hakkarainen sintonen pedagogical perspective motivates new way representing document paper present squash specificitycontrolled questionanswer hierarchy novel challenging text generation task convert input document hierarchy questionanswer pair user click highlevel question eg frodo leave fellowship reveal related specific question eg frodo leave using question taxonomy loosely based lehnert classify question existing reading comprehension datasets either general specific use label input pipelined system centered around conditional neural language model extensively evaluate quality generated qa hierarchy crowdsourced experiment report strong empirical result
task chinese text spam detection challenging due glyph phonetic variation chinese character paper proposes novel framework jointly model chinese variational semantic contextualized representation chinese text spam detection task particular variation familyenhanced graph embedding vfge algorithm designed based chinese character variation graph vfge learn graph embeddings chinese character local latent variation family global furthermore enhanced bidirectional language model combination gate function aggregation learning function proposed integrate graph text information capturing sequential information extensive experiment conducted sm review datasets show proposed method outperforms series stateoftheart model chinese spam detection
although proper handling discourse significantly contributes quality machine translation mt improvement adequately measured common translation quality metric recent work contextaware mt attempt target small set discourse phenomenon evaluation however fully systematic way paper develop multilingual discourseaware muda benchmark series tagger identify evaluate model performance discourse phenomenon given dataset choice phenomenon inspired novel methodology systematically identify translation require context methodology confirms difficulty previously studied phenomenon uncovering others previously addressed find commonly studied contextaware mt model make marginal improvement contextagnostic model suggests model handle ambiguity effectively release code data language pair encourage mt community focus accurately capturing discourse phenomenon code available urlhttpsgithubcomneulabcontextualmt
studying data memorization neural language model help u understand risk eg privacy copyright associated model regurgitating training data aid development countermeasure many prior worksand recently deployed defensesfocus verbatim memorization defined model generation exactly match substring training set argue verbatim memorization definition restrictive fail capture subtle form memorization specifically design implement efficient defense perfectly prevents verbatim memorization yet demonstrate perfect filter prevent leakage training data indeed easily circumvented plausible minimally modified styletransfer promptsand case even nonmodified original promptsto extract memorized information conclude discussing potential alternative definition defining memorization difficult yet crucial open question neural language model
present novel combination dynamic embedded topic model changepoint detection explore diachronic change lexical semantic modality classical early christian latin demonstrate several method finding characterizing pattern output relating traditional scholarship comparative literature classic simple approach unsupervised model semantic change applied suitable corpus conclude future direction refinement aiming allow noisier lesscurated material meet threshold
wctanalyze tool storing accessing visually analyzing huge collection temporally indexed data motivated application medium analysis business intelligence etc higher level analysis performed top linguistically statistically processed unstructured textual data wctanalyze combine fast access economically storage behaviour appropriates lot built visualization option result presentation detail well contrast enables efficient effective way explore chronological text pattern word form cooccurrence set cooccurrence set intersection digging deep cooccurrences semantic syntactic describing wordforms entity recognized temporal related whereas differ significantly behaviour motivates approach interactive discovering event based cooccurrence subset
paper focus learning structureaware document representation data without recourse discourse parser additional annotation drawing inspiration recent effort empower neural network structural bias cheng et al kim et al propose model encode document automatically inducing rich structural dependency specifically embed differentiable nonprojective parsing algorithm neural model use attention mechanism incorporate structural bias experimental evaluation across different task datasets show proposed model achieves stateoftheart result document modeling task inducing intermediate structure interpretable meaningful
spoken language understanding slu extract intended mean ing user utterance critical component conversational virtual agent enterprise virtual agent evas language understanding substantially challenging first user infrequent caller unfamiliar expectation predesigned conversation flow second user paying customer enterprise demand reliable consistent efficient user experience resolving issue work describe general robust framework intent entity extraction utilizing hybrid statistical rulebased approach framework includes confidence modeling incorporates information component slu pipeline critical addition evas en sure accuracy focus creating accurate scalable slu deployed rapidly large class eva application little need human intervention
recent entity relation extraction work focus investigating obtain better span representation pretrained encoder however major limitation existing work ignore interrelation span pair work propose novel span representation approach named packed levitated marker plmarker consider interrelation span pair strategically packing marker encoder particular propose neighborhoodoriented packing strategy considers neighbor span integrally better model entity boundary information furthermore complicated span pair classification task design subjectoriented packing strategy pack subject object model interrelation samesubject span pair experimental result show enhanced marker feature model advance baseline six ner benchmark obtains strict relation f improvement higher speed previous stateoftheart model ace ace code model publicly available urlhttpsgithubcomthunlpplmarker
automatic sql generation active research area aiming streamlining access database writing natural language given intent instead writing sql current sota method semantic parsing depend llm achieve high predictive accuracy benchmark datasets reduces applicability since llm requires expensive gpus furthermore sota method ungrounded thus guaranteed always generate valid sql propose tql new sql generation method improves performance benchmark datasets using smaller lm namely tbase pp compared sota method additionally tql guaranteed always output valid sql using contextfree grammar constrain sql generation finally show dividing semantic parsing two task candidate sqls generation candidate reranking promising research avenue reduce need large lm
crossdomain ner practical yet challenging problem since data scarcity realworld scenario common practice first learn ner model richresource general domain adapt model specific domain due mismatch problem entity type across domain wide knowledge general domain effectively transfer target domain ner model end model label relationship probability distribution construct label graph source target label space enhance contextual representation label structure fuse label graph word embedding output bert representing label relationship graph formulate crossdomain ner graph matching problem furthermore proposed method good applicability pretraining method potentially capable crossdomain prediction task empirical result four datasets show method outperforms series transfer learning multitask learning fewshot learning method
rise social medium exponentially witnessed use clickbait post grab user attention although work done detect clickbait post first task focused generating appropriate spoiler potential clickbaits paper present approach direction use different encoding technique capture context post text target paragraph propose hierarchical encoding count document length featurebased model spoiler type classification us recurrence pretrained encoding also propose combining multiple ranking reciprocal rank fusion passage spoiler retrieval questionanswering approach phrase spoiler retrieval multipart spoiler retrieval combine two spoiler retrieval method experimental result benchmark suggest proposed spoiler retrieval method able retrieve spoiler semantically close ground truth spoiler
paper describes pizzapal voiceonly agent ordering pizza well conversational ai architecture built bai based principle highdensity conversational ai support natural flexible interaction neural conversational language understanding robust dialog state tracking hierarchical task decomposition
social determinant health sdoh documented electronic health record unstructured text increasingly studied understand sdoh impact patient health outcome work utilize social history annotation corpus shac multiinstitutional corpus deidentified social history section annotated sdoh including substance use employment living status information explore automatic extraction sdoh information shac standoff inline annotation format using gpt oneshot prompting setting compare gpt extraction performance highperforming supervised approach perform thorough error analysis promptbased gpt method achieved overall f shac test set similar th bestperforming system among team nc challenge shac
neural sequencetosequence model successfully extended summary generation however existing framework generate single summary given input tune summary towards additional constraintspreferences tunable framework desirable account linguistic preference specific audience consume summary paper propose neural framework generate summary constrained vocabularydefined linguistic preference target audience proposed method account generation context tuning summary word time generation evaluation indicate proposed approach tune summary target vocabulary still maintaining superior summary quality stateoftheart word embedding based lexical substitution algorithm suggesting feasibility proposed approach demonstrate two application proposed approach generate understandable summary simpler word readable summary shorter word
data model encoding format syntactically annotated text corpus need deal syntactic ambiguity underspecified representation particularly well suited representation ambiguous data allow high informational efficiency discus issue informationally efficient tradeoff efficient encoding linguistic annotation complete documentation linguistic analysis main topic article data model encoding scheme based lafgraf ide romary ide suderman provides flexible framework encoding underspecified representation show set dependency structure set tiger graph brant et al representing reading ambiguous sentence encoded discus basic issue querying corpus encoded using framework presented
propose interpretable model score subjective bias present document based textual content model trained pair revision wikipedia article one version biased although prior approach based bias classification struggled obtain high accuracy task able develop useful model scoring bias learning accurately perform pairwise comparison show interpret parameter trained model discover word indicative bias also apply model three different setting studying temporal evolution bias wikipedia article comparing news source based bias scoring bias law amendment case demonstrate output model explained validated even two domain outside trainingdata domain also use model compare general level bias domain see legal text least biased news medium biased wikipedia article
study usefulness hateful metaphorsas feature identification type target hate speech dutch facebook comment purpose hateful metaphor dutch lilah corpus annotated interpreted line conceptual metaphor theory critical metaphor analysis provide svm bertroberta result investigate effect different metaphor information encoding method hate speech type target detection accuracy result conducted experiment show hateful metaphor feature improve model performance task knowledge first time effectiveness hateful metaphor information source hatespeech classification investigated
model pretrained selfsupervised objective large text corpus achieve stateoftheart performance english text summarization task however model typically finetuned hundred thousand data point infeasible requirement applying summarization new niche domain work introduce novel generalizable method called wikitransfer finetuning pretrained model summarization unsupervised datasetspecific manner wikitransfer finetunes pretrained model pseudosummaries produced generic wikipedia data contain characteristic target dataset length level abstraction desired summary wikitransfer model achieve stateoftheart zeroshot abstractive summarization performance cnndailymail dataset demonstrate effectiveness approach three additional diverse datasets model robust noisy data also achieve better comparable fewshot performance using training example compared fewshot transfer summarization datasets boost performance employ data augmentation via roundtrip translation well introduce regularization term improved fewshot transfer understand role dataset aspect transfer performance quality resulting output summary study effect component unsupervised finetuning data analyze fewshot performance using automatic human evaluation
morphological inflection low resource language critical augment existing corpus low resource language help develop several application language good social impact describe attentionbased encoderdecoder approach implement using lstms transformer base unit also describe ancillary technique experimented hallucination language vector injection sparsemax loss adversarial language network alongside approach select related language training present result generated constrained well unconstrained sigmorphon dataset citation one primary goal paper study contribution varied component described towards performance system perform analysis
paper present proposed method isarcasmeval shared task shared task consists three different subtasks participate subtask subtask c purpose subtask predict text sarcastic aim subtask c determine text sarcastic given sarcastic text nonsarcastic rephrase developed solution used bert pretrained model proposed model optimized simple objective easy grasp however despite simplicity method ranked isarcasmeval subtask subtask c arabic text
consider two problem nmt domain adaptation using metalearning first want reach domain robustness ie want reach high quality domain seen training data unseen domain second want system adaptive ie making possible finetune system hundred indomain parallel sentence study domain adaptability metalearning improving domain robustness model paper propose novel approach rmlnmt robust metalearning framework neural machine translation domain adaptation improves robustness existing metalearning model specifically show use domain classifier curriculum learning integrate wordlevel domain mixing model metalearning framework balanced sampling strategy experiment englishgerman englishchinese translation show rmlnmt improves term domain robustness domain adaptability seen unseen domain
introduce kilogram resource studying abstract visual reasoning human machine drawing history tangram puzzle stimulus cognitive science build richly annotated dataset textgreaterk distinct stimulus order magnitude larger diverse prior resource visually linguistically richer moving beyond whole shape description include segmentation map part label use resource evaluate abstract visual reasoning capacity recent multimodal model observe pretrained weight demonstrate limited abstract reasoning dramatically improves finetuning also observe explicitly describing part aid abstract reasoning human model especially jointly encoding linguistic visual input
article present method combining different information retrieval model order increase retrieval performance speech information retrieval task formula combining model tuned training data system evaluated test data task particularly difficult text collection automatically transcribed spontaneous speech many recognition error also topic real information need difficult satisfy information retrieval system able obtain good result data set except case manual summary included
adversarial example perturbation input model elicit large change output shown effective way assessing robustness sequencetosequence seqseq model however perturbation indicate weakness model change input significantly legitimately result change expected output fact largely ignored evaluation growing body related literature using example untargeted attack machine translation mt propose new evaluation framework adversarial attack seqseq model take semantic equivalence pre postperturbation input account using framework demonstrate existing method may preserve meaning general breaking aforementioned assumption source side perturbation result change expected output use framework demonstrate adding additional constraint attack allows adversarial perturbation meaningpreserving nonetheless largely change output sequence finally show performing untargeted adversarial training meaningpreserving attack beneficial model term adversarial robustness without hurting test performance toolkit implementing evaluation framework released urlhttpsgithubcompmichelteapotnlp
automatic text simplification aim reduce linguistic complexity text order make easier understand accessible however simplified text consumed diverse array target audience might appropriately simplified one group reader may differ considerably another work investigate novel formulation sentence simplification paraphrasing controlled decoding approach aim alleviate major burden relying large amount indomain parallel training data time allowing modular adaptive simplification according automatic metric approach performs competitively baseline prove difficult adapt need different target audience require significant amount complexsimple parallel aligned data
present quantitative qualitative comparison discourse tree defined rhetorical structure theory question discussion model based empirical analysis parallel annotation text blog post podcast transcript conclude discourse framework capture similar structural information qualitative analysis show complex discourse unit often match analysis qud structure indicate centrality segment
effort leverage deep learning model lowresource regime led numerous augmentation study however direct application method mixup cutout limited due discrete characteristic textual data method using pre trained language model exhibited good efficiency require additional consideration robustness inspired recent study decision boundary paper proposes decisionboundaryaware data augmentation strategy enhance robustness using pretrained language model proposed technique first focus shifting latent feature closer decision boundary followed reconstruction generate ambiguous version soft label additionally midk sampling suggested enhance diversity generated sentence paper demonstrates performance proposed augmentation strategy compared method extensive experiment furthermore ablation study demonstrates effect soft label midk sampling extensibility method curriculum data augmentation
paper present bidirectional transformer based approach recognising semantic relationship pair word proposed cogalex vi shared task system presented work employing bert embeddings word passing tuned neural network produce learning model pair word relationship afterwards model used relationship unknown word test set cogalex vi provided subtask identification relationship three specific category amongst english pair word presented system opts work resulted relationship unknown word analysed show balanced performance overall characteristic scope improvement
morphological analysis fundamental task natural language processing result beapplied different downstream task named entity recognition syntactic analysis andmachine translation however many problem morphological analysis lowaccuracy caused lack resource paper alleviate lack resource uyghurmorphological analysis research construct uyghur morphological analysis corpus based onthe analysis grammatical feature format general morphological analysis corpus define morphological tag dimension feature manually annotate correctthe dataset finally corpus provided information word lemma part speech morphological analysis tag morphological segmentation lemmatization also paperanalyzes basic feature corpus use model datasets provided bysigmorphon shared task organizer design comparative experiment verify corpussavailability result experiment respectively corpus provides areference value morphological analysis promotes research uyghur natural language processing
paper present participation bacteria biotope task bionlp shared task participation includes two system two subtasks bacteria biotope task normalization entity bbnorm identification relation entity given biomedical text bbrel normalization entity utilized word embeddings syntactic reranking relation extraction task predefined rule used although approach unsupervised sense need labeled data achieved promising result especially bbnorm task result shown proposed method performs good deep learning based method require labeled data
previous work syntactically controlled paraphrase generation heavily rely largescale parallel paraphrase data easily available many language domain paper take research direction extreme investigate whether possible learn syntactically controlled paraphrase generation nonparallel data propose syntacticallyinformed unsupervised paraphrasing model based conditional variational autoencoder vae generate text specified syntactic structure particularly design twostage learning method effectively train model using nonparallel data conditional vae trained reconstruct input sentence according given input syntactic structure furthermore improve syntactic controllability semantic consistency pretrained conditional vae finetune using syntax controlling cycle reconstruction learning objective employ gumbelsoftmax combine new learning objective experiment result demonstrate proposed model trained nonparallel data capable generating diverse paraphrase specified syntactic structure additionally validate effectiveness method generating syntactically adversarial example sentiment analysis task
surge llm evaluation research understand llm capability limitation however much research confined english leaving llm building evaluation nonenglish language relatively unexplored several new llm introduced recently necessitating evaluation nonenglish language study aim perform thorough evaluation nonenglish capability sota llm gptturbo gpt palm geminipro mistral llama gemma comparing set multilingual datasets benchmark comprises datasets covering language including lowresource african language also include two multimodal datasets benchmark compare performance llava model gptvision geminiprovision experiment show larger model gpt geminipro palm outperform smaller model various task notably lowresource language gpt outperforming palm geminipro datasets also perform study data contamination find several model likely contaminated multilingual evaluation benchmark necessitating approach detect handle contamination assessing multilingual performance llm
paper discusses development partofspeech tagger te reo maori indigenous language aotearoa also known new zealand te reo maori particularly analytical polysemic language word class called particle introduced small multifunctional word many meaning example e ai noa rawa mai ano koa particle reflective analytical polysemous nature te reo maori frequently occur singularly also multiword expression including time adverbial phrase paper illustrates challenge presented partofspeech tagging also discusses overcome challenge way appropriate te reo maori given status indigenous language history colonisation includes discussion importance accurately reflecting conceptualization te reo maori involved making linguistic presumption eliciting faithful judgement speaker way uninfluenced linguistic terminology
transfer learning selective data training two many approach extensively investigated improve quality neural machine translation system paper present series experiment applying transfer learning selective data training participation biomedical shared task wmt used information retrieval selectively choose related sentence outofdomain data used additional training data using transfer learning also report effect tokenization translation model performance
paper describes submission task semeval safe biomedical natural language inference clinical trial multievidence natural language inference clinical trial data nlict consists textual entailment te task focused evaluation consistency faithfulness natural language inference nli model applied clinical trial report ctr test distinct approach one based finetuning ensembling masked language model based prompting large language model using template particular using chainofthought contrastive chainofthought prompting flantlarge shot setting lead best system achieves f score faithfulness consistency
paper describes objective concept methodology elexis european infrastructure fostering cooperation information exchange among lexicographical research community infrastructure newly granted project horizon infraia call topic integrating activity starting community project planned start january
tracking stateoftheart sota result machine learning study challenging due high publication volume existing method creating leaderboards scientific document require significant human supervision rely scarcely available latex source file propose table entity linker telin framework extract task model dataset metric quadruple collection scientific publication pdf format telin identifies scientific named entity construct knowledge base leverage human feedback iteratively refine automatic extraction telin identifies prioritizes uncertain impactful entity human review create cascade effect leaderboard completion show telin competitive sota requires much less human annotation
recent work raised concern risk spurious correlation unintended bias statistical machine learning model threaten model robustness fairness paper propose simple intuitive regularization approach integrate causal knowledge model training build robust fair model emphasizing causal feature deemphasizing spurious feature specifically first manually identify causal spurious feature principle inspired counterfactual framework causal inference propose regularization approach penalize causal spurious feature separately adjusting strength penalty type feature build predictive model relies causal feature less noncausal feature conduct experiment evaluate model robustness fairness three datasets multiple metric empirical result show new model built causal awareness significantly improve model robustness respect counterfactual text model fairness respect sensitive attribute
conversational agent used make diagnosis classify mental state promote health education provide emotional support benefit adopting conversational agent include widespread access increased treatment engagement improved patient relationship intervention propose framework assist chat operator mental healthcare service instead fully automated conversational agent design eas avoid adverse effect applying chatbots mental healthcare proposed framework capable improving quality reducing time interaction via chat user chat operator also present case study context health promotion reducing tobacco use proposed framework us artificial intelligence specifically natural language processing nlp technique classify message chat user list suggestion offered chat operator topic discussed session suggestion created based service protocol classification previous chat session operator also edit suggested message data collected used future improve quality suggestion offered
international conference coling dr guy rondeau workshop theoretical issue natural language processing tinlap bonnie nash webber roger schank summer school computational linguistics rocquencourt andreewsky summer school literary statistic cambridge england h alford international conference computer humanity robert dilligan rudolf hirschmann joseph raben donald ross todd k bender grace c hertlein nfais conference information interface ben h weil joseph coyne ann farren hood robert ieee conference computer reach people martin l rubin susan wittig kerry mark joel firschein r k summat ifip conference computer education international conference developing country dr h albayati veenhuis richard c atkinson nsf deputy director richard c atkinson nominated neh calendar grant application national program draft library information service research progress index thomisticus press roberto busa sj computer security afips acm publish guide robert l patrick
paper describes knowledgestore largescale infrastructure combined storage interlinking multimedia resource ontological knowledge information knowledgestore organized around entity person organization location system allows import background knowledge entity form annotated rdf triple ii associate resource entity automatically recognizing coreferring linking mention named entity iii derive new entity based knowledge extracted mention knowledgestore build state art technology language processing including document tagging named entity extraction crossdocument coreference design provides tight integration linguistic semantic feature eas processing information explicitly representing context knowledge mention valid relevant describe system report creation largescale knowledgestore instance storing integrating multimedia content background knowledge relevant italian trentino region
mexico spanish speaking country great language diversity linguistic group variety face lack representation education government public service medium present high level endangerment due lack data available social medium internet technology developed language analyze different linguistic phenomenon country language engineering group developed corpus paralelo de lenguas mexicanas cplm mexican language parallel corpus collaborative parallel corpus lowresourced language mexico cplm aligns spanish six indigenous language maya chol mazatec mixtec otomi nahuatl first paper describes process building cplm text searching digitalization alignment process furthermore present difficulty regarding dialectal orthographic variation second present interface type searching well use filter
several dialogue corpus currently available research purpose still fall short growing interest development dialogue system specific requirement order help requiring corpus paper survey range available option term aspect like speaker size language collection annotation domain trend identified possible approach creation new corpus also discussed
covid pandemic become trending topic twitter people interested sharing diverse information ranging new case healthcare guideline medicine vaccine news information assist people updated situation well beneficial public safety personnel decision making however informal nature twitter make challenging refine informative tweet huge tweet stream address challenge wnut introduced shared task focusing covid related informative tweet identification paper describe participation task propose neural model adopts strength transfer learning handcrafted feature unified architecture extract transfer learning feature utilize stateoftheart pretrained sentence embedding model bert roberta infersent whereas various twitter characteristic exploited extract handcrafted feature next various feature combination utilized train set multilayer perceptron mlp baseclassifier finally majority voting based fusion approach employed determine informative tweet approach achieved competitive performance outperformed baseline approx
narrative analysis becoming increasingly important number linguistic task including summarization knowledge extraction question answering present novel approach narrative event representation using attention recontextualize event across whole story comparing previous analysis find unexpected attachment event semantics predicate token within popular transformer model test utility approach narrative completion prediction achieving state art performance multiple choice narrative cloze scoring competitively story cloze task
icelandic gigaword corpus first published since new version published annually containing new text additional source well previous source paper describes evolution corpus first four year version made available permissive license new version text annotated latest accurate tool show corpus grown almost size first version fourth restructured order better accommodate different metadata different subcorpora furthermore service set facilitate usage corpus different use case include keywordincontext concordance tool ngram viewer word frequency database pretrained word embeddings
knowledge underpins reasoning recent research demonstrates relevant knowledge provided additional context commonsense question answering qa substantially enhance performance even top stateoftheart fundamental challenge find knowledge high quality point respect question knowledge retrieved knowledge base incomplete knowledge generated language model inconsistentwe present rainier reinforced knowledge introspector learns generate contextually relevant knowledge response given question approach start imitating knowledge generated gpt learns generate knowledge via reinforcement learning reward shaped based increased performance resulting question answering rainier demonstrates substantial consistent performance gain tested different commonsense benchmark including datasets seen model training well datasets kept unseen work first report knowledge generated model order magnitude smaller gpt even without direct supervision knowledge exceed quality commonsense knowledge elicited gpt
shortcut reasoning irrational process inference degrades robustness nlp model number previous work tackled identification shortcut reasoning still two major limitation method quantifying severity discovered shortcut reasoning provided ii certain type shortcut reasoning may missed address issue propose novel method identifying shortcut reasoning proposed method quantifies severity shortcut reasoning leveraging outofdistribution data make assumption type token triggering shortcut reasoning experiment natural language inference sentiment analysis demonstrate framework successfully discovers known unknown shortcut reasoning previous work
multimodal entity linking mel task mapping mention multimodal context referent entity knowledge base existing mel method mainly focus designing complex multimodal interaction mechanism require finetuning model parameter prohibitively costly difficult scale era large language model llm work propose gemel generative multimodal entity linking framework based llm directly generates target entity name keep vision language model frozen train feature mapper enable crossmodality interaction adapt llm mel task leverage incontext learning capability llm retrieving multimodal instance demonstration extensive experiment show model parameter finetuned gemel achieves stateoftheart result two wellestablished mel datasets accuracy gain wikidiverse accuracy gain wikimel performance gain stem mitigating popularity bias llm prediction disambiguating less common entity effectively analysis verifies generality scalability gemel framework compatible offtheshelf language model paving way towards efficient general solution utilizing llm mel task code available httpsgithubcomhitsztmggemel
event causality identification eci refers detection causal relation event text however existing study focus sentencelevel eci highresource language leaving challenging documentlevel eci deci lowresource language underexplored paper propose heterogeneous graph interaction model multigranularity contrastive transfer learning gimc zeroshot crosslingual documentlevel eci specifically introduce heterogeneous graph interaction network model longdistance dependency event scattered document improve crosslingual transferability causal knowledge learned source language propose multigranularity contrastive transfer learning module align causal representation across language extensive experiment show framework outperforms previous stateoftheart model average f score monolingual multilingual scenario respectively notably multilingual scenario zeroshot framework even exceeds gpt fewshot learning overall performance
understanding inference text requires merely recovering surface argument adjunct string associated query term human interpret sentence contextualized component narrative discourse filling missing information reasoning event consequence paper define process rewriting textual expression lexeme phrase reduces ambiguity also making explicit underlying semantics necessarily expressed economy sentence structure dense paraphrasing dp apply dp technique english procedural text cooking recipe domain provide scope design application involves creating graph representation event generating hidden argument paraphrasing provide insight dp process enrich source text showing denseparaphrased event graph good resource large llm gpt generate reliable paraphrase experimenting baseline automaticdp generation finally demonstrate utility dataset event graph structure providing case study outofdomain modeling different dp prompt gpt model paraphrasing
conventional topic model ineffective topic extraction microblog message data sparseness exhibited short message lacking structure context result poor messagelevel word cooccurrence pattern address issue organize microblog message conversation tree based reposting replying relation propose unsupervised model jointly learns word distribution represent different role conversational discourse various latent topic reflecting content information explicitly distinguishing probability message varying discourse role containing topical word model able discover cluster discourse word indicative topical content automatic evaluation largescale microblog corpus joint model yield topic better coherence score competitive topic model previous study qualitative analysis model output indicates model induces meaningful representation discourse topic present empirical study microblog summarization based output joint model result show jointly modeled discourse topic representation effectively indicate summaryworthy content microblog conversation
appropriate goal presentday linguistics development general theory relation language one necessary requirement development theory identification classification inflected form term morphosyntactic property set presumably related language according sapir language differ one another certain one differ far others slavic language might well said alike alike others similarity stemming common origin subsequent parallel development enable u group number less homogeneous type experimental comparative research georgetown university focused group four slavic language namely russian czech polish serbocroatian first step comparative procedure described morphosyntactic analysis four language individually analysis based complementary distribution inflectional morpheme property whose distribution must determined graphemic shape inflectional morpheme establishment distributional class subclass stem morpheme basis morphosyntactic function inflectional morpheme determined distributional subclass stem morpheme fxyl x distributional subclass stem morpheme constant given inflectional morpheme free variable basis preliminary analysis pattern absolute equivalence partial equivalence absolute difference established class inflected form language study accomplished result used order determine extent distributional equivalence among individual language applicability procedure tested class adjectivals within frame adjectivals following morphosyntactic property analyzed within language language category gender category animateness category case murder product comparative analysis set formation rule embody system identification inflected form detailed result presented additional report
present system time sensitive topic based summarisation sentiment around target entity topic collection tweet describe main element system illustrate functionality two example sentiment analysis topic related uk general election
multimodal machine translation attractive application neural machine translation nmt help computer deeply understand visual object relation natural language however multimodal nmt system suffer shortage available training data resulting poor performance translating rare word nmt pretrained word embeddings shown improve nmt lowresource domain searchbased approach proposed address rare word problem study effectively combine two approach context multimodal nmt explore take full advantage pretrained word embeddings better translate rare word report overall performance improvement meteor bleu achieve improvement fscore rare word translation
paper describes charles university submission terminology translation shared task wmt objective task design system translates certain term based provided terminology database preserving high overall translation quality competed englishfrench language pair approach based providing desired translation alongside input sentence training model use provided term lemmatize term training inference allow model learn produce correct surface form word differ form provided terminology database submission ranked second exact match metric evaluates ability model produce desired term translation
recently structural reading comprehension src task web page attracted increasing research interest although previous src work leveraged extra information html tag xpaths informative topology web page effectively exploited work propose topological information enhanced model tie transforms tokenlevel task taglevel task introducing twostage process ie node locating answer refining based tie integrates graph attention network gat pretrained language model plm leverage topological information logical structure spatial structure experimental result demonstrate model outperforms strong baseline achieves stateoftheart performance webbased src benchmark websrc time writing code tie publicly available urlhttpsgithubcomxlancetie
present summary effort improve conference peer review implemented acl includes work goal improving review quality clearer workflow decision support area chair well effort improve paperreviewer matching various kind non mainstream nlp work improve overall incentive participant peer review process present analysis factor affecting peer review identify problematic issue author complained provide suggestion future chair hope publishing report would improve transparency decisionmaking b help people new field understand acl conference work c provide useful data future chair workshop organizer also academic work peer review provide useful context final program source information metaresearch structure trajectory field nlp
framing political strategy politician carefully word statement order control public perception issue previous work exploring political framing typically analyze frame usage longer text congressional speech present collection weakly supervised model harness collective classification predict frame used political discourse microblogging platform twitter global probabilistic model show combining lexical feature tweet networkbased behavioral feature twitter able increase average unsupervised f score point lexical baseline alone
understanding text often requires identifying meaningful constituent span noun phrase verb phrase work show effectively recover type label using learned phrase vector deep insideoutside recursive autoencoders diora specifically cluster span representation induce span label additionally improve model labeling accuracy integrating latent code learning training procedure evaluate approach empirically unsupervised labeled constituency parsing method outperforms elmo bert two version wall street journal wsj dataset competitive prior work requires additional human annotation improving previous stateoftheart system depends groundtruth partofspeech tag absolute f point relative error reduction
present give corpus new corpus human instruction giving corpus collected asking one person pair subject guide person towards completing task virtual environment typed instruction setting recent give challenge thus corpus serve source data point comparison nlg system participate give challenge instructiongiving data collect multilingual german english dialogue easily extended language using software made available analyze corpus study effect learning repeated participation task effect participant spatial navigation ability finally present novel annotation scheme situated referring expression compare referring expression german english data
two sentence meaning follow equivalent inferential property ie sentence textually entail however many paraphrase datasets currently widespread use rely sense paraphrase based word overlap syntax teach instead identify paraphrase way draw inferential property sentence overreliant lexical syntactic similarity sentence pair apply adversarial paradigm question introduce new adversarial method dataset creation paraphrase identification adversarial paraphrasing task apt asks participant generate semantically equivalent sense mutually implicative lexically syntactically disparate paraphrase sentence pair used test paraphrase identification model get barely random accuracy improve performance accelerate dataset generation explore automation apt using show resulting dataset also improves accuracy discus implication paraphrase detection release dataset hope making paraphrase detection model better able detect sentencelevel meaning equivalence
recent study argue knowledge distillation promising speech translation st using endtoend model work investigate effect knowledge distillation cascade st using automatic speech recognition asr machine translation mt model distill knowledge teacher model based human transcript student model based erroneous transcription experimental result demonstrated knowledge distillation beneficial cascade st investigation combined knowledge distillation finetuning revealed combination consistently improved two language pair englishitalian spanishenglish
present annotated corpus german driving report analysis questionunderdiscussion qud based information structural distinction since quds hardly defined advance providing corresponding tagset several theoretical issue arise concerning scope quality corpus development appropriate annotation tool creating corpus developed corpus testing adequacy qudbased pragmatic framework information structure first analysis annotated information structure show focusrelated meaning aspect essentially confirmed indicating sufficent accuracy annotation assumption nonatissueness expressed nonrestrictive relative clause made literature seem strong given corpus data
sarcasm analysis user conversion text automatic detection irony insult hurting painful caustic humour vulgarity degrades individual helpful field sentimental analysis cyberbullying immense growth social medium sarcasm analysis help avoid insult hurt humour affect someone paper present traditional machine learning approach deep learning approach lstm rnn bert bidirectional encoder representation transformer identifying sarcasm used approach build model identify categorize much conversion context response needed sarcasm detection evaluated two social medium forum twitter conversation dataset reddit conversion dataset compare performance based approach obtained best f score twitter forum reddit forum respectively
need fast retrieval speed small memory footprint document hashing playing crucial role largescale information retrieval generate highquality hashing code semantics neighborhood information crucial however existing method leverage one simply combine via intuitive criterion lacking theoretical principle guide integration process paper encode neighborhood information graphinduced gaussian distribution propose integrate two type information graphdriven generative model deal complicated correlation among document propose treestructured approximation method learning approximation prove training objective decomposed term involving singleton pairwise document enabling model trained efficiently uncorrelated one extensive experimental result three benchmark datasets show method achieves superior performance stateoftheart method demonstrating effectiveness proposed model simultaneously preserving semantic neighborhood information
growing domain natural language processing lowresourced language like northern kurdish remain largely unexplored due lack resource needed part growth particular task partofspeech tagging tokenization northern kurdish still insufficiently addressed study aim bridge gap evaluating range statistical neural finetunedbased model specifically tailored northern kurdish leveraging limited valuable datasets including universal dependency kurmanji treebank novel manually annotated tokenized goldstandard dataset consisting sentence token evaluate several po tagging model report finetuned transformerbased model outperforms others achieving accuracy macroaveraged f score data model publicly available open license httpsgithubcompeshmergenorthernkurdishpostagging
principal pillar u blueprint ai bill right data privacy specifically individual protected abusive practice data collector data aggregator user control personal information collected used area spotlight need protection found common practice data broker scrape purchase process reassemble personal information bulk sell variety downstream us activity almost always occur absence user knowledge meaningful consent yet legal u law paper examines data broker operate provides example recent u regulatory action taken summarizes federal effort redress data broker practice concludes long continues comprehensive federal data protection privacy scheme effort control behavior limited effect paper also address limit informed consent use personal information language resource suggests solution holistic approach data protection privacy across datadevelopment life cycle
development african wordnet awn reached stage maturity first step towards application attempted awn based expand method compensate general resource scarceness african language various development strategy used aim paper investigate usefulness current isizulu wordnet application language learning advantage incorporating wordnet language language learning system provides learner integrated application enhance learning experience mean unique sense identification feature wordnet paper demonstrated mean variety example within context basic free online course isizulu wordnet offer language learner improved decision support
entailment tree structured reasoning path clearly demonstrates process deriving hypothesis multiple step inference known premise enhances interpretability qa system existing method generating entailment tree typically employ iterative framework ensure reasoning faithfulness however often suffer issue false feasible step selected step appear feasible actually lead incorrect intermediate conclusion moreover existing iterative framework consider errorprone search branch resulting error propagation work propose speh iterative entailment tree generation framework step feasibility perception state error handling mechanism step feasibility perception enables model learn choose step false feasible state error handling includes error detection backtracking allowing model correct error entering incorrect search branch experimental result demonstrate effectiveness approach improving generation entailment tree
raimy b proposed graphical formalism modeling reduplication originallymostly focused phonological overapplication derivational framework framework known precedencebased phonology multiprecedence phonology raimys idea segment input phonology totally ordered precedence paper tackle challenge arose raimys work development deterministic serialization algorithm part derivation surface form matchextend algorithm introduced requires fewer assumption stick tighter attested typology algorithm also contains parameter constraint specific individual graph topology unlike previous proposal matchextend requires nothing except knowing last added set link
paper present result participation bea shared task focus generating ai teacher response educational dialogue conducted experiment using several opensource large language model llm explored finetuning technique along prompting strategy including fewshot chainofthought approach best model ranked competition bertscore f dialogrpt final avg nevertheless internal result exactly correlate obtained competition showed difficulty evaluating task challenge faced data leakage train set irregular format conversation
data scarcity widespread problem numerous natural language processing nlp task within lowresource language within morphology labourintensive task taggingglossing data serious bottleneck nlp fieldwork active learning al aim reduce cost data annotation selecting data informative model paper explore four sampling strategy task morphological inflection using transformer model pair oracle experiment data chosen based correctincorrect prediction model model confidence entropy random selection investigate robustness sampling strategy across typologically diverse language well cycle iteration using natugu case study result show clear benefit selecting data based model confidence unsurprisingly oracle experiment presented proxy linguistlanguage informer feedback show improvement followed closely lowconfidence highentropy form also show despite conventional wisdom larger data set yielding better accuracy introducing instance highconfidence lowentropy form model already inflect correctly reduce model performance
metalearning emerged effective approach fewshot text classification however current study fail realize importance semantic interaction sentence feature neglect enhance generalization ability model new task paper integrate adversarial network architecture metalearning system leverage costeffective module build novel fewshot classification framework named saaml significantly approach exploit temporal convolutional network encourage discriminative representation learning explore attention mechanism promote comprehensive feature expression thus resulting better adaptation new class series experiment four benchmark datasets demonstrate new framework acquires considerable superiority stateoftheart method datasets increasing performance shot classification shot classification respectively
recent stateoftheart neural language model share representation word given input output mapping propose simple modification architecture decouples hidden state word embedding prediction architecture lead comparable better result compared previous tied model model without tying much smaller number parameter also extend proposal wordvec model showing tying appropriate general word prediction task
emotion recognition conversation erc essential dialogue system identify emotion expressed speaker although previous study made significant progress accurate recognition interpretation similar finegrained emotion properly accounting individual variability remains challenge one particular underexplored area role individual belief desire modelling emotion inspired beliefdesire theory emotion propose novel method conversational emotion recognition incorporates belief desire accurately identify emotion extract emotioneliciting event utterance construct graph represent belief desire conversation applying message passing node graph effectively model utterance context speaker global state interaction emotional belief desire utterance evaluate model performance conducting extensive experiment four popular erc datasets comparing multiple stateoftheart model experimental result demonstrate superiority proposed model validate effectiveness module model
moderating user comment promoting healthy understanding challenging task especially context polarized topic climate change propose moderation tool assist moderator promoting mutual understanding regard topic approach twofold first train classifier label incoming post argument entail specific focus minority argument apply active learning supplement training data rare argument second dive deeper singular argument extract lexical pattern distinguish argument others finding indicate climate change argument form clearly separable cluster embedding space class characterized unique lexical pattern provide quick insight argument key concept additionally supplementing training data necessary classifier able adequately recognize rare argument argue detailed rundown argument provides insight others coming computational approach part toolkit content moderator researcher struggling polarized topic
paper present deep learning code completion model r language introduce several technique utilize language modeling based architecture code completion task technique model requires low resource still achieves high quality also present evaluation dataset r language completion task dataset contains multiple autocompletion usage context provides robust validation result dataset publicly available
paper describes participation third sigmorphon shared task graphemetophoneme conversion lowresource crosslingual mccarthy et al model rely different sequence labelling method main model predicts multiple phoneme grapheme trained using ctc loss graf et al find sequence labelling method yield worse performance baseline enough data available still used little data available furthermore demonstrate alignment learned sequence labelling model easily inspected
cclff
data collection knowledge graphtotext generation expensive result research unsupervised model emerged active field recently however unsupervised model use nonparallel version existing small supervised datasets largely constrain potential paper propose largescale generaldomain dataset genwiki unsupervised dataset text graph example respectively humanannotated test set provide new benchmark dataset future research unsupervised text generation knowledge graph
discourse analysis important task model intrinsic semantic structure sentence document discourse marker natural representation discourse daily language one challenge marker well predefined humanlabeled discourse relation ambiguous describing semantics sentence believe better approach use contextualdependent distribution marker express discourse information work propose learn distributed marker representation dmr utilizing potentially unlimited discourse marker data latent discourse sense thereby bridging marker sentence pair representation learned automatically data without supervision turn provide insight data experiment show sota performance dmr implicit discourse relation recognition task strong interpretability method also offer valuable tool understand complex ambiguity entanglement among discourse marker manually defined discourse relation
product review may complex discourse including coreference bridging relation main product competing product interacting product current approach aspectbased sentiment analysis absa opinion summarization largely ignore complexity hand existing system coreference bridging trained different domain collect mention type annotation relevant coreference bridging product review using annotation show stateoftheart factuality score fails catch coreference error product review stateoftheart coreference system trained ontonotes perform nearly well product mention dataset grows expect help absa opinion summarization system avoid entity reference error
paper describe new development brought lre map especially term user interface web application searching information therein data model update
one fundamental goal artificial intelligence build computerbased expert system inferring clinical diagnosis generate clinical assessment patient encounter crucial step towards building medical diagnostic system previous work mainly based either medical domainspecific knowledge patient prior diagnosis clinical encounter paper propose novel model automated clinical assessment generation mcag mcag built innovative graph neural network rich clinical knowledge incorporated endtoend corpuslearning system evaluation result physician generated gold standard show mcag significantly improves bleu rouge score compared competitive baseline model physician evaluation showed mcag could generate highquality assessment
study aim improve highly effective speech enhancement technique demucs revising respective loss function learning demucs developed facebook team built waveunet consists convolutional layer encoding decoding block lstm layer although demucs process input speech utterance purely time wave domain applied loss function consists wavedomain l distance multiscale shorttimefouriertransform stft loss time frequencydomain feature taken consideration learning demucs study present revising stft loss demucs employing compressed magnitude spectrogram compression done either powerlaw operation positive exponent less one logarithmic operation evaluate presented novel framework voicebankdemand database task preliminary experimental result suggest demucs containing powerlaw compressed magnitude spectral loss outperforms original demucs providing test utterance higher objective quality intelligibility score pesq stoi relatively logarithm compressed magnitude spectral loss benefit demucs therefore reveal demucs improved properly revising stft term loss function
abstractive summarization typically relies large collection paired article summary however many case parallel data scarce costly obtain develop abstractive summarization system relies large collection example summary nonmatching article approach consists unsupervised sentence extractor selects salient sentence include final summary well sentence abstractor trained pseudoparallel synthetic data paraphrase extracted sentence perform extensive evaluation method cnndailymail benchmark compare approach fully supervised baseline well novel task automatically generating press release scientific journal article well suited system show promising performance task without relying articlesummary pair
project aimed extending test set mustc speech translation st corpus new reference translation new reference collected professional posteditors working output different st system three language pair englishgermanitalianspanish paper shortly describe data collected distributed evidence usefulness also summarise finding first comparative evaluation cascade direct st approach carried relying collected data project partially funded european association machine translation eamt sponsorship activity programme
paper framed context sshoc project aim exploring language technology help promoting facilitating multilingualism social science humanity ssh although ssh researcher produce culturally societally relevant work local language metadata vocabulary used ssh domain describe index research data currently mostly english thus investigate natural language processing machine translation approach view providing resource tool foster multilingual access discovery ssh content across different language case study create deliver freely openly available data set multilingual metadata concept automatically extracted multilingual data stewardship terminology two case study allow well evaluate performance stateoftheart tool derive set recommendation best apply although adapted specific domain employed tool prove valid asset translation task nonetheless validation result domain expert proficient language unavoidable phase whole workflow
bias mitigation approach reduce model dependence sensitive feature data social group token sgts resulting equal prediction across sensitive feature hate speech detection however equalizing model prediction may ignore important difference among targeted social group hate speech contain stereotypical language specific sgt take specific language sgt account rely counterfactual fairness equalize prediction among counterfactuals generated changing sgts method evaluates similarity sentence likelihood via pretrained language model among counterfactuals treat sgts equally within interchangeable context applying logit pairing equalize outcome restricted set counterfactuals instance improve fairness metric preserving model performance hate speech detection
covid pandemic caused international social tension unrest besides crisis growing sign rising conflict potential society around world indicator global mood change hard detect direct questionnaire suffer social desirability bias however socalled implicit method reveal human intrinsic desire eg social medium text present psychologically validated social unrest predictor replicate scalable automated prediction setting new state art recent german shared task dataset employ model investigate change language towards social unrest covid pandemic comparing established psychological predictor sample tweet spring spring result show significant increase conflict indicating psychometrics work demonstrate applicability automated nlpbased approach quantitative psychological research
paper describes submission upc machine translation group iwslt offline speech translation speechtospeech translation track offline task involves translating english speech german japanese chinese text speech translation system trained endtoend based large pretrained speech text model use efficient finetuning technique train specific layer system explore use adapter module nontrainable layer investigate suitability different speech encoders wavvec hubert model impact knowledge distillation machine translation model use decoder mbart segmenting iwslt test set finetune pretrained audio segmentation model achieve improvement bleu compared given segmentation best single model us hubert parallel adapter achieves bleu englishgerman mustc tstcommon iwslt test ensembling many model increase translation quality bleu accordingly furthermore submission englishjapanese achieves englishchinese obtains bleu mustc tstcommon set finally extend system perform englishgerman speechtospeech translation pretrained texttospeech model
investigate effect varying citation context window size model performance citation intent classification prior study limited application fixedsize contiguous citation context use manually curated citation context introduce new automated unsupervised approach selection dynamicsize potentially noncontiguous citation context utilises transformerbased document representation embedding similarity experiment show addition noncontiguous citing sentence improves performance beyond previous result evalu ating domainspecific aclarc multidisciplinary sdpact dataset demonstrates inclusion additional context beyond citing sentence significantly improves citation classifi cation model performance irrespective datasets domain release datasets source code used experiment urlhttpsgithubcomoacoredynamiccitationcontext
process learning using chinese many learner chinese foreign languagecfl may grammar error due negative migration native language paper introduces system simultaneously diagnose four type grammatical error including redundant r missing selection disorder w nlptea shared task proposed bidirectional lstm crf neural network bilstmcrf combine bilstm crf without handcraft feature chinese grammatical error diagnosis cged evaluation includes three level detection level identification level position level detection level identification level system got third recall score achieved good f value
pretrained characterlevel bytelevel language model shown competitive popular subword model across range natural language processing task however little research effectiveness neural machine translation nmt particularly within popular pretrainthenfinetune paradigm work performs extensive comparison across multiple language experimental condition character subwordlevel pretrained model byt mt respectively nmt show effectiveness characterlevel modeling translation particularly case finetuning data limited analysis show character model gain translation quality reflected better translation orthographically similar word rare word evaluating importance source text driving model prediction highlight wordlevel pattern within byt suggesting ability modulate wordlevel characterlevel information generation conclude assessing efficiency tradeoff byte model suggesting usage nontimecritical scenario boost translation quality
work address question localization syntactic information encoded transformer representation tackle question two perspective considering objectpast participle agreement french identifying first part sentence second part representation syntactic information encoded result experiment using probing causal analysis feature selection method show syntactic information encoded locally way consistent french grammar
lexically constrained machine translation allows user manipulate output sentence enforcing presence absence certain word phrase although current approach enforce term appear translation often struggle make constraint word form agree rest generated output manual analysis show error output baseline constrained model english czech translation related agreement investigate mechanism allow neural machine translation infer correct word inflection given lemmatized constraint particular focus method based training model constraint provided part input sequence experiment englishczech language pair show approach improves translation constrained term automatic manual evaluation reducing error agreement approach thus eliminates inflection error without introducing new error decreasing overall quality translation
topicsensitive query set expansion important area research aim improve search result information retrieval particularly crucial query related sensitive emerging topic work describe method query set expansion emerging topic using vector space interpolation use transformer model called optimus suitable vector space manipulation due variational autoencoder nature one proposed method dirichlet interpolation show promising result query expansion method effectively generate new query sensitive topic incorporating setlevel diversity captured traditional sentencelevel augmentation method paraphrasing backtranslation
paper describes submission text complexity de challenge mohtaj et al evaluate pairwise regression model predicts relative difference complexity two sentence instead predicting complexity score single sentence consequence model return sample score many training sentence instead point estimate due error submission test set result unavailable however show crossvalidation pairwise regression improve performance standard regression model using sentence embeddings taken pretrained language model input furthermore find distribution standard deviation reflect difference uncertainty model prediction useful way
recent study shown subjective annotation task demographic lived experience identity annotator large impact item labeled expand work hypothesizing gender may correlate difference annotation number nlp benchmark including fairly subjective eg affect text typically considered objective eg natural language inference develop robust framework test difference annotation across gender four benchmark datasets result largely show lack statistically significant difference annotation male female task framework used analyze difference annotation various demographic group future work finally note datasets collected without annotator demographic released aggregate form call community consider annotator demographic data collected release disaggregated data allow work analyzing variability among annotator
introduce eureka ensemblebased approach performing automatic euphemism detection identify correct potentially mislabelled row dataset curate expanded corpus called euphaug leverage model representation potentially euphemistic term pet explore using representation semantically close sentence aid classification using augmented dataset knnbased method eureka able achieve stateoftheart result public leaderboard euphemism detection shared task ranking first macro f score
social medium seen promising data source pharmacovigilance however method automatic extraction adverse drug reaction social medium platform twitter still need development included reliably routine pharmacovigilance practice bidirectional encoder representation transformer bert model shown great performance many major nlp task recently decided test performance smmh shared task submitting result pretrained finetuned bert model without added knowledge one carried training datasets additional datasets three submission ended average team submission f task average f task average f score task average used many highranking submission edition smmh shared task bert continues stateoftheart adr extraction twitter data
describe approach st computational linguistics lay summary shared task cllaysumm task produce nontechnical summary scholarly document summary within easy grasp layman may well versed domain research article propose two step divideandconquer approach first judiciously select segment document overly pedantic likely interest laity overextract sentence segment using unsupervised network based method next perform abstractive summarization extraction systematically merge abstraction run ablation study establish step pipeline critical improvement quality lay summary approach leverage stateoftheart pretrained deep neural network based model zeroshot learner achieve high score task
paper present investigation using coattention based neural network sourcedependent essay scoring use coattention mechanism help model learn importance part essay accurately also paper show coattention based neural network model provides reliable score prediction sourcedependent response evaluate model two sourcedependent response corpus result show model outperforms baseline corpus also show attention model similar expert opinion example
paper describes simbow system submitted semevaltask questionquestion similarity subtask b proposed approach supervised combination different unsupervised textual similarity textual similarity rely introduction relation matrix classical cosine similarity bagofwords get softcosine take account relation word according type relation matrix embedded softcosine semantic lexical relation considered system ranked first among official submission subtask b
adversarial attack carried reveal vulnerability deep neural network textual adversarial attacking challenging text discrete small perturbation bring significant change original input wordlevel attacking regarded combinatorial optimization problem wellstudied class textual attack method however existing wordlevel attack model far perfect largely unsuitable search space reduction method inefficient optimization algorithm employed paper propose novel attack model incorporates sememebased word substitution method particle swarm optimizationbased search algorithm solve two problem separately conduct exhaustive experiment evaluate attack model attacking bilstm bert three benchmark datasets experimental result demonstrate model consistently achieves much higher attack success rate craft highquality adversarial example compared baseline method also experiment show model higher transferability bring robustness enhancement victim model adversarial training code data paper obtained urlhttpsgithubcomthunlpsememepsoattack
entitylevel sentiment analysis predicts sentiment entity mentioned given text useful business context understand user emotion towards certain entity product company paper demonstrate developed entitylevel sentiment analysis system analyzes english telephone conversation transcript contact center provide business insight present two approach one entirely based transformerbased distilbert model another us neural network supplemented heuristic rule
paper describes facebook fair submission wmt shared news translation task participate four language direction english textlesstextgreater german english textlesstextgreater russian direction following submission last year baseline system large bpebased transformer model trained fairseq sequence modeling toolkit year experiment different bitext data filtering scheme well adding filtered backtranslated data also ensemble finetune model domainspecific data decode using noisy channel model reranking system improves previous system performance bleu point achieves best casesensitive bleu score translation direction englishrussian
political campaign full political ad posted candidate social medium political advertisement constitute basic form campaigning subjected various social requirement present first publicly open dataset detecting specific text chunk category political advertising polish language contains humanannotated tweet tagged nine category constitute campaigning polish electoral law achieved interannotator agreement cohens kappa score additional annotator resolved mismatch first two annotator improving consistency complexity annotation process used newly created dataset train well established neural tagger achieving percent point f score also present possible direction use case datasets model initial analysis polish presidential election twitter
propose multilingual adversarial training model determining whether sentence contains idiomatic expression given key challenge task limited size annotated data model relies pretrained contextual representation different multilingual stateoftheart transformerbased language model ie multilingual bert xlmroberta adversarial training training method enhancing model generalization robustness without relying humancrafted feature knowledgebase additional datasets target datasets model achieved competitive result ranked thplace subtask zeroshot setting thplace subtask oneshot setting
information extraction electronic health record ehrs crucial task healthcare lack resource language specificity pose significant challenge study address limited availability italian natural language processing nlp tool clinical application computational demand large language model llm training present llamamts instructiontuned llama italian language leveraging lora technique ensembled bertbased model classify ehrs based presence absence metastasis patient affected breast cancer evaluation analysis discovered llamamts exhibit superior performance compared zeroshot llm italian bertbased model specifically finetuned metastatic task llamamts demonstrates promising result resourceconstrained environment offering practical solution information extraction italian ehrs oncology potentially improving patient care outcome
recently various intermediate layer distillation ild objective shown improve compression bert model via knowledge distillation kd however comprehensive evaluation objective taskspecific taskagnostic setting lacking best knowledge first work comprehensively evaluating distillation objective setting show attention transfer give best performance overall also study impact layer choice initializing student teacher layer finding significant impact performance taskspecific distillation vanilla kd hidden state transfer initialisation lower layer teacher give considerable improvement higher layer especially task qnli absolute percentage change accuracy attention transfer behaves consistently different initialisation setting release code efficient transformerbased model distillation framework study
paper describes system used semeval task multilingual tweet intimacy analysis two key challenge task complexity multilingual zeroshot crosslingual learning difficulty semantic mining tweet intimacy solve problem system extract contextual representation pretrained language model xlmt employ various optimization method including adversarial training data augmentation ordinal regression loss special training strategy system ranked th participating team leaderboard ranked th predicting language training data code available github
accented speech classification play vital role advancement highquality automatic speech recognition asr technology certain application like multiaccented speech classification always viable obtain data accent variation especially resourcepoor language one major reason contributes underperformance speech classification system therefore order handle speech variability indian language speaker accent propose fewshot learning paradigm study learns generic feature embeddings using encoder pretrained whisper model classification head classification model refined using llm finetuning technique lora qlora six indian english accent indic accent dataset experimental finding show accuracy model greatly increased fewshot learning paradigm effectiveness combined llm finetuning technique optimal setting model accuracy reach trainable parameter set
event argument extraction critical various natural language processing task providing structured information existing work usually extract event argument one one mostly neglect build dependency information among event argument role especially perspective event structure approach hinders model learning interaction different role paper raise research question adequately model dependency different role better performance end propose intraevent interevent dependencyaware graph network us event structure fundamental unit construct dependency role specifically first utilize dense intraevent graph construct role dependency within event construct dependency event retrieving similar event current event retrieval module optimize dependency information event representation propose dependency interaction module two auxiliary task improve extraction ability model different scenario experimental result ace ram wikievents datasets show great advantage proposed approach
article introduces novel transition system discontinuous lexicalized constituent parsing called srgap extension shiftreduce algorithm additional gap transition evaluation two german treebanks show srgap outperforms previous best transitionbased discontinuous parser maier large margin notably twice accurate prediction discontinuous constituent competitive state art fernandezgonzalez martin side contribution adapt span feature hall et al discontinuous parsing
traditional text complexity assessment usually take account syntactic lexical text complexity task automatic assessment conceptual text complexity important maintaining reader interest text adaptation struggling reader proposed recently paper present coco tool automatic assessment conceptual text complexity based using current stateoftheart unsupervised approach make code api freely available research purpose describe code possibility personalization adaptation detail compare current implementation state art discussing influence choice entity linker performance tool finally present result obtained two widely used text simplification corpus discussing full potential tool
pretrained language model applied various nlp task considerable performance gain however large model size together long inference time limit deployment model realtime application one line model compression approach considers knowledge distillation distill large teacher model small student model study focus singledomain ignores transferable knowledge domain notice training teacher transferable knowledge digested across domain achieve better generalization capability help knowledge distillation hence propose metaknowledge distillation metakd framework build metateacher model capture transferable knowledge across domain pass knowledge student specifically explicitly force metateacher capture transferable knowledge instancelevel featurelevel multiple domain propose metadistillation algorithm learn singledomain student model guidance metateacher experiment public multidomain nlp task show effectiveness superiority proposed metakd framework also demonstrate capability metakd setting training data scarce
charge prediction task aim predict charge case given fact description recent model already achieved impressive accuracy task however little understood mechanism use perform judgmentfor practical application charge prediction model conform certain legal theory civil law country framework civil law case judged according certain local legal theory china example nearly criminal judge make decision based four element theory fetin paper argue trustworthy charge prediction model take legal theory consideration standing prior study model interpretation propose three principle trustworthy model follow task sensitive selective presumption innocencewe design new framework evaluate whether existing charge prediction model learn legal theory finding indicate existing charge prediction model meet selective principle benchmark dataset still sensitive enough satisfy presumption innocence code dataset released urlhttpsgithubcomzhenweianexpljp
paper present thot toolkit set tool train phrasebased model statistical machine translation publicly available open source software toolkit obtains phrasebased model wordbased alignment model knowledge functionality offered publicly available toolkit thot toolkit also implement new way estimating phrase model allows obtain complete phrase model method described literature including segmentation length submodel toolkit output given different format order used statistical machine translation tool like pharaoh beam search decoder phrasebased alignment model used order perform translation experiment generated model additionally thot toolkit used obtain best alignment sentence pair phrase level
usergenerated data source gained significance uncovering adverse drug reaction adrs increasing number discussion occurring digital world however existing clinical corpus predominantly revolve around scientific article english work present multilingual corpus text concerning adrs gathered diverse source including patient forum social medium clinical report german french japanese corpus contains annotation covering entity type four attribute type relation type contributes development realworld multilingual language model healthcare provide statistic highlight certain challenge associated corpus conduct preliminary experiment resulting strong baseline extracting entity relation entity within across language
paper present system semeval task community question answering cqa develop ranking system capable capturing semantic relation text pair little word overlap addition traditional nlp feature introduce several neural network based matching feature enable system measure text similarity beyond lexicon system significantly outperforms baseline method hold second place subtask fifth place subtask b demonstrates efficacy answer selection question retrieval
hypernymy detection aka lexical entailment fundamental subtask many natural language understanding task previous exploration mostly focus monolingual hypernymy detection highresource language eg english investigate lowresource scenario paper address problem lowresource hypernymy detection combining highresource language extensively compare three joint training paradigm first time propose applying meta learning relieve lowresource issue experiment demonstrate superiority method among three setting substantially improves performance extremely lowresource language preventing overfitting small datasets
introduce pubmedqa novel biomedical question answering qa dataset collected pubmed abstract task pubmedqa answer research question yesnomaybe eg preoperative statin reduce atrial fibrillation coronary artery bypass grafting using corresponding abstract pubmedqa k expertannotated k unlabeled k artificially generated qa instance pubmedqa instance composed question either existing research article title derived one context corresponding abstract without conclusion long answer conclusion abstract presumably answer research question yesnomaybe answer summarizes conclusion pubmedqa first qa dataset reasoning biomedical research text especially quantitative content required answer question best performing model multiphase finetuning biobert long answer bagofword statistic additional supervision achieves accuracy compared single human performance accuracy majoritybaseline accuracy leaving much room improvement pubmedqa publicly available urlhttpspubmedqagithubio
mainstream machine learning paradigm nlp often work two underlying presumption first target task predefined static system merely need learn solve exclusively second supervision task mainly come set labeled example question arises build system keep learning new task instructionsthis work defines new learning paradigm contintin continual learning task instruction system learn sequence new task one one task explained piece textual instruction system required generate expected output new task learning instruction ii transfer knowledge acquired upstream task help solve downstream task ie forwardtransfer iii retain even improve performance earlier task learning new task ie backwardtransfer new problem studied stream task equipped instruction technically method instructionspeak contains two strategy make full use task instruction improve forwardtransfer backwardtransfer one learn negative output revisit instruction previous task knowledge first time study contintin nlp addition problem formulation promising approach work also contributes providing rich analysis community better understand novel learning problem
sequencetosequence model shown remarkable generalization power across several natural language task construct solution argued less compositional humanlike generalization paper present seqattn new architecture specifically designed exploit attention find compositional pattern input seqattn two standard component encoderdecoder model connected via transcoder modulates information flow show seqattn successfully generalize without requiring additional supervision two task specifically constructed challenge compositional skill neural network solution found model highly interpretable allowing easy analysis type solution found potential cause mistake exploit opportunity introduce new paradigm test compositionality study extent model overgeneralizes confronted exception show seqattn exhibit overgeneralization larger degree standard sequencetosequence model
present dualner simple effective framework make full use annotated source language corpus unlabeled target language text zeroshot crosslingual named entity recognition ner particular combine two complementary learning paradigm ner ie sequence labeling span prediction unified multitask framework obtaining sufficient ner model trained source data train target data textitdualteaching manner pseudolabels one task constructed prediction task moreover based span prediction entityaware regularization proposed enhance intrinsic crosslingual alignment entity different language experiment analysis demonstrate effectiveness dualner
used simple command recognition device smart speaker mobile phone keyword spotting system everywhere ubiquitous well web application grown popularity complexity last decade however despite obvious advantage natural language interaction voiceenabled web application still far attempt bridge gap honkling novel javascriptbased keyword spotting system purely clientside crossdevice compatible honkling deployed directly user device inbrowser implementation enables seamless personalization greatly improve model quality presence underrepresented nonamerican user accent achieve absolute increase accuracy personalized model example
recent progress natural language processing led transformer architecture becoming predominant model used natural language task however many real world datasets additional modality included transformer directly leverage present multimodal toolkit opensource python package incorporate text tabular categorical numerical data transformer downstream application toolkit integrates well hugging face existing api tokenization model hub allows easy download different pretrained model
artist music language recognition music recording crucial task music information retrieval domain task many industrial application become much important advent music streaming platform work proposed multitask learningbased deep learning model leverage shared latent representation two related task experimentally observe applying multitask learning simple block convolutional neural networkbased model pay improvement performance conduct experiment regional music dataset curated task released others result show improvement percent aucpr similar improvement observed aucroc
research reading comprehension focused answering question based individual document even single paragraph introduce neural model integrates reason relying information spread within document across multiple document frame inference problem graph mention entity node graph edge encode relation different mention eg within crossdocument coreference graph convolutional network gcns applied graph trained perform multistep reasoning entitygcn method scalable compact achieves stateoftheart result multidocument question answering dataset wikihop welbl et al
documentlevel event extraction dee task document typically contains many event record multiple event role therefore accurately extracting event record big challenge since number event record given previous work present entitybased directed acyclic graph edag generation method autoregressively generate event role requires given generation order meanwhile parallel method proposed generate event role simultaneously suffer inadequate training manifest zero accuracy event role paper propose iteratively parallel generation method prefilling strategy ipgpf event role event record generated parallel avoid order selection event record iteratively generated utilize historical result experiment two public datasets show ipgpf improves f previous parallel model f autoregressive model control variable setting moreover enhanced ipgpf outperforms entityenhanced model achieves new stateoftheart performance
paper describes method behind system submitted university groningen wmt unsupervised machine translation task germanlower sorbian dedsb highresource language lowresource one system us transformer encoderdecoder architecture make three change standard training procedure first training focus two language time contrasting wealth research multilingual system second introduce novel method initializing vocabulary unseen language achieving improvement bleu detextgreaterdsb bleu dsbtextgreaterdelastly experiment order offline online backtranslation used train unsupervised system finding using online backtranslation first work better detextgreaterdsb bleu submission ranked first tied another team dsbtextgreaterde third detextgreaterdsb
able perform indepth chat human closed domain precondition opendomain chatbot ever claimed work take close look movie domain present largescale highquality corpus finegrained annotation hope pushing limit moviedomain chatbots propose unified readily scalable neural approach reconciles subtasks like intent prediction knowledge retrieval model first pretrained huge generaldomain data finetuned corpus show simple neural approach trained highquality data able outperform commercial system replying complex rule static interactive test find response generated system exhibit remarkably good engagement sensibleness close humanwritten one analyze limit work point potential direction future work
paper proposes new attention mechanism neural machine translation nmt based convolutional neural network cnns inspired cky algorithm proposed attention represents every possible combination source word eg phrase structure cnns imitates cky table algorithm nmt incorporating proposed attention decodes target sentence basis attention score hidden state cnns proposed attention enables nmt capture alignment underlying structure source sentence without sentence parsing evaluation asian scientific paper excerpt corpus aspec englishjapanese translation task show proposed attention gain point bleu
word embeddings used success variety task involving lexical semantic similarity individual word using unsupervised method cosine similarity encouraging result obtained analogical similarity paper explore potential pretrained word embeddings identify generic type semantic relation unsupervised experiment propose new relational similarity measure based combination wordvecs cbow input output vector outperforms concurrent vector representation used unsupervised clustering semeval relation classification data
machine learning model offer excellent predictive performance often lack interpretability necessary support integrated human machine decisionmaking clinical medicine highrisk setting domain expert may unwilling trust model prediction without explanation work explainable ai must balance competing objective along two different ax model ideally accurate simple explanation must balance faithfulness model decisionmaking plausibility domain expert propose use knowledge distillation training student model mimic behavior trained teacher model technique generate faithful plausible explanation evaluate approach task assigning icd code clinical note demonstrate student model faithful teacher model behavior produce quality natural language explanation
paper describes repository example sentence three endangered athabascan language koyukon upper tanana lower tanana repository allows researcher language teacher browse example sentence corpus either investigate language prepare teaching material originally heterogeneous text collection imported solr store via poio bridge paper describes requirement implementation advantage drawback approach discusses potential apply language athabascan family beyond
present novel feature attribution method explaining text classifier analyze context hate speech detection although feature attribution model usually provide single importance score token instead provide two complementary theoreticallygrounded score necessity sufficiency resulting informative explanation propose transparent method calculates value generating explicit perturbation input text allowing importance score explainable employ method explain prediction different hate speech detection model set curated example test suite show different value necessity sufficiency identity term correspond different kind false positive error exposing source classifier bias marginalized group
study proposes utterance positionaware approach neural networkbased dialogue act recognition dar model incorporates positional encoding utterance absolute relative position proposed approach inspired observation dialogue act tendency occurrence position evaluation switchboard corpus show proposed positional encoding utterance statistically significantly improves performance dar
paper propose transfer learning based simultaneous translation model extending bart pretrained bart korean wikipedia korean news dataset finetuned additional webcrawled parallel corpus duolingo official training dataset experiment duolingo test dataset submission achieves weighted macro f score rank second among submitted enko system
paper introduce tokyo metropolitan university feedback comment generation system submitted feedback comment generation task inlg generation challenge task source sentence offset range preposition us given input system generates hint explanatory note preposition us output tackle generation task finetuned pretrained sequencetosequence language model model using bart showed significant improvement bleu score demonstrating effectiveness pretrained sequencetosequence language model task found using partofspeech tag information auxiliary input improves generation quality feedback comment furthermore adopt simple postprocessing method enhance reliability generation result system achieved f score point bleubased evaluation point manual evaluation ranked second third leaderboard
allow easy understanding various license exist use language resource elras metashares creative common etc elra developed license wizardto help rightholders sharedistribute resource appropriate license also aim exploited user better understand legal obligation apply various licensing situation present paper elaborates license wizard functionality web configurator enables select number legal feature obtain user license adapted user selection define user license would like select order distribute language resource integrate user license term distribution agreement could proposed elra metashare distribution elra catalogue language resource thanks flexible back office structure legal feature selection easily reviewed include feature may relevant license integrating contribution initiative thus aim one obvious next step special focus clarin linked data experience
propose novel methodology namely muler transforms referencebased evaluation metric text generation machine translation mt finegrained analysis tool given system metric muler quantifies much chosen metric penalizes specific error type eg error translating name location muler thus enables detailed error analysis lead targeted improvement effort specific phenomenon perform experiment synthetic naturalistic setting support mulers validity showcase usability mt evaluation task summarization analyzing submission wmt find consistent trend example noun verb among frequent po tag however among hardest translate performance po tag improves overall system performance thus correlated identity change language language preliminary experiment summarization reveal similar trend
online arabic primarily written using arabic script romanscript variety called arabizi often seen social medium although representation capture phonology language onetoone mapping arabic script version issue exacerbated fact arabizi social medium dialectal arabic standard orthography furthermore arabizi tends include lot code mixing arabic english french map arabizi text arabic script context complete utterance previously published effort split arabizi detection arabic script target two separate task paper present first effort unified model arabizi detection transliteration codemixed output consistent arabic spelling convention using sequencetosequence deep learning model best system achieves word accuracy bleu blind test set
paper present approach ehrsql shared task aim develop reliable texttosql system electronic health record propose two approach leverage large language model llm prompting finetuning generate ehrsql query technique concentrate bridging gap realworld knowledge llm trained domainspecific knowledge required task paper provides result approach individually demonstrating achieve high execution accuracy additionally show ensemble approach enhances generation reliability reducing error approach secured u nd place shared task competition methodology outlined paper designed transferable domainspecific texttosql problem emphasize accuracy reliability
privacy issue receiving increasing attention within natural language processing nlp community numerous method proposed sanitize text subject differential privacy however stateoftheart text sanitization mechanism based relaxed notion metric local differential privacy mldp apply nonmetric semantic similarity measure achieve good privacyutility tradeoff address limitation propose novel customized text sanitization custext mechanism based original epsilondifferential privacy dp definition compatible similarity measuremoreover custext assigns input token customized output set provide advanced privacy protection token levelextensive experiment several benchmark datasets show custext achieves better tradeoff privacy utility existing mechanismsthe code available urlhttpsgithubcomsaijulycustext
dependency tree intensively used graph neural network aspectbased sentiment classification though effective method rely external dependency parser unavailable lowresource language perform worse lowresource domain addition dependency tree also optimized aspectbased sentiment classification paper propose aspectspecific languageagnostic discrete latent opinion tree model alternative structure explicit dependency tree ease learning complicated structured latent variable build connection aspecttocontext attention score syntactic distance inducing tree attention score result six english benchmark one chinese dataset show model achieve competitive performance interpretability
large language model llm demonstrated remarkable performance following natural language instruction without finetuning domainspecific task data however leveraging llm domainspecific question answering suffers severe limitation generated answer tends hallucinate due training data collection time using offtheshelf complex user utterance wrong retrieval retrievalaugmented generation furthermore due lack awareness domain expected output llm may generate unexpected unsafe answer tailored target domain paper propose carexpert incar retrievalaugmented conversational questionanswering system leveraging llm different task specifically carexpert employ llm control input provide domainspecific document extractive generative answering component control output ensure safe domainspecific answer comprehensive empirical evaluation exhibit carexpert outperforms stateoftheart llm generating natural safe carspecific answer
consider two competitive machine learning model one considered stateofthe art competitive baseline suppose permuting example training set say reversing original order shuffling minibatching could report substantially betterworst performance system choice multiple percentage point paper illustrate scenario trending nlp task natural language inference nli show two central nli corpus today learning process neural system far sensitive permutation data reopen question judge good neural architecture nli given available dataset perhaps soundness nli task current state
present indrexmm main memory database system interactively executing two interwoven task declarative relation extraction text exploitation sql indrexmm simplifies task user powerful sql extension gathering statistical semantics executing open information extraction integrating relation candidate domain specific data demonstrate function k document reuters rcv billion linguistic annotation report execution time order second
neural machine translation nmt drawback generate highfrequency word owing computational cost softmax function output layer japaneseenglish nmt japanese predicate conjugation cause increase vocabulary size example one verb many surface variety research focus predicate conjugation compressing vocabulary size japanese vocabulary list filled various form verb propose method using predicate conjugation information without discarding linguistic information proposed method generate lowfrequency word deal unknown word two method considered introduce conjugation information first considers token conjugation token second considers embedded vector conjugation feature result using method demonstrate vocabulary size compressed approximately tanaka corpus nmt model output word training data set furthermore bleu score improved point japanesetoenglish translation point englishtojapanese translation aspec
spoken language understanding slu model industry application usually trained offline historic data perform well incoming user request deployment since application data available training time formally similar domain generalization problem domain correspond different temporal segment data goal build model performs well unseen domain eg upcoming data paper explore different strategy achieving good temporal generalization including instance weighting temporal finetuning learning temporal feature building temporallyinvariant model result data largescale slu system show temporal information leveraged improve temporal generalization slu model
opinion summarization focus generating summary reflect popular subjective information expressed multiple online review generated summary offer general concise information particular hotel product information may insufficient help user compare multiple different choice thus user may still struggle question one pick paper propose comparative opinion summarization task aim generating two contrastive summary one common summary two different candidate set review develop comparative summarization framework cocosum consists two base summarization model jointly generate contrastive common summary experimental result newly created benchmark cocotrip show cocosum produce higherquality contrastive common summary stateoftheart opinion summarization model dataset code available urlhttpsgithubcommegagonlabscocosum
neural unsupervised parsing model learn parse without access syntactic annotation optimized another task like language modeling work propose selftraining neural model leverage aggregated annotation predicted copy model supervision future copy able use model prediction training extend recent neural architecture prpn shen et al trained semisupervised fashion add example parses predicted model unlabeled training data selftrained model outperforms prpn f previous state art f addition show architecture also helpful semisupervised parsing ultralowresource setting
even though various speech data set available hungarian lack general overview type size fill gap provide survey available data set spoken hungarian five category eg monolingual hungarian part multilingual pathological childrelated dialectal collection total estimated size available data hour across speaker represents rich spoken language diversity however distribution data alignment reallife eg speech recognition task far optimal indicating need additional largerscale natural language speech data set survey present overview available data set hungarian explaining strength weakness useful researcher working hungarian across discipline addition survey serf starting point towards unified foundational speech model specific hungarian
autosegmental representation ar goldsmith claimed enable local analysis otherwise nonlocal phenomenon odden focusing domain tone investigate ability ar using computationally welldefined notion locality extended chandlee result nuanced understanding way ar interact phonological locality
prediction relationship disease gene mutation important knowledge extraction task potentially help drug discovery paper present approach trigger word detection task identification thematic role task agac track bionlp open shared task task regarded traditional name entity recognition ner cultivates molecular phenomenon related gene mutation task regarded relation extraction capture thematic role entity two task exploit pretrained biomedical language representation model ie bert pipe information extraction collection mutationdisease knowledge pubmed also design finetuning technique extra feature using multitask learning experiment result show proposed approach achieve rank rank task task respectively term f metric
current supervised relational triple extraction approach require huge amount labeled data thus suffer poor performance fewshot setting however people grasp new knowledge learning instance end take first step study fewshot relational triple extraction well understood unlike previous singletask fewshot problem relational triple extraction challenging entity relation implicit correlation paper propose novel multiprototype embedding network model jointly extract composition relational triple namely entity pair corresponding relation specific design hybrid prototypical learning mechanism bridge text knowledge concerning entity relation thus implicit correlation entity relation injected additionally propose prototypeaware regularization learn representative prototype experimental result demonstrate proposed method improve performance fewshot triple extraction
writing highquality test question item critical building educational measure traditionally also timeconsuming process one promising avenue alleviating automated item generation whereby method artificial intelligence ai used generate new item minimal human intervention researcher explored using large language model llm generate new item equivalent psychometric property humanwritten one llm generate item improved psychometric property even existing item poor validity evidence investigate using item natural language inference nli dataset develop novel prompting strategy based selecting item best worst property use prompt use gpt generate new nli item find gpt item show improved psychometric property many case whilst also possessing good content convergent discriminant validity evidence collectively result demonstrate potential employing llm ease item development process suggest careful use prompting may allow iterative improvement item quality
paper present system submitted semeval task multilingual emoji prediction system approach language equal first considering word embeddings associated automatically computed feature different type applying bagging algorithm randomforest predict emoji tweet
paper rwth large vocabulary continuous speech recognition lvcsr system developed iwslt evaluation campaign described evaluation campaign focus transcribing spontaneous speech skype recording stateoftheart bidirectional long shortterm memory lstm deep multilingually boosted feedforward neural network ffnn acoustic model trained narrow broadband feature open vocabulary approach using subword unit also considered lstm countbased full word hybrid backoff language modeling method used model morphological richness german language approach combined using confusion network combination cnc yield competitive wer
judgment prediction legal case attracted much research effort practice use ultimate goal prison term prediction existing work merely predicts total prison term reality defendant often charged multiple crime paper argue chargebased prison term prediction cptp better fit realistic need also make total prison term prediction accurate interpretable collect first largescale structured data cptp evaluate several competitive baseline based observation finegrained feature selection key achieving good performance propose deep gating network dgn chargespecific feature selection aggregation experiment show dgn achieves stateoftheart performance
recent work witnessed paradigm shift seqseq seqedit field text editing aim addressing slow autoregressive inference problem posed former despite promising result seqedit approach still face several challenge inflexibility generation difficulty generalizing language work propose novel nonautoregressive text editing method circumvent issue modeling edit process latent ctc alignment make crucial extension ctc introducing copy operation edit space thus enabling efficient management textual overlap editing conduct extensive experiment gec sentence fusion task showing proposed method significantly outperforms existing seqedit model achieves similar even better result seqseq time speedup moreover demonstrates good generalizability german russian indepth analysis reveal strength method term robustness various scenario generating fluent flexible output
paper present wordforce system powered state art neural network model visualize learned userdependent word embeddings post according post content engaged user generates scatter plot show force word ie whether semantics word embeddings post different stance clearly separated aspect controversial word addition wordforce provides dispersion distance word embeddings post different stance group proposes controversial word accordingly show clue people argue debate
tutorial provide comprehensive survey exciting recent work cuttingedge weaklysupervised unsupervised crosslingual word representation providing brief history supervised crosslingual word representation focus induce weaklysupervised unsupervised crosslingual word representation truly resourcepoor setting bilingual supervision guaranteed critical examination different training condition requirement unsupervised algorithm work effectively robust method distant language pair mitigate instability issue low performance distant language pair comprehensively evaluate representation diverse application benefit crosslingual word representation eg mt dialogue crosslingual sequence labeling structured prediction application crosslingual ir
questionanswering qa task often investigate specific question type knowledge domain reasoning skill leading specialized model catering specific category qa task recent research explored idea unified qa model model usually explored highresource scenario require retraining extend capability overcome drawback paper explores potential two paradigm tuning model prompt unified qa lowresource setting paper provides exhaustive analysis applicability using qa datasets revealing prompt tuning perform well model tuning fewshot setting good initialization study also show parametersharing result superior fewshot performance simple knowledge transfer technique prompt initialization effective prompt tuning achieves significant performance boost pretraining lowresource regime research offer insight advantage limitation prompt tuning unified qa fewshot setting contributing development effective efficient system lowresource scenario
large text corpus used creating word embeddings vector represent word meaning often contain stereotypical gender bias result unwanted bias typically also present word embeddings derived corpus downstream application field natural language processing nlp minimize effect gender bias setting insight needed come bias manifest text corpus employed paper contributes showing gender bias word embeddings wikipedia developed time quantifying gender bias time show art related word become female biased family science word stereotypical bias towards respectively female male word bias seem decreased since change extreme seen random set word career related word strongly associated male female difference become smaller recently written article development provide additional understanding done make wikipedia gender neutral important time writing considering bias word embeddings trained wikipedia text corpus
recent year neural machine translation nmt achieved notable result various translation task however wordbyword generation manner determined autoregressive mechanism lead high translation latency nmt restricts lowlatency application nonautoregressive neural machine translation nat remove autoregressive mechanism achieves significant decoding speedup generating target word independently simultaneously nevertheless nat still take wordlevel crossentropy loss training objective optimal output nat properly evaluated due multimodality problem article propose using sequencelevel training objective train nat model evaluate nat output whole correlate well real translation quality first propose training nat model optimize sequencelevel evaluation metric eg bleu based several novel reinforcement algorithm customized nat outperform conventional method reducing variance gradient estimation second introduce novel training objective nat model aim minimize bagofngrams bon difference model output reference sentence bon training objective differentiable calculated efficiently without approximation finally apply threestage training strategy combine two method train nat model validate approach four translation task wmt ende wmt enro show approach largely outperforms nat baseline achieves remarkable performance translation task source code available urlhttpsgithubcomictnlpseqnat
paper describes participation semeval task argument reasoning comprehension task call develop system given reason claim predict correct warrant two opposing option decided use deep learning architecture combined model different hyperparameters ensemble extensive analysis architecture ensemble reveals decision use ensemble suboptimal additionally benchmark support vector machine baseline furthermore experimented alternative data split achieved stable result
paper explores extending shallow semantic parsing beyond lexicalunit trigger using causal relation test case semantic parsing becomes difficult face wide variety linguistic realization causation take therefore base approach concept construction linguistic paradigm known construction grammar cxg cxg construction formfunction pairing rely arbitrary linguistic semantic feature rather codifying aspect construction form attempt employ cxg nlp done propose method offload problem machine learning describe two supervised approach tagging causal construction argument approach combine automatically induced patternmatching rule statistical classifier learn subtler parameter construction result show approach promising significantly outperform naive baseline construction recognition cause effect head match
extracting bilingual terminology multiword term comparable corpus widely researched work propose unified framework aligning bilingual term independently term length also introduce enhancement contextbased neural network based approach experiment show effectiveness enhancement previous work system adapted specialized domain
abstract present preliminary work application natural language processing technique social network modeling prediction cryptocurrency trading investment behavior specifically building model use language social network behavior predict tweet hour period used buy sell cryptocurrency make profit paper present novel task initial language modeling study
recently speechtext pretraining method shown remarkable success many speech natural language processing task however previous pretrained model usually tailored one two specific task fail conquer wide range speechtext task addition existing speechtext pretraining method fail explore contextual information within dialogue enrich utterance representation paper propose speechtext pretraining spoken dialog understanding explicit crossmodal alignment spectrum firstever speechtext dialog pretraining model concretely consider temporality speech modality design novel temporal position prediction task capture speechtext alignment pretraining task aim predict start end time textual word corresponding speech waveform addition learn characteristic spoken dialog generalize response selection task textual dialog pretraining speechtext dialog pretraining scenario experimental result four different downstream speechtext task demonstrate superiority spectrum learning speechtext alignment multiturn dialog context
transformation education traditional classroom environment online education assessment important accurately assess difficulty question ever teacher may able follow student performance learning behavior closely welldefined method measure difficulty question guide learning necessary paper explore concept question difficulty provide new chinese dtqdc dataset currently largest chinese question dataset also enriched attribute difficulty label additional attribute keywords chapter question type would allow model understand question precisely proposed mtmsbert ormsbert improve judgment difficulty different view proposed method outperforms different baseline fscore mae mse new dtqdc dataset laying foundation question difficulty comprehension task
common law outcome new case determined mostly precedent case rather existing statute however exactly precedent influence outcome new case answering question crucial guaranteeing fair consistent judicial decisionmaking first approach question computationally comparing two longstanding jurisprudential view halsburys belief argument precedent main determinant outcome goodharts belief matter precedent fact base study corpus legal case european court human right ecthr allows u access case also case cited judge argument ie precedent case taking informationtheoretic view modelling question case outcome classification task find precedent argument share nats information case outcome whereas precedent fact share nats information ie less suggesting halsburys view may accurate specific court found however qualitative analysis specific statue goodharts view dominates present evidence one legal concept hand less straightforward
fake news detection closelyrelated factchecking recently attracted lot attention automatization task already studied english language study found eg baly et al best knowledge research conducted west slavic language paper present datasets czech polish slovak also ran initial experiment set baseline research area
paper introduces deepparliament legal domain benchmark dataset gather bill document metadata performs various bill status classification task proposed dataset text cover broad range bill present contains richer information parliament bill content data collection detailed statistic analysis provided paper moreover experimented different type model ranging rnn pretrained reported result proposing two new benchmark binary multiclass bill status classification model developed bill document relevant supportive task may assist member parliament mp president legal practitioner help review prioritise bill thus speeding billing process improving quality decision reducing time consumption house considering foundation country democracy parliament state legislature anticipate research essential addition legal nlp community work first present parliament bill prediction task order improve accessibility legal ai resource promote reproducibility made code dataset publicly accessible githubcommonkdeepparliament
throughout conversation way participant interact constant flux tone may change may resort different strategy convey point might alter interaction pattern understanding dynamic complement actual fact opinion discussed offering holistic view trajectory conversation arrived current state likely headingin work introduce task summarizing dynamic conversation constructing dataset humanwritten summary exploring several automated baseline evaluate whether summary capture trajectory conversation via established downstream task forecasting whether ongoing conversation eventually derail toxic behavior show help human automated system forecasting task human make prediction three time faster greater confidence reading summary reading transcript furthermore automated forecasting system accurate constructing predicting based summary conversation dynamic compared directly predicting transcript
paper present inferential model text type genre identification web page text type inferred using modified form bayes theorem genre derived using simple ifthen rule genre system web complex phenomenon web page usually unpredictable individualized paper document propose approach alternative unsupervised supervised technique inferential model allows classification accommodate genre entirely standardized capable reading web page mixed rarely corresponding ideal type often showing mixture genre genre proper evaluation model remains open issue
work team rgat describe approach semeval task safe biomedical natural language inference clinical trial nlict objective task multievidence natural language inference based different section clinical trial report explored various approach dependency tree input query additional feature graph attention network gat along token partsofspeech feature b sequencetosequence approach using various model synthetic data finally c incontext learning using large language model llm like gpt amongs three approach best result obtained llm fscore highest faithfulness consistence
digitization historical text invite researcher explore largescale corpus historical text computational method study present computational text analysis relatively understudied topic asian worker represented historical newspaper united state found word coolie semantically different state eg massachusetts rhode island wyoming oklahoma arkansas different discourse around coolie also found thenconfederate newspaper thenunion newspaper formed distinctive discourse measuring overrepresented word newspaper thenconfederate state associated coolie slaveryrelated word addition found asian perceived inferior european immigrant subjected target racism study contributes supplementing qualitative analysis racism united state quantitative discourse analysis
paper present new corpus personality dyad corpus consisting multimodal data three conversation three personalitymatched twoperson dyad total separate dialogue participant selected larger sample standard deviation mean bigfive personality extraversion scale produce extravertextravert dyad introvertintrovert dyad extravertintrovert dyad pair carried conversation three different task conversation recorded using optical motion capture body data glove hand dyad speech transcribed gestural postural behavior annotated anvil released corpus includes personality profile anvil file containing speech transcription gestural annotation bvh file containing body hand motion
abstractive dialogue summarization long viewed important standalone task natural language processing previous work explored possibility whether abstractive dialogue summarization also used mean boost nlp system performance important dialogue comprehension task paper propose novel type dialogue summarization task structured dialogue summarization strudel help pretrained language model better understand dialogue improve performance important dialogue comprehension task contrast holistic approach taken traditional freeform abstractive summarization task dialogue strudel aim decompose imitate hierarchical systematic structured mental process human being usually go understanding analyzing dialogue thus advantage focused specific instructive dialogue comprehension model learn introduce new strudel dialogue comprehension modeling framework integrates strudel dialogue reasoning module transformer encoder language model improve dialogue comprehension ability empirical experiment two important downstream dialogue comprehension task dialogue question answering dialogue response prediction demonstrate strudel dialogue comprehension model significantly improve dialogue comprehension performance transformer encoder language model
legal tech developed help people legal service solve legal problem via machine achieve one key requirement machine utilize legal knowledge comprehend legal context fulfilled natural language processing nlp technique instance text representation text categorization question answering qa natural language inference etc end introduce freely available chinese legal tech system iflylegal benefit multiple nlp task integrated system performs legal consulting multiway law searching legal document analysis exploiting technique deep contextual representation various attention mechanism knowledge iflylegal first chinese legal system employ uptodate nlp technique caters need different user group lawyer judge procurator client since jan gathered user page view till june
machine learning quintessential solution many ai problem learning model heavily dependent specific training data learning model incorporated prior knowledge using bayesian setup learning model ability access organized world knowledge demand work propose enhance learning model world knowledge form knowledge graph kg fact triple natural language processing nlp task aim develop deep learning model extract relevant prior support fact knowledge graph depending task using attention mechanism introduce convolutionbased model learning representation knowledge graph entity relation cluster order reduce attention space show proposed method highly scalable amount prior information processed applied generic nlp task using method show significant improvement performance text classification newsgroups news dbpedia datasets natural language inference stanford natural language inference snli dataset also demonstrate deep learning model trained substantially less amount labeled training data access organized world knowledge form knowledge base
objective questionanswering system knowledge graph kgqa respond natural language query presented kg complex question answering system typically address one two category complexity question constraint question involving multiple hop relation previous work addressed complexity separately multihop kgqa necessitates reasoning across numerous edge kg order arrive correct answer kg frequently sparse multihop kgqa present extra complication recent work developed kg embedding approach reduce kg sparsity performing missing link prediction paper tried address multihop constrainedbased query using kg embeddings generate flexible query graph empirical result indicate proposed methodology produce stateoftheart outcome three kgqa datasets
focus highquality hq translation worldwide demand continues increase exponentially far exceeds capacity translation profession satisfy extent mt currently used satisfy growing demand hq translation quite obviously little although mt used today people ever user professional translator represents major change mere ten year ago translator still principal target market mt vendor happened bring change matter happened mt vendor view present promising strategy hq mt embed mt system translation environment translator retains full control output opinion new type interactive mt achieve better acceptance level among translator significantly improve prospect mt commercial success translation industry
empathetic conversation individual express empathy towards others previous work mainly focused generating empathetic response utilizing speaker emotion besides external commonsense knowledge applied enhance system understanding speaker situation however given event commonsense knowledge base contains various relation potentially leading confusion dialogue system consequently inconsistency arise among emotion generated response speaker contextual information end propose novel approach empathetic response generation incorporates adaptive module commonsense knowledge selection ensure consistency generated empathetic response speaker situation selected knowledge used refine commonsense cognition empathy expression generated response experimental result show approach significantly outperforms baseline model automatic human evaluation exhibiting generation coherent empathetic response moreover case study highlight interpretability knowledge selection response effectiveness adaptive module model code urlhttpsgithubcomhanscaldcks
topic taxonomy display hierarchical topic structure text corpus provide topical knowledge enhance various nlp application dynamically incorporate new topic information several recent study tried expand complete topic taxonomy inserting emerging topic identified set new document however existing method focus frequent term document local topicsubtopic relation taxonomy lead limited topic term coverage fails model global taxonomy structure work propose novel framework topic taxonomy expansion named topicexpan directly generates topicrelated term belonging new topic specifically topicexpan leverage hierarchical relation structure surrounding new topic textual content input document topic term generation approach encourages newlyinserted topic cover important less frequent term well keep relation consistency within taxonomy experimental result two realworld text corpus show topicexpan significantly outperforms baseline method term quality output taxonomy
french learner audio corpus german speech flacgs created compare german speech production german native speaker gg french learner german fg across three speech production task increasing production complexity repetition reading picture description speaker gg fg performed three task total lead approximately h speech corpus manually transcribed automatically aligned analysis performed type corpus instance segmental difference speech production l learner compared native speaker chose realization velar nasal consonant engma spoken french engma appear vcv context lead production difficulty fg increasing speech production complexity reading picture description engma realized engma plosive fg case result two way anova unequal sample size duration different realization engma indicate duration reliable factor distinguish engma engma plosive fg production compared engma production gg vcv context flacgs corpus allows study l production perception
application transformerbased contextual representation became de facto solution solving complex nlp task despite success representation arguably opaque latent dimension directly interpretable alleviate limitation contextual representation devise algorithm output representation express humaninterpretable information dimension achieve constructing transformation matrix based semantic content embedding space predefined semantic category using hellinger distance evaluate inferred representation supersense prediction task experiment reveal interpretable nature transformed contextual representation make possible accurately predict supersense category word simply looking transformed coordinate largest coefficient quantify effect proposed transformation applied traditional dense contextual embeddings additionally investigate report consistent improvement integration sparse contextual word representation proposed algorithm
internet censorship imposes restriction information publicized viewed internet according freedom house annual freedom net report half world internet user live place internet censored restricted china built world extensive sophisticated online censorship system paper describe new corpus censored uncensored social medium tweet chinese microblogging website sina weibo collected tracking post mention sensitive topic authored sensitive user use corpus build neural network classifier predict censorship model performs accuracy using linguistic feature discus feature detail hypothesize could potentially used censorship circumvention
propose novel way conversational recommendation instead asking question user acquire preference recommender track conversation people including customer support agent csa join conversation time introduce recommendation building recommender join human conversation rjc propose information extraction discourse argumentation analysis well dialogue management technique compute recommendation product service needed customer inferred conversation special case conversation considered customer raise problem csa attempt resolve along receiving recommendation product feature addressing problem evaluate performance rjc number humanhuman humanchat bot dialogue demonstrate rjc efficient less intrusive way provide high relevance persuasive recommendation
hyperparameter tuning important achieving high accuracy deep learning model yet little interpretability work focused hyperparameters propose use explainable boosting machine ebm glassbox method posthoc analysis tool understanding hyperparameters influence model accuracy present case study transformer model machine translation illustrate kind insight may gleaned perform extensive analysis test robustness ebm different data condition
prediction machine learning model reflect bias data trained gender bias shown prevalent natural language processing model research identifying mitigating gender bias model predominantly considers gender binary male female neglecting fluidity continuity gender variable paper present approach evaluate gender bias prediction task recognises nonbinary nature gender genderneutralise random subset existing realworld hate speech data extend existing template approach measuring gender bias include test example genderneutral measuring bias across selection hate speech datasets show bias genderneutral data closer seen test instance identify male identify female
demo paper present emora stdm state transition dialogue manager dialogue system development framework provides novel workflow rapid prototyping chatbased dialogue manager well collaborative development complex interaction framework caters wide range expertise level supporting interoperability two popular approach state machine information state dialogue management natural language expression package allows seamless integration pattern matching custom nlp module database querying make workflow much efficient user study adopt framework interdisciplinary undergraduate course student technical nontechnical background able develop creative dialogue manager short period time
paper describes system submitted team chateval dstc track competition present three different approach predicting turnlevel quality chatbot response based large language model llm report improvement baseline using dynamic fewshot example vector store prompt chatgpt also analyze performance two approach report needed improvement future work developed three system two week showing potential llm task ablation study conducted challenge deadline show new llama model closing performance gap chatgpt opensource llm however find llama model benefit fewshot example way chatgpt
localizing semantic parser support new language requires effective crosslingual generalization recent work found success machinetranslation zeroshot method although approach struggle model native speaker ask question consider effectively leverage minimal annotated example new language fewshot crosslingual semantic parsing introduce firstorder metalearning algorithm train semantic parser maximal sample efficiency crosslingual transfer algorithm us highresource language train parser simultaneously optimizes crosslingual generalization lowerresource language result across six language atis demonstrate combination generalization step yield accurate semantic parser sampling mboxleq source training data new language approach also train competitive model spider using english generalization chinese similarly sampling mboxleq training data
kashmiri resource poor language less computational language resource available text processing main contribution paper present initial version kashmiri dependency treebank treebank consists sentence token annotated partofspeech po chunk dependency information treebank manually annotated using paninian computational grammar pcg formalism begum et al bharati et al version kashmiri treebank extension earlier verion sentence bhat pilot experiment aimed defining annotation guideline small subset kashmiri corpus paper refined guideline significant change carried interannotator agreement study ascertain quality also present dependency parsing pipeline consisting tokenizer stemmer po tagger chunker interchunk dependency parser therefore constitutes first freely available open source dependency parser kashmiri setting initial baseline kashmiri dependency parsing
text alignment find application task citation recommendation plagiarism detection existing alignment method operate single predefined level learn align text example sentence textitand document level propose new learning approach equips previously established hierarchical attention encoders representing document crossdocument attention component enabling structural comparison across different level documenttodocument sentencetodocument component weakly supervised document pair align multiple level evaluation predicting documenttodocument relationship sentencetodocument relationship task citation recommendation plagiarism detection show approach outperforms previously established hierarchical attention encoders based recurrent transformer contextualization unaware structural correspondence document
largescale parallel corpus extremely important translation memory examplebased machine translation support system create english sentence organized collection establishment largescale corpus currently ongoing however difficult project term copyright well economic efficiency investigate general tendency largescale corpus help improve economical efficiency parallel corpus collection well system establishment study therefore relationship scale parallel corpus degree correspondence clarified using parallel corpus patent
figurative language challenge language model since interpretation based use word way deviate conventional order meaning yet human easily understand interpret metaphor simile idiom derived embodied metaphor language proxy embodiment metaphor conventional lexicalised becomes easier system without body make sense embodied concept yet intricate relation embodiment feature concreteness age acquisition studied context figurative language interpretation concerning language model hence presented study show larger language model perform better interpreting metaphoric sentence action metaphorical sentence embodied analysis rule multicollinearity feature eg word length concreteness provides initial evidence larger language model conceptualise embodied concept degree facilitates figurative language understanding
present joint model entitylevel relation extraction document contrast approach focus local intrasentence mention pair thus require annotation mention level model operates entity level multitask approach followed build upon coreference resolution gather relevant signal via multiinstance learning multilevel representation combining global entity local mention information achieve stateoftheart relation extraction result docred dataset report first entitylevel endtoend relation extraction result future reference finally experimental result suggest joint approach par taskspecific learning though efficient due shared parameter training step
permanence online content combined enhanced authorship identification technique call stronger computational method protect identity privacy online authorship needed eg blind review scientific paper anonymous online review anonymous interaction mental health forum paper propose unsupervised inferencetime approach authorship obfuscation address unique challenge authorship obfuscation lack supervision data diverse authorship domain need sufficient level revision beyond simple paraphrasing obfuscate authorship preserving original content fluencywe introduce jamdec usercontrolled inferencetime algorithm authorship obfuscation principle applied text authorship approach build small language model gptxl order help avoid disclosing original content proprietary llm apis also reducing performance gap small large language model via algorithmic enhancement key idea behind approach boost creative power smaller language model constrained decoding also allowing userspecified control flexibility experimental result demonstrate approach based gptxl outperforms previous stateoftheart method based comparably small model performing competitively gpt b propriety model two order magnitude larger
paper describes language independent method alignment parallel text reuses acquired knowledge system extract word translation equivalent reuses correspondence point order enhance alignment parallel text point may cause misalignment filtered using confidence band linear regression analysis instead heuristic theoretically reliable homograph bootstrap alignment process build primary word translation lexicon step previously acquired lexicon reused repeatedly make finergrained alignment produce reliable translation lexicon
labeled lowresource language tunisian dialect existing prior tt research paper present speech corpus tunisian arabic texttospeech tunartts initiate development endtoend tt system tunisian dialect speech corpus extracted online english tunisian arabic dictionary able extract monospeaker speech corpus hour male speaker sampled khz corpus processed manually diacritized furthermore develop various tt system based two approach training scratch transfer learning tacotron fastspeech used evaluated using subjective objective metric experimental result show best result obtained transfer learning pretrained model english ljspeech dataset model obtained mean opinion score mo tunartts publicly available research purpose along baseline tt system demo keywords tunisian dialect texttospeech lowresource transfer learning tunartts
recent progress large pretrained language model lm led growth analysis examining kind linguistic knowledge encoded model due computational constraint existing analysis mostly conducted publiclyreleased lm checkpoint make difficult study various factor textittraining affect model acquisition linguistic knowledge paper train suite smallscale transformer lm differ respect architectural decision eg selfattention configuration training objective eg multitasking focal loss evaluate lm blimp targeted evaluation benchmark multiple english linguistic phenomenon experiment show none modification yield significant improvement aggregate change loss function result promising improvement several subcategories eg detecting adjunct island correctly scoping negative polarity item hope work offer useful insight future research designing transformer lm effectively learn linguistic knowledge
growing volume diverse information demand classifying arbitrary topic become increasingly critical address challenge introduce draft simple framework designed train classifier fewshot topic classification draft us example specific topic query construct customized dataset dense retriever model multiquery retrieval mqr algorithm effectively handle multiple query related specific topic applied construct customized dataset subsequently finetune classifier using customized dataset identify topic demonstrate efficacy proposed approach conduct evaluation widely used classification benchmark datasets manually constructed datasets diverse topic simulate diverse content encountered realworld application draft show competitive superior performance compared baseline use incontext learning gpt b instructgpt b fewshot topic classification task despite time fewer parameter demonstrating effectiveness
paper describes hellju submission multilexnorm shared task multilingual lexical normalization system based bert token classification preprocessing step token type necessary transformation predicted none uppercase lowercase capitalize modify characterlevel smt step text translated original normalized given bertpredicted transformation constraint language depending result development data training data extended backtranslating opensubtitles data final ordering ten participating team hellju team taken second place scoring better previous stateoftheart
paper present bering lab submission shared task th workshop asian translation wat jpc nictsap participated task jpc domain task nictsap approach task mainly focused building nmt system domainspecific corpus crawled patent document pair englishjapanese chinesejapanese koreanjapanese cleaning noisy data built parallel corpus aligning sentence sentencelevel similarity score also sap test data collected opus dataset including three domain corpus trained transformer collected dataset submission ranked st eight fourteen task achieving improvement jpc nictsap bleu score
voice assistant dialogue agent grow popularity abuse receive conducted largescale quantitative evaluation effectiveness response type avoidance empathetic counter additional factor using redirect voluntarily provided name tested prior work measured direct effectiveness real user inthewild reoffense ratio length conversation initial response number turn next reoffense experiment confirm prior lab study showing empathetic response perform better generic avoidance response well counter response show dialogue agent almost always guide offensive user new topic use redirects use user name provided compared baseline avoidance strategy employed commercial agent best strategy able reduce reoffense ratio
impressive milestone achieved text matching adopting crossattention mechanism capture pertinent semantic connection two sentence representation however regular crossattention focus wordlevel link two input sequence neglecting importance contextual information propose contextaware interaction network coin properly align two sequence infer semantic relationship specifically interaction block includes contextaware crossattention mechanism effectively integrate contextual information aligning two sequence gate fusion layer flexibly interpolate aligned representation apply multiple stacked interaction block produce alignment different level gradually refine attention result experiment two question matching datasets detailed analysis demonstrate effectiveness model
paper present result general machine translation task organised part conference machine translation wmt general mt task participant asked build machine translation system language pair evaluated test set consisting four different domain evaluate system output human annotator using two different technique referencebased direct assessment da combination da scalar quality metric dasqm
use linked data within languagelearning application open research question research prototype presented applies linkeddata principle store linguistic annotation generated languagelearning content using variety nlp tool result database link learning content linguistic annotation opensource resource top diverse range tool languagelearning application built
machine translation highly sensitive size quality training data led increasing interest collecting filtering large parallel corpus paper propose new method task based multilingual sentence embeddings contrast previous approach rely nearest neighbor retrieval hard threshold cosine similarity proposed method account scale inconsistency measure considering margin given sentence pair closest candidate instead experiment show large improvement existing method outperform best published result bucc mining task un reconstruction task f precision point respectively filtering englishgerman paracrawl corpus approach obtain bleu point newstest improvement one point best official filtered version
study address question extent syntactic wordorder trait different language evolved correlation whether dependency found universally across language restricted specific language family use logistic brownian motion bayesian framework model trait evolution language language family test trait correlation single family universally family separate model reveal universal correlation pattern bayes factor analysis model covered family also strongly indicate lineage specific correlation patter instead universal dependency
native language identification nli task aimed determining native language l learner second language l basis written text date research nli focused relatively small corpus apply nli recently released efcamdat corpus multiple time larger previous l corpus also provides longitudinal data several proficiency level investigation using accurate machine learning wide range linguistic feature reveals interesting pattern longitudinal data useful development nli application research l acquisition
aspectlevel sentiment classification aim determine sentiment polarity review sentence towards opinion target sentence could contain multiple sentimenttarget pair thus main challenge task separate different opinion context different target end attention mechanism played important role previous stateoftheart neural model mechanism able capture importance context word towards target modeling semantic association build upon line research propose two novel approach improving effectiveness attention first propose method target representation better capture semantic meaning opinion target second introduce attention model incorporates syntactic information attention mechanism experiment attentionbased lstm long shortterm memory model using datasets semeval experimental result show conventional attentionbased lstm substantially improved incorporating two approach
goal social medium platform facilitate healthy meaningful interaction among user often found becomes avenue wanton attack propose experimental study three aim provide u deeper understanding current data set focus different type abusive language sometimes overlapping racism sexism hate speech offensive language personal attack investigate type attention mechanism contextual v selfattention better abusive language detection using deep learning architecture investigate whether stacked architecture provide advantage simple architecture task
sensetagged corpus used evaluate word sense disambiguation wsd system manual creation resource often prohibitively expensive concept pseudowords conflations two unambiguous word integrated wsd evaluation experiment paper present new method pseudoword generation take account semanticrelatedness candidate word forming part pseudowords particular sens word disambiguated compare new approach alternative show result pseudowords similar real ambiguous word better correspond actual result two technique assessing similarity studied first one take advantage manually created dictionary wordnet second one build automatically computed statistical data obtained large corpus pro con two technique discussed result standard task demonstrated
education domain popular area collaboration nlp researcher decade however many recent breakthrough large transformer based language model provided new opportunity solving interesting difficult problem one problem assigning sentiment review educator performance present edusenti corpus albanian english review educational instructor performance review annotated sentiment emotion educational topic work experiment finetuning several language model edusenti corpus compare albanian masked language trained model last xlmroberta checkpoint show promising result baseline result include f albanian english contribution sentiment analysis corpus albanian english ii large albanian corpus crawled data useful unsupervised training language model iii source code experiment
neural language model lm perform well task require sensitivity syntactic structure drawing syntactic priming paradigm psycholinguistics propose novel technique analyze representation enable success establishing gradient similarity metric structure technique allows u reconstruct organization lm syntactic representational space use technique demonstrate lstm lm representation different type sentence relative clause organized hierarchically linguistically interpretable manner suggesting lm track abstract property sentence
stateoftheart question answering qa relies upon large amount training data labeling time consuming thus expensive reason customizing qa system challenging remedy propose novel framework annotating qa datasets entail learning costeffective annotation policy semisupervised annotation scheme latter reduces human effort leverage underlying qa system suggest potential candidate annotation human annotator simply provide binary feedback candidate system designed past annotation continuously improve future performance thus overall annotation cost best knowledge first paper address problem annotating question minimal annotation cost compare framework traditional manual annotation extensive set experiment find approach reduce annotation cost
english chinese known resourcerich language witnessed strong development transformerbased language model natural language processing task although vietnam approximately people speaking vietnamese several pretrained model eg phobert vibert velectra performed well general vietnamese nlp task including po tagging named entity recognition pretrained language model still limited vietnamese social medium task paper present first monolingual pretrained language model vietnamese social medium text visobert pretrained largescale corpus highquality diverse vietnamese social medium text using xlmr architecture moreover explored pretrained model five important natural language downstream task vietnamese social medium text emotion recognition hate speech detection sentiment analysis spam review detection hate speech span detection experiment demonstrate visobert far fewer parameter surpasses previous stateoftheart model multiple vietnamese social medium task visobert model available research purpose disclaimer paper contains actual comment social network might construed abusive offensive obscene
study controllable text summarization allows user gain control particular attribute eg length limit generated summary work propose novel training framework based constrained markov decision process cmdp conveniently includes reward function along set constraint facilitate better summarization control reward function encourages generation resemble humanwritten reference constraint used explicitly prevent generated summary violating userimposed requirement framework applied control important attribute summarization including length covered entity abstractiveness devise specific constraint aspect extensive experiment popular benchmark show cmdp framework help generate informative summary complying given attribute requirement
subjective language detection one important challenge sentiment analysis weight frequency opinionated text adjective considered key piece opinion extraction process subjective unit frequently collected polarity lexicon appear annotated prior polarity however moment polarity lexicon take account prior polarity variation across domain paper prof majority adjective change prior polarity value depending domain propose distinction domain dependent domain independent adjective moreover analysis led u propose classification related subjectivity degree constant mixed highly subjective adjective following classification polarity value better support sentiment analysis
llm great task involving english dominates training data explore ability address task involving language severely underrepresented training data specifically context datatotext generation irish maltese welsh breton promptengineering phase tested gpt andtextasciitilde range prompt type format small sample example inputoutput pair fully evaluated two promising prompt two scenario direct generation underresourced language ii generation english followed translation underresourced language find fewshot prompting work better direct generation underresourced language difference disappears pivoting via english fewshot translation system variant submitted webnlg shared task outperformed system substantial margin language automatic metric conclude good performance achieved stateoftheart llm outofthe box underresourced language however best result welsh bleu chrf ter well lowest ranked english system webnlg bleu chrf ter
paper present approach task task social medium mining health smmh shared task task differentiate adverse drug reaction adr tweet nonadr tweet treated binary classification task involves extracting adr mention mapping meddra code extracting adr mention treated sequence labeling normalizing adr mention treated multiclass classification system based pretrained language model roberta achieves fscore task average score b relaxed fscore adr extraction task average score relaxed fscore adr extraction normalization task average score overall model achieve promising result task significant improvement average score
universal sentence encoder use gained much popularity recently generalpurpose sentence encoding technique name suggests use designed fairly general indeed shown achieve superior performance many downstream nlp task paper present interesting negative result use context zeroshot text classification challenging task recently gained much attraction specifically found interesting case zeroshot text classification topic based inference outperformed usebased inference term f score investigation revealed use struggle perform well datasets large number label high semantic overlap topicbased classification work well
paper present comparison two corpus acquired mean two different technique first corpus acquired mean wizard oz technique dialog simulation technique developed acquisition second corpus random selection user system turn used defining stop condition automatically deciding simulated dialog successful use several evaluation measure proposed previous research compare two acquired corpus discus similarity difference two corpus regard measure
large language model llm continue advance recent year require development potent system detect whether text created human llm order prevent unethical use llm address challenge alta shared task introduced task build automatic detection system discriminate humanauthored synthetic text generated llm paper present participation task proposed featurelevel ensemble two transformer model namely debertav xlmroberta come robust system given dataset consisted textual data two label task binary classification experimental result show proposed method achieved competitive performance among participant believe solution would make impact provide feasible solution detection synthetic text detection
videogrounded dialogue understanding challenging problem requires machine perceive parse reason situated semantics extracted weakly aligned video dialogue existing benchmark treat modality frameindependent visual understanding task neglecting intrinsic attribute multimodal dialogue scene topic transition paper present textbfvideogrounded scenetopic aware dialogue vstar dataset large scale videogrounded dialogue understanding dataset based tv series based vstar propose two benchmark videogrounded dialogue understanding scene segmentation topic segmentation one benchmark videogrounded dialogue generation comprehensive experiment performed benchmark demonstrate importance multimodal information segment videogrounded dialogue understanding generation
investigate transfer learning based pretrained neural machine translation model translate lowresource similar language work part contribution wmt similar language translation shared task submitted model different language pair including frenchbambara spanishcatalan spanishportuguese direction model catalanspanish bleuand portuguesespanish bleu rank top official shared task evaluation team submit model frenchbambara pair
recent work looked evaluation phone embeddings using sound analogy correlation distinctive feature space embedding space clear aspect natural language phonology learnt neural network inspired distributed representational model wordvec study kind phonological relationship learnt phone embeddings present artificial phonology experiment show phone embeddings learn paradigmatic relationship phonemic allophonic distribution quite well also able capture cooccurrence restriction among vowel observed language vowel harmony however unable learn cooccurrence restriction among class consonant
rise internet social medium platform brought significant change people interact another lot people internet also become source news information world thus due increase accessibility information online sexism also increased effort made make internet safe space everyone irrespective gender larger social norm perspective legal technical regulation help alleviate online genderbased violence part paper explores simple method easily deployed automatically detect online sexism textual statement
many graph embedding approach proposed knowledge graph completion via link prediction among translating embedding approach enjoy advantage lightweight structure high efficiency great interpretability especially extended complex vector space show capability handling various relation pattern including symmetry antisymmetry inversion composition however previous translating embedding approach defined complex vector space suffer two main issue representing modeling capacity model limited translation function rigorous multiplication two complex number embedding ambiguity caused onetomany relation explicitly alleviated paper propose relationadaptive translation function built upon novel weighted product complex space weight learnable relationspecific independent embedding size translation function requires eight scalar parameter relation improves expressive power alleviates embedding ambiguity problem based function present relationadaptive translating embedding rate approach score graph triple moreover novel negative sampling method proposed utilize prior knowledge selfadversarial learning effective optimization experiment verify rate achieves stateoftheart performance four link prediction benchmark
semantic role labeling essential component semantic syntactic processing natural language reveals predicateargument structure language despite importance semantic role labeling korean language studied extensively one notable issue lack uniformity among data annotation strategy across different datasets often lack thorough rationale study suggest annotation strategy korean semantic role labeling line previously proposed linguistic theory well distinct property korean language propose simple yet viable conversion strategy sejong verb dictionary conllstyle dataset korean semantic role labeling experiment result using transformerbased sequence labeling model demonstrate reliability trainability converted dataset
deep learning based general language model achieved stateoftheart result many popular task sentiment analysis qa task text domain like social medium salient characteristic domain knowledge helpful domain relevant task work devise simple method obtain domain knowledge propose method integrate domain knowledge general knowledge based deep language model improve performance emotion classification experiment twitter data show even though deep language model finetuned target domain data attained comparable result previous stateoftheart model finetuned model still benefit extracted domain knowledge obtain improvement highlight importance making use domain knowledge domainspecific application
evolving landscape environmental social corporate governance esg impact assessment mlesg shared task proposes identifying esg impact type address challenge present comprehensive system leveraging ensemble learning technique capitalizing early late fusion approach approach employ four distinct model mbert flaubertbase albertbasev multilayer perceptron mlp incorporating latent semantic analysis lsa term frequencyinverse document frequency tfidf feature extensive experimentation find early fusion ensemble approach featuring integration lsa tfidf mbert flaubertbase albertbasev delivers best performance system offer comprehensive esg impact type identification solution contributing responsible sustainable decisionmaking process vital today financial corporate governance landscape
loanword word incorporated one language another without translation suppose two word distantlyrelated unrelated language sound similar similar meaning case evidence likely borrowing paper present method automatically detect loanword across various language pair accounting difference script pronunciation phonetic transformation borrowing language incorporate edit distance semantic similarity measure phonetic alignment evaluate language pair achieve performance comparable exceeding state art method singlepair loanword detection task also demonstrate multilingual model perform often better model trained single language pair potentially generalize unseen language pair sufficient data method exceed human performance loanword detection
dialog state tracking dst core component taskoriented dialog system existing stateoftheart dst model incorporates insight intuition human experience design supplementary label greatly assisted training process turnbyturn dst model though turnbyturn scheme supplementary label enabled satisfactory performance task dst model fashion label process raw dialogue data premise last turn dialogue state always correct usually case paper address negative impact resulted premise avalanche phenomenon propose jodem stateoftheart dst model tackle avalanche phenomenon two mechanism first mechanism jointly decision making method extract key information dialogue second mechanism compare contrast dialogue update technique prevent error accumulation example study graph analysis presented support claim harmfulness avalanche phenomenon also conduct quantitative qualitative experiment high quality multiwoz corpus dataset demonstrate proposed model outperforms existing stateoftheart method also prof validity solving avalanche degradation problem
work personality detection tended incorporate psychological feature different personality model bigfive mbti psychological feature helpful personality detection however used combination application different calculation standard among feature may result interference feature calculated using distinct system thereby introducing noise reducing performance paper adapts different psychological model proposed psyattention personality detection effectively encode psychological feature reducing number experiment bigfive mbti model pysattention achieved average accuracy respectively outperforming stateoftheart method indicating effective encoding psychological feature
multimodal summarization drawn much attention due rapid growth multimedia data output current multimodal summarization system usually represented text however found experiment multimodal output significantly improve user satisfaction informativeness summary paper propose novel task multimodal summarization multimodal output msmo handle task first collect largescale dataset msmo research propose multimodal attention model jointly generate text select relevant image multimodal input finally evaluate multimodal output construct novel multimodal automatic evaluation mmae method considers intramodality salience intermodality relevance experimental result show effectiveness mmae
recent year seen big advance field sentencelevel quality estimation qe largely result using neuralbased architecture however majority method work language pair trained need retraining new language pair process prove difficult technical point view usually computationally expensive paper propose simple qe framework based crosslingual transformer use implement evaluate two different neural architecture evaluation show proposed method achieve stateoftheart result outperforming current opensource quality estimation framework trained datasets wmt addition framework prof useful transfer learning setting especially dealing lowresourced language allowing u obtain competitive result
using method statistical analysis investigate semantic knowledge acquired english second language evaluate pace development across number predicate type content word combination well across level language proficiency native language exploratory study help identify problematic area language learner different background different stage learning
paper present predicate matrix v new lexical resource resulting integration multiple source predicate information including framenet verbnet propbank wordnet start basis semlink use advanced graphbased algorithm extend mapping coverage semlink second also exploit current content semlink infer new role mapping among different predicate schema result obtained new version predicate matrix largely extends current coverage semlink previous version predicate matrix
propose new domain adaptation method combinatory categorial grammar ccg parsing based idea automatic generation ccg corpus exploiting cheaper resource dependency tree solution conceptually simple relying specific parser architecture making applicable current bestperforming parser conduct extensive parsing experiment detailed discussion top existing benchmark datasets biomedical text question sentence create experimental datasets speech conversation math problem applied proposed method offtheshelf ccg parser show significant performance gain improving speech conversation math problem
choice token vocabulary affect performance machine translation paper aim figure good vocabulary whether find optimal vocabulary without trial training answer question first provide alternative understanding vocabulary perspective information theory motivates u formulate quest vocabularization finding best token dictionary proper size optimal transport ot problem propose volt simple efficient solution without trial training empirical result show volt beat widelyused vocabulary diverse scenario including wmt englishgerman translation ted bilingual translation ted multilingual translation example volt achieves vocabulary size reduction bleu gain englishgerman translation also compared bpesearch volt reduces search time gpu hour gpu hour englishgerman translation code available urlhttpsgithubcomjingjingnlpvolt
paper present approach biolaysumm task shared task held bionlp workshop effective communication scientific knowledge general public often limited technical language used research making difficult nonexperts comprehend address issue lay summary used explain research finding nonexperts accessible form conduct evaluation autoregressive language model general specialized biomedical domain generate lay summary biomedical research article abstract finding demonstrate gpt model combined straightforward fewshot prompt produce lay summary achieve significantly relevance factuality compared generated finetuned biogpt model however summary generated biogpt model exhibit better readability notably submission shared task achieved st place competition
study investigates application transformerbased model violence threat identification participated blp shared task initial submission banglabert large achieved th position leaderboard macro f score approaching highest baseline established task contrast topperforming system leaderboard achieved f score subsequent experiment involving mbert xlmroberta base xlmroberta large banglishbert banglabert banglabert large model revealed banglabert achieved f score closely approximated baseline remarkably mbert xlmroberta base also approximated baseline macro f score respectively notable finding study underperformance larger model shared task dataset requires investigation finding underscore potential transformerbased model identifying violence threat offering valuable insight enhance safety measure online platform
patronizing condescending language pcl towards vulnerable community general medium shown potentially harmful effect due subtlety good intention behind use audience aware language toxicity paper present method semeval task titled patronizing condescending language detection subtask binary classification task introduce adversarial training based fast gradient method fgm employ pretrained model unified architecture subtask b framed multilabel classification problem utilize various improved multilabel crossentropy loss function analyze performance method final evaluation system achieved official ranking subtask subtask b respectively addition explore relationship pcl emotional polarity intensity contains
presentation considers deep temporal model brain build previous formulation active inference simulate behaviour electrophysiological response deep hierarchical generative model discrete state transition deeply structured temporal aspect model mean evidence accumulated distinct temporal scale enabling inference narrative ie temporal scene illustrate behaviour term bayesian belief updating associated neuronal process reproduce epistemic foraging seen reading simulation reproduce sort perisaccadic delay period activity local field potential seen empirically including evidence accumulation place cell activity simulation presented example use basic principle constrain understanding system architecture brain functional imperative may apply neuronal network
paper investigate usefulness neural word embeddings process translating named entity ne resourcerich language language low resource relevant task hand introducing novel yet simple way obtaining bilingual word vector inspired observation mikolov et al b show training word vector model comparable corpus yield comparable vector space representation corpus reducing problem translating word finding rotation matrix result zou et al showed bilingual word embeddings improve chinese named entity recognition ner english chinese phrase translation use sentencealigned englishfrench europarl corpus show word embeddings extracted merged corpus corpus resulted merger two aligned corpus used ne translation extrapolate word embeddings trained merged parallel corpus useful named entity recognition translation task resourcepoor language
emotion recognition conversation erc received much attention lately researcher due potential widespread application diverse area healthcare education human resource paper present dialogue graph convolutional network dialoguegcn graph neural network based approach erc leverage self interspeaker dependency interlocutor model conversational context emotion recognition graph network dialoguegcn address context propagation issue present current rnnbased method empirically show method alleviates issue outperforming current state art number benchmark emotion classification datasets
idiom also referred phraseological unit language terminology subset within broader category multiword expression however lack representation idiom croatian lowresourced language linguistic linked open data cloud llod address gap propose extension existing rdfbased multilingual representation idiom referred lidioms dataset currently includes idiom english german italian portuguese russian paper expands existing resource incorporating croatian idiom ontolex lemon format addition foster translation initiative facilitate intercultural exchange added croatian idiom also linked idiom lidioms dataset share similar meaning despite difference expression aspect addition enriches knowledge base llod community new language resource includes croatian idiom
automatic morphological processing aid downstream natural language processing application especially lowresource language assist language documentation effort endangered language long multilingual field computational morphology increasingly moving towards approach suitable language minimal annotated resource first survey recent development computational morphology focus lowresource language second argue field ready tackle logical next challenge understanding language morphology raw text alone perform empirical study truly unsupervised version paradigm completion task show existing stateoftheart model bridged two newly proposed model devise perform reasonably still much room improvement stake high solving task increase language coverage morphological resource number magnitude
study investigates robustness stability likelihood ratiobased lrbased forensic text comparison ftc system size background population data focus centred scorebased approach estimating authorship lr document represented bagofwords model cosine distance used scoregenerating function set population data differed number score synthesised time using montecarol simulation technique ftc system performance different population size evaluated gradient metric loglr cost cllr experimental result revealed two outcome scorebased approach rather robust small population sizein score obtained author database stability performance system become fairly comparable system maximum number author poor performance term cllr occurred limited background population data largely due poor calibration result also indicated scorebased approach robust data scarcity featurebased approach however finding obliges study
paper show word class based language modeling support integration small language modern application speech technology method described paper applied language demonstrate method upper sorbian word class model semantic expression numeral date time day implementation created grammar realized form finitestatetransducers fsts minimalist grammar mg practically demonstrate usage fsts simple smarthome speech application able set wakeup alarm appointment expressed variety spontaneous natural sentence created mg integrated application practical use yet provide evidence mg could potentially work efficient fsts builton application particular mg work significantly smaller lexicon size since complex structure let generate expression less item still avoiding wrong expression
india known land many tongue dialect neural machine translation nmt current stateoftheart approach machine translation mt performs better large datasets indian language usually lack making approach infeasible paper address problem data scarcity efficiently training multilingual multilingual multi domain nmt system involving language proposing technique using joint domain language tag multilingual setup draw three major conclusion experiment training multilingual system via exploiting lexical similarity based language family help achieving overall average improvement bilingual baseline ii technique incorporating domain information language token help multilingual multidomain system getting significant average improvement baseline iii multistage finetuning help getting improvement language pair interest
paper describes ecosystem consisting three independent text annotation platform demonstrate ability work concert illustrate use address interactive domain adaptation task biomedical entity recognition platform approach general domainindependent readily applied area science
paper present recent work develop phonemic syllabic inventory castilian spanish based coralrom corpus spontaneous spoken resource varying degree naturalness different communicative context inventory developed mean phonemic syllabic automatic transcriptor whose output assessed manually reviewing transcription inventory include absolute frequency occurrence different phone syllable frequency contrasted inventory extracted comparable textual corpus finding evidence available inventory based mainly text provide accurate description spontaneously spoken castilian spanish
dense retrieval approach overcome lexical gap lead significantly improved search result however require large amount training data available domain shown previous work thakur et al b performance dense retriever severely degrades domain shift limit usage dense retrieval approach domain large training datasets paper propose novel unsupervised domain adaptation method textitgenerative pseudo labeling gpl combine query generator pseudo labeling crossencoder six representative domainspecialized datasets find proposed gpl outperform outofthebox stateoftheart dense retrieval approach point ndcg gpl requires less unlabeled data target domain robust training previous method investigate role six recent pretraining method scenario domain adaptation retrieval task three could yield improved result best approach tsdae wang et al combined gpl yielding another average improvement point ndcg across six task code model available urlhttpsgithubcomukplabgpl
effective content moderation imperative fostering healthy productive discussion online domain despite substantial effort moderator overwhelming nature discussion flow limit effectiveness however trained moderator intervene online discussion improve quality ordinary user also act moderator actively intervening correct information user post enhance argument steer discussion back coursethis paper introduces phenomenon user moderation documenting releasing umod first dataset comment whichusers act moderator umod contains commentreply pair subreddit rchangemyview crowdsourced annotation large annotator pool finegrained annotation schema targeting function moderation stylistic propertiesaggressiveness subjectivity sentiment constructiveness well individual perspective annotator task releaseof umod complemented two analysis focus constitutive feature constructiveness user moderation thesources annotator disagreement given high subjectivity task
following paper present formal model description textitdogwhistles dogwhistles class term expression often used political discourse used goal interpreted different way different community model presented describes phenomenon using variation social meaning game framework us probability distribution possible interpretation function well rsaibr reasoning
present semeval shared task universal conceptual cognitive annotation ucca parsing english german french discus participating system result ucca crosslinguistically applicable framework semantic representation build extensive typological work support rapid annotation ucca pose challenge existing parsing technique exhibit reentrancy resulting dag structure discontinuous structure nonterminal node corresponding complex semantic unit shared task yielded improvement stateoftheart baseline language setting full result found task website urlhttpscompetitionscodalaborgcompetitions
paper present corpusbased study emotive predicate verb predicative construction adjectival adverbial noun phrase bulgarian respect syntactic characteristic source empirical data analyzed bulgarian national corpus corpus bulgarian political journalistic speech bulgarian part multilingual comparable corpus parliamentary debate parlamint analyzes organized term morphosyntactic feature emotive predicate transitivity syntactic function thetaroles argument emotive predicate denote state event involving affective experience part special semantic class psychologicalexperiencer verb studied relation interaction lexical semantics argument realization bulgarian data confirm wellestablished division psych predicate three class subject experiencer fear type verb object experiencer frighten type verb dative experiencer third class mostly represented adverbial predicate
relation schema often predefined relation dataset relation type related different datasets overlapping semantics hypothesize combine datasets according semantic relatedness relation type overcome problem lack training data often easy discover connection relation type based relation name annotation guide hard measure exact similarity take advantage connection relation type different datasets propose use prototypical example represent relation type use example augment related type different dataset obtain improvement ace type augmentation strong baseline us multitask learning datasets obtain better feature representation relation make implementation publicly available urlhttpsgithubcomfufrankrelatedness
paper introduces several improvement current state art knowledgebased word sense disambiguation innovation result modifying enriching knowledge base created originally basis wordnet reflect several separate connected strategy manipulating shape content knowledge base assigning weight relation knowledge base addition new relation main contribution paper demonstrate previously proposed knowledge base organize linguistic world knowledge suboptimally task word sense disambiguation paper also establishes new state art knowledgebased approach best model competitive broader context supervised system well
proliferation online misinformation posed significant threat public interest numerous online user actively participate combat misinformation many response characterized lack politeness supporting fact solution text generation approach proposed automatically produce countermisinformation response nevertheless existing method often trained endtoend without leveraging external knowledge resulting subpar text quality excessively repetitive response paper propose retrieval augmented response generation online misinformation rarg collect supporting evidence scientific source generates countermisinformation response based evidence particular rarg consists two stage evidence collection design retrieval pipeline retrieve rerank evidence document using database comprising academic article response generation align large language model llm generate evidencebased response via reinforcement learning human feedback rlhf propose reward function maximize utilization retrieved evidence maintaining quality generated text yield polite factual response clearly refutes misinformation demonstrate effectiveness method study case covid perform extensive experiment crossdomain datasets rarg consistently outperforms baseline generating highquality countermisinformation response
capturing association knowledge graph kg entity alignment entity type inference related task benefit nlp application comprehensive knowledge representation recent related method built euclidean embeddings challenged hierarchical structure different scale kg also depend high embedding dimension realize enough expressiveness differently explore lowdimensional hyperbolic embeddings knowledge association propose hyperbolic relational graph neural network kg embedding capture knowledge association hyperbolic transformation extensive experiment entity alignment type inference demonstrate effectiveness efficiency method
propose neural model normalize text considering similarity word string sound experimentally compared model considers similarity word string sound model considers similarity word string sound model without similarity baseline result showed leveraging word string similarity succeeded dealing misspelling abbreviation taking account sound similarity succeeded dealing phonetic substitution emphasized character proposed model achieved higher f score baseline
paper proposes new approach exploring digitized humanity social science collection based explainable link built question experiment show quality automatically generated question relevance local context well originality link produced embeddings based question analysis also performed understand type question generated corpus related us enrich exploration relationship coreference question generated answer extracted text also discussed open path future improvement system resolution
recent nlp model shown remarkable ability effectively generalise zeroshot new task using natural language instruction guidance however many approach suffer high computational cost due reliance concatenating lengthy instruction every input example resulting costly reprocessing instruction avoid introduce hypernetworks instruction tuning hint convert task instruction example parameterefficient module inserted underlying model using pretrained text encoder eliminating need include instruction model input hypernetwork hint also produce encoded instruction concatenate encoded input decoding improve performance hint model outperform strong stateoftheart baseline controlling compute measured flop converting instruction module hint model effectively disregard length instruction fewshot example input term compute usage result hint enhance performance incorporating additional fewshot data utilizing compute combine strength parameterefficient finetuning incontext learning
paper present harmonisation process carried five treebanks available latin universal dependency aim eliminating discrepancy annotation style indeed first issue addressed parsing latin significant drop parsing accuracy different latin treebanks repeatedly observed latin syntactic variability surely account parsing result well affected divergent annotation choice analysing annotation differ propose pythonbased alignment five ud treebanks consequently impact annotation choice accuracy score assessed performing parsing experiment udpipe stanza
prior work datatotext generation task converting knowledge graph kg triple natural text focused domainspecific benchmark datasets paper however verbalize entire english wikidata kg discus unique challenge associated broad opendomain largescale verbalization show verbalizing comprehensive encyclopedic kg like wikidata used integrate structured kg natural language corpus contrast many architecture developed integrate two source approach convert kg natural text allowing seamlessly integrated existing language model carry advantage improved factual accuracy reduced toxicity resulting language model evaluate approach augmenting retrieval corpus retrieval language model showing significant improvement knowledge intensive task open domain qa lama knowledge probe
describe key point analysis kpa shared task key point analysis organized part th workshop argument mining argmining emnlp outline various approach discus result shared task expect task finding reported paper relevant researcher working text summarization argument mining
many nlp pipeline assume raw clean text many text encounter wild including vast majority legal document clean many visually structured document vsds pdfs conventional preprocessing tool vsds mainly focused word segmentation coarse layout analysis whereas finegrained logical structure analysis identifying paragraph boundary hierarchy vsds underexplored end proposed formulate task prediction transition label text fragment map fragment tree developed featurebased machine learning system fuse visual textual semantic cue system easily customizable different type vsds significantly outperformed baseline identifying different structure vsds example system obtained paragraph boundary detection f score significantly better popular pdftotext tool f score
describe dataset developed named entity recognition german federal court decision consists approx sentence million token resource contains manually annotated entity mapped finegrained semantic class person judge lawyer country city street landscape organization company institution court brand law ordinance european legal norm regulation contract court decision legal literature legal document furthermore automatically annotated timemlbased time expression dataset available ccby license connl format developed training ner service german legal document eu project lynx
speaker identification si text aim identify speaker utterance text previous study divide si several subtasks eg quote extraction named entity recognition gender identification coreference resolution however still far solving subtasks making si system rely seriously suffer error propagation endtoend si system hand limited individual module suffer insufficient training data existing smallscale datasets make large endtoend model possible design new annotation guideline regard si span extraction local context annotate far largest si dataset chinese named csi based eighteen novel viewing si span selection task also introduces possibility applying existing storng extractive machine reading comprehension mrc baseline surprisingly simply using baseline without humanannotated character name carefully designed rule already achieve performance comparable better previous stateoftheart si method public si datasets chinese furthermore show dataset serve additional training data existing benchmark lead gain accuracy finally using csi clean source design effective selftraining paradigm continuously leverage hundred unlabeled novel
tackle discourselevel relation recognition problem determining semantic relation text span implicit relation recognition challenging due lack explicit relational clue increasingly popular neural network technique proven effective semantic encoding whereby widely employed boost semantic relation discrimination however learning predict semantic relation deep level heavily relies great deal training data scale publicly available data field limited paper follow rutherford xue expand training data set using corpus explicitlyrelated argument arbitrarily dropping overtly presented discourse connective basis carry experiment sampling simple active learning approach used take informative instance data expansion goal verify whether selective use external data reduces time consumption retraining also ensures better system performance using expanded training data retrain convolutional neural network cnn based classifer simplified version qin et al stacking gated relation recognizer experimental result show expanding training set smallscale carefullyselected external data yield substantial performance gain improvement accuracy fscore allows weak classifier achieve comparable performance stateoftheart system
paper describes ntuaails submission semeval task detection propaganda technique news article task comprises two different subtasks namely span identification si b technique classification tc goal si subtask identify specific fragment given plain text containing least one propaganda technique tc subtask aim identify applied propaganda technique given text fragment different model trained subtask best performing system si task consists pretrained elmo word embeddings followed residual bidirectional lstm network tc subtask pretrained word embeddings glove fed bidirectional lstm neural network model achieved rank among team f score rank among team f score si tc subtasks respectively result indicate proposed deep learning model although relatively simple architecture fast train achieve satisfactory result task hand
exploring language usage frequency analysis large corpus defining feature recent work corpus computational linguistics psycholinguistic perspective however corpus used contribution often representative language usage either domainspecific limited size extracted unreliable source effort address limitation introduce subimdb corpus everyday language spoken text created contains million word corpus extracted subtitle family comedy child movie series first sizeable structured corpus subtitle made available experiment show word frequency norm extracted corpus effective wellknown norm kucerafrancis hal subtlexus predicting various psycholinguistic property word lexical decision time familiarity age acquisition simplicity also provide evidence contradict longstanding assumption ideal size corpus determined solely based well word frequency correlate lexical decision time
notwithstanding success notion construction computational tradition still lack way represent semantic content linguistic entity present simple corpusbased model implementing idea meaning syntactic construction intimately related semantics typical verb twostep process start identifying typical verb occurring given syntactic construction building distributional vector calculated weighted centroid vector order derive distributional signature construction order assess goodness approach replicated priming effect described johnson golberg function semantic distance construction prototypical verb additional support view come regression analysis showing distributional information used model behavioral data collected crowdsourced elicitation experiment
framework evaluation machine translation femti contains guideline building quality model used evaluate mt system relation purpose intended context use system contextual quality model thus constructed entering femti knowledge required operation complex task experiment set order transfer knowledge mt evaluation expert femti guideline polling expert evaluation method would use particular context inferring result generic relation characteristic context use quality characteristic result handson exercise carried part conference tutorial served refine femtis generic contextual quality model obtain feedback femti guideline general
learning sentence embeddings often requires large amount labeled data however task domain labeled data seldom available creating expensive work present new stateoftheart unsupervised method based pretrained transformer sequential denoising autoencoder tsdae outperforms previous approach point achieve performance indomain supervised approach show tsdae strong domain adaptation pretraining method sentence embeddings significantly outperforming approach like masked language model crucial shortcoming previous study narrow evaluation work mainly evaluates single task semantic textual similarity sts require domain knowledge unclear proposed method generalize domain task fill gap evaluate tsdae recent approach four different datasets heterogeneous domain
work proposes challenging yet realistic setting zeroshot crosstask generalization zeroshot instruction following presuming existence paragraphstyle task definition demonstration exist better learn task supervision definition propose two strategy first automatically find critical sentence definition second ranking objective force model generate gold output higher probability critical part highlighted definition joint effort two strategy yield stateoftheart performance supernaturalinstructions code available github
paraphrase generation aim generate semantically consistent sentence different syntactic realization recent study rely typical encoderdecoder framework generation process deterministic however practice ability generate multiple syntactically different paraphrase important recent work proposed cooperate variational inference targetrelated latent variable introduce diversity latent variable may contaminated semantic information unrelated sentence turn change conveyed meaning generated paraphrase paper propose semantically consistent syntactically variational encoderdecoder framework us adversarial learning ensure syntactic latent variable semanticfree moreover adopt another discriminator improve wordlevel sentencelevel semantic consistency proposed framework generate multiple semantically consistent syntactically different paraphrase experiment show model outperforms baseline model metric based ngram matching semantic similarity model generate multiple different paraphrase assembling different syntactic variable
ecpe emotion cause pair extraction task introduced solve shortcoming ece emotion cause extraction model sequential data processing ability complex architecture utilized solve task contribution solving subtask textual emotioncause pair extraction conversation defined semeval task competition multimodal emotion cause analysis conversation create twostep solution ecpe task utilizing gpt emotion classification spanbert extracting cause utterance
pretrained language model plms trained massive corpus often need specialize specific domain parameterefficient adaptation method suggests training adapter domain task language modeling lead good indomain score impractical domain resourcerestricted setting solution use relateddomain adapter novel domain test time paper introduce adaptersoup approach performs weightspace averaging adapter trained different domain approach embarrassingly parallel first train set domainspecific adapter novel domain determine adapter averaged test time present extensive experiment showing adaptersoup consistently improves performance new domain without extra training also explore weight averaging adapter trained domain different hyperparameters show preserve performance plm new domain obtaining strong indomain result explore various approach choosing adapter combine text clustering semantic similarity find using clustering lead competitive result novel domain
paper present freely available corpus automatic translation accompanied postedited version annotated label identifying different kind error made mt system data extracted translation student exercise corrected senior professor corpus useful training quality estimation tool analyzing type error made mt system
explore authentic counterhate argument online hateful content toward individual previous effort limited counterhate fight hateful content toward group thus present corpus hateful tweetparagraph pair paragraph candidate counterhate argument counterhate argument retrieved online article multiple source propose methodology assures authenticity counter argument specificity individual interest show finding argument online article efficient alternative counterhate generation approach may hallucinate unsupported argument also present linguistic insight language used counterhate argument experimental result show promising result challenging however identify counterhate argument hateful content toward individual included training set
abstraction core tenet human cognition communication composing natural language instruction human naturally evoke abstraction convey complex procedure efficient concise way yet interpreting grounding abstraction expressed nl yet systematically studied nlp accepted benchmark specifically eliciting abstraction nl work set foundation systematic study processing grounding abstraction nlp first deliver novel abstraction elicitation method present hexagon instructionfollowing game using hexagon collected k naturally occurring visuallygrounded instruction rich diverse type abstraction data derive instructiontoexecution task assess different type neural model result show contemporary model modeling practice substantially inferior human performance model performance inversely correlated level abstraction showing less satisfying performance higher level abstraction finding consistent across model setup confirming abstraction challenging phenomenon deserving attention study nlpai research
article describes system submitted citiusixaimaxin team discriminating similar language shared task system based two different strategy classification ranked dictionary naive bayes classifier result evaluation show ranking dictionary sound stable across different domain basic bayesian model perform reasonably well indomain datasets performance drop applied outofdomain text
paper present novel resourceinexpensive architecture metaphor detection based residual bidirectional long shortterm memory conditional random field current approach task rely deep neural network identify metaphorical word using additional linguistic feature word embeddings evaluate proposed approach using different model configuration combine embeddings part speech tag semantically disambiguated synonym set evaluation process performed using training testing partition vu amsterdam metaphor corpus use method evaluation reference compare result current neural approach task implement similar neural architecture feature evaluated using corpus result show system achieves competitive result simpler architecture compared previous approach
despite narrowed performance gap direct approach cascade solution involving automatic speech recognition asr machine translation mt still largely employed speech translation st direct approach employing single model translate input speech signal suffer critical bottleneck data scarcity addition multiple industry application display speech transcript alongside translation making cascade approach realistic practical context cascaded simultaneous st propose several solution adapt neural mt network take input transcript output asr system adaptation achieved enriching speech transcript mt data set closely resemble thereby improving system robustness error propagation enhancing result legibility human address aspect sentence boundary capitalisation punctuation hesitation repetition homophone etc taking account low latency requirement simultaneous st system
assessing credibility online content garnered lot attention lately focus one type online content namely weblogs blog short recent work attempted task automatically assessing credibility blog typically via machine learning however case arabic blog hardly datasets available used train robust machine learning model difficult task overcome lack sufficient training data propose deep colearning semisupervised endtoend deep learning approach assess credibility arabic blog deep colearning multiple weak deep neural network classifier trained using small labeled dataset using different view data one classifier used classify unlabeled data prediction used train classifier semisupervised fashion evaluate deep colearning approach arabic blog dataset report significant improvement performance compared many baseline including fullysupervised deep learning model well ensemble model
rapid proliferation disinformation social medium become one dangerous mean deceive influence people thought viewpoint behavior due social medias facility rapid access lower cost ease use disinformation spread social medium different way fake news story doctored image video deceptive data even conspiracy theory thus making detecting disinformation challenging paper part participation araieval competition relates disinformation detection work evaluated four model marbert proposed ensemble model two test gpt zeroshot fewshot gpt achieved microf ensemble method obtained despite improvement microf score dev dataset using ensemble approach still used test dataset prediction believed merging different classifier might enhance system prediction accuracy
ultrafine entity typing ufet task inferring semantic type large set finegrained candidate apply given entity mention task especially challenging small number training example many type even distant supervision strategy stateoftheart model therefore rely prior knowledge type label way paper show performance existing method improved using simple technique use pretrained label embeddings cluster label semantic domain treat domain additional type show strategy consistently lead improved result long highquality label embeddings used furthermore use label cluster part simple postprocessing technique result performance gain strategy treat ufet model black box thus straightforwardly used improve wide range existing model
logical reasoning vital importance natural language understanding previous study either employ graphbased model incorporate prior knowledge logical relation introduce symbolic logic neural model data augmentation method however heavily depend annotated training data thus suffer overfitting poor generalization problem due dataset sparsity address two problem paper propose merit metapath guided contrastive learning method logical reasoning text perform selfsupervised pretraining abundant unlabeled text data two novel strategy serve indispensable component method particular strategy based metapath devised discover logical structure natural text followed counterfactual data augmentation strategy eliminate information shortcut induced pretraining experimental result two challenging logical reasoning benchmark ie reclor logiqa demonstrate method outperforms sota baseline significant improvement
investigate two research question machine translation mt diacritization influence performance multitask learning setting effect keeping v removing diacritic mt performance examine two question highresource hr lowresource lr setting across different language african language european language result show diacritization significantly benefit mt lr scenario doubling even tripling performance language harm mt hr scenario find mt harm diacritization lr benefit significantly hr language mt performance similar regardless diacritic kept removed addition propose two class metric measure complexity diacritical system finding metric correlate positively performance diacritization model overall work provides insight developing mt diacritization system different data size condition may implication generalize beyond language investigate
present article describes first stage korap project launched recently institut fur deutsche sprache id mannheim germany aim project develop innovative corpus analysis platform tackle increasing demand modern linguistic research platform facilitate new linguistic finding making possible manage analyse primary data annotation petabyte range time allowing undistorted view primary linguistic data thus fully satisfying demand scientific tool additional important aim project make corpus data openly accessible possible light unavoidable legal restriction instance support distributed virtual corpus userdefined annotation adaptable user interface well interface sandbox usersupplied analysis application discus motivation undertaking endeavour challenge face next outline software implementation plan describe development todate
translation divergence varied widespread challenging approach rely parallel text annotate translation divergence propose schema grounded abstract meaning representation amr sentencelevel semantic framework instantiated number language comparing parallel amr graph identify specific point divergence divergence labeled type cause release small corpus annotated englishspanish data analyze annotation corpus
universal morphology unimorph project collaborative effort providing broadcoverage instantiated normalized morphological paradigm hundred diverse world language project comprises two major thrust languageindependent feature schema rich morphological annotation typelevel resource annotated data diverse language realizing schema implemented several improvement extraction pipeline creates data complete correct added new language well new part speech language also amended schema several way finally present three new community tool two validate data resource creator one make morphological data available command line unimorph based center language speech processing clsp john hopkins university baltimore maryland paper detail advance made schema tooling dissemination project resource since unimorph release described lrec
autoregressive transformer strong language model incur ot complexity pertoken generation due selfattention mechanism recent work proposes kernelbased method approximate causal selfattention replacing recurrent formulation various update rule feature map achieve time memory complexity explore approach find unnecessarily complex propose simple alternative decaying fast weight run fast gpu outperforms prior method retains attention performance gpt also show competitive performance wikitext complex attention substitute
given question regarding prototypical situation name something people usually leave house work human easily answer via acquired experience multiple right answer question common situation others paper introduces new question answering dataset training evaluating common sense reasoning capability artificial intelligence system prototypical situation training set gathered existing set question played longrunning international trivia game show family feud hidden evaluation set created gathering answer question crowdworkers also propose generative evaluation task model output ranked list answer ideally covering prototypical answer question presenting multiple competitive baseline model find human performance still exceeds model score evaluation metric meaningful gap supporting challenging nature task
humor essential fascinating element personal communication build computational model discover structure humor recognize humor even generate humor remains challenge yet attempt paper construct collect four datasets distinct joke type english chinese conduct learning experiment humor recognition implement convolutional neural network cnn extensive filter size number highway network increase depth network result show model outperforms recognition different type humor benchmark collected english chinese language accuracy precision recall comparison previous work
paper present submission huawei translate service center hwtsc wmt general machine translation mt shared task participate chineseenglish zhen language pair use transformer architecture obtain best performance via variant larger parameter size perform finegrained preprocessing filtering provided largescale bilingual monolingual datasets mainly use model enhancement strategy including regularized dropout bidirectional training data diversification forward translation back translation alternated training curriculum learning transductive ensemble learning submission obtain competitive result final evaluation
paper explore solution common sense making task model must discern two sentence common sense used pretrained language model used calculate complexity score input discern sentence contained unlikely sequence token approach tested word vector distance used find semantic outlier within sentence siamese network using pretrained language model calculate perplexity score based sequence token input sentence achieved accuracy percent
continuous effort devoted language understanding lu conversational query fast widespread popularity voice assistant paper first study lu problem spatial domain critical problem providing locationbased service voice assistant without indepth investigation existing study spatial domain query several unique property making challenging language understanding common conversational query including lexicalsimilar diverse intent highly ambiguous word thus special tailored lu framework spatial domain query necessary end dataset extracted annotated based reallife query voice assistant service proposed new multitask framework jointly learns intent detection entity linking task invented hierarchical intent detection method triplescoring mechanism entity linking specially designed spatial gcn also utilized model spatial context information among entity conducted extensive experimental evaluation stateoftheart entity linking intent detection method demonstrated outperform baseline significant margin
paper present result shared task th workshop asian translation wat including je jc scientific paper translation subtasks cj kj ej patent translation subtasks mixed domain subtasks je newswire subtasks je recipe subtasks wat institution participated shared task translation result submitted automatic evaluation server selected submission manually evaluated
universal schema predicts type entity relation knowledge base kb jointly embedding union available schema typesnot type multiple structured database freebase wikipedia infoboxes also type expressed textual pattern raw text prediction typically modeled matrix completion problem one type per column either one two entity per row case entity type binary relation type respectively factorizing sparsely observed matrix yield learned vector embedding row column paper explore problem making prediction entity entitypairs unseen training time hence without prelearned row embedding propose approach perrow parameter rather produce row vector fly using learned aggregation function vector observed column row experiment various aggregation function including neural network attention model approach understood natural language database question kb entity answered attending textual database evidence experiment predicting relation entity type demonstrate despite order magnitude fewer parameter traditional universal schema match accuracy traditional model importantly make prediction unseen row nearly accuracy row available training time
advent html sparked great increase interest web development platform variety different research application due ability easily deploy software remote client recent development standardized browser apis argue browser become good platform develop speech labeling tool paper introduces preliminary version opensource clientside web application labeling speech data visualizing speech segmentation information manually correcting derived speech signal formant trajectory user interface designed userfriendly possible order make sometimes tedious task transcribing easy efficient possible future integration next iteration emu speech database management system general architecture also outlined work presented one several component contributing future system
last year increasing number publicly available semantically annotated medical corpus released german language annotation cover comparable semantic class synergy effort explored yet due substantial difference data schema syntax annotated entity semantics hinder creation common metadatasets instance unclear whether named entity recognition ner tagger trained one datasets useful detect entity datasets work create harmonized version german medical corpus using bigbio framework make available community using metadataset perform series crosscorpus evaluation experiment two setting aligned label consist finetuning various pretrained transformer different combination training set testing dataset separately find trained ner model generalize poorly f score dropping approx pp unseen test data b current pretrained transformer model german language systematically alleviate issue however result suggest model benefit additional training corpus case even belong different medical field text genre
present neural framework learning association interrelated group word one found subjectverbobject svo structure model induces joint functionspecific word vector space vector eg plausible svo composition lie close together model retains information word group membership even joint space thereby effectively applied number task reasoning svo structure show robustness versatility proposed framework reporting stateoftheart result task estimating selectional preference event similarity result indicate combination representation learned taskindependent model outperform taskspecific architecture prior work reducing number parameter
although automated metric commonly used evaluate nlg system often correlate poorly human judgement newer metric bertscore addressed many weakness prior metric bleu rouge rely ngram matching newer method however still limited consider generation context properly reward generated text correct deviate given reference paper propose language model augmented relevance score mar new contextaware metric nlg evaluation mar leverage offtheshelf language model guided reinforcement learning create augmented reference consider generation context available human reference used additional reference score generated text compared seven existing metric three common nlg task mar achieves higher correlation human reference judgement also differentiates wellformed candidate adversarial sample larger degree
many potential benefit news reader accessing diverse source modern news aggregator hard work organizing news offering reader plethora source option choosing source read remains challengingwe propose new framework assist reader identifying source difference gaining understanding news coverage diversitythe framework based generation discord question question diverse answer pool explicitly illustrating source differencesto assemble prototype framework focus two component discord question generation task generating question answered differently source propose automatic scoring method create model improves performance current question generation qg method answer consolidation task grouping answer question semantically similar collect data repurpose method achieves balanced accuracy realistic test setwe illustrate framework feasibility prototype interface even though model performance discord qg still lag human performance generated question judged interesting factoid question reveal difference level detail sentiment reasoning source news coverage code available httpsgithubcomsalesforcediscordquestions
work introduces fact salience task generating machinereadable representation prominent information text document set fact also present salie first fact salience system salie unsupervised knowledge agnostic based open information extraction detect fact natural language text pagerank determine relevance clustering promote diversity compare salie several baseline including positional standard saliency task extrinsic evaluation stateoftheart automatic text summarizers salie outperforms baseline text summarizers showing fact effective way compress information
hypernymy detection task addressed various framework previously design unsupervised hypernymy score extensively studied contrast supervised classifier especially distributional model leverage global context term make prediction likely suffer lexical memorization work revisit supervised distributional model hypernymy detection rather taking embeddings two term classification input introduce representation learning framework named bidirectional residual relation embeddings birre model term pair represented birre vector feature hypernymy classification model possibility term mapped another embedding space hypernymy relation latent projection model negative regularization lpmnr proposed simulate hypernym hyponym generated neural language model generate birre vector based bidirectional residual projection experiment verify birre outperforms strong baseline various evaluation framework
sentiment analysis often used examine different actor portrayed medium analysis news headline particular interest due attentiongrabbing role address task entitylevel sentiment analysis croatian news headline frame task targeted sentiment analysis tsa explicitly differentiating sentiment toward named entity overall tone headline describe stone new dataset task sentiment tone label implement several neural benchmark model utilizing single multitask training show tsa benefit tone information finally gauge difficulty task leveraging dataset cartography
paper describe abstractive text summarization method improved informativeness automatic summary integrating syntactic text simplification subjectverbobject concept frequency scoring set rule transform text semantic representation analyzed impact component approach quality generated summary tested duc dataset experiment showed approach outperformed stateoftheart abstractive method maintaining acceptable linguistic quality redundancy rate
paper describe language resource developed within project feedback acquisition syntax oral proficiency fasop aimed investigating effectiveness various form practice feedback acquisition syntax second language l oral proficiency well interplay learner characteristic education level learner motivation confidence purpose use made computer assisted language learning call system employ automatic speech recognition asr technology allow spoken interaction create experimental environment guarantee much control language learning setting possible focus present paper resource produced fasop line theme conference present different type resource developed within project way could used pursue innovative research second language acquisition develop improve asrbased language learning application
automatic chinese irony detection challenging task strong impact linguistic research however chinese irony detection often lack labeled benchmark datasets paper introduce ciron first chinese benchmark dataset available irony detection machine learning model ciron includes k post collected weibo micro blogging platform importantly ciron collected precondition ensure much wider coverage evaluation seven different machine learning classifier prof usefulness ciron important resource chinese irony detection
semantic verbal fluency task svf efficient minimally invasive speechbased screening tool mild cognitive impairment mci svf testee produce many word given semantic category possible within second stateoftheart approach automatic evaluation svf employ word embeddings analyze semantic similarity word sequence approach proven promising variety test language small amount data available given language limit performance paper first time investigate multilingual learning approach mci classification svf order combat data scarcity allow crosslanguage generalisation approach either rely translation shared language make use several distinct word embeddings evaluation multilingual corpus older french dutch german participant control mci show multilingual approach clearly improve singlelanguage baseline
paper present exploration annotating chinese word sens using english wordnet synset example extracted ontonotes chinese sense inventory given target word along example contains annotator select wordnet synset best describes meaning target word context result demonstrates interannotator agreement two annotator delve instance disagreement comparing two annotated synset including position within wordnet hierarchy examination reveals intriguing pattern among closely related synset shedding light similar concept represented within wordnet structure data offer indirect linking chinese word sens defined ontonotes chinese sense inventory wordnet sysnets thus promotes value ontonotes corpus compared direct linking chinese word sens wordnet synset examplebased annotation merit affected inaccurate sense definition thus offer new way mapping wordnet different language time annotated data also serf valuable linguistic resource exploring potential lexical difference english chinese potential contribution broader understanding crosslinguistic semantic mapping
social mediabased text mining healthcare received special attention recent time due enhanced accessibility social medium site like twitter increasing trend spreading important information distress help patient reach prospective blood donor time bound manner however manual effort mostly inefficient due limited network user novel step solve problem present annotated emergency blood donation request ebdr dataset classify tweet referring necessity urgent blood donation requirement additionally also present automated featurebased svm classification technique help selective ebdr tweet reach relevant personal well medical authority experiment also present quantitative evidence linguistic along handcrafted heuristic act representative set signal task accuracy
ability track mental health condition via social medium opened door largescale automated mental health surveillance however inferring accurate populationlevel trend requires representative sample underlying population challenging given bias inherent social medium data previous work adjusted sample based demographic estimate population selected based specific outcome eg specific mental health condition depart method conducting analysis demographically representative digital cohort social medium user validated approach constructed cohort u based twitter user measure prevalence depression ptsd investigate illness manifest across demographic subpopulation analysis demonstrates cohortbased study help control sampling bias contextualize outcome provide deeper insight data
main motivation developing contextsensitive lemmatizers improve performance unseen ambiguous word yet previous system carefully evaluated whether use context actually help case introduce lematus lemmatizer based standard encoderdecoder architecture incorporates characterlevel sentence context evaluate lemmatization accuracy across language full data setting lowerresource setting k training example language setting show including context significantly improves result contextfree version model context help ambiguous word unseen word though latter greater effect overall performance difference language also compare three previous contextsensitive lemmatization system use preextracted edit tree well handselected feature andor additional source information tagged training data without using contextsensitive model outperforms best competitor system lemming fulldata setting performs par lowerresource setting
deep neural network empowered pretrained language model achieved remarkable result natural language understanding nlu task however performance drastically deteriorate logical reasoning needed nlu principle depends analogical reasoning deep neural network good also logical reasoning according dualprocess theory analogical reasoning logical reasoning respectively carried system system human brain inspired theory present novel framework nlu called neuralsymbolic processor nsp performs analogical reasoning based neural processing logical reasoning based neural symbolic processing case study conduct experiment two nlu task question answering qa natural language inference nli numerical reasoning type logical reasoning necessary experimental result show method significantly outperforms stateoftheart method task
deep learning recently shown much promise nlp application traditionally nlp approach document sentence represented sparse bagofwords representation lot work go beyond adopting distributed representation word constructing socalled neural embedding vector space representation word document aim tutorial go beyond learning word vector present method learning vector representation multiword expression bilingual phrase pair useful various nlp applicationsthis tutorial aim provide attendee clear notion linguistic distributional characteristic multiword expression mwes relevance intersection deep learning natural language processing method resource available support use could done future target audience researcher practitioner machine learning parsing syntactic semantic language technology necessarily expert mwes interested task involve could benefit considering mwes pervasive phenomenon human language communication
instruction tuning aligns response large language model llm human preferencesdespite effort humanllm alignment find instruction tuning always make llm humanlike cognitive modeling perspective specifically nextword probability estimated instructiontuned llm often worse simulating human reading behavior estimated base llmsin addition explore prompting methodology simulating human reading behavior llm result show prompt reflecting particular linguistic hypothesis improve psychometric predictive power still inferior small base modelsthese finding highlight recent advancement llm ie instruction tuning prompting offer better estimate direct probability measurement base llm cognitive modeling word pure nextword probability remains strong predictor human reading behavior even age llm
knowledge base increasingly exploited gold standard data source benefit various knowledgedriven nlp task paper explore new research direction perform knowledge base kb representation learning grounded recent theoretical framework knowledge distillation neural network given set kb proposed approach kdmkb learns kb embeddings mutually jointly distilling knowledge within dynamic teacherstudent setting experimental result two standard datasets show knowledge distillation kb entity relation inference actually observed also show cooperative learning significantly outperforms two proposed baseline namely traditional sequential distillation
babel briefing novel dataset featuring million news headline august november across language location worldwide english translation article included designed natural language processing medium study serf highquality dataset training evaluating language model well offering simple accessible collection article example analyze global news coverage cultural narrative simple demonstration analysis facilitated dataset use basic procedure using tfidf weighted similarity metric group article cluster event visualize textitevent signature event showing article language appear time revealing intuitive feature based proximity event unexpectedness event dataset available kagglehttpswwwkagglecomdatasetsfelixludosbabelbriefings huggingfacehttpshuggingfacecodatasetsfelixludosbabelbriefings accompanying githubhttpsgithubcomfelixludosbabelbriefings code
vent specialised iosandroid social medium platform stated goal encourage people post feeling explicitly label paper study snapshot million message obtained developer vent together label assigned author message establish quality selfannotated data conducting qualitative analysis vocabulary based analysis training testing emotion classifier conclude selfannotated label corpus indeed indicative emotional content expressed text thus support detailed analysis emotion expression social medium emotion trajectory factor influencing
personal note coling sixth international conference cl guy rondeau letter yorick wilks logo mt fondazione dalle molle award afips honor iverson astrahan nsf chapin new program officer linguistics acm forsythe student paper competition national computer conference hammer winkler aaa section new name fellowship program joseph becker ottawa linguistics documentation centre thomas r hofmann mt mat list system center herbert bruderer nfais officer ben h weil abstracting indexing world inventory service gaye hofsman toni carbo bearman
comprehending article requires understanding constituent event however context event mentioned often lack detail event question arises reader obtain knowledge particular event addition provided local context article work defines event linking new natural language understanding task event level event linking try link event mention appearing article appropriate wikipedia page page expected provide rich knowledge event mention refers standardize research new direction contribute fourfold first first work community formally defines event linking task second collect dataset new task specifically automatically gather training set wikipedia create two evaluation set one wikipedia domain reporting indomain performance second realworld news domain evaluate outofdomain performance third retrain evaluate two stateoftheart sota entity linking model showing challenge event linking propose eventspecific linking system evelink set competitive result new task fourth conduct detailed insightful analysis help understand task limitation current model overall analysis show event linking challenging essential task requiring effort community
illustrate effectiveness mediumsized carefully tagged bilingual core corpus semantic typology pattern term together example give concrete evidence usefulness important characteristic semantic typology pattern bridging mechanism two language based sequence syntactic code semantic code characteristic give wide coverage flexible applicability core bilingual core corpus though volume size large work done grasping intuitive feeling pertinent coarseness fineness pattern coarseness feeling concerning generalization phraselevel clauselevel semantic pattern fineness concerning wordlevel semantic pattern based feeling complete core tagged bilingual corpus enhancing necessary support function utility
widespread fake news detrimental societal effect recent work model information propagation graph structure aggregate structural feature user interaction fake news detection however usually neglect broader propagation uncertainty issue caused missing unreliable interaction actual spreading suffer learning accurate diverse structural property paper propose novel dual graphbased model uncertaintyaware propagation structure reconstruction upsr improving fake news detection specifically original propagation modeling introduce propagation structure reconstruction fully explore latent interaction actual propagation design novel gaussian propagation estimation refine original deterministic node representation multiple gaussian distribution arise latent interaction kl divergence distribution multifacet manner extensive experiment two realworld datasets demonstrate effectiveness superiority model
fertility intention verbalized survey poor predictor actual fertility outcome number child people partly explained uncertainty people intention uncertainty hard capture traditional survey question although openended question used get insight people subjective narrative future determine intention analyzing answer openended question done natural language processing technique traditional topic model eg lsa lda however often fail since rely cooccurrences often rare short survey response aim study apply evaluate topic model demographic survey data study applied neural topic model eg bertopic combinedtm based language model response dutch woman fertility plan compared topic coherence score model expert judgment result show neural model produce topic line human interpretation compared lda however coherence score could partly reflect depending corpus used calculation research important first help u develop informed strategy model selection evaluation topic modeling survey data second show field demography much gain adopting nlp method
study problem grounding distributional representation text visual domain namely visualsemantic embeddings vse short begin insightful adversarial attack vse embeddings show limitation current framework imagetext datasets eg mscoco quantitatively qualitatively large gap number possible constitution realworld semantics size parallel data large extent restricts model establish strong link textual semantics visual concept alleviate problem augmenting mscoco image captioning datasets textual contrastive adversarial sample sample synthesized using language prior human wordnet knowledge base enforce model ground learned embeddings concrete concept within image simple powerful technique brings noticeable improvement baseline diverse set downstream task addition defending knowntype adversarial attack code available urlhttpsgithubcomexplorerfredavsec
counterspeech proposed solution proliferation online hate research shown natural language processing nlp approach could generate counterspeech automatically competing idea nlp model might used task variety evaluation metric whose relationship one another unclear test three different approach collect rating generated counterspeech tweetparticipant pair systematically compare counterspeech three aspect quality effectiveness user preference examine model performs best metric aspect counterspeech predict user preference freeform text generation approach using chatgpt performs consistently well though generation occasionally unspecific repetitive experiment participant preference counterspeech predicted quality counterspeech perceived effectiveness result help future research approach counterspeech evaluation systematically
present main finding mup shared task first shared task multiperspective scientific document summarization task provides testbed representing challenge summarization scientific document facilitates development better model leverage summary generated multiple perspective received total submission team evaluated submission automated metric ie rouge human judgment faithfulness coverage readability provided nuanced view difference system observe encouraging result participating team conclude still significant room left improving summarization leveraging multiple reference dataset available urlhttpsgithubcomallenaimup
recent study achieved inspiring success unsupervised grammar induction using masked language modeling mlm proxy task despite high accuracy identifying lowlevel structure prior art tend struggle capturing highlevel structure like clause since mlm task usually requires information local context work revisit lmbased constituency parsing phrasecentered perspective inspired natural reading process human propose regularize parser phrase extracted unsupervised phrase tagger help lm model quickly manage lowlevel structure better understanding highlevel structure propose phraseguided masking strategy lm emphasize reconstructing nonphrase word show initial phrase regularization serf effective bootstrap phraseguided masking improves identification highlevel structure experiment public benchmark two different backbone model demonstrate effectiveness generality method
recently prefixtuning proposed efficiently adapt pretrained language model broad spectrum natural language classification task leverage soft prefix taskspecific indicator language verbalizer categoricallabel mention narrow formulation gap pretraining language model however label space increase considerably ie manyclass classification tuning technique suffers verbalizer ambiguity problem since manyclass label represented semanticsimilar verbalizer short language phrase overcome inspired humandecision process ambiguous class would mulled instance propose brandnew prefixtuning method counterfactual contrastive prefixtuning ccprefix manyclass classification basically instancedependent soft prefix derived factcounterfactual pair label space leveraged complement language verbalizer manyclass classification conduct experiment manyclass benchmark datasets fully supervised setting fewshot setting indicates model outperforms former baseline
topic modelling established research area quality given topic measured using coherence metric often infer topic neural topic model ntm interpreting decoder weight consisting topactivated word projected individual neuron transformerbased language model tlm similarly consist decoder weight however due hypothesised superposition property final logits originating residual path considered uninterpretable therefore posit interpret tlm superposed ntm proposing novel weightbased modelagnostic corpusagnostic approach search disentangle decoderonly tlm potentially mapping individual neuron multiple coherent topic result show empirically feasible disentangle coherent topic gpt model using wikipedia corpus validate approach gpt model using zeroshot topic modelling finally extend proposed approach disentangle analyse llama model
fewshot knowledge graph completion fkgc become new research focus field knowledge graph recent year aim predict missing link relation associative triple existing model attempt solve problem via learning entity relation representation however limited training data severely hinders performance existing model end propose solve fkgc problem data augmentation technique specifically perform data augmentation two perspective ie intertask view intratask view former generates new task fkgc latter enriches support query set individual task worth noting proposed framework applied number existing fkgc model experimental evaluation two public datasets indicates model capable achieving substantial improvement baseline
introduce new resource safet speech analysis emergency response technology corpus designed simulate firstresponder communication inducing high vocal effort urgent speech situational background noise gamebased collection protocol linguistic data consortium developed safet corpus support nist national institute standard technology opensat speech analytic technology evaluation series whose goal advance speech analytic technology including automatic speech recognition speech activity detection keyword search multiple domain including simulated public safety communication data corpus comprises hour audio unique speaker engaged collaborative problemsolving activity representative public safety communication term speech content noise type noise level portion corpus used opensat evaluation full corpus published ldc catalog describe design implementation safet corpus collection discus approach capturing spontaneous speech study participant gamebased speech collection report collection result including several challenge associated collection
paper describe study portugueseenglish word alignment focusing measuring importance coupling dictionary corpus ii assessing relevance using syntactic information po lemma word form iii taking account direction translation first provide motivation study well insist separating type token anlignment briefly describe resource employed europarl compara corpus alignment tool natools introducing measure evaluate two kind dictionary obtained present result several experiment comparing size overlap translation fertility alignment density several bilingual resource built also describe preliminary data far quality resulting dictionary alignment result concerned
efficient knearest neighbor search fundamental task foundational many problem nlp similarity measured dotproduct dualencoder vector ldistance already exist many scalable efficient search method similarity measured accurate expensive blackbox neural similarity model crossencoders jointly encode query candidate neighbor crossencoders high computational cost typically limit use reranking candidate retrieved cheaper model dual encoder tfidf however accuracy twostage approach upperbounded recall initial candidate set potentially requires additional training align auxiliary retrieval model crossencoder model paper present approach avoids use dualencoder retrieval relying solely crossencoder retrieval made efficient cur decomposition matrix decomposition approach approximates pairwise crossencoder distance small subset row column distance matrix indexing item using approach computationally cheaper training auxiliary dualencoder model distillation empirically k textgreater approach provides testtime recallvscomputational cost tradeoff superior current widelyused method rerank item retrieved using dualencoder tfidf
report result wmt shared task quality estimation challenge predict quality output neural machine translation system word sentence level without access reference translation edition introduces novel aspect extension aim enable finegrained explainable quality estimation approach introduce updated quality annotation scheme using multidimensional quality metric obtain sentence wordlevel quality score three language pair also extend provided data new language pair specifically target lowresource language provide training development test data englishhindi englishtamil englishtelegu englishgujarati well zeroshot testset englishfarsi introduce novel finegrained error prediction task aspiring motivate research towards detailed quality prediction
queryfocused summarization qfs aim generate summary source document answer specific query although qfs task gained increasing attention recently development constrained fact mainstream qfs model bart variant autoregressive suffer longterm dependency exposure bias address problem adopt diffusion language model performs well nonautoregressive scenario effectively resolve issue related autoregressive method however qfs requires guidance query generate adequate summary diffusion language model limited sensitivity query paper propose qfsdlm nonautoregressive diffusion language model incorporates querydocument fragment relevance querydocument global relevance enhance adaptability qfs task firstly extract key fragment document based query assign higher weight thereby emphasizing crucial continuous information within document secondly calculate global relevance score query document integrate score model loss function enabling model prefer highquality data distance lowquality data overall method achieves stateoftheart performance debatepedia pubmedqa datasets rouge score gpt human evaluation
paper present work task automatic decomposition text editing example primitive edit operation toward detailed analysis behavior text editing system identification finegrained edit operation performed system essential given pair source edited sentence goal task generate nonredundant sequence primitive edit operation ie semantically minimal edit operation preserving grammaticality iteratively convert source sentence edited sentence first formalize task explaining significant feature specifying constraint primitive edit operation satisfy propose method automate task consists two step generation edit operation lattice selection optimal path obtain wide range edit operation candidate first step combine phrase aligner large language model experimental result show method perfectly decomposes editing example text simplification machine translation postediting datasets respectively detailed analysis also provide insight difficulty task suggesting direction improvement
paper present methodology rapidly generating fstbased verbalizer asr tt system efficiently sourcing languagespecific data describe questionnaire collect necessary data bootstrap number grammar induction system parameterize verbalizer template described ritchie et al machinereadable data store allows data collected questionnaire supplemented additional data source system allows u rapidly scale technology asr tt language including lowresource language
neural abstractive summarization model drastically improved recent year however summary generated model generally suffer issue capturing critical fact source document containing fact inconsistent source document work present general framework train abstractive summarization model alleviate issue first train sequencetosequence model summarize document train model reinforcement learning setting questionanswering based reward evaluate summary generated framework using multiple automatic measure human judgement experimental result show questionanswering reward used general framework improve neural abstractive summarization particularly result human evaluation show summary generated approach preferred time summary generated general abstractive summarization model
automatically analyse complex trajectory information enclosed clinical text eg timing symptom duration treatment important understand related temporal aspect anchoring event absolute point time clinical domain temporally annotated corpus currently available moreover underlying annotation schema mainly rely timeml standard necessarily easily applicable application patient timeline reconstruction work investigated temporal information documented clinical text annotating corpus medical report time expression timexes based timeml developed corpus available nlp community starting annotation analysed suitability timeml timex schema capturing timeline information identifying challenge possible solution result propose novel annotation schema could useful timeline reconstruction calendar expression calex
paper present system semeval task emocontext contextual emotion detection text propose deep learning architecture bidirectional lstm network augmented emotionoriented attention network capable extracting emotion information utterance experimental result show model outperforms variant baseline overall system achieved microaveraged f score
common metric evaluating automatic speech recognition asr word error rate wer solely take account discrepancy wordlevel although useful wer guaranteed correlate well human judgment performance downstream task use asr meaningful assessment asr mistake becomes even important highstake scenario healthcare propose general measure evaluate severity mistake made asr system one based sentiment analysis another based text embeddings evaluate measure simulated patientdoctor conversation using asr system result show measure capture characteristic asr error wer furthermore train asr system incorporating severity demonstrate potential using severity evaluation development asr advantage limitation methodology analyzed discussed
work investigate capability graph attention network extracting aspect opinion term aspect opinion term extraction posed tokenlevel classification task akin named entity recognition use dependency tree input query additional feature graph attention network along token partofspeech feature show dependency structure powerful feature presence crf layer substantially improves performance generates best result commonly used datasets semeval experiment additional layer like bilstm transformer addition crf layer also show approach work well presence multiple aspect sentiment query necessary modify dependency tree based single aspect original application sentiment classification
story character perform action typically also perceive feel think communicate interested child render character perspective freely telling fantasy story drawing sample narrative elicited dutch child aged provide inventory instance characterperspective representation cpr distinguishing fourteen different type firstly observe character perspective ubiquitous freely told childrens story take varied form traditional framework accommodate secondly discus variation use different type cpr across age group finding character perspective fleshed advanced diverse way child grow older thirdly explore whether variation meaningfully linked automatically extracted linguistic feature thereby probing potential using automated tool nlp extract classify character perspective childrens story
opaque nature unexplained behavior transformerbased language model lm spurred wide interest interpreting prediction however current interpretation method mostly focus probing model outside executing behavioral test analyzing salience input feature internal prediction construction process largely understood work introduce lmdebugger interactive debugger tool transformerbased lm provides finegrained interpretation model internal prediction process well powerful framework intervening lm behavior backbone lmdebugger relies recent method interprets inner token representation update feedforward layer vocabulary space demonstrate utility lmdebugger singleprediction debugging inspecting internal disambiguation process done gpt moreover show easily lmdebugger allows shift model behavior direction user choice identifying vector network inducing effective intervention prediction process release lmdebugger opensource tool demo gpt model
describe two nmt system submitted wmt shared task englishczech news translation cunidoctransformer documentlevel cubbitt cunimarianbaselines improve former better sentencesegmentation preprocessing postprocessing fixing error number unit use latter experiment various backtranslation technique
describe shared task clpsych workshop focused predicting current future psychological health essay authored childhood languagebased prediction person current health potential supplement traditional psychological assessment questionnaire improving intake risk measurement monitoring prediction future psychological health aid early detection development preventative care research mental health trajectory people beginning childhood thus far area little work within nlp community shared task represents one first attempt evaluate use early language predict future health potential support wide variety clinical health care task early assessment lifetime risk mental health problem optimal timing targeted intervention aimed prevention treatment
high performance obtained highresource language performance lowresource language lag behind paper focus parsing lowresource language frisian use sample codeswitched spontaneously spoken data prof challenging setup propose train parser specifically tailored towards target domain selecting instance multiple treebanks specifically use latent dirichlet allocation lda word character ngrams use deep biaffine parser initialized mbert best single source treebank nlalpino resulted la whereas data selection outperformed single best transfer treebank led la test data additional experiment consisted removing diacritic frisian data creating similar training data cropping sentence running best model using xlmr experiment lead better performance
short length multitargets target relationship monetary expression outside reference characteristic financial tweet paper proposes method extract target span tweet referencing web page total publicly available sentiment dictionary one sentiment dictionary constructed training set containing sentiment score binary real number used compute sentiment score text span moreover correlation coefficient price return two stock learned price data bloomberg used capture relationship interesting target stock mentioned tweet best result method subtask evaluated evaluation method
continuous growth large language model process finetuning model new task become increasingly parameterintensive prompt tuning method involves tuning small set soft prompt emerged effective efficient approach adapting large pretrained language model however existing prompt tuning approach introduce prompt input layer limiting performance leaving large room improvement work propose novel attention prompt tuning method namely aprompt efficient adaptation pretrained language model first demonstrate existing prompt tuning considered special case attention prompt tuning formally introduce aprompt incorporates query key value prompt attention layer guide attention computation finetuning experimental result superglue benchmark consistently demonstrate proposed approach outperforms stateoftheart baseline full finetuning method pretrained model different scale addition comprehensive set ablation study validate effectiveness prompt design well efficiency approach
crosslingual transfer highresource transfer language used improve accuracy lowresource task language invaluable tool improving performance natural language processing nlp lowresource language however given particular task language clear language transfer standard strategy select language based ad hoc criterion usually intuition experimenter since large number feature contribute success crosslingual transfer including phylogenetic similarity typological property lexical overlap size available data even enlightened experimenter rarely considers factor particular task hand paper consider task automatically selecting optimal transfer language ranking problem build model consider aforementioned feature perform prediction experiment representative nlp task demonstrate model predicts good transfer language much better ad hoc baseline considering single feature isolation glean insight feature informative different nlp task may inform future ad hoc selection even without use method
recently topic modeling widely applied data mining due powerful ability common major challenge applying topic model task accurately interpret meaning topic topic labeling major interpreting method attracted significant attention recently however previous work focus effectiveness topic labeling less attention paid quickly creating good topic descriptor meanwhile hard assign label new emerging topic using existing method solve problem paper propose novel fast topic labeling framework cast labeling problem knearest neighbor knn search problem probability vector set experimental result show proposed sequential interleaving method based locality sensitive hashing lsh technology efficient boosting comparison speed among probability distribution proposed framework generate meaningful label interpret topic including new emerging topic
describe lmu munich unsupervised machine translation system englishgerman translation system used participate wmt news translation shared task specifically unsupervised learning subtrack system trained english german monolingual data exploit combine previously proposed technique using wordbyword translated data based bilingual word embeddings denoising onthefly backtranslation
ever growing amount textual data large variety language domain genre become standard evaluate nlp algorithm multiple datasets order ensure consistent performance across heterogeneous setup however multiple comparison pose significant challenge traditional statistical analysis method nlp lead erroneous conclusion paper propose replicability analysis framework statistically sound analysis multiple comparison algorithm nlp task discus theoretical advantage framework current statistically unjustified practice nlp literature demonstrate empirical value across four application multidomain dependency parsing multilingual po tagging crossdomain sentiment classification word similarity prediction
generative dialogue model suffer badly generic response problem limiting application toy scenario recently interesting approach namely negative training proposed alleviate problem reminding model generate highfrequency response training however performance hindered two issue ignoring lowfrequency generic response bringing lowfrequency meaningless response paper propose novel negative training paradigm called negative distillation keep model away undesirable generic response avoiding problem first introduce negative teacher model produce querywise generic response student model required maximize distance multilevel negative knowledge empirical result show method outperforms previous negative training method significantly
clinical phenotyping enables automatic extraction clinical condition patient record beneficial doctor clinic worldwide however current stateoftheart model mostly applicable clinical note written english therefore investigate crosslingual knowledge transfer strategy execute task clinic use english language small amount indomain data available result reveal two strategy outperform stateoftheart translationbased method combination domainspecific encoders crosslingual encoders plus adapter find strategy perform especially well classifying rare phenotype advise method prefer situation result show using multilingual data overall improves clinical phenotyping model compensate data sparseness
paper describes creation syntactically annotated tibetan corpus corpus form part tusnelda collection corpus database linguistic research ultimately comprise spoken written tibetan text originating different region historical epoch text annotated several kind linguistic information particular po tag phrase argument structure verb clause sentence well several kind discourse unit textual segment annotation done xml primary research interest guide development corpus investigation crossclausal reference especially relation empty argument ie argument overtly realised clause antecedent previous clause purpose reference explicitly encoded qualitatively quantitatively evaluated help standard xml technique xpath search xslt transformation apart primary research interest expect corpus useful project concerning tibetan related language like data tusnelda made accessible via www query interface
recent work aimed discovering ontological relation text corpus approach based assumption verb typically indicate semantic relation concept however problem finding appropriate generalization level verb argument respect given taxonomy received much attention ontology learning community paper address issue determining appropriate level abstraction binary relation extracted corpus respect given concept hierarchy purpose reuse technique subcategorization selectional restriction acquisition community contribution work lie systematic analysis three different measure conduct experiment genia corpus genia ontology evaluate different measure comparing result approach gold standard provided one author biologist
work introduce novel algorithm solving textbook question answering tqa task describes realistic qa problem compared recent task mainly focus two related issue analysis tqa dataset first solving tqa problem requires comprehend multimodal context complicated input data tackle issue extracting knowledge feature long text lesson merging visual feature establish context graph text image propose new module fgcn based graph convolutional network gcn second scientific term spread chapter subject split tqa dataset overcome called outofdomain issue learning qa problem introduce novel selfsupervised openset learning process without annotation experimental result show model significantly outperforms prior stateoftheart method moreover ablation study validate method incorporating fgcn extracting knowledge multimodal context newly proposed selfsupervised learning process effective tqa problem
task unsupervised bilingual lexicon induction ubli aim induce word translation monolingual corpus two language previous work shown morphological variation intractable challenge ubli task induced translation failure case usually morphologically related correct translation tackle challenge propose morphologyaware alignment model ubli task proposed model aim alleviate adverse effect morphological variation introducing grammatical information learned pretrained denoising language model result show approach substantially outperform several stateoftheart unsupervised system even achieves competitive performance compared supervised method
large language model llm recently reached impressive level linguistic capability prompting comparison human language skill however relatively systematic inquiry linguistic capability latest generation llm study exist ignore remarkable ability human generalize ii focus english iii investigate syntax semantics overlook capability lie heart human language like morphology close gap conducting first rigorous analysis morphological capability chatgpt four typologically varied language specifically english german tamil turkish apply version berkos wug test chatgpt using novel uncontaminated datasets four examined language find chatgpt massively underperforms purposebuilt system particularly english overall resultsthrough lens morphologycast new light linguistic capability chatgpt suggesting claim humanlike language skill premature misleading
paper present novel neural machine translation model jointly learns translation sourceside latent graph representation sentence unlike existing pipelined approach using syntactic parser endtoend model learns latent graph parser part encoder attentionbased neural machine translation model thus parser optimized according translation objective experiment first show model compare favorably stateoftheart sequential pipelined syntaxbased nmt model also show performance model improved pretraining small amount treebank annotation final ensemble model significantly outperforms previous best model standard englishtojapanese translation dataset
abstract concept notwithstanding lack physical referent real world grounded sensorimotor experience fact image depicting concrete entity may associated abstract concept via direct indirect grounding process however link connecting concrete concept represented image abstract one still unclear investigate link conducted preliminary study collecting word association data imageabstract word pair rating identify whether association visual verbal system rely conceptual mapping goal research understand extent linguistic association could confirmed visual stimulus order starting point multimodal analysis abstract concrete concept
aspectbased sentiment analysis absa task aim extract sentiment tuples sentence recent generative method seqseq model achieved good performance formulating output sequence sentiment tuples however order sentiment tuples naturally exist generation current tuple condition previous one paper propose seqpath generate sentiment tuples path tree tree represent ton relation eg aspect term may correspond multiple opinion term path tree independent order training treat path independent target calculate average loss ordinary seqseq model path inference apply beam search constrained decoding introducing additional discriminative token applying data augmentation technique valid path automatically selected conduct experiment five task including aope aste tasd uabsa acos evaluate method four common benchmark datasets including laptop rest rest rest proposed method achieves stateoftheart result almost case
analysis word embedding property inform use downstream nlp task largely studied assessing nearest neighbor however geometric property continuous feature space contribute directly use embedding feature downstream model largely unexplored consider four property word embedding geometry namely position relative origin distribution feature vector space global pairwise distance local pairwise distance define sequence transformation generate new embeddings expose subset property downstream model evaluate change task performance understand contribution property nlp model transform publicly available pretrained embeddings three popular toolkits wordvec glove fasttext evaluate variety intrinsic task model linguistic information vector space extrinsic task use vector input machine learning model find intrinsic evaluation highly sensitive absolute position extrinsic task rely primarily local similarity finding suggest future embedding model postprocessing technique focus primarily similarity nearby point vector space
word embeddings trained predict word cooccurrence statistic lead possess different lexical property syntactic semantic etc depending notion context defined training time property manifest querying embedding space similar vector used input layer deep neural network trained solve downstream nlp problem metaembeddings combine multiple set differently trained word embeddings shown successfully improve intrinsic extrinsic performance equivalent model use one set source embeddings introduce word prism simple efficient metaembedding method learns combine source embeddings according task hand word prism learn orthogonal transformation linearly combine input source embeddings allows efficient inference time evaluate word prism comparison metaembedding method six extrinsic evaluation observe word prism offer improvement performance task
current natural language processing model work well single task yet often fail continuously learn new task without forgetting previous one retrained throughout lifetime challenge known lifelong learning stateoftheart lifelong language learning method store past example episodic memory replay training inference time however show later experiment three significant impediment needing unrealistically large memory module achieve good performance suffering negative transfer requiring multiple local adaptation step test example significantly slows inference speed paper identify three common principle lifelong learning method propose efficient metalifelong framework combine synergistic fashion achieve sample efficiency method train model manner learns better initialization local adaptation extensive experiment text classification question answering benchmark demonstrate effectiveness framework achieving stateoftheart performance using merely memory size narrowing gap multitask learning show method alleviates catastrophic forgetting negative transfer time
task converting nonstandard text standard readable text known lexical normalization almost natural language processing nlp application require text data normalized form build quality taskspecific model hence lexical normalization proven improve performance numerous natural language processing task social medium study aim solve problem lexical normalization formulating lexical normalization task sequence labeling problem paper proposes sequence labeling approach solve problem lexical normalization combination wordalignment technique goal use single model normalize text various language namely croatian danish dutch english indonesianenglish german italian serbian slovenian spanish turkish turkishgerman shared task th workshop noisy usergenerated text wnut participant expected create systemmodel performs lexical normalization translation noncanonical text canonical equivalent comprising data language proposed single multilingual model achieves overall err score intrinsic evaluation overall labeled attachment score la score extrinsic evaluation proposed method achieves highest error reduction rate err score among participant shared task study highlight effect using additional training data get better result well using pretrained language model trained multiple language rather one language
study new problem setting information extraction ie referred texttotable texttotable given text one creates table several table expressing main content text model learned texttable pair data problem setting differs existing method ie first extraction carried long text large table complex structure second extraction entirely datadriven need explicitly define schema far know previous work study problem work formalize texttotable sequencetosequence seqseq problem first employ seqseq model finetuned pretrained language model perform task also develop new method within seqseq approach exploiting two additional technique table generation table constraint table relation embeddings consider texttotable inverse problem wellstudied tabletotext make use four existing tabletotext datasets experiment texttotable experimental result show vanilla seqseq model outperform baseline method using relation extraction named entity extraction result also show method boost performance vanilla seqseq model discus main challenge proposed task code data available urlhttpsgithubcomshirleywutexttotable
objective interactive translation prediction itp paradigm computeraided translation assist professional translator offering contextbased computergenerated suggestion type stateoftheart itp system tightly coupled machine translation mt system often created adhoc purpose proposal follows resourceagnostic approach one need access inner working bilingual resource mt system bilingual resource used generate suggestion thus allowing include new resource almost seamlessly expect user tolerate proposal time set potential suggestion need filtered ranked resourceagnostic approach evaluated using set intuitive lengthbased positionbased heuristic designed determine suggestion show achieving promising result paper propose principled suggestion ranking approach using regressor multilayer perceptron achieves significantly better result
building retrievalbased dialogue model predict appropriate response based understanding multiturn context message challenging problem early model usually concatenate utterance independently encode dialogue turn may lead inadequate understanding dialogue status although researcher noticed importance context modeling multiturn response prediction systematic comparison analyze model context effectively framework unify method paper instead configuring new architecture investigate improve existing model better context modeling method specifically heuristically summarize three category turnaware context modeling strategy model context message perspective sequential relationship local relationship queryaware manner respectively turnaware context modeling tacm layer explored flexibly adapt unify context modeling strategy several advanced response selection model evaluation result three public data set indicate employing individual context modeling strategy multiple strategy consistently improve performance existing model
constructed japarapat japaneseenglish parallel patent application corpus bilingual corpus million japaneseenglish sentence pair patent application published japan united state obtained publication unexamined patent application japan patent office jpo united state patent trademark office uspto also obtained patent family information docdb bibliographic database maintained european patent office epo extracted approximately japaneseenglish document pair translation based patent family extracted sentence pair document pair using translationbased sentence alignment method whose initial translation model bootstrapped dictionarybased sentence alignment experimentally improved accuracy patent translation bleu point adding sentence pair obtained patent application sentence pair obtained web
daily spoken variety arabic often termed colloquial dialect form arabic many arabic dialect across arab world within arabic speaking community dialect vary widely region region lesser extent city city region dialect standardized taught official status however primary vehicle communication facetoface recently online large presence art well paper present first multidialectal arabic parallel corpus collection sentence standard arabic egyptian tunisian jordanian palestinian syrian arabic addition english parallel data exist naturally make corpus valuable resource many potential application arabic dialect identification machine translation
introduce first endtoend coreference resolution model show significantly outperforms previous work without using syntactic parser handengineered mention detector key idea directly consider span document potential mention learn distribution possible antecedent model computes span embeddings combine contextdependent boundary representation headfinding attention mechanism trained maximize marginal likelihood gold antecedent span coreference cluster factored enable aggressive pruning potential mention experiment demonstrate stateoftheart performance gain f ontonotes benchmark f using model ensemble despite fact first approach successfully trained external resource
recent advance machine learning demonstrated multimodal pretraining improve automatic speech recognition asr performance compared randomly initialized model even model finetuned unimodal task existing multimodal pretraining method asr task primarily focused singlestage pretraining single unsupervised task used pretraining followed finetuning downstream task work introduce novel method combining multimodal multitask unsupervised pretraining translationbased supervised midtraining approach empirically demonstrate multistage approach lead relative word error rate wer improvement baseline librispeech superb additionally share several important finding choosing pretraining method datasets
paper report effort towards acquisition construction bilingual parallel corpus french wolof nigercongo language belonging northern branch atlantic group corpus constructed part sysnetloc project currently contains frenchwolof parallel sentence drawn various source different domain paper discusses data collection procedure conversion alignment corpus well application training data neural machine translation fact using corpus able create word embedding model wolof relatively good result currently corpus used develop neural machine translation model translate french sentence wolof
present tagset annotation quantification currently use annotate certain quantified statement fictional work literature literary text feature rich variety expressing quantification including broad range lexeme express quantifier complex sentence structure express restrictor nuclear scope quantification tagset consists seven tag cover type quantification occur natural language including vague quantification generic quantification second part paper introduce german corpus annotation generalising statement form proper subset quantified statement
contrastive learning demonstrated effective unsupervised sentence representation learning given one sentence positive pair obtained passing sentence encoder twice using different dropout mask negative pair obtained taking another sentence minibatch however method suffers surface structure bias ie sentence similar surface structure regarded close semantics sentence dissimilar surface structure viewed distinct semantics lead result paraphrasing sentence dissimilar surface structure receive lower semantic similarity score inserting negative word sentence paper first verify bias collecting sentence transformation testset systematically probe existing model proposing novel split based benchmark datasets accordance semantic surface structure similarity tackle bias two aspect balancing learning target augmenting data counter bias meanwhile preserving word semantics leveraging recall loss prevent catastrophic forgetting evaluate model standard semantic textual similarity sts task using different pretrained backbone achieve stateoftheart averaged performance across sts benchmark particularly model finetuned robertabase robertalarge achieve significantly better performance benchmark datasets
paper present accwsi attentive context clustering wsi method word sense induction suitable language limited resource pretrained small corpus given ambiguous word query word set excerpt contain accwsi us attention mechanism generating contextaware embeddings distinguishing different sens assigned query word embeddings clustered provide group main common us query word method demonstrates practical applicability shedding light meaning ambiguous word ancient language classical hebrew
today probabilistic language generator fall short come producing coherent fluent text despite fact underlying model perform well standard metric eg perplexity discrepancy puzzled language generation community last year work posit abstraction natural language generation discrete stochastic processwhich allows informationtheoretic analysiscan provide new insight behavior probabilistic language generator example highprobability text dull repetitive human use language mean communicating information aiming simultaneously efficient errorminimizing manner fact psycholinguistics research suggests human choose word string subconscious goal mind formally define set string meet criterion word information content close expected information content namely conditional entropy model propose simple efficient procedure enforcing criterion generating probabilistic model call locally typical sampling automatic human evaluation show comparison nucleus topk sampling locally typical sampling offer competitive performance abstractive summarization story generation term quality consistently reducing degenerate repetition
social medium text tweet twitter contain many type nonstandard token number normalization approach handling noisy text increasing present method automatically extracting pair variant word normal form unsegmented text basis pairwise similarity approach incorporated acquired variantnormalization pair japanese morphological analysis experimental result show method extract widely covered variant large twitter data improve recall normalization without degrading overall accuracy japanese morphological analysis
present neural architecture modeling argumentative dialogue explicitly model interplay opinion holder oh reasoning challenger argument goal predicting argument successfully change oh view model two component vulnerable region detection attention model identifies part oh reasoning amenable change interaction encoding identifies relationship content oh reasoning challenger argument based evaluation discussion change view forum reddit two component work together predict oh change view outperforming several baseline posthoc analysis suggests sentence picked attention model addressed frequently successful argument unsuccessful one
paper focus unsupervised domain adaptation machine reading comprehension mrc source domain large amount labeled data unlabeled passage available target domain end propose adversarial domain adaptation framework adamrc pseudo question first generated unlabeled passage target domain ii domain classifier incorporated mrc model predict domain given passagequestion pair come classifier passagequestion encoder jointly trained using adversarial learning enforce domaininvariant representation learning comprehensive evaluation demonstrate approach generalizable different mrc model datasets ii combined pretrained largescale language model elmo bert iii extended semisupervised learning
paper present methodology corpus design used study comparison influence linguistic nudge positive negative influence three conversational agent robot smart speaker human recruited fortynine participant form six group conversational agent first asked participant willingness adopt five ecological habit invest time money ecological problem participant asked question preceded one linguistic nudge positive negative influence comparison standard deviation mean metric difference two note nudge showed participant mainly affected nudge positive influence even though several nudge negative influence decreased average note addition participant group willing spend money time ecological problem general experiment early result suggest machine agent influence participant degree human agent better understanding power influence different conversational machine potential influence nudge different polarity lead development ethical norm humancomputer interaction
general format natural language inference nli make tempting used zeroshot text classification casting target label sentence hypothesis verifying whether could entailed input aiming generic classification applicable specified label space opinion piece point overlooked issue yet discussed line work observe huge variance across different classification datasets amongst standard bertbased nli model surprisingly find pretrained bert without finetuning yield competitive performance bert finetuned nli concern model heavily rely spurious lexical pattern prediction also experiment preliminary approach robust nli result general negative observation reveal implicit challenging difficulty entailmentbased zeroshot text classification
many task natural language processing involve comparing two sentence compute notion relevance entailment similarity typically comparison done either word level sentence level attempt leverage inherent structure sentence sentence structure used comparison obtained nondifferentiable preprocessing step leading propagation error introduce model structured alignment sentence showing compare two sentence matching latent structure using structured attention mechanism model match candidate span first sentence candidate span second sentence simultaneously discovering tree structure sentence model fully differentiable trained matching objective evaluate model two task natural entailment detection answer sentence selection find modeling latent tree structure result superior performance analysis learned sentence structure show reflect syntactic phenomenon
quantifying uncertainty automatically generated text important letting human check potential hallucination making system reliable conformal prediction attractive framework provide prediction imbued statistical guarantee however application text generation challenging since iid assumption realistic paper bridge gap leveraging recent result nonexchangeable conformal prediction still ensures bound coverage result nonexchangeable conformal nucleus sampling novel extension conformal prediction framework generation based nearest neighbor method used posthoc arbitrary model without extra training supply tokenlevel calibrated prediction set equipped statistical guarantee experiment machine translation language modeling show encouraging result generation quality also producing tighter prediction set good coverage thus give theoretically principled way perform sampling conformal guarantee
abstract meaning representation amrs broadcoverage sentencelevel semantic representation amrs represent sentence rooted labeled directed acyclic graph amr parsing challenging partly due lack annotated alignment node graph word corresponding sentence introduce neural parser treat alignment latent variable within joint probabilistic model concept relation alignment exact inference requires marginalizing alignment infeasible use variational autoencoding framework continuous relaxation discrete alignment show joint modeling preferable using pipeline align parse parser achieves best reported result standard benchmark ldce
codemixing refers mixed use multiple language prevalent multilingual society also one challenging natural language processing task paper study bahasa rojak dialect popular malaysia consists english malay chinese aiming establish model deal codemixing phenomenon bahasa rojak use data augmentation automatically construct first bahasa rojak corpus pretraining language model name bahasa rojak crawled corpus brcc also develop new pretrained model called mixed xlm model tag language input token automatically process codemixing input finally test effectiveness mixed xlm model pretrained brcc social medium scenario codemixing found frequently compile new bahasa rojak sentiment analysis dataset sentibahasarojak kappa value
visuallygrounded natural language processing become important research direction past year however majority available crossmodal resource eg imagecaption datasets built english directly utilized multilingual nonenglish scenario study present novel multilingual multimodal corpus extending flickrk entity imagecaption dataset japanese translation name flickrk entity jp fkentjp best knowledge first multilingual imagecaption dataset caption two language parallel shared annotation manytomany phrasetoregion linking believe phrasetoregion well phrasetophrase supervision play vital role finegrained grounding language vision promote many task multilingual image captioning multimodal machine translation verify dataset performed phrase localization experiment language investigated effectiveness japanese annotation well multilingual learning realized dataset
ingrained principle fairness dialogue system decisionmaking process generated response crucial user engagement satisfaction task achievement absence equitable inclusive principle hinder formation common ground turn negatively impact overall performance system example misusing pronoun user interaction may cause ambiguity intended subject yet comprehensive study equitable text generation dialogue aptly work use theory computational learning study problem provide formal definition equity text generation prove formal connection learning humanlikeness learning equity algorithm improving equity ultimately reduce algorithm improving humanlikeness augmented data insight also formulate reasonable condition text generation algorithm learn generate equitable text without modification biased training data learn exemplify theory practice look group algorithm guesswhat visual dialogue game using example test theory empirically theory accurately predicts relativeperformance multiple algorithm generating equitable text measured human automated evaluation
paper brief summary first wmt shared task sign language translation wmtslt project partly funded eamt focus shared task automatic translation signed spoken language detail found website urlhttpswwwwmtsltcom finding paper muller et al
spoken language understanding slu essential component conversational system slu component treat utterance independently following component aggregate multiturn information separate phase order avoid error propagation effectively utilize context prior work leveraged history contextual slu however previous model paid attention related content history utterance ignoring temporal information dialogue intuitive recent utterance important least recent one word timeaware attention decaying manner therefore paper design investigates various type timedecay attention sentencelevel speakerlevel proposes flexible universal timedecay attention mechanism experiment benchmark dialogue state tracking challenge dstc dataset show proposed timedecay attention mechanism significantly improve stateoftheart model contextual understanding performance
paper describes machine translation system developed barcelona supercomputing bsc team biomedical translation shared task wmt system based neural machine translation unsing opennmtpy toolkit transformer architecture participated four translation direction englishspanish englishportuguese language pair create training data concatenated several parallel corpus indomain outofdomain source well terminological resource umls
introduce novel chartbased algorithm spanbased parsing discontinuous constituency tree block degree two including illnested structure particular show build variant parser smaller search space time complexity ranging cubic time variant cover constituent observed linguistic treebanks complexity continuous constituency parser evaluate approach german english treebanks negra tiger dptb report stateoftheart result fully supervised setting also experiment pretrained word embeddings bertbased neural network
paper compare two approach train multilingual language model simple multilingual learning using datamixing ii metalearning examine performance model extending unseen language pair finetune task unsupervised nmt perform several experiment varying amount data give comparative analysis approach observe approach give comparable performance metalearning give slightly better result case low amount data oriyapunjabi language pair metalearning performs better multilingual learning using sentence
paper present madamira system morphological analysis disambiguation arabic combine best aspect two previously commonly used system arabic processing mada habash rambow habash et al habash et al amira diab et al madamira improves upon two system streamlined java implementation robust portable extensible faster ancestor order magnitude also discus online demo see urlhttpnlpldeocolumbiaedumadamira highlight aspect
consumer price index cpi one major statistic produced statistical office crucial importance central bank calculate cpi statistical office collect large amount individual price good service nowadays price many consumer good obtained online enabling much detailed measurement inflation rate one major challenge classify variety product different shop language given statistical schema consisting complex multilevel classification hierarchy european classification individual consumption according purpose ecoicop european country since model mapping labelled data available focus analysis food beverage tobacco account ecoicop category euro area inflation basket paper build classifier web scraped handlabeled product data german retailer test transfer french data using cross lingual word embedding compare performance classifier trained single language classifier language trained jointly furthermore propose pipeline effectively create data set balanced label using transferred prediction active learning addition test much data take build single language classifier scratch benefit multilingual training proposed system reduces time complete task two third already used support analysis inflation
annotator disagreement often dismissed noise result poor annotation process quality others argued meaningful lacking rigorous statistical foundation analysis disagreement pattern resemble hightech form tealeafreading contribute framework analyzing variation peritem annotator response distribution data humansintheloop machine learning provide visualization use framework analyze variance crowdsourced dataset hardtoclassify example openimages archive
word sense disambiguation wsd task identifying intended sense word context prior work unsupervised wsd leveraged lexical knowledge base wordnet babelnet resource proven less effective chinese instead widely used lexical knowledge base chinese hownet previous hownetbased wsd method exploited contextual translation information paper present first hownetbased wsd system combine monolingual contextual information pretrained neural language model bilingual information obtained via machine translation sense translation information hownet result evaluation experiment test set prior work demonstrate new method achieves new state art unsupervised chinese wsd
work progress cef action national language technology platform nltp presented action aim combining advanced language technology lt tool solution new stateoftheart artificial intelli gence ai driven national language technology platform nltp
accuracy statistical parsing model improved use lexical information statistical parsing using lexicalized tree adjoining grammar ltag kind lexicalized grammar remained relatively unexplored believe largely part due absence large corpus accurately bracketed term perspicuous yet broad coverage ltag work attempt alleviate difficulty extract different ltags penn treebank show certain strategy yield improved extracted ltag term compactness broad coverage supertagging accuracy furthermore perform preliminary investigation smoothing grammar mean external linguistic resource namely tree family xtag grammar hand built grammar english
paper deal process designing phonetically prosodically rich speech corpus unit selection speech synthesis attention given mainly recording verification stage process order ensure high quality consistency recording possible special recording environment consisting recording session management pluggable chain checking module designed utilised stage namely text collection including phonetically prosodically balanced sentence selection careful annotation orthographic phonetic level also mentioned
consider two related problem paper given undeciphered alphabetic writing system monoalphabetic cipher determine letter vowel consonant whether writing system vocalic alphabet abjad able show simple spectral decomposition based character cooccurrences provides nearly perfect performance respect answering question type
much mathematics therefore much computer science built notion set paper argued parsing theory sometimes convenient replace set related notion textitbunches replacement much matter principle help create concise theory advantage bunch concept illustrated using description formal semantics contextfree grammar functional parsing algorithm
general qa field developing methodology referencing stanford question answering dataset squad significant benchmark compiling factual question datasets requires manual annotation limiting training data potential size present wikiomnia dataset new publicly available set qa pair corresponding russian wikipedia article summary section composed fully automated generation filtration pipeline ensure high quality generated qa pair diverse manual automated evaluation technique applied wikiomnia pipeline available opensource also tested creating squadformatted qa domain like news text fiction social medium resulting dataset includes two part raw data whole russian wikipedia qa pair paragraph rugpt xl qa pair paragraph rutlarge cleaned data strict automatic verification qa pair paragraph rugpt xl qa pair paragraph rutlarge
majority work targeted sentiment analysis concentrated finding better method improve overall result within paper show model robust linguistic phenomenon specifically negation speculation paper propose multitask learning method incorporate information syntactic semantic auxiliary task including negation speculation scope detection create englishlanguage model robust phenomenon create two challenge datasets evaluate model performance negated speculative sample find multitask model transfer learning via language modelling improve performance challenge datasets overall performance indicate still much room improvement release datasets source code urlhttpsgithubcomjerbarnesmultitasknegationfortargetedsentiment
natural disaster conflict information happened often confusing messy distributed across many source would like able automatically identify relevant information assemble coherent narrative happened make task accessible neural model introduce textitstory salad mixture multiple document generated scale exploiting wikipedia hierarchy generate salad exhibit challenging inference problem story salad give rise novel challenging clustering task objective group sentence narrative demonstrate simple bagofwords similarity clustering fall short task necessary take account global context coherence
knowledge distillation widely used transfer language understanding large model smaller model however knowledge distillation found smaller model biased gender compared source large model paper study cause gender bias increase knowledge distillation process moreover suggest applying variant mixup knowledge distillation used increase generalizability distillation process augmentation significantly reduce gender bias amplification knowledge distillation also conduct experiment glue benchmark demonstrate even mixup applied significant adverse effect model performance
paper describe function assistant lightweight pythonbased toolkit querying exploring source code repository using natural language toolkit designed help endusers target api quickly find information function highlevel natural language query description given text query background api tool find candidate function performing translation text known representation api using semantic parsing approach richardson kuhn translation automatically learned example textcode pair example apis toolkit includes feature building translation pipeline query engine arbitrary source code project explore last feature perform new experiment wellknown python project hosted github
statistical machine translation smt dominant paradigm machine translation mt research nearly three decade recently superseded endtoend deep learning approach mt although deep neural model produce stateoftheart result many translation task found underperform resourcepoor scenario despite success none presentday benchmark tried overcome problem regarded universal solution problem translation many lowresource language work investigate performance phrasebased smt pbsmt neural mt nmt rarelytested lowresource languagepair englishtotamil taking specialised data domain software localisation consideration particular produce ranking mt system via social medium platformbased human evaluation scheme demonstrate finding lowresource domainspecific text translation task
paper detail system designed social medium mining health application smmh shared task specifically describe system designed solve task automatic classification multilingual tweet report adverse effect task automatic extraction normalization adverse effect english tweet fine tuning roberta large classifying english tweet enables u achieve f score increase compared average f score submission using bert based ner question answering able achieve f score extracting adverse reaction mention tweet increase compared average f score submission
machine translation system vulnerable domain mismatch especially lowresource scenario outofdomain translation often poor quality prone hallucination due exposure bias decoder acting language model adopt two approach alleviate problem lexical shortlisting restricted ibm statistical alignment hypothesis reranking based similarity method computationally cheap show success lowresource outofdomain test set however method lose advantage sufficient data great domain mismatch due ibm model losing advantage implicitly learned neural alignment issue subword segmentation unseen word
data augmentation effective way improve model performance grammatical error correction gec paper identifies critical sideeffect gec data augmentation due style discrepancy data used gec task ie text produced nonnative speaker data augmentation ie native text alleviate issue propose use alternative data source translationese ie humantranslated text input gec data augmentation easier obtain usually better quality nonnative text similar style nonnative text experimental result conll bea english nlpcc chinese falkomerlin german rulecgec russian gec benchmark show approach consistently improves correction accuracy strong baseline analysis reveal approach helpful overcoming mainstream correction difficulty correction frequent word missing word substitution error data code model script freely available urlhttpsgithubcomnlpcttransgec
tackle task adapting event extractor new domain without labeled data aligning marginal distribution source target domain testbed create two new event extraction datasets using english text two medical domain clinical note ii doctorpatient conversation test efficacy three marginal alignment technique adversarial domain adaptation ada ii domain adaptive finetuning daft iii new instance weighting technique based language model likelihood score liw liw daft improve notransfer bert baseline domain ada improves note deeper analysis performance different type shift eg lexical shift semantic shift explains variation among model bestperforming model reach f score note conversation respectively using labeled target data
short text classification found rich critical application news tweet tagging help user find relevant information due lack labeled training data many practical use case pressing need studying semisupervised short text classification existing study focus long text achieve unsatisfactory performance short text due sparsity limited labeled data paper propose novel heterogeneous graph neural network based method semisupervised short text classification leveraging full advantage labeled data large unlabeled data information propagation along graph particular first present flexible hin heterogeneous information network framework modeling short text integrate type additional information well capture relation address semantic sparsity propose heterogeneous graph attention network hgat embed hin short text classification based duallevel attention mechanism including nodelevel typelevel attention attention mechanism learn importance different neighboring node well importance different node information type current node extensive experimental result demonstrated proposed model outperforms stateoftheart method across six benchmark datasets significantly
present kanjingo mobile app postediting currently running io app developed using agile methodoly cngl dcu though could used numerous scenario test scenario involved postediting machine translated sample content nonprofit translation organization translator without border feedback first round user testing englishfrench englishspanish positive user also identified number usability issue required improvement issue addressed second development round second usability evaluation carried collaboration another nonprofit translation organization rosetta foundation french spanish target language
multihop knowledge graph kg reasoning widely studied recent year provide interpretable prediction missing link evidential path previous work use reinforcement learning rl based method learn navigate path towards target entity however method suffer slow poor convergence may fail infer certain path missing edge along path present squire first sequencetosequence based multihop reasoning framework utilizes encoderdecoder transformer structure translate query path framework brings two benefit learn predict endtoend fashion give better faster convergence transformer model rely existing edge generate path flexibility complete missing edge along path especially sparse kg experiment standard sparse kg show approach yield significant improvement prior method converging xx faster
address problem automatic short answer grading evaluating collection approach inspired recent advance distributional text representation addition propose unsupervised approach determining text similarity using onetomany alignment word vector evaluate proposed technique across two datasets different domain namely computer science english reading comprehension additionally vary highschool level undergraduate student experiment demonstrate proposed technique often outperforms compositional distributional semantics approach well vector space method latent semantic analysis combined scoring scheme proposed technique provides powerful tool tackling complex problem short answer grading also discus number key point worthy consideration preparing viable easytodeploy automatic shortanswer grading system realworld
age social medium conspiracy theory ct become issue longer ignored providing overview ct literature corpus study describe creation token englishitalian bilingual corpus conspiracyoriented telegram comment complotto corpus linguistic analysis performed using sketch engine online platform kilgarriff et al annotated data identify statistically relevant linguistic marker ct discourse thanks platform keywords key term extraction function able assess statistical significance following lexical semantic phenomenon crosslinguistically crossct namely evidentiality epistemic modality marker debunking vocabulary referring another version truth lying behind official one conceptual metaphor institution abuser feature qualify marker ct discourse potential effectively used future semantic annotation task develop automatic system ct identification
paper present method designing compiling annotating corpus intended language learner particular focus spoken corpus used complementary material classroom well examination describe three corpus spanish chinese japanese compiled laboratorio de linguistica informatica autonomous university madrid lliuam webbased concordance tool used search example corpus providing text along corresponding audio teaching material corpus consisting text audio file exercise currently development
finetuning contextualized representation learned pretrained language model remains prevalent practice nlp however finetuning lead representation degradation also known representation collapse may result instability suboptimal performance weak generalization paper propose representation projection invariance repina novel regularization method maintain information content representation reduce representation collapse finetuning discouraging undesirable change representation study empirical behavior proposed regularization comparison comparable baseline across language understanding task glue benchmark six additional datasets evaluating indomain performance repina consistently outperforms baseline task additionally repina improves outofdistribution performance also demonstrate effectiveness fewshot setting robustness label perturbation byproduct extend previous study representation collapse propose several metric quantify empirical finding show approach significantly effective mitigating representation collapse
tuples extraction fundamental task information extraction knowledge graph construction extracted tuples usually represented knowledge triple consisting subject relation object practice however validity knowledge triple associated change spatial temporal kind constraint motivated observation paper proposes constrained tuple extraction cte task guarantee validity knowledge tuples formally cte task extract constrained tuples unstructured text add constraint conventional triple end propose interactionaware network combinatorial interaction among contextspecific external feature distinctgranularity internal feature exploited effectively mine potential constraint moreover built new dataset containing totally constrained tuples training one evaluation experiment dataset public carb dataset demonstrate superiority proposed model constructed dataset code publicly available
stateoftheart transformer model achieved robust performance variety nlp task many approach employed domain agnostic pretraining task train model yield highly generalized sentence representation finetuned specific downstream task propose refining pretrained nlp model using objective detecting shuffled token use sequential approach starting pretrained roberta model training using approach applying random shuffling strategy wordlevel found approach enables roberta model achieve better performance glue task result indicate learning detect shuffled token promising approach learn coherent sentence representation
automatic headline generation subtask oneline summarization many reported application evaluation system generating headline challenging undeveloped area introduce headline evaluation analysis system hevas performs automatic evaluation system term quality generated headline hevas provides two type metric one measure informativeness headline another measure readability result evaluation compared result baseline method implemented hevas system also performs statistical analysis evaluation result provides different visualization chart paper describes evaluation metric baseline analysis architecture utilized system
evaluate efficacy predicted upos tag input feature dependency parser lower resource setting evaluate treebank size affect impact tagging accuracy parsing performance real low resource universal dependency treebanks artificially low resource data varying treebank size small treebanks varying amount augmented data find predicted upos tag somewhat helpful low resource treebanks especially fewer fullyannotated tree available also find positive impact diminishes amount data increase
paper describes submission social medium mining health smmh shared task participated task task classification tweet selfreporting exact age b task classification reddit post selfreporting exact age evaluated two bert roberta transformer based model task task robertalarge achieved f score test set bertlarge achieved f score test set task
participated semeval shared task capturing discriminative attribute task simple system ranked th amongst team took part evaluation final score competitive winning score particularly given system zeroshot system requires training minimal parameter optimisation addition describing submitted system discussing implication relative success system task also report complex model experimented
text infilling aim filling missing part sentence paragraph applied variety realworld natural language generation scenario given welltrained sequential generative model challenging unidirectional decoder generate missing symbol conditioned past future information around missing part paper propose iterative inference algorithm based gradient search could first inference algorithm broadly applied neural sequence generative model text infilling task extensive experimental comparison show effectiveness efficiency proposed method three different text infilling task various mask ratio different mask strategy comparing five stateoftheart method
many paper speech processing use term spontaneous speech catchall term situation like speaking friend interviewed radiotv giving lecture however automatic speech recognition asr system performance seems exhibit variation type speech spontaneous speech higher wer word error rate study focus better understanding element influencing level spontaneity order evaluate relation category spontaneity asr system performance improve recognition category first analyzed literature listed unraveled element finally identified four ax situation communication level intimacy speaker channel type communication trained asr system measured impact instance facetoface interaction labeled previous dimension different level spontaneity wer made two ax vary found dimension impact wer situation communication seems biggest impact spontaneity asr system give better result situation like interview friend conversation home
system support user automatic creation visualization must address several subtasks understand semantics data enumerate relevant visualization goal generate visualization specification work pose visualization generation multistage generation problem argue wellorchestrated pipeline based large language model llm image generation model igm suitable addressing task present lida novel tool generating grammaragnostic visualization infographics lida comprises module summarizer convert data rich compact natural language summary goal explorer enumerates visualization goal given data visgenerator generates refines executes filter visualization code infographer module yield datafaithful stylized graphic using igm lida provides python api hybrid user interface direct manipulation multilingual natural language interactive chart infographics data story generation code demo available url urlhttpsmicrosoftgithubiolida
emergence crowdsourcing commonly used approach collect vast quantity human assessment variety task represents nothing less paradigm shift particularly true academic research suddenly become possible collect highquality annotation rapidly without need expert paper investigate factor influence quality result obtained amazon mechanical turk crowdsourcing platform investigated impact different presentation method free text versus radio button worker base usa versus india main base mturk worker payment scale per hour quality result run assessed result provided worker set task run two different experiment using objective task math general text question task answer unique eliminates uncertainty usually present subjective task clear whether unexpected answer caused lack worker motivation worker interpretation task genuine ambiguity work present result comparing influence different factor used one interesting finding result confirm previous study concluded increase payment attracts noise also find country origin impact category general text question significant difference top pay
one main obstacle hampering method development comparative evaluation named entity recognition social medium lack sizeable diverse high quality annotated corpus analogous conll news dataset instance biggest ritter tweet corpus token mere size conll another major shortcoming lack temporal geographic author diversity paper introduces broad twitter corpus btc significantly bigger sampled across different region temporal period type twitter user goldstandard named entity annotation made combination nlp expert crowd worker enables u harness crowd recall maintaining high quality also measure entity drift observed dataset ie entity representation varies time compare newswire corpus released openly including source text intermediate annotation
introduce denoised web treebank treebank including normalization layer corresponding evaluation metric dependency parsing noisy text tweet benchmark enables evaluation parser robustness well text normalization method including normalization machine translation unsupervised lexical normalization directly syntactic tree experiment show text normalization together combination domainspecific generic partofspeech tagger lead significant improvement parsing accuracy test set
paper describe concept entitycentric information access biomedical domain entity recognition technology approaching acceptable level accuracy put forward paradigm document browsing searching entity domain relation explicitly modeled provide user possibility collecting exhaustive information relation interest describe three working prototype along line newsleak developed investigative journalist need quick overview large leaked document collection storyfinder personalized organizer information found web page allows adding entity well relation capable personalized information management adaptive annotation capability webanno generalpurpose linguistic annotation tool discus future step towards adaptation tool biomedical data subject recently started project biomedical knowledge acquisition key difference approach centering around user humanintheloop machine learning approach user define extend category enable system improve via feedback interaction
paper discusses build practical syntactic analyzer address distributional difference existing corpus actual document application case study focus noun phrase headed main verb sentence without punctuation end rare number universal dependency corpus frequently appear realworld use case syntactic parser converted training corpus distribution closer realistic input obtained better score general syntax benchmarking sentiment detection task typical application dependency analysis
generalization problem kbqa drawn considerable attention existing research suffers generalization issue brought entanglement coarsegrained modeling logical expression inexecutability issue due finegrained modeling disconnected class relation real kb propose finetocoarse composition framework kbqa fckbqa ensure generalization ability executability logical expression main idea fckbqa extract relevant finegrained knowledge component kb reformulate middlegrained knowledge pair generating final logical expression fckbqa derives new stateoftheart performance grailqa webqsp run time faster baseline code available github urlhttpsgithubcomruckbreasoningfckbqa
information extraction deal extracting entity people organization location named relation entity people bornin country text document important challenge information extraction labeling training data usually done manually therefore laborious certain case impractical paper introduces new model extract semantic relation fully automatically text using encarta encyclopedia lexicalsemantic relation discovered mindnet mindnet lexical knowledge base constructed fully automatically given text corpus without human intervention encarta article categorized linked related article expert demonstrate structured data available encarta lexical semantic relation word mindnet used enrich mindnet semantic relation entity slight trade accuracy semantically enriched mindnet used extract relation text corpus without human intervention
neural dense retrieval model state art many datasets however model often exhibit limited domain transfer ability existing approach adaptation unwieldy requiring explicit supervision complex model architecture massive external model present textttabel simple effective unsupervised method enhance passage retrieval zeroshot setting technique follows straightforward loop dense retriever learns supervision signal provided reranker subsequently reranker updated based feedback improved retriever iterating loop two component mutually enhance one anothers performance experimental result demonstrate unsupervised textttabel model outperforms leading supervised unsupervised retriever beir benchmark meanwhile exhibit strong adaptation ability task domain unseen training either finetuning textttabel labelled data integrating existing supervised dense retriever achieve stateoftheart result
paper propose method discovering semantic difference word appearing two corpus key idea measure coverage meaning word corpus norm mean word vector equivalent examining kind variance word vector distribution proposed method require alignment word andor corpus comparison previous method require compute variance norm mean word vector word type nevertheless rival bestperforming system semeval task addition robust skew corpus size ii capable detecting semantic difference infrequent word iii effective pinpointing word instance meaning missing one two corpus comparison show advantage historical corpus also nativenonnative english corpus
recurrent neural network rnns process input text sequentially model conditional transition word token contrast advantage recursive network include explicitly model compositionality recursive structure natural language however current recursive architecture limited dependence syntactic tree paper introduce robust syntactic parsingindependent tree structured model neural tree indexer nti provides middle ground sequential rnns syntactic treebased recursive model nti construct full nary tree processing input text node function bottomup fashion attention mechanism applied structure node function implemented evaluated binary tree model nti showing model achieved stateoftheart performance three different nlp task natural language inference answer sentence selection sentence classification outperforming stateoftheart recurrent recursive neural network
present computational exploration argument critique writing young student middle school student asked criticize argument presented prompt focusing identifying explaining reasoning flaw task resembles established collegelevel argument critique task lexical discourse feature utilize detailed domain knowledge identify critique exist college task perform well young student data instead transformerbased architecture eg bert finetuned large corpus critique essay college task performs much better improvement f score analysis performance various configuration system suggests childrens writing exhibit standard discourse structure argumentative essay share basic local sequential structure mature writer
child focal point studying link language theory mind tom competence language tom often studied younger child standardized test social competence data method higher ecological validity critical leverage corpus freelytold story dutch child aged recorded everyday classroom environment study language tom nlptools labelled story according mental depth story character child create proxy tom competence action built classifier feature encoding linguistic competence identified existing work predictive tomwe obtain good fairly robust result fmacro relative complexity task human result explainable link specific linguistic feature lexical complexity sentential complementation relatively independent childrens age higher level character depth confirms extends earlier work study includes older child socially embedded data different domain overall result support idea language tom strongly interlinked narrative former scaffold latter
machine translation mt studied developed since advent computer yet rarely used actual business business use rulebased mt developed requires rule domainspecific dictionary created manually hand huge amount text data become available corpusbased mt actively studied particularly corpusbased statistical machine translation smt study tested verified usefulness smt aviation manual manual tend similar repetitive smt powerful even small amount training data although experiment smt preliminary stage bleu score high smt appears powerful promising technique domain
working textual data natural application disentangled representation fair classification goal make prediction without biased influenced sensible attribute may present data eg age gender race dominant approach disentangle sensitive attribute textual representation rely learning simultaneously penalization term involves either adversary loss eg discriminator information measure eg mutual information however method require training deep neural network several parameter update update representation model matter fact resulting nested optimization loop time consuming adding complexity optimization dynamic requires fine hyperparameter selection eg learning rate architecture work introduce family regularizers learning disentangled representation require training regularizers based statistical measure similarity conditional probability distribution respect sensible attribute novel regularizers require additional training faster involve additional tuning achieving better result combined pretrained randomly initialized text encoders
paper present framework understand negation positive term specifically extract positive meaning negation negation cue syntactically modifies noun adjective approach grounded generating potential positive interpretation automatically scoring experimental result show interpretation scored high reliably identified
learning multihop reasoning key challenge reading comprehension model leading design datasets explicitly focus ideally model able perform well multihop question answering task without multihop reasoning paper investigate two recently proposed datasets wikihop hotpotqa first explore sentencefactored model task design model multihop reasoning still able solve large number example datasets furthermore find spurious correlation unmasked version wikihop make easy achieve high performance considering question answer finally investigate one key difference datasets namely spanbased v multiplechoice formulation qa task multiplechoice version datasets easily gamed two model examine marginally exceed baseline setting overall datasets useful testbeds highperforming model may learning much multihop reasoning previously thought
paper study keyphrase extraction realworld scenario document diverse domain variant content quality curate release openkp large scale open domain keyphrase extraction dataset near one hundred thousand web document expert keyphrase annotation handle variation domain content quality develop blingkpe neural keyphrase extraction model go beyond language understanding using visual presentation document weak supervision search query experimental result openkp confirm effectiveness blingkpe contribution neural architecture visual feature search log weak supervision zeroshot evaluation duc demonstrate improved generalization ability learning open domain data compared specific domain
annotator disagreement ubiquitous natural language processing nlp task multiple reason disagreement including subjectivity task difficult case unclear guideline rather simply aggregating label obtain data annotation instead try directly model diverse perspective annotator explicitly account annotator idiosyncrasy modeling process creating representation annotator annotator embeddings also annotation annotation embeddings addition propose tid inherent disagreement dataset benchmark consists eight existing language understanding datasets inherent annotator disagreement test approach tid show approach help model learn significantly better disagreement six different datasets tid increasing model size fewer parameter capturing unique tendency subjectivity individual annotator embeddings representation prime ai model inclusive diverse viewpoint
multimodal sentiment analysis attracted increasing attention lot model proposed however performance stateoftheart model decrease sharply deployed real world find main reason realworld application access text output automatic speech recognition asr model may error limitation model capacity analysis asr output find case sentiment word key sentiment element textual modality recognized word make sentiment text change hurt performance multimodal sentiment analysis model directly address problem propose sentiment word aware multimodal refinement model swrm dynamically refine erroneous sentiment word leveraging multimodal sentiment clue specifically first use sentiment word position detection module obtain possible position sentiment word text utilize multimodal sentiment word refinement module dynamically refine sentiment word embeddings refined embeddings taken textual input multimodal feature fusion module predict sentiment label conduct extensive experiment realworld datasets including mosispeechbrain mosiibm mosiiflytek result demonstrate effectiveness model surpasses current stateoftheart model three datasets furthermore approach adapted multimodal feature fusion model easily
decoder simultaneous neural machine translation receives limited information source balance opposing requirement latency versus translation quality paper use auxiliary targetside language model augment training decoder model notion target adaptive training generating rare difficult token rewarded improves translation quality reducing latency prediction made language model decoder combined traditional cross entropy loss free focus source side context experimental result multiple language pair show compared previous state art method simultaneous translation use augmented target side context improve bleu score significantly show improvement state art low latency range lower average lagging value faster output
product matching ie able infer product sold merchantcreated offer crucial ecommerce marketplace enabling productbased navigation price comparison product review etc problem prof challenging task mostly due extent product catalog data heterogeneity missing product representants varying level data quality moreover new product introduced every day making difficult cast problem classification task work apply bertbased model similarity learning setup solve product matching problem provide thorough ablation study showing impact architecture training objective choice application transformerbased architecture proper sampling technique significantly boost performance range ecommerce domain allowing production deployment
paper study keyphrase generation kg task scenario structure play important role example scientific publication consists short title long body title used deemphasizing unimportant detail body similarly short social medium post tweet scarce context augmented title though often missing contribution generatingaugmenting structure injecting information encoding using existing keyphrases document complementing missingincomplete title propose novel structureaugmented document encoding approach consist following two phase first phase generating structure extends given document related absent keyphrases augmenting missing context second phase encoding structure build graph keyphrases given document obtain structureaware representation augmented text empirical result validate proposed structure augmentation augmentationaware encodingdecoding improve kg scenario outperforming stateoftheart
present machine learning pipeline identifies key sentence abstract oncological article aid evidencebased medicine problem characterized lack gold standard datasets data imbalance thematic difference available silver standard corpus additionally available training target data differs regard domain professional summary v sentence abstract make supervised machine learning inapplicable propose use two semisupervised machine learning approach mitigate difficulty arising heterogeneous data source overcome data imbalance create reliable training data propose using transductive learning positive unlabelled data pu learning obtaining realistic classification model propose use abstract summarised relevant sentence unlabelled example selftraining best model achieves accuracy f score dataset
creating finegrained annotated data previously relevent document set important evaluating individual component automatic question answering system paper describe using amazon mechanical turk amt judge whether paragraph relevant document answer corresponding list question trec qa track based amt result build collection goldstandard supporting paragraph list question online experiment suggested recruiting people per task assures better annotation quality order learning true label amt annotation investigated three approach two datasets different level annotation error experimental study show naive bayesian model embased glad model generate result highly agreeing goldstandard annotation dominate significantly majority voting method true label learning also suggested setting higher hit approval rate assure better online annotation quality lead better performance learning method
interlingual homograph word spell possess different meaning across language recognizing interlingual homograph formidentical word generally need linguistic knowledge massive annotation work paper propose automatic interlingual homograph recognition method based crosslingual word embedding similarity cooccurrence formidentical word parallel sentence conduct experiment various offtheshelf language model coordinating crosslingual alignment operation cooccurrence metric chinesejapanese englishdutch language pair experimental result demonstrate proposed method able make accurate consistent prediction across language
stateoftheart nlp model often fooled adversary apply seemingly innocuous labelpreserving transformation eg paraphrasing input text number possible transformation scale exponentially text length data augmentation cover transformation input paper considers one exponentially large family labelpreserving transformation every word input replaced similar word train first model provably robust word substitution family training procedure us interval bound propagation ibp minimize upper bound worstcase loss combination word substitution induce evaluate model robustness transformation measure accuracy adversarially chosen word substitution applied test example ibptrained model attain adversarial accuracy sentiment analysis imdb natural language inference snli comparison imdb model trained normally one trained data augmentation achieve adversarial accuracy respectively
article describes first emotional corpus named emovo applicable italian language database built voice actor played sentence simulating emotional state disgust fear anger joy surprise sadness plus neutral state emotion wellknown big six found literature related emotional speech recording made professional equipment fondazione ugo bordoni laboratory paper also describes subjective validation test corpus based emotiondiscrimination two sentence carried two different group listener test successful yielded overall recognition accuracy observed emotion less easy recognize joy disgust whereas easy detect anger sadness neutral state
executable taskoriented semantic parsing system aim translate user utterance natural language machineinterpretable program api call executed according predefined api specification popularity large language model llm incontext learning offer strong baseline scenario especially datalimited regime however llm known hallucinate therefore pose formidable challenge constraining generated content thus remains uncertain llm effectively perform taskoriented utterancetoapi generation respecting apis structural taskspecific constraint crucial work seek measure analyze mitigate constraint violation first identify category various constraint obtaining apisemantics taskoriented utterance define finegrained metric complement traditional one second leverage metric conduct detailed error analysis constraint violation seen stateoftheart llm motivates u investigate two popular mitigation strategy semanticretrieval demonstration srd apiaware constrained decoding apicd experiment show strategy effective reducing constraint violation improving quality generated api call require careful consideration given implementation complexity latency
mental health issue differ widely among individual varied sign symptom recently languagebased assessment haveshown promise capturing diversity require substantial sample word per person accuracy work introducesthe task adaptive languagebased assessment alba involves adaptively ordering question also scoring individual latent psychological trait using limited language response previous question end develop adaptive testing method two psychometric measurement theory classical test theory item response theorywe empirically evaluate ordering scoring strategy organizing two new method semisupervised item response theorybasedmethod alirt supervised actorcritic model found method improve nonadaptive baseline foundalirt accurate scalable achieving highest accuracy fewer question eg pearson r mboxapprox question compared typically needing least question general adaptive languagebased assessment depression anxiety able utilize smaller sample language without compromising validity large computational cost
paper present kogito opensource tool generating commonsense inference situation described text kogito provides intuitive extensible interface interact natural language generation model used hypothesizing commonsense knowledge inference textual input particular kogito offer several feature targeted multigranularity knowledge generation include standardized api training evaluating knowledge model generating filtering inference also include helper function converting natural language text format ingestible knowledge model intermediate pipeline stage knowledge head extraction text heuristic modelbased knowledge headrelation matching ability define use custom knowledge relation make code kogito available urlhttpsgithubcomepflnlpkogito along thorough documentation urlhttpskogitoreadthedocsio
fake news detection received quite bit attention recent year hyperpartisan news detection still underresearched topic paper present work towards building classification system hyperpartisan news detection context semeval shared task experiment two different approach stylistic one content related one achieving average result
developing conventional natural language generation system requires extensive attention human expert order craft complex set sentence planning rule propose bayesian nonparametric approach learn sentence planning rule inducing synchronous tree substitution grammar pair text plan morphosyntacticallyspecified dependency tree system able learn rule used generate novel text training small datasets
understanding dynamic international politics important yet challenging civilian work explore unsupervised neural model infer relation nation news article extend existing model incorporating shallow linguistics information propose new automatic evaluation metric aligns relationship dynamic manually annotated key event understanding international relation requires carefully analyzing complex relationship conduct inperson human evaluation three group participant overall human prefer output model give insightful feedback suggests future direction humancentered model furthermore model reveals interesting regional difference news coverage instance respect uschina relation singaporean medium focus strengthening purchasing u medium focus criticizing denouncing
real world many relational fact require context instance politician hold given elected position particular timespan context timespan typically ignored knowledge graph link prediction task leveraged model designed specifically make use ie nary link prediction model show task nary link prediction easily performed using language model applied basic method constructing clozestyle query sentence introduce pretraining methodology based around auxiliary entitylinked corpus outperforms popular pretrained model like bert even smaller model methodology also enables nary link prediction without access nary training set invaluable circumstance expensive timeconsuming curation nary knowledge graph feasible achieve stateoftheart performance primary nary link prediction dataset wdk wikipeople fact include literal typically ignored knowledge graph embedding method
word modern hebrew text morphologically ambiguous describe method finding correct morphological analysis word modern hebrew text program first us small tagged corpus estimate probability possible analysis word regardless context chooses probable analysis applies automatically learned rule correct analysis word according neighbor finally us simple syntactical analyzer correct analysis thus combining statistical method rulebased syntactic analysis shown combination greatly improves accuracy morphological analysisachieving accuracy
increasing interest studying natural language computer code together large corpus programming text become readily available internet example stackoverflow currently million programming related question written million user meanwhile still lack fundamental nlp technique identifying code token softwarerelated named entity appear within natural language sentence paper introduce new named entity recognition ner corpus computer programming domain consisting sentence annotated finegrained entity type trained indomain bert representation bertoverflow million sentence stackoverflow lead absolute increase f score offtheshelf bert also present softner model achieves overall f score code named entity recognition stackoverflow data softner model incorporates contextindependent code token classifier corpuslevel feature improve bertbased tagging model code data available urlhttpsgithubcomjeniyatstackoverflowner
paper demonstrate context free grammar cfg based method grammar induction benefit modeling lexical dependency contrast popular current method grammar induction focus discovering either constituent dependency previous approach marry two disparate syntactic formalism eg lexicalized pcfgs plagued sparsity making unsuitable unsupervised grammar induction however work present novel neural model lexicalized pcfgs allow u overcome sparsity problem effectively induce constituent dependency within single model experiment demonstrate unified framework result stronger result representation achieved modeling either formalism alone
study compare output quality two mt system statistical smt neural nmt engine customised swiss post language service using training data focus point view professional translator investigate perceive difference mt output human reference namely deletion substitution insertion word order finding show translator frequently consider difference error smt nmt deletion serious error architecture also observe lower agreement difference corrected nmt smt suggesting error easier identify smt finding confirm ability nmt produce correct paraphrase could also explain bleu often considered inadequate metric evaluate performance nmt system
data augmentation effective way enhance performance neural machine translation model especially lowresource language existing data augmentation method either token level sentence level data augmented using token level method lack syntactic diversity may alter original meaning sentence level method usually generate lowquality source sentence semantically paired original target sentence paper propose novel data augmentation method generate diverse highquality meaningpreserved new instance method leverage highquality translation model trained highresource language rephrase original sentence translating intermediate language back original language process highperforming translation model guarantee quality rephrased sentence syntactic knowledge intermediate language bring syntactic diversity rephrased sentence experimental result show method enhance performance various lowresource machine translation task moreover combining method technique facilitate nmt yield even better result
present paper aim describe collection parlamintro corpus analyse several trend parliamentary debate plenary session lower house held short description data collection existing transcript workflow data processing text extraction conversion encoding linguistic annotation overview corpus paper move multilayered linguistic analysis validate interdisciplinary perspective use computational method corpus linguistics approach scrutinize future tense form used romanian speaker order create datasupported profile parliamentary group strategy planning
abundance methodological work aim detect hateful racist language text however tool hampered problem like low annotator agreement remain largely disconnected theoretical work race racism social science using annotation tweet annotator investigate annotator perception racism tweet vary annotator racial identity two text feature tweet relevant keywords latent topic identified structural topic modeling provide descriptive summary data estimate series generalized linear model determine annotator racial identity latent topic alone combination explain way racial sentiment annotated net relevant annotator characteristic tweet feature result show white nonwhite annotator exhibit significant difference rating reading tweet high prevalence particular raciallycharged topic conclude suggesting future methodological work draw result incorporate social science theory analysis
electronic health record ehr claim data rich source realworld data reflect patient health status healthcare utilization querying database answer epidemiological question challenging due intricacy medical terminology need complex sql query introduce endtoend methodology combine texttosql generation retrieval augmented generation rag answer epidemiological question using ehr claim data show approach integrates medical coding step texttosql process significantly improves performance simple prompting finding indicate although current language model yet sufficiently accurate unsupervised use rag offer promising direction improving capability shown realistic industry setting
nlp model achieved stateoftheart performance benchmark gained wide application increasingly important ensure safe deployment model real world eg making sure model robust unseen challenging scenario despite robustness increasingly studied topic separately explored application like vision nlp various definition evaluation mitigation strategy multiple line research paper aim provide unifying survey define measure improve robustness nlp first connect multiple definition robustness unify various line work identifying robustness failure evaluating model robustness correspondingly present mitigation strategy datadriven modeldriven inductivepriorbased systematic view effectively improve robustness nlp model finally conclude outlining open challenge future direction motivate research area
generating concise summary large collection argument given topic intriguing yet understudied problem propose represent summary small set talking point termed textitkey point scored according salience show analyzing large dataset crowdcontributed argument small number key point per topic typically sufficient covering vast majority argument furthermore found domain expert often predict key point advance study task argumenttokey point mapping introduce novel largescale dataset task report empirical result extensive set experiment dataset showing promising performance
given lack annotated corpus nontraditional odia literature serf standard come sentiment analysis created annotated corpus odia sentence made publicly available promote research field secondly order test usability currently available odia sentiment lexicon experimented various classifier training testing sentiment annotated corpus using identified affective word feature annotation classification done sentence level usage sentiment lexicon best suited sentiment analysis level created corpus contains odia sentence news domain annotated sentiment label using welldefined annotation scheme interannotator agreement score reported corpus
introduce whatlies open source toolkit visually inspecting word sentence embeddings project offer unified extensible api current support range popular embedding backends including spacy tfhub huggingface transformer gensim fasttext bytepair embeddings package combine domain specific language vector arithmetic visualisation tool make exploring word embeddings intuitive concise offer support many popular dimensionality reduction technique well many interactive visualisation either statically exported shared via jupyter notebook project documentation available urlhttpsrasahqgithubiowhatlies
automatic language recognition spontaneous speech experienced rapid development last year development part due competitive technological language recognition evaluation lre organized national institute standard technology nist need clearly defined consistent evaluation kept reallife application issue evaluation particular past nist lres used exclusively conversational telephone speech ct development test fortunately changed current nist lre since includes also broadcast speech however testing telephone speech found broadcast data used reallife application could several type speech system could forced use mix different type data training development recognition article defined testbed including several type speech data analyzed typical language recognition system work using different type speech also combination different type speech training testing
knowledge graph kg often represent knowledge base incomplete machine learning model alleviate helping automate graph completion recently growing interest completing knowledge base dynamic previously unseen entity may added kg many missing link paper present textbfstatiktextbfstructure textbfand textbftext textbfinductive textbfknowledge completion statik us language model extract semantic information text description using message passing neural network capture structural information statik achieves state art result three challenging inductive baseline analyze hybrid model detailed ablation study
taskoriented dialog model typically leverage complex neural architecture largescale pretrained transformer achieve stateoftheart performance popular natural language understanding benchmark however model frequently excess ten million parameter making impossible deploy ondevice resourceefficiency major concern work show simple convolutional model compressed structured pruning achieves largely comparable result bert atis snip k parameter moreover perform acceleration experiment cpu observe multitask model predicts intent slot nearly x faster even distilbert
adjective project noun part motorcycle red wheel red nuclear submarine captain nuclear question easy human judge using commonsense understanding world difficult computer attack challenge crowdsource set human judgment answer englishlanguage question given whole described adjective adjective also describe given part build strong baseline task classification approach finding indicate despite recent success large language model task aimed assess commonsense knowledge model greatly outperform simple wordlevel model based pretrained word embeddings provides evidence amount commonsense knowledge encoded language model extend far beyond already baked word embeddings dataset serve useful testbed future research commonsense reasoning especially relates adjective object
demo introduce webbased misinformation detection system panacea covid related claim two module factchecking rumour detection factchecking module supported novel natural language inference method selfattention network outperforms stateoftheart approach also able give automated veracity assessment ranked supporting evidence stance towards claim checked addition panacea adapts bidirectional graph convolutional network model able detect rumour based comment network related tweet instead relying knowledge base rumour detection module assist warning user early stage knowledge base may available
present collection morphologically annotated corpus seven arabic dialect taizi yemeni sanaani yemeni najdi jordanian syrian iraqi moroccan arabic corpus collectively cover word manually annotated common set standard orthography diacritized lemma tokenization morphological unit english gloss corpus publicly available serve benchmark training evaluating system arabic dialect morphological analysis disambiguation
nonautoregressive nar machine translation recently received significant development achieves comparable quality autoregressive ar model benchmark providing efficient alternative ar inference however ar translation often used implement multilingual model benefit transfer language improved serving efficiency multilingual nar model remain relatively unexplored taking connectionist temporal classification example nar model imputer seminar model present comprehensive empirical study multilingual nar test capability respect positive transfer related language negative transfer capacity constraint nar model require distilled training set carefully study impact bilingual versus multilingual teacher finally fit scaling law multilingual nar determine capacity bottleneck quantifies performance relative ar model model scale increase
different representation concept could often seen scientific report publication entity normalization entity linking task match different representation standard concept paper present twostep ensemble cnn method normalizes microbiologyrelated entity free text concept standard dictionary method capable linking entity small microbiologyrelated biomedical corpus available training achieved reasonable performance online test bionlpost shared task bacteria biotope
proliferation online hate speech necessitated creation algorithm detect toxicity past research focus detection classification task assigning absolute toxicity label often tricky hence past work transform task regression paper show comparative evaluation different transformer traditional machine learning model recently released toxicity severity measurement dataset jigsaw demonstrate issue model prediction using explainability analysis
expository document vital resource conveying complex information reader despite usefulness writing expository text hand challenging process requires careful content planning obtaining fact multiple source ability clearly synthesize fact ease burden propose task expository text generation seek automatically generate accurate stylistically consistent expository text topic intelligently searching knowledge source solve task developing irp framework overcomes limitation retrievalaugmented model iteratively performs content planning fact retrieval rephrasing experiment three diverse newlycollected datasets show irp produce factual organized expository text accurately inform reader
automated personality prediction social medium gaining increasing attention natural language processing social science community however due high labeling cost privacy issue publicly available datasets limited size low topic diversity address problem introducing largescale dataset derived reddit source far overlooked personality prediction dataset labeled myersbriggs type indicator mbti come rich set feature k user carry preliminary feature analysis revealing marked difference mbti dimension pole furthermore use dataset train evaluate benchmark personality prediction model achieving macro fscores individual dimension accuracy exact oneoff accurate type prediction result encouraging comparable reliability standardized test
acknowledgment often overlooked sometimes entirely missing publication short section paper provide insight state field characterize perform textual analysis acknowledgment nlp conference proceeding across last year revealing broader trend funding research direction nlp well interesting phenomenon including career incentive influence default
paper describes system nlptea task chinese grammatical error diagnosis grammatical error diagnosis one challenging nlp task locate grammar error tell error type system built model bidirectional long shortterm memory conditional random field layer bilstmcrf integrates several new feature first richer feature considered bilstmcrf model second probabilistic ensemble approach adopted third template matcher used postprocessing bring human knowledge official evaluation system obtains highest f score identifying error type locating error position second highest f score sentence level error detection also recommend error correction specific error type achieve best f performance among participant
social medium people express every day issue affect life parliamentary election people interaction candidate social medium post reflects lot social trend charged atmosphere people like dislike leader political party stand often become subject hate offensive post collected social medium post hindi english facebook twitter runup parliamentary election india pei data created dataset sentiment analysis three category hate speech offensive hate offensive report initial result sentiment classification dataset using different classifier
paper report participation fbk iwslt evaluation namely english asr track arabicenglish mt track englishfrench mt slt track asr system feature acoustic model trained portion ted talk recording automatically selected according fidelity provided transcription three decoding step performed interleaved acoustic feature normalization acoustic model adaptation concerning mt slt system besides language specific preprocessing automatic introduction punctuation asr output two major improvement reported last year baseline first applied fillup method phrasetable adaptation second explored use hybrid classbased language model better capture language style public speech
existing datasets causality identification argumentative text several limitation type input text eg claim causality type eg positive linguistic pattern investigated eg verb connective resolve limitation build webiscausality dataset sophisticated input unit argument balanced distribution causality type larger number linguistic pattern denoting causality dataset contains example derived combining two paradigm distant supervision uncertainty sampling identify diverse highquality sample causality relation annotate costeffective manner
describe verse verse experiment augmenting creative process writing poetry ai created group ai poet styled various american classic poet able offer suggestion generated line verse user composing poem paper describe underlying system offer suggestion includes generative model tasked generating large corpus line verse offline stored index dualencoder model tasked recommending next possible set verse index given previous line verse
paper describe system shared task fighting covid infodemic english language proposed architecture consists multioutput classification model seven task taskwise multihead attention layer intertask information aggregation built top bidirectional encoder representation obtained roberta transformer able achieve mean f score test data leading u second position testset leaderboard
speaker identification novel dialogue widely applied various downstream task producing multispeaker audiobooks converting novel script however existing stateoftheart method limited handling explicit narrative pattern like tom said unable thoroughly understand longrange context deal complex case end propose framework named spc identifies implicit speaker novel via symbolization prompt classification first spc symbolizes mention candidate speaker construct unified label set inserting prompt reformulate speaker identification classification task minimize gap training objective speaker identification pretraining task two auxiliary task also introduced spc enhance longrange context understanding experimental result show spc outperforms previous method large margin accuracy web novel collection reduces speaker identification error also outperforms emerging chatgpt addition spc accurate implicit speaker identification case require longrange context semantic understanding
information synchronization semistructured data across language challenging example wikipedia table one language need synchronized others address problem introduce new dataset infosync twostep method tabular synchronization infosync contains k entitycentric table wikipedia infoboxes across language subset textasciitildek pair manually annotated proposed method includes information alignment map row information update updating missingoutdated information aligned table across multilingual table evaluated infosync information alignment achieves f score en textlesstextgreater nonen evaluate information updation perform humanassisted wikipedia edits infoboxes table pair approach obtains acceptance rate wikipedia showing effectiveness proposed method
paper proposes ontologystyle relation osr annotation approach conventional relation extraction datasets relation annotated link entity mention contrast osr annotation relation annotated relation mention ie link node domain range link annotated relation mention argument entity mention expect following benefit relation annotation easily converted resource description framework rdf triple populate ontology part conventional task tackled named entity recognition ner task relation class limited several rdf property domain range subclassof osr annotation clear documentation ontology content case study converted inhouse corpus japanese traffic rule conventional annotation osr annotation built novel osrror rule road corpus interannotator agreement conversion evaluated performance neural ner tool conventional osr annotation experimental result showed osr annotation make task easier introducing slight complexity ner task
paper show reporting single performance score insufficient compare nondeterministic approach demonstrate common sequence tagging task seed value random number generator result statistically significant p difference stateoftheart system two recent system ner observe absolute difference one percentage point fscore depending selected seed value making system perceived either stateoftheart mediocre instead publishing reporting single performance score propose compare score distribution based multiple execution based evaluation lstmnetworks five sequence tagging task present network architecture produce superior performance well stable respect remaining hyperparameters
prevalence social medium present growing opportunity collect analyse example english variety whilst usage variety often used spoken context hardtoaccess private message social medium site like twitter provide platform user communicate informally scrapeable format notably indian english hinglish singaporean english singlish africanamerican english aae commonly found online variety pose challenge existing natural language processing nlp tool often differ orthographically syntactically standard english majority tool built nlp model trained standard english text produced biased outcome user underrepresented variety blodgett oconnor research aimed overcome inherent bias caused unrepresentative data technique like data augmentation adjusting training model aim address issue bias root data curate dataset tweet country high proportion underserved english variety speaker propose annotation framework six categorical classification along pseudospectrum measure degree standard english thereby indirectly aim surface manifestation english variety tweet
human innovation language inventing new word challenge pretrained language model assess ability one large model gpt process new word decide meaning create set nonce word prompt gpt generate dictionary definition find gpt produce plausible definition align human judgment moreover gpts definition sometimes preferred invented human signaling intriguing ability adapt add evolving vocabulary english language
current logical reasoning evaluation large language model llm primarily focus singleturn static environment arithmetic problem crucial problem multiturn strategic reasoning underexplored work analyze multiturn strategic reasoning llm textdriven complete incompleteinformation gaming eg board game tictactoe connect poker game texas holdem poker specifically consider two distinct scenario online racing featuring multiple llmsagents facilitate direct competition comparison offline probing constructing targeted question verified ground truth evaluate llm strategic behavior experimental result demonstrate existing stateoftheart llm reasoning scheme largely ineffective strategic reasoning task mitigate limitation propose simple yet effective recursively thinkingahead reta agent incorporating recursive prompting mechanism automatically analyzes opponent future movesactions assigns reward signal situation strengthen strategic reasoning llm hope work could spur research exploration multiturn strategic reasoning llm code available httpsgithubcomjinhaoduanreta
image captioning model usually evaluated ability describe heldout set image ability generalize unseen concept study problem compositional generalization measure well model composes unseen combination concept describing image stateoftheart image captioning model show poor generalization performance task propose multitask model address poor performance combine caption generation imagesentence ranking us decoding mechanism reranks caption according similarity image model substantially better generalizing unseen combination concept compared stateoftheart captioning model
regular physical activity associated reduced risk chronic disease type diabetes improved mental wellbeing yet half u population insufficiently active health coaching successful promoting healthy behavior paper present work towards assisting health coach extracting physical activity goal user coach negotiate via text message show information captured dialogue act help improve goal extraction result employ traditional transformerbased machine learning model dialogue act prediction find statistically indistinguishable performance health coaching dataset moreover discus feedback provided health coach evaluating correctness extracted goal summary work step towards building virtual assistant health coach promote healthy lifestyle
production deployment complex system require ml architecture highly efficient usable multiple task particularly demanding classification problem data arrives streaming fashion class presented separately recent method stochastic gradient learning shown struggle setup limitation like memory buffer restricted specific domain disable usage realworld scenario reason present fully differentiable architecture based mixture expert model enables training highperformance classifier example class presented separately conducted exhaustive experiment proved applicability various domain ability learn online production environment proposed technique achieves sota result without memory buffer clearly outperforms reference method
train several language model icelandic including icebert achieve stateoftheart performance variety downstream task including partofspeech tagging named entity recognition grammatical error detection constituency parsing train model introduce new corpus icelandic text icelandic common crawl corpus ic collection high quality text found online targeting icelandic topleveldomain several public data source also collected total gb icelandic text enhance evaluation model performance raise bar baseline icelandic manually translate adapt winogrande commonsense reasoning dataset effort demonstrate properly cleaned crawled corpus sufficient achieve stateoftheart result nlp application low medium resource language comparison model trained curated corpus show initializing model using existing multilingual model lead stateoftheart result downstream task
paper contribution sign language sl modeling focus hitherto imprecise notion multiplicity assumed express plurality french sign language lsf using azee approach azee linguistic formal approach modeling lsf take account linguistic property specificity lsf respecting constraint linked modeling process present methodology extract azee production rule based analysis strong formmeaning association sl data elicited image description short news identified two production rule structuring expression multiplicity lsf explain newly extracted production rule different existing one goal refine azee approach allow coverage growing part lsf work could lead improvement sl synthesis sl automatic translation
intonational information frequently discarded speech recognition assigned default heuristic texttospeech generation however many application involving dialogue interactive discourse intonation conveys significant information ignore peril translating telephone personal assistant interesting test case salience rapidly shifting discourse topic fact sentence machinegenerated rather written human combine make application particularly vulnerable poor theoretical grasp intonation function discus number approach problem application ranging cheap trick combinatory grammarbased theory semantics involved syntaxphonology interface building generating interpretation
arls falcon system proven integrated ocr mt technology valuable asset soldier field bosnia haiti extended include six systran language pair response military need automatic translation capability pursue u national objective east asia pacific rim portable translator provide robust automatic translation bidirectionally english chinese japanese korean allow rapid assimilation foreign information twoway communication well public private sector
chainofthought cot prompting enables large language model solve complex reasoning problem generating intermediate step however confined inherent singlepass sequential generation process cot heavily relies initial decision causing error early step accumulate impact final answer contrast human adopt recursive thinking tackling complex reasoning problem ie iteratively breaking original problem approachable subproblems aggregating answer resolve original one inspired human cognitive process propose socratic questioning divideandconquer style algorithm mimic recursive thinking process specifically socratic questioning leverage large language model raise answer subquestions collecting enough information tackle original question unlike cot socratic questioning explicitly navigates thinking space stimulates effective recursive thinking robust towards error thinking process extensive experiment several complex reasoning task including mmlu math logiqa visual questionanswering demonstrate significant performance improvement stateoftheart prompting method cot treeofthought qualitative analysis clearly show intermediate reasoning step elicited socratic questioning similar human recursively thinking process complex reasoning problem
neural networkbased sequencetosequence seqseq model strongly suffer lowdiversity problem come opendomain dialogue generation bland generic utterance usually dominate frequency distribution daily chitchat avoiding generate interesting response requires complex data filtering sampling technique modifying training objective paper propose new perspective diversify dialogue generation leveraging textitnonconversational text compared bilateral conversation nonconversational text easier obtain diverse cover much broader range topic collect largescale nonconversational corpus multi source including forum comment idiom book snippet present training paradigm effectively incorporate text via iterative back translation resulting model tested two conversational datasets different domain shown produce significantly diverse response without sacrificing relevance context
nonautoregressive machine translation nat model demonstrated significant inference speedup suffer inferior translation accuracy common practice tackle problem transferring autoregressive machine translation knowledge nat model eg knowledge distillation work hypothesize empirically verify nat encoders capture different linguistic property source sentence therefore propose adopt multitask learning transfer knowledge nat model encoder sharing specifically take model auxiliary task enhance nat model performance experimental result wmt ende wmt enro datasets show proposed multitask nat achieves significant improvement baseline nat model furthermore performance largescale wmt wmt ende datasets confirm consistency proposed method addition experimental result demonstrate multitask nat complementary knowledge distillation standard knowledge transfer method nat
scenariobased question answering sqa attracted increasing research attention typically requires retrieving integrating knowledge multiple source applying general knowledge specific case described scenario sqa widely exists medical geography legal domainsboth practice exam paper introduce geosqa dataset consists scenario multiplechoice question geography domain high school level diagram eg map chart manually annotated natural language description benefit nlp research benchmark result variety stateoftheart method question answering textual entailment reading comprehension demonstrate unique challenge presented sqa future research
paper describe system submitted semeval task assessing humor edited news headline participated subtasks main goal predict mean funniness edited headline given original edited headline system involves two similar subnetworks generate vector representation original edited headline respectively subtract operation output two subnetworks predict funniness edited headline
salient feature neural machine translation nmt endtoend nature training employed eschewing need separate component model different linguistic phenomenon rather nmt model learns translate individual sentence labeled data however traditional nmt method trained large parallel corpus onetoone sentence mapping make implicit assumption sentence independence make challenging current nmt system model intersentential discourse phenomenon recent research direction mainly leverage single previous source sentence model discourse paper proposes incorporation context window spanning previous well next sentence sourceside context previously generated output targetside context using effective nonrecurrent architecture based selfattention experiment show improvement noncontextual model well contextual method using previous context
computeraided summarisation technology developed university wolverhampton complement automatic summarisation produce high quality summary less effort achieve userfriendly environment incorporates several wellknown summarisation method developed paper present main feature computeraided summarisation environment explains change introduced result user feedback
order access indigenous regional knowledge contained language corpus semantic tool network method typically employed paper present approach identification dialectal variation word word pertain high german example nonstandard language legacy collection questionnaire bavarian dialect austria dbo based selected cultural category relevant wider project context common word cultural category lemma using germalemma identified word embedding model semantic vicinity word explored followed use german wordnet germanet hunspell tool whilst none tool comprehensive coverage standard german word serve indication dialect specific semantic hierarchy method tool applied study may serve example similar project dealing nonstandard endangered language collection aiming access analyze ultimately preserve native regional language heritage
efficient word representation play important role solving various problem related natural language processing nlp data mining text mining etc issue data sparsity pose great challenge creating efficient word representation model solving underlying problem problem intensified resourcepoor scenario due absence sufficient amount corpus work propose minimize effect data sparsity leveraging bilingual word embeddings learned parallel corpus train evaluate long short term memory lstm based architecture aspect level sentiment classification neural network architecture assisted handcrafted feature prediction show efficacy proposed model stateoftheart method two experimental setup ie multilingual crosslingual
many task question answering reading comprehension rely information extracted unreliable source system would thus benefit knowing whether statement unreliable source correct present experiment fever fact extraction verification task shared task involves selecting sentence wikipedia predicting whether claim supported sentence refuted enough information fact checking task benefit asserting disputing veracity claim also finding evidence position task dependent ideal model would consider veracity claim finding evidence also find evidence relevant thus jointly model sentence extraction verification fever shared task among participant ranked th blind test set prior additional human evaluation evidence
describe datadriven approach automatically explaining new nonstandard english expression given sentence building large dataset includes year crowdsourced example urbandictionarycom unlike prior study focus matching keywords slang dictionary investigate possibility learning neural sequencetosequence model generates explanation unseen nonstandard english expression given context propose dual encoder approacha wordlevel encoder learns representation context second characterlevel encoder learn hidden representation target nonstandard expression model produce reasonable definition new nonstandard english expression given context certain confidence
evergrowing presence social medium platform come increased spread harmful content need robust hate speech detection system system easily overfit specific target keywords evaluating without considering distribution shift might occur train test data overestimate benefit challenge hate speech model via new traintest split existing datasets rely clustering model hidden representation present two split variant subsetsumsplit closestsplit applied two datasets using four pretrained model reveal model catastrophically fail blind spot latent space result generalises developing split one model evaluating another analysis suggests clear surfacelevel property data split correlate decreased performance underscore task difficulty always humanly interpretable recommend incorporating latent featurebased split model development release two split via genbench benchmark
given partial description like opened hood car human reason situation anticipate might come next examined engine paper introduce task grounded commonsense inference unifying natural language inference commonsense reasoning present swag new dataset k multiple choice question rich spectrum grounded situation address recurring challenge annotation artifact human bias found many existing datasets propose adversarial filtering af novel procedure construct debiased dataset iteratively training ensemble stylistic classifier using filter data account aggressive adversarial filtering use stateoftheart language model massively oversample diverse set potential counterfactuals empirical result demonstrate human solve resulting inference problem high accuracy various competitive model struggle task provide comprehensive analysis indicates significant opportunity future research
introduce twt new treebank turkish consists web wikipedia sentence annotated segmentation morphology partofspeech dependency relation date largest publicly available humanannotated morphosyntactic turkish treebank term annotated word count also first large turkish dependency treebank dedicated wikipedia section present tagsets methodology used annotating treebank also result baseline experiment turkish dependency parsing treebank
neural conversational qa task sharc require system answer question based content given passage studying recent stateoftheart model sharc qa task found indication model learn spurious cluespatterns dataset heuristicbased program built exploit pattern comparative performance neural model paper share finding four type pattern sharc corpus neural model exploit motivated finding create share modified dataset fewer spurious pattern original dataset consequently allowing model learn better
data balancing known technique improving performance classification task work define novel balancingviageneration framework termed balagen balagen consists flexible balancing policy coupled text generation mechanism combined two technique used augment dataset balanced distribution evaluate balagen three publicly available semantic utterance classification suc datasets one new covid qa dataset published first time work demonstrates optimal balancing policy significantly improve classifier performance augmenting part class undersampling others furthermore capitalizing advantage balancing show usefulness relevant balagen framework component validate superiority balagen ten semantic utterance datasets taken reallife goaloriented dialogue system based result encourage using data balancing prior training text classification task
paper describes winning system endtoend pipeline phase nlpcontributiongraph task system composed three bertbased model three model used extract sentence entity triple respectively experiment show sampling adversarial training greatly boost system endtoend pipeline phase system got average f significantly higher secondplaced system got average f
present novel multitask attention based neural network model address implicit discourse relationship representation identification two type representation learning attention based neural network learning discourse relationship representation two argument multitask framework learning knowledge annotated unannotated corpus extensive experiment performed two benchmark corpus ie pdtb conll datasets experimental result show proposed model outperforms stateoftheart system benchmark corpus
automated generation information indicating characteristic article headline key phrase summary category help writer alleviate workload previous research tackled task using neural abstractive summarization classification method however output may inconsistent generated individually purpose study generate multiple output consistently introduce multitask learning model shared encoder multiple decoder task propose novel loss function called hierarchical consistency loss maintain consistency among attention weight decoder evaluate consistency employ human evaluation result show model generates consistent headline key phrase category addition model outperforms baseline model rouge score generates adequate fluent headline
quality estimation qe machine translation mt system task growing importance reduces cost postediting allowing machinetranslated text used formal occasion work describe submission system wmt sentencelevel qe task mainly explore utilization pretrained translation model qe adopt bidirectional translationlike strategy strategy similar elmo additionally condition source sentence experiment wmt qe dataset show strategy make pretraining slightly harder bring improvement qe wmt qe task system ranked second place ende nmt dataset third place enru nmt dataset
information extraction ie scientific text used guide reader central information scientific document narrow ie system extract fraction information captured open ie system perform well long complex sentence encountered scientific text work combine output type system achieve semiopen relation extraction new task explore biology domain first present focused open biological information extraction fobie dataset use fobie train stateoftheart narrow scientific ie system extract tradeoff relation argument central biology text run narrow ie system stateoftheart open ie system corpus k openaccess scientific biological text show significant amount erroneous uninformative open ie extraction filtered using narrow ie extraction furthermore show retained extraction significantly often informative reader
present first dataset targeted endtoend nlg czech restaurant domain along several strong baseline model using sequencetosequence approach nonenglish nlg underexplored general czech morphologically rich language make task even harder since czech requires inflecting named entity delexicalization copy mechanism work outofthebox lexicalizing generated output nontrivial experiment present two different approach problem using neural language model select correct inflected form lexicalizing twostep generation setup sequencetosequence model generates interleaved sequence lemma morphological tag inflected morphological generator
paper describes neurosent system participated semeval task system take supervised approach build neural network word embeddings word embeddings built starting repository user generated review thus specific sentiment analysis task tweet converted corresponding vector representation given input neural network aim learning different semantics contained emotion taken account semeval task output layer adapted based characteristic subtask preliminary result obtained provided training set encouraging pursuing investigation direction
abstract derived biomedical literature possess distinct domainspecific characteristic including specialised writing style biomedical terminology necessitate deep understanding related literature result existing language model struggle generate technical summary par produced biomedical expert given absence domainspecific background knowledge paper aim enhance performance language model biomedical abstractive summarisation aggregating knowledge external paper cited within source article propose novel attentionbased citation aggregation model integrates domainspecific knowledge citation paper allowing neural network generate summary leveraging paper content relevant knowledge citation paper furthermore construct release largescale biomedical summarisation dataset serf foundation research extensive experiment demonstrate model outperforms stateoftheart approach achieves substantial improvement abstractive biomedical text summarisation
information act sentence understanding robustly represented human brain investigate question comparing sentence encoding model brain decoding task sentence experimental participant seen must predicted fmri signal evoked sentence take pretrained bert architecture baseline sentence encoding model finetune variety natural language understanding nlu task asking lead improvement braindecoding performance find none sentence encoding task tested yield significant increase brain decoding performance task ablation representational analysis find task produce syntaxlight representation yield significant improvement brain decoding performance result constrain space nlu model could best account human neural representation language also suggest limit possibility decoding finegrained syntactic information fmri human neuroimaging
text simplification important branch natural language processing present method used evaluate semantic retention text simplification mostly based string matching propose sema text simplification evaluation measure semantic alignment based semantic alignment semantic alignment include complete alignment partial alignment hyponymy alignment experiment show evaluation result sema high consistency human evaluation simplified corpus chinese english news text
event detection ed seek discover classify event instance plain text previous method ed typically adopt supervised learning requiring fully labeled highquality training data however realworld application may obtain clean training data partially labeled one could substantially impede learning process work conduct seminal study learning partial annotation edwe propose new trigger localization formulation using contrastive learning distinguish groundtruth trigger context showing decent robustness addressing partial annotation noise impressively extreme scenario event unlabeled approach achieves f score addition reannotate make available two fully annotated subset ace serve unbiased benchmark event detection hope approach data inspire future study vital yet understudied problem
adaptive policy better fixed policy simultaneous translation since flexibly balance tradeoff translation quality latency based current context information previous method obtaining adaptive policy either rely complicated training process underperform simple fixed policy design algorithm achieve adaptive policy via simple heuristic composition set fixed policy experiment chinese textgreater english german textgreater english show adaptive policy outperform fixed one bleu point latency surprisingly even surpasses bleu score fullsentence translation greedy mode close beam mode much lower latency
rise increasingly powerful userfacing nlp system growing interest assessing whether good representation uncertainty evaluating quality predictive distribution outcome identify two main perspective drive starkly different evaluation protocol first treat predictive probability indication model confidence second indication human label variation discus merit limitation take position crucial trustworthy fair nlp system exploiting single predictive distribution limiting recommend tool highlight exciting direction towards model disentangled representation uncertainty prediction uncertainty human label
work propose approach generating statement explicate implicit knowledge connecting sentence text make use pretrained language model refine finetuning specifically prepared corpus enriched implicit information constraining relevant concept connecting commonsense knowledge path manual automatic evaluation generation show refining language model proposed generate coherent grammatically sound sentence explicate implicit knowledge connects sentence pair text indomain outofdomain test data
despite impressive empirical success neural machine translation nmt standard benchmark limited parallel data impedes application nmt model many language pair data augmentation method backtranslation make possible use monolingual data help alleviate issue backtranslation fails extreme lowresource scenario especially syntactically divergent language paper propose simple yet effective solution whereby targetlanguage sentence reordered match order source used additional source trainingtime supervision experiment simulated lowresource japanesetoenglish real lowresource uyghurtoenglish scenario find significant improvement semisupervised alternative
digital archive collection contributed community known communitygenerated digital content cgdc important source historical cultural knowledge however cgdc item easily searchable due semantic information obscured within textual metadata paper investigate extent stateoftheart generaldomain entity linking el model ie blink epgel mgenre map named entity mentioned cgdc textual metadata wikidata entity evaluate compare performance annotated dataset cgdc textual metadata provide error analysis way informing future study aimed enriching cgdc metadata using entity linking method
paper describes approach handling structural divergence recovering dropped argument implemented korean english machine translation system approach relies canonical predicateargument structure dependency structure provide suitable pivot representation handling structural divergence recovery dropped argument also converted interface representation many offtheshelf parser generator
research speakeradapted neural machine translation nmt scarce one main challenge personalized mt system finding large enough annotated parallel datasets speaker information rabinovich et al published annotated parallel dataset enfr ende however many language pair sufficiently large annotated datasets available
web service increasingly used natural language processing community way increase interoperability amongst language resource paper extends previous work integrating two different platform ie heart gold language grid language grid infrastructure built top internet provide distributed language service heart gold known middleware architecture integrating deep shallow natural language processing component new feature integrated architecture combination composite language service language grid multiple linguistic processing component heart gold provide better quality language resource available web thus language resource different characteristic combined based concept service oriented computing different treatment combination heart gold fully integrated language grid environment would contribute heterogeneity language service
enormous amount conversation occurs online every day chat platform multiple conversation may take place concurrently interleaved conversation lead difficulty following discussion also retrieving relevant information simultaneous message conversation disentanglement aim separate intermingled message detached conversation paper propose leverage representation learning conversation disentanglement siamese hierarchical convolutional neural network shcnn integrates local global representation message first presented estimate conversationlevel similarity closely posted message estimated similarity score algorithm conversation identification similarity ranking cisir derives conversation based highconfidence message pair pairwise redundancy experiment conducted four publicly available datasets conversation reddit irc channel experimental result show approach significantly outperforms comparative baseline pairwise similarity estimation conversation disentanglement
accurately extracting structured content pdfs critical first step nlp scientific paper recent work improved extraction accuracy incorporating elementary layout information example token position page language model pretraining introduce new method explicitly model visual layout vila group text line text block improve performance ivila approach show simply inserting special token denoting layout group boundary model input lead macro f improvement token classification hvila approach show hierarchical encoding layoutgroups result inference time reduction less macro f loss unlike prior layoutaware approach method require expensive additional pretraining finetuning show reduce training cost experiment conducted newly curated evaluation suite svlue unifies existing automatically labeled datasets includes new dataset manual annotation covering diverse paper scientific discipline pretrained weight benchmark datasets source code available urlhttpsgithubcomallenaivila
develop investigate several crosslingual alignment approach neural sentence embedding model supervised inference classifier infersent sequential encoderdecoder model evaluate three alignment framework applied model joint modeling representation transfer learning sentence mapping using parallel text guide alignment result support representation transfer scalable approach modular crosslingual alignment neural sentence embeddings observe better performance compared joint model intrinsic extrinsic evaluation particularly smaller set parallel data
grammatical error diagnosis essential part languagelearning tutoring system based data set chinese grammar error detection task proposed system measure likelihood correction candidate generated deleting inserting character word moving substring different position substituting preposition preposition substituting word synonym similar string sentence likelihood measured based frequency substring spaceremoved version google ngrams evaluation training set show missingrelated selectionrelated candidate generation method promising performance final system achieved precision recall identification level evaluated test set
tree model well known expressing historic evolution language model considered method describing genetic relationship language nevertheless researcher question model ability predict proximity two language since represents genetic relatedness rather linguistic resemblance defining language proximity model active research area many year paper explore partofspeech model defining proximity language using multilingual language model finetuned task crosslingual partofspeech tagging train model one language evaluate another measured performance used define proximity two language developing model show reconstruct part tree model
paper present goldstandard reference corpus historical slovene containing sampled page text part written page transcription associated facsimile word text manually annotated modernday equivalent lemma partofspeech paper present structure text collection sampling procedure annotation process encoding corpus corpus meant facilitate hlt research enable corpus based diachronic study historical slovene corpus encoded according text encoding initiative guideline tei p available via concordancer download urlhttpnlijssiimp creative common attribution licence
explore relationship empathy toxicity context online mental health forum despite common assumption negative correlation concept empirically examined augment epitome mental health empathy dataset toxicity label using two widely employed toxicharmful content detection apis perspective api openai moderation api find notable presence toxicharmful content within empathetic response weak negative correlation two variable qualitative analysis revealed contribution labeled empathetic often contain harmful content promotion suicidal idea result highlight need reevaluating empathy independently toxicity future research encourage reconsideration empathy role natural language generation evaluation
pretrained language model plms shown vulnerable minor word change pose significant threat realworld system previous study directly focus manipulating word input limited mean generating adversarial sample lacking generalization versatile realworld attack paper study basic structure transformerbased plms selfattention sa mechanism propose powerful perturbation technique named hackattend perturbs attention score within sa matrix via meticulously crafted attention mask show stateoftheart plms fall heavy vulnerability minor attention perturbation resulting high attack success rate paper extends conventional text attack word perturbation general structural perturbation introduce sattend novel smoothing technique effectively make sa robust via structural perturbation empirically demonstrate simple yet effective technique achieves robust performance par adversarial training facing various text attacker
paper describes postechs submission wmt shared task automatic postediting ape focus increasing quantity available ape data overcome shortage humancrafted training data experiment implemented noising module simulates four type postediting error introduced module transformerbased multisource ape model noising module implant error text target side parallel corpus training phase make synthetic mt output increasing entire number training sample also generated additional training data using parallel corpus nmt model released quality estimation task used data train ape model experimental result wmt englishgerman ape data set show improvement baseline term ter bleu score primary submission achieved improvement ter bleu contrastive submission achieved improvement ter bleu
paper address debiasing news editing evaluates effectiveness conversational large language model task designed evaluation checklist tailored news editor perspective obtained generated text three popular conversational model using subset publicly available dataset medium bias evaluated text according designed checklist furthermore examined model evaluator checking quality debiased model output finding indicate none llm perfect debiasing notably model including chatgpt introduced unnecessary change may impact author style create misinformation lastly show model perform proficiently domain expert evaluating quality debiased output
introduce metaicl metatraining incontext learning new metatraining framework fewshot learning pretrained language model tuned incontext learning large set training task metatraining enables model effectively learn new task context test time simply conditioning training example parameter update taskspecific template experiment large diverse collection task consisting nlp datasets including classification question answering natural language inference paraphrase detection across seven different metatrainingtarget split metaicl outperforms range baseline including incontext learning without metatraining multitask learning followed zeroshot transfer find gain particularly significant target task domain shift metatraining task using diverse set metatraining task key improvement also show metaicl approach sometimes beat performance model fully finetuned target task training data outperforms much bigger model nearly x parameter
social medium platform along many public forum internet shown significant rise case abusive behavior misogynism misandry homophobia cyberbullying tackle concern technology developed applied tedious timeconsuming task identify report block offender task automate process identifying abusive comment classify appropriate category datasets provided dravidianlangtechacl organizer codemixed form tamil text trained datasets using pretrained transformer model bertmbert xlnet achieved weighted average f score tamilenglish code mixed text tamil text
visual question answering vqa challenging model handle multimodal information also hard collect sufficient training example many question one ask image result vqa model trained solely humanannotated example could easily overfit specific question style image content asked leaving model largely ignorant sheer diversity question existing method address issue primarily introducing auxiliary task visual grounding cycle consistency debiasing paper take drastically different approach found many unknown learned vqa model indeed known dataset implicitly instance question asking object different image likely paraphrase number detected annotated object image already provides answer many question even question annotated image building upon insight present simple data augmentation pipeline simpleaug turn known knowledge training example vqa show augmented example notably improve learned vqa model performance vqacp dataset language prior shift also vqa v dataset without shift method open door leverage weaklylabeled unlabeled image principled way enhance vqa model code data publicly available urlhttpsgithubcomheendungsimpleaug
neural machine translation represents exciting leap forward translation quality longstanding weakness resolve remain address question challenge set approach translation evaluation error analysis challenge set consists small set sentence handdesigned probe system capacity bridge particular structural divergence language exemplify approach present englishfrench challenge set use analyze phrasebased neural system resulting analysis provides finegrained picture strength neural system also insight linguistic phenomenon remain reach
understand legal document realworld application semeval task proposes shared subtask rhetorical role rrs prediction requires system automatically assign rr label semantical segment legal text paper propose legalbert based hierarchical bilstm model conditional random field crf rr prediction primarily consists two part wordlevel sentencelevel encoders wordlevel encoder first adopts legaldomain pretrained language model legalbert initially wordembedding word sentence document wordlevel bilstm encoding sentence representation sentencelevel encoder us attentive pooling method sentence embedding sentencelevel bilstm document modeling finally crf utilized predict rrs sentence officially released result show method outperformed baseline system team th rank participant subtask
year slow steady change attitude society towards different kind sexuality however social medium platform people license anonymous toxic comment targeted homosexual transgenders lgbtq community uncommon detection homophobic comment social medium useful making internet safer place everyone task used combination word embeddings svm classifier well bertbased transformer achieved weighted fscore english dataset tamil dataset tamilenglish codemixed dataset
grasping commonsense property everyday concept important prerequisite language understanding contextualised language model reportedly capable predicting commonsense property humanlevel accuracy argue result inflated high similarity training test concept mean model capture concept similarity perform well even capture knowledge commonsense property setting overlap property considered training testing find empirical performance standard language model drop dramatically address study possibility finetuning language model explicitly model concept property particular train separate concept property encoders two type readily available data extracted hyponymhypernym pair generic sentence experimental result show resulting encoders allow u predict commonsense property much higher accuracy possible directly finetuning language model also present experimental result related task unsupervised hypernym discovery
paper describes feature new bit window version pahos englishspanish engspan spanishenglish spanam machine translation software new dictionary update interface designed help user add terminology lexicon encourage write contextsensitive rule improve quality output expanded search capability provide instant access related source target entry expression rule live system demonstration accompany presentation
one key step language resource creation identification text segment annotated markables depending task may vary nominal chunk named entity resolution potentially nested noun phrase coreference resolution mention larger text segment text segmentation markable identification typically carried semiautomatically running markable identifier correcting output handwhich increasingly done via annotator recruited crowdsourcing aggregating response paper present method identifying markables coreference annotation combine highperformance automatic markable detector checking gamewithapurpose gwap aggregation using bayesian annotation model method evaluated news data data variety genre result improvement f mention boundary seven percentage point compared stateoftheart domainindependent automatic mention detector almost three point indomain mention detector one key contribution proposal applicability case markables nested case coreference markables gwap several proposed markable detector task languageindependent thus applicable variety annotation scenario
automatic summarisation written text direct speech usually deemed unsuitable inclusion important sentence due fact human usually include quotation create summary paper argue despite generally negative attitude direct speech useful summarisation ignoring result omission important relevant information present analysis corpus annotated newswire text substantial amount speech marked different annotator describe direct speech included summary attempt make direct speech appropriate summary also describe rule currently developed transform summaryacceptable format
domainspecific goaloriented dialogue system typically require modeling three type input namely knowledgebase associated domain ii history conversation sequence utterance iii current utterance response need generated modeling input current stateoftheart model memseq typically ignore rich structure inherent knowledge graph sentence conversation context inspired recent success structureaware graph convolutional network gcns various nlp task machine translation semantic role labeling document dating propose memoryaugmented gcn goaloriented dialogue model exploit entity relation graph knowledgebase ii dependency graph associated utterance compute richer representation word entity take cognizance fact certain situation conversation codemixed language dependency parser may available show situation could use global word cooccurrence graph enrich representation utterance experiment four datasets modified dstc dataset ii recently released codemixed version dstc dataset four language iii wizardofoz style cam dataset iv wizardofoz style multiwoz dataset four datasets method outperforms existing method wide range evaluation metric
essential task taskoriented dialog system slot filling requires extensive training data certain domain however data always available hence crossdomain slot filling naturally arisen cope data scarcity problem paper propose coarsetofine approach coach crossdomain slot filling model first learns general pattern slot entity detecting whether token slot entity predicts specific type slot entity addition propose template regularization approach improve adaptation robustness regularizing representation utterance based utterance template experimental result show model significantly outperforms stateoftheart approach slot filling furthermore model also applied crossdomain named entity recognition task achieves better adaptation performance existing baseline code available urlhttpsgithubcomzliucrcoach
child less linguistic skill adult make difficult understand text instance browsing internet context present novel method predicts minimal age text understood method analysis sentence text using recurrent neural network aggregate information provide textlevel prediction different approach proposed compared baseline model sentence text level experiment carried corpus text k sentence best model based lstms outperforms stateoftheart result achieves mean absolute error sentence text level respectively
crosslingual representation learning transfer knowledge resourcerich data resourcescarce one improve semantic understanding ability different language however previous work rely shallow unsupervised data generated token surface matching regardless global contextaware semantics surrounding text token paper propose unsupervised pseudo semantic data augmentation unipsda mechanism crosslingual natural language understanding enrich training data without human intervention specifically retrieve token similar meaning semantic data augmentation across different language propose sequential clustering process stage within single language across multiple language language family across language multiple language family meanwhile considering multilingual knowledge infusion contextaware semantics alleviating computation burden directly replace key constituent sentence abovelearned multilingual family knowledge viewed pseudosemantic infusion process optimized via three debiasing technique without introducing neural parameter extensive experiment demonstrate model consistently improves performance general zeroshot crosslingual natural language understanding task including sequence classification information extraction question answering
understanding need fear citizen especially pandemic covid essential government legislative entity effective covid strategy requires public understand accept restriction plan imposed entity paper explore causal mediation scenario want emphasize use nlp method combination method economics social science based sentiment analysis tweet towards current covid situation uk sweden conduct several causal inference experiment attempt decouple effect government restriction mobility behavior effect occurs due public perception covid strategy country avoid biased result control valid country specific epidemiological timevarying confounders comprehensive experiment show change mobility caused country implemented policy also support individual fight pandemic find social medium text important source capture citizen concern trust policy maker suitable evaluate success government policy
existing research fairness evaluation document classification model mainly us synthetic monolingual data without ground truth author demographic attribute work assemble publish multilingual twitter corpus task hate speech detection inferred four author demographic factor age country gender raceethnicity corpus cover five language english italian polish portuguese spanish evaluate inferred demographic label crowdsourcing platform figure eight examine factor cause bias take empirical analysis demographic predictability english corpus measure performance four popular document classifier evaluate fairness bias baseline classifier authorlevel demographic attribute
despite potential federated learning known vulnerable backdoor attack many robust federated aggregation method proposed reduce potential backdoor risk however mainly validated cv field paper find nlp backdoor hard defend cv provide theoretical analysis malicious update detection error probability determined relative backdoor strength nlp attack tend small relative backdoor strength may result failure robust federated aggregation method nlp attack inspired theoretical result choose dimension higher backdoor strength settle issue propose novel federated aggregation algorithm dimkrum nlp task experimental result validate effectiveness
sentiment analysis sa system widely deployed many world language welldocumented evidence demographic bias system language beyond english scarcer training data often supplemented transfer learning using pretrained model including multilingual model trained language case even supervision data come language crosslingual transfer also import new bias answer question use counterfactual evaluation test whether gender racial bias imported using crosslingual transfer compared monolingual transfer setting across five language find system using crosslingual transfer usually become biased monolingual counterpart also find racial bias much prevalent gender bias spur research topic release sentiment model used study intermediate checkpoint throughout training yielding distinct model also release evaluation code
recently distant supervision gained great success finegrained entity typing fet despite efficiency reducing manual labeling effort also brings challenge dealing false entity type label distant supervision assigns label contextagnostic manner existing work alleviated issue partiallabel loss usually suffer confirmation bias mean classifier fit pseudo data distribution given work propose regularize distantly supervised model compact latent space clustering clsc bypass problem effectively utilize noisy data yet proposed method first dynamically construct similarity graph different entity mention infer label noisy instance via label propagation based inferred label mention embeddings updated accordingly encourage entity mention close semantics form compact cluster embedding space thus leading better classification performance extensive experiment standard benchmark show clsc model consistently outperforms stateoftheart distantly supervised entity typing system significant margin
rapidly evolving field crypto asset white paper essential document investor guidance subject unprecedented content requirement european union market cryptoassets regulation micar natural language processing nlp serve powerful tool analyzing document assisting regulatory compliance paper delivers two contribution topic first survey existing application textual analysis unregulated crypto asset white paper uncovering research gap could bridged interdisciplinary collaboration conduct analysis change introduced micar highlighting opportunity challenge integrating nlp within new regulatory framework finding set stage research potential benefit regulator crypto asset issuer investor
surge pretraining witnessed rapid development document understanding recently pretraining finetuning framework effectively used tackle text various format including plain text document text web text despite achieving promising performance existing pretrained model usually target one specific document format one time making difficult combine knowledge multiple document format address propose xdoc unified pretrained model deal different document format single model parameter efficiency share backbone parameter different format word embedding layer transformer layer meanwhile introduce adaptive layer lightweight parameter enhance distinction across different format experimental result demonstrated parameter xdoc achieves comparable even better performance variety downstream task compared individual pretrained model cost effective realworld deployment code pretrained model publicly available urlhttpsakamsxdoc
paper describe experiment application text clustering technique dossier amendment proposed legislation discussed italian senate aim assist senate staff detection group amendment similar textual formulation order schedule simultaneous voting experiment show exploitation extraction annotation normalization domain feature crucial improve clustering performance many problematic case properly dealt standard approach similarity engine implemented integrated experimental feature internal application used management amendment senate assembly committee thanks open data strategy pursued senate several year document data produced institution publicly available reuse open format
paper summarizes methodology result bea shared task competition focused predicting item difficulty response time retired multiplechoice item united state medical licensing examination usmle extracted linguistic feature item stem response option using multiple method including biomedbert model fasttext embeddings cohmetrix extracted feature combined additional feature available item metadata eg item type predict item difficulty average response time result showed biomedbert model effective predicting item difficulty finetuned model based fasttext word embeddings best model predicting response time
present novel method injecting temporality entailment graph address problem spurious entailment may arise similar temporally distinct event involving pair entity focus sport domain pair team play different occasion different outcome present unsupervised model aim learn entailment winlose play avoiding pitfall learning nonentailments win lose evaluate model manually constructed dataset showing incorporating time interval applying temporal window around effective strategy
detecting hate speech codemixed language vital secure online space curbing harmful content promoting inclusive communication safeguarding user discrimination despite linguistic complexity codemixed language study explores diverse preprocessing method find transliteration method excels handling linguistic variation research comprehensively investigates machine learning deep learning approach namely logistic regression bidirectional gated recurrent unit bigru model model achieved f score respectively contributing ongoing effort combat hate speech codemixed language offering valuable insight future research critical domain
curse multilinguality training multilingual pretrained language model mplms refers negative interference language especially capacity limited increasing capacity may appear intuitive overcoming curse negatively affect training inference cost distinction pursuing competing goal reducing negative interference keeping capacity per language less specifically first scale model reduce interference search perlanguage subnetwork lottery ticket comparable performance full model according lottery ticket hypothesis scalethenfindticket approach alleviates interfering signal scaled model redistributes parameter keep parameter reduced finally avoid cost multiple retraining searching multilingual ticket explore zeroshot neural architecture search na method investigate appropriate zeroshot na method find multilingual ticket proposed multilingual ticket reduce inference cost model language boosting performance ticket search cost negligible ticket found qualitatively preserve linguistic similarity code publicly available
large scale pretrained model demonstrated strong performance several natural language generation understanding benchmark however introducing commonsense generate realistic text remains challenge inspired previous work commonsense knowledge generation generative commonsense reasoning introduce two method add commonsense reasoning skill knowledge abstractive summarization model method beat baseline rouge score demonstrating superiority model baseline human evaluation result suggest summary generated method realistic fewer commonsensical error
pretraining nlp model variant masked language model mlm objective recently led significant improvement many task paper examines benefit pretrained model function number training sample used downstream task several text classification task show number training example grow million accuracy gap finetuning bertbased model training vanilla lstm scratch narrow within finding indicate mlmbased model might reach diminishing return point supervised data size increase significantly
article describes submission semeval task factchecking community forum system discussion participated subtask decide whether question asks factual information opinionadvice socializing primary submission ranked second one among participant official evaluation phase article present primary solution deeply regularized residual neural network drr nn universal sentence encoder embeddings followed description two contrastive solution based ensemble method
documentlevel information extraction ie task recently begun revisited earnest using endtoend neural network technique successful sentencelevel ie counterpart evaluation approach however limited number dimension particular precisionrecallf score typically reported provide insight range error model make build work kummerfeld klein propose transformationbased framework automating error analysis documentlevel event nary relation extraction employ framework compare two stateoftheart documentlevel templatefilling approach datasets three domain gauge progress ie since inception year ago v four system muc evaluation
meme pictorial representation idea theme age emerging volume social medium platform meme spreading rapidly person person becoming trending way opinion expression however due multimodal characteristic meme content detecting analyzing underlying emotion meme formidable task paper present approach detecting emotion meme defined semeval task team csecukdema employ attentionbased neural network model tackle problem upon extracting text content meme using optical character reader ocr represent using distributed representation word next perform convolution based multiple kernel size obtain higherlevel feature sequence feature sequence fed attentive timedistributed bidirectional lstm model learn longterm dependency effectively experimental result show proposed neural model obtained competitive performance among participant system
deep neural network based machine learning model shown perform poorly unseen outofdomain example numerous recent study transfer learning aim avoid overfitting improve generalizability leveraging information obtained multiple task yet benefit transfer learning depend largely task selection finding right method sharing thesis hypothesize current deep neural network based transfer learning model achieve fullest potential various task still many task combination benefit transfer learning considered current model end started research implementing novel multitask learner relaxed annotated data requirement obtained performance improvement two nlp task devise model tackle task multiple area machine learning bioinformatics computer vision addition nlp
propose multitask probabilistic approach facilitate distantly supervised relation extraction bringing closer representation sentence contain knowledge base pair achieve bias latent space sentence via variational autoencoder vae trained jointly relation classifier latent code guide pair representation influence sentence reconstruction experimental result two datasets created via distant supervision indicate multitask learning result performance benefit additional exploration employing knowledge base prior thevae reveals sentence space shifted towards knowledge base offering interpretability improving result
beam search widely used neural machine translation usually improves translation quality compared greedy search widely observed however beam size larger hurt translation quality explain happens propose several method address problem furthermore discus optimal stopping criterion method result show hyperparameterfree method outperform widelyused hyperparameterfree heuristic length normalization bleu achieve best result among method chinesetoenglish translation
work explores crosslingual transfer learning tl named entity recognition focusing bootstrapping japanese english deep neural network model adopted best combination weight transfer extensively investigated moreover novel approach presented overcomes linguistic difference language pair romanizing portion japanese input experiment conducted external datasets well internal largescale realworld one gain tl achieved evaluated case finally influence tl target dataset size target tagset distribution investigated
despite recent success deep neural network natural language processing sphere artificial intelligence interpretability remains challenge analyze representation learned neural machine translation nmt model various level granularity evaluate quality relevant extrinsic property particular seek answer following question accurately word structure captured within learned representation important aspect translating morphologically rich language ii representation capture longrange dependency effectively handle syntactically divergent language iii representation capture lexical semantics conduct thorough investigation along several parameter layer architecture capture linguistic phenomenon ii choice translation unit word character subword unit impact linguistic property captured underlying representation iii encoder decoder learn differently independently iv representation learned multilingual nmt model capture amount linguistic information bilingual counterpart datadriven quantitative evaluation illuminates important aspect nmt model ability capture various linguistic phenomenon show deep nmt model trained endtoend fashion without provided direct supervision training process learn nontrivial amount linguistic information notable finding include following observation word morphology partofspeech information captured lower layer model ii contrast lexical semantics nonlocal syntactic semantic dependency better represented higher layer model iii representation learned using character informed wordmorphology compared learned using subword unit iv representation learned multilingual model richer compared bilingual model
paper describes first step creating lemma bank old irish ce within linked data paradigm taking inspiration similar resource latin built part lila project focus extraction rdf conversion noun goidelex novel highly structured morphological resource old irish aim strike good balance retaining representative level morphological granularity time keeping amount lemma variant within workable limit facilitate straightforward resource interlinking old irish planned future work
event relation recognition challenging language processing task required determine relation class pair query event causality condition isnt reliable clue use follow traditional statistical approach paper speculating relation class target event based relationclass distribution similar event minimal supervision used speculation process particular incorporate image processing acquisition similar event instance including utilization image visually representing event scene use neural network based image matching approximate calculation event test method acer corpus compared model fullysupervised neural network model experimental result show achieve comparable performance cnn slightly better lstm
light prominence pretrained language model plms across numerous downstream task shedding light learn important endeavor whereas previous work focus assessing indomain knowledge evaluate generalization ability biased scenario component combination could easy plms learn shortcut training corpus would lead poor performance testing corpus combinationally reconstructed training component result show plms able overcome distribution shift specific task sufficient data find overfitting lead model depend bias prediction thus hurting combinational generalization ability plms
propose system us long shortterm memory attention mechanism lstmattention model complete task lstmattention model us two lstm extract feature question answer pair feature sequentially composed using attention mechanism concatenating two vector one finally concatenated vector used input mlp mlps output layer us softmax function classify provided answer three category model capable extracting feature question answer pair well result show proposed system outperforms baseline algorithm
paper describes system built ynuhpcc team semeval task nlpcontributiongraph task involves first identifying sentence given natural language processing nlp scholarly article reflect research contribution binary classification identifying core scientific term relation phrase contribution sentence sequence labeling finally scientific term relation phrase categorized identified organized subjectpredicateobject triple form knowledge graph help multiclass classification multilabel classification developed system task using pretrained language representation model called bert stand bidirectional encoder representation transformer achieved good result average fscore evaluation phase part ranked th average fscore evaluation phase part also ranked th
cumulative effort past decade gone developing linguistic resource task ranging machine readable dictionary translation system enormous effort prohibitively expensive language outside largely european family possibility building resource automatically accessing electronic corpus language therefore great interest involved studying new lesser known language main stumbling block applying data driven technique directly require large corpus rarely available new language paper describes attempt setting bootstrapping agenda exploit scarce corpus resource may available outset researcher concerned language particular report result experiment use stateoftheart datadriven technique building linguistic resource sinhala noneuropean language virtually electronic resource
fundamental several knowledgecentric application need identify named entity textual mention however entity lack unique representation mention differ greatly variation arise complex way captured using textual similarity metric however entity underlying structure typically shared entity entity type help reason name variation discovering learning manipulating structure typically requires high manual effort form large amount labeled training data handwritten transformation program work propose activelearning based framework drastically reduces labeled data required learn structure entity show program mapping entity mention structure automatically generated using humancomprehensible label experiment show framework consistently outperforms handwritten program supervised learning model also demonstrate utility framework relation extraction entity resolution task
biomedical entity linking bel challenging task lowresource language due lack appropriate resource datasets knowledge base kb pretrained model paper propose approach create biomedical knowledge base german bel using umls information wikidata provides good coverage easily extended language contribution adapt several existing approach use german bel setup report result chosen method include sparse model using character ngrams multilingual biomedical entity linker two generalpurpose text retrieval model result show languagespecific kb provides good coverage lead improvement entity linking performance irrespective used model finetuned german bel model newly created umlswikidata kb well code reproduce result publicly available
despite recent finding conceptual linguistic organization personification relatively little knowledge lexical pattern grammatical template especially true case hungarian remained understudied language regarding construction figurative meaning generation present paper aim provide corpusdriven approach personification analysis framework cognitive linguistics approach based building semiautomatically processed research corpus perse corpus personifying linguistic structure annotated manually present test version corpus consists online car review written hungarian word altogether text tokenized lemmatized morphologically analyzed syntactically parsed postagged emagyar nlp tool identification personification adaptation mipvu protocol used combined additional analysis semantic relation within personifying multiword expression paper demonstrates structure corpus well level annotation furthermore give overview possible data type emerging analysis lexical pattern grammatical characteristic constructionlike behavior personification hungarian
named entity recognition ner foundational nlp task aim provide class label like person location organisation time number word free text named entity also multiword expression additional iob annotation information help label ner annotation process english european language considerable annotated data ner task indian language lack front term quantity following annotation standard paper release significantly sized standardabiding hindi ner dataset containing sentence token annotated tag discus dataset statistic essential detail provide indepth analysis ner tagset used data statistic tagset dataset show healthy pertag distribution especially prominent class like person location organisation since proof resourceeffectiveness building model resource testing model benchmark data leaderboard entry shared task aforesaid data use different language model perform sequence labelling task ner show efficacy data performing comparative evaluation model trained another dataset available hindi ner task dataset help achieve weighted f score tag collapse tagset discussed paper best knowledge available dataset meet standard volume amount variability diversity far hindi ner concerned fill gap work hope significantly help nlp hindi release dataset code model research urlhttpsgithubcomcfiltnlphiner
codeswitching csw common phenomenon occurs multilingual geographic social context raise challenging problem natural language processing tool focus machine translation mt csw text aim simultaneously disentangle translate two mixed language due lack actual translated csw data generate artificial training data regular parallel text experiment show training strategy yield mt system surpass multilingual system codeswitched text result confirmed alternative task aimed providing contextual translation l writing assistant
identification intensity ordering among polar positive negative word semantics lead finegrained sentiment analysis example master seasoned familiar point different intensity level though convey meaning semantics ie expertise good knowledge paper propose semisupervised technique us sentiment bearing word embeddings produce continuous ranking among adjective share common semantics system demonstrates strong spearmans rank correlation gold standard ranking show sentiment bearing word embeddings facilitate accurate intensity ranking system standard word embeddings wordvec glove wordvec stateoftheart intensity ordering task
propose fully bayesian framework learning ground truth label noisy annotator framework ensures scalability factoring generative bayesian soft clustering model label distribution classic david skene joint annotatordata model earlier research along line neither fully incorporated label distribution explored clustering annotator data framework incorporates property within graphical model designed provide better ground truth estimate annotator response input black box supervised learning algorithm conduct supervised learning experiment variation model compare performance several baseline model
sexism become growing concern social medium platform impact health internet negative impact society paper describes coco system participated semeval task explainable detection online sexism edo aim sexism detection various setting natural language understanding develop novel neural framework sexism detection misogyny combine text representation obtained using pretrained language model model bidirectional encoder representation transformer using bilstm architecture obtain local global semantic information considering edo dataset relatively small extremely unbalanced conducted data augmentation introduced two datasets field sexism detection moreover introduced focal loss loss function order improve performance processing imbalanced data classification system achieved f score textbackslash task binary sexism
transformerbased language model lm known capture factual knowledge parameter previous work looked factual association stored little known retrieved internally inference investigate question lens information flow given subjectrelation query study model aggregate information subject relation predict correct attribute intervention attention edge first identify two critical point information propagates prediction one relation position followed another subject position next analyzing information point unveil threestep internal mechanism attribute extraction first representation lastsubject position go enrichment process driven early mlp sublayers encode many subjectrelated attribute second information relation propagates prediction third prediction representation query enriched subject extract attribute perhaps surprisingly extraction typically done via attention head often encode subjectattribute mapping parameter overall finding introduce comprehensive view factual association stored extracted internally lm facilitating future research knowledge localization editing
field natural language processing nlp extracting method entity biomedical text challenging task scientific research paper commonly consist complex keywords domainspecific terminology new terminology continuously appearing research find method terminology biomedical text using rulebased machine learning technique first use linguistic feature extract method sentence candidate large corpus biomedical text construct silver standard biomedical corpus composed sentence rulebased method make use stanza dependency parsing module label method entity sentence using silver standard corpus train two machine learning algorithm automatically extract method entity biomedical text result show possible develop machine learning model automatically extract method entity reasonable accuracy without need gold standard dataset
unlike nonconversation scene emotion recognition dialogue erd pose complicated challenge due interactive nature intricate contextual information present method model historical utterance without considering content target utterance however different part historical utterance may contribute differently emotion inference different target utterance therefore propose finegrained extraction reasoning network fernet generate targetspecific historical utterance representation reasoning module effectively handle local global sequential dependency reason context update target utterance representation informed vector experiment two benchmark show method achieves competitive performance compared previous method
neural machine translation nmt model tend achieve best performance larger set parallel sentence provided training reason augmenting training set artificiallygenerated sentence pair boost performance nonetheless performance also improved small number sentence domain test set accordingly want explore use artificiallygenerated sentence along dataselection algorithm improve nmt model trained solely authentic data work show artificiallygenerated sentence beneficial authentic pair advantage used combination dataselection algorithm
unsupervised neural machine translation nmt utilizes monolingual data training quality backtranslated data play important role performance nmt system backtranslation generated pseudo parallel sentence pair quality taking inspiration domain adaptation indomain sentence given weight training paper propose approach filter backtranslated data part training process unsupervised nmt approach give weight good pseudo parallel sentence pair backtranslation phase calculate weight pseudo parallel sentence pair using sentencewise roundtrip bleu score normalized batchwise compare approach current state art approach unsupervised nmt
knowledge graph integration typically suffers widely existing dangling entity find alignment cross knowledge graph kg dangling entity set unavailable realworld scenario manually mining entity pair consist entity meaning laborconsuming paper propose novel accurate unsupervised method joint entity alignment ea dangling entity detection ded called ued ued mine literal semantic information generate pseudo entity pair globally guided alignment information ea utilizes ea result assist ded construct medical crosslingual knowledge graph dataset meded providing data ea ded task extensive experiment demonstrate ea task ued achieves ea result comparable stateoftheart supervised ea baseline outperforms current stateoftheart ea method combining supervised ea data ded task ued obtains highquality result without supervision
paper suggest key feature look successful parser ability lend naturally semantic interpretation therefore argue favour parser based semantically oriented model grammar demonstrating benefit model offer parsing process particular adopt systemic functional syntax basis implementing chart based probabilistic incremental parser nontrivial subset english
paper present method incorporating available linguistic information statistical language model used asr system transcribing spontaneous speech employ classbased language model paradigm use morphological tag basis worldtoclass mapping since number different tag least one order magnitude lower number word even task moderatelysized vocabulary tagbased model rather robustly estimated using even relatively small text corpus unfortunately robustness go hand hand restricted predictive ability classbased model hence apply twopass recognition strategy first pas performed standard wordbased ngram resulting lattice rescored second pas using aforementioned classbased model using decoding scenario managed moderately improve word error rate performed asr experiment
indepth analysis level language understanding required existing machine reading comprehension mrc benchmark provide insight reading capability machine paper propose ablationbased methodology assess extent mrc datasets evaluate understanding explicit discourse relation define seven mrc skill require understanding different discourse relation introduce ablation method verify whether skill required succeed dataset observing drop performance neural mrc model evaluated original modified dataset measure degree dataset requires skill order understood correctly experiment three largescale datasets bertbase albertxxlarge model show relative change skill small less result imply answered question examined datasets require understanding discourse structure text specifically probe natural language understanding need design challenging benchmark correctly evaluate intended skill
introduce inception new annotation platform task including interactive semantic annotation eg concept linking fact linking knowledge base population semantic frame annotation task time consuming demanding annotator especially knowledge base used address issue developing annotation platform incorporates machine learning capability actively assist guide annotator platform generic modular target range research domain need semantic annotation digital humanity bioinformatics linguistics inception publicly available opensource software
emergence social medium ecommerce platform enabled perpetrator spread negativity abuse individual organisation worldwide rapidly critical detect hate speech visual textual content may moderated excluded online platform keep sound safe user however multimodal hate speech detection complex challenging task people sarcastically present hate speech different modality ie image text involved content paper describes participation case multimodal hate speech event detection task task objective automatically detect hate speech target given textembedded image proposed transformerbased multimodal hierarchical fusion model detect hate speech present visual content jointly finetune language vision pretrained transformer model extract visualcontextualized feature representation textembedded image concatenate feature fed multisample dropout strategy moreover contextual feature vector fed bilstm module output bilstm module also pass multisample dropout employed arithmetic mean fusion fuse sample dropout output predict final label proposed method experimental result demonstrate model obtains competitive performance ranked th among participant
wassa shared task predicting empathy emotion personality trait consists essay conversation article textual form participant demographic information numerical form address task contribution include converting numerical information meaningful text information using appropriate template summarising lengthy article augmenting training data paraphrasing achieve contribution leveraged two separate tbased pretrained transformer finetuned pretrained bert distilbert albert predicting empathy personality trait used optuna hyperparameter optimisation framework finetune learning rate batch size weight initialisation proposed system achieved highest performance pearson correlation coefficient onversationlevel empathy prediction task system implementation publicly available http githubcomhasanrakibulwassaempathyemotion
paper investigates effectiveness cohesionbased variable commonly used literature predictive feature assess text readability evaluate efficiency variable across narrative informative text intended audience l french learner experiment use french corpus manually automatically annotated regard coreference anaphoric chain efficiency variable readability analyzed correlational analysis modelling experiment
dropout widely used regularization trick resolve overfitting issue large feedforward neural network trained small dataset performs poorly heldout test subset although effectiveness regularization trick extensively studied convolutional neural network lack analysis unsupervised model particular vaebased neural topic model paper analyzed consequence dropout encoder well decoder vae architecture three widely used neural topic model namely contextualized topic model ctm prodlda embedded topic model etm using four publicly available datasets characterize dropout effect model term quality predictive performance generated topic
paper summarizes participation semeval task multigenerator multidomain multilingual blackbox machinegenerated text detection task aim solve two three subtasks monolingual multilingual binary humanwritten v machinegenerated text classification multiway machinegenerated text classification conducted comprehensive comparative study across three methodological group five metricbased model loglikelihood rank logrank entropy mfdmetric two finetuned sequencelabeling language model roberta xlmr finetuned largescale language model lsllama finding suggest llm outperformed traditional sequencelabeling lm benchmark metricbased approach furthermore finetuned classifier excelled detecting machinegenerated multilingual text accurately classifying machinegenerated text within specific category eg chatgpt bloomz dolly however exhibit challenge detecting category eg cohere davinci due potential overlap distribution metric among various llm overall achieved th rank multilingual binary humanwritten v machinegenerated text classification multiway machinegenerated text classification leaderboard
semantic specialization distributional word vector referred retrofitting process finetuning word vector using external lexical knowledge order better embed semantic relation existing retrofitting model integrate linguistic constraint directly learning objective consequently specialize vector word constraint work contrast transform external lexicosemantic relation training example use learn explicit retrofitting model er er model allows u learn global specialization function specialize vector word unobserved training data well report large gain original distributional vector space intrinsic word similarity evaluation two downstream task lexical simplification dialog state tracking finally also successfully specialize vector space new language ie unseen training data coupling er shared multilingual distributional vector space
train deploy language model lm federated learning fl differential privacy dp google keyboard gboard recent dpfollow regularized leader dpftrl algorithm applied achieve meaningfully formal dp guarantee without requiring uniform sampling client provide favorable privacyutility tradeoff introduce new client participation criterion discus implication configuration large scale system show quantilebased clip estimation combined dpftrl adaptively choose clip norm training reduce hyperparameter tuning preparation training help pretraining public data trained deployed fifteen gboard lm achieve high utility textbackslashrhozcdp privacy guarantee textbackslashrho textbackslashin one model additionally trained secure aggregation summarize experience provide concrete suggestion dp training practitioner
outofvocabulary word still challenge crosslingual natural language processing task transliteration source target language script one solution study collect personal name dataset wikidata language script train transformerbased multilingual transliteration model high lessresourced language compare bilingual model merhav ash determine multilingual model perform better lessresourced language discover intrinsic evaluation ie comparison single gold standard might appropriate task transliteration due high variability reason propose using extrinsic evaluation transliteration via crosslingual named entity list search task eg personal name search contact list code datasets publicly available online
work examines different way aggregating score error annotation mt output raw error count error count normalised total number word word percentage error count normalised total number error error percentage use three score calculate interannotator agreement form krippendorffs alpha pearsons r compare obtained number overall separately different type error score advantage depending goal evaluation argue best way estimating interannotator agreement using number raw count annotation process ensures total number word differ among annotator example due adding omission symbol normalising number word lead conclusion contrast total number error subjective different annotator often perceive different amount error text therefore normalising number indicate lower agreement
vocabulary learning vital foreign language learning correct adequate feedback essential successful satisfying vocabulary training however many vocabulary language evaluation system perform simple rule account reallife user learning data work introduces multilanguage vocabulary evaluation data set mulve data set consisting vocabulary card reallife user answer labeled indicating whether user answer correct incorrect data source user learning data phase vocabulary trainer data set contains vocabulary question german english spanish french target language available four different variation regarding preprocessing deduplication experiment finetune pretrained bert language model downstream task vocabulary evaluation proposed mulve data set result provide outstanding result textgreater accuracy fscore data set available european language grid
news article summary usually consists key sentence reflect gist news article paper explore using public post following new article improve automatic summary generation news article propose different approach incorporate information public post including using frequency information post reestimate bigram weight ilpbased summarization model reweight dependency tree edge importance sentence compression directly selecting sentence post final summary finally strategy combine summarization result generated news article post experiment data collected facebook show relevant public post provide useful information effectively leveraged improve news article summarization result
increasing rate scientific knowledge discovered health claim shared online highlighted importance developing efficient factchecking system scientific claim usual setting task literature assumes document containing evidence claim already provided annotated contained limited corpus render system unrealistic realworld setting knowledge source potentially million document need queried find relevant evidence paper perform array experiment test performance opendomain claim verification system test final verdict prediction system four datasets biomedical health claim different setting keeping pipeline evidence selection verdict prediction part constant document retrieval performed three common knowledge source pubmed wikipedia google using two different information retrieval technique show pubmed work better specialized biomedical claim wikipedia suited everyday health concern likewise bm excels retrieval precision semantic search recall relevant evidence discus result outline frequent retrieval pattern challenge provide promising future direction
automatic essay evaluation help reduce teacher workload enable student refine work rapidly previous study focus mainly giving discrete score either holistic quality orseveral distinct trait however realworld teacher usually provide detailed comment natural language informative single score paper present comment generation task aim generate commentsfor specified segment given student narrative essay tackle task propose planningbased generation model first plan sequence keywords expands keywords complete comment improve correctness informativeness generated comment adopt two following technique training error correction module filter incorrect keywords recognizing finegrained structured feature source essay enrich keywords support evaluation task collect humanwritten chinese dataset contains essaycomment pair extensive experiment show model outperforms strong baseline significantly moreover exert explicit control model generate comment describe strength weakness input success rate deploy model urlhttpcoaicstsinghuaeducnstaticessaycomment demo video available urlhttpsyoutubeiufvkduxbi code data available urlhttpsgithubcomthucoaiessaycommentgen
rapid development automatic fake news detection technology fact extraction verification fever attracting attention task aim extract related fact evidence million opendomain wikipedia document verify credibility corresponding claim although several strong model proposed task made great process argue fail utilize multiview contextual information thus obtain better performance paper propose integrate multiview contextual information imci fact extraction verification evidence sentence define two kind context ie intradocument context interdocument context intradocument context consists document title sentence document interdocument context consists evidence may come different document integrate multiview contextual information encode evidence sentence handle task experimental result fever shared task show imci framework make great progress fact extraction verification achieves stateoftheart performance winning fever score label accuracy online blind test set also conduct ablation study detect impact multiview contextual information
paper describes system first second shared task fourth social medium mining health application smmh workshop enhance tweet representation language model distinguish importance different word multihead selfattention addition transfer learning exploited make data shortage system achieved competitive result task fscore task overlap strict task
interpret retrieve medical evidence support clinical decision clinical trial report ctr amassed year contain indispensable information development personalized medicine however practically infeasible manually inspect clinical trial report order find best evidence experimental treatment natural language inference nli offer potential solution problem allowing scalable computation textual entailment however existing nli model perform poorly biomedical corpus previously published datasets fail capture full complexity inference ctrs work present novel resource advance research nli reasoning ctrs resource includes two main task firstly determine inference relation natural language statement ctr secondly retrieve supporting fact justify predicted relation provide nlict corpus statement ctrs annotated task baseline corpus expose limitation existing nli approach stateoftheart nli model achieving maximum f score best knowledge first design task cover interpretation full ctrs encourage work challenging dataset make corpus competition leaderboard website available codalab code replicate baseline experiment github
paper describes critical role dungeon dragon dataset crd related analysis critical role unscripted livestreamed show fixed group people play dungeon dragon openended roleplaying game dataset collected critical role episode transcribed text dialogue consisting turn also includes corresponding abstractive summary collected fandom wiki dataset linguistically unique narrative generated entirely player collaboration spoken interaction dialogue large number turn multiple abstractive summary varying level detail semantic tie previous dialogue addition provide data augmentation method produce summarydialogue chunk pair support current neural ml approach provide abstractive summarization benchmark evaluation
propose approach nbest list reranking using neural sequencelabelling model train compositional model error detection calculates probability token sentence correct incorrect utilising full sentence context using error detection model rerank n best hypothesis generated statistical machine translation system approach achieves stateoftheart result error correction three different datasets additional advantage using small set easily computed feature require linguistic input
neural sequence generation typically performed tokenbytoken lefttoright whenever token generated previously produced token taken consideration contrast problem sequence classification bidirectional attention take past future token consideration shown perform much better propose make sequence generation process bidirectional employing special placeholder token treated node fully connected graph placeholder token take past future token consideration generating actual output token verify effectiveness approach experimentally two conversational task proposed bidirectional model outperforms competitive baseline large margin
unlike comprehensionstyle question clarification question look missing information given context however without guidance neural model question generation similar dialog generation model lead generic bland question elicit useful information argue controlling level specificity generated question useful application propose neural clarification question generation model first train classifier annotates clarification question level specificity generic specific given context result amazon question dataset demonstrate training clarification question generation model specificity annotated data generate question varied level specificity given context
mental health disorder continue plaguing human worldwide aggravating situation severe shortage qualified competent mental health professional mhps underline need developing virtual assistant va textitassist mhps dataml automation come platform allow visiting posting message peertopeer anonymous manner sharing experience frequently stigmatized seeking support paper propose va act first point contact comfort mental health patient curate dataset motivational va motivate comprising k dyadic conversation collected peertopeer support platform system employ two mechanism mental illness classification attention based bert classifier output mental disorder category category viz major depressive disorder mdd anxiety obsessive compulsive disorder ocd posttraumatic stress disorder ptsd based input ongoing dialog support seeker va ii mental illness conditioned motivational dialogue generation mimdg sentiment driven reinforcement learning rl based motivational response generator empirical evaluation demonstrates system capability way outperforming several baseline
socratic method way guiding student toward solving problem independently without directly revealing solution problem asking incremental question although method shown significantly improve student learning outcome remains complex laborintensive task instructor large language model llm used augment human effort automatically generating socratic question student however existing method involve prompting llm sometimes produce invalid output eg directly reveal solution problem provide irrelevant premature question alleviate problem inspired reinforcement learning ai feedback rlaif first propose data augmentation method enrich existing socratic questioning datasets question invalid specific way also propose method optimize opensource llm llama prefer groundtruth question generated invalid one using direct preference optimization dpo experiment socratic question dataset student code debugging show dpooptimized llama b model effectively avoid generating invalid question result outperforms existing stateoftheart prompting method
demo urlhttpsyoutubewqlltpbcabstractwe present deepgen system deployed web scale automatically creating sponsored search advertisement ad bingads customer leverage stateoftheart natural language generation nlg model generate fluent ad advertiser web page abstractive fashion solve practical issue factuality inference speed addition system creates customized ad realtime response user search query therefore highlighting different aspect product based user looking achieve system generates diverse choice smaller piece ad ahead time query time selects relevant one stitched complete ad improve generation diversity training controllable nlg model generate multiple ad web page highlighting different selling point system design improves diversity horizontally first running ensemble generation model trained different objective using diversity sampling algorithm pick diverse subset generation result online selection experimental result show effectiveness proposed system design system currently deployed production serving textasciitilde global ad served bing
context language learning feedback comment generation task generating hint explanatory note learner text help understand part text erroneous paper present approach feedback comment generation shared task collocated th international natural language generation conference inlg approach augments generation feedback comment selfsupervised identification feedback type multitasklearning setting within shared task approach performed effective yet combined modeling feedback type classification feedback comment generation superior performing eedback generation
large body research studying deep learning method text generation structured data almost focus purely english paper study effectiveness machine translation based pretraining datatotext generation nonenglish language since structured data generally expressed english text generation language involves element translation transliteration copying element already encoded neural machine translation system moreover since datatotext corpus typically small task benefit greatly pretraining conduct experiment czech morphologically complex language result show machine translation pretraining let u train endtoend model significantly improve upon unsupervised pretraining linguistically informed pipelined neural system judged automatic metric human evaluation also show approach enjoys several desirable property including improved performance low data scenario applicability low resource language
investigate paper problem classifying stylome character literary work previous research field authorship attribution shown writing style author characterized distinguished author automatically paper take look less approached problem style different character distinguished trying verify author managed create believable character individual style present result initial experiment developed novel liaison dangereuses showing simple bag word model used classify character
querying knowledge base kb long challenge endtoend taskoriented dialogue system previous sequencetosequence seqseq dialogue generation work treat kb query attention entire kb without guarantee generated entity consistent paper propose novel framework query kb two step improve consistency generated entity first step inspired observation response usually supported single kb row introduce kb retrieval component explicitly return relevant kb row given dialogue history retrieval result used filter irrelevant entity seqseq response generation model improve consistency among output entity second step perform attention mechanism address correlated kb column two method proposed make training feasible without labeled retrieval data include distant supervision gumbelsoftmax technique experiment two publicly available task oriented dialog datasets show effectiveness model outperforming baseline system producing entityconsistent response
world language primary data available even many language disappearing throughout last two decade however language documentation project produced substantial amount primary data wide variety endangered language resource still early day exploration one factor make hard use relative lack standardized annotation convention paper describe common practice existing corpus order facilitate future processing brief introduction main format used annotation file focus commonly used tier widespread elan toolbox format minimally corpus language documentation contain transcription tier aligned translation tier mean constitute parallel corpus additional common annotation include named reference morpheme separation morphemebymorpheme gloss partofspeech tag note
paper evaluate capability transformerbased language model making inference uncertain text includes uncertain rule reasoning cover pretrained language model plms generative large language model llm evaluation result show generation language model struggle reasoning uncertain text propose novel endtoend finetuning approach probabilistic constraint training pct utilizes probabilistic logical rule constraint finetuning phase without relying rule inference stage assess effectiveness pct utilize related corpus additionally create new challenging benchmark unlike previous one us instancespecific rule study demonstrates pct improves transformerbased language model intrinsic reasoning make probabilistic logical reasoning process explicit explainable furthermore pct equips model effectively handle novel situation including higher reasoning depth new domain complex probabilistic structure
introduce premon predicate model ontology linguistic resource exposing predicate model propbank nombank verbnet framenet mapping eg semlink linked open data consists two component premon ontology extension lemon model wc ontologylexica community group enables homogeneously represent data various predicate model ii premon dataset collection rdf datasets integrating various version aforementioned predicate model mapping resource premon freely available accessible online different way including dedicated sparql endpoint
paper describe formal constraint mechanism label conceptual constraint variable ccvs introduced restrict surface pattern automated text analysis objective increasing precision representation informational content briefly present exemplify various type ccvs applicable english text corpus show constraint allow u resolve problem inherent surface pattern recognition specifically related resolution conceptual syntactic ambiguity introduced frequent english preposition
factchecking task verifying veracity claim assessing assertion credible evidence vast majority factchecking study focus exclusively political claim little research explores factchecking topic specifically subject matter expertise required present first study explainable factchecking claim require specific expertise case study choose setting public health support case study construct new dataset pubhealth k claim accompanied journalist crafted gold standard explanation ie judgment support factcheck label claim explore two task veracity prediction explanation generation also define evaluate human computationally three coherence property explanation quality result indicate training indomain data gain made explainable automated factchecking claim require specific expertise
paper describes transformerbased system designed semeval task multilingual tweet intimacy analysis purpose task predict intimacy tweet range intimate intimate official training set competition consisted tweet six language english spanish italian portuguese french chinese test set included given six language well external data four language presented training set hindi arabic dutch korean presented solution based ensemble xlmt multilingual roberta model adapted twitter domain improve performance unseen language tweet supplemented english translation explored effectiveness translated data language seen finetuning compared unseen language estimated strategy using translated data transformerbased model solution ranked th leaderboard achieving overall pearsons r test set proposed system improves pearsons r score averaged across submission
unpaired crosslingual image captioning long suffered irrelevancy disfluency issue due inconsistency semantic scene syntax attribute transfer work propose address problem incorporating scene graph sg structure syntactic constituency sc tree captioner contains semantic structureguided imagetopivot captioning syntactic structureguided pivottotarget translation two joined via pivot language take sg sc structure pivoting performing crossmodal semantic structure alignment crosslingual syntactic structure alignment learning introduce crosslingualcrossmodal backtranslation training fully align captioning translation stage experiment englishchinese transfer show model show great superiority improving captioning relevancy fluency
dialog state tracking used estimate current belief state dialog given preceding conversation machine reading comprehension hand focus building system read passage text answer question require understanding passage formulate dialog state tracking reading comprehension task answer question state current dialog reading conversational context contrast traditional state tracking method dialog state often predicted distribution closed set possible slot value within ontology method us simple attentionbased neural network point slot value within conversation experiment multiwoz crossdomain dialog dataset show simple system obtain similar accuracy compared previous complex method exploiting recent advance contextual word embeddings adding model explicitly track whether slot value carried next turn combining method traditional joint state tracking method relies closed set vocabulary obtain jointgoal accuracy standard test split exceeding current stateoftheart
design natural language processing nlp system learn human feedback growing research body humanintheloop hitl nlp framework continuously integrate human feedback improve model hitl nlp research nascent multifarioussolving various nlp problem collecting diverse feedback different people applying different method learn human feedback present survey hitl nlp work machine learning ml humancomputer interaction hci community highlight short yet inspiring history thoroughly summarize recent framework focusing task goal human interaction feedback learning method finally discus future study integrating human feedback nlp development loop
crosslingual summarization cl attracted increasing interest recent year due availability largescale webmined datasets advancement multilingual language model however given rareness naturally occurring cl resource majority datasets forced rely translation contain overly literal artifact restricts ability observe naturally occurring cl pair capture organic diction including instance codeswitching alteration language midmessage common phenomenon multilingual setting yet largely overlooked crosslingual context due data scarcity address gap introduce crocosum dataset crosslingual codeswitched summarization technology news consists english source article humanwritten chinese news summary summary containing codeswitched phrase reference evaluate performance existing approach including pipeline endtoend zeroshot method show leveraging existing cl resource pretraining step improve performance crocosum indicating limited generalizability current datasets finally discus challenge evaluating crosslingual summarizers codeswitched generation qualitative error analysis
paper extend existing annotation scheme isospace annotating necessary spatial information task placing specified object specified location specified direction according natural language instruction call task spatial placement problem extension particularly focus describing object direction object placed plane conducted annotation experiment corpus situated dialogue annotated annotation result showed number newly introduced tag proposal negligible also implemented analyser automatically assigns proposed tag corpus evaluated performance result showed performance entity tag quite high ranging fmeasure case relation tag ie less fmeasure
paper summarizes team scalar work semeval task legal argument reasoning civil procedure address binary classification task daunting due complexity legal text involved propose simple yet novel similarity distancebased unsupervised approach generate label explore multilevel fusion legalbert embeddings using ensemble feature including cnn gru lstm address lengthy nature legal explanation dataset introduce tbased segmentwise summarization successfully retained crucial information enhancing model performance unsupervised system witnessed point increase macro fscore development set point increase test set promising given uncomplicated architecture
sequencetosequence model shown strong performance across broad range application however application parsing generating text using abstract meaning representation amr limited due relatively limited amount labeled data nonsequential nature amr graph present novel training procedure lift limitation using million unlabeled sentence careful preprocessing amr graph amr parsing model achieves competitive result smatch current best score reported without significant use external semantic resource amr generation model establishes new stateoftheart performance bleu present extensive ablative qualitative analysis including strong evidence sequencebased amr model robust ordering variation graphtosequence conversion
extraction event causality especially implicit causality text data challenging task causality often treated specific relation type considered part relation extraction relation classification task many causality identificationrelated task designed select plausible alternative set possible cause consider multiplechoice classification setting since powerful question answering qa system pretrained large text corpus investigated zeroshot qabased approach event causality extraction using wikipediabased dataset containing event description article annotated cause aimed evaluate extent reading comprehension ability qapipeline used eventrelated causality extraction plain text without additional training evaluation challenge limitation data discussed compared performance twostep pipeline consisting passage retrieval extractive qa qaonly pipeline eventassociated article mixed one system achieved average cosine semantic similarity score different setting
performance large language model llm existing reasoning benchmark significantly improved past year response present jeebench considerably challenging benchmark dataset evaluating problem solving ability llm curate challenging preengineering mathematics physic chemistry problem highly competitive iit jeeadvanced exam longhorizon reasoning top deep indomain knowledge essential solving problem benchmark evaluation various opensource proprietary model reveals highest performance even using technique like selfconsistency selfrefinement chainofthought prompting less typical failure mode gpt best model error algebraic manipulation difficulty grounding abstract concept mathematical equation accurately failure retrieving relevant domainspecific concept also observe mere prompting gpt unable assess risk introduced negative marking incorrect answer develop posthoc confidencethresholding method selfconsistency enables effective response selection hope challenging benchmark guide future research problemsolving using llm
pretrained contextual representation led dramatic performance improvement range downstream task performance improvement motivated researcher quantify understand linguistic information encoded representation general researcher quantify amount linguistic information probing endeavor consists training supervised model predict linguistic property directly contextual representation unfortunately definition probing subject extensive criticism literature observed lead paradoxical counterintuitive result theoretical portion paper take position goal probing ought measuring amount inductive bias representation encode specific task describe bayesian framework operationalizes goal allows u quantify representation inductive bias empirical portion paper apply framework variety nlp task result suggest proposed framework alleviates many previous problem found probing moreover able offer concrete evidence thatfor tasksfasttext offer better inductive bias bert
much existing work text novelty detection studied topic level ie identifying whether topic document sentence novel little work done finegrained semantic level contextual level example given know elon musk ceo technology company sentence elon musk acted sitcom big bang theory novel surprising normally ceo would actor existing topicbased novelty detection method work poorly problem perform semantic reasoning involving relation named entity text background knowledge paper proposes effective model called patsnd solve problem also characterize novelty annotated dataset also created evaluation show patsnd outperforms baseline large margin
paper describe approach modelling causal reasoning natural language detecting counterfactuals text using multihead selfattention weight use pretrained transformer model extract contextual embeddings selfattention weight text show use convolutional layer extract taskspecific feature selfattention weight describe finetuning approach common base model knowledge sharing two closely related subtasks counterfactual detection analyze compare performance various transformer model experiment finally perform qualitative analysis multihead selfattention weight interpret model dynamic
propose novel abstract meaning representation amr based approach identifying molecular eventsinteractions biomedical text key contribution empirical validation hypothesis event subgraph amr graph neural networkbased model identifies event subgraph given amr distant supervision based approach gather additional training data evaluate approach genia event extraction dataset show promising result
suffix tree data structure used index corpus paper explore property suffix tree naturally provide functionality ngram language model variable n explain property suffix tree leverage suffix tree language model stlm implementation explain suffix tree implicitly contains data needed ngram language modeling also discus kind smoothing technique appropriate model show suffixtree language model implementation competitive compared stateoftheart language model srilm stolke statistical machine translation experiment
despite rapid recent progress creating accurate compact incontext learner recent work focus incontext learning icl task english however ability interact user language outside english present great potential broadening applicability language technology nonenglish speaker work collect infrastructure necessary training evaluation icl selection slavic language czech polish russian link diverse set datasets cast unified instructional format set transformation newlycrafted template written purely target language using newlycurated dataset evaluate set recent incontext learner compare result supervised baseline finally train evaluate publish set incontext learning model train collected resource compare performance previous work find icl model tuned english also able learn task nonenglish context multilingual instruction finetuning consistently improves icl ability also find massive multitask training outperformed singletask training target language uncovering potential specializing incontext learner language application
speech resource describe interruption phenomenon especially tv medium content description phenomenon may vary across author thus leaf room improved annotation protocol present annotation transitionrelevance place trp floortaking event type existing french tv radio broadcast corpus facilitate study interruption turntaking speaker change annotated presence absence trp classification nextspeaker floortaking smooth backchannel different type turn violation cooperative competitive successful attempted interruption interrater agreement analysis show annotation moderate substantial reliability interannotator agreement trp annotation reach backchannel interruptionnoninterruption distinction precise difference linked cooperative competitive behavior lead lower agreement result underline importance lowlevel feature like trp derive classification turn change would less subject interpretation analysis presence overlapping speech highlight existence interruption without overlap smooth transition overlap annotation available httpsliumunivlemansfrcorpusallies
text internet serve important data source financial market modeling early statistical approach rely manually defined feature capture lexical sentiment event information suffers feature sparsity recent work considered learning dense representation news title abstract compared news title full document contain potentially helpful information also noise compared event sentence less investigated previous work fill gap propose novel targetspecific abstractguided news document representation model model us targetsensitive representation news abstract weigh sentence news content select combine informative sentence market modeling result show document representation give better performance estimating cumulative abnormal return company compared title abstract model especially effective used combine information multiple document source compared sentencelevel baseline
stock movement influenced historical price also information outside market social medium news stock related stock practice news price stock one day normally impacted different day different weight influence term issue paper propose fundamental analysis based neural network stock movement prediction first propose three new technical indicator based raw price according finance theory basic encode price day introduce coattention mechanism capture sufficient context information text price across every day within time window based mutual promotion influence text price different time obtain sufficient stock representation perform extensive experiment realworld stocknet dataset experimental result demonstrate effectiveness method
coping ambiguous question perennial problem realworld dialogue system although clarification asking question common form human interaction hard define appropriate question elicit specific intent user work propose reinforcement model clarify ambiguous question suggesting refinement original query first formulate collection partitioning problem select set label enabling u distinguish potential unambiguous intent list chosen label intent phrase user confirmation selected label along original user query serf refined query suitable response easily identified model trained using reinforcement learning deep policy network evaluate model based realworld user click demonstrate significant improvement across several different experiment
prompt tuning pt promising parameterefficient method utilize extremely large pretrained language model plms achieve comparable performance fullparameter finetuning tuning soft prompt however pt requires much training time finetuning intuitively knowledge transfer help improve efficiency explore whether improve pt via prompt transfer empirically investigate transferability soft prompt across different downstream task plms work find zeroshot setting trained soft prompt effectively transfer similar task plm also plms crossmodel projector trained similar task used initialization trained soft prompt similar task projected prompt plms significantly accelerate training also improve performance pt moreover explore decides prompt transferability investigate various transferability indicator find overlapping rate activated neuron strongly reflects transferability suggests prompt stimulate plms essential finding show prompt transfer promising improving pt research shall focus prompt stimulation plms source code obtained urlhttpsgithubcomthunlpprompttransferability
paper address structural ambiguity dutch relative clause investigating task disambiguation grounding study presence prior sentence resolve relative clause ambiguity apply method two parsing architecture attempt demystify parsing language model component two presentday neural parser result show neurosymbolic parser based proof net open data bias correction approach based universal dependency although setup suffer comparable initial data bias
paper motivates present twitter deliberative politics dataset corpus political tweet labeled deliberative characteristic corpus randomly sampled reply u congressman woman expected useful general community computational linguist political scientist social scientist interested study online political expression computermediated communication political deliberation data sampling annotation method discussed classical machine learning approach evaluated predictive performance different deliberative facet paper concludes discussion future work aimed developing dictionary quality assessment online political talk english dataset demo dashboard available urlhttpsgithubcomkjtwitterdeliberativepolitics
paper proposes new method sentiment analysis utilizing intersentence structure especially coping reversal phenomenon word polarity quotation others opinion opposite side model phenomenon using hidden conditional random fieldshcrfs three kind feature transition feature polarity feature reversal polarity feature polarity feature reversal feature doubly added word weight feature trained common structure positive negative corpus example assuming reversal phenomenon occured reason feature polarity corpus method achieved better accuracy naive bayes method good svms
recent study suggested neural language model learn store large amount fact commonsense knowledge training data ability language model restore knowledge often evaluated via zeroshot clozestyle qa task however evaluation rely prediction accuracy without punishing system mistake eg simply guessing hallucinating likely answer selective prediction informative evaluation framework take confidence prediction account selective prediction setting model evaluated number correct prediction also ability filter dubious prediction estimating confidence individual prediction confidenceaware evaluation crucial determining whether trust zeroshot prediction language model paper apply selective prediction setting existing benchmark lama probe conduct extensive experiment recent neural language model different confidence function empirically show selectivelama evaluation robust effect simple guess conventional accuracybased evaluation evaluation reveals importance choice confidence function showing simply relying token probability always best choice analysis show various confidence function exhibit different preference predicted token given context
submitted model nmt system based transformer model improve incorporating several enhancement applying dropout whole source target word weighting target subwords averaging model checkpoint using trained model iteratively correcting intermediate translation system restricted track trained provided corpus oversampled cleaner sentence reach f score test set system lowresource track trained wikipedia revision history reach f score finally finetune system lowresource track restricted data achieve f score
work explores arabic disinformation identification crucial task natural language processing using stateoftheart nlp model highlight performance system model baseline model including multilingual arabicspecific one showcase effectiveness domainspecific pretrained model work advocate adoption tailored pretrained model nlp emphasizing significance understanding diverse language merging advanced nlp technique domainspecific pretraining advance arabic disinformation identification
analyze performance encoderdecoder neural model compare wellknown established method latter represent different class traditional approach applied monotone sequencetosequence task ocr postcorrection spelling correction graphemetophoneme conversion lemmatization task practical relevance various higherlevel research field including digital humanity automatic text correction speech recognition investigate well generic deeplearning approach adapt task perform comparison established specialized method including adaptation pruned crfs
scarcity data pose significant challenge closeddomain event extraction common complex nlp task limitation primarily arises intricate nature annotation process address issue present multitask model structure training approach leverage additional data found event information document sentence level generated event annotation process incorporating supplementary data proposed framework demonstrates enhanced robustness scenario improved performance particularly noteworthy observation including negative document addition original data contributes performance enhancement finding offer promising insight leveraging extra data mitigate data scarcity challenge closeddomain event extraction
paper present overview shared task emotional analysis tamil result shared task presented workshop paper present dataset used shared task task description methodology used participant evaluation result submission task organized two task task carried emotion annotated data social medium comment tamil task b organized finegrained emotion annotated data social medium comment tamil conducting experiment training development datasets provided participant result evaluated unseen data totally received around submission team evaluating model precision recall micro average metric used
named entity recognition ner performance often degrades rapidly applied target domain differ text observed training indomain labelled data available transfer learning technique used adapt existing ner model target domain one handlabelled data target domain paper present simple powerful approach learn ner model absence labelled data weak supervision approach relies broad spectrum labelling function automatically annotate text target domain annotation merged together using hidden markov model capture varying accuracy confusion labelling function sequence labelling model finally trained basis unified annotation evaluate approach two english datasets conll news article reuters bloomberg demonstrate improvement percentage point entitylevel f score compared outofdomain neural ner model
distant supervision reduces reliance human annotation named entity recognition task classlevel imbalanced distant annotation realistic unexplored problem popular method selftraining handle classlevel imbalanced learning importantly selftraining dominated highperformance class selecting candidate deteriorates lowperformance class bias generated pseudo label address classlevel imbalance performance propose classrebalancing selftraining framework improving distantlysupervised named entity recognition candidate selection classwise flexible threshold designed fully explore class besides highperformance class label generation injecting distant label hybrid pseudo label adopted provide straight semantic information lowperformance class experiment five flat two nested datasets show model achieves stateoftheart result also conduct extensive research analyze effectiveness flexible threshold hybrid pseudo label
relation extraction often challenged insufficient labeled data previous method exploit knowledge unlabeled data generating pseudo label selftraining pipeline suffers gradual drift problem logic rule transferable explainable form expert knowledge achieved promising success improving model weak label manually writing comprehensive rule set challenging tedious alleviate human labor writing highquality rule work propose aria automatic taskspecific rule distilling framework specifically guide pretrained language model reason rule expert compose robust compound rule data labeling besides aria could continuously enrich rule set power labeling ability discovering reliable modellabeled data distinguishable rule generation experiment two public datasets demonstrate effectiveness aria lowresource scenario
past decade due lack sufficient labeled data study crossdomain parsing focus unsupervised domain adaptation assuming targetdomain training data however unsupervised approach make limited progress far due intrinsic difficulty domain adaptation parsing paper tackle semisupervised domain adaptation problem chinese dependency parsing based two newlyannotated largescale domainaware datasets propose simple domain embedding approach merge source targetdomain training data shown effective direct corpus concatenation multitask learning order utilize unlabeled targetdomain data employ recent contextualized word representation show simple finetuning procedure boost crossdomain parsing accuracy large margin
academic publication citation used build context concept highlighting relevant aspect reference paper automatically identifying referenced snippet help researcher swiftly isolate principal contribution scientific work paper exploit underlying structure scientific article predict reference paper span facet corresponding citation propose two method detect citation span keyphrase overlap bert along structural prior finetune fasttext embeddings leverage textual positional feature predict citation facet
natural language understanding nlu integral taskoriented dialog system demand considerable amount annotated training data increase coverage diverse utterance study report construction linguistic resource named fiad financial annotated dataset use generate korean annotated training data nlu banking customer service c domain empirical examination corpus banking app review identified three linguistic pattern occurring korean request utterance topic entity feature event discourse marker represented lggs local grammar graph generate annotated data covering diverse intent entity assess practicality resource evaluate performance dietonly intent topic entityfeature diet hanbert diet kobert diet korbert model trained fiadgenerated data extract various type semantic item
investigate use machine learning classifier detecting online abuse empirical research show uncalibrated classifier ie raw score used align poorly human evaluation limit use understanding dynamic pattern prevalence online abuse examine two widely used classifier created perspective davidson et al dataset tweet directed candidate uk general election bayesian approach presented recalibrate raw score classifier using probabilistic programming newly annotated data argue interpretability evaluation recalibration integral application abusive content classifier
syntactic tree widely applied relation extraction however since parsing quality stable different text domain predefined grammar may well fit target relation schema introduction syntactic structure sometimes fails improve performance consistently work study model various unsupervised structure mined pretrained language model eg bert show similar syntactic tree unsupervised structure quite informative task able obtain competitive even best performance score benchmark datasets ace webnlg scierc also conduct detailed analysis ability adapting new domain influence noise link structure result suggest unsupervised structure reasonable alternative commonly used syntactic structure relation extraction model
paper fifth series biennial progress report review activity linguistic data consortium particular emphasis general trend language resource landscape change distinguish two year since ldcs last report lrec preceding year providing perspective current landscape language resource paper go describe vision role ldc within research community serf sketching briefly specific publication resource creation project focus attention since last report
data modeling standardization central issue field digital humanity dealing holocaust testimony stable preservation longterm accessibility key ehri online edition composed document diverse nature testimony letter diplomatic report etc held ehris partnering institution selected gathered thematically encoded according tei guideline editor within ehri consortium standardization essential order make sure edition consistent one another issue consistency also encourages broader reflection usage standard processing data standardization digital scholarly edition textual document general paper present normalization work carried ehri online edition includes customization tei adapted holocaustrelated document focus implementation controlled vocabulary recommend use encoding specification tool researcher andor nontei expert ensure encoding valid consistent across edition also mechanism integrating edition work smoothly within wider workflow leading image digitization publication
datasets used train deep learning model industrial setting often exhibit skewed distribution sample repeated large number time paper present simple yet effective solution reduce increased burden repeated computation redundant datasets approach eliminates duplicate batch level without altering data distribution observed model making modelagnostic easy implement plugandplay module also provide mathematical expression estimate reduction training time approach provides empirical evidence show approach significantly reduces training time various model across datasets varying redundancy factor without impacting performance named entity recognition task publicly available datasets real industrial setting latter approach speed training average drop model performance relative worst finally release modular reusable codebase advance research area
recent year seen flourishing neural keyphrase generation kpg work including release several largescale datasets host new model tackle model performance kpg task increased significantly evolving deep learning research however lack comprehensive comparison among different model design thorough investigation related factor may affect kpg system generalization performance empirical study aim fill gap providing extensive experimental result analyzing crucial factor impacting generalizability kpg model hope study help clarify uncertainty surrounding kpg task facilitate future research topic
natural language processing nlp representation text play crucial role various task language modeling sentiment analysis machine translation standard approach represent text way human read write paper propose novel approach represent text consonant present compact representation english text offer improved efficiency without sacrificing performance exploit fact consonant discriminative vowel representing text using consonant significantly reduce overall memory compute footprint required storing processing textual data present two alternative representation consonantsonly completely remove vowel text maskedvowels mask vowel one special symbol evaluate approach conducted experiment various nlp task including text classification partofspeech po tagging namedentity recognition ner neural machine translation nmt addition language modeling result demonstrate proposed consonantbased representation achieves comparable performance compared standard text representation requiring significantly fewer computational resource furthermore show representation seamlessly integrated existing nlp model framework providing practical solution efficient text processing last least present technique retrieve vowel information processed text representation keeping mind need reproduce text human readable form nlp application
style transfer task paraphrasing text targetstyle domain retaining content unsupervised approach mainly focus training generator rewrite input sentence work assume text style determined small proportion word therefore rewriting sentence via generative model may unnecessary alternative consider style transfer sequence tagging task specifically use edit operation ie deletion insertion substitution tag word input sentence train classifier language model score tagged sequence build conditional random field finally optimal path conditional random field used output result experiment comparing model indicate proposed model exceeds endtoend baseline term accuracy sentiment style transfer task comparable better content preservation
referring expression generation reg task generating description unambiguously identifies given target scene different image captioning ic reg requires learning finegrained characteristic scene object also surrounding context referring expression usually singular object often uniquely referenced numerous way instance color location relationship object prior work however explored aspectbased multiplicity referring expression hence work focus aspectcontrolled reg task requires generating referring expression conditioned input aspect aspect capture style reference changing input aspect color location action etc one generate multiple distinct expression per target region solve new task first modify blip aligning imageregions textexpressions achieve novel approach feeding input drawing bounding box around target imageregion prompting model generate referring expression base reg model already beat prior work cider score tackle aspectcontrolled reg append aspect token prompt show distinct expression generated changing prompt finally prove highquality diversity data generated proposed aspectcontrolled reg model also perform dataaugmentationbased evaluation downstream referring expression comprehension rec task half real data augmented generated synthetic data achieve performance comparable training real data using sota rec model
offensive language detection crucial natural language processing nlp investigated importance context detecting language reply tweet twitter use offensive language widespread collected turkish tweet dataset target group unvaccinated people covid period tweet dataset enriched contextual information adding original tweet particular tweet posted reply dataset includes tweetreply pair manually labeled human annotator made publicly available addition compared performance different machine learning model without contextual information result show type contextual information useful improving performance model general although slightly increased macroaveraged fscore certain model
recently nlp community witnessed rapid advancement multilingual crosslingual transfer research supervision transferred highresource language hrls lowresource language lrls however crosslingual transfer uniform across language particularly zeroshot setting towards goal one promising research direction learn shareable structure across multiple task limited annotated data downstream multilingual application may benefit learning setup language across globe lowresource share structure language paper propose novel metalearning framework called metaxnlg learn shareable structure typologically diverse language based metalearning language clustering step towards uniform crosslingual transfer unseen language first cluster language based language representation identify centroid language cluster metalearning algorithm trained centroid language evaluated language zeroshot setting demonstrate effectiveness modeling two nlg task abstractive text summarization question generation popular datasets typologically diverse language consistent improvement strong baseline demonstrate efficacy proposed framework careful design model make endtoend nlg setup less vulnerable accidental translation problem prominent concern zeroshot crosslingual nlg task
factoid question answering qa recently benefited development deep learning dl system neural network model outperform traditional approach domain large datasets exist squad ca question wikipedia article however system yet applied qa specific domain biomedicine datasets generally small train dl system scratch example bioasq dataset biomedical qa comprises less factoid single answer list multiple answer qa instance work adapt neural qa system trained large opendomain dataset squad source biomedical dataset bioasq target employing various transfer learning technique network architecture based stateoftheart qa system extended biomedical word embeddings novel mechanism answer list question contrast existing biomedical qa system system rely domainspecific ontology parser entity tagger expensive create despite fact system achieve stateoftheart result factoid question competitive result list question
currently great effort carried digitalisation large historical document collection preservation purpose document collection usually written ancient language latin greek limit access general public content due language barrier therefore digital library aim storing raw image digitalised document also annotate corresponding text transcription translation modern language unfortunately ancient language disposal scarce electronic resource exploited natural language processing technique paper describes compilation process novel latincatalan parallel corpus new task statistical machine translation smt preliminary experimental result also reported using stateoftheart phrasebased smt system result presented work reveal complexity task challenging interesting nature future development
paper describes rouletabille participation hyperpartisan news detection task propose use different text classification method task preliminary experiment using similar collection used potthast et al show neuralbased classification method reach stateofthe art result final submission composed unique run rank among run position bypublisher test dataset byarticle test dataset term accuracy
major goal study test method nlp domain health care education related covid vulnerable group indigenous people latin america order achieve goal asked participant survey questionnaire provide answer health related topic used answer measure health education status ofour participant paper summarize result nlpapplication participant answer first experiment use embeddingsbased tool measure semantic similarity participant answer expert reference answer second experiment use synonymbased method classify answer topic compare result experiment human annotation result show tested nlpmethods reach significantly lower accuracy score human annotation experiment explain difference assumption human annotator much better pragmatic inferencing necessary classify semantic similarity topic classification answer
describe saarland university submission shared task crossframework meaning representation parsing mrp conference computational natural language learning conll
motivated task semantic parsing describe transition system generalizes standard transitionbased dependency parsing technique generate graph rather tree system includes cache fixed size characterize relationship parameter class graph produced graphtheoretic concept tree decomposition find empirically small cache size cover high percentage sentence existing semantic corpus
syntax play important role task predicting semantic structure sentence syntactic phenomenon alternation control raising tend obfuscate relation syntax semantics paper predict semantic structure sentence using deeper syntax usually done deep syntactic representation abstract away purely syntactic phenomenon proposes structural organization sentence closer semantic representation experiment conducted french corpus annotated semantic frame showed semantic parser reach better performance deep syntactic input
development multilingual terminology long costly process present creation multilingual terminological database called grisp covering multiple technical scientific field various open resource crucial aspect merging different resource based proposal definition sound conceptual model different domain mapping use structural constraint machine learning technique controlling fusion process result massive terminological database several million term concept semantic relation definition accuracy concept merging several resource evaluated following several method resource allowed u improve significantly mean average precision information retrieval system applied large collection multilingual multidomain patent document new specialized terminology specifically created text processing application aggregated merged grisp minimal manual effort
sentiment analysis important task analysing online content across language task content moderation opinion mining though significant amount resource available sentiment analysis several indian language exist largescale openaccess corpus gujarati paper present describes gujarati sentiment analysis corpus gsac sourced twitter manually annotated native speaker language describe detail collection annotation process conduct extensive experiment corpus provide reliable baseline future work using dataset
rapid development nlp research leaderboards emerged one tool track performance various system various nlp task effective goal extent generally present rather simplistic onedimensional view submitted system communicated holistic accuracy number paper present new conceptualization implementation nlp evaluation explainaboard addition inheriting functionality standard leaderboard also allows researcher diagnose strength weakness single system eg bestperforming system bad ii interpret relationship multiple system eg system outperform system b combine system b c iii examine prediction result closely eg common error made multiple system context particular error occur far explainaboard cover system datasets language task released online platform website also make evaluation tool api mit licence github pypi allows user conveniently assess model offline additionally release output file system run collected motivate outputdriven research future
professional user mt quality performance cost efficiency critical therefore surprising little attention theory practice given task postediting machine translated text paper focus important user aspect demonstrate substantial saving time effort achieved implementing intelligent automatic tool point departure patrans mtsystem developed cst used danish translation company lingtech intelligent postediting facility ape developed added system outline discus mechanism positive effect output underlying idea intelligent postediting facility exploit lexical grammatical knowledge already present mtsystems linguistic component conceptually approach general although implementation remains system specific survey posteditor satisfaction costefficiency improvement well quantitative benchmarkbased evaluation effect ape demonstrate success approach encourage development
paper introduces aix map task corpus corpus audio video recording taskoriented dialogue modelled original hcrc map task corpus lexical material designed analysis speech prosody described astesano et al design lexical material protocol basic quantitative feature existing corpus presented corpus collected two communicative condition one audioonly condition one facetoface condition recording took place studio sound attenuated booth respectively headset microphone facetoface condition two video camera recording segmented interpausalunits transcribed using transcription convention containing actual production canonical form said made publicly available online
variational autoencoders vaes known suffer learning uninformative latent representation input due issue approximated posterior collapse entanglement latent space impose explicit constraint kullbackleibler kl divergence term inside vae objective function explicit constraint naturally avoids posterior collapse use understand significance kl term controlling information transmitted vae channel within framework explore different property estimated posterior distribution highlight tradeoff amount information encoded latent code training generative capacity model
moving beyond postediting machine translation number recent research effort advanced computer aided translation method allow interactivity richer information confidence score completed feedback loop instant adaptation machine translation model user translationsthis tutorial explain main technique several aspect computer aided translation confidence measuresinteractive machine translation interactive translation predictionbilingual concordancerstranslation option displayparaphrasing alternative translation suggestionsvisualization word alignmentonline adaptationautomatic reviewingintegration translation memoryeye tracking logging cognitive user modelsfor state art open challenge presented tutorial also look hood open source casmacat toolkit based matecat available home edition installed desktop machine target audience tutorial researcher interested computer aided machine translation practitioner want use deploy advanced cat technology
pretrained masked language model plms shown inheriting considerable amount relational knowledge source corpus paper present indepth comprehensive study concerning specializing plms relational model perspective network pruning show possible find subnetworks capable representing grounded commonsense relation nontrivial sparsity generalizable original plms scenario requiring knowledge single multiple commonsense relation
recent proliferation smart device necessitates method learn smallsized model paper demonstrates feature total n osqrtm feature required distinguish example omegalog training example reasonable setting possible obtain good model textitsuccinct representation using n log fracmn om bit using pipeline existing compression method lregularized logistic regression feature hashing eliasfano index randomized quantization experiment show noun phrase chunking task existing library requires megabyte compressed less textitkilobytes without notable loss accuracy
propose new annotated corpus metaphor interpretation paraphrase novel dnn model performing task corpus consists set sentence set containing one reference metaphorical sentence four ranked candidate paraphrase model trained binary classification paraphrase candidate used predict graded paraphrase acceptability reach encouraging accuracy binary classification task high pearson spearman correlation gradient judgment prediction task
one exciting capability recent language model dialog ability independently search relevant information ground given dialog response however obtaining training data teach model issue search query time resource consuming work propose qd automatic data generation pipeline generates informationseeking dialog question prompt large language model palm create conversational version question answering datasets use improve query generation model communicate external search apis ground dialog response unlike previous approach relied human written dialog search query method allows automatically generate querybased grounded dialog better control scale experiment demonstrate query generation qrecc dataset model trained syntheticallygenerated data achieve performance model trained humangenerated data successfully generate data training dialog model new domain without existing dialog data demonstrated multihop musique bamboogle qa datasets perform thorough analysis generated dialog showing human find high quality struggle distinguish humanwritten dialog
paper present machine translation system implemented translation centre body european union cdt main goal project create domainspecific machine translation engine order support machine translation service application translation centre client article explain entire implementation process nice neural integrated custom engine describe problem identified solution provided present final result different language pair finally describe work done project future
speech entity linking amis recognize mention speech link entity knowledge base previous work entity linking mainly focus visual context text context contrast speech entity linking focus audio context paper first propose speech entity linking task facilitate study task propose first speech entity linking dataset tedel corpus highquality humanannotated audio text mentionentity pair parallel dataset derived technology entertainment design ted talk includes wide range entity type type based tedel designed two type model rankingbased generative speech entity linking model conducted experiment tedel dataset type model result show rankingbased model outperform generative model achieving f score
dialogue act da tagging crucial spoken language understanding system provides general representation speaker intent bound particular dialogue system unfortunately publicly available data set da annotation based different annotation scheme thus incompatible moreover scheme often cover aspect necessary opendomain humanmachine interaction paper propose methodology map several publicly available corpus subset iso standard order create large taskindependent training corpus da classification show feasibility using corpus train domainindependent da tagger testing outofdomain conversational data argue importance training multiple corpus achieve robustness across different da category
nlp datasets annotated human judgment rife disagreement judge especially true task depending subjective judgment sentiment analysis offensive language detection particularly latter case nlp community come realize common approach reconciling different subjective interpretation risk misrepresenting evidence many nlp researcher therefore concluded rather eliminating disagreement annotated corpus preserve themindeed argue corpus aim preserve interpretation produced annotator approach corpus creation nlp yet widely accepted objective lewidi series shared task promote approach developing nlp model providing unified framework training evaluating datasets report second shared task differs first edition three crucial respect focus entirely nlp instead nlp computer vision task first edition ii focus subjective task instead covering different type disagreement training aggregated label subjective nlp task effect misrepresentation data iii evaluation concentrated soft approach evaluation second edition lewidi attracted wide array partici pant resulting shared task submission paper
work present replication study exploring neural text simplification model nisioi et al able successfully replicate extend method presented original paper alongside replication result present improvement dubbed combinmt using updated implementation opennmt incorporating newsela corpus alongside original wikipedia dataset hwang et al well refining datasets select high quality training example work present two new system combinmt result matched sentence cosine similarity less combinmt similarly run cosine similarity less extending human evaluation presented within original paper increasing number annotator number sentence annotated intention increasing quality result combinmt show significant improvement neural text simplification nt system original paper term number change percentage correct change made
study certain linguistic phenomenon development time large amount textual data must enriched relevant annotation since manual creation annotation requires lot effort automating process nlp method would convenient required amount training data usually available nonstandard historical language present study investigates whether model trained modern newspaper text used automatically identify topological field ie syntactic structure different modern historical german text evaluation show general possible transfer parser model register time period overall fscores textgreater however error analysis make clear additional rule domainspecific training data would beneficial sentence structure differ significantly training data eg case early new high german
named entity recognition ner far evolved traditional flat ner overlapped discontinuous ner mostly solved separately several exception concurrently tackle three task single model current bestperforming method formalizes unified ner wordword relation classification barely focus mention content learning fails detect entity mention comprising single word paper propose twostage spanbased framework template namely tner resolve unified ner task first stage extract entity span flat overlapped entity recognized second stage classify entity span pair discontinuous entity recognized finally multitask learning used jointly train two stage improve efficiency spanbased model design grouped template typed template two stage realize batch computation also apply adjacent packing strategy latter packing strategy model discriminative boundary information learn better span pair representation moreover introduce syntax information enhance span representation perform extensive experiment eight benchmark datasets flat overlapped discontinuous ner model beat current competitive baseline obtaining best performance unified ner
popularity conversational digital assistant resulted availability large amount conversational data utilized improved user experience personalized response generation building assistant using popular large language model like chatgpt also require additional emphasis prompt engineering evaluation method textual similarity metric key ingredient analysis evaluation many similarity metric proposed literature proven effective taskoriented conversation take advantage unique conversational feature address gap present taskdiff novel conversational similarity metric utilizes different dialogue component utterance intent slot distribution compute similarity extensive experimental evaluation taskdiff benchmark dataset demonstrates superior performance improved robustness related approach
paper describes microsoft translator submission wmt news translation shared task englishgerman main focus documentlevel neural machine translation deep transformer model start strong sentencelevel baseline trained largescale data created via datafiltering noisy backtranslation find backtranslation seems mainly help translationese input explore finetuning technique deeper model different ensembling strategy counter effect using document boundary present authentic synthetic parallel data create sequence subword segment train transformer translation model experiment data augmentation technique smaller authentic data documentboundaries larger authentic data without boundary explore multitask training incorporation documentlevel source language monolingual data via bertobjective encoder twopass decoding combination sentencelevel documentlevel system based preliminary human evaluation result evaluator strongly prefer documentlevel system comparable sentencelevel system documentlevel system also seem score higher human reference sourcebased direct assessment
building datasets creative text humor quite challenging introduce funlines competitive game player edit news headline make funny rate funniness headline edited others funlines make humor generation process fun interactive collaborative rewarding educational keeping player engaged providing humor data low cost compared traditional crowdsourcing approach funlines offer useful performance feedback assisting player getting better time generating assessing humor analysis show help increase quality generated dataset show effectiveness data training humor classification model outperform previous benchmark release dataset public
question generation knowledge base knowledge base question generation kbqg task generating question structured database information typically form triple representing fact handle rare entity generalize unseen property previous work kbqg resorted extensive often adhoc pre postprocessing input triple revisit kbqg using pre training new triple question dataset taking question type account show approach outperforms previous work standard zeroshot setting also show extended kbqg dataset also helpful knowledge base question answering provide allows better coverage term knowledge base kb property also increased output variability permit generation multiple question kb triple
paper present work carried transform gloss fable italian sign language li text read tt synthesizer ssml modified version text whereas many system exist generate sign language text decided reverse operation generate text li purpose used version fable tortoise hare signed made available youtube alba cooperativa sociale annotated manually second author master thesis order achieve goal converted multilayer gloss linear prolog term fed generator paper focus main problem encountered transformation gloss semantically pragmatically consistent representation main problem caused complexity text like fable requires coreference mechanism speech act implemented representation often unexpressed constitute implicit information
existing approach table annotation entity type either capture structure table using graphical model learn embeddings table entry without accounting complete syntactic structure propose tabgcn us graph convolutional network capture complete structure table knowledge graph training annotation jointly learns embeddings table element well entity type account knowledge incompleteness tabgcns embeddings used discover new entity type using experiment benchmark datasets show tabgcn significantly outperforms multiple stateoftheart baseline table annotation showing promising performance downstream tablerelated application
many effort try understand grammatical knowledge eg ability understand part speech token encoded large pretrained language model lm done edge probing ep test supervised classification task predict grammatical property span whether particular part speech using token representation coming lm encoder however nlp application finetune lm encoders specific task ask lm finetuned encoding linguistic information change measured ep test specifically focus task question answering qa conduct experiment multiple datasets find ep test result change significantly finetuned model performs well adversarial situation model forced learn wrong correlation similar finding recent paper conclude finetuning change linguistic knowledge encoders provide explanation find ep model susceptible exploiting spurious correlation ep datasets dataset bias corrected see improvement ep test result expected
although large language model llm impressive solving various task quickly outdated deployment maintaining uptodate status pressing concern current era paper provides comprehensive review recent advance aligning deployed llm everchanging world knowledge categorize research work systemically provide indepth comparison discussion also discus existing challenge highlight future direction facilitate research field
paper report design implementation morphophonological analyzer lakota member siouan language family initial motivation work support development precision implemented grammar lakota basis lingo grammar matrix finitestate transducer fst developed adapt lakota complex verbal morphology form directly usable input grammar matrixderived grammar fst formalism applied direction approach also support generative output correct surface form implemented grammar article describes approach used model lakota verbal morphology using finitestate method also discusses result developing lexicon existing text evaluating application related novel text analyzer presented along companion precision grammar explores approach may application enabling machine translation endangered underresourced language
taking account background knowledge context always important part solving task involve natural language one representative example task textbased game player need make decision based description text previously shown game background knowledge language common sense work investigate simply giving common sense seen prior research also effective usage assume part environment state different common sense constitute one ground action selection propose novel agent diffgrl construct difference graph organizes environment state common sense mean interactive object dedicated graph encoder diffgrl also contains framework extracting appropriate amount representation common sense source support construction graph validate diffgrl experiment textbased game require common sense show outperforms baseline score make code publicly available
language powerful tool used state fact well express view perception time find subtle bias towards someone something come politics medium house journalist known create bias shrewd mean misinterpreting reality distorting viewpoint towards party misinterpretation large scale lead production biased news conspiracy theory automating bias detection newspaper article could good challenge research nlp proposed headline attention network bias detection model two distinctive characteristic structure mirror person way reading news article ii attention mechanism applied article based headline enabling attend critical content predict bias required datasets available created dataset comprising news article collected various telugu newspaper marked bias towards particular political party experiment conducted demonstrated model outperforms various baseline method substantial margin
crowdsourcing platform often used collect datasets training machine learning model despite higher level inaccurate labeling compared expert labeling two common strategy manage impact noise first involves aggregating redundant annotation come expense labeling substantially fewer example secondly prior work also considered using entire annotation budget label many example possible subsequently apply denoising algorithm implicitly clean dataset find middle ground propose approach reserve fraction annotation explicitly clean highly probable error sample optimize annotation process particular allocate large portion labeling budget form initial dataset used train model model used identify specific example appear likely incorrect spend remaining budget relabel experiment across three model variation four natural language processing task show approach outperforms match label aggregation advanced denoising method designed handle noisy label allocated finite annotation budget
crossdomain crosscompositional generalization texttosql semantic parsing challenging task existing large language model llm based solution rely inferencetime retrieval fewshot exemplar training set synthesize runtime prompt natural language nl test query contrast devise algorithm performs offline sampling minimal setof fewshots training data complete coverage sql clause operator function maximal domain coverage within allowed token length allows synthesis fixed generic prompt gp diverse setof exemplar common across nl test query avoiding expensive test time exemplar retrieval autoadapt gp target database domain dagp better handle crossdomain generalization followed decomposed leasttomostprompting ltmpdagp handle crosscompositional generalization synthesis ltmpdagp offline task performed onetime per new database minimal human intervention approach demonstrates superior performance kaggledbqa dataset designed evaluate generalizability texttosql task showcase consistent performance improvement ltmpdagp gp across llm database kaggledbqa highlighting efficacy model agnostic benefit prompt based adapt decompose approach
present simple method find topic user review accompany rating product service standard topic analysis perform suboptimal data since word distribution document determined topic sentiment well reduce influence sentiment topic selection adding two explicit topic representing positive negative sentiment evaluate proposed method set hospital review show proposed method latent semantic analysis explicit word feature find topic much smaller bias sentiment similar method
without labeled questionanswer pair necessary training unsupervised commonsense questionanswering qa appears extremely challenging due indispensable unique prerequisite commonsense source like knowledge base kb usually highly resource consuming construction recently pretrained language model plms show effectiveness alternative commonsense clue play role knowledge generator however existing work either relies largescale indomain outofdomain labeled data fails generate knowledge high quality general way motivated human thinking experience propose approach allround thinker art fully taking association knowledge generating detail model first focus key part given context generates highly related knowledge basis association way like human thinking besides casual reasoning reverse thinking mechanism especially added enhance bidirectional inferring cause effect art totally unsupervised kbsfree evaluate three commonsense qa benchmark copa socialiqa sct scale plm backbone art show brilliant performance outperforms previous advanced unsupervised model
connected text characterised presence linguistic element relating shared referent throughout text element together form structure lends cohesion text realisation cohesive structure subject different constraint varying preference different language regularly observe mismatch cohesive structure across language parallel text result either divergence languageinternal constraint effect translation process fully automatic highquality mt starting look achievable question arises cohesive element handled mt evaluation since common assumption correspondence referring expression poor match find corpus data focusing translation pronoun discus different approach evaluating particular type cohesive element mt output tradeoff make evaluation cost validity specificity coverage suggest meaningful evaluation cohesive structure translation difficult achieve simply appealing intuition human annotator requires structured approach force u make mind standard expect translation output adhere
propose novel embedding model represents relationship among several element bibliographic information high representation ability flexibility based model present novel search system show relationship among element acl anthology reference corpus evaluation result show model achieve high prediction ability produce reasonable search result
pretrained language model plms shown effectiveness multiple scenario however kbqa remains challenging especially regarding coverage generalization setting due two main factor understanding semantics question relevant knowledge kb ii generating executable logical form semantic syntactic correctness paper present new kbqa model tiara address issue applying multigrained retrieval help plm focus relevant kb context viz entity exemplary logical form schema item moreover constrained decoding used control output space reduce generation error experiment important benchmark demonstrate effectiveness approach tiara outperforms previous sota including using plms oracle entity annotation least f point grailqa webquestionssp respectively specifically grailqa tiara outperforms previous model category improvement f point zeroshot generalization
paper present ongoing work construction french factbank lexicon french eventselecting predicate esp applying factuality detection algorithm introduced sauri pustejovsky algorithm relies lexicon esp specifying predicate influence polarity embedded event pilot study focused french factive implicative verb capitalised lexical resource english counterpart verb provided clsi group nairn et al karttunen
recent growth popularity success deep learning model nlp classification task accompanied need generating form natural language explanation predicted label generated natural language nl explanation expected faithful ie correlate well model internal decision making work focus task natural language inference nli address following question build nli system produce label high accuracy also generating faithful explanation decision propose naturallanguage inference labelspecific explanation nile novel nli method utilizes autogenerated labelspecific nl explanation produce label along faithful explanation demonstrate nile effectiveness previously reported method automated human evaluation produced label explanation evaluation nile also support claim accurate system capable providing testable explanation decision designed discus faithfulness nile explanation term sensitivity decision corresponding explanation argue explicit evaluation faithfulness addition label explanation accuracy important step evaluating model explanation demonstrate taskspecific probe necessary establish sensitivity
present transitionbased amr parser directly generates amr parses plain text use stacklstms represent parser state make decision greedily experiment show parser achieves competitive score english using amr training data adding additional information po tag dependency tree improves result
image captioning prominent artificial intelligence ai research area deal visual recognition linguistic description image interdisciplinary field concerning computer see understand digital image video describe language known human constructing meaningful sentence need structural semantic information language paper highlight contribution image caption generation assamese language unavailability image caption generation system assamese language open problem ainlp researcher early stage research achieve defined objective used encoderdecoder framework combine convolutional neural network recurrent neural network experiment tested flickrk coco caption dataset originally present english language translated datasets assamese language using stateoftheart machine translation mt system designed work
sentence represented hierarchical syntactic structure successfully modeled sentence processing contrast despite theoretical agreement hierarchical syntactic structure within word word argued computationally less complex sentence implemented finitestate model linear string morpheme even psychological reality morpheme denied paper extending computational model employed sentence processing morphological processing performed computational simulation experiment given incremental surprisal linking hypothesis five computational model different representational assumption evaluated human reaction time visual lexical decision experiment available english lexicon project elp shared task morphological processing literature simulation experiment demonstrated amorphous model without morpheme unit underperformed relative morphous model ii computational model hierarchical syntactic structure probabilistic contextfree grammar pcfg accurately explained human reaction time iii performance achieved top surface frequency effect result strongly suggest morphological processing track morpheme incrementally left right parses hierarchical syntactic structure contrary amorphous finitestate model morphological processing
prior research investigated impact various linguistic feature crosslingual transfer performance study investigate manner effect mapped onto representation space past study focused impact crosslingual alignment multilingual language model finetuning study examines absolute evolution respective language representation space produced mllms place specific emphasis role linguistic characteristic investigate intercorrelation impact representation space crosslingual transfer performance additionally paper provides preliminary evidence finding leveraged enhance transfer linguistically distant language
aspectcategory sentiment analysis acsa aim predict aspect category mentioned text corresponding sentiment polarity joint model proposed address task given text joint model detect aspect category mentioned text predict sentiment polarity toward although joint model obtain promising performance train separate parameter aspect category therefore suffer data deficiency aspect category solve problem propose novel joint model contains shared sentiment prediction layer shared sentiment prediction layer transfer sentiment knowledge aspect category alleviates problem caused data deficiency experiment conducted semeval datasets demonstrate effectiveness model
multimodal emotion recognition gained increasing attention recent year due widespread application advance multimodal learning approach however previous study primarily focus developing model exploit unification multiple modality paper propose maintaining modality independence beneficial model performance according principle construct dataset devise multimodal transformer model new dataset chinese emotion recognition dataset modalitywise annotions abbreviated cherma provides unimodal label individual modality multimodal label modality jointly observed model consists unimodal transformer module learn representation modality multimodal transformer module fuse modality module supervised corresponding label separately forward information flow unidirectionally unimodal module multimodal module supervision strategy model architecture guarantee individual modality learns representation independently meanwhile multimodal module aggregate information extensive empirical result demonstrate proposed scheme outperforms stateoftheart alternative corroborating importance modality independence multimodal emotion recognition dataset code availabel urlhttpsgithubcomsunjunaimerlfmim
knowledge extraction scientific literature major issue crucial promoting transparency reproducibility innovation research community work present novel approach towards identification extraction analysis dataset codesoftware mention within scientific literature introduce comprehensive dataset synthetically generated chatgpt meticulously curated augmented expanded real snippet scientific text fulltext publication computer science using humanintheloop process dataset contains snippet highlighting mention two research artifact ra type dataset codesoftware along insightful metadata including name version license url well intended usage provenance also finetune simple large language model llm using lowrank adaptation lora transform research artifact analysis raa instructionbased question answering qa task ultimately report improvement performance test set dataset compared base llm model method provides significant step towards facilitating accurate effective efficient extraction datasets software scientific paper contributing challenge reproducibility reusability scientific research
paper describes independent effort extending monolingual semantic textual similarity sts task setting multiple crosslingual setting involving english japanese chinese far adopted monolingual similarity translation strategy predict semantic similarity pair sentence different language strategy monolingual similarity method applied one target sentence translated pivot language therefore paper specifically detail required developed resource implement framework presenting current result englishjapanesechinese crosslingual sts task may exemplify validity framework
describe participation team takelab aggression detection shared task trac workshop english aggression manifest variety way unlike form aggression impossible prevent daytoday life aggressive speech abounding social network could principle prevented least reduced simply disabling user post aggressively worded message first step achieving detect message task however far trivial considered aggressive speech quite subjective task complicated noisy nature usergenerated text social network system learns distinguish open aggression covert aggression nonaggression social medium text tried different machine learning approach including traditional shallow machine learning model deep learning model combination achieved respectable result ranking th th submission facebook twitter test set respectively
data annotation timeconsuming laborintensive process many nlp task although exist various method produce pseudo data label often taskspecific require decent amount labeled data start recently immense language model gpt billion parameter achieved tremendous improvement across many fewshot learning task paper explore way leverage gpt lowcost data labeler train model find make downstream model achieve performance variety nlu nlg task cost less use label gpt using label human furthermore propose novel framework combining pseudo label gpt human label lead even better performance result present costeffective data labeling methodology generalizable many practical application
many application personal digital assistant constant need new domain increase system coverage user query conventional approach learn separate model every time new domain introduced approach slow inefficient bottleneck scaling large number domain paper introduce framework allows u single model handle domain including unknown domain may created future long covered master schema key idea remove need distinguishing domain explicitly predicting schema query given permitted schema query perform constrained decoding lattice slot sequence allowed schema proposed model achieves competitive often superior performance conventional model trained separately per domain
anonymity darknet allows vendor stay undetected using multiple vendor alias frequently migrating market consequently illegal market connection challenging uncover darknet identify relationship illegal market vendor propose vendorlink nlpbased approach examines writing pattern verify identify link unique vendor account across text advertisement ad seven public darknet market contrast existing literature vendorlink utilizes strength supervised pretraining perform closedset vendor verification openset vendor identification lowresource market adaption task vendorlink uncover migrant potential alias alphabaydreamssilk dataset ii migrant potential alias valhallaberlusconi dataset iii migrant potential alias traderouteagora dataset altogether approach help law enforcement agency lea make informed decision verifying identifying migrating vendor potential alias existing lowresource lr emerging darknet market
enhance explainability meeting summarization construct new dataset called explainmeetsum augmented version qmsum newly annotating evidence sentence faithfully explain summary using explainmeetsum propose novel multiple extractor guided summarization namely multidyle extensively generalizes dyle enable using supervised extractor based humanaligned extractive oracle present explainabilityaware task named explainable evidence extraction e aim automatically detect evidence sentence support given summary experimental result qmsum dataset show proposed multidyle outperforms dyle gain rouge score present initial result e task setting using separate joint evaluation metric
language contextual meaning word dependent context contextuality concomitantly welldefined concept quantum mechanic considered major resource quantum computation investigate whether natural language exhibit quantum mechanic contextual feature show meaning combination ambiguous phrase modelled sheaftheoretic framework quantum contextuality become possibilistically contextual using framework contextualitybydefault cbd explore probabilistic variant show cbdcontextuality also possible
recent advance incorporating layout information typically bounding box coordinate pretrained language model achieved significant performance entity recognition document image using coordinate easily model position token sensitive manipulation document image eg shifting rotation scaling common real scenario limitation becomes even worse training data limited fewshot setting paper propose novel framework lager leverage topological adjacency relationship among token learning relative layout information graph neural network specifically consider token document node formulate edge based topological heuristic adjacency graph invariant affine transformation making robust common image manipulation incorporate graph pretrained language model adding graph neural network layer top language model embeddings extensive experiment two benchmark datasets show lager significantly outperforms strong baseline different fewshot setting also demonstrate better robustness manipulation
recent improvement nlp come change neural network architecture modeling text input yet stateoftheart model often rely simple approach model label space eg bigram conditional random field crfs sequence tagging expressive graphical model rarely used due prohibitive computational cost work present approach efficiently training decoding hybrid graphical model neural network based gibbs sampling approach natural adaptation samplerank wick et al neural model widely applicable task beyond sequence tagging apply approach named entity recognition present neural skipchain crf model exact inference impractical skipchain model improves strong baseline three language conll obtain new stateoftheart result dutch
scale capacity pretrained model growing rapidly parameterefficient language model tuning emerged popular paradigm solving various nlp visionandlanguage vl task paper design unified parameterefficient multitask learning framework work effectively nlp vl task particular use shared hypernetwork take trainable hyperembeddings visual modality input output weight different module pretrained language model parameter inserted multihead attention block ie prefixtuning feedforward block ie adaptertuning proposed framework add fewer trainable parameter multitask learning achieving superior performance transfer ability compared stateoftheart method empirical result glue benchmark multiple vl task confirm effectiveness framework
claim central component argument detecting claim across different domain data set often challenging due varying conceptualization propose alleviate problem finetuning language model using reddit corpus million opinionated claim claim selflabeled author using internet acronym imoimho humble opinion empirical result show using approach improves state art performance across four benchmark argumentation data set average absolute f point claim detection data set include diverse domain social medium student essay improvement demonstrates robustness finetuning novel corpus
show novel approach detecting noun abstraction within large language model llm starting psychologically motivated set noun pair taxonomic relationship instantiate surface pattern indicating hypernymy analyze attention matrix produced bert compare result two set counterfactuals show detect hypernymy abstraction mechanism solely related distributional similarity noun pair finding first step towards explainability conceptual abstraction llm
paper describes system submitted iwslt volctrans team participate offline speech translation texttotext simultaneous translation track offline speech translation best endtoend model achieves bleu improvement benchmark mustc test set even approaching result strong cascade solution texttotext simultaneous translation explore best practice optimize waitk model result final submitted system exceed benchmark around bleu latency regime release code model facilitate future research work industrial application
creating explanation answer science question challenging task requires multihop inference large set fact sentence year refocus textgraphs shared task problem gathering relevant statement rather solely finding single correct path worldtree dataset augmented expert rating relevance statement overall explanation system achieved second place shared task leaderboard combine initial statement retrieval language model trained predict relevance score ensembling number resulting ranking code implementation made available urlhttpsgithubcommddaworldtreecorpustreetextgraphs
one main challenge field embodied conversational agent eca generate socially believable agent common strategy agent behaviour synthesis rely dedicated corpus analysis corpus composed multimedia file socioemotional behavior annotated external observer underlying idea identify interaction information agent socioemotional behavior checking whether intended socioemotional behavior actually perceived human annotation used learning class machine learning algorithm applied social signal paper introduces potus corpus composed highquality audiovideo file political address american people two protagonist present database first includes speech former president barack obama american people secondly provides video speech given virtual agent named rodrigue eca reproduces original address closely possible using social signal automatically extracted original one annotated social attitude providing information stance observed file also provides social signal automatically extracted obamas address used generate rodrigues one
paper present application automatic identification important moment might occur student collaborative chat moment detected based input received user may choose perform analysis topic interest himher moreover application offer various type suggestive intuitive graphic aid user identification moment two main aspect considered identifying important moment concept frequency distribution throughout conversation chat tempo analyzed identifying intensively debated concept tempo chat understand rate idea input chat participant expressed utterance timestamps
conditional set generation learns mapping input sequence token set several nlp task entity typing dialogue emotion tagging instance set generation seqseq model popular choice model set generation treat set sequence fully leverage key property namely orderinvariance cardinality propose novel algorithm effectively sampling informative order combinatorial space label order jointly model set cardinality output listing set size first element taking advantage autoregressive factorization used seqseq model method modelindependent data augmentation approach endows seqseq model signal orderinvariance cardinality training seqseq model new augmented data without additional annotation get average relative improvement four benchmark datasets across model spanning bartbase tb gpt release code data upon acceptance
multimodal emotion recognition video gained considerable attention recent year three modality textitie textual visual acoustic involved due diverse level informational content related emotion three modality typically possess varying degree contribution emotion recognition seriously might inconsistency emotion individual modality video challenge mentioned caused inherent uncertainty emotion inspired recent advance quantum theory modeling uncertainty make initial attempt design quantuminspired adaptiveprioritylearning model qap address challenge specifically quantum state introduced model modal feature allows modality retain emotional tendency final classification additionally design qattention orderly integrate three modality qap learns modal priority adaptively modality provide different amount information based priority experimental result iemocap mosei datasets show qap establishes new stateoftheart result
privacy design also referred data protection design approach solution mechanism addressing privacy data protection embedded entire project lifecycle early design stage rather added additional lawyer final product formulated privacy commissionner ontario principle privacy design discussed institution policymakers side atlantic mentioned already eu data protection directive ec recently privacy design introduced one requirement general data protection regulation gdpr obliging data controller define adopt already conception phase appropriate measure safeguard implement data protection principle protect right data subject failing meet obligation may result hefty fine case uniontrad decision french data protection authority cnil ambition proposed paper analyse practical meaning privacy design context language resource propose measure safeguard implemented community ensure respect principle
current evaluation metric timeline summarization either ignore temporal aspect task require strict date matching introduce variant rouge allow alignment daily summary via temporal distance semantic similarity argue suitability variant theoretical analysis demonstrate battery taskspecific test
success site acled world data demonstrated massive utility extracting event structured format large volume textual data formof news social medium blog discussion forum event extraction provide window ongoing geopolitical crisis yield actionable intelligence work cast sociopolitical event extraction machine reading comprehension mrc task proliferation large pretrained language model machine reading comprehension mrc emerged new paradigm event extraction recent time approach extraction socialpolitical actor target sentence framed extractive questionanswering problem conditioned event type several advantage using mrc task including ability leverage large pretrained multilingual language model ability perform zeroshot extraction moreover find problem longrange dependency ie large lexical distance trigger argument word difficulty processing syntactically complex sentence plague mrcbased approach address present general approach improve performance mrcbased event extraction performing unsupervised sentence simplification guided mrc model evaluate approach icews geopolitical event extraction dataset specific attention actor target argument role show context simplification improve performance mrcbased event extraction actor extraction target extraction
paper introduce hybrid search attentionbased neural machine translation nmt target phrase learned statistical mt model extends hypothesis nmt beam search attention nmt model focus source word translated phrase phrase added way scored nmt model also smt feature including phraselevel translation probability target language model experimental result germantoenglish news domain englishtorussian ecommerce domain translation task show using phrasebased model nmt search improves mt quality bleu absolute compared strong nmt baseline
recent generative approach multihop question answering qa utilize fusionindecoder method generate single sequence output includes final answer reasoning path taken arrive answer passage title key fact passage model lead better interpretability high quantitative score often difficulty accurately identifying passage corresponding key entity context resulting incorrect passage hop lack faithfulness reasoning path address propose singlesequence prediction method local reasoning graph integrates graph structure connecting key entity context passage relevant subsequent passage question use graph neural network encode graph structure fuse resulting representation entity representation model experiment show significant improvement answer exactmatchf score faithfulness grounding reasoning path hotpotqa dataset achieve stateoftheart number musique dataset increase model parameter
tablebased fact verification task aim verify whether given statement supported given semistructured table symbolic reasoning logical operation play crucial role task existing method leverage program contain rich logical information enhance verification process however due lack fully supervised signal program generation process spurious program derived employed lead inability model catch helpful logical operation address aforementioned problem work formulate tablebased fact verification task evidence retrieval reasoning framework proposing logiclevel evidence retrieval graphbased verification network lergv specifically first retrieve logiclevel programlike evidence given table statement supplementary evidence table construct logiclevel graph capture logical relation entity function retrieved evidence design graphbased verification network perform logiclevel graphbased reasoning based constructed graph classify final entailment relation experimental result largescale benchmark tabfact show effectiveness proposed approach
paper present forwardquestions data set made humangenerated question related knowledge triple data set result conversion merger existing simpledbpediaqa simplequestionswikidata data set including mapping predicate dbpedia wikidata selection forward question opposed backward one new data set used generate novel question given unseen wikidata triple replacing subject existing question new one selecting best candidate question using semantic syntactic criterion evaluation result indicate question generation method using forwardquestions improves quality question respect baseline using ranking criterion
despite outstanding performance many task language model notoriously inclined make factual error task requiring arithmetic computation address deficiency creating calcx collection datasets demonstrates appropriate use calculator reasoning chain calcx suitable teaching language model offload computation symbolic system survey unify several existing chainofthought datasets proposed format resulting standard collection sample requiring arithmetic reasoning finally use new calcx collection train opensource calculatorusing model show model approximately double accuracy generating correct result compared vanilla language model baseline
study influence context sentence acceptability first compare acceptability rating sentence judged isolation relevant context irrelevant context result show context induces cognitive load human compress distribution rating moreover relevant context observe discourse coherence effect uniformly raise acceptability next test unidirectional bidirectional language model ability predict acceptability rating bidirectional model show promising result best model achieving new stateoftheart unsupervised acceptability prediction two set experiment provide insight cognitive aspect sentence processing central issue computational modeling text discourse
since development wide use pretrained language model plms several approach applied boost performance downstream task specific domain biomedical scientific domain additional pretraining indomain text common approach providing domainspecific knowledge plms however pretraining method require considerable indomain data training resource longer training time moreover training must reperformed whenever new plm emerges study propose domain knowledge transferring doktra framework plms without additional indomain pretraining specifically extract domain knowledge existing indomain pretrained language model transfer plms applying knowledge distillation particular employ activation boundary distillation focus activation hidden neuron also apply entropy regularization term teacher training distillation encourage model generate reliable output probability thus aid distillation applying proposed doktra framework downstream task biomedical clinical financial domain student model retain high percentage teacher performance even outperform teacher certain task code available urlhttpsgithubcomdmcbgistdoktra
paper describes implementation generalized query language google ngram database language allows expressive query exploit semantic similarity acquired corpus eg lsa wordnet phonetic similarity available cmu pronouncing dictionary contains large number new operator combined proper query help user extract ngrams similarly close syntactic semantic relational property also characterize operator respect corpus affiliation functionality query syntax considered next given term backusnaur rule followed interesting example tool used also describe commandline argument user could input comparing one retrieving ngrams interface google ngram database finally discus possible improvement extraction process relevant query completeness issue
paper introduces fire financial relation extraction sentencelevel dataset named entity relation within financial sector comprising instance dataset encapsulates named entity type along relation type sourced public financial report financial news article fire capture wide array financial information business including limited corporate structure business model revenue stream market activity acquisition full dataset labeled single annotator minimize labeling noise labeling time sentence recorded labeling process show feature along curriculum learning technique used improved model performance fire dataset designed serve valuable resource training evaluating machine learning algorithm domain financial information extraction dataset code reproduce experimental result available httpsgithubcomhmhamadfire repository labeling tool found httpsgithubcomabhinavkumarthakurrelationextractionannotator
paper describes system extracting typed dependency parses english sentence phrase structure parses order capture inherent relation occurring corpus text critical realworld application many np relation included set grammatical relation used provide comparison system minipar link parser typed dependency extraction facility described integrated stanford parser available download
semantic role labeling srl aim recognize predicateargument structure sentence syntactic information paid great attention role enhancing srl however latest advance show syntax would important srl emerging much smaller gap syntaxaware syntaxagnostic srl comprehensively explore role syntax srl task extend existing model propose unified framework investigate effective diverse way incorporating syntax sequential neural network exploring effect syntactic input quality srl performance confirm highquality syntactic parse could still effectively enhance syntacticallydriven srl using empirically optimized integration strategy even enlarge gap syntaxaware syntaxagnostic srl framework achieves stateoftheart result conll benchmark english chinese substantially outperforming previous model
acquiring training data natural language processing system expensive timeconsuming given training example crafted expert large corpus mined thousand semantically similar example provide useful variability improve model generalization present topgunn fast contextualized knn retrieval system efficiently index search contextual embeddings generated large corpus topgunn demonstrated training data augmentation use case gigaword corpus using approximate knn efficient architecture topgunn performs query embedding space tb approximately b embeddings less day
paper evaluate several transformerbased language model icelandic four downstream task partofspeech tagging named entity recognition dependency parsing automatic text summarization pretrain four type monolingual electra convbert model compare result previously trained monolingual roberta model multilingual mbert model find transformer model obtain better result often large margin compared previous stateoftheart model furthermore result indicate pretraining larger language model result significant reduction error rate comparison smaller model finally result show monolingual model icelandic outperform comparably sized multilingual model
paper present newsreader meantime corpus semantically annotated corpus wikinews article corpus consists news article ie english news article translation spanish italian dutch meantime contains annotation different level documentlevel annotation includes markables eg entity mention event mention time expression numerical expression relation markables modeling example temporal information semantic role labeling entity event intradocument coreference corpuslevel annotation includes entity event crossdocument coreference semantic annotation english section performed manually annotation italian spanish partially dutch procedure devised automatically project annotation english text onto translated text based manual alignment annotated element enabled u speed annotation process also provided crosslingual coreference english section corpus extended timeline annotation semeval timeline shared task first clin dutch shared task clin based dutch section evalita facta event factuality annotation shared task based italian section currently organized
literary domain continues pose challenge sentiment analysis method due particularly nuanced layered nature paper explores adequacy different sentiment analysis tool dictionarybased approach stateoftheart transformer capturing valence modelling sentiment arc take ernest hemingway novel old man sea case study address challenge inherent literary language compare transformer rulebased system score human annotation shed light complexity analyzing sentiment narrative text finally emphasize potential model ensemble
discus preprocessing tokenisation standard within delphin large scale opensource collaboration providing multiple independent multilingual shallow deep processor discus componentspecific xml interface format used time interface preprocessor result pet parser ii implementation generic xml interface format influenced heavily iso working draft morphosyntactic annotation framework maf generic format encapsulates information may passed preprocessing stage parser us standoffannotation lattice representation structural ambiguity intraannotation dependency allows highly structured annotation content work build existing heart gold middleware system previous work robust minimal recursion semantics rmrs part intercomponent interface give example usage number delphin processing component deep grammar
describe cubreporter information access system allows access news archive use natural language technology system includes advanced text search question answering summarization entity profiling capability designed taking account characteristic background gathering task
team wordguessing game one player cluegiver give clue attempting elicit targetword another player receiver popular form entertainment also used educational purpose creating engaging computational agent capable emulating talented human cluegiver timed wordguessing game depends ability provide effective clue clue able elicit correct guess human receiver many available web resource database mined raw material clue targetwords however large number clue unlikely able elicit correct guess human guesser paper propose method automatically filtering clue corpus effective clue arbitrary targetword larger set potential clue using machine learning set feature clue including pointwise mutual information clue constituent word clue targetword result experiment significantly improve average clue quality previous approach bring quality rate inline measure human clue quality derived corpus humanhuman interaction paper also introduces data used develop method audio recording people making guess heard clue spoken synthesized voice
recent work shown learn better visualsemantic embeddings leveraging image description one language investigate detail condition affect performance type grounded language learning model show multilingual training improves bilingual training lowresource language benefit training higherresource language demonstrate multilingual model trained equally well either translation comparable sentence pair annotating set image multiple language enables improvement via additional captioncaption ranking objective
suicide prevention hotline counselor aid individual difficult time million call chat chatbot safely replace counselor explore whether chatbot developed help train human counselor system need simulate intimate situation across multiple practice session opendomain dialogue system frequently suffer generic response characterize personal story look infuse conversation persona information mimicking prototype conversation towards building crisisbot hotline visitor simulation propose counseling strategy annotation scheme multitask framework leverage counselor strategy retrieve similar example generate diverse subutterances interleave prototype generated subutterances complex response evaluate framework crowdworkers experienced hotline counselor framework considerably increase response diversity specificity limited impact coherence result also show considerable discrepancy crowdworker counselor judgement emphasizes importance including target population system development evaluation
one biggest challenge hindering progress lowresource multilingual machine translation lack good evaluation benchmark current evaluation benchmark either lack good coverage lowresource language consider restricted domain low quality constructed using semiautomatic procedure work introduce flores evaluation benchmark consisting sentence extracted english wikipedia covering variety different topic domain sentence translated language professional translator carefully controlled process resulting dataset enables better assessment model quality long tail lowresource language including evaluation manytomany multilingual translation system translation fully aligned publicly releasing highquality highcoverage dataset hope foster progress machine translation community beyond
highly accurate machine translation system important society country multilinguality common english often suffice indian subcontinent south asia region indic language currently underrepresented nlp ecosystem essential thoroughly explore various technique improve performance lowresource language least using data available opensource something explored indic ecosystem work perform study focus improving performance verylowresource south asian language especially country addition india specifically propose unified model built exploit data comparatively resourcerich language region propose strategy unify different type unexplored script especially persoarabic script indic script build multilingual model south asian language despite script barrier also study augmentation technique like backtranslation made useof build unified model using openly available raw data understand level improvement expected indic language
multimodal aspectbased sentiment analysis mabsa finegrained sentiment analysis task attracted growing research interest recently existing work mainly utilizes image information improve performance mabsa task however study overestimate importance image since many noise image unrelated text dataset negative impact model learning although work attempt filter lowquality noise image setting threshold relying threshold inevitably filter lot useful image information therefore work focus whether negative impact noisy image reduced without modifying data achieve goal borrow idea curriculum learning propose multigrained multicurriculum denoising framework mdf achieve denoising adjusting order training data extensive experimental result show framework consistently outperforms stateoftheart work three subtasks mabsa
multiword expression especially verbal one vmwes show idiosyncratic variability challenging nlp application hence need vmwe identification focus task variant identification ie identifying variant previously seen vmwes whatever surface form model problem classification task syntactic subtrees previously seen combination lemma first extracted classified basis feature relevant morphosyntactic variation vmwes feature value absolute ie hold particular vmwe candidate relative ie based comparing candidate previously seen vmwes approach outperforms baseline percent point fmeasure french corpus
paper describes facility converser healthcare highly interactive speech translation system enables user verify correct speech recognition machine translation correction presently useful realtime reliability future prove applicable offline machine learning provide example interactive tool action emphasizing semantically controlled backtranslation lexical disambiguation explain first time technique employed tool creation focusing upon compilation database semantic cue connection thirdparty mt engine planned extension technique statistical mt also discussed
warning paper contains content may offensive upsetting commonsense knowledge base cskb increasingly used various natural language processing task since cskbs mostly humangenerated may reflect societal bias important ensure bias conflated notion commonsense focus two widely used cskbs conceptnet genericskb establish presence bias form two type representational harm overgeneralization polarized perception representation disparity across different demographic group cskbs next find similar representational harm downstream model use conceptnet finally propose filteringbased approach mitigating harm observe filteredbased approach reduce issue resource model lead performance drop leaving room future work build fairer stronger commonsense model
goal sentimenttosentiment translation change underlying sentiment sentence keeping content main challenge lack parallel data solve problem propose cycled reinforcement learning method enables training unpaired data collaboration neutralization module emotionalization module evaluate approach two review datasets yelp amazon experimental result show approach significantly outperforms stateoftheart system especially proposed method substantially improves content preservation performance bleu score improved two datasets respectively
extractive summarization aim form summary directly extracting sentence source document existing work mostly formulate sequence labeling problem making individual sentence label prediction paper proposes diffusum novel paradigm extractive summarization directly generating desired summary sentence representation diffusion model extracting sentence based sentence representation matching addition diffusum jointly optimizes contrastive sentence encoder matching loss sentence representation alignment multiclass contrastive loss representation diversity experimental result show diffusum achieves new stateoftheart extractive result cnndailymail rouge score experiment two datasets different summary length crossdataset evaluation also demonstrate effectiveness diffusum strong performance framework show great potential adapting generative model extractive summarization
paper give overview evaluation campaign international workshop spoken language translation iwslt previous evaluation campaign primary focus workshop translation spoken language travel domain year four language pair translation chinese italian arabic japanese english input data consisted output asr system read speech clean text exception challenge task italian english language pair used spontaneous speech asr output transcription chinese english task used clean text new characteristic year evaluation campaign increased focus sharing resource participant requested submit data supplementary resource used building system participant might able take advantage resource second new characteristic year focus human evaluation system primary run judged human evaluation every task using straightforward ranking system year workshop saw increased participation last year workshop year group submitted run one task compared group submitted run last year automatic human evaluation carried measure mt performance condition asr system output read speech spontaneous travel dialogue clean text
language model serve valuable tool software developer increase productivity large generative model used code generation code completion smaller encoderonly model capable performing code search task using natural language query capability heavily influenced quality diversity available training data source code datasets used training usually focus popular language testing mostly conducted distribution often overlooking lowresource programming language motivated nlp generalization taxonomy proposed hupkes etal propose new benchmark dataset called gencodesearchnet gecs build upon existing natural language code search datasets systemically evaluate programming language understanding generalization capability language model part full dataset introduce new manually curated subset statcodesearch focus r popular far underrepresented programming language often used researcher outside field computer science evaluation comparison collect several baseline result using finetuned bertstyle model gptstyle large language model zeroshot setting
important property argumentation concern degree persuasiveness influenced various modality social medium platform individual usually option supporting textual statement image goal imagearg shared task held argmining therefore classify tweet stance considering modality b predict influence image persuasiveness tweet text paper present proposed methodology show strong performance task placing rd team leaderboard case f score b framework relies pretrained model extract text image feature fed taskspecific classification model experiment highlighted multimodal vision language model clip hold specific importance extraction feature particular task
lot recent work language vision looked generating description referring expression object scene realworld image though focusing mostly relatively simple language like object name color location attribute eg brown chair left paper present work drawandtell dataset detailed description common object image annotator produced finegrained attributecentric expression distinguishing target object range similar object additionally dataset come handdrawn sketch object drawandtell mediumsized contains rich vocabulary constitutes interesting challenge cnnlstm architecture used stateoftheart image captioning model explore whether additional modality given sketch help model learn accurately ground detailed language referring expression object shape result encouraging
important application artificial intelligence legal intelligence recently attracted attention many researcher previous work investigated diverse issue like predicting crime predicting outcome judicial debate extracting informationknowledge various kind legal document although many advance made research supporting prediction court judgment remains relatively scarce lack largescale data resource limit development researchin paper present novel largesize court debate dataset cdd includes court case totaling utterance cdd contains realworld conversation involving judge plaintiff defendant court trial construct dataset invited experienced judge design appropriate label data record asked law school student provide annotation based defined label dataset applied several downstream task text summarization dialogue generation text classification etc introduce detail different task rapidly developing field legal intelligence research fostered thanks dataset provide corresponding benchmark performance
large language model llm label data faster cheaper human various nlp task despite prowess llm may fall short understanding complex sociocultural domainspecific context potentially leading incorrect annotation therefore advocate collaborative approach human llm work together produce reliable highquality label present meganno humanllm collaborative annotation system offer effective llm agent annotation management convenient robust llm annotation exploratory verification llm label human
chinese word segmentation cws partofspeech po tagging important fundamental task chinese language processing joint learning effective onestep solution task previous study joint cws po tagging mainly follow characterbased tagging paradigm introducing contextual information ngram feature sentential representation recurrent neural model however many case joint tagging need modeling context feature also knowledge attached eg syntactic relation among word limited effort made existing research meet need paper propose neural model named twasp joint cws po tagging following characterbased sequence labeling paradigm twoway attention mechanism used incorporate context feature corresponding syntactic knowledge input character particularly use existing language processing toolkits obtain autoanalyzed syntactic knowledge context proposed attention module learn benefit although quality may perfect experiment illustrate effectiveness twoway attention joint cws po tagging stateoftheart performance achieved five benchmark datasets
introduce novel setup lowresource taskoriented semantic parsing incorporates several constraint may arise realworld scenario lack similar datasetsmodels related domain inability sample useful logical form directly grammar privacy requirement unlabeled natural utterance goal improve lowresource semantic parser using utterance collected user interaction highly challenging realistic setting investigate data augmentation approach involving generating set structured canonical utterance corresponding logical form simulating corresponding natural language filtering resulting pair find approach effective despite restrictive setup lowresource setting complex smcalflow calendaring dataset andreas et al observe relative improvement nondataaugmented baseline top match
team silpnlp participated three track semeval task semantic textual relatedness str created system total subtasks across track nine subtasks track subtasks track b ten subtasks track c make knowledge across subtasks used transformerbased pretrained model known strong crosslingual transferability track trained model two stage first stage focused multilingual learning track second stage finetuned model individual track track b used unigram bigram representation suport vector regression svr extreme gradient boosting xgboost regression track c utilized crosslingual transferability without use targeted subtask data work highlight fact knowledge gained subtasks transferred individual subtask base language model strong crosslingual characteristic system ranked first indonesian subtask track b c top three four subtasks
neural machine translation nmt model shown vulnerable adversarial attack wherein carefully crafted perturbation input mislead target model paper introduce act novel adversarial attack framework nmt system guided classifier attack adversary aim craft meaningpreserving adversarial example whose translation target language nmt model belong different class original translation unlike previous attack new approach substantial effect translation altering overall meaning lead different class determined oracle classifier evaluate robustness nmt model attack propose enhancement existing blackbox wordreplacementbased attack incorporating output translation target nmt model output logits classifier within attack process extensive experiment including comparison existing untargeted attack show attack considerably successful altering class output translation effect translation new paradigm reveal vulnerability nmt system focusing class translation rather mere translation quality studied traditionally
paper describe dell emcs framework automatically collect mtrelated productivity metric large translation supply chain extended period time characteristic volume gathered data insight analyzing data guide mt strategy aligning tool process people required decision concession contribution dell management technology provider tool implementors lsps linguist harvest data scale year dell emc migrated customized smt generic nmt customized nmt system content two quality tier ranked language pair productivity graphed trendlines compared time needed edit machine translation versus fuzzy match studied time spent segment postedits going postedit density reviewed segment distribution postedit scale correlation extent edits segment length
spite low literacy level afghanistan tribal area pakistan pashto dari region world wide web manifest diverse content author broad range viewpoint used crosslanguage information retrieval clir machine translation explore content present informal study principal genre encountered suitability limitation existing machine translation package language exploitation content discussed
paper present participation fidji system web questionanswering evaluation campaign organized quaero fidji opendomain questionanswering system combine syntactic information traditional qa technique named entity recognition term weighting order validate answer multiple document originally designed process clean document collection overall result significantly lower traditional campaign result french evaluation quite good compared stateoftheart system show syntaxbased strategy applied uncleaned web data still obtain good result moreover obtain much higher score complex question ie question representative real user need result show questioning web advanced linguistic technique done without heavy preprocessing result come near best system use strong resource large structured index
paper describes nicts participation iwslt evaluation campaign ted chineseenglish translation sharedtask approach used combination phrasebased hierarchical statistical machine translation smt system focus several area specifically system combination word alignment various language modeling technique including use neural network joint model experiment test set shared task showed improvement bleu score gained translation performance technique largest improvement coming using large data size train language model
paper present submission global tone communication co ltd dalian univeristy technology wmt shared general machine translation mt task conference empirical method natural language processing emnlp participation span language pair including englishukrainian ukrainianenglish czechukrainian englishhebrew hebrewenglish englishczech germanenglish japaneseenglish system designed without specific constraint requirement allowing u explore wider range possibility machine translation prioritize backtranslation utilize multilingual translation model employ finetuning strategy enhance performance additionally propose novel data generation method leverage human annotation generate highquality training data resulting improved system performance specifically use combination humangenerated machinegenerated data finetune model leading accurate translation automatic evaluation result show system rank first term bleu score ukrainianenglish hebrewenglish englishhebrew germanenglish
aspect based sentiment analysis dominant research area potential application social medium analytics business finance health prior work area primarily based supervised method technique using weak supervision limited predicting single aspect category per review sentence paper present extremely weakly supervised multilabel aspect category sentiment analysis framework use labelled data rely single word per class initial indicative information propose automatic word selection technique choose seed category sentiment word explore unsupervised language model posttraining improve overall performance propose multilabel generator model generate multiple aspect categorysentiment pair per review sentence experiment conducted four benchmark datasets showcase method outperform weakly supervised baseline significant margin
report describes gmus machine translation system wmt shared task largescale machine translation evaluation african language participated constrained translation track data listed shared task page allowed including submission accepted data track approach us model initialized deltalm generic pretrained multilingual encoderdecoder model finetuned correspondingly allowed data source best submission incorporates language family languagespecific adapter unit ranking ranked second constrained setting
schizophrenia one disabling difficult treat human medicalhealth condition ranking top ten cause disability worldwide puzzle part due difficulty identifying basic fundamental component several study shown manifestation schizophrenia eg negative symptom include blunting speech prosody well disorganization symptom lead disordered language understood perspective linguistics however schizophrenia research kept pace technology computational linguistics especially semantics pragmatic examine writing schizophrenia patient analyzing syntax semantics pragmatic addition analyze tweet self proclaimed schizophrenia patient publicly discus diagnosis writing sample dataset syntactic feature found successful classification whereas less structured twitter dataset combination feature performed best
paper focus topic inferential machine comprehension aim fully understand meaning given text answer generic question especially one needed reasoning skill particular first encode given document question option context aware way propose new network solve inference problem decomposing series attentionbased reasoning step result previous step act context next step make step directly inferred text design operational cell prior structure recursively linking cell inferred result synthesized together form evidence chain reasoning reasoning direction guided imposing structural constraint regulate interaction cell moreover termination mechanism introduced dynamically determine uncertain reasoning depth network trained reinforcement learning experimental result popular data set including mctest race multirc demonstrate effectiveness approach
clinical tempeval aimed answer question well system trained annotated timeline one medical condition colon cancer perform predicting timeline another medical condition brain cancer nine subtasks included covering problem time expression identification event expression identification temporal relation identification participant system evaluated clinical pathology note mayo clinic cancer patient annotated extension timeml clinical domain team participated task best system achieving f score time expression event expression temporal relation task observed point drop clinical tempeval system trained evaluated domain colon cancer
paper present initial step taken integrate language variation conversational ai agent enhance user engagement study built upon sociolinguistic pragmatic tradition involves creation annotation taxonomy taxonomy includes eleven class ranging concrete abstract covered aspect instance time sentiment register state region type grammar part speech meaning language paper discusses challenge incorporating vernacular language ai agent procedure data collection taxonomy organization also outline next step including database expansion computational implementation author believe integrating language variation conversational ai build nearreal language inventory boost user engagement paper concludes discussing limitation importance building rapport user vernacular
present approach discovery semantically similar term utilizes web search engine source generating related term tool estimating semantic similarity term system work associating document search engine index weighted term vector comprising phrase best describe document subject matter related term given seed phrase generated running seed search query mining result vector produced averaging weight term associated top document query result set degree similarity seed term related term computed cosine angle respective result vector test effectiveness approach building term recommender system designed help online advertiser discover additional phrase describe product offering comparison output several alternative method find competitive best known alternative
process learning using chinese foreigner may grammatical error due negative migration native language currently computeroriented automatic detection method grammatical error mature enough based evaluating task cged select analyze classification model design feature extraction method obtain grammatical error including missionm disorderw selection redundant r automatically experiment result based dynamic corpus hsk show chinese grammatical error automatic detection method us crf classification model ngram feature extraction method simple efficient play positive effect research chinese grammatical error automatic detection also supporting guiding role teaching chinese foreign language
large language model llm demonstrated impressive capability general scenario exhibiting level aptitude approach aspect even surpasses humanlevel intelligence among numerous skill translation ability llm received considerable attention compared typical machine translation focus solely sourcetotarget mapping llmbased translation potentially mimic human translation process might take preparatory step ensure highquality translation work explores possibility proposing map framework stand multiaspect prompting selection specifically enable llm first analyze given source sentence induce three aspect translationrelated knowledge keywords topic relevant demonstration guide final translation process moreover employ selection mechanism based quality estimation filter noisy unhelpful knowledge automatic llm mboxtimes direction mboxtimes automatic metric human evaluation preference study mqm demonstrate effectiveness map analysis show mimicking human translation process map reduces various translation error hallucination ambiguity mistranslation awkward style untranslated text omission source code available httpsgithubcomzwhemapsmt
recent research robust representation biomedical name focused modeling large amount finegrained conceptual distinction using complex neural encoders paper explore opposite paradigm training simple encoder architecture using small set name sampled highlevel biomedical concept encoder postprocesses pretrained representation biomedical name effective various type input representation domainspecific unsupervised validate proposed fewshot learning approach multiple biomedical relatedness benchmark show allows continual learning accumulate information various conceptual hierarchy consistently improve encoder performance given finding propose approach lowcost alternative exploring impact conceptual distinction robust biomedical name representation
interpolationbased regularisation method data augmentation proven effective various task modality method involve performing mathematical operation raw input sample latent state representation vector often possess complex hierarchical geometry however operation performed euclidean space simplifying representation may lead distorted noisy interpolation propose hypmix novel model data modalityagnostic interpolative data augmentation technique operating hyperbolic space capture complex geometry input hidden state hierarchy better contemporary evaluate hypmix benchmark low resource datasets across speech text vision modality showing hypmix consistently outperforms stateoftheart data augmentation technique addition demonstrate use hypmix semisupervised setting probe adversarial robustness qualitative inference draw hypmix elucidate efficacy riemannian hyperbolic manifold interpolationbased data augmentation
paper proposes new method constructing arbitrary classbased related word dictionary interactive topic model assume class described topic propose new semisupervised method us simplest topic model yielded standard em algorithm model calculation rapid furthermore approach allows dictionary modified interactively final dictionary hierarchical structure paper make three contribution first proposes wordbased semisupervised topic model second apply semisupervised topic model interactive learning approach called interactive topic model third propose score function extract related word occupy middle layer hierarchical structure experiment show method appropriately retrieve word belonging arbitrary class
natural language processing advanced aidriven language model lm applied widely text generation question answering model pretrained wide spectrum data source enhancing accuracy responsiveness however process inadvertently entail absorption diverse spectrum viewpoint inherent within training data exploring political leaning within lm due viewpoint remains lessexplored domain context lowresource language like bangla area research nearly nonexistent bridge gap comprehensively analyze bias present bangla language model specifically focusing social economic dimension finding reveal inclination various lm provide insight ethical consideration limitation associated deploying bangla lm
paper examines method improve user impression spoken dialog system introducing mechanism gradually change form utterance every time user us system language including japanese form utterance change corresponding social relationship talker listener thus mechanism effective express system intention make social distance user closer however actual effect method investigated enough introduced dialog system paper conduct dialog experiment show controlling form system utterance improve user impression
present approach mathematical information retrieval mir exploit special kind technical terminology referred mathematical type paper present evaluate type detection mechanism show positive effect retrieval researchlevel mathematics best model performs query expansion typeaware embedding space strongly outperforms standard ir model stateoftheart query expansion vector spacebased language modellingbased relatively new corpus researchlevel query
building nlp model tendency aim broader coverage often overlooking cultural sociolinguistic nuance position paper make case care attention nuance particularly dataset annotation well inclusion cultural linguistic expertise process present playbook responsible dataset creation polyglossic multidialectal language work informed study arabic annotation social medium content
propose two model verbalizing number key component speech recognition synthesis system first model us endtoend recurrent neural network second model drawing inspiration linguistics literature us finitestate transducer constructed minimal amount training data model achieve nearperfect performance latter model trained using several order magnitude less data former making particularly useful lowresource language
paper describes lingjing team method workshop computational approach subjectivity sentiment social medium analysis wassa shared task personality prediction per reactivity index prediction iri paper adopt promptbased method pretrained language model accomplish task specifically prompt designed provide knowledge extra personalized information enhancing pretrained model data augmentation model ensemble adopted obtaining better result extensive experiment performed show effectiveness proposed method final submission system achieves pearson correlation coefficient track track respectively ranked st subtasks
documentlevel evaluation machine translation raised interest community especially since response claim human parity toral et al laubli et al documentlevel human evaluation published yet little known best practice regarding human evaluation machine translation documentlevel paper present comparison difference interannotator agreement quality assessment using sentence documentlevel setup report result agreement professional translator fluency adequacy scale error annotation pairwise ranking along effort needed perform different task best knowledge first study kind
question interoperability linguistic annotated resource cover different aspect first requires representation framework making possible compare eventually merge different annotation schema paper general description level representing multimodal linguistic annotation proposed focus time representation data content representation paper reconsiders enhances current generalized representation annotation xml schema annotation proposed python api also proposed framework implemented multiplatform software distributed term gnu public license
authorship attribution active research area prevalent many decade nevertheless majority approach consider problem size candidate author making difficult apply recent scenario incorporating thousand author emerging due manifold mean digitally share text study focus largescale problem propose effectively reduce number candidate author applying common attribution technique utilizing document embeddings show novel comprehensive dataset collection set candidate author reduced high accuracy moreover show common authorship attribution method substantially benefit preliminary reduction thousand author involved
data scarcity common problem nlp especially annotation pertains nuanced sociolinguistic concept require specialized knowledge result fewshot identification concept desirable fewshot incontext learning using pretrained large language model llm recently applied successfully many nlp task paper study fewshot identification psycholinguistic concept morality frame roy et al using llm morality frame representation framework provides holistic view moral sentiment expressed text identifying relevant moral foundation haidt graham finer level granularity moral sentiment expressed towards entity mentioned text previous study relied human annotation identify morality frame text expensive paper propose prompting based approach using pretrained large language model identification morality frame relying fewshot exemplar compare model performance fewshot roberta found promising result
script knowledge play central role text understanding relevant variety downstream task paper consider two recent datasets provide rich general representation script event term paraphrase set introduce task mapping event mention narrative text script event type present model task exploit rich linguistic representation well information temporal ordering result experiment demonstrate complex task indeed feasible
wordnet ontology development resourcepoor language like persian requires composition several strategy employment appropriate heuristic lexical linguistic structured resource limited persian lot diversity structural syntagmatic complexity paper proposes system extraction verbal synset relation extend farsnet persian wordnet proposed method extract verbal word concept using noun adjective word synset exploit data digital lexicon glossary lead identification proper verbal word verbal synset precision respectively proposed system also extract relation semantic role verbal argument instrument location agent patient also relatedto unlabeled relation cooccurrence among verb concept purpose combination linguistic approach morphological analysis word semantic analysis use key phrase syntactic semantic pattern corpusbased approach statistical technique cooccurrence analysis utilized presented strategy extract proper relation existing concept farsnet precision
referring resolution task identifying referent natural language expression example woman behind woman getting massage paper investigate kind referring expression current transformer based model fail motivated analysis identify weakening spatial natural constraint one cause propose model aim restore evaluate proposed model different datasets task showing improved performance challenging kind referring expression finally present thorough analysis kind error improved new model remain future challenge task
describe corpus numerical expression developed part numgen project corpus contains newspaper article scientific paper exactly numerical fact presented many time within across text annotation numerical fact original example number automatically classified round nonround algorithm derived jansen pollmann also numerical hedge little marked classified semantically using arithmetical relation explicit alignment phrase describing fact corpus support research influence various contextual factor eg document position intended readership way numerical fact expressed example present result investigation showing fact mentioned text clear tendency precision increase first subsequent mention mathematical level either remain constant increase
transliteration important indian language context due usage multiple script widespread use romanized input however training evaluation set publicly available introduce aksharantar largest publicly available transliteration dataset indian language created mining monolingual parallel corpus well collecting data human annotator dataset contains million transliteration pair indic language language family using script aksharantar time larger existing datasets first publicly available dataset language language family also introduce test set k word pair language enables finegrained analysis transliteration model native origin word foreign word frequent word rare word using training set trained indicxlit multilingual transliteration model improves accuracy dakshina test set establishes strong baseline aksharantar testset introduced work model mining script transliteration guideline datasets available httpsgithubcomaibharatindicxlit opensource license
characterlevel model used extensively recent year nlp task supplement replacement closedvocabulary tokenlevel word representation one popular architecture characterlevel lstms used feed token representation sequence tagger predicting tokenlevel annotation partofspeech po tag work examine behavior po tagger across language perspective individual hidden unit within character lstm aggregate behavior unit languagelevel metric quantify challenge tagger face language different morphological property identify link synthesis affixation preference emergent behavior hidden tagger layer comparative experiment show modifying balance forward backward hidden unit affect model arrangement performance type language
comment social medium diverse term content style vocabulary make generating comment much challenging existing natural language generation nlg task besides since different user different expression habit necessary take user profile consideration generating comment paper introduce task automatic generation personalized comment agpc social medium based ten thousand user real comment corresponding user profile weibo propose personalized comment generation network pcgn agpc model utilizes user feature embedding gated memory attends user description model personality user addition external user representation taken consideration decoding enhance comment generation experimental result show model generate natural humanlike personalized comment
increasingly globalized world situation people different native tongue communicate become frequent many situation human interpreter prohibitively expensive simply available automatic spoken language translation slt costeffective solution dilemma received increased attention recent year broad number application including live slt lecture oral presentation automatic system ideally operate real time low latency large highly specialized vocabulary well strong variation speaking style ranging read speech free presentation suffering spontaneous event make simultaneous slt lecture challenging task paper present progress building simultaneous germanenglish lecture translation system emphasize challenge particular language pair propose solution tackle problem encountered
research computational linguistics computer graphic autonomous agent led development increasingly sophisticated communicative agent past year bringing new perspective machine translation research engineering language based smooth expressive naturallooking human gesture give u useful insight design principle evolved natural communication people paper prototype machine translation system english american sign language asl taking account linguistic also visual spatial information associated asl sign
paper present brief snapshot state affair computational processing catalan initiative starting take place effort bring field step forward making better efficient use already existing resource tool bridging gap research market establishing periodical meeting point community particular present result first workshop computational processing catalan succeeded putting together fair representation research area received attention industry administration aside facilitating communication among researcher developer user workshop provided organizer valuable information existing resource tool developer provider information allowed u go step setting harvesting procedure hopefully build seed portalcatalogueobservatory language resource technology catalan
person unique personality affect feel convey emotion hence speaker modeling important task emotion recognition conversation erc paper propose novel graphbased erc model considers conversational context speaker personality model internal state speaker personality static dynamic speaker state dynamic speaker state modeled graph neural network based encoder experiment benchmark dataset show effectiveness model model outperforms baseline graphbased method analysis result also show importance explicit speaker modeling
introduce dissim discourseaware sentence splitting framework english german whose goal transform syntactically complex sentence intermediate representation present simple regular structure easier process downstream semantic application purpose turn input sentence twolayered semantic hierarchy form core fact accompanying context identifying rhetorical relation hold way preserve coherence structure input hence interpretability downstream task
describe evaluate characterlevel tagger languageindependent named entity recognition ner instead word sentence represented sequence character model consists stacked bidirectional lstms input character output tag probability character probability converted consistent word level named entity tag using viterbi decoder able achieve close stateoftheart ner performance seven language basic model using labeled ner data handengineered feature external resource like syntactic tagger gazetteer
recent development computer vision application based machine learning model allow realtime object detection segmentation captioning image video stream paper present development extension coco category novel ontology class covering thematic subdomains related sport transport art security development image dataset object segmentation accelerated machine learning automatic generation object boundary class multilingual image dataset contains image annotation used pretrain model object detection classification show established approach development new model integration application evaluation framework
differentiable neural computer dnc neural network model addressable external memory solve algorithmic question answering task various improved version dnc rsdnc dncdms however integrate structured knowledge dnc model remains challenging research question incorporate architecture knowledge dnc model ie dnc rsdnc dncdms improve ability generate correct response using contextual information structured knowledge improved rsdnc model improves mean accuracy approximately original rsdnc task requiring knowledge dialog babi task addition improved rsdnc dncdms model also yield better performance original model movie dialog dataset
online computermediated communication speaker considered experienced difficulty catching partner emotion conveying emotion explain online emotional communication difficult investigate problem solved multimodal online emotional communication corpus constructed recording approximately speaker emotional expression reaction modalitycontrolled environment speaker communicated internet using video chat voice chat text chat facetoface conversation used comparison purpose corpus incorporated emotional label evaluating speaker dynamic emotional state measurement speaker facial expression vocal expression autonomic nervous system activity initial study project used largescale emotional communication corpus accuracy online emotional understanding assessed demonstrate emotional label evaluated speaker summarize speaker answer questionnaire regarding difference online chat facetoface conversation actually participated result revealed speaker difficulty communicating emotion online communication environment regardless type communication modality inaccurate emotional understanding occurs frequently online computermediated communication facetoface communication
genetic algorithm gas studied across different field engineering medicine optimize diverse problem network routing medical image segmentation moreover used automatically find optimal architecture deep neural network however knowledge applied weight optimizer transformer model gradient descent main paradigm task believe gas advantage bring table paper show even though gas capable finetuning transformer encoders generalization ability considerably poorer adam however closer look gas ability exploit knowledge different pretraining datasets surpasses adam ability
verb play fundamental role many biomedical task application relation event extraction hypothesize performance many downstream task improved aligning input pretrained embeddings according semantic verb class work show using semantic cluster verb large lexicon verbclasses derived biomedical literature weare able improve performance common pretrained embeddings downstream task retrofitting verb class present simple computationally efficient approach using widelyavailable offtheshelf retrofitting algorithm align pretrained embeddings according semantic verb cluster achieve stateoftheart result text classification relation extraction task
image caption generation gathered widespread interest artificial intelligence community automatic generation image description requires computer vision natural language processing technique advanced research english caption generation research generating arabic description image extremely limited semitic language like arabic heavily influenced rootwords leverage critical dependency arabic generate caption image directly arabic using rootword based recurrent neural network deep neural network experimental result dataset various middle eastern newspaper website allow u report first bleu score direct arabic caption generation also compare result approach bleu score caption generated english translated arabic experimental result confirm generating image caption using rootwords directly arabic significantly outperforms englisharabic translated caption using stateoftheart method
main purpose article state effect using different method model counterfactual determination detection causal knowledge nowadays counterfactual reasoning widely used various field realm natural language processnlp counterfactual reasoning huge potential improve correctness sentence shared task detecting counterfactual semeval preprocess officially given dataset according case conversion extract stem abbreviation replacement use last bidirectional encoder representation bidirectional encoder representation transformer bertand term frequencyinverse document frequency tfidf vectorizer counterfactual detection meanwhile multisample dropout cross validation used improve versatility prevent problem poor generosity caused overfitting finally team ferryman ranked th place subtask competition
longstanding goal dense retriever abtractive opendomain question answering odqa task learn capture evidence passage among relevant passage given query reader produce factually correct output evidence passage one key challenge insufficient amount training data supervision answerability passage recent study rely iterative pipeline annotate answerability using signal reader high computational cost hamper practical application paper instead focus datadriven approach propose evidentialityaware dense passage retrieval eadpr leverage synthetic distractor sample learn discriminate evidence passage distractors conduct extensive experiment validate effectiveness proposed method multiple abstractive odqa task
goal product copywriting capture interest potential buyer emphasizing feature product text description ecommerce platform offer wide range service becoming essential dynamically adjust style autogenerated description typical approach copywriting generation often rely solely specified product attribute may result dull repetitive content tackle issue propose generate copywriting based customer review provide firsthand practical experience product offering richer source information product attribute developed sequencetosequence framework enhanced reinforcement learning produce copywriting attractive authentic rich information framework outperforms existing baseline zeroshot large language model including llamachatb gpt term attractiveness faithfulness furthermore work feature use llm aspectbased summary collection argument allure assessment experiment demonstrate effectiveness using llm marketing domain corpus construction code dataset publicly available urlhttpsgithubcomyuxianglincopywritinggeneration
current dialogue system fail engaging user especially trained endtoend without relying proactive reengaging scripted strategy zhang et al showed engagement level endtoend dialogue model increase conditioning text persona providing personalized backstory model however dataset used zhang et al synthetic contains around k different persona paper introduce new dataset providing million persona million personabased dialogue experiment show scale training using persona still improves performance endtoend system addition show task benefit wide coverage dataset finetuning model data zhang et al achieving stateoftheart result
model alignment human preference essential step making large language model llm helpful consistent human value typically consists supervised finetuning sft reinforcement learning human feedback rlhf stage however rlhf face inherent limitation stemming complex training setup tendency align model implicit value end user control runtime moreover reward model rlhf stage commonly rely singledimensional feedback opposed explicit multifaceted signal indicate attribute helpfulness humor toxicity address limitation propose steerlm supervised finetuning method empowers endusers control response inference steerlm condition response conform explicitly defined multidimensional set attribute thereby empowering steerable ai capable generating helpful highquality response maintaining customizability experiment show steerlm trained open source datasets generates response preferred human automatic evaluator many stateoftheart baseline trained rlhf much easier train try steerlm httpshuggingfaceconvidiasteerlmllamab
recent large language model llm revealed strong ability understand natural language since share basic structure ie transformer block possible contributor success training process scaling instruction tuning however factor affect model language perception unclear work compare selfattention several existing llm llama alpaca vicuna different size b b b b together eye saccade aspect human reading attention assess effect scaling instruction tuning language perception result show scaling enhances human resemblance improves effective attention reducing trivial pattern reliance instruction tuning however instruction tuning significantly enhances model sensitivity instruction also find current llm consistently closer nonnative native speaker attention suggesting suboptimal language perception model code data used analysis available github
interdisciplinary longitudinal study adult development aging ilse created facilitate study challenge posed rapidly aging society developed country germany ilse contains hour biographic interview recorded participant course year investigation various aspect aging cognitive decline often rely analysis linguistic feature derived spoken content like interview however transcribing speech time cost consuming manual process far hour ilse interview transcribed thus aim work establish technical system fully automatically transcribe ilse interview data joint occurrence poor recording quality long audio segment erroneous transcription varying speaking style crosstalk emotional dialectal speech interview present challenge automatic speech recognition asr describe ongoing work towards fully automatic transcription ilse interview step implemented preparing transcription meet interview challenge using recursive long audio alignment procedure hour transcribed data made accessible asr training
paper describes novel application semisupervision shallow discourse parsing use neural approach sequence tagging focus extraction explicit discourse argument first additional unlabeled data prepared semisupervised learning data weak annotation generated first setting later used another setting study performance difference study show increase performance model range f score give insight generated discourse annotation compare developed additional relation training relation release new dataset explicit discourse argument enable training large statistical model
develop technique transfer learning machine comprehension mc using novel twostage synthesis network given high performing mc model one domain technique aim answer question document another domain use labeled data questionanswer pair using proposed synthesis network pretrained model squad dataset achieve f measure challenging newsqa dataset approaching performance indomain model f measure outperforming outofdomain baseline without use provided annotation
prior work ideology prediction largely focused single modality ie text image work introduce task multimodal ideology prediction model predicts binary fivepoint scale ideological leaning given textimage pair political content first collect five new largescale datasets english document image along ideological leaning covering news article wide range mainstream medium u social medium post reddit twitter conduct indepth analysis news article reveal difference image content usage across political spectrum furthermore perform extensive experiment ablation study demonstrating effectiveness targeted pretraining objective different model component bestperforming model latefusion architecture pretrained triplet objective multimodal content outperforms stateoftheart textonly model almost strong multimodal baseline pretraining
open information extraction system extract subject text relation text object text triple raw text triple textual version fact ie noncanonicalized mention entity relation paper investigate whether possible infer new fact directly open knowledge graph without canonicalization supervision curated knowledge purpose propose open link prediction taskie predicting test fact completing subject text relation text question evaluation setup raise question correct prediction actually new fact induced reasoning open knowledge graph trivially explained example fact appear different paraphrased textual variant lead test leakage end propose evaluation protocol methodology creating open link prediction benchmark olpbench performed experiment prototypical knowledge graph embedding model openlink prediction task challenging result suggests possible predict genuinely new fact trivially explained
event extraction ee crucial information extraction ie task aim identify event trigger associated argument unstructured text subsequently classifying predefined type role biomedical domain ee widely used extract complex structure representing biological event literature due complicated semantics specialized domain knowledge challenging construct biomedical event extraction datasets additionally existing biomedical ee datasets primarily focus cell experiment overall experimental procedure therefore introduce aniee event extraction dataset concentrated animal experiment stage establish novel animal experiment customized entity event scheme collaboration domain expert create expertannotated highquality dataset containing discontinuous entity nested event evaluate dataset recent outstanding ner ee model
neural network nn applied natural language processing nlp becoming deeper complex making increasingly difficult understand interpret even application limited scope fixed data creation complex blackboxes creates substantial challenge debugging understanding generalization rapid development field lead building straightforward interpretable model propose new technique diskcsv distill knowledge concurrently neural network architecture text classification captured lightweight interpretableexplainable classifier across multiple datasets approach achieves better performance target blackbox addition approach provides better explanation existing technique
abstract meaning representation amr graphical meaning representation language designed represent propositional information argument structure however present unable satisfyingly represent nonveridical intensional context often licensing inappropriate inference paper show resolve problem nonveridicality without appealing layered graph mapping amrs simplytyped lambda calculus stlc least case requires introduction new role content function intensional operator translation proposed inspired formal linguistics literature event semantics attitude report next address interaction quantifier scope intensional operator socalled de rede dicto ambiguity adopt scope node literature provide explicit multidimensional semantics utilizing cooper storage allows u derive de de dicto scope reading well intermediate scope reading prove difficult account without scope node
documentlevel context neural machine translation nmt crucial improve translation consistency cohesion translation ambiguous input well several linguistic phenomenon many work published topic documentlevel nmt restrict system local context typically including one two preceding sentence additional information might enough resolve ambiguous input probably sufficient capture documentlevel information like topic style conversation increasing context size beyond local context two challenge memory usage increase exponentially ii translation performance start degrade argue widelyused attention mechanism responsible issue therefore propose constrained attention variant focus attention relevant part sequence simultaneously reducing memory consumption evaluation utilize targeted test set combination novel evaluation technique analyze translation regard specific discourserelated phenomenon find approach good compromise sentencelevel nmt v attending full context especially low resource scenario
two contrasting approach endtoend neural nli system linguisticallyoriented nli pipeline consisting module neural ccg parser theorem provers latter however face challenge integrating neural model used syntactic semantic component rnngs framework potentially fill gap conventional rnngs adopt cfg syntactic theory address issue implemented rnnccg syntactic parser replaces cfg ccg conducted experiment comparing rnnccg rnngs withwithout po tag evaluated behavior first step towards building nli system based rnnccg
certain phenomenon interest linguist mainly occur lowresource language contactinduced language change show possible study contactinduced language change computationally historical variety lowresource language earlymodern frisian creating model using feature established relevant closely related language modern dutch allows u test two hypothesis two type language contact may taken place frisian dutch time model show frisian verb cluster word order associated different context feature dutch verb order supporting learned borrowing hypothesis
task clickbait spoiling generating short text satisfies curiosity induced clickbait post clickbait link web page advertises content arousing curiosity instead providing informative summary previous study clickbait spoiling shown approach classifing type spoiler needed generating appropriate spoiler effective webis clickbait spoiling corpus dataset contribution focused study three class phrase passage multi finding appropriate model generate spoiler foreach class result analysed type spoiler revealed reason diversed result different spoiler type passage type spoiler identified difficult valuable type spoiler
paper present new corpus consisting sentence hindi short story annotated five different discourse mode argumentative narrative descriptive dialogic informative present detailed account entire data collection annotation process annotation high interannotator agreement kalpha analyze data term label distribution part speech tag sentence length characterize performance various classification algorithm dataset perform ablation study understand nature linguistic model suitable capturing nuance embedded discourse structure presented corpus
paper describes system developed detecting propaganda technique news article focus examining emotional salience feature extracted news segment help characterize predict presence propaganda technique correlation analysis surfaced interesting pattern instance loaded language slogan technique negatively associated valence joy intensity positively associated anger fear sadness intensity contrast flag waving appeal fearprejudice exact opposite pattern predictive experiment result indicate whereas bertonly feature obtained fscore emotion intensity feature bert hybrid feature able obtain fscore simple feedforward network used classifier setting gold test data system obtained microaveraged fscore overall detection efficacy fourteen propaganda technique performed relatively well detecting loaded language f name calling labeling f doubt f flag waving f
paper present new method collecting naturally generated dialogue data low resourced language specifically hereuyghur plan build game purpose gwaps encourage native speaker actively contribute dialogue data research project since aim characterize response space query uyghur design various scenario conversation yield question posed responded implement gwap rpg maker mv game engine integrate chatroom system game dialogue experimental toolkit diet diet help u improve data collection process importantly make u control interaction among participant
propose simple modification existing neural machine translation nmt model enables using single universal model translate multiple language allowing language specific parameterization also used domain adaptation approach requires change model architecture standard nmt system instead introduces new component contextual parameter generator cpg generates parameter system eg weight neural network parameter generator accepts source target language embeddings input generates parameter encoder decoder respectively rest model remains unchanged shared across language show simple modification enables system use monolingual data training also perform zeroshot translation show able surpass stateoftheart performance iwslt iwslt datasets learned language embeddings able uncover interesting relationship language
attempt formulate method automatically evaluating machine translation mt generally looked attrinbute translation tried explicitly implicitly extrapolate measurement cover broader class attribute particular study focused measuring fidelity translation inferring intelligibility others taken opposite approach paper examine fundamental question whether extent one attribute predicted starting point use darpa mt corpus measure attribute perform simple comparison behavior two hypothesis predictable inference fidelity intelligibility compared comparative behavior across language pair document corpus
ability identify important entity text known named entity recognition ner useful large variety downstream task biomedical domain considerably difficult task working consumer health question chqs consist informal language used daytoday life patient difficulty amplified case bengali allows huge amount flexibility sentence structure significant variance regional dialect unfortunately complexity language accurately reflected limited amount available data make difficult build reliable decisionmaking system address scarcity data paper present banglahealthner comprehensive dataset designed identify named entity healthrelated text bengali language consists sample sourced popular online public health platform allows capture diverse range linguistic style dialect used native speaker various region daytoday life insight diversity language prove useful medical decisionmaking system developed use realworld application highlight difficulty dataset benchmarked stateoftheart token classification model banglishbert achieved highest performance fscore pm dataset relevant code used work made publicly available
early online perception experiment software percy deployed production server lab since experiment made publicly available total experiment session course time software continuously updated extended adapt changing user requirement webbased editor structure layout experiment developed paper describes system architecture present usage statistic discusses typical characteristic online experiment give outlook ongoing work webappphonetikunimuenchendewebexperiment list currently active experiment
retrieveandedit based approach structured prediction structure associated retrieved neighbor edited form new structure recently attracted increased interest however much recent work merely condition retrieved structure eg sequencetosequence framework rather explicitly manipulating show perform accurate sequence labeling explicitly copying label retrieved neighbor moreover copying labelagnostic achieve impressive performance zeroshot sequencelabeling task additionally consider dynamic programming approach sequence labeling presence retrieved neighbor allows controlling number distinct copied segment used form prediction lead interpretable accurate prediction
translation quality estimation qe important component realworld machine translation application unfortunately human labeled qe datasets play important role developing assessing qe model available limited language pair paper present first englishpersian qe dataset called epoque manually annotated direct assessment label epoque contains sentence translated english persian annotated three human annotator publicly available thus used zeroshot test set scenario future work also evaluate report performance two stateoftheart qe model ie transquest cometkiwi baseline dataset furthermore experiment show using small subset proposed dataset containing sentence finetune transquest improve performance term pearson correlation heldout test set
paper describe submission simultaneous speech translation iwslt explore strategy utilize offline model simultaneous setting without need modify original model experiment show onlinization algorithm almost par offline setting x faster offline term latency test set also show onlinized offline model outperforms best iwslt simultaneous system medium high latency regime almost par low latency regime make system publicly available
emotion recognition conversation challenging task recently gained popularity due potential application however largescale multimodal multiparty emotional conversational database containing two speaker per dialogue missing thus propose multimodal emotionlines dataset meld extension enhancement emotionlines meld contains utterance dialogue tvseries friend utterance annotated emotion sentiment label encompasses audio visual textual modality propose several strong multimodal baseline show importance contextual multimodal information emotion recognition conversation full dataset available use urlhttpaffectivemeldgithubio
social medium platform twitter offer people opportunity publish short post share opinion perspective application valuable also exploited promote negative opinion insult hatred person race group opinion spread million people click mouse need develop mechanism offensive language automatically detected social medium channel managed timely manner help achieve goal semeval offered shared task offenseval involved detection offensive text arabic propose ensemble approach combine different level word embedding model transfer learning source emotionrelated task proposed system ranked th entry within arabic offensive language identification subtask
ad hoc abbreviation commonly found informal communication channel favor shorter message consider task reversing abbreviation context recover normalized expanded version abbreviated message problem related distinct spelling correction ad hoc abbreviation intentional involve substantial difference original word ad hoc abbreviation also productively generated onthefly resolved solely dictionary lookup generate large opensource data set ad hoc abbreviation data used study abbreviation strategy develop two strong baseline abbreviation expansion
scaling size language model usually lead remarkable advancement nlp task often come price growing computational cost although sparse mixture expert moe reduce cost activating small subset parameter eg one expert input computation escalates significantly increasing number activated expert limiting practical utility retain advantage adding expert without substantially increasing computational cost paper first demonstrate superiority selecting multiple expert propose computationefficient approach called textbfmerging expert one meo reduces computation cost single expert extensive experiment show meo significantly improves computational efficiency eg flop drop g vanilla moe g meo moreover propose tokenlevel attention block enhances efficiency performance tokenlevel meo eg meo v vanilla moe average score glue benchmark code released upon acceptance code released urlhttpsgithubcomshwaihemeo
study propose multigranularity ordinal classification method address problem emphasis selection detail word embedding learned embeddings language model elmo extract feature vector representation ordinal classification implemented four different multigranularities approximate continuous emphasize value comparative experiment conducted compare model baseline problem transformed label distribution problem
strength scalable gradient tree boosting algorithm xgboost distributed sentence encoder skipthought vector explored yet cqa research community tried apply combine two effective method finding factual nature question answer work also include experimentation popular classifier model like adaboost classifier decisiontree classifier randomforest classifier extratrees classifier xgboost classifier multilayer neural network paper present feature used approach followed feature engineering model experimented finally result
docred widely used dataset documentlevel relation extraction largescale annotation recommendrevise scheme adopted reduce workload within scheme annotator provided candidate relation instance distant supervision manually supplement remove relational fact based recommendation however comparing docred subset relabeled scratch find scheme result considerable amount false negative sample obvious bias towards popular entity relation furthermore observe model trained docred low recall relabeled dataset inherit bias training data analysis annotator behavior figure underlying reason problem scheme actually discourages annotator supplementing adequate instance revision phase appeal future research take consideration issue recommendrevise scheme designing new model annotation scheme relabeled dataset released urlhttpsgithubcomandrewzherevisitdocred serve reliable test set document model
paper report three business opportunity encountered spoken translation inc developer software system automatic spoken translation healthcare organization needing improved communication limitedenglish patient caregiver networking communication firm aiming add unstyle simultaneous interpreting telepresence facility retail arm device manufacturer hoping enable effective instore consulting customer imperfect command outlet native language none opening yet led substantial business one remains negotiation describe business introduction came u proposed use case demonstration presentation test etc issueschallenges also comment early consumeroriented product spoken language translation aim provide snapshot one company business possibility challenge dawn era automatic interpreting
paper describe goal estonian corpus collection analysis activity introduce recent collection estonian first encounter data mint project aim deepening understanding conversational property practice human interaction especially investigate conversational engagement cooperation discus observation participant view concerning interaction engaged
paper describes approach unibuc team tackling semeval task safe biomedical natural language inference clinical trial used solar instruct without finetuning focusing input manipulation tailored prompting customizing prompt individual ctr section zeroshot fewshots setting managed achieve consistency score ranking th leaderboard thorough error analysis revealed model tendency take shortcut rely simple heuristic especially dealing semanticpreserving change
recent work proposed methodology systematic evaluation situated language understanding agent agent operate rich linguistic nonlinguistic context testing carefully constructed interactive setting recent work argued large language model llm suitably set understood simulator agent connection suggests paper explores llm evaluated meaningfully exposing constrained gamelike setting built challenge specific capability proof concept paper investigates five interaction setting showing current chatoptimised llm extent capable following gameplay instruction capability quality game play measured well objective different game met follows development cycle newer model generally performing better metric even comparatively simple example game far saturated suggesting proposed instrument remain diagnostic value
recently pretrained language model plms achieved great success various nlp task shown trend exponential growth model size alleviate unaffordable computational cost brought size growth model compression widely explored existing effort achieved promising result compressing mediumsized model specific task taskagnostic compression big model billion parameter rarely studied taskagnostic compression provide efficient versatile big model prompting delta tuning leading general impact taskspecific compression hence introduce taskagnostic compression toolkit bmcook big model bmcook implement four representative compression method including quantization pruning distillation moefication developer easily combine method towards better efficiency evaluate bmcook apply compress tb plm billion parameter achieve nearly x efficiency improvement maintaining original tb performance three typical nlp benchmark moreover final compressed model also significantly outperforms tbase plm million parameter similar computational cost bmcook publicly available urlhttpsgithubcomopenbmbbmcook
paper describes evaluation methodology followed measure impact using machine learning algorithm automatically segment intralingual subtitle segmentation quality productivity selfreported postediting effort achieved approach shown improve obtained technique based counting character mainly employed automatic subtitle segmentation currently corpus used train test proposed automated segmentation method also described shared community order foster research area
paper describe th koln submission shared task identification toxic comment germeval toxicity severe latent problem comment online discussion complex language model based method shown success identifying toxicity however approach lack explainability might insensitive domainspecific rendition toxicity scope germeval toxic comment classification task risch et al employed simple promising combination termfrequencybased classification rulebased labeling produce effective lesser degree explainable toxicity prediction
paper introduces ongoing project development parallel treebank italian english french ie paralleltut simply partut development resource dependency constituencybased format italian turin university treebank tut applied preliminary dataset includes whole text universal declaration human right sentence jrcacquis multilingual parallel corpus creative common licence focus project mainly quality annotation investigation issue related alignment data allowed tut format also taking account availability conversion tool display data standard way tigerxml conll format fact belief increasing portability treebank could give u opportunity access resource tool provided research group especially stage project particular tool compatible tut format available order tackle alignment problem
metalearning considers problem learning efficient learning process leverage past experience accurately solve new task however efficacy metalearning crucially depends distribution task available training often assumed known priori constructed limited supervised datasets work aim provide task distribution metalearning considering selfsupervised task automatically proposed unlabeled text enable largescale metalearning nlp design multiple distribution selfsupervised task considering important aspect task diversity difficulty type domain curriculum investigate affect metalearning performance analysis show factor meaningfully alter task distribution inducing significant improvement downstream fewshot accuracy metalearned model empirically result downstream task show significant improvement fewshot learning adding absolute accuracy average previous unsupervised metalearning method perform comparably supervised method fewrel benchmark
paper describes submission social medium mining health application smmh shared task team mattica participated detecting stance premise tweet health mandate related covid task approach based using indomain pretrained language model finetuned combining different strategy leveraging additional stance detection dataset twostage finetuning jointlearning stance premise detection objective ensembling sentimentpolarity given offtheshelf finetuned model
paper discusses classificationbased approach machine translation evaluation opposed common regressionbased approach wmt metric task recent machine translation usually work well sometimes make critical error due wrong word choice classificationbased approach focus error using several error type label practical machine translation evaluation age neural machine translation made additional annotation wmt metric datasets fluency adequacy label distinguish different type translation error syntactic semantic viewpoint present human evaluation criterion corpus development automatic evaluation experiment using corpus human evaluation corpus publicly available upon publication
text style transfer task requires model transfer sentence one style another style retaining original content meaning challenging problem long suffered shortage parallel data paper first propose semisupervised text style transfer model combine smallscale parallel data largescale nonparallel data two type training data introduce projection function latent space different style design two constraint train also introduce two simple effective semisupervised method compare evaluate performance proposed method build release novel style transfer dataset alters sentence style ancient chinese poem modern chinese
present tool text characterization toolkit tct researcher use study characteristic large datasets furthermore property lead understanding influence attribute model behaviour traditionally nlp research model usually evaluated reporting singlenumber performance score number readily available benchmark without much deeper analysis argue especially given wellknown fact benchmark often contain bias artefact spurious correlation deeper result analysis become defacto standard presenting new model benchmark tct aim filling gap facilitating deeper analysis datasets scale datasets trainingdevelopmentevaluation tct includes easytouse tool well offtheshelf script used specific analysis also present usecases several different domain tct used predict difficult example given wellknown trained model tct also used identify potentially harmful bias present dataset
aim teach automatic speechtotext translation system human interpreting strategy first step identify interpreting strategy often used language pair interest englisharabic article run automatic analysis corpus parallel speech human interpretation provide result manually annotating human interpreting strategy sample corpus give glimpse corpus whose value surpasses fact contains high number scientific speech interpretation english arabic also provides rich information interpreter also discus difficulty encountered way well solution methodology manual resegmentation alignment parallel segment choice annotation tool annotation procedure annotation finding explain previously extracted specific statistical feature interpreted corpus compared translation one well quality interpretation provided different interpreter
human conversation naturally evolve around related concept hop distant concept paper present new conversation generation model conceptflow leverage commonsense knowledge graph explicitly model conversation flow grounding conversation concept space conceptflow represents potential conversation flow traverse concept space along commonsense relation traverse guided graph attention concept graph moving towards meaningful direction concept space order generate semantic informative response experiment reddit conversation demonstrate conceptflows effectiveness previous knowledgeaware conversation model gpt based model using fewer parameter confirming advantage explicit modeling conversation structure source code work available urlhttpsgithubcomthunlpconceptflow
system description paper detail team ufals approach summscreen tvmegasite subtask creativesumm shared task subtask deal creating summary dialogue tv soap opera utilized bart based pretrained model finetuned samsum dialouge summarization dataset example automin dataset dataset provided organizer also inserted data fewshot learning objective additional data manually broken chunk based different boundary summary dialogue file inference choose similar strategy topperforming team automin data split chunk either scenechange exceeding predefined token length accommodate maximum token possible pretrained model one example final training strategy chosen based natural response looked instead well model performed automated evaluation metric rogue
paper present frame dataset multimodal dataset built corpus brazilian travel tv show annotated framenet category text image communicative mode frame comprises minute video correlated sentence either transcribing audio spoken episode subtitling segment show host conduct interview english first release dataset total annotation set sentence video included former includes target lexical unit evoking frame one frame element video annotation bounding box image correlated frame frame element lexical unit evoking frame framenet
service account including organization official account miniprograms provide various convenient service user become crucial component number application therefore retrieving service account quickly accurately vital however task suffers problem limited human annotation ie manually assessing account functionality assigning rating based user experience laborintensive timeconsuming end paper proposes novel approach auxiliary task boosted multitask learning method auxboostmtl specifically proposed method introduces multiple auxiliary task able utilized log data application supervision enhance performance main task service account retrieval furthermore introduce adaptive hierarchical fusion module ahf module approach module designed adaptively perform hierarchical fusion embeddings auxiliary task main task thereby enhancing model efficacy experiment two realworld industrial datasets demonstrate effectiveness proposed approach
neural module network originally proposed task visual question answering class neural network architecture involve humanspecified neural module designed specific form reasoning current formulation network parameter neural module andor order execution learned work expand approach also learn underlying internal structure module term ordering combination simple elementary arithmetic operator utilize minimum amount prior knowledge humanspecified neural module form different input type arithmetic operator used module result show one indeed able simultaneously learn internal module structure module sequencing without extra supervisory signal module execution sequencing approach report performance comparable model using handdesigned module addition analysis sensitivity learned module wrt arithmetic operation infer analytical expression learned module
large multilingual language model generally demonstrate impressive result zeroshot crosslingual transfer yet often fail successfully transfer lowresource language even tokenlevel prediction task like named entity recognition ner work introduce simple yet highly effective approach improving zeroshot transfer ner lowresource language observe ner finetuning source language decontextualizes token representation ie token increasingly attend increased reliance token information hypothesize trigger type overfitting property ne token within source language share generally present ne mention target language remedy propose simple yet effective sliced finetuning ner slicer force stronger token contextualization transformer divide transformed token representation classifier disjoint slice independently classified training evaluate slicer two standard benchmark ner involve lowresource language wikiann masakhaner show indeed reduces decontextualization ie extent ne token attend consequently ii yielding consistent transfer gain especially prominent lowresource target language distant source language
describe work carried amex ailabs extractive summarization benchmark task focused financial narrative summarization fns task focus summarizing annual financial report pose two main challenge compared typical news document summarization task annual report lengthier average length page compared typical news document ii annual report loosely structured eg comprising table chart textual data image make challenging effectively summarize address summarization task investigate range unsupervised supervised ensemble based technique find ensemble based technique perform relatively better compared using unsupervised supervised based technique ensemble based model achieved highest rank system submitted benchmark task based rougel evaluation metric
critical toponymy examines dynamic power capital resistance place name site refer study traditionally focused semantic content toponym topdown institutional process produce however generally ignored way toponym used ordinary people everyday discourse well strategy geospatial description accompany contextualize toponymic reference develop computational method measure cultural economic capital shape way people refer place novel annotated dataset new york city airbnb listing building dataset introduce new named entity recognition ner model able identify important discourse category integral characterization place finding point toward new direction critical toponymy range previously understudied linguistic signal relevant research neighborhood status housing tourism market gentrification
lexicon relation extraction given distributional representation word important topic nlp observe stateoftheart projectionbased method generalized handle unseen hypernym propose analyze perspective pollution construct corresponding indicator measure propose word relation autoencoder wrae model address challenge experiment several hypernymlike lexicon datasets show model outperforms competitor significantly
present pandagpt approach empower large language model visual auditory instructionfollowing capability pilot experiment show pandagpt perform complex task detailed image description generation writing story inspired video answering question audio interestingly pandagpt take multimodal input simultaneously compose semantics naturally example pandagpt connect object look imagevideo sound audio pandagpt combine multimodal encoders imagebind large language model vicuna notably aligned imagetext pair required training pandagpt thanks strong capability imagebind embedding data different modality space pandagpt display emergent ie zeroshot crossmodal behavior data image text eg video audio depth thermal imu hope pandagpt serf initial step toward building agi perceive understand input different modality holistically human
human communication collaborative process speaker top conveying intent adjust content language expression taking listener account including knowledge background personality physical capability towards building ai agent similar ability language communication propose novel rational reasoning framework pragmatic rational speaker pr speaker attempt learn speakerlistener disparity adjust speech accordingly adding lightweighted disparity adjustment layer working memory top speaker longterm memory system fixing longterm memory pr need update working memory learn adapt different type listener validate framework create dataset simulates different type speakerlistener disparity context referential game empirical result demonstrate pr able shift output towards language listener able understand significantly improve collaborative task outcome learn disparity efficiently joint training
artificial intelligence aiaided disease prediction gained extensive research interest due capability support clinical decisionmaking existing work mainly formulate disease prediction multilabel classification problem use historical electronic medical record emr train supervised model however realworld clinic purely datadriven approach pose two main challenge long tail problem excessive emrs common disease insufficient emrs rare disease thus training imbalanced data set could result biased model ignores rare disease diagnosis easily misdiagnosed disease disease easily distinguished others sharing analogous condition much difficult general classification model without emphasizing easily misdiagnosed disease may generate incorrect prediction tackle two problem propose medical knowledgeenhanced contrastive learning textbfmkecl approach disease diagnosis paper mkecl incorporates medical knowledge graph medical licensing exam modeling order compensate insufficient information rare disease handle hardtodiagnose disease mkecl introduces contrastive learning strategy separate disease easily misdiagnosed moreover establish new benchmark named textbfjarvisd contains clinical emrs collected various hospital experiment real clinical emrs show proposed mkecl outperforms existing disease prediction approach especially setting fewshot zeroshot scenario
rich variety data set sentiment analysis viz polarity subjectivity classification challenging task detecting discrete emotion following definition ekman plutchik however much fewer data set notably resource social medium domain paper contributes closing gap extending textitsemeval stance sentiment datasetwith emotion annotation analyse annotation reliability annotation merging b investigate relation emotion annotation annotation layer stance sentiment c report modelling result baseline future work
language may differently distant mutual intelligibility may asymmetric paper introduce incompy toolbox calculating linguistic distance asymmetry related language incompy allows linguist expert quickly easily perform statistical analysis compare experimental result demonstrate efficacy incompy incomprehension experiment two slavic language bulgarian russian using incompy able validate three method measure linguistic distance asymmetry levenshtein distance word adaptation surprisal conditional entropy predictor success reading intercomprehension experiment
rise online communication platform accompanied undesirable effect proliferation aggressive abusive behaviour online aiming tackle problem natural language processing nlp community experimented range technique abuse detection achieving substantial success method far focused modelling linguistic property comment online community user disregarding emotional state user might affect language latter however inextricably linked abusive behaviour paper present first joint model emotion abusive language detection experimenting multitask learning framework allows one task inform result demonstrate incorporating affective feature lead significant improvement abuse detection performance across datasets
recent research revealed machine learning model tendency leverage spurious correlation exist training set may hold true general circumstance instance sentiment classifier may erroneously learn token performance commonly associated positive movie reviewsrelying spurious correlation degrades classifier performance deploys outofdistribution datain paper examine implication spurious correlation novel perspective called neighborhood analysis analysis uncovers spurious correlation lead unrelated word erroneously cluster together embedding space driven analysis design metric detect spurious token also propose family regularization method nfl dont forget language mitigate spurious correlation text classificationexperiments show nfl effectively prevent erroneous cluster significantly improve robustness classifier without auxiliary data code publicly available httpsgithubcomoscarchewdontforgetyourlanguage
conversational question answering cqa system meet user information need conversation answer question retrieved text exist variety datasets english ten thousand training example pretrained language model allowed obtain impressive result goal research test performance cqa system lowresource condition common nonenglish language small amount native annotation limitation linked low resource language like lack crowdworkers smaller wikipedias focus basque language present first nonenglish cqa dataset result experiment show possible obtain good result low amount native data thanks crosslingual transfer quality comparable obtained english also discovered dialogue history model directly transferable another language calling research dataset publicly available
paper present method digitising large collection handwritten irishlanguage text part project mine information large corpus irish scottish gaelic folktale handwritten text form part main manuscript collection national folklore collection ireland contain handwritten transcription oral folklore collected ireland th century goal creating large text corpus irishlanguage folktale contained within collection method involves scanning page physical volume digitising text page using transkribus platform recognition historical document given nature collection approach taken involves creation individual text recognition model multiple collector hand way motivated fact relatively small number collector contributed bulk material difference collector term style layout orthography difficult reconcile within single handwriting model present preliminary result along discussion viability using crowdsourced correction improve htr model
latest batch research equipped language model ability attend relevant factual information nonparametric external source drawing complementary path architectural scaling besides mastering language exploiting contextualizing latent world knowledge crucial complex domain like biomedicine however work field rely generalpurpose model supported database like wikipedia book introduce bioreader first retrievalenhanced texttotext model biomedical natural language processing domainspecific tbased solution augments input prompt fetching assembling relevant scientific literature chunk neural database mboxapprox million token centered pubmed finetune evaluate bioreader broad array downstream task significantly outperforming several stateoftheart method despite using x fewer parameter tandem extensive ablation study show domain knowledge easily altered supplemented make model generate correct prediction bypassing retraining step thus addressing literature overload issue
despite recent advancement attentionbased deep learning architecture across majority natural language processing task application remains limited lowresource setting lack pretrained model language study make first attempt investigate challenge adapting technique extremely lowresource language sumerian cuneiform one world oldest written language attested least beginning rd millennium bc specifically introduce first crosslingual information extraction pipeline sumerian includes partofspeech tagging named entity recognition machine translation introduce interpretlr interpretability toolkit lowresource nlp use alongside human evaluation gauge trained model notably technique component pipeline generalised lowresource language publicly release implementation including novel data set domainspecific preprocessing promote research domain
recent advance computational stylometry enabled scholar detect authorial signal high degree precision focus accuracy come expense explainability powerful blackbox model often little use traditional humanistic discipline mind conducted stylometric experiment maospeak language style shaped writing speech mao zedong measure pertoken perplexity across different gpt model compute kullbackleibler divergence local global vocabulary distribution train tfidf classifier examine modern chinese language transformed convey tenet maoist doctrine offer computational interpretation ideology reduction perplexity increase systematicity language use
introductory tutorial address advance deep bayesian learning natural language ubiquitous application ranging speech recognition document summarization text classification text segmentation information extraction image caption generation sentence generation dialogue control sentiment classification recommendation system question answering machine translation name traditionally deep learning taken learning process inference optimization based realvalued deterministic model semantic structure word sentence entity action document drawn large vocabulary may well expressed correctly optimized mathematical logic computer program distribution function discrete continuous latent variable model natural language may properly decomposed estimated tutorial address fundamental statistical model neural network focus series advanced bayesian model deep model including hierarchical dirichlet process chinese restaurant process hierarchical pitmanyor process indian buffet process recurrent neural network long shortterm memory sequencetosequence model variational autoencoder generative adversarial network attention mechanism memoryaugmented neural network skip neural network stochastic neural network predictive state neural network policy neural network present model connected work variety application symbolic complex pattern natural language variational inference sampling method formulated tackle optimization complicated model word sentence embeddings clustering coclustering merged linguistic semantic constraint series case study domain application presented tackle different issue deep bayesian processing learning understanding last point number direction outlook future study
previous work approach sqltotext generation task using vanilla seqseq model may fully capture inherent graphstructured information sql query paper propose graphtosequence model encode global structure information node embeddings model effectively learn correlation sql query pattern interpretation experimental result wikisql dataset stackoverflow dataset show model outperforms seqseq treeseq baseline achieving stateoftheart performance
language shaped relationship speakerwriter audience object discussion talk turn language used reshape relationship course interaction computational researcher succeeded operationalizing sentiment formality politeness construct capture aspect social relational meaning theory interactional stancetaking put forward holistic account theory applied detailed qualitative analysis portion individual conversation article propose new computational operationalization interpersonal stancetaking begin annotation three linked stance dimensionsaffect investment alignmenton conversation thread online platform reddit using annotation investigate thread structure linguistic property stancetaking online conversation identify lexical feature characterize extreme along stancetaking dimension show stancetaking property predicted moderate accuracy bagofwords feature even relatively small labeled training set quantitative analysis supplemented extensive qualitative analysis highlighting compatibility computational qualitative method synthesizing evidence creation interactional meaning
lifelogging gained attention due wide application personalized recommendation memory assistance issue collecting extracting personal life event emerged people often share life experience others conversation however extracting life event conversation rarely explored paper present life event dialog dataset containing finegrained life event annotation conversational data addition initiate novel conversational life event extraction task differentiate task public event extraction life event extraction source like microblogs explore three information extraction ie framework address conversational life event extraction task openie relation extraction event extraction comprehensive empirical analysis three baseline established result suggest current event extraction model still struggle extracting life event human daily conversation proposed life event dialog dataset indepth analysis ie framework facilitate future research life event extraction conversation
paper describes system submitted team ufrgsent semeval task structured sentiment analysis propose multilingual approach relies question answering model find tuples consisting aspect opinion holder approach start general question us extracted tuple element find remaining component finally employ aspect sentiment classification model classify polarity entire tuple despite method midrank position semeval competition show questionanswering approach achieve good coverage retrieving sentiment tuples allowing room improvement technique
paper describes fudans submission conll shared task universal dependency parsing jointly train model two language similar according linguistic typology ensemble model using simple reparse algorithm outperform baseline method average development test set conll ud shared task
psychological plausibility word embeddings studied different task word similarity semantic priming lexical entailment recent work predicting category structure word embeddings report low correlation human rating heyman heyman showed static word embeddings fail predicting typicality using cosine similarity category exemplar word misra et al obtain equally modest result various contextual language model clms using cloze task formulation handcrafted taxonomic sentence work test wider array method probing clms predicting typicality score experiment using bert devlin et al show importance using right type clm probe best bertbased typicality prediction method improve previous work second result highlight importance polysemy task best result obtained contextualization paired disambiguation mechanism chronis erk finally additional experiment analysis reveal information contentbased wordnet miller similarity disambiguation match performance best bertbased method fact capture complementary information combined bert allow enhanced typicality prediction
paper performs detailed analysis alignment portuguese contraction based previously aligned bilingual corpus alignment task performed manually subset englishportuguese cluetranslation alignment collection initial parallel corpus preprocessed decision made whether contraction maintained decomposed alignment decomposition required case two word concatenated ie preposition determiner pronoun go two separate translation alignment pair eg seio de uniao europeia within european union contraction required decomposition context positioned end multiword unit hand contraction tend maintained occur beginning middle multiword unit ie frozen part multiword eg que diz respeito regard alem disso addition correct alignment multiwords phrasal unit containing contraction instrumental machine translation paraphrasing variety adaptation
usage social medium platform resulted proliferation work arabic natural language processing anlp including development resource also increased interest processing arabic dialect number model algorithm utilised purpose dialectal arabic natural language processing danlp paper conduct comparison study wellknown commonly used method nlp order test performance different corpus two nlp task dialect identification sentiment analysis particular compare three general class model traditional machine learning model feature b classic deep learning architecture lstms pretrained word embeddings lastly c different bidirectional encoder representation transformer bert model multilingualbert arabert twitterarabicbert result comparison show using featurebased classification still compete bert model dialectal arabic context use transformer model ability outperform traditional machine learning approach depending type text trained contrast classic deep learning model like lstms perform well task
multiturn response selection model recently shown comparable performance human several benchmark datasets however real environment model often weakness making incorrect prediction based heavily superficial pattern without comprehensive understanding context example model often give high score wrong response candidate containing several keywords related context using inconsistent tense study analyze weakness opendomain korean multiturn response selection model publish adversarial dataset evaluate weakness also suggest strategy build robust model adversarial environment
named entity recognition ner essential various natural language processing nlp application traditional ner model effective limited set predefined entity type contrast large language model llm extract arbitrary entity natural language instruction offering greater flexibility however size cost particularly accessed via apis like chatgpt make impractical resourcelimited scenario paper introduce compact ner model trained identify type entity leveraging bidirectional transformer encoder model gliner facilitates parallel entity extraction advantage slow sequential token generation llm comprehensive testing gliner demonstrate strong performance outperforming chatgpt finetuned llm zeroshot evaluation various ner benchmark
traditional approach task ace event extraction usually depend manually annotated data often laborious create limited size therefore addition difficulty event extraction insufficient training data hinders learning process well promote event extraction first propose event extraction model overcome role overlap problem separating argument prediction term role moreover address problem insufficient training data propose method automatically generate labeled data editing prototype screen generated sample ranking quality experiment ace dataset demonstrate extraction model surpass existing extraction method besides incorporating generation method exhibit significant improvement obtains new stateoftheart result event extraction task including pushing f score trigger classification f score argument classification
paper describes czengclass bilingual lexical resource built investigate verbal synonymy bilingual context relate semantic role common one synonym class verb argument verb valency addition resource linked existing resource similar aim english czech wordnet framenet propbank verbnet semlink valency lexicon czech english pdtvallex vallex engvallex several goal work resource provide gold standard data automatic experiment future automatic discovery synonym class word sense disambiguation assignment class occurrence verb text coreferential linking verb event argument text etc b build core bilingual lexicon linked existing resource comparative study possibly training automatic tool c enrich annotation parallel treebank prague czech english dependency treebank far contained valency annotation linked synonymous sens verb together method used extracting synonym class semiautomatic process substantial amount manual work filtering role assignment class individual class member argument linking external lexical resource present first version class verb evaluate interannotator agreement using several metric
kannada one major spoken classical language india morphologically rich highly agglutinative nature one important grammatical aspect concept sandhieuphonic change sandhi generator kannada work aim basic sandhi generation paper present algorithm lopa adesha sandhi using rulebased approach proposed method generates sandhied word corresponding sandhi without help dictionary work significant agglutinative language especially dravidian language used enhance vocabulary language related task
submission wmt general mt task consists translation produced series nmt model following two language pair germantoenglish germantofrench model trained using parallel training data specified wmt monolingual training data used model follow transformer architecture employing attention head layer encoder decoder also worth mentioning order limit computational resource would use training process decided train majority model limiting training epoch moreover translation submitted wmt produced using test data released wmtthe aim experiment evaluate method cleaningup parallel corpus determine lead translation model producing accurate translation language pair base nmt model trained raw parallel training corpus additional nmt model trained corpus subjected special cleaning process following tool bifixer bicleaner mentioned bicleaner repository doesnt provide pretrained classifier language pair consequently trained probabilistic dictionary order produce new model fundamental difference nmt model produced mainly related quality quantity training data difference training parameter complete work used following three software package marian nmt version v used training neural machine translation model ii bifixer iii bicleaner used order correct clean parallel training data concerning bifixer bicleaner tool followed step described meticulously following article ramirezsanchez g zaragozabernabeu j banon rojas bifixer bicleaner two opensource tool clean parallel data eamt also official github page urlhttpsgithubcombitextorbifixer urlhttpsgithubcombitextorbicleaner
work develop simulspeech endtoend simultaneous speech text translation system translates speech source language text target language concurrently simulspeech consists speech encoder speech segmenter text decoder segmenter build upon encoder leverage connectionist temporal classification ctc loss split input streaming speech real time encoderdecoder attention adopts waitk strategy simultaneous translation simulspeech challenging previous cascaded system simultaneous automatic speech recognition asr simultaneous neural machine translation nmt introduce two novel knowledge distillation method ensure performance attentionlevel knowledge distillation transfer knowledge multiplication attention matrix simultaneous nmt asr model help training attention mechanism simulspeech datalevel knowledge distillation transfer knowledge fullsentence nmt model also reduces complexity data distribution help optimization simulspeech experiment mustc englishspanish englishgerman spoken language translation datasets show simulspeech achieves reasonable bleu score lower delay compared fullsentence endtoend speech text translation without simultaneous translation better performance twostage cascaded simultaneous translation model term bleu score translation delay
paper present music retrieval recommendation system using machine learning technique propose query humming system music retrieval us deep neural network note transcription notebased retrieval system retrieving correct song database evaluate query humming system using standard mirex qbsh dataset also propose similar artist recommendation system recommends similar artist based acoustic feature artist music online text description artist social medium data use supervised machine learning technique feature compare recommendation result produced popular similar artist recommendation website
describe method automatically generating lexical transfer rule ltrs word equivalence using transfer rule template template skeletal ltrs unspecified word new ltrs created instantiating template word provided word belong appropriate lexical category required template define two method creating inventory template using generate new ltrs simpler method consists extracting finite set template sample hand coded ltrs directly using generation process method consists abstracting initial finite set template define higher level template bilingual equivalence defined term correspondence involving phrasal category phrasal template mapped onto set lexical template aid grammar way infinite set lexical template recursively defined new ltrs created parsing input word matching template phrasal level using corresponding lexical category instantiate lexical template definition infinite set template enables automatic creation ltrs multiword noncompositional word equivalence cardinality
semantic parsing using sequencetosequence model allows parsing deeper representation compared traditional word tagging based model spite advantage widespread adoption model realtime conversational use case stymied higher compute requirement thus higher latency work propose nonautoregressive approach predict semantic parse tree efficient seqseq model architecture combining nonautoregressive prediction convolutional neural network achieve significant latency gain parameter size reduction compared traditional rnn model novel architecture achieves reduction latency top dataset retains competitive performance nonpretrained model three different semantic parsing datasets
many different way external information might used nlp task paper investigates external syntactic information used effectively semantic role labeling srl task evaluate three different way encoding syntactic parses three different way injecting stateoftheart neural elmobased srl sequence labelling model show using constituency representation input feature improves performance achieving new stateoftheart nonensemble srl model indomain conll conll benchmark
item categorization ic aim classify product description leaf node categorical taxonomy key technology used wide range application along fact datasets often longtailed distribution classification performance tail label tend poor due scarce supervision causing many issue reallife application address ic task longtail issue kpositive contrastive loss kcl proposed image classification task applied ic task using textbased contrastive learning eg simcse however one shortcoming using kcl neglected previous research false negative fn instance may harm kcls representation learning address fn issue kcl proposed reweight positive pair kcl loss regularization sum weight constrained k close possible controlling fn instance proposed method ic performance improved superior ltaddressing method
intent detection slot filling two critical task spoken natural language understandingfor taskoriented dialog system work describe participation slot intent detection lowresource language variety sidlr aepli et al investigate slot intent detection sid task using wide range model setting given recent success multitask promptedfinetuning large language model also test generalization capability recent encoderdecoder model mt muennighoff et al new task ie sid language never intentionally seen show best model outperforms baseline large margin f point sid task
multiword adverbial nbyn numbynum english brick brick one one respectively event modifier require temporal sequencing event modify linearly ordered series subevents previous study unified two construction single semantic analysis adopted either mereological scalar approach however based corpus study examining new slavic language material binomial logistic regression modelling manually annotated data argue two separate analysis needed account construction namely scalar analysis nbyn construction mereological one numbynum construction
contextual embedding model bert easily finetuned labeled sample create stateoftheart model many downstream task however finetuned bert model suffers considerably unlabeled data applied different domain unsupervised domain adaptation aim train model work well target domain provided labeled source sample unlabeled target sample paper propose pseudolabel guided method unsupervised domain adaptation two model finetuned labeled source sample pseudo labeling model learn representation target domain one model adapted masked language modeling target domain model used assign pseudolabels target sample train final model sample evaluate method named entity segmentation sentiment analysis task experiment show approach outperforms baseline method
pretrained language model adopt oncloud deployment privacy issue grow quickly mainly exposure plaintext user data eg search history medical record bank account privacypreserving inference transformer model demand cloud service user protect privacy attractive choice compute ciphertext homomorphic encryption however enabling pretrained model inference ciphertext data difficult due complex computation transformer block supported current tool yet work introduce thex approximation approach transformer enables privacypreserving inference pretrained model developed popular framework thex proposes workflow deal complex computation transformer network including nonpolynomial function like gelu softmax layernorm experiment reveal proposed thex enable transformer inference encrypted data different downstream task negligible performance drop enjoying theoryguaranteed privacypreserving advantage
vast amount speech data collected language documentation research remain untranscribed unsearchable often small amount speech may text translation available present method partially labeling additional speech translation scenario modify unsupervised speechtotranslation alignment model obtain prototype speech segment match translation word turn used discover term unlabelled data evaluate method spanishenglish speech translation corpus two corpus endangered language arapaho ainu demonstrating appropriateness applicability actual verylowresource scenario
explore domainagnostic approach analyzing speech goal opinion prediction represent speech signal melfrequency cepstral coefficient apply long shortterm memory neural network automatically learn temporal regularity speech contrast previous work approach require complex feature engineering work without textual transcript consequence easily applied various speech analysis task different language result show nevertheless competitive stateoftheart opinion prediction detailed error analysis opinion mining find approach performs well identifying speakerspecific characteristic combined additional information subtle difference linguistic content need identified
generating abstract collection document desirable capability many realworld application however abstractive approach multidocument summarization thoroughly investigated paper study feasibility using abstract meaning representation amr semantic representation natural language grounded linguistic theory form content representation approach condenses source document set summary graph following amr formalism summary graph transformed set summary sentence surface realization step framework fully datadriven flexible component optimized independently using smallscale indomain training data perform experiment benchmark summarization datasets report promising result also describe opportunity challenge advancing line research
consider novel question answering qa task machine need read large streaming data long document video without knowing question given difficult solve existing qa method due lack scalability tackle problem propose novel endtoend deep network model reading comprehension refer episodic memory reader emr sequentially read input context external memory replacing memory less important answering unseen question specifically train rl agent replace memory entry memory full order maximize qa accuracy future timepoint encoding external memory using either gru transformer architecture learn representation considers relative importance memory entry validate model synthetic dataset babi well realworld largescale textual qa triviaqa video qa tvqa datasets achieves significant improvement rule based memory scheduling policy rl based baseline independently learns queryspecific importance memory
paper describes system submitted semeval statement verification evidence finding table task system relies candidate generation logical form table based keyword matching dependency parsing claim statement
present endtoend neural approach generate english sentence formal meaning representation discourse representation structure drss use rather standard bilstm sequencetosequence model work linearized drs input representation evaluate characterlevel wordlevel decoder obtain encouraging result term referencebased automatic metric bleu metric evaluate surface level generated output develop new metric rose target specific semantic phenomenon five drs generation challenge set focusing tense grammatical number polarity named entity quantity aim challenge set assess neural generator systematicity generalization unseen input
german ja used discourse particle indicate proposition according speaker believed speaker audience use observation create kojak distantlylabeled english dataset derived europarl studying speaker belief statement common ground corpus analyzed identify lexical choice english correspond german ja finally perform experiment dataset predict english clause corresponds german clause containing ja achieve fmeasure balanced test corpus
machine translation performs automatic translation one natural language another neural machine translation attains stateoftheart approach machine translation requires adequate training data severe problem lowresource language pair translation concept multimodal introduced neural machine translation nmt merging textual feature visual feature improve lowresource pair translation wat workshop asian translation organizes shared task multimodal translation english hindi participated team name cnlpnitspp two submission multimodal textonly nmt work investigates phrase pair injection via data augmentation approach attains improvement previous work wat task textonly multimodal nmt achieved second rank challenge test set english hindi multimodal translation bilingual evaluation understudy bleu score rankbased intuitive bilingual evaluation score ribes adequacyfluency metric amfm score respectively
knowledge data massive widespread realworld serve good external source enrich conversation however knowledgegrounded conversation current model still lack finegrained control knowledge selection integration dialogue finally lead knowledgeirrelevant response generation problem knowledge selection merely relies dialogue context ignoring inherent knowledge transition along conversation flow model often overfit training resulting incoherent response referring unrelated token specific knowledge content testing phase although response generated upon dialogue history knowledge model often tend overlook selected knowledge hence generates knowledgeirrelevant response address problem proposed explicitly model knowledge transition sequential multiturn conversation abstracting knowledge topic tag besides fully utilizing selected knowledge generative process propose pretraining knowledgeaware response generator pay attention selected knowledge particular sequential knowledge transition model equipped pretrained knowledgeaware response generator sktkg formulates highlevel knowledge transition fully utilizes limited knowledge data experimental result structured unstructured knowledgegrounded dialogue benchmark indicate model achieves better performance baseline model
investigate ability transformer model approximate cky algorithm using directly predict sentence parse thus avoid cky algorithm cubic dependence sentence length find standard constituency parsing benchmark approach achieves competitive better performance comparable parser make use cky faster also evaluate viability approach parsing textitrandom pcfgs find performance decline grammar becomes ambiguous suggesting transformer fully capturing cky computation however also find incorporating additional inductive bias helpful propose novel approach make use gradient respect chart representation predicting parse analogy cky algorithm subgradient partition function variant respect chart
two main consideration design procedure economical recognition representation multiple reading syntactically ambiguous sentence general applicability language english russian chinese following feature discussed type structural description form linguistic rule use linguistic heuristic achieve economical multiple analysis application linguistic research application production mt system also relation procedure existing sentence analysis procedure discussed
opendomain question answering remains challenging task requires model capable understanding question answer collecting useful information reasoning evidence previous work typically formulates task reading comprehension entailment problem given evidence retrieved search engine however existing technique struggle retrieve indirectly related evidence directly related evidence provided especially complex question hard parse precisely question asks paper propose retrieverreader model learns attend essential term question answering process build essential term selector first identifies important word question reformulates query search related evidence enhanced reader distinguishes essential term distracting word predict answer evaluate model multiple opendomain qa datasets notably achieving level stateoftheart ai reasoning challenge arc dataset
braincomputer interface augmentative alternative communication device introduce languagemodeing challenge distinct characterentry method particular acquired signal eeg electroencephalogram signal noisier turn make user intent harder decipher order adapt condition propose maintain ambiguous history every time step employ apart character language model word information produce robust prediction system present preliminary result compare proposed onlinecontext language model oclm current algorithm used type setting evaluation perplexity predictive accuracy demonstrates promising result dealing ambiguous history order provide front end distribution next character user might type
abbreviation acronym part textual communication domain however abbreviation necessarily defined document employ understanding abbreviation used given document often requires extensive knowledge target domain ability disambiguate based context creates considerable entry barrier newcomer difficulty automated document processing existing abbreviation expansion system tool require substantial technical knowledge set make strong assumption limit use practice present abbreviation expander system build state art method identification abbreviation acronym definition novel disambiguator abbreviation expansion easily accessible webbased solution
traditional text classification typically categorizes text predefined coarsegrained class produced model handle realworld scenario finer category emerge periodically accurate service work investigate setting finegrained classification done using annotation coarsegrained category coarsetofine mapping propose lightweight contrastive clusteringbased bootstrapping method iteratively refine label passage clustering pull away negative passageprototype pair guidance mapping global local perspective experiment nyt news show method outperforms stateoftheart method large margin
natural language generation nlg used generate personalized health information especially useful provided one language however nlg technique widely used different domain languagestemplateswas shown inapplicable bantu language due characteristic agglutinative structure present use grammar engine nlg technique generate text runyankore bantu language indigenous uganda grammar engine add previous work field new rule cardinality constraint preposition role passive phonological conditioning evaluated generated text linguist nonlinguists regarded text grammatically correct understandable regarded text generated system authored human
masked language model like bert perform text classification zeroshot fashion reformulating downstream task text infilling however approach highly sensitive template used prompt model yet practitioner blind designing strict zeroshot setting paper propose alternative miningbased approach zeroshot learning instead prompting language model use regular expression mine labeled example unlabeled corpus optionally filtered prompting used finetune pretrained model method flexible interpretable prompting outperforms wide range task using comparable template result suggest success prompting partly explained model exposed similar example pretraining directly retrieved regular expression
recent work shown prompting language model codelike representation natural language lead performance improvement structured reasoning task however task comprise small subset natural language task work seek answer whether codeprompting preferred way interacting language model general compare code text prompt across three popular gpt model davinci codedavinci textdavinci broader selection task eg qa sentiment summarization find exception code prompt consistently outperform text prompt furthermore show style code prompt large effect performance task finetuning text instruction lead better relative performance code prompt
joint entity relation extraction challenging due complex interaction interaction named entity recognition relation extraction although existing work tend jointly train two task shared network fail fully utilize interdependence entity type relation type paper design novel synchronous dual network sdn crosstype attention via separately interactively considering entity type relation type one hand sdn adopts two isomorphic bidirectional typeattention lstm encode entity type enhanced representation relation type enhanced representation respectively hand sdn explicitly model interdependence entity type relation type via crosstype attention mechanism addition also propose new multitask learning strategy via modeling interaction two type information experiment nyt webnlg datasets verify effectiveness proposed model achieving stateoftheart performance
extensive training datasets represent one important factor impressive learning capability large language model llm however training datasets current llm especially recent stateoftheart model often fully disclosed creating training data highperforming llm involves extensive cleaning deduplication ensure necessary level quality lack transparency training data thus hampered research attributing addressing hallucination bias issue llm hindering replication effort advancement community challenge become even pronounced multilingual learning scenario available multilingual text datasets often inadequately collected cleaned consequently lack opensource readily usable dataset effectively train llm multiple language overcome issue present culturax substantial multilingual dataset trillion token language tailored llm development dataset undergoes meticulous cleaning deduplication rigorous pipeline multiple stage accomplish best quality model training including language identification urlbased filtering metricbased cleaning document refinement data deduplication culturax released hugging face facilitate research advancement multilingual llm httpshuggingfacecodatasetsuonlpculturax
paper describes semevals shared task intended sarcasm detection english arabic task includes english arabic tweet sarcasm nonsarcasm sample irony speech label first two subtasks predict whether text sarcastic ironic category sarcasm sample belongs third one find sarcastic sample nonsarcastic paraphrase deep neural network recently achieved highly competitive performance many task combining deep learning language model also resulted acceptable accuracy inspired propose novel deep learning model top language model top architecture us encoder module transformer followed lstm attention utilizing past future information concentrating informative token due success proposed model used architecture modification output layer three subtasks
present gtpsw billion parameter autoregressive language model trained newly created gb swedish corpus paper provides insight regard data collection training highlight challenge proper model evaluation result quantitive evaluation perplexity indicate gptsw competent model comparison existing autoregressive model similar size additionally perform extensive prompting study reveals good text generation capability gtpsw
notion face refers public selfimage individual emerges individual action well interaction others modeling face understanding state change throughout conversation critical study maintenance basic human need interaction grounded politeness theory brown levinson propose generalized framework modeling face act persuasion conversation resulting reliable coding manual annotated corpus computational model framework reveals insight difference face act utilization asymmetric role persuasion conversation using computational model able successfully identify face act well predict key conversational outcome eg donation success finally model latent representation conversational state analyze impact predicted face act probability positive conversational outcome observe several correlation corroborate previous finding
large language model gpt wellsuited text prediction task help delight user text composition llm known generate ethically inappropriate prediction even seemingly innocuous context toxicity detection followed filtering common strategy mitigating harm prediction however shall argue paper context text prediction sufficient detect filter toxic content one also need ensure factual correctness grouplevel fairness prediction failing make system ineffective nonsensical best unfair detrimental user worst discus gap challenge toxicity detection approach blocklistbased approach sophisticated stateoftheart neural classifier evaluating text prediction task english manually crafted checklist harm targeted different group different level severity
goal text zoning segment text zone ie background conclusion serve distinct function argumentative zoning specific text zoning scheme scientific domain considered antecedent argument mining many researcher surprisingly however little work concerned exploiting zoning information improve performance argument mining model despite relatedness two task paper propose two transformerbased model incorporate zoning information argumentative component identification classification task one model sentencelevel argument mining task tokenlevel task particular add zoning label predicted offtheshelf model beginning sentence inspired convention commonly used biomedical abstract moreover employ multihead attention transfer sentencelevel zoning information token sentence based experiment result find significant improvement fscores sentence tokenlevel task worth mentioning zoning label obtained high accuracy utilising readily available automated method thus existing argument mining model improved incorporating zoning information without additional annotation cost
paper present exhaustive study generation graph input unsupervised graphbased noncontextual single document keyword extraction system concrete hypothesis concept coordination document scientific article put forward consistent two separate graph model one based word adjacency linear textan approach forming foundation previous graphbased keyword extraction method novel one based word adjacency modulo modifier achieve best reported ndcg score date system data term best parameter fscore achieve highest reported date reasonable ranked list cutoff n also best reported fscore keyword extraction generation system literature data bestparameter fscore corresponds reduction error conservatively
study whether novel idea biomedical literature appear first preprints traditional journal develop bayesian method estimate time appearance phrase literature apply number phrase automatically extracted suggested expert see presently phrase appear first traditional journal number phrase first appearance preprint server comparison general composition text biorxiv traditional journal show growing trend biorxiv predictive traditional journal discus application method related problem
automatic sign language processing gaining popularity natural language processing nlp research yin et al machine translation mt particular sign language translation based gloss prominent approach paper review recent work neural gloss translation find limitation gloss general limitation specific datasets discussed transparent manner common standard evaluation address issue put forward concrete recommendation future research gloss translation suggestion advocate awareness inherent limitation glossbased approach realistic datasets stronger baseline convincing evaluation
large language model like chatgpt recently shown great promise performing several task including hate speech detection however crucial comprehend limitation model build robust hate speech detection system bridge gap study aim evaluate strength weakness chatgpt model detecting hate speech granular level across language evaluation employ series functionality test reveals various intricate failure model aggregate metric like macro f accuracy able unfold addition investigate influence complex emotion use emojis hate speech performance chatgpt model analysis highlight shortcoming generative model detecting certain type hate speech highlighting need research improvement working model
propaganda form deceptive narrative instigate mislead public usually political purpose paper aim identify propaganda political news two finegrained level sentencelevel tokenlevel observe propaganda content likely embedded sentence attribute causality assert contrast nearby sentence well seen opinionated evaluation speculation discussion future expectation hence propose incorporate local global discourse structure propaganda discovery construct two teacher model identifying pdtbstyle discourse relation nearby sentence common discourse role sentence news article respectively devise two method incorporate two type discourse structure propaganda identification either using teacher predicted probability additional feature soliciting guidance knowledge distillation framework experiment benchmark dataset demonstrate leveraging guidance discourse structure significantly improve precision recall propaganda content identification
introduce corpus u presidential debate commentary containing argumentative proposition annotated finegrained proposition type modern machine learning pipeline analyzing argument difficulty distinguishing type proposition based factuality rhetorical positioning speaker commitment inability properly account facet leaf system inaccurate understanding finegrained proposition type paper demonstrate approach annotating four complex proposition type namely normative claim desire future possibility reported speech develop hybrid machine learning human workflow annotation allows efficient reliable annotation complex linguistic phenomenon demonstrate preliminary analysis rhetorical strategy structure presidential debate new dataset method support technical researcher seeking nuanced representation argument well argumentation theorist developing new quantitative analysis
monolingual make minority world speaker yet language technology lag behind handling linguistic behaviour produced bilingual multilingual speaker commonly observed phenomenon community codemixing prevalent social medium thus requires attention nlp research work look ability pretrained language model handle codemixed data focus impact language present pretraining downstream performance model measured task sentiment analysis ultimately find pretraining language little effect performance model see codemixed data downstream finetuning also evaluate model codemixed data zeroshot setting taskspecific finetuning monolingual dataset find brings difference model performance attributed pretraining language present thorough analysis finding also look model performance based composition participating language codemixed datasets
continual fewshot relation learning cfrl aim learn increasing number new relational pattern data stream however due limited number sample continual training mode method frequently encounter catastrophic forgetting issue research causal inference suggests issue caused loss causal effect old data new training process inspired causal graph propose unified causal framework cfrl restore causal effect specifically establish two additional causal path old data prediction new data memory data collide old data separately old feature space augmentation allows u preserve causal effect effectively enhance utilization valuable information within memory data thereby alleviating phenomenon catastrophic forgetting furthermore introduce selfadaptive weight achieve delicate balance causal effect new old relation type extensive experiment demonstrate superiority method existing stateoftheart approach cfrl task setting code publicly available httpsgithubcomywhcecf
past year witnessed remarkable advancement code pretrained model codeptms model achieved excellent representation capability designing structurebased pretraining task code however enhance absorption structural knowledge finetuning codeptms still remains significant challenge fill gap paper present sat novel structureenhanced plugandplay finetuning method codeptms first propose structure loss quantify difference information learned codeptms knowledge extracted code structure specifically use attention score transformer layer learned information shortest path length leaf abstract syntax tree structural knowledge subsequently multitask learning introduced improve performance finetuning experiment conducted four pretrained model two generation task demonstrate effectiveness proposed method plugandplay solution furthermore observed sat benefit codeptms limited training data
paper focus representation querying knowledgebased multimodal data work stand otim project aim processing multimodal annotation large conversational french speech corpus within otim aim providing linguist unique framework encode manipulate numerous linguistic domain prosody gesture linguist commonly use typed feature structure tfs provide uniform view multimodal annotation representation used within applicative framework moreover tfs expressibility limited hierarchical constituency relation suit linguistic domain need example represent temporal relation overcome limit propose ontological approach based description logic dl description linguistic knowledge provide applicative framework based owl dl ontology web language query language sparql
recently neural topic model ntms incorporated pretrained language model plms capture global semantic information text summarization however method remain limitation way capture integrate global semantic information paper propose novel model graph contrastive topic enhanced language model gretel incorporates graph contrastive topic model pretrained language model fully leverage global local contextual semantics long document extractive summarization better capture incorporate global semantic information plms graph contrastive topic model integrates hierarchical transformer encoder graph contrastive learning fuse semantic information global document context gold summary end gretel encourages model efficiently extract salient sentence topically related gold summary rather redundant sentence cover suboptimal topic experimental result general domain biomedical datasets demonstrate proposed method outperforms sota method
present study linguistic output germanspeaking writer robert walser using nlp curated corpus comprising text written walser period sound health writing year hospitalization writing first year stay psychiatric clinic likely tributed schizophrenia within corpus identified analyzed total lin guistic marker encompassing established met rics lexical diversity semantic similarity syntactic complexity additionally ex plored lesserknown marker lexical innovation concreteness imageability tably introduced two additional marker phonological similarity first time within context finding reveal sig nificant temporal dynamic marker closely associated walsers contempora neous diagnosis schizophrenia furthermore investigated relationship marker leveraging classification schizophrenic episode
search engine web existing questionanswering system provide user set hyperlink andor web page extract containing answer question answer often incoherent certain degree equivalent contradictory etc quite difficult user know answer correct one paper present approach aim providing synthetic numerical answer questionanswering system answer generated natural language cooperative perspective aim explain user variation numerical value several value apparently incoherent extracted web possible answer question present particular lexical resource essential answer extraction web characterization variation mode associated type information answer generation natural language
aspect level sentiment classification finegrained sentiment analysis task detect sentiment towards particular aspect sentence previous study developed various attentionbased method generating aspectspecific sentence representation however attention may inherently introduce noise downgrade performance paper propose constrained attention network simple yet effective solution regularize attention multiaspect sentiment analysis alleviates drawback attention mechanism specifically introduce orthogonal regularization multiple aspect sparse regularization single aspect experimental result two public datasets demonstrate effectiveness approach extend approach multitask setting outperform stateoftheart method
aspect sentiment triplet extraction aste aim extracting triplet given sentence triplet includes aspect sentiment polarity corresponding opinion explaining polarity existing method poor detecting complicated relation aspect opinion well classifying multiple sentiment polarity sentence detecting unclear boundary multiword aspect opinion also challenge paper propose multitask dualtree network mtdtn address issue employ constituency tree modified dependency tree two subtasks aspect opinion coextraction aoce aste respectively enhance information interaction two subtasks design transitionbased inference strategy tbis transfer boundary information tag aoce aste transition matrix extensive experiment conducted four popular datasets result show effectiveness model
question answering qa one challenging impactful task natural language processing research qa however focused opendomain monolingual setting realworld application deal specific domain language tutorial attempt bridge gap firstly introduce standard benchmark multidomain multilingual qa scenario discus stateoftheart approach achieve impressive performance ranging zeroshot transfer learning outofthebox training opendomain qa system finally present open research problem new research agenda pose multitask learning crosslingual transfer learning domain adaptation training large scale pretrained multilingual language model
large language model benefit training large amount unlabeled text give increasingly fluent diverse generation capability however using model text generation take account target attribute sentiment polarity specific topic remains challenge propose simple flexible method controlling text generation aligning disentangled attribute representation contrast recent effort training discriminator perturb token level distribution attribute use data learn alignment function guide pretrained noncontrolled language model generate text target attribute without changing original language model parameter evaluate method sentiment topiccontrolled generation show large performance gain previous method retaining fluency diversity
paper describes nemo submission sigtyp shared task bjerva et al deal prediction linguistic typological feature multiple language using data derived world atlas language structure wals employ frequentist inference represent correlation typological feature use representation train simple multiclass estimator predict individual feature describe two submitted ridge regressionbased configuration ranked second third overall constrained task best configuration achieved microaveraged accuracy score test language
according george k zipf frequent word sens tested law using corpus wordnet english spanish portuguese french polish japanese indonesian chinese proved law work pretty well language take zipf mean value meaning count averaged rank hand law disastrously fails predicting number sens single lemma also provided evidence slope coefficient zipfian loglog linear model may vary language language
dense retriever encode query document map embedding space using pretrained language model embeddings need highdimensional fit training signal guarantee retrieval effectiveness dense retriever however highdimensional embeddings lead larger index storage higher retrieval latency reduce embedding dimension dense retrieval paper proposes conditional autoencoder conae compress highdimensional embeddings maintain embedding distribution better recover ranking feature experiment show conae effective compressing embeddings achieving comparable ranking performance teacher model making retrieval system efficient analysis show conae alleviate redundancy embeddings dense retrieval one linear layer code work available httpsgithubcomneuirconae
sentiment analysis deal task determining polarity document sentence received lot attention recent year english language rapid growth social medium day lot data available regional language besides english telugu one regional language abundant data available social medium hard find labelled data sentence telugu sentiment analysis paper describe effort build goldstandard annotated corpus telugu sentence support telugu sentiment analysis corpus named actsa annotated corpus telugu sentiment analysis collection telugu sentence taken different source preprocessed manually annotated native telugu speaker using annotation guideline total annotated sentence make corpus largest resource currently available corpus annotation guideline made publicly available
paper present system semeval task aim identify human value behind argument classifying whether argument draw specific category approach leverage secondphase pretraining method adapt roberta language model lm tackle problem using oneversusall strategy final prediction determined majority voting module combine output ensemble three set perlabel model conducted experiment evaluate impact different pretrained lm task comparing performance pretrained taskadapted setting finding show finetuning roberta lm taskspecific dataset improves performance outperforming bestperforming baseline bert approach overall approach achieved macrof score official test set demonstrating potential identifying human value behind argument
present result participation vardial shared task discriminating closely related language submission includes simple traditional model using linear support vector machine svms neural network nn main idea leverage language group information twolayer approach traditional model multitask objective neural network case result confirm earlier finding simple traditional model outperform neural network consistently task least given amount system could examine available time twolayer linear svm ranked nd shared task
term event extraction cover wide range information extraction task method developed evaluated one task may prove quite unsuitable another understanding task difference essential making broad progress event extraction look back muc ace task term one characteristic breadth scenario wide range information subsumed single extraction task examine affect strategy collecting information method semisupervised training new extractor also consider heterogeneity corpus varied topic document corpus extraction system may intended principle general news typically evaluated topicfocused corpus evaluation context may affect system design one case study examine task identifying physical attack event news corpus observing effect system performance shifting attackeventrich corpus varied corpus considering impact shift may mitigated
paper introduces webbased authoring support system mutual aim help writer create multilingual text highlighted feature system enables machine translation mt generate output appropriate functional context within target document system operational online implementing core mechanism document structuring controlled writing include topic template controlled language authoring assistant linked statistical mt system
codemixing become moving method communication among multilingual speaker social medium content multilingual society written codemixed text however current translation system neglect convert codemixed text standard language user written codemixed content social medium remains unprocessed due unavailability linguistic resource parallel corpus paper proposes neural machine translationnmt model translate sinhalaenglish codemixed text sinhala language due limited resource available sinhalaenglish codemixedsecm text parallel corpus created secm sentence sinhala sentence srilankan social medium site contain secm text frequently standard language model proposed codemixed text translation study combination encoderdecoder framework lstm unit teacher forcing algorithm translated sentence model evaluated using bleubilingual evaluation understudy metric model achieved remarkable bleu score translation
ambient assisted living aal name european technology innovation funding programme aal research field intelligent assistant system healthier safer life preferred living environment use information communication technology ict focus specifically speech gesture interaction enhance quality lifestyle people living assistive environment senior people physical cognitive disability paper describe user study conducted lab university bremen order collect empirical speech gesture data later create analyse multimodal corpus user study human user sitting wheelchair performing certain inherently spatial task
training transformer language model requires vast amount text computational resource drastically limit usage model niche domain optimized domainspecific training data scarce focus clinical domain limited access training data common task structured ontological data often readily available recent observation model compression transformer model show optimization potential improving representation capacity attention head propose kimera knowledge injection via mask enforced retraining attention detecting retraining instilling attention head complementary structured domain knowledge novel multitask training scheme effectively identifies target individual attention head least useful given downstream task optimizes representation information structured data kimera generalizes well thereby building basis efficient finetuning kimera achieves significant performance boost seven datasets medical domain information retrieval clinical outcome prediction setting apply kimera bertbase evaluate extent domain transfer also improve already strong result biobert clinical domain
ideally people navigate together complex indoor space share mental model facilitates explanation paper report robot control system whose cognitive world model based spatial affordances generalize perceptual data given target control system formulates multiple plan modelrelevant metric selects among result provide readily understandable natural language robot intention confidence generate diverse contrastive explanation reference acquired spatial model empirical result large complex environment demonstrate robot ability provide humanfriendly explanation natural language
reasoning mathematical domain remains significant challenge relatively small language model lm many current method focus specializing lm mathematical reasoning rely heavily distilling knowledge powerful yet inefficient large lm llm work explore new direction avoids overreliance llm teacher introducing multiview finetuning method efficiently exploit existing mathematical problem datasets diverse annotation style approach uniquely considers various annotation format different view may help leverage training model postpending distinct instruction input question model learn generate solution diverse format flexible manner experimental result show strategy enables relatively small lm outperform prior approach heavily rely knowledge distillation well carefully established baseline additionally proposed method grant model promising generalization ability across various view datasets capability learn inaccurate incomplete noisy data hope multiview training paradigm could inspire future study machine reasoning domain
paper present work wmt quality estimation qe shared task participated three subtasks including sentencelevel direct assessment da task word sentencelevel postediting effort task critical error detection task language pair system employ framework predictorestimator concretely pretrained xlmroberta predictor taskspecific classifier regressor estimator task improve system incorporating postedit sentence additional highquality translation sentence way multitask learning encoding predictor directly moreover zeroshot setting data augmentation strategy based montecarlo dropout brings significant improvement da subtask notably submission achieve remarkable result task
sentence compression reduces length text removing nonessential content preserving important fact grammaticality unsupervised objective driven method sentence compression used create customized model without need groundtruth training data allowing flexibility objective function used learning inference recent unsupervised sentence compression approach use custom objective guide discrete search however guided search expensive inference time work explore use reinforcement learning train effective sentence compression model also fast generating prediction particular cast task binary sequence labelling finetune pretrained transformer using simple policy gradient approach approach outperforms unsupervised model also efficient inference time
usual concern opting rulebased hybrid machine translation mt system much effort required adapt system different language pair new domain paper describe way adapting existing hybrid mt system new language pair show system outperform standard phrasebased statistical machine translation system average personsmonth work specifically important case domainspecific mt enough parallel data training statistical machine translation system
lois lexical ontology legal information sharing project legal knowledge base resulting lois lexical ontology legal information sharing lexical ontology legal information sharing project consists legal wordnet six language italian dutch portuguese german czech english architecture based eurowordnet ewn framework vossen et al using ewn framework assures compatibility lois wordnet ewn allowing function extension ewn legal domain legal system documentderived legal concept integrated taxonomy link existing formal ontology give legal wordnet first formal backbone future extended database consists synset aimed used information retrieval provides mono multilingual access european legal database legal expert well layman lois knowledge base also provides flexible modular architecture allows integration multiple classification scheme enables comparison legal system exploring translation equivalence structure across different legal wordnet
syndicated feed rss atom related format emerged ubiquitous information source world wide web language community including arabic farsi chinese others providing subscriber timely update topic particular interest modified existing open source rss reader sage crosslanguage use permitting englishspeakers discover subscribe update browse rss feed ten language early prototype called clip perrss integrated clipper crosslanguage information retrieval tool integrated system provides englishspeakers effective mean exploring potential foreignlanguage syndicated feed domain interest
paper describes spindle open source python module providing efficient accurate parser written dutch transforms raw text input program meaning composition expressed term parser integrates number breakthrough advance made recent year output consists hire derivation multimodal typelogical grammar capturing two orthogonal ax syntax namely deep functionargument structure dependency relation produced three interdependent system static typechecker asserting wellformedness grammatical analysis stateoftheart structurallyaware supertagger based heterogeneous graph convolution massively parallel proof search component based sinkhorn iteration packed software also handy utility extra proof visualization inference intended facilitate enduser utilization
sememes minimum semantic unit word meaning meaning word sense typically composed several sememes since sememes explicit word people manually annotate word sememes form linguistic commonsense knowledge base paper present word sememe information improve word representation learning wrl map word lowdimensional semantic space serf fundamental step many nlp task key idea utilize word sememes capture exact meaning word within specific context accurately specifically follow framework skipgram present three sememeencoded model learn representation sememes sens word apply attention scheme detect word sens various context conduct experiment two task including word similarity word analogy model significantly outperform baseline result indicate wrl benefit sememes via attention scheme also confirm model capable correctly modeling sememe information
work introduce timeframe online platform easily query visualize event participant extracted document collection italian following framebased approach system allows user select one event frame event category display occurrence timeline different query type coarse finegrained available interface enabling timebound analysis large historical corpus present three use case based full archive news published newspaper corriere della serum show different crucial event explored providing interesting insight narrative around event main participant point view
conversational search provides natural interface information retrieval ir recent approach demonstrated promising result applying dense retrieval conversational ir however training dense retriever requires large amount indomain paired data hinders development conversational dense retriever abundant indomain conversation expensive collect paper propose converser framework training conversational dense retriever example indomain dialogue specifically utilize incontext learning capability large language model generate conversational query given passage retrieval corpus experimental result conversational retrieval benchmark orquac trec cast show proposed converser achieves comparable performance fullysupervised model demonstrating effectiveness proposed framework fewshot conversational dense retrieval source code generated datasets available httpsgithubcommiulabconverser
question answering qa knowledge graph kg task answering natural language nl query using information stored kg realworld industrial setting involves addressing multiple challenge including entity linking multihop reasoning kg etc traditional approach handle challenge modularized sequential manner error one module lead accumulation error downstream module often challenge interrelated solution reinforce handled simultaneously endtoend learning setup end propose multitask bert based neural machine translation nmt model address challenge experimental analysis demonstrate efficacy proposed approach one publicly available one proprietary dataset
monitoring analysis complex phenomenon attract attention academy industry dealing data produced complex phenomenon requires use advance computational intelligence technique namely linguistic description complex phenomenon constitutes mature research line supported computational theory perception grounded fuzzy set theory aim development computational system ability generate vague description world similar way human humancentric multidisciplinary research work moreover success matter careful design thus developer play key role rldcp r package designed facilitate development new application demo introduces use rldcp beginner advance developer practical use case
big language like english spoken lot people whose mother tongue different second language often distinct accent also different lexical syntactic characteristic speech recognition performance severely affected lexical syntactic semantic characteristic training recognition task differ language model speech recognition system usually trained transcribed speech data text data collected english native country therefore speech recognition performance expected degraded mismatch lexical syntactic characteristic native speaker second language speaker well distinction accent aim language model adaptation exploit specific albeit limited knowledge recognition task compensate mismatch lexical syntactic semantic characteristic paper describes whether language model adaptation effective compensating mismatch lexical syntactic semantic characteristic native speaker second language speaker
goal semantic parsing map natural language machine interpretable meaning representation language mrl one constraint limit full exploration deep learning technology semantic parsing lack sufficient annotation training data paper propose using sequencetosequence multitask setup semantic parsing focus transfer learning explore three multitask architecture sequencetosequence model compare performance independently trained model experiment show multitask setup aid transfer learning auxiliary task large labeled data target task smaller labeled data see absolute accuracy gain ranging inhouse data set also see good gain ranging atis semantic parsing task syntactic semantic auxiliary task
response selection play vital role building retrievalbased conversation system despite response selection naturally learningtorank problem prior work take pointwise view train binary classifier task response candidate labeled either relevant one irrelevant zero one hand formalization suboptimal due ignorance diversity response quality hand annotating grayscale data learningtorank prohibitively expensive challenging work show grayscale data automatically constructed without human effort method employ offtheshelf response retrieval model response generation model automatic grayscale data generator constructed grayscale data propose multilevel ranking objective training teach matching model capture finegrained contextresponse relevance difference reduce traintest discrepancy term distractor strength method simple effective universal experiment three benchmark datasets four stateoftheart matching model show proposed approach brings significant consistent performance improvement
paper provides detailed overview system submitted part osact shared task finegrained hate speech detection arabic twitter outcome limitation submission accomplished hard parameter sharing multitask model consisted shared layer containing stateoftheart contextualized text representation model marbert arabert arbert task specific layer finetuned quasirecurrent neural network qrnn downstream subtask result show marbert finetuned qrnn outperforms previously mentioned model
work experiment various configuration transformerbased sequencetosequence neural network training discourse representation structure drs parser present result along code reproduce experiment use community working drs parsing configuration tested prior work task parallel meaning bank pmb english data set used train model result evaluated pmb test set using counter standard evaluation tool drss show performance improves upon previous state art f pmb f pmb test set also present result pmb evaluated using counter previous research
develop process execution graph peg documentlevel representation realworld wet lab biochemistry protocol addressing challenge crosssentence relation longrange coreference grounding implicit argument manually annotate peg corpus complex lab protocol novel interactive textual simulator keep track entity trait semantic constraint annotation use data develop graphprediction model finding good entity identification local relation extraction corpus facilitates exploration challenging longrange relation
following previous work metaphor annotation automatic metaphor processing study present evaluation initial phase novel area linguistic metaphor detection mexican spanish popular science tweet specifically examine challenge posed annotation process stemming disagreement among annotator phase work conducted annotation corpus comprising mexican spanish popular science tweet corpus divided two half half assigned two different pair native mexican spanishspeaking annotator despite rigorous methodology continuous training interannotator agreement measured cohens kappa found low slightly chance level although concordance percentage exceeded elucidating inherent complexity metaphor annotation task evaluation emphasizes implication finding offer insight future research field aim creating robust dataset machine learning
development deep learning recent year text classification research achieved remarkable result however text classification task often requires large amount annotated data data different field often force model learn different knowledge often difficult model distinguish data labeled different domain sometimes data different domain even damage classification ability model reduce overall performance model address issue propose sharedprivate architecture based contrastive learning multidomain text classification improve accuracy robustness classifier extensive experiment conducted two public datasets result experiment show approach achieves stateoftheart performance multidomain text classification
paper summarises experimental setup result first shared task endtoend ee natural language generation nlg spoken dialogue system recent endtoend generation system promising since reduce need data annotation however currently limited small delexicalised datasets ee nlg shared task aim assess whether novel approach generate betterquality output learning dataset containing higher lexical richness syntactic complexity diverse discourse phenomenon compare system submitted institution covering wide range approach including machine learning architecture majority implementing sequencetosequence model seqseq well system based grammatical rule template
negation one fundamental concept human cognition language several natural language inference nli probe designed investigate pretrained language model ability detect reason negation however existing probing datasets limited english enable controlled probing performance absence presence negation response present multilingual english bulgarian german french chinese benchmark collection nli example grammatical correctly labeled result manual inspection reformulation use benchmark probe negationawareness multilingual language model find model correctly predict example negation cue often fail correctly predict counterexample without negation cue even cue irrelevant semantic inference
paper describe lmu munich submission textitwmt parallel corpus filtering shared task address problem cleaning noisy parallel corpus task mining cleaning parallel sentence important improving quality machine translation system especially lowresource language tackle problem fully unsupervised fashion relying bilingual word embeddings created without bilingual signal prefiltering noisy data rank sentence pair calculating bilingual sentencelevel similarity remove redundant data employing monolingual similarity well unsupervised system achieved good performance official evaluation shared task scoring bleu point behind best system requiring parallel training data
paper describes tencent ai lab submission wmt shared task chat translation englishgerman neural machine translation nmt system built sentencelevel documentlevel nonautoregressive nat pretrained model integrate number advanced technique system including data selection backforward translation larger batch learning model ensemble finetuning well system combination specifically proposed hybrid data selection method select highquality indomain sentence outofdomain data better capture source context exploit augment nat model evolved crossattention furthermore explore transfer general knowledge four different pretraining language model downstream translation task general present extensive experimental result new translation task among participant germantoenglish primary system ranked second term bleu score
relational fact important component human knowledge hidden vast amount text order extract fact text people working relation extraction year early pattern matching current neural network existing method achieved significant progress yet explosion web text emergence new relation human knowledge increasing drastically thus require powerful system robustly utilize data efficiently learn relation easily handle complicated context flexibly generalize open domain paper look back existing method analyze key challenge facing nowadays show promising direction towards powerful hope view advance field inspire effort community
text semantic matching crucial natural language processing applied information retrieval question answering recommendation system traditional textmatching method struggle semantic nuance short text recent advancement multigranularity representation learning led increased interest improving text semantic matching model propose novel multigranularity fusion model harness wobert pretrained language model enhance accuracy text semantic information capture initially process text using wobert acquire semantic representation effectively capturing individual text semantic nuance next employ soft attention alignment mechanism enabling multigranularity fusion among character word sentence thus improving matching performance approach evaluated experiment common chinese short text matching datasets bq lcqmc result reveal significant improvement performance compared traditional method particularly term accuracy
developing country like india doctor healthcare professional working public health spend significant time answering health query factbased repetitive therefore propose automated way answer maternal child healthrelated query database frequently asked question faq corresponding answer generated expert curated rural health worker young mother develop hindi chatbot identifies k relevant question answer qna pair database response healthcare query q written devnagri script hindienglish hinglish codemixed script curated database cover query user study likely ask experimented rulebased method ii sentence embeddings iii paraphrasing classifier calculate qq similarity observed paraphrasing classifier give best result trained first opendomain text healthcare domain chatbot us ensemble three approach observed given q answered using database chatbot provide least one relevant qna pair among top three suggestion query
statistical machine translation smt model recently begun include source context modeling assumption proper lexical choice translation ambiguous word determined context appears various type lexical syntactic feature explored effective source context improve phrase selection smt present work introduce lexicosyntactic description form supertags sourceside context feature stateoftheart hierarchical phrasebased smt hpb model feature enable u exploit source similarity addition target similarity modelled language model experiment two kind supertags employed lexicalized treeadjoining grammar ltag combinatory categorial grammar ccg use memorybased classification framework enables efficient estimation feature despite difference two supertagging approach give similar improvement evaluate performance approach englishtodutch translation task report statistically significant improvement bleu score translation quality adding ccg ltag supertags respectively contextinformed feature
recently pretrained language model released cloud service allows user lack computing resource perform inference powerful model uploading data cloud plain text may contain private information result user prefer partial computation locally upload intermediate representation cloud subsequent inferencehowever recent study shown intermediate representation also recovered plain text reasonable accuracy thus risk privacy leakage still exists address issue propose textfusion novel method preserving inference privacyspecifically train fusion predictor dynamically fuse token representation hide multiple private token representation behind unrecognizable onefurthermore adversarial training regime employed privatize representation way cloud receives incomplete perturbed representation making difficult accurately recover complete plain textthe experimental result diverse classification task show approach effectively preserve inference privacy without significantly sacrificing performance different scenario
describe novel methodology measuring affective language historical text expanding affective lexicon jointly adapting prior language stage automatically construct lexicon wordemotion association th th century german validated expert rating subsequently resource used identify distinct emotional pattern trace longterm emotional trend different genre writing spanning several century
long document question answering challenging task due demand complex reasoning long text previous work usually take long document nonstructured flat text consider local structure long document however method usually ignore global structure long document essential longrange understanding tackle problem propose compressive graph selector network cgsn capture global structure compressive iterative manner proposed model mainly focus evidence selection phase long document question answering specifically consists three module local graph network global graph network evidence memory network firstly local graph network build graph structure chunked segment token sentence paragraph segment level capture shortterm dependency text secondly global graph network selectively receives information level local graph compress global graph node applies graph attention global graph node build longrange reasoning entire text iterative way thirdly evidence memory network designed alleviate redundancy problem evidence selection saving selected result previous step extensive experiment show proposed model outperforms previous method two datasets
develop novel crosslingual word representation model injects syntactic information dependencybased context shared crosslingual word vector space model termed cldepemb based following assumption dependency relation largely languageindependent least related language prominent dependency link direct object evidenced universal dependency project word translation equivalent take similar grammatical role sentence therefore substitutable within syntactic context experiment several language pair word similarity bilingual lexicon induction two fundamental semantic task emphasising semantic similarity suggest usefulness proposed syntactically informed crosslingual word vector space improvement observed task standard crosslingual offline mapping baseline trained using setup equal level bilingual supervision
neural network based word embeddings wordvec glove purely data driven capture distributional information word training corpus past work attempted improve embeddings incorporating semantic knowledge lexical resource like wordnet technique like retrofitting modify word embeddings postprocessing stage others use joint learning approach modifying objective function neural network paper discus two novel approach incorporating semantic knowledge word embeddings first approach take advantage levy et al work showed using svd based method cooccurrence matrix provide similar performance neural network based embeddings propose sprinkling technique add semantic relation cooccurrence matrix directly factorization second approach wordnet similarity score used improve retrofitting method evaluate proposed method intrinsic extrinsic task observe significant improvement baseline many datasets
dialogue system increasingly using knowledge base kb storing realworld fact help generate quality response however kb inherently incomplete remain fixed conversation limit dialogue system ability answer question handle question involving entity relation kb paper make attempt propose engine continuous interactive learning knowledge cilk dialogue system give ability continuously interactively learn infer new knowledge conversation knowledge accumulated time able learn better answer question empirical evaluation show cilk promising
introduce first version geczlex online electronic resource translation equivalent czech german discourse connective lexicon one outcome research anaphoricity longdistance relation discourse contains present anaphoric connective ac czech german connective possible translation documented bilingual parallel corpus necessarily anaphoric basis use two existing monolingual lexicon connective lexicon czech discourse connective czedlex lexicon discourse marker dimlex german interlink relevant entry via semantic annotation connective according pdtb sense taxonomy statistical information translation possibility czech german parallel data intercorp project lexicon far know first bilingual inventory connective linkage level individual entry first attempt systematically describe device engaged longdistance nonlocal discourse coherence lexicon freely available creative common license
plwordnet wordnet polish become comprehensive description polish lexical system paper present plan semiautomated integration thesaurus terminological database ontology necessary step development improve linking plwordnet linked open data facilitate application eg wsd keyword extraction automated metadata generation present overview resource relevant polish plan linking plwordnet
lexicosemantic element doubt capture large amount linguistic information argued capture information contained text assumption central constructionist approach language argue language consists construction learned pairing form function meaning either frequent meaning predicted component part berts training objective give access tremendous amount lexicosemantic information bertology shown bert capture certain important linguistic dimension study exploring extent bert might access constructional information work design several probe conduct extensive experiment answer question result allow u conclude bert indeed access significant amount information much linguist typically call constructional information impact observation potentially farreaching provides insight deep learning method learn text also showing information contained construction redundantly encoded lexicosemantics
present research narrative aimed enabling language technology multiple natural language generation nlg task lowresource language lrls approximately language spoken globally many lack resource required model training nlg application lrls present two additional key challenge training pronounced ii zeroshot modeling viable research direction scalability however generating zeroshot wellformed text target lrls challenging addressing concern narrative introduces three promising research exploration serve step toward enabling language technology many lrls approach make effective use transfer learning limited supervision technique modeling evaluation conducted mostly zeroshot setting enabling scalability research narrative ongoing doctoral thesis
paper present corpus study extends generalises existing annotation model integrates functional content description delivered via text picture interactive component model used describe new corpus online vegan recipe blog term attractiveness least two type reader vegan reader reader interested vegan lifestyle arguably reader value blog show target dish easy make inferred number ingredient procedural step visualised action according easy read cooking instruction display coherent use verbal visual modality presenting process result cooking action involved moreover added value may attributed invitation engage blog content functionality information recipe author diet nutrition accessed thus corpus study merges generalisable annotation verbal visual interaction phenomenon capture attractiveness online vegan recipe blog inform reader user study ultimately offer guideline authoring effective online multimodal instruction
popular application machine translation mt textitgisting mt consumed textitas make sense text foreign language evaluation usefulness mt gisting surprisingly uncommon classical method us textitreading comprehension questionnaire rcq informant asked answer professionallywritten question language foreign text machinetranslated language recently textitgapfilling gf form textitcloze testing proposed cheaper alternative rcq gf certain word removed reference translation reader asked fill gap left using machinetranslated text hint paper report first time comparative evaluation using rcq gf translation multiple mt system foreign text systematic study effect variable gap density gapselection strategy document context gf main finding study rcq gf clearly identify mt useful b global rcq gf ranking mt system mostly agreement c gf score vary widely across informant making comparison among mt system hard unlike rcq framed around document gf evaluation framed sentence level finding support use gf cheaper alternative rcq
paper report implementation deployment mt system polish branch ey global limited system support standard cat mt functionality translation memory fuzzy search document translation postediting meet less common customerspecific expectation deployment began august proof concept ended signing final version acceptance certificate october present challenge faced deployment particularly relation security check installation process production environment
propose multitask pretraining approach zeroprompt zeroshot generalization focusing task scaling zeroshot promptingwhile previous model trained dozen task scale task first time using realworld data lead crucial discovery task scaling efficient alternative model scaling ie model size less impact performance extremely large number task result show task scaling improve training efficiency time flopsempirically zeroprompt substantially improves efficiency performance zeroshot learning across variety academic production datasets
paper explores task answeraware question generation based attentionbased pointer generator model propose incorporate auxiliary task language modeling help question generation hierarchical multitask learning structure jointlearning model enables encoder learn better representation input sequence guide decoder generate coherent fluent question squad marco datasets multitask learning model boost performance achieving stateoftheart result moreover human evaluation prof high quality generated question
multilingual machine translation mmt benefit crosslingual transfer challenging multitask optimization problem partly clear framework systematically learn languagespecific parameter selfsupervised learning ssl approach leverage large quantity monolingual data parallel data unavailable shown promise improving translation performance complementary task mmt task however jointly optimizing ssl mmt task even challenging work first investigate utilize intradistillation learn languagespecific parameter show importance languagespecific parameter next propose novel simple ssl task concurrent denoising cotrains mmt task concurrently denoising monolingual data encoder decoder finally apply intradistillation cotraining approach combining two approach significantly improves mmt performance outperforming three stateoftheart ssl method large margin eg improvement language language benchmark compared mass respectively
propaganda spread ideology belief likeminded people brainwashing audience sometimes leading violence semeval task aim design automated system news propaganda detection task consists two subtasks namely span identification given news article system tag specific fragment contain least one propaganda technique technique classification correctly classify given propagandist statement amongst propaganda technique subtask use contextual embeddings extracted pretrained transformer model represent text data various granularity propose multigranularity knowledge sharing approach subtask use ensemble bert logistic regression classifier linguistic feature result reveal linguistic feature strong indicator covering minority class highly imbalanced dataset
language engineering le product resource world major language steadily increasing remains major gap regard less widelyused language paper considers current situation regarding le resource language question proposal rectifying situation made including technique based adapting existing resource knowledge extraction technique machinereadable corpus
choice input text prompt play critical role performance visionlanguage pretrained vlp model clip present apollo unified multimodal approach combine adapter prompt learning visionlanguage model method designed substantially improve generalization capability vlp model finetuned fewshot setting introduce trainable crossattentionbased adapter layer conjunction vision language encoders strengthen alignment two modality enforce consistency respective encoder branch receiving augmented input prevent overfitting downstream task method evaluated three representative task generalization novel class crossdataset evaluation unseen domain shift practice apollo achieves relative gain maple sota novel class diverse image recognition datasets
writing intended inform frequently contains reference document entity de mixed class includes orthographically structured item eg illustration section list discourse entity argument suggestion point reference vital interpretation document often eschew identifier figure inexplicit phrase like figure premise examine inexplicit reference de termed de reference recast problem automatic detection determination relevant word sens show feasibility machine learning detection derelevant word sens using corpus humanlabeled synset wordnet test crossdomain performance gathering lemma synset three corpus website privacy policy wikipedia article wikibooks textbook identifying de reference enable language technology use information encoded permitting automatic generation finelytuned description de presentation richlystructured information reader
work propose new language modeling paradigm ability perform prediction moderation information flow multiple granularity neural lattice language model model construct lattice possible path sentence marginalize across lattice calculate sequence probability optimize parameter approach allows u seamlessly incorporate linguistic intuition including polysemy existence multiword lexical item language model experiment multiple language modeling task show english neural lattice language model utilize polysemous embeddings able improve perplexity relative wordlevel baseline chinese model handle multicharacter token able improve perplexity relative characterlevel baseline
paper propose brandtopic model btm aim detect brandassociated polaritybearing topic product review different existing model sentimenttopic extraction assume topic grouped discrete sentiment category positive negative neural btm able automatically infer realvalued brandassociated sentiment score generate finegrained sentimenttopics observe continuous change word certain topic eg shaver cream associated sentiment gradually varies negative positive btm built poisson factorisation model incorporation adversarial learning evaluated dataset constructed amazon review experimental result show btm outperforms number competitive baseline brand ranking achieving better balance topic coherence uniqueness extracting betterseparated polaritybearing topic
machine translation mt task automatically converting text source language text target language preserving meaning mt usually require large corpus training translation model due scarcity resource less attention given translating low resource language particular indic language direction shared task called adapmt low resource domain adaptation indic machine translation organized illustrate capability general domain mt translating indic language low resource domain adaptation mt system paper team mucs describe simple word extraction based domain adaptation approach applied englishhindi mt mt proposed model carried using opennmt popular neural machine translation tool general domain corpus built effectively combining available englishhindi corpus removing duplicate sentence domain specific corpus updated extracting sentence generic corpus contains word given domain specific corpus proposed model exhibited satisfactory result small domain specific ai che corpus provided organizer term bleu score respectively methodology quite generic easily extended low resource language pair well
development poetry generation system mainly focus enhancing capacity generation model however demand customization polishing generally ignored highly reduces scope application work present yu sheng webbased poetry generation system featured humaninloop generation framework providing various customization option user different background engage process poetry composition end propose two method train model perform constrained generation finegrained polishing automatic human evaluation result show system strong ability generate polish poetry compared vanilla model system publicly accessible urlhttpsyushengcisumedumo
although large language model llm achieved excellent performance variety evaluation benchmark still struggle complex reasoning task require specific knowledge multihop reasoning improve reasoning ability propose textbfchatcot toolaugmented chainofthought reasoning framework chatbased llm textiteg chatgpt chatcot model chainofthought cot reasoning multiturn conversation utilize tool natural way chatting turn llm either interact tool perform reasoning approach effectively leverage multiturn conversation ability chatbased llm integrate thought chain following tool manipulation unified way specially initialize early turn conversation knowledge tool task reasoning format propose iterative textittoolaugmented reasoning step perform stepbystep toolaugmented reasoning experiment result two complex reasoning datasets math hotpotqa shown effectiveness chatcot complex reasoning task achieving relative improvement stateoftheart baseline
existing sentiment analysis model achieved great advance help sufficient sentiment annotation unfortunately many language sufficient sentiment corpus end recent study proposed crosslingual sentiment analysis transfer sentiment analysis model resourcerich language lowresource language however study either rely external crosslingual supervision eg parallel corpus translation model limited crosslingual gap work based intuitive assumption relationship emojis sentiment consistent across different language investigate transferring sentiment knowledge across language help emojis end propose novel crosslingual sentiment analysis approach dubbed curriculum knowledge distiller ckd core idea ckd use emojis bridge source target language note compared text emojis transferable reveal precise sentiment thus distill multiple intermediate sentiment classifier isc source language corpus emojis get iscs different attention weight text transfer target language distill iscs target language sentiment classifier tsc following curriculum learning mechanism way tsc learn delicate sentiment knowledge meanwhile avoid affected crosslingual gap experimental result five crosslingual benchmark clearly verify effectiveness approach
paper conduct study utilize llm solution decision making requires complex data analysis define decision qa task answering best decision dbest decisionmaking question q business rule r database since benchmark examine decision qa propose decision qa benchmark dqa two scenario locating building constructed two video game europa universalis iv victoria almost goal decision qa address decision qa effectively also propose new rag technique called iterative planthenretrieval augmented generation planrag planragbased lm generates plan decision making first step retriever generates query data analysis second step proposed method outperforms stateoftheart iterative rag method locating scenario building scenario respectively release code benchmark httpsgithubcommyeonhplanrag
propose visual news captioner entityaware model task news image captioning also introduce visual news largescale benchmark consisting one million news image along associated news article image caption author information metadata unlike standard image captioning task news image depict situation people location event paramount importance proposed method effectively combine visual textual feature generate caption richer information event entity specifically built upon transformer architecture model equipped novel multimodal feature fusion technique attention mechanism designed generate named entity accurately method utilizes much fewer parameter achieving slightly better prediction result competing method larger diverse visual news dataset highlight remaining challenge captioning news image
propose method transfer knowledge across neural machine translation nmt model mean shared dynamic vocabulary approach allows extend initial model given language pair cover new language adapting vocabulary long new data become available ie introducing new vocabulary item included initial model parameter transfer mechanism evaluated two scenario adapt trained single language nmt system work new language pair ii continuously add new language pair grow multilingual nmt system scenario goal improve translation performance minimizing training convergence time preliminary experiment spanning five language different training data size ie k k parallel sentence show significant performance gain ranging bleu different language direction moreover compared training nmt model scratch transferlearning approach allows u reach higher performance training total training step
preliminary implementation aramwe hybrid project includes statistical component ccg symbolic component extract treat mwes idiom arabic eng lish parallel text presented together general sketch system thorough description statistical component proof concept ccg component
propose new sentence simplification task splitandrephrase aim split complex sentence meaning preserving sequence shorter sentence like sentence simplification splittingandrephrasing potential benefiting natural language processing societal application shorter sentence generally better processed nlp system could used preprocessing step facilitates improves performance parser semantic role labellers machine translation system also use people reading disability allows conversion longer sentence shorter one paper make two contribution towards new task first create make available benchmark consisting tuples mapping single complex sentence sequence sentence expressing meaning second propose five model vanilla sequencetosequence semanticallymotivated model understand difficulty proposed task
aim work study impact covid pandemic basque speaking twitter community applying natural language processing unsupervised technique order carry study collected publicly released biggest dataset basque tweet containing tweet september february analyze impact pandemic variability content time studied quantitative qualitative analysis word emojis quantitative analysis shift frequency term calculated using linear regression frequency hand qualitative analysis word embeddings used study change meaning significant word emojis different period pandemic multifaceted approach discovered noteworthy alteration political inclination exhibited basque user throughout course pandemic
clustering document typegrouping invoice invoice article articlesis desirable first step organizing large collection document scan human approaching task use semantics text document layout assist grouping like document layoutlm xu et al layoutaware transformer built top bert stateoftheart performance documenttype classification could reasonably expected outperform regular bert devlin et al documenttype clustering however find experimentally bert significantly outperforms layoutlm task p textless analyze cluster show layout awareness asset liability
title judithjeyafreedaandrewdravidianlangtecheacloffensive language detection dravidian codemixed youtube comment author judith jeyafreeda andrew messaging online become one major way communication level case onlinedigital bullying include rant taunt offensive phrase thus identification offensive language internet essential task paper task offensive language detection youtube comment dravidian lan guages tamil malayalam kannada seen upon mutliclass classification prob lem subjected language spe cific preprocessing several machine learn ing algorithm trained task hand paper present accuracy result development datasets machine learning model used fi nally present weighted average score test set using best performing chine learning model
recent year number text grown rapidly example reviewbased portal like yelp amazon contain thousand usergenerated review impossible human reader process even relevant document promising tool solve task text summarization existing approach however work small homogeneous english datasets account multilinguality opinion shift domain effect paper introduce research plan use neural network usergenerated travel review generate summary take account shifting opinion time outline future direction summarization address issue resolving existing problem make easier user reviewsites make informed decision
paper explores crosslingual transfer learning natural language understanding nlu focus bootstrapping arabic highresource english french language domain classification intent classification named entity recognition task adopt bertbased architecture pretrain three model using opensource wikipedia data largescale commercial datasets monolingualarabic bilingualarabicenglish trilingualarabicenglishfrench model additionally use offtheshelf machine translator translate internal data source english language target arabic language effort enhance transfer learning translation conduct experiment finetune three model nlu task evaluate large internal dataset despite morphological orthographical grammatical difference arabic source language transfer learning performance gain source language machine translation achieved realworld arabic test dataset zeroshot setting setting model finetuned labeled data target language
factual accuracy important property neural abstractive summarization model especially factcritical domain clinical literature work introduce guided continued pretraining stage encoderdecoder model improves understanding factual attribute document followed supervised finetuning summarization approach extends pretraining recipe bart incorporate additional objective based pico span capture population intervention comparison outcome related clinical study experiment multidocument summarization clinical domain demonstrate approach competitive prior work improving quality factuality summary achieving bestpublished result factual accuracy mslr task
social medium play crucial role main resource news information seeker online however unmoderated feature social medium platform lead emergence spread untrustworthy content harm individual even society current automated approach automatically determining veracity rumor generalizable novel emerging topic paper describes hybrid system comprising rule machine learning model make use replied tweet identify veracity source tweet proposed system paper achieved fmacro stance classification fmacro rmse rumor verification task task semeval
large sparse feedforward layer sffn mixtureofexperts moe proven effective scaling transformer model size pretraining large language model activating part ffn parameter conditioning input sffn improves generalization performance keeping training inference cost flop fixed work analyzed two major design choice sffn memory block aka expert size memory block selection method general conceptual framework sparse neural memory using unified framework compare several sffn architecture language modeling provide insight relative efficacy efficiency found simpler selection method avgk selects block mean aggregated hidden state achieving lower perplexity language model pretraining compared existing moe architecture including switch transformer fedus et al hashlayer roller et al
present method extracting causality knowledge wikipedia protectionism textgreater trade war cause effect entity correspond wikipedia article causality knowledge easy verify reading corresponding wikipedia article translate multiple language wikidata connect knowledge base derived wikipedia method exploit wikipedia article section describe causality redundancy stemming multilinguality wikipedia experiment showed method achieved precision recall respectively particular could extract causality whose cause effect written distantly wikipedia article released code data research
paper describe experiment morphosyntactic annotation historical language variety example middle low german mlg official language german hanse middle age dominant language around baltic sea time best knowledge first experiment automatically producing morphosyntactic annotation middle low german accordingly partofspeech po tagset currently agreed upon experiment illustrate ontologybased specification projected annotation employed circumvent issue instead training evaluating given tagset decomponse independent feature predicted independently neural network using consistency constraint axiom ontology predicted feature probability decoded sound ontological representation using representation finally bootstrap po tagset capturing morphosyntactic feature could reliably predicted way approach capable optimize precision recall morphosyntactic annotation simultaneously bootstrapping tagset rather performing iterative cycle
recently different system learn populate extend knowledge base kb web different language presented although large set concept learnt independently language used read fact expected easily gathered local language eg culture geography system merges kb learnt different language benefit complementary information long common belief identified well redundancy present web page written different language paper deal problem identifying equivalent belief concept across language specific kb assuming share ontology category relation case study two kb independently learnt different input namely web page written english web page written portuguese respectively report result two methodology approach based personalized pagerank inference technique find common relevant path kb proposed inference technique efficiently identifies relevant path outperforming baseline dictionarybased classifier vast majority tested category
language identification wellknown task natural language document paper explore search query language identification usually first task query understanding without loss generalization run experiment adobe stock search engine even though domain relatively generic adobe stock query cover broad range object concept outofthebox language identifier perform well due extremely short text found query unlike wellstudied supervised approach task examine practical approach cold start problem automatically getting largescale querylanguage pair training describe process creating weaklabeled training data humanannotated evaluation data search query language identification task effectiveness technique demonstrated training gradient boosting model language classification given query outperform open domain text model baseline large margin
present seaeval benchmark multilingual foundation model addition characterizing model understand reason natural language also investigate well comprehend cultural practice nuance value alongside standard accuracy metric investigate brittleness foundation model dimension semantics multilinguality analysis span opensourced closed model leading empirical result across classic nlp task reasoning cultural comprehension key finding indicate many model exhibit varied behavior given paraphrased instruction many model still suffer exposure bias eg positional bias majority label bias question rooted factual scientific commonsense knowledge consistent response expected across multilingual query semantically equivalent yet model surprisingly demonstrate inconsistent performance query multilinguallytrained model attained balanced multilingual capability endeavor underscore need generalizable semantic representation enhanced multilingual contextualization seaeval serve launchpad thorough investigation evaluation multilingual multicultural scenario
recent year conversational recommender system crss drawn wide attention research community focus providing highquality recommendation user via natural language conversation however due diverse scenario data format existing study crss lack unified standardized implementation comparison tackle challenge release opensource toolkit crslab provides unified extensible framework highlydecoupled module develop crss based framework collect commonly used humanannotated cr datasets implement model include advanced technique graph neural network pretraining model besides toolkit provides series automatic evaluation protocol humanmachine interaction interface evaluate compare different cr method project document released urlhttpsgithubcomrucaiboxcrslab
contrast consistency ability model make consistently correct prediction presence perturbation essential aspect nlp studied task sentiment analysis reading comprehension remains unexplored opendomain question answering openqa due difficulty collecting perturbed question satisfy factuality requirement work collect minimally edited question challenging contrast set evaluate openqa model collection approach combine human annotation large language model generation find widely used dense passage retriever dpr performs poorly contrast set despite fitting training set well performing competitively standard test set address issue introduce simple effective queryside contrastive loss aid data augmentation improve dpr training experiment contrast set demonstrate dprs contrast consistency improved without sacrificing accuracy standard test set
paper proposes method classifying type lexicalsemantic relation given pair word given inventory target relationship task seen multiclass classification problem train supervised classifier assuming specific type lexicalsemantic relation pair word would indicated carefully designed set relationspecific similarity associated word similarity could effectively computed sense representation senseconcept embeddings experimental result show proposed method clearly outperforms existing stateoftheart method utilize senseconcept embeddings thereby demonstrating effectiveness sense representation
lexical ambiguity pose one greatest challenge field machine translation last decade multiple effort undertaken investigate incorrect translation caused polysemous nature word within body research study posited model pick semantic bias existing training data thus producing translation error paper present dibimt first entirely manuallycurated evaluation benchmark enables extensive study semantic bias machine translation nominal verbal word five different language combination namely english one following language chinese german italian russian spanish furthermore test stateoftheart machine translation system commercial noncommercial one new test bed provide thorough statistical linguistic analysis result release dibimt urlhttpsnlpuniromaitdibimt closed benchmark public leaderboard
despite recent success achieved several twostage prototypical network fewshot named entity recognition ner task overdetected false span span detection stage inaccurate unstable prototype type classification stage remain challenging problem paper propose novel typeaware decomposed framework namely tadner solve problem first present typeaware span filtering strategy filter false span removing semantically far away type name present typeaware contrastive learning strategy construct accurate stable prototype jointly exploiting support sample type name reference extensive experiment various benchmark prove proposed tadner framework yield new stateoftheart performance
offensive language become pervasive social medium offensive language identification task may difficult predict accurately according surface word try dig deeper semantic information text paper present use attentionbased two layer bidirectional longshort memory neural network bilstm semantic feature extraction additionally residual connection mechanism used synthesize two different deep feature emoji attention mechanism used extract semantic information emojis text participated three subtasks semeval task cnhitmit team macroaveraged fscore subtask ranking got subtask b ranking subtask c got ranking also tried method submitting result
recent neural model datatotext generation rely massive parallel pair data text learn writing knowledge often assume writing knowledge acquired training data alone however people writing rely data also consider related knowledge paper enhance neural datatotext model external knowledge simple effective way improve fidelity generated text besides relying parallel data text previous work model attends relevant external knowledge encoded temporary memory combine knowledge context representation data generating word allows model infer relevant fact explicitly stated data table external knowledge source experimental result twentyone wikipedia infoboxtotext datasets show model kbatt consistently improves stateoftheart model datasets addition quantify external knowledge effective design metric kbgain show strong correlation observed performance boost result demonstrates relevance external knowledge sparseness original data main factor affecting system performance
present approach taken turkunlp group craft structural annotation task shared task dependency parsing approach build primarily turku neural parser native dependency parser ranked among best recent conll task parsing universal dependency adapt parser biomedical domain considered evaluated number approach including generation custom word embeddings combination indomain resource incorporation information named entity recognition achieved labeled attachment score best result among task participant
present newsome news social medium corpus set subcorpora annotation opinion expression across genre news report blog product review tweet covering multiple language english spanish catalan portuguese newsome result effort increase opinion corpus resource available language english build unifying annotation framework analyzing opinion different genre including controlled text news report well different type user generated content ugc given broad design resource annotation effort carried resorting crowdsourcing platform amazon mechanical turk crowdflower created excellent opportunity research feasibility crowdsourcing method annotating big amount text different language
recent pretrained language model solved many reading comprehension benchmark question written access evidence document however datasets containing informationseeking query evidence document provided query written independently remain challenging analyze answering informationseeking query challenging prevalent unanswerabilities arise natural question tydi qa controlled experiment suggest two headroom paragraph selection answerability prediction ie whether paired evidence document contains answer query provided gold paragraph knowing abstain answering existing model easily outperform human annotator however predicting answerability remains challenging manually annotate unanswerable example across six language make challenging answer new data conduct percategory answerability prediction revealing issue current dataset collection well task formulation together study point avenue future research informationseeking question answering dataset creation model development code annotated data publicly available urlhttpsgithubcomakariasaiunanswerableqa
recently datasetgenerationbased zeroshot learning shown promising result training taskspecific model dataset synthesized large pretrained language model plms final taskspecific model often achieves compatible even better performance plms zeroshot setting order magnitude fewer parametershowever synthetic datasets drawback long suffering lowquality issue eg low informativeness redundancy explains massive synthetic data lead better performance scenario would expect humanlabeled data improve quality dataset synthesis propose progressive zeroshot dataset generation framework progen leverage feedback taskspecific model guide generation new training data via incontext examplesextensive experiment five text classification datasets demonstrate effectiveness proposed approach also show progen achieves onpar superior performance synthetic dataset size comparing baseline method without incontext feedback
argument mining core technology enabling argument search large corpus however current approach fall short applied heterogeneous text paper present argument retrieval system capable retrieving sentential argument given controversial topic analyzing highestranked result extracted web source found system cover argument found expertcurated list argument online debate portal also identifies additional valid argument
typical medical curriculum organized hierarchy instructional objective called learning outcome los thousand los span five year study gaining thorough understanding curriculum requires learner recognize apply related los across year across different part curriculum however given large scope curriculum manually labeling related los tedious almost impossible scale paper build system learns relationship los achieve humanlevel performance lo relationship extraction task present application proposed system employed build map related los learning resource lr pertaining virtual patient case believe system help medical student grasp curriculum better within classroom well intelligent tutoring system setting
existing research generally treat chinese character minimum unit representation however chinese character representation suffer two bottleneck learning bottleneck learning benefit rich internal feature eg radical stroke parameter bottleneck individual character represented unique vector paper introduce novel representation method chinese character break bottleneck namely strokenet represents chinese character latinized stroke sequence eg concave ajaie convex aeaqe specifically strokenet map stroke specific latin character thus allowing similar chinese character similar latin representation introduction strokenet neural machine translation nmt many powerful applicable technique nonlatin language eg shared subword vocabulary learning ciphertextbased data augmentation perfectly implemented experiment widelyused nist chineseenglish wmt chineseenglish iwslt japaneseenglish nmt task show strokenet provide significant performance boost strong baseline fewer model parameter achieving bleu wmt chineseenglish task better previously reported result without using monolingual data code script freely available httpsgithubcomzjwangstrokenet
transformerbased pretrained language model bert achieved remarkable result semantic sentence matching however existing model still suffer insufficient ability capture subtle difference minor noise like word addition deletion modification sentence may cause flipped prediction alleviate problem propose novel dual attention enhanced bert dabert enhance ability bert capture finegrained difference sentence pair dabert comprises dual attention module measure soft word match introducing new dual channel alignment mechanism model affinity difference attention adaptive fusion module module us attention learn aggregation difference affinity feature generates vector describing matching detail sentence pair conduct extensive experiment wellstudied semantic matching robustness test datasets experimental result show effectiveness proposed method
french many language lack semantically annotated corpus data aim provide linguistic nlp research community gold standard senseannotated corpus french using wordnet unique beginner semantic tag thus allowing interoperability paper report first phase project focused annotation common noun resulting dataset consists french noun occurrence annotated double blind adjudicated according carefully redefined set supersenses resource released online creative common licence
advancement natural language generation raised concern potential misuse deep fake news grover model generation detection neural fake news performance automatically discriminating neural fake news surpassed gpt bert grover could face variety adversarial attack deceive detection work present investigation groveras susceptibility adversarial attack characterlevel wordlevel perturbation experiment result show even singular character alteration cause grover fail affecting target article unlimited attack attempt exposing lack robustness analyse misclassified case highlight affected word identify vulnerability within groveras encoder perform novel visualisation cumulative classification score assist interpreting model behaviour
paper revisits feature engineering approach predicting complexity level english word particular context using regression technique best submission lexical complexity prediction lcp shared task ranked rd system subtask achieved pearson correlation coefficient single word multiword expression respectively conclusion combination lexical contextual semantic feature still produce strong baseline compared human judgement
recently several type japanese english mt machine translation system developed prior using system required preediting process rewriting original text japanese could easily translated communication translated information requiring speed dissemination application system would necessarily pose problem overcome problem multilevel translation method based constructive process theory proposed paper benefit method altje described comparison conventional elementary composition method multilevel translation method emphasizing importance meaning contained expression structure ascertained capable conducting translation according meaning context processing comparative ease hopeful realizing machine translation omitting process preediting
neural machine translation shown enable inference crosslingual knowledge transfer across multiple language direction using single multilingual model focusing multilingual translation scenario work summarizes fbks participation iwslt shared task submission rely two multilingual system trained five language english dutch german italian romanian first one language direction model handle possible combination five language second multilingual system trained direction leaving others zeroshot translation direction ie representing complex inference task language pair seen training time specifically zeroshot direction dutchgerman italianromanian resulting four language combination despite small amount parallel data used training system resulting multilingual model effective even comparison model trained separately every language pair ie favorable condition compare show result two multilingual model baseline single language pair system particularly focus four zeroshot direction show multilingual model trained small data provide reasonable result furthermore investigate pivoting ie using bridgepivot language inference sourcepivottarget translation using multilingual model alternative enable zeroshot translation low resource setting
learning suitable wellperforming dialogue behaviour statistical spoken dialogue system focus research many year work based reinforcement learning employ objective measure like task success modelling reward signal use reward based user satisfaction estimation propose novel estimator show outperforms previous estimator learning temporal dependency implicitly furthermore apply novel user satisfaction estimation model live simulated experiment satisfaction estimation model trained one domain applied many domain cover similar task show applying model result higher estimated satisfaction similar task success rate higher robustness noise
paraphrase generation longstanding nlp task diverse application downstream nlp task however effectiveness existing effort predominantly relies large amount golden labeled data though unsupervised endeavor proposed alleviate issue may fail generate meaningful paraphrase due lack supervision signal work go beyond existing paradigm propose novel approach generate highquality paraphrase data weak supervision specifically tackle weaklysupervised paraphrase generation problem obtaining abundant weaklylabeled parallel sentence via retrievalbased pseudo paraphrase expansion developing metalearning framework progressively select valuable sample finetuning pretrained language model bart sentential paraphrasing task demonstrate approach achieves significant improvement existing unsupervised approach even comparable performance supervised stateofthearts
present breakingnews novel dataset approximately k news article including image text caption enriched heterogeneous metadata eg gps coordinate popularity metric tenuous connection image text news data appropriate take work intersection computer vision natural language processing next step hence hope dataset help spur progress field
gauging therapist empathy counselling important component understanding counselling quality sessionlevel empathy assessment based machine learning investigated extensively relies relatively large amount wellannotated dialogue data realtime evaluation overlooked past paper focus task lowresource utterancelevel binary empathy assessment train deep learning model heuristically constructed empathy v nonempathy contrast general conversation apply model directly therapeutic dialogue assuming correlation empathy manifested two domain show training yield poor performance general probe cause examine actual effect learning empathy contrast general conversation
lowresource machine translation suffers scarcity training data unavailability standard evaluation set number research effort target former unavailability evaluation benchmark remain major hindrance tracking progress lowresource machine translation paper introduce arabench evaluation suite dialectal arabic english machine translation compared modern standard arabic arabic dialect challenging due spoken nature nonstandard orthography large variation dialectness end pool together already available dialectal arabicenglish resource additionally build novel test set arabench offer coarse finegrained citylevel dialect category belonging diverse genre medium chat religion travel varying level dialectness report strong baseline using several training setting finetuning backtranslation data augmentation evaluation suite open wide range research frontier push effort lowresource machine translation particularly arabic dialect translation evaluation suite dialectal system publicly available research purpose
word morpheme segmentation fundamental step language documentation allow discover lexical unit language lexicon unknown however language documentation scenario linguist start blank page may already preexisting dictionary initiated manual segmentation small part data paper study weak supervision taken advantage bayesian nonparametric model segmentation experiment two low resource language mboshi japhug whose documentation still progress show weak supervision beneficial segmentation quality addition investigate incremental learning scenario manual segmentation provided sequential manner work open way interactive annotation tool documentary linguist
paper contributes growing body evidence thatwhen coupled appropriate machinelearning techniqueslinguistically motivated informationrich representation outperform onehot encoding linguistic data particular show phonological feature outperform characterbased model panphon database relating ipa segment subsegmental articulatory feature show database boost performance various nerrelated task phonologically aware neural crf model built panphon feature able perform better monolingual spanish turkish ner task characterbased model also shown work well transfer model uzbek turkish panphon feature also contribute measurably orthographytoipa conversion task
computational linguistics application multimedia service clam platform provides access computational content analysis tool multimedia material version present robust update initial prototype implementation platform sport variety image video audio text processing tool interact via common multimodal representation language named mmif multimedia interchange format describe overall architecture mmif format tool included platform process set run workflow visualization included clam evaluate aspect platform data american archive public broadcasting showing clam add metadata massdigitized multimedia collection metadata typically available implicitly largely unsearchable digitized medium archive library
coreference resolution essential natural language understanding long studied nlp recent year format question answering qa became standard machine reading comprehension mrc data collection effort eg dasigi et al attempt evaluate ability mrc model reason coreference however show coreference reasoning mrc greater challenge earlier thought mrc datasets reflect natural distribution consequently challenge coreference reasoning specifically success datasets reflect model proficiency coreference reasoning propose methodology creating mrc datasets better reflect challenge coreference reasoning use create sample evaluation set result dataset show stateoftheart model still struggle phenomenon furthermore develop effective way use naturally occurring coreference phenomenon existing coreference resolution datasets training mrc model allows u show improvement coreference reasoning ability stateoftheart model
paper investigates crucial aspect mental health exploring detection suicidal ideation spoken phone conversation caller counselor suicide prevention hotline conversation lengthy noisy cover broad range topic making challenging nlp model accurately identify caller suicidal ideation address difficulty introduce novel selfadaptive approach identifies critical utterance nlp model easily distinguish experiment use realworld lifeline transcription expertly labeled show approach outperforms baseline model overall performance fscore detecting dangerous case approach achieves significantly higher fscore compared baseline model improvement selected utterance also provide valuable insight suicide prevention research furthermore approach demonstrates versatility showing effectiveness sentiment analysis making valuable tool nlp application beyond healthcare domain
opendomain question answering openqa aim answer question text retrieval reading comprehension recently lot neural networkbased model proposed achieved promising result openqa however success model relies massive volume training data usually english available many language especially lowresource language therefore essential investigate crosslingual openqa paper construct novel dataset xqa crosslingual openqa research consists training set english well development test set eight language besides provide several baseline system crosslingual openqa including two machine translationbased method one zeroshot crosslingual method multilingual bert experimental result show multilingual bert model achieves best result almost target language performance crosslingual openqa still much lower english analysis indicates performance crosslingual openqa related similar target language english also difficult question set target language xqa dataset publicly available urlhttpgithubcomthunlpxqa
word embeddings widely used natural language processing mainly due success capturing semantic information massive corpus however creation process allow different meaning word automatically separated conflates single vector address issue proposing new model learns word sense embeddings jointly model exploit large corpus knowledge semantic network order produce unified vector space word sense embeddings evaluate main feature approach qualitatively quantitatively variety task highlighting advantage proposed method comparison stateoftheart word sensebased model
study task crossdatabase semantic parsing xsp system map natural language utterance executable sql query evaluated database unseen training recently several datasets including spider proposed support development xsp system propose challenging evaluation setup crossdatabase semantic parsing focusing variation across database schema indomain language use repurpose eight semantic parsing datasets wellstudied setting indomain training data available instead use additional evaluation data xsp system instead build system performs well spider find struggle generalize repurposed set setup uncovers several generalization challenge crossdatabase semantic parsing demonstrating need use develop diverse training evaluation datasets
annotated corpus treebanks important development parser language application well understanding language language possess scarce resource paper describe effort syntactically annotating small corpus sentence tamil language annotation similar prague dependency treebank pdt consists annotation level layer morphological layer mlayer ii analytical layer alayer layer introduce annotation scheme ie positional tagging mlayer dependency relation alayers finally discus issue treebank development tamil
paper describes contemplata annotation platform offer generic solution treebank building well treebank enrichment relation syntactic node contemplata dedicated annotation constituency tree framework includes support syntactic parser provide automatic annotation manually revised balanced strategy annotation automatic parsing manual revision allows reduce annotator workload favour data reliability paper present software architecture contemplata describes practical use eventually give two example annotation project conducted platform
propose novel deep learning model joint documentlevel entity disambiguation leverage learned neural representation key component entity embeddings neural attention mechanism local context window differentiable joint inference stage disambiguation approach thereby combine benefit deep learning traditional approach graphical model probabilistic mentionentity map extensive experiment show able obtain competitive stateoftheart accuracy moderate computational cost
pretrained language model plms achieved superhuman performance many benchmark creating need harder task introduce coda context definition alignment challenging benchmark measure natural language understanding nlu capability plms given definition context k word word task align k definition k context coda requires deep understanding context definition including complex inference world knowledge find large gap human plm performance suggesting coda measure aspect nlu sufficiently covered existing benchmark
paper describes solution social medium mining health smmh shared task participated taska taskb taskc solve problem presence twitter data used pretrained language model used training strategy involved adversarial training head layer weighted fusion etc improve performance model experimental result show effectiveness designed system task system achieved f score task b overlapping f score strict f score task c yield overlapping f strict f score respectively
performance sentence encoders significantly improved simple practice finetuning using contrastive loss natural question arises characteristic model acquire contrastive learning paper theoretically experimentally show contrastivebased sentence encoders implicitly weight word based informationtheoretic quantity informative word receive greater weight others receive less theory state lower bound optimal value contrastive learning objective norm word embedding reflects information gain associated distribution surrounding word also conduct comprehensive experiment using various model multiple datasets two method measure implicit weighting model integrated gradient shap two informationtheoretic quantity information gain selfinformation result provide empirical evidence contrastive finetuning emphasizes informative word
subevent relation extraction sre task information extraction aim recognize spatial temporal containment relation event mention text recent method utilized pretrained language model represent input text sre however key issue existing sre method employment sequential order word text feed representation learning method thus unable explicitly focus important context word interaction enhance representation work introduce new method sre learns induce effective graph structure input text boost representation learning method feature word alignment framework dependency path optimal transport identify important context word form effective graph structure sre addition enable sre research nonenglish language present new multilingual sre dataset five typologically different language extensive experiment reveal stateoftheart performance method different datasets language
german richer system inflectional morphology english cause problem current approach statistical word alignment using giza reference implementation ibm model hmmbased alignment ibm model measure impact normalizing inflectional morphology germanenglish statistical word alignment demonstrate normalizing inflectional morphology improves perplexity model reduces alignment error
much recent work training neural attention model sequencelevel using either reinforcement learningstyle method optimizing beam paper survey range classical objective function widely used train linear model structured prediction apply neural sequence sequence model experiment show loss perform surprisingly well slightly outperforming beam search optimization like like setup also report new state art result iwslt germanenglish translation well gigaword abstractive summarization large wmt englishfrench task sequencelevel training achieves bleu par state art
seen success machine assisted captioning translation voiceovers also seen embarrassing error engine reallife usage course somewhere two session show couple reallife example speech text stt machine translation mt text speech tt using neural voice look would expect perfect candidate automatic speech recognition asr using multiple commercial engine seeing well transferred multiple mt engine also see usage audiovisual translation different standard text translation also give brief demo well modern neural voice perform multiple language based input avt timed text vtt format file
tackle task building supervised event trigger identification model generalize better across domain work leverage adversarial domain adaptation ada framework introduce domaininvariance ada us adversarial training construct representation predictive trigger identification predictive example domain requires labeled data target domain making completely unsupervised experiment two domain english literature news show ada lead average f score improvement outofdomain data best performing model berta reach f across domain using labeled target data preliminary experiment reveal finetuning labeled data followed selftraining lead substantial improvement reaching f literature news respectively
work describes participation universidad autonoma de chihuahua instituto nacional de astrofisica optica electronica team social medium mining health application smmh shared task team participated task focused automatic classification twitter post related covid task oriented solving binary classification problem trying identify selfreporting tweet potential case covid task objective classify tweet containing covid symptom task used model based bidirectional encoder representation transformer bert objective determine model pretrained corpus domain interest outperform one trained much larger general domain corpus f result encouraging task respectively achieved highest score among participant latter
revisit idea mining wikipedia order generate namedentity annotation propose new methodology applied english wikipedia build winer large high quality annotated corpus evaluate usefulness ner task comparing popular stateofthe art approach show lstmcrf approach benefit corpus report impressive gain model using small portion winer top conll training material last propose simple efficient method exploiting full range winer leading improvement
allowing human communicate natural language robot requires connection word percept process creating connection called symbol grounding studied nearly three decade although many study conducted many considered grounding synonym employed algorithm either work offline supervised manner paper crosssituational learning based grounding framework proposed allows grounding word phrase corresponding percept without human supervision online ie require explicit training phase instead update obtained mapping every new encountered situation proposed framework evaluated interaction experiment human tutor robot compared existing unsupervised grounding framework result show proposed framework able ground word corresponding percept online unsupervised manner outperforming baseline framework
unsupervised neural machine translation unmt recently attracted great interest machine translation community main advantage unmt lie easy collection required large training text sentence slightly worse performance supervised neural machine translation requires expensive annotated translation pair translation task study umnt trained clean data without considering robustness noisy data however realworld scenario usually exists noise collected input sentence degrades performance translation system since unmt sensitive small perturbation input sentence paper first time explicitly take noisy data consideration improve robustness unmt based system first clearly defined two type noise training sentence ie word noise word order noise empirically investigate effect unmt propose adversarial training method denoising process unmt experimental result several language pair show proposed method substantially improved robustness conventional unmt system noisy scenario
large scale pretrained language model pose challenge deployment various device growing emphasis method compress model particularly knowledge distillation however current knowledge distillation method rely model intermediate layer feature golden label also called hard label usually require aligned model architecture enough labeled data respectively moreover parameter vocabulary usually neglected existing method address problem propose general language model distillation glmd method performs twostage word prediction distillation vocabulary compression simple surprisingly show extremely strong performance specifically glmd support general application scenario eliminating constraint dimension structure model need labeled datasets absence intermediate layer golden label meanwhile based longtailed distribution word frequency data glmd design strategy vocabulary compression decreasing vocabulary size instead dimensionality experimental result show method outperforms stateoftheart method superglue benchmark achieving average score surpasses best method
evaluating factuality longform text generated large language model lm nontrivial generation often contain mixture supported unsupported piece information making binary judgment quality inadequate human evaluation timeconsuming costly paper introduce factscore new evaluation break generation series atomic fact computes percentage atomic fact supported reliable knowledge source conduct extensive human evaluation obtain factscores people biography generated several stateoftheart commercial lmsinstructgpt chatgpt retrievalaugmented perplexityaiand report new analysis demonstrating need finegrained score eg chatgpt achieves since human evaluation costly also introduce automated model estimate factscore using retrieval strong language model less error rate finally use automated metric evaluate generation new set recent lm would cost k evaluated human various finding gpt chatgpt factual public model vicuna alpaca best public model factscore available public use via pip install factscore
advent social medium brought along novel way communication meaning composed combining short text message visual enhancement socalled emojis describe system participating semeval task multilingual emoji prediction approach relies combining rich set various type feature semantic metadata important type turned metadata feature subtask emoji prediction english primary submission obtain map precision recall accuracy
paper present two different system semeval shared task assessing humor edited news headline subtask aim estimate intensity humor generated edited headline first system featurebased machine learning system combine different type information eg word embeddings string similarity partofspeech tag perplexity score named entity recognition nu support vector regressor nusvr second system deep learningbased approach us pretrained language model roberta learn latent feature news headline useful predict funniness headline latter system also final submission competition ranked seventh among participating team rootmeansquare error rmse
critical task question answering final answer selection stage combine multiple signal available answer candidate paper proposes evinets novel neural network architecture factoid question answering evinets score candidate answer entity combining available supporting evidence eg structured knowledge base unstructured text document evinets represents piece evidence dense embeddings vector score relevance question aggregate support candidate predict final score component generic allows plugging variety model semantic similarity scoring information aggregation demonstrate effectiveness evinets experiment existing trec qa wikimovies benchmark new yahoo answer dataset introduced paper evinets extended information type could facilitate future work combining evidence signal joint reasoning question answering
question answering qa system return concise answer answer list based natural language text us given context document many resource go curating qa datasets advance development robust qa model surge qa datasets language english different lowresource language like amharic indeed published publicly available amharic qa dataset hence foster research lowresource qa present first publicly available benchmarking amharic question answering dataset amhquad crowdsource questionanswer pair amharic wikipedia article using training set finetune xlmrbased language model introduce new reader model leveraging newly finetuned reader run baseline model spark opendomain amharic qa research interest best performing baseline qa achieves fscore retrieverreader reading comprehension setting
paper describes architecture novel multilayer long text summarizer mllts system proposed task creative writing summarization typically writing long often spanning page summarizers available online either equipped enough handle long text even able generate summary quality poor proposed mllts system handle difficulty splitting text several part part subjected different existing summarizers multilayer network constructed establishing linkage different part training phase several hyperparameters finetuned system achieved good rouge score test data supplied contest
work describe system submission semeval task nlp contribution graph challenge attempt three subtasks challenge report result subtask aim identify contributing sentence given publication subtask follows subtask extract scientific term predicate phrase identified contributing sentence final subtask entail extracting textittriples subject predicate object phrase categorizing one defined information unit nlpcontributiongraph shared task organizer formalized building scholarly contributionsfocused graph nlp scholarly article automated task approach include bertbased classification model identifying contributing sentence research publication rulebased dependency parsing phrase extraction followed cnnbased model information unit classification set rule triple extraction quantitative result show obtain th th th rank respectively three evaluation phase make code available urlhttpsgithubcomhardikarorasemevalinnovators
although neural machine translation nmt achieved significant progress recent year previous nmt model depend source text generate translation inspired success templatebased syntaxbased approach field propose use extracted template tree structure soft target template guide translation procedure order learn syntactic structure target sentence adopt constituencybased parse tree generate candidate template incorporate template information encoderdecoder framework jointly utilize template source text experiment show model significantly outperforms baseline model four benchmark demonstrates effectiveness soft target template
introduce greybox adversarial attack defence framework sentiment classification address issue differentiability label preservation input reconstruction adversarial attack defence one unified framework result show trained attacking model capable generating highquality adversarial example substantially faster one order magnitude less time stateoftheart attacking method example also preserve original sentiment according human evaluation additionally framework produce improved classifier robust defending multiple adversarial attacking method code available urlhttpsgithubcomibmaurnlpadvdeftextdist
paper describes curriculum teaching linguist apply machineintheloop mitl approach documentary descriptive task also share observation learning participant primarily noncomputational linguist interact mitl approach found prefer cleaning increasing training data proceed reanalyze analytical decision finally undertaking small action emphasize analytical strategy overall participant display understanding curriculum cover fundamental concept machine learning statistical modeling
feature attribution method popular explaining neural network prediction often evaluated metric comprehensiveness sufficiency paper highlight intriguing property metric solvability concretely define problem optimizing explanation metric solved beam search observation lead obvious yet unaddressed question use explainers eg lime based solving target metric metric value represents explanation quality present series investigation showing strong performance beam search explainer discus broader implication definitionevaluation duality interpretability concept implement explainer release python solvex package model text image tabular domain
new event emerge time influencing topic rumor social medium current rumor detection benchmark use random split training development test set typically result topical overlap consequently model trained random split may perform well rumor classification previously unseen topic due temporal concept drift paper provide reevaluation classification model four popular rumor detection benchmark considering chronological instead random split experimental result show use random split significantly overestimate predictive performance across datasets model therefore suggest rumor detection model always evaluated using chronological split minimizing topical overlap
back translation bt widely used field machine translation proved effective enhancing translation quality however bt mainly improves translation input share similar style specific translationliked input since source side bt data machinetranslated natural input bt brings slight improvement sometimes even adverse effect address issue propose text style transfer back translation tst bt us style transfer modify source side bt data making style sourceside text natural aim improve translation natural input experiment various language pair including highresource lowresource one demonstrate tst bt significantly improves translation performance popular bt benchmark addition tst bt proved effective domain adaptation strategy regarded generalized data augmentation method training code text style transfer model opensourced
release internationalized annotation human evaluation bundle called textinator along documentation video tutorial textinator allows annotating data wide variety nlp task user interface offered multiple language lowering entry threshold domain expert latter fact quite rare feature among annotation tool allows controlling possible unintended bias introduced due hiring englishspeaking annotator illustrate rarity feature presenting thorough systematic comparison textinator previously published annotation tool along different ax internationalization one encourage researcher design human evaluation starting annotate data textinator offer easytouse tool human evaluation allowing importing survey potentially hundred evaluation item one click finish presenting several use case annotation evaluation project conducted using prerelease version textinator presented use case represent textinators full annotation evaluation capability interested reader referred online documentation information
collecting data training dialog system extremely expensive due involvement human participant need extensive annotation especially documentgrounded dialog system human expert need carefully read unstructured document answer user question result existing documentgrounded dialog datasets relatively smallscale obstruct effective training dialogue system paper propose automatic data augmentation technique grounded document generative dialogue model dialogue model consists user bot agent bot synthesize diverse dialogue given input document used train downstream model supplementing original dataset method achieves significant improvement traditional data augmentation method also achieve great performance lowresource setting
reranking model enable integration rich feature select better output hypothesis within nbest list lattice model long history nlp revisit discriminative reranking modern neural machine translation model training large transformer architecture take input source sentence well list hypothesis output ranked list reranker trained predict observed distribution desired metric eg bleu nbest list since discriminator contains hundred million parameter improve generalization using pretraining data augmentation technique experiment four wmt direction show discriminative reranking approach effective complementary existing generative reranking approach yielding improvement bleu beam search output
language rich morphology often introduce sparsity language processing task morphological analyzer reduce sparsity providing morphemelevel analysis word often introduce ambiguity returning multiple analysis surface form problem disambiguating morphological parses complicated fact correct parse word dependent surface form also word context paper present languageagnostic approach morphological disambiguation address problem using context morphological disambiguation presenting several lstmbased neural architecture encode longrange surfacelevel analysislevel contextual dependency applied approach turkish russian arabic compare effectiveness across language matching stateoftheart result two three language result also demonstrate context play role learning disambiguate type amount context needed varies language
modular design encourages neural model disentangle recombine different facet knowledge generalise systematically new task work assume task associated subset latent skill arbitrary size inventory turn skill corresponds parameterefficient sparse lowrank model adapter jointly learning adapter routing function allocates skill task full network instantiated average parameter active skill propose several inductive bias encourage reusage composition skill including variablesize skill allocation dualspeed learning rate evaluate latentskill model two main setting multitask reinforcement learning instruction following level babyai platform fewshot finetuning language model nlp task crossfit benchmark find modular design network enhances sample efficiency reinforcement learning fewshot generalisation supervised learning compared series baseline include model parameter fully shared taskspecific conditionally generated hyperformer sparse mixtureofexperts taskmoe
modern model event causality detection ecd mainly based supervised learning small handlabeled corpus however handlabeled training data expensive produce low coverage causal expression limited size make supervised method hard detect causal relation event solve data lacking problem investigate data augmentation framework ecd dubbed knowledge enhanced distant data augmentation knowdis experimental result two benchmark datasets eventstoryline corpus causaltimebank show knowdis augment available training data assisted lexical causal commonsense knowledge ecd via distant supervision method outperforms previous method large margin assisted automatically labeled training data
local coherence relation two phrasessentences causeeffect contrast give strong influence whether text wellstructured paper follows assumption present method scoring text clarity utilizing local coherence adjacent sentence hypothesize contextual feature coherence relation learned utilizing different data target training data also possible discriminate wellstructured target text thus help score text clarity propose text clarity scoring method utilizes local coherence analysis outdomain setting ie training data source target task different method language model pretraining bert firstly train local coherence model auxiliary manner retrains together clarity text scoring model experimental result using peerread benchmark dataset show improvement compared single model scoring text clarity model source code available online
assessing summary demanding yet useful task provides valuable information language competence especially second language learner consider automated scoring collegelevel summary writing task english second language el adopt readingforunderstanding ru cognitive framework extended readingtowrite rw element use analytic scoring six rubric covering content writing quality show regression model referencebased linguistic feature considerably outperform baseline across rubric moreover find interesting correlation summary feature analytic rubric revealing link ru rw construct
nonnegative randomized word embedding propose word embedding method based novel random projection technique show weighting method positive pointwise mutual information ppmi applied model construction reduced dimensionality hence proposed technique efficiently transfer word onto semantically discriminative space demonstrating high computational performance besides benefit ease update simple mechanism interoperability report performance method several task show yield competitive result compared neural embedding method monolingual corpusbased setup
study continual learning natural language instruction generation observing human user instruction execution focus collaborative scenario system act delegate task human user using natural language compare user execution generated instruction original system intent indication system success communicating intent show use signal improve system ability generate instruction via contextual bandit learning interaction real user system demonstrates dramatic improvement ability generate language time
paper detail approach task detecting reportage adverse drug reaction tweet part social medium mining healthcare application shared task employed combination three type word representation input lstm model approach achieved f score
paper investigates evolution computational linguistics domain quantitative analysis acl anthology containing around paper published approach combine complex system method natural language processing technique reconstruct sociosemantic landscape domain inferring coauthorship semantic network analysis corpus first keywords extracted using hybrid approach mixing linguistic pattern statistical information semantic network built using cooccurrence analysis keywords within corpus combining temporal network analysis technique able examine main evolution field active subfields time lastly propose model explore mutual influence social semantic network time leading sociosemantic coevolutionary system
paper describes electronic variant popular word game alias people guess word according association via synonym opposite hyperonyms etc lexical data come estonian wordnet computer game alias draw information estonian wordnet useful least two reason creates opportunity learn language play help evaluate improve quality estonian wordnet
main obstacle incremental sentence processing arises rightbranching constituent structure present majority english sentence well optional constituent adjoin right right adjunct right conjuncts ccg many rightbranching derivation replaced semantically equivalent leftbranching incremental derivation problem rightadjunction resistant solution tackled past using revealingbased approach often rely either higherorder unification lambda term pareschi steedman heuristic dependency representation cover whole ccgbank ambati et al propose new incremental parsing algorithm ccg following revealing tradition work purely syntactic approach depend access distinct level semantic representation algorithm cover whole ccgbank greater incrementality accuracy previous proposal
finding counterevidence statement key many task including counterargument generation build system given statement retrieves counterevidence diverse source web core system natural language inference nli model determines whether candidate sentence valid counterevidence nli model date however lack proper reasoning ability necessary find counterevidence involves complex inference thus present knowledgeenhanced nli model aim handle causality examplebased inference incorporating knowledge graph nli model outperforms baseline nli task especially instance require targeted inference addition nli model improves counterevidence retrieval system notably finding complex counterevidence better
natural language appealing medium explaining large language model process store information evaluating faithfulness explanation challenging help address develop two mode evaluation natural language explanation claim individual neuron represent concept text input observational mode evaluate claim neuron activates input string refer concept picked proposed explanation e intervention mode construe e claim neuron causal mediator concept denoted e apply framework gptgenerated explanation gpt xl neuron bill et al show even confident explanation high error rate little causal efficacy close paper critically assessing whether natural language good choice explanation whether neuron best level analysis
article present experiment pseudonymised swedish clinical text used training data deidentify real clinical text future aim transfer nonsensitive training data hospital conditional random field cfr long shortterm memory lstm machine learning algorithm used train deidentification model two model trained pseudonymised data evaluated real data benchmarking model also trained real data evaluated real data well trained pseudonymised data evaluated pseudonymised data crf showed better performance phi information like date part first name last name consistent report literature contrast poor performance location health care unit information noted partially due constrained vocabulary pseudonymised training data concluded possible train transferable model based pseudonymised swedish clinical data even small narrative distributional variation could negatively impact performance
crossdocument event coreference resolution cdcr task identifying event mention refer event throughout collection document annotating cdcr data arduous expensive process explaining existing corpus small lack domain coverage overcome bottleneck automatically extract event coreference data hyperlink online news referring significant realworld event writer often add hyperlink another article covering event demonstrate collecting hyperlink point article produce extensive highquality cdcr data create corpus document silverstandard event mention called hypercoref evaluate stateoftheart system three cdcr corpus find model trained small subset hypercoref highly competitive performance similar model trained goldstandard data work free cdcr research depending costly humanannotated training data open possibility research beyond english cdcr data extraction approach easily adapted language
recent development large language model llm manifested significant advancement facilitate safeguard malicious exploitation body research concentrated aligning llm human preference inhibiting generation inappropriate content unfortunately alignment often vulnerable finetuning minimal amount harmful data easily unalign target llm effective finetuningbased unalignment approach also limitation nonstealthiness finetuning safety audit redteaming easily expose potential weakness unaligned model thereby precluding releaseuse nonpersistence unaligned llm easily repaired realignment ie finetuning aligned data point work show possible conduct stealthy persistent unalignment large language model via backdoor injection also provide novel understanding relationship backdoor persistence activation pattern provide guideline potential trigger design extensive experiment demonstrate proposed stealthy persistent unalignment successfully pas safety evaluation maintaining strong persistence realignment defense
present norwegian anaphora resolution corpus narc first publicly available corpus annotated anaphoric relation noun phrase norwegian paper describes annotated data document norwegian bokmaal together interannotator agreement discussion relevant statistic also present preliminary modelling result comparable existing corpus language discus relevant problem relation modelling annotation
current approach natural language generation nlg dialog mainly focus domainspecific taskoriented application eg restaurant booking using limited ontology slot type usually without considering previous conversation context furthermore approach require large amount data domain benefit example may available domain work explores feasibility applying statistical nlg scenario requiring larger ontology multidomain dialog application opendomain question answering qa based knowledge graph model nlg encoderdecoder framework using large dataset interaction realworld user conversational agent opendomain qa first investigate impact increasing number slot type generation quality experiment different partition qa data progressively larger ontology slot type second perform multitask learning experiment opendomain qa taskoriented dialog benchmark model popular nlg dataset moreover experiment using conversational context additional input improve response generation quality experiment show feasibility learning statistical nlg model opendomain qa larger ontology
propose multioped opendomain news editorial corpus support various task pertaining argumentation structure news editorial focusing automatic perspective discovery news editorial genre persuasive text argumentation structure usually implicit however argument presented editorial typically center around concise focused thesis refer perspective multioped aim supporting study multiple task relevant automatic perspective discovery system expected produce singlesentence thesis statement summarizing argument presented argue identifying abstracting natural language perspective editorial crucial step toward studying implicit argumentation structure news editorial first discus challenge define conceptual task towards goal demonstrate utility multioped induced task study problem perspective summarization multitask learning setting case study show induced task auxiliary task improve quality perspective summary generated hope multioped useful resource future study argumentation news editorial domain
paper focus automatic detection hidden intention speaker question asked meal corpus composed set transcript spontaneous oral conversation eslos corpus suggest typology intention based research work exploration annotation corpus define two explicit category request agreement request information three implicit category opinion doubt implement supervised automatic classification model based annotated data selected linguistic feature evaluate result performance finally try interpret result looking deeply specifically prediction algorithm feature used many motivation work part ongoing challenge opinion analysis irony detection development conversational agent
neural document rerankers extremely effective term accuracy however best model require dedicated hardware serving costly often feasible avoid servingtime requirement present method capturing gain transformer crossattention model lexicalized scoring function requires transformer flop per document served using commodity cpu combined bm retriever approach match quality stateofthe art dual encoder retriever still requires accelerator query encoding introduce nail nonautoregressive indexing language model model architecture compatible recent encoderdecoder decoderonly large language model gpt palm model architecture leverage existing pretrained checkpoint finetuned efficiently constructing document representation require neural processing query
speech disfluency hypothesized occur word less predictable therefore cognitively demanding paper revisit hypothesis using openais gpt calculate predictability word language model perplexity using switchboard corpus find disfluency occur highest second highest within one token highest perplexity distribution random also show disfluency precede word significantly higher perplexity fluent context based result offer new evidence disfluency likely occur less predictable word
understanding emotion people express largescale crisis help inform policy maker first responder emotional state population well provide emotional support need support present covidemo dataset textasciitilde english tweet labeled emotion temporally distributed across month analysis reveal emotional toll caused covid change social narrative associated emotion time motivated timesensitive nature crisis cost largescale annotation effort examine well large pretrained language model generalize across domain timeline task perceived emotion prediction context covid analysis suggest crossdomain information transfer occur yet still significant gap propose semisupervised learning way bridge gap obtaining significantly better performance using unlabeled data target domain
existing machine translation system operate level word relying explicit segmentation extract token introduce neural machine translation nmt model map source character sequence target character sequence without segmentation employ characterlevel convolutional network maxpooling encoder reduce length source representation allowing model trained speed comparable subwordlevel model capturing local regularity charactertocharacter model outperforms recently proposed baseline subwordlevel encoder wmt deen csen give comparable performance fien ruen demonstrate possible share single characterlevel encoder across multiple language training model manytoone translation task multilingual setting characterlevel encoder significantly outperforms subwordlevel encoder language pair observe csen fien ruen quality multilingual characterlevel translation even surpasses model specifically trained language pair alone term bleu score human judgment
spontaln corpus spontaneous interactional norwegian knowledge first corpus norwegian majority speaker spent significant part life sweden recorded speech display varying degree interference swedish corpus consists studio quality audio videorecordings four minute free conversation acquaintance manual orthographic transcription entire material basis orthographic transcription automatically annotated approximately percent material phoneme level mean forced alignment acoustic signal pronunciation listed dictionary approximately seven percent automatic transcription manually corrected taking manual correction gold standard evaluated several source pronunciation variant automatic transcription spontaln intended general purpose speech resource also suitable investigating phonetic detail
multidocument summarization challenging task exists little largescale datasets propose multixscience largescale multidocument summarization dataset created scientific article multixscience introduces challenging multidocument summarization task writing relatedwork section paper based abstract article reference work inspired extreme summarization dataset construction protocol favour abstractive modeling approach descriptive statistic empirical resultsusing several stateoftheart model trained multixscience datasetreveal multixscience well suited abstractive model
accessing structured data form ontology requires training learning formal query language eg serql sparql pose significant difficulty nonexpert user one way lower learning overhead make ontology query straightforward natural language interface nli existing nlis structured data reasonable performance tend require expensive customisation new domain ontology additionally often require specific adherence predefined syntax turn mean user still undergo training paper present questionbased interface ontology questio tool querying ontology using unconstrained languagebased query questio simple interface requires user training easily embedded system used ontology knowledge base without prior customisation
submission sigmorphon shared task morpheme segmentation study whether unsupervised morphological segmentation method morfessor help supervised setting previous research shown effectiveness approach semisupervised setting small amount labeled data current task vary data size amount wordlevel annotated training data much larger amount sentencelevel annotated training data remains small approach presegment input data neural sequencetosequence model unsupervised method unsupervised method trained raw text data use wikipedia increase amount training data addition train multilingual model sentencelevel task result morfessorenriched feature mixed showing benefit three sentencelevel task wordlevel task multilingual training yield considerable improvement monolingual sentencelevel model negates effect enriched feature
leveraging contextual knowledge become standard practice automated claim verification yet impact temporal reasoning largely overlooked study demonstrates time positively influence claim verification process evidencebased factchecking temporal aspect relation claim evidence first established grounding shared timeline constructed using publication date time expression extracted text temporal information provided rnnbased transformerbased classifier claim evidence encoding timeaware factchecking model surpass base model micro f macro f multifc dataset also outperform prior method explicitly model temporal relation evidence finding show presence temporal information manner timeline constructed greatly influence factchecking model determine relevance supporting refuting character evidence document
incrementality ubiquitous humanhuman interaction beneficial humancomputer interaction topic research different part nlp community mostly focus specific topic hand even though incremental system deal similar challenge regardless domain survey consolidate categorize approach identifying similarity difference computation data show tradeoff considered focus lie evaluating incremental system standard metric often fail capture incremental property system coming suitable evaluation scheme nontrivial
show leveraging metadata information web page improve performance model answer passage selectionreranking propose neural passage selection model leverage metadata information finegrained encoding strategy learns representation metadata predicate hierarchical way model evaluated m marco nguyen et al recipemarco datasets result show model significantly outperform baseline model incorporate metadata also show finegrained encoding advantage strategy encoding metadata
discourse segmentation sentencelevel discourse parsing play important role various nlp task consider textual coherence despite recent achievement task still room improvement due scarcity labeled data solve problem propose language modelbased generative classifier lmgc using information label treating label input enhancing label representation embedding description label moreover since enables lmgc make ready representation label unseen pretraining step effectively use pretrained language model lmgc experimental result rstdt dataset show lmgc achieved stateoftheart f score discourse segmentation achieved stateoftheart relation f score gold edu boundary automatically segmented boundary respectively sentencelevel discourse parsing
probing study extensively explored neural language model linguistic information located standard approach interpreting result probing classifier focus layer whose representation give highest performance probing task propose alternative method asks taskrelevant information emerges model framework consists family metric explicitly model local information gain relative previous layer layer contribution model overall performance apply new metric two pair syntactic probing task different degree complexity find metric confirm expected ordering one pair local metric show massive dominance first layer indicating feature contribute probing task highlevel global metric suggest
relation schema induction rsi problem identifying type signature argument relation unlabeled text previous work area focused binary rsi ie inducing subject object type signature per relation however practice many relation highorder ie two argument inducing type signature argument necessary example sport domain inducing schema winwinningplayer opponentplayer tournament location informative inducing winwinningplayer opponentplayer refer problem higherorder relation schema induction hrsi paper propose tensor factorization backoff aggregation tfba novel framework hrsi problem best knowledge first attempt inducing higherorder relation schema unlabeled text using experimental analysis three real world datasets show tfba help dealing sparsity induce higherorder schema
past work relation extraction focused binary relation single sentence recent nlp inroad highvalue domain sparked interest general setting extracting nary relation span multiple sentence paper explore general relation extraction framework based graph long shortterm memory network graph lstms easily extended crosssentence nary relation extraction graph formulation provides unified way exploring different lstm approach incorporating various intrasentential intersentential dependency sequential syntactic discourse relation robust contextual representation learned entity serf input relation classifier simplifies handling relation arbitrary arity enables multitask learning related relation evaluate framework two important precision medicine setting demonstrating effectiveness conventional supervised learning distant supervision crosssentence extraction produced larger knowledge base multitask learning significantly improved extraction accuracy thorough analysis various lstm approach yielded useful insight impact linguistic analysis extraction accuracy
year greyc translation system improved translation memory designed scratch experiment approach whose goal improve output standard translation memory making heavy use subsentential alignment restricted case translation analogy track system participated btec track arabic english chinese english turkish english
one main driver recent advance authorship verification pan largescale authorship dataset despite generating significant progress field inconsistent performance difference closed open test set reported end improve experimental setup proposing five new public split pan dataset specifically designed isolate identify bias related text topic author writing style evaluate several bertlike baseline split showing model competitive authorship verification stateoftheart method furthermore using explainable ai find baseline biased towards named entity show model trained without named entity obtain better result generalize better tested darkreddit new dataset authorship verification
human expertise participation speech community essential factor success technology lowresource language accordingly propose new computational task tuned available knowledge interest indigenous community support construction high quality text lexicon task illustrated kunwinjku morphologicallycomplex australian language combine finite state implementation published grammar partial lexicon apply noisy phone representation signal locate known lexeme signal use morphological transducer build hypothetical morphologicallycomplex word human validation show applying single iteration method result relative transcription density gain find breath group test set receive least one correct partial fullword suggestion
performing data augmentation using large language model llm common approach directly generate large number new sample based original dataset model trained integration augmented dataset original dataset however data generation demand extensive computational resource study propose minida minimized data augmentation method leverage feedback target model training process select challenging sample validation set augmentation experimental result show text classification task using little percent original augmentation volume minida achieve performance comparable full data augmentation intent detection task significantly improving data computational resource utilization efficiency
paper procedure production sentence described producing written sentence particular language starting formal representation meaning brief description internal representation used algorithm presented result future trend discussed
transfer learning domain adaptive learning applied various field including computer vision eg image recognition natural language processing eg text classification one benefit transfer learning learn effectively efficiently limited labeled data pretrained model shared task identifying categorizing offensive language social medium preprocess dataset according language behavior social medium adapt finetune bidirectional encoder representation transformer bert pretrained google ai language team team nuli win first place st subtask offensive language identification ranked th th subtask b automatic categorization offense type subtask c offense target identification respectively
recognizing distinguishing antonym type semantic relation essential part language understanding system paper present novel method deriving antonym pair using paraphrase pair containing negation marker propose neural network model antnet integrates morphological feature indicative antonymy pathbased relation detection algorithm demonstrate model outperforms stateoftheart model distinguishing antonym semantic relation capable efficiently handling multiword expression
order apply computational linguistic analysis pas information downstream application transcription speech obtained via automatic speech recognition asr need divided smaller meaningful unit task refer speechunit su delimitation closely recreate automatic delimitation system described lee glass sentence detection using multiple annotation proceeding interspeech combine prosodic model language model speechunit length model loglinear fashion since stateoftheart natural language processing nlp tool developed deal written text characteristic sentencelike unit su delimitation help bridge gap asr nlp normalising spoken data canonical format previous work focused native speaker recording test system lee glass nonnative speaker learner data achieving performance stateoftheart also consider alternative evaluation metric move away idea single truth su delimitation frame work context downstream nlp application
reader choose adventure novel user modern virtual assistant subtle similarity may right lens viewed engaging work interactive fiction literary form emerged grown like vine along branch modern technology one guided advance work weave together thread interactive fiction community neural semantic parsing dialog system defining data model necessary algorithm novel type interactive fiction open sourcing accompanying authoring tool specifically work integrates retrieval based semantic parsing predicate branching story structure well known interactive fiction community relaxing relatively strict lexical option preexisting system
paper describes expansion finite state transducer fst transitive verb system tsuutina iso sr dene athabaskan language spoken alberta canada dene language unique templatic morphology lexical inflectional derivational tier interlaced drawing data close verbal form expanded model handle great range common rare argument structure type including ditransitive uniquely dene object experiencer verb challenge speed remain expansion show ability fst modelling handle morphology type expnded fst show great promise community language application morphologically informed online dictionary word predictor fst development paper describes expansion finite state transducer fst transitive verb system tsuutina iso sr dene athabaskan language spoken alberta canada dene language unique templatic morphology lexical inflectional derivational tier interlaced drawing data verb form expanded model handle great range common rare argument structure type including ditransitive uniquely dene object experiencer verb challenge speed remain expansion show ability fst modelling handle morphology type expnded fst show great promise community language application morphologically informed online dictionary word predictor fst development
commonsense knowledge widely considered building intelligent opendomain dialogue agent aiming generate meaningful diverse response previous work field usually lack ability effectively obtain utilize auxiliary commonsense external visual world paper argue exploiting logical information image related context effective enrich steer generation process view propose victor contextrelevant visual commonsense enhanced dialogue generator generating coherent informative response obtain associated visual commonsense devise novel approach expands topic word knowledge graph map daily scenario generation model adopts multimodal fusion mechanism integrate visual textual information adaptively combine decoding distribution better response generation experimental result two public datasets show proposed method outperforms latest competitive method term coherence diversity
thanks strong representation power neural encoders neural chartbased parser achieved highly competitive performance using local feature recently shown nonlocal feature crf structure lead improvement paper investigate injecting nonlocal feature training process local spanbased parser predicting constituent ngram nonlocal pattern ensuring consistency nonlocal pattern local constituent result show simple method give better result selfattentive parser ptb ctb besides method achieves stateoftheart bertbased performance ptb f strong performance ctb f parser also outperforms selfattentive parser multilingual zeroshot crossdomain setting
relish project promotes languageoriented research addressing twopronged problem lack harmonization digital standard lexical information europe america lack interoperability among existing lexicon endangered language particular created shoeboxtoolbox lexicon building software cooperation partner relish project university frankfurt fra max planck institute psycholinguistics mpi nijmegen eastern michigan university host linguist list ilit project aim harmonizing key european american digital standard whose divergence hitherto impeded international collaboration language technology resource creation analysis well web service archive access focusing several lexicon endangered language project establish unified way referencing lexicon structure linguistic concept develop procedure migrating heterogeneous lexicon standardscompliant format developed procedure generalizable large store lexical resource involved lego dobes project
answering factual question heterogenous source graph text key capacity intelligent system current approach either perform question answering text structured source separate pipeline followed merge step ii provide early integration giving strength particular information source solve problem present humaniq method teach language model dynamically combine retrieved information imitating human use retrieval tool approach couple generic method gathering human demonstration tool use adaptive fewshot learning tool augmented model show humaniq confers significant benefit including reducing error rate strongest baseline gpt across benchmark ii improving human preference response vanilla gpt win tie loss iii outperforming numerous taskspecific baseline
found transformerbased language model ability perform basic quantitative reasoning paper propose method studying model internally represent numerical data use proposal analyze albert family language model specifically extract learned embeddings model use represent token correspond number ordinal subject embeddings principal component analysis pca pca result reveal albert model different size trained initialized separately consistently learn use ax greatest variation represent approximate ordering various numerical concept numeral textual counterpart represented separate cluster increase along direction space finding illustrate language model trained purely model text intuit basic mathematical concept opening avenue nlp application intersect quantitative reasoning
number size parallel corpus keep growing make necessary automatic method processing combining checking improving corpus quality etc introduce method enables performing many exploiting overlapping parallel corpus method find correspondence sentence pair two corpus first corresponding language part corpus aligned two resulting alignment compared method take consideration slight difference source document different level segmentation input corpus encoding difference aspect task paper describes two experiment conducted test method first experiment estonianenglish part jrcacquis corpus combined another corpus legislation text second experiment alternatively aligned version jrcacquis compared example language pair english estonian latvian several additional conclusion corpus drawn result method prof effective several parallel corpus processing task
cree one spoken indigenous language canada speech recognition perspective lowresource language since little data available either acoustic language modeling prevented development speech technology could help revitalize language describe experiment available cree data improve automatic transcription speaker independent dependent scenario difficult get low speakerindependent word error rate six speaker able get low word phoneme error rate speakerdependent scenario compare phoneme recognition two stateoftheart opensource phoneme recognition toolkits use endtoend training sequencetosequence modeling phoneme error rate significantly lower achieved best system system varying amount transcribed text data show pretraining language important speakerindependent recognition even small amount additional textonly document useful result guide practical language documentation work deciding much transcribed text data needed achieve useful phoneme accuracy
recently nonrecurrent architecture convolutional selfattentional outperformed rnns neural machine translation cnns selfattentional network connect distant word via shorter network path rnns speculated improves ability model longrange dependency however theoretical argument tested empirically alternative explanation strong performance explored indepth hypothesize strong performance cnns selfattentional network could also due ability extract semantic feature source text evaluate rnns cnns selfattention network two task subjectverb agreement capturing longrange dependency required word sense disambiguation semantic feature extraction required experimental result show selfattentional network cnns outperform rnns modeling subjectverb agreement long distance selfattentional network perform distinctly better rnns cnns word sense disambiguation
paper proposes investigation role populist theme rhetoric italian twitter corpus hate speech immigrant corpus annotated four new layer analysis nominal utterance seen consistent populist rhetoric inoutgroup rhetoric common populist strategy polarize public opinion sloganlike nominal utterance may convey call severe illiberal policy immigrant news recognize role newspaper headline reference article twitter political discourse immigration featured hate speech
introduce substantial update prague czechenglish dependency treebank parallel corpus manually annotated deep syntactic layer linguistic representation english part consists wall street journal wsj section penn treebank czech part translated english source sentence sentence paper give high level overview underlying linguistic theory socalled tectogrammatical annotation detail important feature like valency annotation ellipsis reconstruction coreference
increasing number people world today speak mixedlanguage result multilingual however building speech recognition system codeswitching remains difficult due availability limited resource expense significant effort required collect mixedlanguage data therefore propose new learning method metatransfer learning transfer learn codeswitched speech recognition system lowresource setting judiciously extracting information highresource monolingual datasets model learns recognize individual language transfer better recognize mixedlanguage speech conditioning optimization codeswitching data based experimental result model outperforms existing baseline speech recognition language modeling task faster converge
large multilingual model inspired new class word alignment method work well model pretraining language however language need automatic alignment lowresource thus typically included pretraining data work ask modern aligners perform unseen language better traditional method contribute goldstandard alignment bribrispanish guaranispanish quechuaspanish shipibokonibospanish evaluate stateoftheart aligners without model adaptation target language finally also evaluate resulting alignment extrinsically two downstream task named entity recognition partofspeech tagging find although transformerbased method generally outperform traditional model two class approach remain competitive
complex nlp application machine translation system utilize various kind resource namely lexical multiword domain dictionary map rule etc similarly translator working computer aided translation workbench also require help various kind resource glossary terminology concordance translation memory workbench order increase productivity additionally translator look away workbench linguistic resource like named entity multiwords lexical lexeme dictionary order get help available resource like concordance terminology glossary often enough paper present kunji resource management system translation workbench mt module system easily integrated translation workbench also used management tool resource mt system described resource management system integrated translation workbench transzaar also study impact providing resource management system along linguistic resource productivity translator englishhindi language pair linguistic resource like lexeme ner mwe dictionary made available translator addition regular translation memory concordance terminology productivity increased
model perform well training domain often fail generalize outofdomain ood example data augmentation common method used prevent overfitting improve ood generalization however natural language difficult generate new example stay underlying data manifold introduce ssmba data augmentation method generating synthetic training example using pair corruption reconstruction function move randomly data manifold investigate use ssmba natural language domain leveraging manifold assumption reconstruct corrupted text masked language model experiment robustness benchmark across task datasets ssmba consistently outperforms existing data augmentation method baseline model indomain ood data achieving gain ood amazon review accuracy ood mnli bleu indomain iwslt germanenglish
present design framework called conversational learning analytical stepbystep strategy class building advanced intelligent tutoring system powered highperformance large language model llm class framework empowers two key capability first carefully curated scaffolding dataset class equips essential problemsolving strategy enabling provide tutorlike stepbystep guidance student second using dynamic conversational dataset class assist facilitating natural language interaction fostering engaging studenttutor conversation class framework also provides valuable insight itss internal decisionmaking process allows seamless integration user feedback thus enabling continuous refinement improvement also present proofofconcept referred spock trained using class framework focus introductory college level biology content carefully constructed protocol developed spock preliminary evaluation examining aspect factual accuracy relevance response expert field biology offered favorable remark particularly highlighting spock capability break question manageable subproblems provide encouraging response student
translating formal document capturing sentence structure specific sublanguage extremely necessary obtain highquality translation paper proposes novel global reordering method particular focus longdistance reordering capturing global sentence structure sublanguage proposed method learns global reordering model nonannotated parallel corpus work conjunction conventional syntactic reordering experimental result patent abstract sublanguage show substantial gain point ribes metric comparable bleu score japanesetoenglish englishtojapanese translation
paper asks whether extrapolating hidden space distribution text example one class onto another valid inductive bias data augmentation operationalize question propose simple data augmentation protocol called goodenough example extrapolation ge ge lightweight hyperparameters applied three text classification datasets various data imbalance scenario ge improves performance upsampling hiddenspace data augmentation method
paper present annotation experiment three different annotation scheme identification argument component text related vaccination debate identifying claim vaccination made participant debate great societal interest decision vaccinate impact public health safety since corpus annotated argumentation information contain text belong specific genre well defined argumentation structure needed adjust annotation scheme corpus contains heterogeneous text web started complex annotation scheme simplified due low iaa final experiment focused annotating claim annotator reached iaa
computationintensive pretrained model taking lead many natural language processing benchmark glue however energy efficiency process model training inference becomes critical bottleneck introduce hulk multitask energy efficiency benchmarking platform responsible natural language processing hulk compare pretrained model energy efficiency perspective time cost baseline benchmarking result provided analysis finetuning efficiency different pretrained model differ significantly among different task fewer parameter number necessarily imply better efficiency analyzed phenomenon demonstrated method comparing multitask efficiency pretrained model platform available urlhttpshulkbenchmarkgithubio
machine translation mt model usually translate text sentence level considering isolated sentence based strict assumption sentence text independent one another however fact text discourse level property going beyond individual sentence property reveal text frequency distribution word word sens referential form syntactic structure dissregarding dependency across sentence harm translation quality especially term coherence cohesion consistency solve problem several approach previously investigated conventional statistical machine translation smt fast growth neural machine translation nmt discourselevel nmt drawn increasing attention researcher work review major work addressing discourse related problem smt nmt model survey recent trend field
transformer achieved stateoftheart result across multiple nlp task however selfattention mechanism complexity scale quadratically sequence length creating obstacle task involving long sequence like speech domain paper discus usefulness selfattention direct speech translation first analyze layerwise token contribution selfattention encoder unveiling local diagonal pattern prove attention weight avoidable propose substitute standard selfattention local efficient one setting amount context used based result analysis approach model match baseline performance improves efficiency skipping computation weight standard attention discard
quotation crucial successful explanation persuasion interpersonal communication however finding quote conversation challenging human machine work study automatic quotation generation online conversation explores language consistency affect whether quotation fit given context capture contextual consistency quotation term latent topic interaction dialogue history coherence query turn existing content encoderdecoder neural framework employed continue context quotation via language generation experiment result two largescale datasets english chinese demonstrate quotation generation model outperforms stateoftheart model analysis show topic interaction query consistency helpful learn quote online conversation
research paper undertake comprehensive examination several pivotal factor impact performance arabic disinformation detection araieval shared task exploration encompasses influence surface preprocessing morphological preprocessing fasttext vector model weighted fusion tfidf feature carry classification task employ linear support vector classification lsvc model evaluation phase system showcase significant result achieving f micro score binary multiple classification scenario respectively accomplishment closely correspond average f micro score achieved system submitted second subtask standing binary multiple classification scenario respectively
paper describes anonymous submission wmt quality estimation shared task participate task quality prediction sentence wordlevel quality prediction task system multilingual multitask model whereby single system infer sentence wordlevel quality multiple language pair system architecture consists pretrained language model plm task layer jointly optimized sentence wordlevel quality prediction task using multilingual dataset propose novel auxiliary task training explore diverse source additional data demonstrate improvement performance ablation study examine effectiveness proposed component find optimal configuration train submission system language pair task setting finally submission system trained inferenced using kfolds ensemble system greatly outperform task organizer baseline achieve comparable performance participant submission sentence wordlevel quality prediction task
report describes method employed democritus university thrace duth team participating semeval task fact checking community question answering forum team dealt subtask question classification approach based shallow natural language processing nlp preprocessing technique reduce noise data feature selection method supervised machine learning algorithm nearestcentroid perceptron linearsvc determine essential feature aided exploratory data analysis visualization order improve classification accuracy developed customized list stopwords retaining opinion factdenoting common function word would removed standard stoplisting furthermore examined usefulness partofspeech po category task trying remove noun adjective found evidence verb valuable po category opinion question class
neural controllable text generation important area gaining attention due plethora application although large body prior work controllable text generation unifying theme work provide new schema pipeline generation process classifying five module control attribute generation process requires modification module present overview different technique used perform modulation module also provide analysis advantage disadvantage technique pave way develop new architecture based combination module described paper
introduction online marketplace platform led advent new form flexible ondemand gig work yet prior research concerning experience gig worker examines delivery crowdsourcing platform experience large number worker undertake educational labour form tutoring gig remains understudied address use computational grounded theory approach analyse tutor discussion reddit approach consists three phase including data exploration modelling humancentred interpretation use validation human evaluation increase trustworthiness reliability computational method paper work progress report first three phase approach
pretrained language model encode undesirable social bias exacerbated downstream use end propose mabel method attenuating gender bias using entailment label intermediate pretraining approach mitigating gender bias contextualized representation key approach use contrastive learning objective counterfactually augmented genderbalanced entailment pair natural language inference nli datasets also introduce alignment regularizer pull identical entailment pair along opposite gender direction closer extensively evaluate approach intrinsic extrinsic metric show mabel outperforms previous taskagnostic debiasing approach term fairness also preserve task performance finetuning downstream task together finding demonstrate suitability nli data effective mean bias mitigation opposed using unlabeled sentence literature finally identify existing approach often use evaluation setting insufficient inconsistent make effort reproduce compare previous method call unifying evaluation setting across gender debiasing method better future comparison
hyperbole metaphor common daytoday communication eg deep trouble trouble depth make detection important especially conversational ai setting existing approach automatically detect metaphor hyperbole studied language phenomenon independently relationship hardly ever explored computationally paper propose multitask deep learning framework detect hyperbole metaphor simultaneously hypothesize metaphor help hyperbole detection viceversa test hypothesis annotate two hyperbole datasets hypo hypol metaphor label simultaneously annotate two metaphor datasets trofi lcc hyperbole label experiment using datasets give improvement state art hyperbole detection additionally multitask learning mtl approach show improvement singletask learning stl hyperbole metaphor detection supporting hypothesis best knowledge first demonstration computational leveraging linguistic intimacy metaphor hyperbole leading showing superiority mtl stl hyperbole metaphor detection
propose variant wellknown machine translation mt evaluation metric hyter dreyer marcu exploit reference translation enriched meaning equivalent expression original hyter metric relied handcrafted paraphrase network restricted applicability new data test first time hyter automatically built paraphrase lattice show although metric obtains good result small carefully curated data manually automatically selected substitute achieves medium performance much larger noisier datasets demonstrating limit metric tuning evaluation current mt system
important aspect machine translation evaluation achieved use variety metric compare metric workshop statistical machine translation annually evaluates metric based correlation human judgement year method measuring correlation human changed little research performed optimal method acquiring human score human correlation measured work method evaluating metric system segmentlevel analyzed detail shortcoming pointed
one crucial aspect democracy fair information sharing hard prevent bias news identified better transparency propose approach automatically characterize bias take account structural difference efficient long text yield new way provide explanation textual classifier going beyond mere lexical cue show use discoursebased structureaware document representation compare well local computationally heavy domainspecific model classification task deal textual bias ii approach based different level granularity allows generation better explanation model decision lexical structural level addressing challenge posed long text
paper present approach participate semeval task clinical tempeval challenge specifically event time expression span attribute identification subtasks e ea t ta approach consisted training conditional random field crf classifier using provided annotation creating manually curated rule classify attribute event time expression used set common feature event time crf classifier set feature specific type entity based domain knowledge training source domain data best fscores event time span identification subtasks adding target domain annotation training data best fscores obtained subtasks obtained second highest fscore challenge event polarity subtask source code system clinical timeline annotation cita available urlhttpsgithubcomlasigebiotmcita
event scenario often complex involve multiple event sequence connected different entity participant exploring complex scenario requires ability branch different sequence something difficult achieve standard event language modeling address propose questionguided generation framework model event complex scenario answer question participant step generation process framework us previouslygenerated event context generates next event answer one three question else participant else happened participant else happened participant question sampled provided input user allowing controllable exploration empirical evaluation show questionguided generation provides better coverage participant diverse event within domain comparable perplexity modeling event sequence effective control interactive schema generation
paper present kachna corpus spontaneous speech ten czech ten norwegian speaker recorded native language english dialogue elicited using picture replication task requires active cooperation interaction speaker asking produce drawing close original possible corpus appropriate study interactional feature speech reduction phenomenon across native second language combination production nonnative english speaker native language advantageous investigation l issue providing l behaviour reference speaker corpus consists dialogue comprising hour minute recording collected preparation transcription including manual orthographic transcription automatically generated phonetic transcription currently progress phonetic transcription automatically generated aligning acoustic model speech signal basis orthographic transcription dictionary pronunciation variant compiled relevant language upon completion corpus made available via european language resource association elra
making official transcript meeting record parliament edits made faithful transcript utterance linguistic correction formality classification edits provided paper quantitative analysis conducted japanese european parliamentary meeting comparing faithful transcript audio recording official meeting record different trend observed two parliament due nature language used meeting style moreover diachronic change japanese transcript presented showing significant decrease edits past decade found majority edits japanese parliament diet simply remove filler redundant word keeping transcript verbatim possible property useful evaluation automatic speech transcription system developed u used japanese parliament
paper present comprehensive overview existing data evaluation spoken content processing multimedia framework french language focus etape corpus made publicly available elda mid completion evaluation campaign recall existing resource resulting previous evaluation campaign etape corpus consists hour tv radio broadcast selected cover wide variety topic speaking style emphasizing spontaneous speech multiple speaker area
paper explore spelling error source information detecting native language writer previously underexplored area note character ngrams misspelled word indicative native language author combination lexical feature spelling error feature lead improvement accuracy classifying text toefl corpus author native language compared system participating nli shared task
detecting biased language useful variety application identifying hyperpartisan news source flagging onesided rhetoric work introduce wikievolve dataset documentlevel promotional tone detection unlike previously proposed datasets wikievolve contains seven version article wikipedia different point revision history one promotional tone six without allows obtaining precise training signal learning model promotional tone detection adapt previously proposed gradient reversal layer framework encode two article version simultaneously thus leverage additional training signal experiment proposed adaptation gradient reversal improves accuracy four different architecture indomain outofdomain evaluation
readability assessment task evaluating reading difficulty given piece text article take closer look contemporary nlp research developing computational model readability assessment identifying common approach used task shortcoming challenge future possible survey also connects computational research insight related work discipline education psychology
multilingual automatic speech recognition asr system great interest multilingual environment studied case comunitat valenciana two official language spanish valencian two language share phoneme syntax vocabulary also quite similar since influenced many year constructed system trained acoustic model small corpus spanish valencian produced poor result due lack data adaptation technique used adapt acoustic model trained large corpus language inr order obtain acoustic model phonetically similar language process known language adaptation maximum likelihood linear regression mllr technique commonly used speaker adaptation however used mllr language adaptation compared several mllr variant mean square diagonal matrix full matrix language adaptation order choose best alternative system
named geographic entity geoentities short building block many geographic datasets characterizing geoentities integral various application domain geointelligence map comprehension key challenge capture spatialvarying context entity hypothesize shall know characteristic geoentity surrounding entity similar knowing word meaning linguistic context accordingly propose novel spatial language model spabert provides generalpurpose geoentity representation based neighboring entity geospatial data spabert extends bert capture linearized spatial context incorporating spatial coordinate embedding mechanism preserve spatial relation entity dimensional space spabert pretrained masked language modeling masked entity prediction task learn spatial dependency apply spabert two downstream task geoentity typing geoentity linking compared existing language model use spatial context spabert show significant performance improvement task also analyze entity representation spabert various setting effect spatial coordinate embedding
islex multilingual scandinavian dictionary icelandic source language danish norwegian swedish faroese finnish target language within islex fact contained several independent bilingual dictionary faroese finnish still construction language opened public web november use dictionary free charge extremely well received user result project threefold firstly long awaited icelandicscandinavian dictionary published digital medium secondly project important experience nordic language collaboration jointly building work six country simultaneously academic institution iceland denmark norway sweden faroe island finland thirdly work resulted compilation structured linguistic data nordic language data suitable use lexicographic work various language technology project
traditional automatic video dubbing avd pipeline consists three key module namely automatic speech recognition asr neural machine translation nmt texttospeech tt within avd pipeline isometricnmt algorithm employed regulate length synthesized output text done guarantee synchronization respect alignment video audio subsequent dubbing process previous approach focused aligning number character word source target language text machine translation model however approach aim align number phoneme instead closely associated speech duration paper present development isometric nmt system using reinforcement learning rl focus optimizing alignment phoneme count source target language sentence pair evaluate model propose phoneme count compliance pcc score measure length compliance approach demonstrates substantial improvement approximately pcc score compared stateoftheart model applied englishhindi language pair moreover propose studentteacher architecture within framework rl approach maintain tradeoff phoneme count translation quality
conversational questionanswer generation task automatically generates largescale conversational question answering dataset based input passage paper introduce novel framework extract questionworthy phrase passage generates corresponding question considering previous conversation particular framework revise extracted answer generating question answer exactly match paired question experimental result show simple answer revision approach lead significant improvement quality synthetic data moreover prove framework effectively utilized domain adaptation conversational question answering
describe system ranked first hope speech detection hsd shared task fourth offensive language identification oli shared task tamil language goal hsd oli identify codemixed comment post contains hope speech offensive content respectively pretrain transformerbased model roberta using synthetically generated codemixed data use ensemble along pretrained ulmfit model available inltk
crosslingual abstract meaning representation amr parsing researcher develop model project sentence various language onto amrs capture essential semantic structure given sentence language aim capture core semantic content concept connected manifold type semantic relation method typically leverage large silver training data learn single model able project nonenglish sentence amrs however find simple baseline tends overlooked translating sentence english projecting amr monolingual amr parser translateparsetp paper revisit simple twostep baseline enhance strong nmt system strong amr parser experiment show tp outperforms recent stateoftheart system across tested language german italian spanish mandarin smatch point
zeroshot learning zsl task pertains identification entity relation text seen training zsl emerged critical research area due scarcity labeled data specific domain application grown significantly recent year advent large pretrained language model several novel method proposed resulting substantial improvement zsl performance growing demand research community industry comprehensive zsl framework facilitates development accessibility latest method pretrained model study propose novel zsl framework called zshot aim address aforementioned challenge primary objective provide platform allows researcher compare different stateoftheart zsl method standard benchmark datasets additionally designed framework support industry readily available apis production standard spacy nlp pipeline api extendible evaluable moreover include numerous enhancement boosting accuracy pipeline ensembling visualization utility available spacy extension
indian language wordnet individual webbased browsing interface along common interface indowordnet interface prove useful language learner educational domain however provide functionality connecting browsing data lucid application programming interface api paper present work creating easytouse framework bundled data indian language wordnet provides nltk wordnet interface like core functionality python additionally use prebuilt speech synthesis system hindi language augment hindi data audio word gloss example sentence provide detailed usage api explain function ease user also package indowordnet data along source code provide openly purpose research aim provide work open source framework development
paper two objective analyse adequacy using neural machine translation nmt translation health information spanish english romanian used spanish public health campaign compare result considering two linguistic combination result show postediting essential improve quality translation language combination since used primary resource informing foreign user without postediting moreover romanian translation require postediting however using nmt informative text combined human postediting used strategy benefit potential mt time ensuring quality public service translation depending language combination amount time allotted task
paper present two datasets tamasheq developing language mainly spoken mali niger two datasets made available iwslt lowresource speech translation track consist collection radio recording daily broadcast news niger studio kalangou mali studio tamani share massive amount unlabeled audio data hour five language french niger fulfulde hausa tamasheq zarma ii smaller hour parallel corpus audio recording tamasheq utterancelevel translation french language data shared creative common byncnd license hope resource inspire speech community develop benchmark model using tamasheq language
existing visual question answering vqa method tend exploit dataset bias spurious statistical correlation instead producing right answer right reason address issue recent bias mitigation method vqa propose incorporate visual cue eg human attention map better ground vqa model showcasing impressive gain however show performance improvement result improved visual grounding regularization effect prevents overfitting linguistic prior instance find actually necessary provide proper humanbased cue random insensible cue also result similar improvement based observation propose simpler regularization scheme require external annotation yet achieves near stateoftheart performance vqacpv
recognition realworld entity crucial nlp application since introduction twenty year ago named entity processing undergone significant evolution among others definition new task eg entity linking emergence new type data eg speech transcription microblogging pose certainly new challenge affect method algorithm especially linguistic resource stand respect named entity resource paper aim providing systematic overview named entity resource accounting quality multilingualism dynamicity interoperability identify shortfall order guide future development
present guideline annotation procedure create human corrected machine translated postedited corpus modern standard arabic overarching goal use annotated corpus develop automatic machine translation postediting system arabic used help accelerate human revision process translated text creation manually annotated corpus usually present many challenge order address challenge created comprehensive simplified annotation guideline used team five annotator one lead annotator order ensure high annotation agreement annotator multiple training session held regular interannotator agreement measure performed check annotation quality created corpus manual postedited translation english arabic article largest date language pair
conditional text generation often requires lexical constraint ie word shouldnt included output text dominant recipe conditional text generation largescale pretrained language model finetuned taskspecific training data model learn follow underlying constraint reliably even supervised large amount taskspecific example propose neurologic decoding simple yet effective algorithm enables neural language model supervised generate fluent text satisfying complex lexical constraint approach powerful yet efficient handle set lexical constraint expressible predicate logic asymptotic runtime equivalent conventional beam search empirical result four benchmark show neurologic decoding outperforms previous approach including algorithm handle subset constraint moreover find unsupervised model neurologic decoding often outperform supervised model conventional decoding even latter based considerably larger network result suggest limit largescale neural network finegrained controllable generation promise inferencetime algorithm
recent study shown pretrained language model plms vulnerable adversarial example crafted introducing humanimperceptible perturbation clean example deceive model vulnerability stem divergence data distribution clean adversarial example therefore addressing issue involves teaching model diminish difference two type sample focus similarity end propose novel approach named textittaichi employ siamese network architecture specifically consists two subnetworks sharing structure trained clean adversarial sample respectively us contrastive learning strategy encourage generation similar language representation kind sample furthermore utilizes kullbackleibler kl divergence loss enhance consistency predictive behavior two subnetworks extensive experiment across three widely used datasets demonstrate textittaichi achieves superior tradeoff robustness adversarial attack token character level accuracy clean example compared previous defense method code data publicly available urlhttpsgithubcomsaijulytaichi
paper present englishgerman automatic postediting ape system called transference submitted ape task organized wmt transference model based multiencoder transformer architecture unlike previous approach us transformer encoder block src ii followed transformer decoder block without masking selfattention mt effectively act second encoder combining src textgreater mt iii feed representation final decoder block generating pe model improves raw blackbox neural machine translation system absolute bleu point wmt ape development test set submission ranked rd however compared two top system performance difference statistically significant
endtoend task bot typically learned static usually limitedsize corpus however deployed dynamic changing open environment interact user task bot tend fail confronted data deviate training corpus ie outofdistribution sample paper study problem automatically adapting task bot changing environment learning humanbot interaction minimum zero human annotation propose slagent novel selflearning framework building endtoend task bot slagent consists dialog model pretrained reward model predict quality agent response enables task bot automatically adapt changing environment learning unlabeled humanbot dialog log accumulated deployment via reinforcement learning incorporated reward model experimental result four wellstudied dialog task show effectiveness slagent automatically adapt changing environment using automatic human evaluation release code data research
paper present system submitted multilingual gender biased communal language identification shared task bfcai team proposed model used support vector machine svms classification algorithm feature extracted using tfidf model unigram bigram proposed model simple external resource needed build model
present study integration timesensitive information lexiconbased offensive language detection system focus offenseval subtask aimed detecting offensive tweet apply semantic change detection algorithm short time span two year detect word whose semantics changed focus particularly word acquired lost offensive meaning using output semantic change detection approach train svm classifier offenseval training set build already competitive sinai system submitted offenseval adding new lexical feature including capture change usage word association emerging offensive usage discus challenge opportunity limitation integrating semantic change detection offensive language detection model work draw attention often neglected aspect offensive language namely meaning word constantly evolving nlp system account change achieve good performance even trained recent training data
historical cryptology study historical encrypted message aiming decryption analyzing mathematical linguistic coding pattern historical context library archive find quite lot cipher well key describing method used transform plaintext message ciphertext paper present work automatically mapping key cipher reconstruct original plaintext message use language model generated historical text guess underlying plaintext language
given collection image spoken audio caption present method discovering wordlike acoustic unit continuous speech signal grounding semantically relevant image region example model able detect spoken instance word lighthouse within utterance associate image region containing lighthouse use form conventional automatic speech recognition use text transcription conventional linguistic annotation model effectively implement form spoken language acquisition computer learns recognize word category sound also enrich word learns semantics grounding image
paper present result project teacher tool et opetaja tooriistad published subpage new language portal sonaveeb developed institute estonian language toolbox includes four module vocabulary grammar communicative language activity text evaluation tool aimed help teacher specialist estonian second language plan course create new educational material exercise test based cefr level description
mathematical expression widely used scholar document paper analyze characteristic textual visual me characteristic imagetolatex translation task open datasets latex file me included complicated extract me document compile list me therefore release corpus openaccess scholar document pdf jatsxml parallel file me document latex encoded document independent data contains million distinct annotated formula million raw token latex me thousand document variety textual length visual size me well defined found task analyzing me scholar document reduced subtask particular text length image width height bound display me processed array partial me
paper investigate domain generalization dg problem supervised paraphrase identification pi observe performance existing pi model deteriorates dramatically tested outofdistribution ood domain conjecture caused shortcut learning ie model tend utilize cue word unique particular dataset domain alleviate issue enhance dg ability propose pi framework based optimal transport ot method force network learn necessary feature word input alleviates shortcut learning problem experimental result show method improves dg ability pi model
human conversation recommendation naturally involve shift interest align recommendation action conversation process make accurate recommendation rich explanation however existing conversational recommendation system cr ignore advantage user interest shift connecting recommendation conversation lead ineffective loose coupling structure cr address issue modeling recommendation action recommendation path knowledge graph kg propose dicr textbfdual textbfimitation textbfconversational textbfrecommendation design dual imitation explicitly align recommendation path user interest shift path recommendation module conversation module respectively exchanging alignment signal dicr achieves bidirectional promotion recommendation conversation module generates highquality response accurate recommendation coherent explanation experiment demonstrate dicr outperforms stateoftheart model recommendation conversation performance automatic human novel explainability metric
previous work demonstrated effectiveness planning story generation exclusively monolingual setting focusing primarily english consider whether planning brings advantage automatic story generation across language propose new task crosslingual story generation planning present new dataset task conduct comprehensive study different plan generate story several language leveraging creative reasoning capability large pretrained language model result demonstrate plan structure story three act lead coherent interesting narrative allowing explicitly control content structure
human learn language listening speaking writing reading also via interaction multimodal real world existing language pretraining framework show effectiveness textonly selfsupervision explore idea visuallysupervised language model paper find main reason hindering exploration large divergence magnitude distribution visuallygrounded language datasets purelanguage corpus therefore develop technique named vokenization extrapolates multimodal alignment languageonly data contextually mapping language token related image call vokens vokenizer trained relatively small image captioning datasets apply generate vokens large language corpus trained contextually generated vokens visuallysupervised language model show consistent improvement selfsupervised alternative multiple purelanguage task glue squad swag
paper present result large vocabulary continuous speech recognition lvcsr swedish trained acoustic model public domain nst swedish corpus made freely available community training procedure corresponds reference recogniser refrec developed speechdat database cost action describe modification made procedure order train nst database language model created based ngram data available norwegian language council test include medium vocabulary isolated word recognition lvcsr previous result available lvcsr swedish use baseline performance speechdat model task also compare best result one obtained similar condition resource rich language american english tested acoustic model htk julius plan make available cmu sphinx format well near future believe free availability resource boost research speech language technology swedish even research group resource develop asr system
visual medium text emphasis strengthening word text convey intent author text emphasis visual medium generally done using different color background font text help conveying actual meaning message reader emphasis selection task choosing candidate word emphasis help automatically designing poster medium content written text consider text know intent multiple valid emphasis selection propose use ensemble emphasis selection improve single emphasis selection model show use multiembedding help enhancing result base model show efficacy proposed approach also done comparison result stateoftheart model
dynamic terminology integration neural machine translation nmt soughtafter feature computeraided translation tool among language service provider small medium business despite recent surge research terminology integration nmt still seldom inadequately supported commercial machine translation solution presentation share experience developing deploying terminology integration capability nmt system production look three core task terminology integration terminology management terminology identification translation terminology talk insightful nmt system developer translator terminologists anyone interested translation project
paper describes entry intelligent knowledge management ikm laboratory biolaysumm task aim transform lengthy biomedical article concise readerfriendly summary easily comprehended general public utilized longtext abstractive summarization longformer model experimented several prompt method task entry placed th overall particularly proud achieve rd place score readability evaluation metric
paper present first fewshot llmbased chatbot almost never hallucinates high conversationality low latency wikichat grounded english wikipedia largest curated freetext corpus wikichat generates response llm retains grounded fact combine additional information retrieves corpus form factual engaging response distill wikichat based gpt bparameter llama model minimal loss quality significantly improve latency cost privacy facilitate research deployment using novel hybrid humanandllm evaluation methodology show best system achieves factual accuracy simulated conversation significantly outperforms retrievalbased llmbased baseline head tail recent knowledge compared gpt compared previous stateoftheart retrievalbased chatbots wikichat also significantly informative engaging like llm wikichat achieves factual accuracy conversation human user recent topic better gpt receiving significantly higher user rating favorable comment
conjectured multilingual information help monolingual word sense disambiguation wsd however existing wsd system rarely consider multilingual information effective method proposed improving wsd generating translation paper present novel approach improves performance base wsd system using machine translation since approach language independent perform wsd experiment several language result demonstrate method consistently improve performance wsd system obtain stateoftheart result english multilingual wsd facilitate use lexical translation information also propose babalign precise bitext alignment algorithm guided multilingual lexical correspondence babelnet
massively multilingual transformer mmts pretrained via language modeling eg mbert xlmr become default paradigm zeroshot language transfer nlp offering unmatched transfer performance current evaluation however verify efficacy transfer language sufficiently large pretraining corpus b close language work analyze limitation downstream language transfer mmts showing much like crosslingual word embeddings substantially less effective resourcelean scenario distant language experiment encompassing three lowerlevel task po tagging dependency parsing ner two highlevel task nli qa empirically correlate transfer performance linguistic proximity source target language also size target language corpus used mmt pretraining importantly demonstrate inexpensive fewshot transfer ie additional finetuning targetlanguage instance surprisingly effective across board warranting research effort reaching beyond limiting zeroshot condition
paper describe system task semeval involves differentiating natural language statement conform common sense organizer propose three subtasks first selecting two sentence one common sense second identifying crucial reason statement make sense third generating novel reason explaining common sense statement three subtasks paper report system description subtask subtask b paper proposes model based transformer neural network architecture addressing subtasks novelty work lie architecture design handle logical implication contradicting statement simultaneous information extraction sentence use parallel instance transformer responsible boost performance achieved accuracy subtask subtask b test set
last year two promising research direction lowresource neural machine translation nmt emerged first focus utilizing highresource language improve quality lowresource language via multilingual nmt second direction employ monolingual data selfsupervision pretrain translation model followed finetuning small amount supervised data work join two line research demonstrate efficacy monolingual data selfsupervision multilingual nmt offer three major result using monolingual data significantly boost translation quality lowresource language multilingual model ii selfsupervision improves zeroshot translation quality multilingual model iii leveraging monolingual data selfsupervision provides viable path towards adding new language multilingual model getting bleu roen translation without parallel data backtranslation
present asr based pipeline amharic orchestrates nlp component within cross medium analysis framework cmaf one major challenge inherently associated cmafs effectively addressing multilingual issue result many language remain underresourced fail leverage available medium analysis solution although spoken natively million people everincreasing amount amharic multimedia content web querying simple text search difficult searching especially audiovideo content simple key word even hard exist raw form study introduce spoken textual content processing workflow cmaf amharic design asrnamed entity recognition ner pipeline includes three main component asr transliterator ner explore various acoustic modeling technique develop opennlpbased ner extractor along transliterator interface asr ner designed asrner pipeline amharic promotes multilingual support cmafs also stateofthe art design principle technique employed study shed light lessresourced language particularly semitic one
paper describes espnetst group iwslt submission offline speech translation track year made various effort training data architecture audio segmentation data side investigated sequencelevel knowledge distillation seqkd endtoend ee speech translation specifically used multireferenced seqkd multiple teacher trained different amount bitext architecture side adopted conformer encoder multidecoder architecture equips dedicated decoder speech recognition translation task unified encoderdecoder model enables search source target language space inference also significantly improved audio segmentation using pyannoteaudio toolkit merging multiple short segment long context modeling experimental evaluation showed contributed large improvement translation performance best ee system combined technique model ensembling achieved bleu ref tst bleu bleu two single reference tst
leveraging additional unlabeled data boost model performance common practice machine learning natural language processing generation task overlap additional data target text evaluation data training additional data training answer test set lead overlyinflated score additional data compared realworld testing scenario problem comparing model study amr dataset gigaword popularly used improving amrtotext generator find significant overlap gigaword subset amr dataset propose method excluding part gigaword remove overlap show approach lead realistic evaluation task amrtotext generation going forward give simple bestpractice recommendation leveraging additional data amrtotext generation
paper propose multihop attention transformer refines attention output symbol integrating head consists two hop first hop attention scaled dotproduct attention attention mechanism used original transformer second hop attention combination multilayer perceptron mlp attention head gate efficiently increase complexity model adding dependency head demonstrate translation accuracy proposed multihop attention outperforms baseline transformer significantly bleu point iwslt germantoenglish task bleu point wmt germantoenglish task also find number parameter required multihop attention smaller stacking another selfattention layer proposed model converges significantly faster original transformer
selfattention recently adopted wide range sequence modeling problem despite effectiveness selfattention suffers quadratic computation memory requirement respect sequence length successful approach reduce complexity focused attending local sliding window small set location independent content work proposes learn dynamic sparse attention pattern avoid allocating computation memory attend content unrelated query interest work build upon two line research combine modeling flexibility prior work contentbased sparse attention efficiency gain approach based local temporal sparse attention model routing transformer endows selfattention sparse routing module based online kmeans reducing overall complexity attention ond ond sequence length n hidden dimension show model outperforms comparable sparse attention model language modeling wikitext v perplexity well image generation imagenet v bitsdim using fewer selfattention layer additionally set new stateoftheart newly released pg dataset obtaining test perplexity layer routing transformer model trained sequence length opensource code routing transformer tensorflow
domain adaptation important topic natural language processing extensive research topic various method explored including training data selection model combination semisupervised learning study propose use goodness measure namely description length gain dlg domain adaptation chinese word segmentation demonstrate dlg help domain adaptation two way additional feature supervised segmenters improve system performance also similarity measure selecting training data better match test set evaluated system chinese penn treebank version million word five different genre chinese word segmentation bakeoff data
large language model llm shown nearly saturated performance many natural language processing nlp task result natural people believe llm also mastered ability time understanding reasoning however research temporal sensitivity llm insufficiently emphasized fill gap paper construct multiple sensitive factor time qa menatqa encompasses three temporal factor scope factor order factor counterfactual factor total sample evaluating time comprehension reasoning ability llm paper test current mainstream llm different parameter size ranging billion hundred billion result show llm fall behind smaller temporal reasoning model different degree factor specific llm show significant vulnerability temporal bias depend heavily temporal information provided question furthermore paper undertakes preliminary investigation potential improvement strategy devising specific prompt leveraging external tool approach serve valuable baseline reference future research endeavor
hyperparameters hp important knowledge graph kg learning existing method fail search efficiently solve problem first analyze property different hp measure transfer ability small subgraph full graph based analysis propose efficient twostage search algorithm kgtuner efficiently explores hp configuration small subgraph first stage transfer topperformed configuration finetuning large full graph second stage experiment show method consistently find better hp baseline algorithm within time budget achieves average relative improvement four embedding model largescale kg open graph benchmark code released urlhttpsgithubcomautomlresearchkgtuner
automatically generating animation natural language text find application number area eg movie script writing instructional video public safety however translating natural language text animation challenging task existing texttoanimation system handle simple sentence limit application paper develop texttoanimation system capable handling complex sentence achieve introducing text simplification step process building existing animation generation system screenwriting create robust nlp pipeline extract information screenplay map system knowledge base develop set linguistic transformation rule simplify complex sentence information extracted simplified sentence used generate rough storyboard video depicting text sentence simplification module outperforms existing system term bleu sari metric evaluated system via user study participant believe system generates reasonable animation input screenplay
open information extraction model shown promising result sufficient supervision however model face fundamental challenge syntactic distribution training data partially observable comparison real world paper propose syntactically robust training framework enables model trained syntacticabundant distribution based diverse paraphrase generation tackle intrinsic problem knowledge deformation paraphrasing two algorithm based semantic similarity matching syntactic tree walking used restore expressionally transformed knowledge training framework generally applied syntactic partial observable domain based proposed framework build new evaluation set called carbautopara syntactically diverse dataset consistent realworld setting validating robustness model experiment including thorough analysis show performance model degrades increase difference syntactic distribution framework give robust boundary
present new extended version royal society corpus rsc diachronic corpus scientific english covering year scientific writing corpus comprises text primarily scientific article based publication royal society london mainly philosophical transaction proceeding corpus built basis fair principle freely available creative common license excluding copyrighted part provide information corpus found file format available download well accessibility via webbased corpus query platform show number analytic tool implemented better usability provide example use corpus linguistic analysis well example subsequent external us earlier release place rsc background existing english diachronicscientific corpus elaborating value linguistic humanistic study
resourcepoor language may suffer lack basic resource fundamental computational linguistics including adequate digital lexicon given relatively small corpus text exists language extending lexicon present challenge language complex morphology present special case however individual word language provide great deal information grammatical property root based given morphological analyzer even possible extract novel root word paper look case tigrinya semitic language limited lexical resource morphological analyzer available shown analyzer applied list tigrinya word extracted web crawler extend lexicon two way adding new root inferring derivational constraint apply known root
last several year seen massive increase quantity influence disinformation spread online various approach developed target process different stage identifying source tracking distribution social medium providing follow debunks people encountered disinformation one common conclusion approach disinformation nuanced subjective topic fully automated solution work quantity data process crossreference high human handle unassisted ultimately problem call hybrid approach human expert technological assistance paper demonstrate application certain stateoftheart nlp technique assisting expert debunkers fact checker well role nlp algorithm within holistic approach analyzing countering spread disinformation present multilingual corpus disinformation debunks contains text concept tag image video well various method searching leveraging content
previous work suggested parameter sharing transitionbased neural dependency parser related language lead better performance consensus parameter share present evaluation different parameter sharing strategy across language representing five pair related language pair different language family find sharing transition classifier parameter always help whereas usefulness sharing word andor character lstm parameter varies based result propose architecture transition classifier shared sharing word character parameter controlled parameter tuned validation data model linguistically motivated obtains significant improvement monolingually trained baseline also find sharing transition classifier parameter help training parser unrelated language pair find case unrelated language sharing many parameter help
field computational linguistics many lexical resource developed aim encoding complex lexical semantic information according different linguistic model wordnet frame semantics generative lexicon etc however resource often easily accessible available entirety yet point view continuous growth technology semantic web visibility availability integration becoming utmost importance italwordnet parolesimpleclips two resource tackling lexical semantics different perspective least partially complementary profit linking paper address issue linking resource focusing problematic part lexicon second order entity particular brief description two resource different approach verb semantics described accurate comparison set verbal entry belonging speech act semantic class carried aiming evaluate possibility advantage semiautomatic link
language model shown perform remarkably well wide range natural language processing task paper propose leap novel system us language model perform multistep logical reasoning incorporates explicit planning inference procedure explicit planning enables system make informed reasoning decision step looking ahead future effect moreover propose training strategy safeguard planning process led astray spurious feature full system significantly outperforms competing method multiple standard datasets using small model core selection deduction component system performs competitively compared gpt despite b parameter ie time smaller gpt using gpt significantly outperforms chainofthought prompting challenging prontoqa dataset conducted extensive empirical study demonstrate explicit planning play crucial role system performance
paper develop sindhi subjective lexicon using merger existing english resource nrc lexicon list opinion word sentiwordnet sindhienglish bilingual dictionary collection sindhi modifier positive negative sentiment score assigned sindhi opinion word afterwards determine coverage proposed lexicon subjectivity analysis moreover crawl multidomain tweet corpus news sport finance crawled corpus annotated experienced annotator using doccano text annotation tool sentiment annotated corpus evaluated employing support vector machine svm recurrent neural network rnn variant convolutional neural network cnn
conversational search scenario query might contextdependent word referred previous expression omitted previous work tackle issue either reformulating query selfcontained query query rewriting learning contextualized query embedding query context context modelling paper propose model crdr perform query rewriting context modelling unified framework query rewriting supervision signal enhance context modelling instead generating new query crdr performs necessary modification original query improves accuracy efficiency query rewriting meantime query rewriting benefit context modelling explicitly highlighting relevant term query context improves quality learned contextualized query embedding verify effectiveness crdr perform comprehensive experiment trec cast trec cast datasets result show method outperforms baseline model term quality query rewriting quality contextaware ranking
workshop online abuse harm woah held satellite panel rightscons international human right conference aim bridge gap human right scholarship natural language processing nlp research community tackling online abuse report discussion took place present analysis four key issue emerged problem tackling online abuse solution meta concern ecosystem content moderation research argue pressing need nlp research community engage human right perspective identify four key way nlp research online abuse could immediately enhanced create better ethical solution
study shown sentence syntactic structure important semantic sentence matching typical approach encoding sentence syntactic structure embedding vector combined feature predict final matching score though success observed embedding whole syntactic structure one vector inevitably overlook finegrained syntax matching pattern eg alignment specific term dependency relation two inputted sentence paper formalize task semantic sentence matching problem graph matching sentence represented directed graph according syntactic structure syntax matching pattern ie similar syntactic structure two sentence therefore extracted subgraph structure alignment proposed method referred interacted syntax graph isg represents two sentence syntactic alignment well semantic matching signal one association graph neural quadratic assignment programming qap adapted extract syntactic matching pattern association graph way syntactic structure fully interact fine granularity matching process experimental result three public datasets demonstrated isg outperform stateoftheart baseline effectively efficiently empirical analysis also showed isg match sentence interpretable way
widespread popularity social medium led increase hateful abusive sexist language motivating method automatic detection phenomenon goal semeval shared task towards explainable detection online sexism edo detect sexism english social medium post subtask categorize post four coarsegrained sexism category subtask b eleven finegrained subcategories subtask c paper present submitted system three subtasks based multitask model finetuned range related task datasets finetuned specific edo subtasks implement multitask learning formulating task binary pairwise text classification dataset label description given along input text result show clear improvement finetuned debertav serving baseline leading fscores subtask rank subtask b rank subtask c
work translation richresource language lowresource language main challenge identify lack lowresource language data effective method crosslingual transfer variablebinding problem common neural system build translation system address challenge using eight european language family test ground firstly add source target family label study intrafamily interfamily influence effective crosslingual transfer achieve improvement bleu score englishswedish translation using eight family compared singlefamily multisource multitarget baseline moreover find training two neighboring family closest lowresource language often enough secondly construct ablation study find reasonably good result achieved even considerably less target data thirdly address variablebinding problem building orderpreserving named entity translation model obtain accuracy qualitative evaluation translation akin human translation preliminary study
tokenization noiseless channel zouhar et al renyi efficiency suggested intrinsic mechanism evaluating tokenizer nlp task tokenizer lead highest renyi efficiency unigram distribution chosen renyi efficiency thus treated predictor downstream performance eg predicting bleu machine translation task without expensive step training multiple model different tokenizers although useful predictive power metric perfect author note additional quality good tokenization scheme renyi efficiency alone capture describe two variant bpe tokenization arbitrarily increase renyi efficiency decreasing downstream model performance counterexample expose case renyi efficiency fails intrinsic tokenization metric thus give insight building accurate predictor
questionanswer qa one effective method storing knowledge used future retrieval identifying mention question answer text necessary knowledge construction retrieval system literature qa identification well studied nlp community however prior work restricted formal written document paper website question answer presented informalnoisy document adequately studied one domain significantly benefit qa identification domain livestreaming video transcript involve abundant qa pair provide valuable knowledge future user service since video transcript often transcribed automatically scale prone error combined informal nature discussion video prior qa identification system might able perform well domain enable comprehensive research domain present largescale qa identification dataset annotated human transcript hour streamed video employ behancenet collect video automatically obtained transcript furthermore conduct extensive analysis annotated dataset understand complexity qa identification livestreaming video transcript experiment show annotated dataset present unique challenge existing method research necessary explore effective method dataset model developed work publicly released future research
many people may find motivation life spreading content social medium encouraging hopeful creating effective model help accurately predicting target class challenging task problem hope speech identification dealt work using machine learning deep learning method paper present description system submitted teamvel hope speech detection equality diversity inclusionhsdedi ltediranlp shared task bulgarian language main goal shared task identify given text hope speech nonhope speech category proposed method used ho deep learning model mpnet embeddings achieved second rank bulgarian language macro f score
demonstrate surprising strength unimodal baseline multimodal domain make concrete recommendation best practice future research existing work often compare random majority class baseline argue unimodal approach better capture reflect dataset bias therefore provide important comparison assessing performance multimodal technique present unimodal ablation three recent datasets visual navigation qa seeing absolute gain performance published baseline
eyetracking data chinese language present unique challenge due nonalphabetic unspaced nature chinese writing system paper introduces first deeplyannotated joint mandarincantonese eyetracking dataset achieve unified eyetracking prediction system language variety addition commonly studied first fixation duration total fixation duration dataset also includes second fixation duration expressing fixation pattern relevant higherlevel structural processing basic comparison feature measurement dataset revealed variation mandarin cantonese fixation pattern related word class word position test feature usefulness suggested traditional feature less powerful predicting secondpass fixation linear distance root make leading contribution mandarin contrast cantonese eyemovement behavior relies word position part speech
idiom lexicallycomplex phrase whose meaning derived compositionally interpreting component although automatic identification understanding idiom essential wide range natural language understanding task still largely underinvestigated motivated organization semeval task divided two multilingual subtasks one idiomaticity detection sentence embeddings work focus first subtask propose transformerbased dualencoder architecture compute semantic similarity potentiallyidiomatic expression context based predict idiomaticity show extent named entity recognition exploited reduce degree confusion idiom identification system therefore improve performance model achieves f oneshot setting show strong robustness towards unseen idiom achieving f zeroshot setting release code urlhttpsgithubcombabelscapenerid
natural language generated people yet traditional language modeling view word document generated independently propose human language modeling hulm hierarchical extension language modeling problem human level exists connect sequence document eg social medium message capture notion human language moderated changing human state introduce hart largescale transformer model solving hulm pretrained approximately social medium user demonstrate effectiveness term language modeling perplexity social medium finetuning downstream task spanning document userlevels result task meet surpass current stateoftheart
abundance electronic health record ehr produced every day within healthcare record possess valuable information research future improvement healthcare multiple effort done protect integrity patient making electronic health record usable research removing personally identifiable information patient record supervised machine learning approach deidentification ehrs need annotated data training annotation costly time human resource annotation cost clinical text even costly process must carried protected environment limited number annotator must signed confidentiality agreement paper therefore semisupervised method proposed automatically creating highquality training data study show method used improve recall without sacrificing precision extent dropping model recall arguably important deidentification precision
degree ascribe cognitive capacity large language model llm ability reason intention belief known theory mind tom add emerging debate testing base instructiontuned llm capability relevant tom beyond dominant falsebelief paradigm including nonliteral language usage recursive intentionality ii using newly rewritten version standardized test gauge llm robustness iii prompting scoring open besides closed question iv benchmarking llm performance child aged task find instructiontuned llm gpt family outperform model often also child basellms mostly unable solve tom task even specialized prompting suggest interlinked evolution development language tom may help explain instructiontuning add rewarding cooperative communication take account interlocutor context conclude arguing nuanced perspective tom llm
recent time attention brought human language technology hlt community legal framework making available reusing language resource lr tool licensing issue foreseen research project essential provide legal certainty repository distributing resource repository zenodo quantum stat offer possibility search resource license turn searching relevant resource complex task repository hugging face propose search feature license may make difficult figure use made resource european language grid elg project moved step forward link metadata term condition use paper document process undertook categorize legal feature license listed spdx license list widely used hlt community well license used within elg platform
text simplification emerged increasingly useful application ai bridging communication gap specialized field medicine lexicon often dominated technical jargon complex construct despite notable progress method medical simplification sometimes result generated text lower quality diversity work explore way improve readability text simplification medical domain propose new unlikelihood loss encourages generation simpler term reranked beam search decoding method optimizes simplicity achieve better performance readability metric three datasets study finding offer promising avenue improving text simplification medical field
consumer read online review insight help make decision given large volume review succinct review summary important many application existing research focused mining opinion review text largely ignores reviewer however reviewer bias may write lenient harsh review may also preference towards topic others therefore review equal ignoring bias review generate misleading summary aim summarization review include balanced opinion reviewer different bias preference propose model reviewer bias review text rating distribution learn biasaware opinion representation devise approach balanced opinion summarization review using biasaware opinion representation
domainspecific ner due insufficient labeled training data deep model usually fail behave normally paper proposed novel neural inductive teaching framework nite transfer knowledge existing domainspecific ner model arbitrary deep neural network teacherstudent training manner nite general framework build upon transfer learning multiple instance learning collaboratively transfer knowledge deep student network also reduces noise teacher nite help deep learning method effectively utilize existing resource ie model labeled unlabeled data small domain experiment resulted disease ner proved without using labeled data nite significantly boost performance cnnbidirectional lstmcrf ner neural network nearly term fscore
paper describe new webbased corpus hypernym detection consists gb high quality english paragraph along partofspeech tagged dependency parsed version hypernym detection current stateoftheart us corpus available freely evaluate stateoftheart method corpus achieve similar result advantage corpus available open license main contribution corpus postags dependency tag code extract simulate result achieved using corpus
paper present new webbased annotation tool clarinel webbased annotation tool based existing annotation infrastructure offered ellogon language enginneering platform new tool transfer large part ellogons feature functionality web environment exploiting capability cloud computing new annotation tool able support wide range annotation task user provided annotation schema xml new annotation tool already employed several annotation task including anotation argument presented use case clarinel annotation tool compared existing solution along several dimension feature finally future work includes improvement integration clarinel infrastructure inclusion feature currently supported annotation aligned document
present fiveyear retrospective development voxworld platform first introduced multimodal platform modeling motion language evolved platform rapidly building deploying embodied agent contextual situational awareness capable interacting human multiple modality exploring environment particular discus evolution theoretical underpinnings voxml modeling language platform accommodates neural symbolic input build agent capable multimodal interaction hybrid reasoning focus three distinct agent implementation functionality needed accommodate diana virtual collaborative agent kirby mobile robot babybaw agent selfguides exploration world
presented work aim generating systematically annotated corpus support enhancement sentiment analysis task telugu using wordlevel sentiment annotation ontosensenet extracted adjective adverb verb sentiment annotation done language expert discus methodology followed polarity annotation validate developed resource work aim developing benchmark corpus extension sentiwordnet baseline accuracy model lexeme annotation applied sentiment prediction fundamental aim paper validate study possibility utilizing machine learning algorithm wordlevel sentiment annotation task automated sentiment identification furthermore accuracy improved annotating bigram extracted target corpus
documentlevel event extraction dee task event argument always scatter across sentence acrosssentence issue multipleevents may lie one document multievent issue paper argue relation information event argument greatsignificance addressing two issue propose new dee framework model relation dependency calledrelationaugmented documentlevel event extraction redee specifically framework feature novel tailored transformernamed relationaugmented attention transformer raat raat scalable capture multiscale multiamount argument relation leverage relation information introduce separate event relation prediction task adopt multitask learning method explicitly enhance event extraction performance extensive experiment demonstrate effectiveness proposed method achieve stateoftheart performance two public datasets code available urlhttpsgithubcomtencentyouturesearchraat
coreference resolution task finding expression refer entity text coreference model generally trained monolingual annotated data annotating coreference expensive challenging hardmeier et al shown parallel data contains latent anaphoric knowledge explored endtoend neural model yet paper propose simple yet effective model exploit coreference knowledge parallel data addition conventional module learning coreference annotation introduce unsupervised module capture crosslingual coreference knowledge proposed crosslingual model achieves consistent improvement percentage point ontonotes english dataset using different synthetic parallel datasets experimental result confirm parallel data provide additional coreference knowledge beneficial coreference resolution task
recently research explored graph neural network gnn technique text classification since gnn well handling complex structure preserving global information however previous method based gnn mainly faced practical problem fixed corpus level graph structure dont support online testing high memory consumption tackle problem propose new gnn based model build graph input text global parameter sharing instead single graph whole corpus method remove burden dependence individual text entire corpus support online testing still preserve global information besides build graph much smaller window text extract local feature also significantly reduce edge number well memory consumption experiment show model outperforms existing model several text classification datasets even consuming less memory
transformer become defacto standard speech modeling upon finegrained framelevel feature remains open challenge capturing longdistance dependency distributing attention weight propose progressive downsampling pd gradually compress acoustic feature coarsergrained unit containing complete semantic information like textlevel representation addition develop representation fusion method alleviate information loss occurs inevitably high compression way compress acoustic feature initial length achieving better comparable performance speech recognition task bonus yield inference speedup ranging x xby reducing modeling burden also achieve competitive result training challenging speech translation task
triangular machine translation special case lowresource machine translation language pair interest limited parallel data language abundant parallel data pivot language naturally key triangular machine translation successful exploitation auxiliary data work propose transferlearningbased approach utilizes type auxiliary data train auxiliary sourcepivot pivottarget translation model initialize parameter pivot side pretrained language model freeze encourage translation model work pivot language space smoothly transferred sourcetarget translation model experiment show approach outperform previous one
event detection one fundamental task information extraction knowledge graph however realistic event detection system often need deal new event class constantly new class usually labeled instance timeconsuming laborintensive annotate large number unlabeled instance therefore paper proposes new task called classincremental fewshot event detection nevertheless two problem ie old knowledge forgetting new class overfitting task solve problem paper present novel knowledge distillation prompt learning based method called promptkd specifically reduce forgetting issue old knowledge promptkd develops attention based multiteacher knowledge distillation framework ancestor teacher model pretrained base class reused learning session father teacher model derives current student model via adaptation hand order cope fewshot learning scenario alleviate corresponding new class overfitting problem promptkd also equipped prompt learning mechanism extensive experiment two benchmark datasets ie fewevent maven demonstrate stateoftheart performance promptkd
research metaphorical language shown tie abstractness emotionality regard metaphoricity prior work however limited word sentence level date empirical study establishing extent also true discourse level paper explores textual perceptual feature human annotator perceive important metaphoricity discourse expression address two research question specifically first metaphoricallyperceived discourse abstract emotional comparison literally perceived discourse second metaphorical expression preceded metaphoricalabstractemotional context synonymous literal alternative used dataset corpusextracted discourse crowdsourced annotator provided judgement whether perceived discourse metaphorical literal systematically listed lexical term triggered decision result indicate metaphorical discourse emotional certain extent abstract literal discourse however neither metaphoricity abstractness emotionality preceding discourse seem play role triggering choice synonymous metaphorical v literal expression dataset available urlhttpswwwimsunistuttgartdedatadiscoursemetlit
current natural language processing strongly focused raising accuracy progress come cost superheavy model hundred million even billion parameter however simple syntactic task partofspeech po tagging dependency parsing named entity recognition ner require largest model achieve acceptable result line assumption try minimize size model jointly performs three task introduce comboner lightweight tool order magnitude smaller stateoftheart transformer based pretrained subword embeddings recurrent neural network architecture comboner operates polish language data model output po tagging dependency parsing ner paper contains insight finetuning model report overall result
ai system embodied physical world face fundamental challenge partial observability operating limited view knowledge environment creates challenge ai system try reason language relationship environment object referred language eg giving many instruction immediately visible action ai system may required bring object view good benchmark study challenge dynamic referring expression recognition drer task goal find target location dynamically adjusting field view fov partially observed scene paper introduce holm hallucinating object language model address challenge partial observability holm us large pretrained language model lm infer object hallucination unobserved part environment core intuition pair object coappear environment frequently usage language reflect fact world based intuition prompt language model extract knowledge object affinity give u proxy spatial relationship object experiment show holm performs better stateoftheart approach two datasets drer allowing study generalization indoor outdoor setting
propose simple efficient framework learn syntactic embeddings based information derived constituency parse tree using biased random walk method embeddings encode syntactic information word also capture contextual information also propose method train embeddings multiple constituency parse tree ensure encoding global syntactic representation quantitative evaluation embeddings show competitive performance po tagging task compared type embeddings qualitative evaluation reveals interesting fact syntactic typology learned embeddings
recent work clark et al introduces ai reasoning challenge arc associated arc dataset partition open domain complex science question easy challenge set paper includes analysis question respect type knowledge reasoning required answer however include clear definition type offer information quality label propose comprehensive set definition knowledge reasoning type necessary answering question arc dataset using ten annotator sophisticated annotation interface analyze distribution label across challenge set statistic related additionally demonstrate although naive information retrieval method return sentence irrelevant answering query sufficient supporting text often present arc corpus evaluating humanselected relevant sentence improves performance neural machine comprehension model point
acl anthology prime resource research paper within computational linguistics natural language processing continuing opensource communitydriven project since gildea et al reported state planned direction anthology seen major technical change discus led change impact longterm maintainability community engagement describe opensource data software tool anthology currently provides provide survey literature used anthology main data source
paper describe correction po tag new icelandic corpus mimgold consisting million token sampled tagged icelandic corpus mim released goal use corpus among thing new gold standard training testing po tagger construction corpus first described together preliminary work error detection correction paper describe correction tag corpus describe manual correction method semiautomatic error detection correction show even manual correction number tagging error corpus reduced significantly applying semiautomatic detection correction method semiautomatic error correction preliminary evaluation tagging accuracy show low error rate hope existence corpus make possible improve po tagger icelandic text
casual neutral formal language register highly perceptible discourse production however still poorly studied natural language processing nlp especially outside english new textual type like tweet stimulate research paper introduces large corpus french tweet word annotated language register label provided multilabel camembert classifier trained checked manually annotated subset corpus tweet selected avoid undesired bias based corpus initial analysis linguistic trait either human annotator automatic extraction provided describe corpus pave way various nlp task corpus annotation guide classifier available urlhttptremoloirisafr
misinformation pose critical societal challenge current approach yet produce effective solution propose focusing generalization uncertainty leverage recent large language model order create practical tool evaluate information veracity context perfect classification impossible first demonstrate gpt outperform prior method multiple setting language next explore generalization revealing gpt robertalarge exhibit difference failure mode third propose technique handle uncertainty detect impossible example strongly improve outcome also discus result language model temperature prompting versioning explainability web retrieval one providing practical insight direction future research finally publish liarnew dataset novel paired english french misinformation data possibility label indicate sufficient context veracity evaluation overall research lay groundwork future tool drive realworld progress combat misinformation
identifying metaphor text challenging requires comprehending underlying comparison automation cognitive process gained wide attention lately however majority existing approach concentrate wordlevel identification treating task either singleword classification sequential labelling without explicitly modelling interaction metaphor component hand existing relationlevel approach implicitly model interaction ignore context metaphor occurs work address limitation introducing novel architecture identifying relationlevel metaphoric expression certain grammatical relation based contextual modulation methodology inspired work visual reasoning approach based conditioning neural network computation deep contextualised feature candidate expression using featurewise linear modulation demonstrate proposed architecture achieves stateoftheart result benchmark datasets proposed methodology generic could applied textual classification problem benefit contextual interaction
recent work shown current text classification model fragile sensitive simple perturbation work propose novel adversarial training approach lexicalat improve robustness current classification model proposed approach consists generator classifier generator learns generate example attack classifier classifier learns defend attack considering diversity attack generator us largescale lexical knowledge base wordnet generate attacking example replacing word training example synonym eg sad unhappy neighbor word eg fox wolf supersuperior word eg chair armchair due discrete generation step generator use policy gradient reinforcement learning approach train two module experiment show lexicalat outperforms strong baseline reduces test error various neural network including cnn rnn bert
article introduce two new part new multipart version lexical markup framework lmf iso standard namely part standard iso deal etymological diachronic data part iso consists tei serialisation prior part model demonstrate use standard describing lmf encoding small number example taken sample conversion reference portuguese dictionary textitgrande dicionario houaiss da lingua portuguesa part broader experiment comprising analysis different heterogeneously encoded portuguese lexical resource present example unified modelling language uml also couple case tei
paper focus domainspecific translation low resource indomain parallel corpus scarce nonexistent one common effective strategy case exploiting indomain monolingual data backtranslation method however synthetic parallel data noisy generated imperfect outofdomain system resulting poor performance domain adaptation address issue propose novel iterative domainrepaired backtranslation framework introduces domainrepair dr model refine translation synthetic bilingual data end construct corresponding data dr model training roundtrip translating monolingual sentence design unified training framework optimize paired dr nmt model jointly experiment adapting nmt model specific domain general domain specific domain demonstrate effectiveness proposed approach achieving bleu improvement average unadapted model backtranslation
paper examines usefulness semantic feature based word alignment estimating quality text simplification specifically introduce seven type alignmentbased feature computed basis word embeddings paraphrase lexicon empirical experiment using qat dataset confirm achieve stateoftheart performance feature
natural language processing nlp increasingly relying general endtoend system need handle many different linguistic phenomenon nuance example natural language inference nli system recognize sentiment handle number perform coreference etc solution complex problem still far perfect important create system learn correct mistake quickly incrementally little training data work propose continual fewshot learning cfl task system challenged difficult phenomenon asked learn correct mistake training example end first create benchmark based previously annotated data two nli anli snli one sentiment analysis imdb datasets next present various baseline diverse paradigm eg memoryaware synapsis prototypical network compare fewshot learning continual fewshot learning setup contribution creating benchmark suite evaluation protocol continual fewshot learning text classification task making several interesting observation behavior similaritybased method hope work serf useful starting point future work important topic
text infilling aim restore incomplete text filling blank attracted attention recently wide application ancient text restoration text rewriting however attribute aware text infilling yet explored existing method seldom focus infilling length blank numberlocation blank paper propose attributeaware text infilling method via pretrained language model atip contains text infilling component plug andplay discriminator specifically first design unified text infilling component modified attention mechanism intra interblank positional encoding better perceive number blank infilling length blank propose plugandplay discriminator guide generation towards direction improving attribute relevance without decreasing text fluency finally automatic human evaluation three opensource datasets indicate atip achieves stateof theart performance compared baseline
natural language generation lie core generative dialogue system conversational agent describe ensemble neural language generator present several novel method data representation augmentation yield improved result model test model three datasets restaurant tv laptop domain report objective subjective evaluation best model using range automatic metric well human evaluator show approach achieves better result stateoftheart model datasets
information retrieval relational database requires professional understanding structural query language sql textsql model apply natural language inference enable user interacting database via natural language utterance current textsql model normally focus generating complex sql query precise complete fashion certain feature realworld application production environment fully addressed paper aimed develop serviceoriented texttosql parser translates natural language utterance structural executable sql query introduce algorithmic framework named semanticenriched sql generator sesql enables flexibly access database rigid api application keeping performance quality commonly used case qualitative result show proposed model achieves execution accuracy wikisql task outperforming baseline error reduction moreover framework considers several serviceoriented need including lowcomplexity inference outoftable rejection text normalization
specialized information service biodiversity research biofid launched mobilize valuable biological data printed literature hidden german library past year project annotate german text converted ocr historical scientific literature biodiversity plant bird moth butterfly work enables automatic extraction biological information previously buried mass paper volume purpose generated training data task named entity recognition ner taxon recognition tr biological document use data train number leading machine learning tool create gold standard tr biodiversity literature specifically perform practical analysis newly generated biofid dataset various downstreamtask evaluation establish new state art tr fscore sense paper lay foundation future work field information extraction biology text
paper summarizes research multilingual detection persuasion technique meme semeval task work focused englishsubtask implemented based robertalarge pretrained model provided transforms tool finetuned corpus social medium post method significantly outperforms officially released baseline method ranked th englishsubtask test set paper also compare performance different deep learning model architecture bert albert xlmroberta multilingual detection persuasion technique meme experimental source code covered paper later sourced github
layerattentivelstmcailfbert
propose asymmetric encoderdecoder structure keep rnn encoder cnn decoder model explores subsequent context information supervision asymmetry model architecture training pair reduces large amount training time contribution work summarized design experiment show autoregressive decoder rnn decoder necessary encoderdecoder type model term learning sentence representation based result present finding two interesting finding lead final model design rnn encoder cnn decoder learns encode current sentence decode subsequent contiguous word suite technique model performs good downstream task trained efficiently large unlabelled corpus
paper present first attempt verifying integrity constraint openwordnetpt ontology wordnet encoding wordnet distributed resource description format rdf want guarantee syntax correctness also semantics soundness
understanding influence training instance neural network model lead improving interpretability however difficult inefficient evaluate influence show model prediction would changed training instance used paper propose efficient method estimating influence method inspired dropout zeromasks subnetwork prevents subnetwork learning training instance switching dropout mask use subnetworks learned learn training instance estimate influence experiment bert vggnet classification datasets demonstrate proposed method capture training influence enhance interpretability error prediction cleanse training dataset improving generalization
release massive expansion paraphrase database ppdb includes collection paraphrase different language resource derived large volume bilingual parallel data collection extracted ranked using state art method multilingual ppdb billion paraphrase pair total covering following language arabic bulgarian chinese czech dutch estonian finnish french german greek hungarian italian latvian lithuanian polish portugese romanian russian slovak slovenian swedish
paper describes project called axolotl comprises spanishnahuatl parallel corpus search interface spanish nahuatl distant language spoken country due scarcity digital resource describe several problem arose compiling corpus source nondigital book faced error digitizing source difficulty sentence alignment process mention document parallel corpus homogeneous extracted different source dialectal diachronical orthographical variation additionally present web search interface allows make query whole parallel corpus system capable retrieve parallel fragment contain word phrase searched user language knowledge first spanishnahuatl public available digital parallel corpus think resource useful develop language technology linguistic study language pair
current reading comprehension method generalise well indistribution test set yet perform poorly adversarially selected data prior work adversarial input typically study model oversensitivity semantically invariant text perturbation cause model prediction change focus complementary problem excessive prediction undersensitivity input text meaningfully changed model prediction even though formulate adversarial attack search among semantic variation question model erroneously predicts answer even higher probability demonstrate model trained squad newsqa vulnerable attack investigate data augmentation adversarial training defence substantially decrease adversarial vulnerability generalises heldout data heldout attack space addressing undersensitivity furthermore improves model robustness previously introduced addsent addonesent datasets model generalise better facing train evaluation distribution mismatch less prone overly rely shallow predictive cue present training set outperform conventional model much f
biomedical event extraction natural text challenging task search complex often nested structure describing specific relationship multiple molecular entity gene protein cellular component usually implemented complex pipeline individual tool solve different relation extraction subtasks present alternative approach detection relationship entity described uniformly question iteratively answered question answering qa system based domainspecific language model scibert model outperforms two strong baseline two biomedical event extraction corpus knowledge base population setting also achieves competitive performance bionlp challenge evaluation setting
article describes methodology recovering preservation old romanian text problem related recognition focus create gold corpus romanian language novella sania alphabet used transnistria cyrillic latin resource available similar research technology based transliteration semiautomatic alignment parallel text level letterlexemmultiwords analysed every text segment present corpus discovered convention writing level transliteration academic norm editorial intervention convention allowed u elaborate implement new heuristic make correct automatic transliteration process sometimes word latin script modified cyrillic script semantic reason instance editor interpretation semantic transliteration seen good practice introducing multiwords cyrillic latin preserve multiwords sound source script also enables translator modify original text choosing common sense expression technology could interest lexicographer also specialist computational linguistics improve actual transliteration standard
paper introduce evalnlp shared task explainable quality estimation given sourcetranslation pair shared task requires provide sentencelevel score indicating overall quality translation also explain score identifying word negatively impact translation quality present data annotation guideline evaluation setup shared task describe six participating system analyze result best knowledge first shared task explainable nlp evaluation metric datasets result available urlhttpsgithubcomevalnlpsharedtask
present simple knowledgebased wsd method us word sense embeddings compute similarity gloss sense context word method inspired lesk algorithm exploit context word definition sens requires large unlabeled corpus sense inventory wordnet therefore rely annotated data explore whether additional extension lesk compatible method result experiment show lexically extending amount word gloss context although work well implementation lesk harm method using lexical selection method context word hand improves combination method lexical selection enables method outperform stateof art knowledgebased system
propose novel approach learn domainspecific plausible material component vehicle repair domain probing pretrained language model plms cloze task style setting overcome lack annotated datasets devise new method aggregate salient prediction set cloze query template show domainadaptation using either small highquality customized wikipedia corpus boost performance exploring resourcelean alternative find distilled plm clearly outperforming classic patternbased algorithm given domainspecific component multiword expression successfully exploit compositionality assumption way address data sparsity
large language model llm exhibited remarkable capability learning expla nation prompt limited understanding exactly explana tions function effective work aim better understand mechanism explanation used incontext learning first study impact two dif ferent factor performance prompt explanation computation trace way solution decomposed natural language used express prompt per turbing explanation three controlled task show factor contribute ef fectiveness explanation study form maximally effective set expla nation solving given test query find llm benefit complemen tarity explanation set diverse reasoning skill shown different exemplar lead better performance therefore propose maximal marginal relevancebased exemplar selection approach constructing exemplar set relevant well comple mentary successfully improves context learning performance across three real world task multiple llm
traditional entity linking el technology rely rich structure property target knowledge base kb however many application kb may simple sparse list name type eg list product call listonly entity linking problem fortunately mention may cue linking used seed mention bridge mention uninformative entity work select linkable mention seed mention disambiguate mention comparing seed mention rather directly entity experiment linking mention seven automatically mined list show promising result demonstrate effectiveness approach
tackling task given domain shown adapting model domain using raw text data training supervised task improves performance versus solely training task downside lot domain data required want tackle task n domain require n model adapted domain data task learning storing using model separately prohibitive lowend device paper show domain adaptation generalised cover multiple domain specifically single model trained across various domain time minimal drop performance even use less data resource thus instead training multiple model train single multidomain model saving computational resource training time
use automatic evaluation metric assess machine translation mt quality well established translation industry whereas relatively easy cover word characterbased metric mt course less obvious integrate newer neural metric paper discus introduced topic mt quality assessment course translation student selected three english source text different difficulty level style let student translate text l reflect upon translation difficulty afterwards student asked assess mt quality text using different method critically reflect upon obtained result student access mateo web interface contains word characterbased metric well neural metric student used two different reference translation translation professional translation three text synthesise comment student also present result crosslingual analysis nine different language pair
research natural language processing nlp aim detect hate speech comment specifically targeted lgbtq community within youtube platform shared task conducted ltedi workshop dataset provided organizer exhibited high degree class imbalance mitigate employed nlpaug data augmentation library employed several classification method reported result using recall precision fscore metric classification model discussed paper include bidirectional long shortterm memory bilstm model trained wordvec embeddings bilstm model trained twitter glove embeddings transformer model bert distibert roberta xlmroberta trained finetuned achieved weighted fscore test data secured fifth place task b class english language
automatic language identification li widely addressed task user example linguist mean interest develop tool train existing one data several offtheshelf li tool language unclear tool best specific type text article present comparison performance several offtheshelf language identification tool bulgarian social medium data li tool tested multilingual twitter dataset composed tweet existing bulgarian twitter dataset topic fake content detection tweet article present manual annotation procedure first dataset dis cussion decision two annotator result testing offtheshelf li tool datasets finding show tool easiest user programming skill achieves highest fscore bulgarian social medium data tool useful functionality bulgarian social medium text
propose novel hybrid approach lemmatization enhances seqseq neural model additional lemma extracted external lexicon rulebased system training enhanced lemmatizer learns generate lemma via sequential decoder copy lemma character external candidate supplied runtime lemmatizer enhanced candidate extracted apertium morphological analyzer achieves statistically significant improvement compared baseline model utilizing additional lemma information achieves average accuracy set ud language higher obtained stanford stanza model set language also compare method integrating external data lemmatization show enhanced system performs considerably better simple lexicon extension method based stanza system achieves complementary improvement wrt data augmentation method
verb lexical semantic property one factor contribute determination event type expressed sentence instead result complex interplay verb meaning linguistic context report two computational model automatic identification event type italian model use linguisticallymotivated feature extracted italian corpus main goal experiment evaluate contribution different type linguistic indicator identify event type sentence well model various case contextdriven event type shift first model event type identification modelled supervised classification task performed maximum entropy classifier second model selforganizing map used define identify event type unsupervised way interaction various contextual factor determining event type expressed sentence make event type identification highly challenging task computational model help u shed new light real structure event type class well gain better understanding contextdriven semantic shift
charge prediction task determine appropriate charge given case helpful legal assistant system user input fact description argue relevant law article play important role task therefore propose attentionbased neural network method jointly model charge prediction task relevant article extraction task unified framework experimental result show besides providing legal basis relevant article also clearly improve charge prediction result full model effectively predict appropriate charge case different expression style
location information support social medium analysis providing geographic context accurate popular twitter geolocation system rely rulebased method examine userprovided profile location fail handle informal noisy location name propose geoseqseq sequencetosequence seqseq model twitter user geolocation rewrite noisy multilingual userprovided location string structured english location name train system ten million multilingual location string geotaggedtweet pair compared leading method model vastly increase coverage ie number user geolocate achieving comparable superior accuracy error analysis reveals constrained decoding help model produce valid location according location database finally measure bias across language country origin time evaluate fairness find model generalize well unseen temporal data performance vary language country
evolution knowledge graph kg new entity emerge seen representation learning kg inductive setting aim capture transfer structural pattern existing entity new entity however performance existing method inductive kg limited sparsity implicit transfer paper propose vmcl contrastive learning cl framework graph guided variational autoencoder metakgs inductive setting first propose representation generation capture encoded generated representation entity generated variation densify representation complementary feature design two cl objective work across entity metakgs simulate transfer mode extensive experiment demonstrate proposed vmcl significantly outperform previous stateoftheart baseline
cosmos multidisciplinary research project investigating schoolchildrens belief representation specific concept control variable age gender language spoken home seven concept studied textitfriend father mother villain work television textitdog first present protocol used data collected survey child two age group year four school brittany france wordlevel lexical study show childrens linguistic proficiency lexical diversity increase age observe interaction effect gender age lexical diversity measured mlr measure lexical richness contrast none control variable affect lexical density also present lemma schoolchildren often associate concept generalized linear mixedeffects model reveal significant effect age gender home language conceptlemma association specific interaction age gender identified effect documented child development literature better understand process semantic construction child additional lexical analysis ngram chunk clause level would helpful briefly present ongoing planned work direction cosmos data soon made freely available scientific community
paper describes npumsxf system iwslt speechtospeech translation sst task aim translate english speech multisource chinese speech system built cascaded manner consisting automatic speech recognition asr machine translation mt texttospeech tt make tremendous effort handle challenging multisource input specifically improve robustness multisource speech input adopt various data augmentation strategy roverbased score fusion multiple asr model output better handle noisy asr transcript introduce threestage finetuning strategy improve translation accuracy finally build tt model high naturalness sound quality leverage twostage framework using network bottleneck feature robust intermediate representation speaker timbre linguistic content disentanglement based twostage framework pretrained speaker embedding leveraged condition transfer speaker timbre source english speech translated chinese speech experimental result show system high translation accuracy speech naturalness sound quality speaker similarity moreover show good robustness multisource data
word embeddings learn implicit bias linguistic regularity captured word cooccurrence statistic extending method quantify humanlike bias word embeddings introduce valnorm novel intrinsic evaluation task method quantify valence dimension affect humanrated word set social psychology apply valnorm static word embeddings seven language chinese english german polish portuguese spanish turkish historical english text spanning year valnorm achieves consistently high accuracy quantifying valence nondiscriminatory nonsocial group word set specifically valnorm achieves pearson correlation r human judgment score valence word collected establish pleasantness norm english contrast measure gender stereotype using set word embeddings find social bias vary across language result indicate valence association nondiscriminatory nonsocial group word represent widelyshared association seven language year
natural language inference nli semantic textual similarity sts key task natural language understanding nlu although several benchmark datasets task released english language publicly available nli sts datasets korean language motivated construct release new datasets korean nli sts dubbed kornli korsts respectively following previous approach machinetranslate existing english training set manually translate development test set korean accelerate research korean nlu also establish baseline kornli korsts datasets publicly available urlhttpsgithubcomkakaobrainkornludatasets
paper introduce method identifying component ie dimension word embeddings strongly signifies property word elucidating property hidden word embeddings could make word embeddings interpretable also could perform propertybased meaning comparison capability answer question like degree given word property cuteness perspective two word similar verify method examining strength propertysignifying component correlate degree prototypicality target word
topic segmentation play important role discourse parsing information retrieval due absence training data previous work mainly adopts unsupervised method rank semantic coherence paragraph topic segmentation paper present intuitive simple idea automatically create quasi training dataset includes large amount text pair different document different semantic coherence training corpus design symmetric cnn neural network model text pair rank semantic coherence within learning rank framework experiment show algorithm able achieve competitive performance strong baseline several realworld datasets
study applied deep lstm structure classify dialogue act da opendomain conversation found word embeddings parameter dropout regularization decay rate number layer parameter largest effect final system accuracy using finding experiment trained deep lstm network outperforms stateoftheart switchboard corpus mrda
answer selection opendomain dialogue aim select accurate answer candidate recent success answer selection model hinge training large amount labeled data however collecting largescale labeled data laborintensive timeconsuming paper introduce predicted intent label calibrate answer label selftraining paradigm specifically propose intentcalibrated selftraining icast improve quality pseudo answer label intentcalibrated answer selection paradigm employ pseudo intent label help improve pseudo answer label carry extensive experiment two benchmark datasets opendomain dialogue experimental result show icast outperforms baseline consistently labeled data specifically improves f score two datasets compared strongest baseline labeled data
identifying complex word text important first step text simplification t system paper investigate performance binary comparative lexical complexity prediction lcp model applied popular benchmark dataset complex dataset used semeval task data complex create new dataset contain sentence referred complexbc using complexbc train multiple model differentiate two target word less complex sentence linear svm model achieved best performance experiment fscore
paper describe mflens multilingual flexible plugandplay architecture designed accommodate neural symbolic module initially instantiated rulebased module focus using mflens specific purpose building new resource irish language currently underrepresented nlp landscape present general mflens framework use build irish natural language generation system verbalising part dbpedia ontology building multilayered dataset rich linguistic annotation via automatic human assessment output text show limited resource able create system reach high level fluency semantic accuracy low energy memory requirement
dialogue system becoming ubiquitous various form shape virtual assistantssiri alexa etc chatbots customer support chitchat system name advance language model publication democratised advanced nlphowever data remains crucial bottleneck contribution essential pillar ismatilda best knowledge first multiannotator multilanguage dialogue annotation tool matilda allows creation corpus management user annotation dialogue quick adaptation user interface language resolution interannotator disagreement evaluate tool ease use annotation speed interannotation resolution expert novice conclude tool support full pipeline dialogue annotation also allows nontechnical people easily use completely opensourcing tool urlhttpsgithubcomwlupermatilda provide tutorial video
emotion detection high potential positive impact benefit business society politics education given main objective research contribute resolution one important challenge textual emotion detection emotional corpus annotation tackled proposing semiautomatic methodology consists two main phase automatic process preannotate unlabelled sentence reduced number emotional category manual process refinement human annotator determine dominant emotion predefined set objective paper show preannotation process well evaluate usability subjective polarity information process evaluation performed confirms clearly benefit employing polarity subjective information emotion detection thus endorses relevance approach
recent exploration commercial large language model llm shown nonexpert user jailbreak llm simply manipulating prompt resulting degenerate output behavior privacy security breach offensive output violation content regulator policy limited study conducted formalize analyze attack mitigation bridge gap proposing formalism taxonomy known possible jailbreak survey existing jailbreak method effectiveness opensource commercial llm gptbased model opt bloom flantxxl discus challenge jailbreak detection term effectiveness known attack analysis release dataset model output across jailbreak prompt task
present paw multilingual parallel treebank coreference annotation consists english text wall street journal translated czech russian polish addition text syntactically parsed wordaligned paw based pcedt continues tradition multilingual treebanks coreference annotation paper focus coreference annotation paw languagespecific difference paw offer linguistic material leveraged crosslingual study especially coreference
u congress legislator use active passive cosponsorship support bill show two type cosponsorship driven two different motivation backing political colleague backing bill content end develop encoderrgcn based model learns legislator representation bill text speech transcript representation predict active passive cosponsorship fscore applying representation predict voting decision show interpretable generalize unseen task
machine translation mt widely used crosslingual classification either translating test set english running inference monolingual model translatetest translating training set target language finetuning multilingual model translatetrain however research area focus multilingual model rather mt component show using stronger mt system mitigating mismatch training original text running inference machine translated text translatetest substantially better previously assumed optimal approach however highly task dependent identify various source crosslingual transfer gap affect different task approach differently work call question dominance multilingual model crosslingual classification prompt pay attention mtbased baseline
paper investigates two method constructing binary classifier distinguish humangenerated machinegenerated text main emphasis straightforward approach based zipfs law despite simplicity achieves moderate level performance additionally paper briefly discusses experimentation utilization unigram word count
present study leveraging multilingual pretrained generative language model zeroshot crosslingual event argument extraction eae formulating eae language generation task method effectively encodes event structure capture dependency argument design languageagnostic template represent event argument structure compatible language hence facilitating crosslingual transfer proposed model finetunes multilingual pretrained generative language model generate sentence fill languageagnostic template argument extracted input passage model trained source language directly applied target language event argument extraction experiment demonstrate proposed model outperforms current stateoftheart model zeroshot crosslingual eae comprehensive study error analysis presented better understand advantage current limitation using generative language model zeroshot crosslingual transfer eae
theory mind ie ability reason intent belief agent important task artificial intelligence central resolving ambiguous reference natural language dialogue work revisit evaluation theory mind question answering show current evaluation method flawed existing benchmark task solved without theory mind due dataset bias based prior work propose improved evaluation protocol dataset explicitly control data regularity via careful examination answer space show stateoftheart method successful existing benchmark fail solve theoryofmind task proposed approach
paper introduces citizen science platform languagearc developed within nieuw novel incentive workflow project supported national science foundation grant languagearc communityoriented online platform bringing together researcher citizen linguist shared goal contributing linguistic research language technology development like citizen science platform project languagearc harness power effort volunteer motivated incentive contributing science learning discovery belonging community dedicated social improvement citizen linguist contribute language data judgment participating research task classifying regional accent audio clip recording audio picture description answering personality questionnaire create baseline data nlp research autism neurodegenerative condition researcher create project language arc without coding html required using project builder toolkit
paper describes participation sinai team task toxic span detection consists identifying span make text toxic although several resource system developed far context offensive language annotation task mainly focused classifying whether text offensive however detecting toxic span crucial identify text toxic assist human moderator locate type content social medium order accomplish task follow deep learningbased approach using bidirectional variant long short term memory network along stacked conditional random field decoding layer bilstmcrf specifically test performance combination different pretrained word embeddings recognizing toxic entity text result show combination word embeddings help detecting offensive content team rank th participant
present outcome poststroke speech transcription psst challenge challenge prepared new data resource response two confrontation naming test found aphasiabank extracting audio adding new phonemic transcript response challenge consisted two task task asked challenger build automatic speech recognizer asr phonemic transcription psst sample evaluated term phoneme error rate per well finergrained metric derived phonological feature theory feature error rate fer best model fer per improving baseline relative respectively task b approximated downstream assessment task asking challenger identify whether recording contained correctly pronounced target word challenger unable improve baseline algorithm however using algorithm improved transcript task resulted accuracy f relative improvement respectively
paper built several pretrained model participate semeval task multilingual offensive language identification social medium common task offensive language identification social medium pretrained model bidirectional encoder representation transformer bert achieved good result preprocess dataset language habit user social network considering data imbalance offenseval screened newly provided machine annotation sample construct new dataset use dataset finetune robustly optimized bert pretraining approach roberta english subtask b adopted method adding auxiliary sentence transform singlesentence classification task relationship recognition task sentence team ujnlp win ranking th english subtask offensive language identification
describe ubcnlp contribution iest focused learning implicit emotion twitter data among participating team system ranked th textitfscore post competition able score slightly higher rd ranking system reaching system trained top pretrained language model lm finetuned data provided task organizer best result acquired average ensemble language model also offer analysis system performance impact training data size task example show training best model one epoch textless data enables better performance baseline reported klinger et al task
languageagnostic sentence embeddings generated pretrained model laser labse attractive option mining large datasets produce parallel corpus lowresource machine translation test laser labse extracting bitext two related lowresource african language luhya swahili work created new parallel set nearly luhyaenglish sentence allows new zeroshot test laser labse find labse significantly outperforms laser language laser labse however perform poorly zeroshot alignment luhya achieving successful alignment respectively p score finetune embeddings small set parallel luhya sentence show significant gain improving labse alignment accuracy restricting dataset sentence embedding pair cosine similarity yielded alignment accuracy
crowdsourced dialogue corpus usually limited scale topic coverage due expensive cost data curation would hinder generalization downstream dialogue model opendomain topic work leverage large language model dialogue augmentation task emotional support conversation esc treating dialogue augmentation dialogue completion task prompt finetuned language model complete full dialogue available dialogue post various topic postprocessed based heuristic applying approach construct augesc augmented dataset esc task largely extends scale topic coverage crowdsourced esconv corpus comprehensive human evaluation demonstrate approach superior strong baseline dialogue augmentation augesc comparable dialogue quality crowdsourced corpus also conduct human interactive evaluation prove posttraining augesc improves downstream dialogue model generalization ability opendomain topic result suggest utility augesc highlight potential large language model improving datascarce dialogue generation task
recent advance interpretability suggest project weight hidden state transformerbased language model lm vocabulary transformation make human interpretable paper investigate lm attention head memory value vector model dynamically create recall processing given input analyzing token represent projection identify pattern information flow inside attention mechanism based discovery create tool visualize forward pas generative pretrained transformer gpts interactive flow graph node representing neuron hidden state edge representing interaction visualization simplifies huge amount data easytoread plot reflect model internal processing uncovering contribution component model final prediction visualization also unveils new insight role layer norm semantic filter influence model output neuron always activated forward pass act regularization vector
extracting relational triple text crucial task constructing knowledge base recent advancement joint entity relation extraction model demonstrated remarkable f score mboxgeq accurately extracting relational triple free text however model evaluated restrictive experimental setting unrealistic datasets overlook sentence zero triple zerocardinality thereby simplifying task paper present benchmark study stateoftheart joint entity relation extraction model realistic setting include sentence lack triple experiment providing comprehensive evaluation finding reveal significant decline approximately one dataset another dataset model f score within realistic experimental setup furthermore propose twostep modeling approach utilizes simple bertbased classifier approach lead overall performance improvement model within realistic experimental setting
paper define apply representational stability analysis resta intuitive way analyzing neural language model resta variant popular representational similarity analysis rsa cognitive neuroscience rsa used compare representation model model component human brain resta compare instance model systematically varying single model parameter using resta study four recent successful neural language model evaluate sensitive internal representation amount prior context using rsa perform systematic study similar representational space first second higher layer model pattern activation human brain result reveal surprisingly strong difference language model give insight deep linguistic processing integrates information multiple sentence happening model combination resta rsa model brain allows u start addressing important question kind linguistic process hope observe fmri brain imaging data particular result suggest data story reading wehbe et al contains signal shallow linguistic processing show evidence interesting deep linguistic processing
predicting congressional legislator vote important understanding past future behavior however previous work rollcall prediction limited single session setting thus allowing generalization across session paper show text alone insufficient modeling voting outcome new context session change lead change underlying data generation process propose novel neural method encoding document alongside additional metadata achieving average boost accuracy previous stateoftheart
ability convey relevant faithful information critical many task conditional generation yet remains elusive neural seqtoseq model whose output often reveal hallucination fail correctly cover important detail work advocate planning useful intermediate representation rendering conditional generation less opaque grounded propose new conceptualization text plan sequence questionanswer qa pair enhance existing datasets eg summarization qa blueprint operating proxy content selection ie say planning ie order obtain blueprint automatically exploiting stateoftheart question generation technology convert inputoutput pair inputblueprintoutput tuples develop transformerbased model varying incorporate blueprint generated output eg global plan iteratively evaluation across metric datasets demonstrates blueprint model factual alternative resort planning allow tighter control generation output
speaker build rapport process aligning conversational behavior rapport engendered teachable agent instructing domain material shown promote learning past work lexical alignment field education suffers limitation measure used quantify alignment type interaction alignment agent studied paper apply alignment measure based datadriven notion shared expression possibly composed multiple word compare alignment oneonone humanrobot hr interaction hr portion collaborative humanhumanrobot hhr interaction find student hr setting align teachable robot hhr setting relationship lexical alignment rapport complex predicted previous theoretical empirical work
paper explores moral judgment moral reasoning ability exhibited large language model llm across language defining issue test well known fact moral judgment depends language question asked extend work beyond english new language chinese hindi russian spanish swahili probe three llm chatgpt gpt llamachatb show substantial multilingual text processing generation ability study show moral reasoning ability model indicated postconventional score substantially inferior hindi swahili compared spanish russian chinese english clear trend performance latter four language moral judgment vary considerably language
despite recent progress stateoftheart question answering model remain vulnerable variety adversarial attack dynamic adversarial data collection human annotator try write example fool modelintheloop improve model robustness process expensive limit scale collected data work first use synthetic adversarial data generation make question answering model robust human adversary develop data generation pipeline selects source passage identifies candidate answer generates question finally filter relabels improve quality using approach amplify smaller humanwritten adversarial dataset much larger set synthetic questionanswer pair incorporating synthetic data improve stateoftheart adversarialqa dataset f improve model generalisation nine twelve mrqa datasets conduct novel humanintheloop evaluation show model considerably robust new humanwritten adversarial example crowdworkers fool model time average compared model trained without synthetic data
mixedinitiative dialogue task involve repeated exchange information conversational control conversational agent gain control generating response follow particular dialogue intent strategy prescribed policy planner standard approach finetuning pretrained language model perform generation conditioned intent however supervised generation model limited cost quality data annotation instead prompt large language model dropin replacement finetuning conditional generation formalize prompt construction controllable mixedinitiative dialogue finding show improvement finetuning ground truth response according human evaluation automatic metric two task persuasionforgood emotional support conversation
paper describes winning system textgraphs shared task multihop inference explanation regeneration given question corresponding correct answer task aim select fact explain answer correct question answering qa large knowledge base address problem accelerate training well strategy includes two step first finetuning pretrained language model plms triplet loss recall topk relevant fact question answer pair adopting architecture train reranking model rank topk candidate improve performance average result model based different plms eg roberta different parameter setting make final prediction official evaluation show system outperform second best system point prof effectiveness system code open source address urlhttpsgithubcomdeepblueaitextgraphs
neural text generation neural machine translation summarization image captioning beam search widely used improve output text quality however neural generation setting hypothesis finish different step make difficult decide end beam search ensure optimality propose provably optimal beam search algorithm always return optimalscore complete hypothesis modulo beam size finish soon optimality established counter neural generation tendency shorter hypothesis also introduce bounded length reward mechanism allows modified version beam search algorithm remain optimal experiment neural machine translation demonstrate principled beam search algorithm lead improvement bleu score previously proposed alternative
debatepedia publicly available dataset consisting argument counterargument controversial topic widely used singledocument queryfocused abstractive summarization task recent year however recently found dataset limited noise even query dataset relevance respective document paper study whether large language model llm utilized clean debatepedia dataset make suitable queryfocused abstractive summarization specifically harness language generation capability two llm namely chatgpt palm regenerate query based experiment find solely depending large language model query correction may useful data cleaning however observe leveraging rulebased approach data sampling followed query regeneration using llm especially chatgpt sampled instance may ensure higher quality version dataset suitable development generalized queryfocused text summarization model
propose novel decoding approach neural machine translation nmt based continuous optimisation reformulate decoding discrete optimization problem continuous problem optimization make use efficient gradientbased technique powerful decoding framework allows accurate decoding standard neural machine translation model well enabling decoding intractable model intersection several different nmt model empirical result show decoding framework effective lead substantial improvement translation especially situation greedy search beam search feasible finally show technique highly competitive complementary reranking
paper present jsi wunlp system submitted dialectcopa shared task causal commonsense reasoning dialectal text jointly compare llmbased zeroshot fewshot incontext inference jsi team taskspecific fewshot finetuning english respective standard language zeroshot crosslingual transfer zsxlt test dialect wunlp team given strong zeroshot especially fewshot incontext learning icl performance investigate whether task semantics languagedialect semantics explain strong performance showing significant part improvement indeed stem learning language dialect semantics incontext example minor contribution understanding nature task higher importance dialect semantics task semantics shown finding incontext learning dialectal instance achieves comparable result supervised finetuning approach hundred instance standard language
social medium demographic inference critical task order gain better understanding cohort facilitate interacting one audience previous work made independence assumption topological textual label information social network work employ recursive neural network break independence assumption obtain inference demographic characteristic twitter show model performs better existing model including stateoftheart
workingnotes participation umuteam ltedi shared task concerning identification homophobic transphobic comment youtube comment written english high availability machinelearning resource tamil fewer resource transliteration tamil roman script combined english sentence carry shared task train neural network combine several feature set applying knowledge integration strategy feature linguistic feature extracted tool developed research group contextual noncontextual sentence embeddings ranked th english subtask macro fscore rd tamil subtask macro fscore nd tamilenglish subtask macro fscore
usergenerated content scorebased prediction item recommendation become inseparable part online recommendation system rating allow people express opinion may affect market value item consumer confidence ecommerce decision major problem model designed user review prediction unknowingly neglect rating bias occurring due personal user bias preference propose tendencybased approach model user item tendency score prediction along text review analysis respect rating
prevalent supervised learning method natural language processing nlp notoriously datahungry demand large amount highquality annotated data practice acquiring data costly endeavor recently superior fewshot performance large language model llm propelled development dataset generation training data solely synthesized llm however approach usually suffers lowquality issue requires order magnitude labeled data achieve satisfactory performance fully exploit potential llm make use massive unlabeled data propose llmaaa take llm annotator put active learning loop determine annotate efficiently learn robustly pseudo label optimize annotation training process draw knn example small demonstration pool incontext example adopt example reweighting technique assign training sample learnable weight compared previous approach llmaaa feature efficiency reliability conduct experiment analysis two classic nlp task named entity recognition relation extraction llmaaa taskspecific model trained llmgenerated label outperform teacher within hundred annotated example much costeffective baseline
paper describes named entity language resource developed part development project south african language development effort focused creating protocol annotated data set least annotated named entity token ten official south african language description protocol annotated data set provide overview problem encountered annotation data set based annotated data set crf named entity recognition system developed leverage existing linguistic resource newly created named entity recognisers evaluated fscores error analysis performed identify possible avenue improving quality system
paper describes umdsub system participated task semeval developed system predicts emoji given raw text english tweet system multichannel convolutional neural network based subword embeddings representation tweet model improves character word based method system placed st participating system official evaluation
human use language convey information also express inner feeling mental state work adapt stateoftheart language generation model generate affective emotional text posit model capable generating affectdriven topic focused sentence without losing grammatical correctness affect intensity increase propose incorporate emotion prior probabilistic stateoftheart text generation model gpt model give user flexibility control category intensity emotion well topic generated text previous attempt modelling finegrained emotion fall grammatical correctness extreme intensity model resilient delivers robust result intensity conduct automated evaluation human study test performance model provide detailed comparison result model evaluation model outperforms existing affective text generation model
machine translation system require semantic knowledge grammatical understanding neural machine translation nmt system often assume information captured attention mechanism decoder ensures fluency recent work shown incorporating explicit syntax alleviates burden modeling type knowledge however requiring parses expensive explore question syntax model need translation address issue introduce model simultaneously translates inducing dependency tree way leverage benefit structure investigating syntax nmt must induce maximize performance show dependency tree language pair dependent improve translation quality
present khan academy corpus totalling hour recording across language recording hour equipped humanwritten subtitle subtitle text cover total language dataset collected open access khan academy lecture benefiting manual transcript manual translation transcript dataset serve creation evaluation multilingual speech recognition translation system featuring diverse set subject domain
covid pandemic raging worldwide since beginning decade need monitoring system track relevant information social medium vitally important paper describes submission wnut task identification informative covid english tweet investigate effectiveness variety classification model found domainspecific pretrained bert model lead best performance top attempt variety ensembling strategy attempt lead improvement final best model standalone ctbert model proved highly competitive leading shared first place shared task result emphasize importance domain taskrelated pretraining
work investigate human perception coherence opendomain dialogue particular address problem annotating modeling coherence nextturn candidate considering entire history dialogue first create switchboard coherence swbdcoh corpus dataset humanhuman spoken dialogue annotated turn coherence rating nextturn candidate utterance rating provided considering full dialogue context statistical analysis corpus indicates turn coherence perception affected pattern distribution entity previously introduced dialogue act used second experiment different architecture model entity dialogue act combination evaluate performance predicting human coherence rating swbdcoh find model combining da entity information yield best performance response selection turn coherence rating
critical step achieve humanlike chatbots empathetic response generation attained increasing interest previous attempt incomplete sufficient enough elicit empathy stay initial stage empathy automatically sense simulate feeling thought others via otherawareness however ignore include selfawareness consider view self response crucial process achieve empathy end propose generate empathetic response explicit selfother awareness empsoa specifically three stage selfother differentiation selfother modulation selfother generation devised clearly maintain regulate inject selfother aware information process empathetic response generation automatic human evaluation benchmark dataset demonstrate superiority empsoa generate empathetic response source code publicly available
logical reasoning natural language one challenging task deep learning model increasing interest developing new benchmark evaluate reasoning capability language model bert parallel new model based transformer emerged achieve ever better performance datasets however currently library logical reasoning includes benchmark model paper introduces logitorch pytorchbased library includes different logical reasoning benchmark different model well utility function coreference resolution make easy directly use preprocessed datasets run model finetune different hyperparameters logitorch open source found github
paper focus problem dialog act da labelling problem recently attracted lot attention important subpart automatic question answering system currently great demand traditional method tend see problem sequence labelling task deal applying classifier rich feature current neural network model still omit sequential information conversation henceforth apply novel multilevel gated recurrent neural network grnn nontextual information predict da tag model utilizes textual information also make use nontextual contextual information comparison model shown significant improvement previous work switchboard dialog act swda task
common law judicial system follow doctrine precedent mean legal principle articulated court judgement binding subsequent case lower court reason lawyer must search prior judgement legal principle relevant case difficulty within legal profession information looking may contained within paragraph sentence paragraph may buried within hundredpage document study create schema based relevant information legal professional seek within judgement perform text classification based aim assisting lawyer researching case eventually enabling largescale analysis legal judgement find trend court outcome time
paper describes participation irit team trac shared task aggression identification precisely shared task english language three following method used combination machine learning technique relies set feature documenttext vectorization b convolutional neural network cnn c combination convolutional neural network cnn long shortterm memory lstm best result obtained using method english test data facebook ranked method sixteenth thirty team method c english test data social medium obtained fifteenth rank thirty
multilingual neural machine translation mnmt offer convenience translating multiple language single model however mnmt often suffers performance degradation highresource language compared bilingual counterpart degradation commonly attributed parameter interference occurs parameter fully shared across language pair work tackle issue propose gradientbased gradual pruning technique mnmt approach aim identify optimal subnetwork language pair within multilingual model leveraging gradientbased information pruning criterion gradually increasing pruning ratio schedule approach allows partial parameter sharing across language pair alleviate interference pair preserve unique parameter capture languagespecific information comprehensive experiment iwslt wmt datasets show approach yield notable performance gain datasets
describe submission semeval task specifically subtask persuasion technique detection work team nlubot tackled novel task classifying persuasion technique online news article paragraph level lowresource multilingual datasets along imbalanced label distribution make task challenging team presented crosslingual data augmentation approach leveraged recently proposed multilingual natural language inference model address challenge solution achieves highest macrof score english task top microf score english russian leaderboards
morpholex study root prefix suffix word analyzed morpholex many word analyzed according certain rule useful database created due fact turkish agglutinative language richness language structure offer different analyzes result previous study morpholex study revealed process creating database word result difference language structure
paper evaluate translation negation automatically manually englishgerman ende english chinese enzh show ability neural machine translation nmt model translate negation improved deeper advanced network although performance varies language pair translation direction accuracy manual evaluation ende deen enzh zhen respectively addition show undertranslation significant error type nmt contrast diverse error profile previously observed statistical machine translation better understand root undertranslation negation study model information flow training data information flow analysis reveal deficiency could used detect fix undertranslation negation find negation often rephrased training could make difficult model learn reliable link source target negation finally conduct intrinsic analysis extrinsic probing task negation showing nmt model distinguish negation nonnegation token well encode lot information negation hidden state nevertheless leave room improvement
previous method text data augmentation limited simple task weak baseline explore data augmentation hard task ie fewshot natural language understanding strong baseline ie pretrained model one billion parameter setting reproduced large number previous augmentation method found method bring marginal gain best sometimes degrade performance much address challenge propose novel data augmentation method flipda jointly us generative model classifier generate labelflipped data central idea flipda discovery generating labelflipped data crucial performance generating labelpreserved data experiment show flipda achieves good tradeoff effectiveness robustnessit substantially improves many task negatively affecting others
backtranslation data augmentation technique shown improve model quality creation synthetic training bitext early study showed promise technique follow study produced additional refinement undertaken broad investigation using backtranslation train model language english majority language considered moderate lowresource language observed consistent gain though compared prior work saw conspicuous gain quite number lowerresourced language analyzed difference translation baseline backtranslation model observed many indication improved translation quality translation rare common term improved improvement occur despite less natural synthetic sourcelanguage text used training
nearest neighbor word embedding model commonly observed semantically similar relation vary greatly investigate extent word embedding model preserve syntactic interchangeability reflected distance word vector effect hyperparameterscontext window size particular use part speech po proxy syntactic interchangeability generally speaking word po syntactically valid context also investigate relationship interchangeability similarity judged commonlyused word similarity benchmark correlate result performance word embedding model benchmark result inform future research application selection word embedding model suggesting principle appropriate selection context window size parameter depending usecase
answering question ask temporal information involves several form inference order develop question answering capability benefit temporal inference believe large corpus question answer discovered based temporal information available paper describes methodology creating answertimebank large corpus question answer question answering system operate using complex temporal inference
sharing personal narrative fundamental aspect human social behavior help share life experience tell story rely background understand context similarity difference substantial effort made towards developing storytelling machine inferring character feature however dont usually find model compare narrative task remarkably challenging machine since sometimes lack understanding similarity mean address challenge first introduce corpus realworld spoken personal narrative comprising narrative clause video transcript second ask nonnarrative expert annotate clause labovs sociolinguistic model personal narrative ie action orientation evaluation clause type train classifier reach fscore highestagreed clause finally match story explore whether people implicitly rely labovs framework compare narrative show action followed narrator evaluation aspect nonexperts consider approach intended help inform machine learning method aimed studying representing personal narrative
following navigation instruction natural language nl requires composition language action knowledge environment knowledge environment may provided via visual sensor symbolic world representation referred map previous work mapbased nl navigation relied small artificial world fixed set entity known advance introduce realistic urban navigation run task aimed interpreting nl navigation instruction based real dense urban map using amazon mechanical turk collected dataset instruction aligned actual route three region manhattan empirically study aspect neural architecture important run success empirically show entity abstraction attention word world constantly updating worldstate significantly contribute task accuracy
paper summarizes group effort offensive language identification shared task organized part international workshop semantic evaluation semeval final submission system ensemble three different model cnnlstm bilstmattention bert word embeddings pretrained tweet used training first two model berturk first bert model turkish also explored final submitted approach ranked second best model turkish subtask
sentence function significant factor achieve purpose speaker however touched largescale conversation generation far paper present model generate informative response controlled sentence function model utilizes continuous latent variable capture various word pattern realize expected sentence function introduces type controller deal compatibility controlling sentence function generating informative content conditioned latent variable type controller determines type ie functionrelated topic ordinary word word generated decoding position experiment show model outperforms stateoftheart baseline ability generate response controlled sentence function informative content
spoken language understanding slu requires model analyze input acoustic signal understand linguistic content make prediction boost model performance various pretraining method proposed learn rich representation largescale unannotated speech text however inherent disparity two modality necessitate mutual analysis paper propose novel semisupervised learning framework splat jointly pretrain speech language module besides conducting selfsupervised masked language modeling task two individual module using unpaired speech text splat aligns representation two module shared latent space using small amount paired speech text thus finetuning speech module alone produce representation carrying acoustic information contextual semantic knowledge input acoustic signal experimental result verify effectiveness approach various slu task example splat improves previous stateoftheart performance spoken squad dataset
propose novel knowledge grounded dialogue interview dataset sportsinterview set domain sport interview dataset contains two type external knowledge source knowledge grounding rich content containing k interview session k distinct interviewee compared existing knowledge grounded dialogue datasets interview dataset larger size comprises natural dialogue revolving around realworld sport match one dimension external knowledge linking performed several experiment sportsinterview found model bart finetuned dataset able learn lot relevant domain knowledge generate meaningful sentence question response however performance still far human comparing gold sentence dataset hence encourages future research utilizing sportsinterview
power word embeddings attributed linguistic theory similar word appear similar context idea specifically invoked noting shall know word company keep quote british linguist jr firth along american colleague zellig harris often credited invention distributional semantics firth harris cited major nlp textbook many foundational paper content difference theory seldom discussed engaging close reading work discover two distinct many way divergent theory meaning one focus exclusively internal working linguistic form invite u consider word new companynot linguistic element also broader cultural situational context contrasting theory perspective current debate nlp discover firth figure could guide field towards culturally grounded notion semantics consider expanded notion context might modeled practice two different strategy comparative stratification syntagmatic extension
paper present deeplearning model submitted semeval task competition affect tweet participated subtasks english tweet propose bilstm architecture equipped multilayer self attention mechanism attention mechanism improves model performance allows u identify salient word tweet well gain insight model making interpretable model utilizes set wordvec word embeddings trained large collection million twitter message augmented set word affective feature due limited amount taskspecific training data opted transfer learning approach pretraining bilstms dataset semeval task proposed approach ranked st subtask e multilabel emotion classification nd subtask emotion intensity regression achieved competitive result subtasks
automatic evaluation opendomain dialogue remains largely unsolved challenge despite abundance work done field human judge evaluate dialogue quality consequence performing evaluation scale usually expensive work investigates using deeplearning model trained general language understanding evaluation glue benchmark serve quality indication opendomain dialogue aim use various glue task different perspective judging quality conversation thus reducing need additional training data response serve quality reference due nature method infer various quality metric derive componentbased overall score achieve statistically significant correlation coefficient
automatic translation sign language video transcribed text rarely approached whole implies finely model grammatical mechanism govern language presented work first step towards interpretation french sign language lsf specifically targeting iconicity spatial referencing paper describes lsfshelves corpus well original technology designed implemented collect goal use deep learning method circumvent use model spatial referencing recognition order obtain training material sufficient variability designed lightweight lowcost capture protocol enabled u collect data large panel lsf signer protocol involves use portable device providing skeleton software developed specifically application facilitate postprocessing handshapes lsfshelves includes simple compound iconic spatial dynamic organized complexity level representing total sequence signed lsf signer
adapter lightweight module allow parameterefficient finetuning pretrained model specialized language task adapter recently proposed facilitate crosslingual transfer multilingual pretrained model pfeiffer et al b however approach requires training separate language adapter every language one wish support impractical language limited data intuitive solution use related language adapter new language variety observe solution lead suboptimal performance paper aim improve robustness language adapter uncovered language without training new adapter find ensembling multiple existing language adapter make finetuned model significantly robust language variety included adapter building upon observation propose entropy minimized ensemble adapter emea method optimizes ensemble weight pretrained language adapter test sentence minimizing entropy prediction experiment three diverse group language variety show method lead significant improvement named entity recognition partofspeech tagging across language
case eacl proposes shared task hate speech stance detection climate activism participation stance detection task tested different approach using llm classification task tested generative model using classical seqseq structure subsequently considerably improved result replacing last layer llm classifier layer also studied performance affected amount data used training purpose partition dataset used external data posture detection task added
linguistic data consortium georgetown university press collaborating create updated edition bilingual diction aries originally published englishspeaking learner moroccan syrian iraqi arabic first edition dictionary used ad hoc latinalphabet orthography colloquial arabic dialect adopted proper tie arabicbased writing collation order arabic headword clitic attachment word form example phrase despite common feature notable difference among three book impede comparison across dialect well com parisons dialect modern standard arabic updating volume use arabic script international pho netic alphabet orthography former provides common basis word recognition across dialect latter provides dialectspecific pronunciation goal preserve full content original publication supplement arabic headword inventory new usage produce uniform lexicon structure expressible via lexical markup framework lmf iso end developed relational database schema applies consistently dialect httpbased tool searching editing workflow review inventory management
propose interpolated backoff method strike balance traditional surface form translation model factored model decompose translation lemma morphological feature mapping step show approach improves translation quality bleu germanenglish phrasebased model due better translation rare noun adjective
headline generation becomes vital tool dynamic world digital medium combining creativity scientific rigor engage reader maintaining accuracy however accuracy currently hampered numerical integration problem affect abstractive extractive approach sentence extracted original material typically short accurately represent complex information research introduces innovative twostep training technique tackle problem emphasizing significance enhanced numerical reasoning headline development promising advance presented utilizing texttotext processing capability model advanced nlp approach like bert roberta help external contribution dataset flant model improved demonstrate method may used overcome numerical integration issue improve accuracy headline production
multitask learning mtl transfer learning tl technique overcome issue data scarcity training stateoftheart neural network however finding beneficial auxiliary datasets mtl tl time resourceconsuming trialanderror approach propose new method automatically assess similarity sequence tagging datasets identify beneficial auxiliary data mtl tl setup method compute similarity two sequence tagging datasets need annotated tagset multiple label parallel additionally method take token label account robust using either information source conducted prior work empirically show similarity measure correlate change test score neural network use auxiliary dataset mtl increase main task performance provide efficient opensource implementation
training supervised neural network classifier typically requires many annotated training sample collecting annotating large number data point costly sometimes even infeasible traditional annotation process us lowbandwidth humanmachine communication interface classification label provides bit information propose active learning contrastive explanation alice expertintheloop training framework utilizes contrastive natural language explanation improve data efficiency learning alice learns first use active learning select informative pair label class elicit contrastive natural language explanation expert extract knowledge explanation using semantic parser finally incorporates extracted knowledge dynamically changing learning model structure applied alicein two visual recognition task bird specie classification social relationship classification found incorporating contrastive explanation model outperform baseline model trained training data found addingexplanation lead similar performance gain adding labeled training data point
understanding event semantically related essence reading comprehension recent eventcentric reading comprehension datasets focus mostly event argument temporal relation task partially evaluate machine ability narrative understanding humanlike reading comprehension requires capability process eventbased information beyond argument temporal reasoning example understand causality event need infer motivation purpose establish event hierarchy need understand composition event facilitate task introduce ester comprehensive machine reading comprehension mrc dataset event semantic relation reasoning dataset leverage natural language query reason five common event semantic relation provides k question capture k event relation pair experimental result show current sota system achieve tokenbased exactmatch em f eventbased hit score significantly human performance respectively highlighting dataset challenging benchmark
paper rethink translation memory augmented neural machine translation tmaugmented nmt two perspective ie probabilistic view retrieval variancebias decomposition principle finding demonstrates tmaugmented nmt good ability fitting data ie lower bias sensitive fluctuation training data ie higher variance provides explanation recently reported contradictory phenomenon translation task tmaugmented nmt substantially advance nmt without tm high resource scenario whereas fails low resource scenario paper proposes simple yet effective tmaugmented nmt model promote variance address contradictory phenomenon extensive experiment show proposed tmaugmented nmt achieves consistent gain conventional nmt existing tmaugmented nmt two variancepreferable low resource plugandplay scenario well high resource scenario
commonsense reasoning refers ability evaluating social situation acting accordingly identification implicit cause effect social context driving capability enable machine perform commonsense reasoning dynamic world social interaction requires contextdependent ondemand system infer underlying information however current approach realm lack ability perform commonsense reasoning upon facing unseen situation mostly due incapability identifying diverse range implicit social relation hence fail estimate correct reasoning path paper present conditional seqseqbased mixture model cosmo provides u capability dynamic diverse content generation use cosmo generate contextdependent clause form dynamic knowledge graph kg onthefly commonsense reasoning show adaptability model contextdependant knowledge generation address task zeroshot commonsense question answering empirical result indicate improvement stateoftheart model
international classification disease icd provides standardized way classifying disease endows disease unique code icd coding aim assign proper icd code medical record since manual coding laborious prone error many method proposed automatic icd coding task however existing method independently predict code ignoring two important characteristic code hierarchy code cooccurrence paper propose hyperbolic cograph representation method hypercore address problem specifically propose hyperbolic representation method leverage code hierarchy moreover propose graph convolutional network utilize code cooccurrence experimental result two widely used datasets demonstrate proposed model outperforms previous stateoftheart method
complaint classification aim using information deliver greater insight enhance user experience purchasing product service categorized information help u quickly collect emerging problem order provide support needed indeed response complaint without delay grant user highest satisfaction paper aim deliver novel approach clarify complaint precisely aim classify complaint nine predefined class ie accessibility company brand competitor facility process product feature staff quality timing respectively others given idea one word usually conveys ambiguity interpreted context word embedding technique used provide word feature applying deep learning technique classifying type complaint dataset use contains complaint one company
key challenge visual dialog task fuse feature multimodal source extract relevant information dialog history answer current query work formulate visual dialog information flow piece information encoded joint visuallinguistic representation single dialog round based formulation consider visual dialog task sequence problem consisting ordered visuallinguistic vector featurization use dense symmetriccoattention network nguyen okatani lightweight visonlanguage joint representation generator fuse multimodal feature ie image text yielding better computation data efficiency inference propose two sequential dialog network seqdialn first us lstmhochreiter schmidhuber information propagation ip second us modified transformer vaswani et al multistep reasoning mr architecture separate complexity multimodal feature fusion inference allows simpler design inference engine visdial v teststd dataset best single generative seqdialn achieves ndcg mrr ensemble generative seqdialn achieves ndcg mrr set new stateoftheart generative visual dialog model finetune discriminative seqdialn dense annotation boost performance ndcg mrr work discus extensive experiment conducted demonstrate effectiveness model component also provide visualization reasoning process relevant conversation round discus finetuning method code available urlhttpsgithubcomxiaoxiaoheimeiseqdialn
human bias ubiquitous uniform disparity exist across linguistic cultural societal border large amount recent literature suggest language model lm trained human data reflect often amplify effect social bias however vast majority existing study bias heavily skewed towards western european language work scale word embedding association test weat language enabling broader study yielding interesting finding lm bias additionally enhance data culturally relevant information language capturing local context global scale encompass widely prevalent societal bias examine new bias dimension across toxicity ableism moreover delve deeper indian linguistic landscape conducting comprehensive regional bias analysis across six prevalent indian language finally highlight significance social bias new dimension extensive comparison embedding method reinforcing need address pursuit equitable language model
obtaining training data often difficult part nlp ml project develop method predicting much data required achieve desired test accuracy extrapolating result model trained small pilot training dataset model accuracy varies function training size subset pilot data use model predict much training data would required achieve desired accuracy introduce new performance extrapolation task evaluate well different extrapolation predict accuracy larger training set show detail hyperparameter optimisation extrapolation model dramatic effect document classification task believe important first step developing method estimating resource required meet specific engineering performance target
many work proposed method improve performance neural machine translation nmt model domainmultidomain adaptation scenario however understanding nmt baseline represent text domain information internally still lacking analyze sentence representation learned nmt transformer show explicitly include information text domain even seeing input sentence without domain label furthermore show internal information enough cluster sentence underlying domain without supervision show nmt model produce cluster better aligned actual domain compared pretrained language model lm notably computed documentlevel nmt clustertodomain correspondence nears use finding together approach nmt domain adaptation using automatically extracted domain whereas previous work relied external lm text clustering propose reusing nmt model source unsupervised cluster perform extensive experimental study comparing two approach across two data scenario three language pair sentencelevel documentlevel clustering showing equal significantly superior performance compared lm
answer question may change depending extralinguistic context question asked study challenge introduce situatedqa openretrieval qa dataset system must produce correct answer question given temporal geographical context construct situatedqa first identify question existing qa datasets find significant proportion information seeking question contextdependent answer eg roughly nqopen contextdependent question crowdsource alternative context corresponding answer study show existing model struggle producing answer frequently updated uncommon location quantify existing model trained data collected past fail generalize answering question asked present even provided updated evidence corpus roughly point drop accuracy analysis suggests openretrieval qa benchmark incorporate extralinguistic context stay relevant globally future data code datasheet available urlhttpssituatedqagithubio
endtoend relation extraction aim identify named entity extract relation recent work model two subtasks jointly either casting one structured prediction framework performing multitask learning shared representation work present simple pipelined approach entity relation extraction establish new stateoftheart standard benchmark ace ace scierc obtaining absolute improvement relation f previous joint model pretrained encoders approach essentially build two independent encoders merely us entity model construct input relation model series careful examination validate importance learning distinct contextual representation entity relation fusing entity information early relation model incorporating global context finally also present efficient approximation approach requires one pas entity relation encoders inference time achieving mboxtimes speedup slight reduction accuracy
paper evaluate new sentiment lexicon danish danish sentiment lexicon dsl gain input regarding carry final adjustment lexicon feature lexicon differentiates sentiment resource danish linked large number danish lexical resource via ddo lemma sense inventory llod via danish wordnet dannet perform evaluation four datasets labeled sentiment addition compare lexicon two existing benchmark danish afinn sentida resource observe dsl performs mostly comparably existing resource finegrained exploration need done order fully exploit possibility given linking property
outofdomain ood intent classification new intent discovering two basic critical task taskoriented dialogue system typically treated two independent task classification focus identifying intent beyond predefined set dialog system differentiate detected ood intent fine granularity discovering focus cluster unlabeled sample according semantic representation relies heavily prior knowledge provide label information formed cluster closer real userfacing scenario introduce task paradigm extend classification discovering referred open environment intent prediction make finegrained discovery ood based ood intent classification using various widelyused generative model archetype propose general scheme open environment intent prediction nutshell first perform intent detection identify indomain ind sample generate label identified ood generated label discover new general intent provide label information develop suite benchmark existing intent datasets present simple yet effective implementation extensive experiment demonstrate method establishes substantial improvement compared baseline
recent study revealed backdoor attack threaten safety natural language processing nlp model investigating strategy backdoor attack help understand model vulnerability existing textual backdoor attack focus generating stealthy trigger modifying model weight paper directly target interior structure neural network backdoor mechanism propose novel trojan attention loss tal enhances trojan behavior directly manipulating attention pattern loss applied different attacking method boost attack efficacy term attack successful rate poisoning rate applies traditional dirtylabel attack also challenging cleanlabel attack validate method different backbone model bert roberta distilbert various task sentiment analysis toxic detection topic classification
article present result recent research recognition normalisation polish temporal expression temporal information extracted text play major role many information extraction system like question answering event recognition discourse analysis proposed new method temporal expression normalisation called cascade partial rule describe result achieved updated version liner machine learning system
extractive generative reader successfully applied question answering qa task little attention paid toward systematic comparison characterizing strength weakness two reader crucial making informed reader selection practice also developing deeper understanding foster research improving reader principled manner motivated goal make first attempt systematically study comparison extractive generative reader question answering aligned stateoftheart explore nine transformerbased large pretrained language model prlms backbone architecture furthermore organize finding two main category keeping architecture invariant varying underlying prlms among several interesting finding important highlight generative reader perform better long context qa extractive reader perform better short context also showing better outofdomain generalization encoder encoderdecoder prlms eg turn strong extractive reader outperforms standard choice encoderonly prlms eg roberta also study effect multitask learning two type reader varying underlying prlms perform qualitative quantitative diagnosis provide insight future direction modeling better reader
present unsupervised language agnostic approach exploiting morphological regularity present high dimensional vector space propose novel method generating embeddings word morphological variant using morphological transformation operator evaluate approach msr word analogy test set accuracy higher previous best known system
paper describes current status emerging ontolex module linguistic morphology serf update previous version vocabulary klimek et al whereas earlier model exclusively focusing descriptive morphology focused application lexicography present novel part novel application vocabulary application language technology ie rulebased generation lexicon introducing dynamic component ontolex
surge environmental societal governance esg report essential corporate transparency modern investment present challenge investor due varying length sheer volume present novel methodology called multitaxogen creating topic taxonomy designed specifically analysing esg report topic taxonomy serve illustrate topic covered corpus esg report also highlighting hierarchical relationship unfortunately current stateoftheart approach constructing topic taxonomy designed general datasets resulting ambiguous topic omission many latent topic presented esgfocused corpus make unsuitable specificity required investor method instead adapts topic modelling technique employing recursively topic local neighbourhood subcorpus document assigned topic iterative approach allows u identify child topic offer better understanding topic hierarchy finegrained paradigm finding reveal method capture latent topic esg report corpus leading method provides coherent topic comparable relational accuracy
chainofthought cot prompting successfully enhanced reasoning capability large language model llm least billion parameter however ineffective even detrimental performance reasoning task smaller language model slms less billion parameter paper propose dialogueguided chainofthought dialcot improve reasoning capability slms aim generating intermediate reasoning step dialogue format guide model final answer furthermore optimize model choose optimal reasoning path proximal policy optimization ppo algorithm enhancing reasoning capability compared previous method advantage lie transform process solving complex reasoning problem decomposing problem solving series simpler subquestions significantly reducing task difficulty making suitable slms optimize model choose optimal reasoning path ppo algorithm comprehensive experiment four arithmetic reasoning datasets show method achieve significant performance gain stateoftheart competitor
examine various type noise parallel training data impact quality neural machine translation system create five type artificial noise analyze degrade performance neural statistical machine translation find neural model generally harmed noise statistical model one especially egregious type noise learn copy input sentence
new linguistically annotated video database automatic sign language recognition presented new rwthboston corpus consists sentence several speaker separate subset training development testing described detail evaluation benchmarking automatic sign language recognition large corpus needed recent research focused mainly isolated sign language recognition method using video sequence recorded lab condition using special hardware like data glove database often consisted generally one speaker thus speakerdependent small vocabulary new database access interface designed created provide fast access database statistic content make possible easily browse retrieve particular subset video database preliminary baseline result new corpus presented contradistinction research area database presented paper publicly available
propose ebleu metric inspired bleu metric us embedding similarity instead string match introduce meaning diffusion vector enable matching ngrams semantically similar word bleulike algorithm using efficient noncontextual word embeddings like fasttext wmt data ebleu beat bleu chrf around systemlevel score approaching bertscore absolute difference wmt scenario ebleu outperforms fspbleu chrf mqm curiously mturk evaluation ebleu surpasses past method fspbleu comet ebleu present interesting middleground traditional metric pretrained metric
paper proposes new method italian verb classification preliminary example resulting class inspired levin verbnet kipperschuler yet partially independent resource achieved result integrating levin verbnets model classification theoretic framework resource classification rooted constructionist framework goldberg distributionbased also semantically characterized link framenetssemanticframesto represent event expressed class however new italian class maintain hierarchic tree structure monotonic nature verbnets class possible original name eg verb killing verb putting etc therefore propose taxonomy compatible verbnet time adapted italian syntax semantics also address number problem intrinsic original classification role argument alternation regarded simply epiphenomenon consistently constructionist approach
queryfocused meeting summarizationqfms aim generate specific summary given query according meeting transcript due conflict long meeting limited input size previous work mainly adopt extractthensummarize method use extractor simulate binary label rouge score extract utterance related query generate summary however previous approach fails fully use comparison utterance extractor comparison order important specific score paper propose rankergenerator framework learns rank utterance comparing pair learning global order us top utterance generator input show learning rank utterance help select utterance related query effectively summarizer benefit experimental result qmsum show proposed model outperforms existing multistage model fewer parameter
transfer learning imperative achieve strong alignment pretrained model downstream task prior work done proposing taskspecific pretraining objective sacrifice inherent scalability transfer learning paradigm instead achieve strong alignment simultaneously modifying pretrained model formulation downstream task efficient preserve scalability transfer learning present gensf generative slot filling leverage generative pretrained opendomain dialog model slot filling gensf adapts pretrained model incorporating inductive bias task adapts downstream task reformulating slot filling better leverage pretrained model capability gensf achieves stateoftheart result two slot filling datasets strong gain fewshot zeroshot setting achieve f score improvement zeroshot slot filling highlight value strong alignment pretrained model downstream task
introduce entity postmodifier generation instance collaborative writing task given sentence target entity task automatically generate postmodifier phrase provides contextually relevant information entity example sentence barack obama supported metoo movement phrase father two girl contextually relevant postmodifier end build pomo postmodifier dataset created automatically news article reflecting journalistic need incorporating entity information relevant particular news event pomo consists k sentence postmodifiers associated fact extracted wikidata around k unique entity use crowdsourcing show modeling contextual relevance necessary accurate postmodifier generation adapt number existing generation approach baseline dataset result show large room improvement term identifying relevant fact include knowing claim relevant give textgreater improvement bleu score generating appropriate postmodifier text context providing relevant claim sufficient accurate generation conduct error analysis suggests promising direction future research
paper describes zeroshot approachesfor visual word sense disambiguationvwsd task english preliminarystudy show simple approach matching candidate image phrase usingclip suffers manytomany natureof imagetext pair find clip textencoder may limited ability capturing compositionality natural language conversely descriptive focus phrasevaries instance instance addressthese issue two system augmentclipand stable diffusion sampling sd samplingaugmentclip augments text prompt bygenerating sentence contain contextphrase help large language model llm explore clip modelsin language ambiguous wordmay translated unambiguous one inthe language sd sampling us texttoimage stable diffusion generate multipleimages given phrase increasing thelikelihood subset image match theone paired text
steep increase number scholarly publication given rise various digital repository library knowledge graph aimed capture manage preserve scientific data efficiently navigating database requires system able classify scholarly document according respective research subfield however every digital repository possesses relevant classification schema categorising publication instance one largest digital archive computational linguistics cl natural language processing nlp acl anthology lack system classifying paper topic subtopics paper address gap constructing corpus acl anthology publication annotated main contribution using novel hierarchical taxonomy core clnlp topic subtopics corpus used shared task goal classifying clnlp paper respective subtopics
traditional dialect vocabulary netherlands flanders recorded researched several dutch belgian research institute university distributed dictionary creation research project collaborate permanent overlegorgaan regionale woordenboeken rewo project digital database digital tool wbd wld dsquare dialect data published two dictionary project woordenboek van de brabantse dialecten woordenboek van de limburgse dialecten digitised one additional goal dsquare project development infrastructure electronic access dialect dictionary collaborating rewo paper firstly reconsider nature core data type form sense location present different dialect dictionary way data type classified next focus problem encountered trying unify dictionary data classification suggest solution finally look several implementation issue regarding specific encoding dictionary
study task labeling covert veiled toxicity online conversation prior research highlighted difficulty creating language model recognize nuanced toxicity microaggressions investigation underscore difficulty parsing label reliably raters via crowdsourcing introduce initial dataset coverttoxicity aim identify categorize comment refined rater template finally finetune commentdomain bert model classify covertly offensive comment compare existing baseline
paper describes aspect hpsg style computational grammar west african language ga kwa language spoken accra area ghana volta basin kwa language ga feature many type multiverb expression particular constructional pattern verbal nominal domain paper highlight theoretical formal feature grammar motivated phenomenon possibly innovative formal framework socalled deep grammar language host rich lexical structure describe way grammar build previously available lexical resource outline environment current resource grammar part line research development environment used
pretrained model bert shown large gain across natural language understanding task performance improved training model datarich intermediate task finetuning target task however still poorly understood intermediatetask training beneficial given target task investigate perform largescale study pretrained roberta model intermediatetarget task combination evaluate trained model probing task meant reveal specific skill drive transfer observe intermediate task requiring highlevel inference reasoning ability tend work best also observe target task performance strongly correlated higherlevel ability coreference resolution however fail observe granular correlation probing target task performance highlighting need work broadcoverage probing benchmark also observe evidence forgetting knowledge learned pretraining may limit analysis highlighting need work transfer learning method setting
within current trend pretained language model plm emerge criticism ethical ecological impact model article considering critical remark propose focus smaller model compact model like albert ecologically virtuous plm however plms enable huge breakthrough natural language processing task spoken natural language understanding classification questionanswering task plms also advantage multilingual far know multilingual version compact albert model exist considering fact propose free release first version multilingual compact albert model pretrained using wikipedia data complies ethical aspect language model also evaluate model classical multilingual plms classical nlp task finally paper proposes rare study subword tokenization impact language performance
dependency parsing algorithm capable producing type crossing dependency seen natural language sentence traditionally order magnitude slower algorithm projective tree dependency parses various natural language treebanks whenever edge crossed edge cross common vertex optimal dependency tree satisfies endpointcrossing property found parsing algorithm recursively combine forest interval one exterior point endpointcrossing tree also natural connection linguistics another class graph studied nlp
text attribute transfer modifying certain linguistic attribute eg sentiment style authorship etc sentence transforming one type another paper aim analyze interpret changed transfer process start observation many existing model datasets certain word within sentence play important role determining sentence attribute class word referred pivot word based pivot word propose lexical analysis framework pivot analysis quantitatively analyze effect word text attribute classification transfer apply framework existing datasets model show pivot word strong feature classification sentence attribute change attribute sentence many datasets requires change certain pivot word consequently many transfer model perform lexicallevel modificationwhile leaving higherlevel sentence structure unchanged work provides indepth understanding linguistic attribute transfer identifies future requirement challenge task
paper present new comprehensive multilevel partofspeech tag set support vector machine based partofspeech tagger sinhala language currently available tag set sinhala two limitation unavailability tag represent word class lack tag capture inflection based grammatical variation word new tag set presented paper overcomes limitation accuracy available sinhala partofspeech tagger based hidden markov model still fall far behind state art support vector machine based tagger achieved overall accuracy accuracy unknown word known word test set contains unknown word
company provide annual report shareholder end financial year describes operation financial condition average length report andit may extend page long paper propose methodology point thecombination pointer network testtotext transfer transformer algorithm weused financial narrative summarisation fns task proposed method usespointer network extract important narrative sentence report used toparaphrase extracted sentence concise yet informative sentence evaluate methodusing rougen l su proposed method achieves highest precision score inall metric highest f score three four evaluation metric rouge lcs solution cross muse solution baseline rougelcs metric
named entity recognition ner popular language processing task wide application progress ner noteworthy evidenced f score obtained standard datasets practice however enduser us ner model dataset outofthebox text may pristine paper present four modelagnostic adversarial attack gauge resilience ner model scenario experiment four stateoftheart ner method five english datasets suggest ner model overreliant case information utilise contextual information well highly susceptible adversarial attack based feature
paper proposes improvement existing datadriven neural belief tracking nbt framework dialogue state tracking dst existing nbt model us handcrafted belief state update mechanism involves expensive manual retuning step whenever model deployed new dialogue domain show update mechanism learned jointly semantic decoding context modelling part nbt model eliminating last rulebased module dst framework propose two different statistical update mechanism show dialogue dynamic modelled small number additional model parameter dst evaluation three language show model achieves competitive performance provides robust framework building resourcelight dst model
investigate writer dementia automatically distinguished without analyzing linguistic marker written text form blog post built corpus several thousand blog post people dementia others people loved one dementia use dataset train test several machine learning method achieve prediction performance level far baseline
event extraction difficult information extraction task li et al explore benefit modeling event extraction two related task entity mention relation extraction jointly joint system achieves stateoftheart performance task however system operating sentence level miss valuable information part document paper present incremental easyfirst approach make global context entire document available intrasentential stateoftheart event extractor show method robustly increase performance two datasets namely ace tac
impressive progress nlp technique driven development multitask benchmark glue superglue benchmark focus task one two input sentence exciting work designing efficient technique processing much longer input paper present muld new long document benchmark consisting document token modifying existing nlp task create diverse benchmark requires model successfully model longterm dependency text evaluate existing model perform find benchmark much challenging short document equivalent furthermore evaluating regular efficient transformer show model increased context length better able solve task presented suggesting future improvement model vital solving similar long document problem release data code baseline encourage research efficient nlp model
incremental syntactic parsing active research area cognitive scientist trying model human sentence processing nlp researcher attempting combine incremental parsing language modelling asr mt effort directed designing right transition mechanism less done answer question probabilistic model transition parser look like incremental transition mechanism recently proposed ccg parser trained straightforward locally normalised discriminative fashion produce bad result english ccgbank identify three bias cause problem label bias exposure bias imbalanced probability bias known technique tackling bias improve result still make parser state art instead tackle three bias time using improved version beam search optimisation minimises beam search violation instead minimising biggest violation new incremental parser give better result previously published incremental ccg parser outperforms even widely used nonincremental ccg parser
paper describe structure development brandeis semantic ontology bso large generative lexicon ontology lexical database bso designed allow widespread access generative lexiconbased lexical resource help researcher variety computational task specification type system used bso largely follows proposed simple specification busa et al adopted eusponsored simple project lenci et al
currently little agreement natural language generation nlg system evaluated agreement regarding automatic metric high degree variation way human evaluation carried paper provides overview human evaluation currently conducted present set best practice grounded literature paper hope contribute quality consistency human evaluation nlg
knowledge graph kg directed graphical representation entity relation real world kg applied diverse natural language processing nlp task knowledge required need scale complete kg automatically yield knowledge graph embedding kge shallow machine learning model suffering memory training time consumption issue mitigate computational load propose parametersharing method ie using conjugate parameter complex number employed kge model method improves memory efficiency x relation embedding achieving comparable performance stateoftheart nonconjugate model faster least comparable training time demonstrated generalizability method two bestperforming kge model bigstarmathrme citation mathrmcomplex citation five benchmark datasets
paper describes technology developed automatically grade student english spontaneous spoken language proficiency common european framework reference language cefr level automated assessment system contains two task elicited imitation spontaneous speech assessment spontaneous speech assessment challenging task requires evaluating various aspect speech quality content coherence paper propose multimodal multitask transformer model leverage audio text feature perform three task scoring coherence modeling prompt relevancy scoring model us fusion multiple feature multiple modality attention capture interaction audio text modality learn different source information
predicateargument structure analysis central component meaning representation text fact argument explicitly mentioned sentence give rise ambiguity language understanding render difficult machine interpret text correctly however resource represent implicit role nlu existing study nlp make coarse distinction category argument omitted linguistic form paper proposes typology finegrained implicit argument annotation top universal conceptual cognitive annotation foundational layer proposed implicit argument categorisation driven theory implicit role interpretation consists six type deictic generic genrebased typeidentifiable nonspecific iteratedset exemplify design revisiting part ucca ewt corpus providing new dataset annotated refinement layer making comparative analysis scheme
text attribute user product information product review used improve performance sentiment classification model de facto standard method incorporate additional bias attention mechanism performance gain achieved extending model architecture paper show method least effective way represent inject attribute demonstrate hypothesis unlike previous model complicated architecture limit base model simple bilstm attention classifier instead focus attribute incorporated model propose represent attribute chunkwise importance weight matrix consider four location model ie embedding encoding attention classifier inject attribute experiment show proposed method achieves significant improvement standard approach attention mechanism worst location inject attribute contradicting prior work also outperform stateoftheart despite use simple base model finally show representation transfer well task model implementation datasets released urlhttpsgithubcomrktamplayochim
domain adaptation allows generative language model address specific flaw caused domain shift application however traditional adaptation training indomain data rapidly weakens model ability generalize domain making openended deployment adapted model prone error work introduces novel training objective built upon semantic similarity predicted token reference result show avoiding common assumption single correct prediction constructing training target token semantic similarity largely mitigate catastrophic forgetting adaptation preserving adaptation indomain quality negligible addition compute cost broader context objective grounded continuous token similarity pioneer exploration middle ground efficient naive exactmatch tokenlevel objective expressive computationally resourceintensive sequential objective
present kathaa open source webbased visual programming framework natural language processing nlp system kathaa support design execution analysis complex nlp system visually connecting nlp component easily extensible module library model nlp system edgelabeled directed acyclic multigraph let user use publicly cocreated module nlp application irrespective technical proficiency natural language processing kathaa expose intuitive web based interface user interact modify complex nlp system precise module definition api allow easy integration new state art nlp component kathaa enables researcher publish service standardized format enable mass use service box vision work pave way system like kathaa lego block nlp research application practical use case use kathaa visually implement sampark hindipanjabi machine translation pipeline sampark hindiurdu machine translation pipeline demonstrate fact kathaa handle really complex nlp system still intuitive end user
historical linguist identified regularity process historic sound change comparative method utilizes regularity reconstruct protowords based observed form daughter language process efficiently automated address task protoword reconstruction model exposed cognate contemporary daughter language predict proto word ancestor language provide novel dataset task encompassing comparative entry show neural sequence model outperform conventional method applied task far error analysis reveals variability ability neural model capture different phonological change correlating complexity change analysis learned embeddings reveals model learn phonologically meaningful generalization corresponding wellattested phonological shift documented historical linguistics
paper present effort preparation polishtoenglish smt system ted lecture domain evaluated iwslt conference attempt cover system use stem morphological information polish word using two different tool stem po
pretraining pt backtranslation bt two simple powerful method utilize monolingual data improving model performance neural machine translation nmt paper take first step investigate complementarity pt bt introduce two probing task pt bt respectively find pt mainly contributes encoder module bt brings benefit decoder experimental result show pt bt nicely complementary establishing stateoftheart performance wmt englishromanian englishrussian benchmark extensive analysis sentence originality word frequency also demonstrate combining tagged bt pt helpful complementarity leading better translation quality source code freely available urlhttpsgithubcomsunbowliuptvsbt
multiword expression posed challenge past computational linguistics since comprise heterogeneous family word cluster difficult detect natural language data paper present fmri study based language comprehension provide neuroimaging evidence processing mwes investigate whether different mwes distinct neural base eg verbal mwes involve separate brain area nonverbal mwes mwes varying level cohesiveness activate dissociable brain region study contributes neuroimaging evidence illustrating different mwes elicit spatially distinct pattern activation also adapt association measure usually used detect mwes cognitively plausible metric language processing
neither possible fair compare performance questionanswering system holy quran hadith sharif arabic due absence golden test dataset hadith sharif small size easy question newly created golden test dataset holy quran article present two questionanswer datasets hadith questionanswer pair haqa quran questionanswer pair quqa haqa first arabic hadith questionanswer dataset available research community quqa dataset regarded challenging extensive collection arabic questionanswer pair quran haqa designed data collected several expert source quqa went several step construction phase designed integrated existing datasets different format datasets enlarged addition new data book expert haqa corpus consists questionanswer pair quqa contains may useful goldstandard datasets evaluation process training datasets language model questionanswering task us artificial intelligence
common assertion mt system improved last decade examined informal comparison translation produced operational system translation source text produced currently available commercial online system scarcity source target text earlier system mean conclusion consequently tentative preliminary
framesemantic annotation exist tiny fraction world language wikidata however link knowledge base triple text many language providing common distant supervision signal semantic parser present wikibank multilingual resource partial semantic structure used extend preexisting resource rather creating new manmade resource scratch also integrate form supervision offtheshelf framesemantic parser allow crosslingual transfer using google sling architecture show significant improvement english spanish conll datasets whether training full available datasets small subsamples thereof
one pressing question cognitive science remains unanswered cognitive mechanism enable child learn world language much discovery made regard specific learning mechanism specific language however given remarkable diversity language structure evans levinson bickel burning question remains underlying process make language acquisition possible despite substantial crosslinguistic variation phonology morphology syntax etc investigate question comprehensive crosslinguistic database longitudinal child language acquisition corpus maximally diverse language built
introduce question answering cotext focus task simulates free interaction qa system user read screen information topic followup question either related topic answer found document containing screen content page call information context study task construct focusqa dataset answer sentence selection unique questioncontext pair total answer build dataset developed novel methodology take existing question pair relevant context show benefit approach present comparative analysis set question written human reading context showing approach greatly help eliciting realistic questioncontext pair finally show task pose several challenge incorporating contextual information respect introduce strong baseline answer sentence selection outperform precision stateoftheart model absolute point
transformerbased architecture model choice natural language understanding come significant cost quadratic complexity input length require lot training data difficult tune pursuit lower cost investigate simple mlpbased architecture find existing architecture mlpmixer achieves token mixing static mlp applied feature independently detached inductive bias required natural language understanding paper propose simple variant hypermixer form token mixing mlp dynamically using hypernetworks empirically demonstrate model performs better alternative mlpbased model par transformer contrast transformer hypermixer achieves result substantially lower cost term processing time training data hyperparameter tuning
valid data archive open multimedia data archive construction data speaker suffering language impairment report pilot project clarinnl framework five data resource curated data set concerned written informed consent participant caretaker obtained material anonymized audio file converted wav linear pcm file transcription chat elan format research data consisted test spss excel file documented converted csv file data set obtained appropriate cmdi metadata file new cmdi metadata profile type data resource established care taken isocat metadata category used optimize interoperability curation data deposited max planck institute psycholinguistics nijmegen persistent identifier linked resource content transcription chat plain text format searched trova search engine
conll english named entity recognition ner dataset widely used train evaluate ner model almost year however unclear well model trained yearold data developed period decade using test set perform applied modern data paper evaluate generalization different model trained conll show ner model different generalization surprisingly find evidence performance degradation pretrained transformer roberta even finetuned using decadesold data investigate model generalize well new data others attempt disentangle effect temporal drift overfitting due test reuse analysis suggests deterioration due temporal mismatch pretraining corpus downstream test set found four factor important good generalization model architecture number parameter time period pretraining corpus addition amount finetuning data suggest current evaluation method sense underestimated progress ner past year ner model improved original conll test set improved even modern data datasets found urlhttpsgithubcomshuhenglaclconllpp
reading comprehension rc question answering useful method evaluating reader understands text standard accuracy metric used evaluation high accuracy taken indicative good understanding however literature quality learning suggests task performance also evaluated undergone process answer questionanswer relationship qar one strategy evaluating reader understanding based ability select different source information depending question type propose creation dataset learn qar strategy weak supervision expect complement current work reading comprehension introducing new setup evaluation
study extends previous research literary quality using information theorybased method assess level perplexity recorded three large language model processing thcentury english novel deemed high literary quality recognized expert canonical compared broader control group find canonical text appear elicit higher perplexity model explore textual feature might concur create effect find usage heavily nominal style together diverse vocabulary one leading cause difference two group trait could reflect strategy achieve informationally dense literary style
text transcript without punctuation sentence boundary hard comprehend human machine punctuation mark play vital role providing meaning sentence incorrect use placement punctuation mark often alter impact downstream task language translation understanding pronoun resolution text summarization etc human machine automated punctuation restoration apr system minimal human intervention improve comprehension text help user write better paper describe multitask modeling approach system restore punctuation multiple high resource germanic english german romanic french low resource language indoaryan hindi dravidian tamil require extensive knowledge grammar syntax given language spoken written form text german language given indic based language first towards restoring punctuation serve baseline future work
neural language model demonstrated impressive performance various task remain vulnerable wordlevel adversarial attack wordlevel adversarial attack formulated combinatorial optimization problem thus attack method decomposed search space search method despite significance two component previous work inadequately distinguish may lead unfair comparison insufficient evaluation paper address inappropriate practice previous work perform thorough ablation study search space illustrating substantial influence search space attack efficiency effectiveness imperceptibility based ablation study propose two standardized search space search space imperceptibility ssip search space effectiveness sset reevaluation eight previous attack method demonstrates success ssip sset achieving better tradeoff efficiency effectiveness imperceptibility different scenario offering fair comprehensive evaluation previous attack method providing potential guidance future work
universal knowledge core ukc large multilingual lexical database focus language diversity covering two thousand language aim database well tool data catalogue make abstract notion linguistic diversity visually understandable human formally exploitable machine ukc website let user explore million individual word meaning also phenomenon crosslingual convergence divergence shared interlingual meaning lexicon similarity cognate cluster lexical gap ukc livelanguage catalogue turn provides access underlying lexical data computerprocessable form ready reused crosslingual application
vietnamese native language million people world however existing vietnamese question answering qa datasets explore model ability perform advanced reasoning provide evidence explain answer introduce vimqa new vietnamese dataset wikipediabased multihop questionanswer pair dataset humangenerated four main feature question require advanced reasoning multiple paragraph sentencelevel supporting fact provided enabling qa model reason explain answer dataset offer various type reasoning test model ability reason extract relevant proof dataset vietnamese lowresource language also conduct experiment dataset using stateoftheart multilingual singlehop multihop qa method result suggest dataset challenging existing method room improvement vietnamese qa system addition propose general process data creation publish framework creating multilingual multihop qa datasets dataset framework publicly available encourage research vietnamese qa system
examine new task detecting derogatory compound eg curry muncher derogatory compound much difficult detect derogatory unigrams eg idiot since sparsely represented lexical resource previously found effective task eg wiktionary propose unsupervised classification approach incorporates linguistic property compound mostly depends simple distributional representation compare approach previously established method proposed extracting derogatory unigrams
although problem similar language translation area research interest many year yet still far solved paper study performance two popular approach statistical neural conclude method yield similar result however performance varies depending language pair statistical approach outperforms neural one difference bleu point spanishportuguese language pair proposed neural model surpasses statistical one difference bleu point czechpolish former case language similarity based perplexity much higher latter case additionally report negative result system combination backtranslation talpupc system submission st place czechtextgreaterpolish nd place spanishtextgreaterportuguese official evaluation st wmt similar language translation task
entity linking el task identifies entity mention text corpus associate unambiguous identifier knowledge base much work done topic first present result survey reveal lack consensus community regarding form mention text form link el task consider argue one definition entity linking task fit rather propose finegrained categorization different type entity mention link reannotate three el benchmark datasets ace kore voxel respect category propose fuzzy recall metric address lack consensus conclude finegrained evaluation result comparing selection online el system
counterfactual statement describe event take place consider problem counterfactual detection cfd product review purpose annotate multilingual cfd dataset amazon product review covering counterfactual statement written english german japanese language dataset unique contains counterfactuals multiple language cover new application area ecommerce review provides high quality professional annotation train cfd model using different text representation method classifier find model robust selectional bias introduced due cue phrasebased sentence selection moreover cfd dataset compatible prior datasets merged learn accurate cfd model applying machine translation english counterfactual example create multilingual data performs poorly demonstrating languagespecificity problem ignored far
modern neural language model produce remarkably fluent grammatical text much fact recent work clark et al reported conventional crowdsourcing longer reliably distinguish machineauthored gpt humanauthored writing error machine generation become ever subtler harder spot pose new challenge research community robust machine text evaluation propose new framework called scarecrow scrutinizing machine text via crowd annotation support broad range real machine error identified laypeople ten error category scarecrowsuch redundancy commonsense error incoherenceare identified several round crowd annotation experiment without predefined ontology use scarecrow collect k error span humanwritten machinegenerated paragraph english language news text isolate factor detailed analysis including parameter count training data various decodingtime configuration approach successfully quantifies measurable gap human authored text generation model several size including fourteen configuration gpt addition analysis unveils new insight detailed rationale provided laypeople eg commonsense capability improving larger model math capability choice simple decoding hyperparameters make remarkable difference perceived quality machine text release training material annotation toolkit dataset urlhttpsyaodougithubioscarecrow
almost summarisation method datasets focus single language short summary introduce new dataset called wikinewssum english german french spanish portuguese polish italian summarisation tailored extended summary approx sentence dataset comprises summary news article wikinews source compare three multilingual transformer model extractive summarisation task three training scenario finetune mt perform abstractive summarisation result strong baseline extractive abstractive summarisation wikinewssum also show combination extractive model abstractive one used create extended abstractive summary long input document finally result show finetuning mt language combined significantly improves summarisation performance lowresource language
document understanding task particular visuallyrich document entity retrieval vder gained significant attention recent year thanks broad application enterprise ai however publicly available data scarce task due strict privacy constraint high annotation cost make thing worse nonoverlapping entity space different datasets hinder knowledge transfer document type paper propose method collect massivescale weakly labeled data web benefit training vder model collected dataset named documentnet depend specific document type entity set making universally applicable vder task current documentnet consists document spanning nearly document type organized fourlevel ontology experiment set broadly adopted vder task show significant improvement documentnet incorporated pretraining classic fewshot learning setting recent emergence large language model llm documentnet provides large data source extend multimodal capability vder
paper present novel datatotext system cancer patient providing information quality life implication treatment embedded context shared decision making currently information quality life implication often discussed partly recently data lacking work rely newly developed prediction model assigns patient scenario furthermore use datatotext technique explain scenariobased prediction personalized understandable language highlight possibility nlg personalization discus ethical implication also present outcome first evaluation clinician
routing input token split expert sparse mixtureofexperts enabled efficient training large language model recent finding suggest fixing router achieve competitive performance alleviating collapsing problem expert eventually learn similar representation however strategy two key limitation policy derived random router might suboptimal ii requires extensive resource training evaluation leading limited efficiency gain work introduces hyperrouter dynamically generates router parameter fixed hypernetwork trainable embeddings achieve balance training router freezing learn improved routing policy extensive experiment across wide range task demonstrate superior performance efficiency gain hyperrouter compared existing routing method implementation publicly available urlhttpsgithubcomgiangdiphyperrouter
present development dataset kazakh named entity recognition dataset built clear need publicly available annotated corpus kazakh well annotation guideline containing straightforwardbut rigorousrules example dataset annotation based iob scheme carried television news text two native kazakh speaker supervision first author resulting dataset contains sentence annotation entity class stateoftheart machine learning model automatise kazakh named entity recognition also built bestperforming model achieving exact match fscore test set annotated dataset guideline code used train model freely available download cc licence urlhttpsgithubcomisaikaznerd
neural language model often trained maximum likelihood estimation mle next word generated conditioned groundtruth word token testing however model instead conditioned previously generated token resulting termed exposure bias reduce gap training testing propose using optimal transport ot match sequence generated two mode examine necessity adding studentforcing scheme training imitation learning interpretation extension proposed improve ot learning long sequence based structural contextual information text sequence effectiveness proposed method validated machine translation text summarization text generation task
paper investigates use bilingual word embeddings mining hiligaynon translation english word little research hiligaynon extremely lowresource language malayopolynesian origin million speaker philippine found one paper use publicly available hiligaynon corpus k word match comparable corpus english bilingual resource available manually develop englishhiligaynon lexicon use train bilingual word embeddings fail mine accurate translation due small amount data find hold true related language pair simulate lowresource setup english german arrive similar result vary size comparable english german corpus determine minimum corpus size necessary achieve competitive result investigate role seed lexicon show corpus size smaller seed lexicon performance surpass result previous study release lexicon englishhiligaynon word pair created encourage investigation
lexical normalization addition word segmentation partofspeech tagging fundamental task japanese usergenerated text processing paper propose text editing model solve three task jointly method pseudolabeled data generation overcome problem data deficiency experiment showed proposed model achieved better normalization performance trained diverse pseudolabeled data
paper describes system developed semeval task multigenerator multidomain multilingual blackbox machinegenerated text detection machinegenerated text one main concern due use large language model llm fake text generation phishing cheating exam even plagiarizing copyright material lot system developed detect machinegenerated text nonetheless majority system rely textgenerating model limitation impractical realworld scenario often impossible know specific model user used text generation work propose single model based contrastive learning us textasciitilde baseline parameter v show comparable performance test dataset st participant key finding even without ensemble multiple model single base model comparable performance help data augmentation contrastive learning
decoding phrasebased translation model general case known npcomplete reduction traveling salesman problem knight practice phrasebased system often impose hard distortion limit limit movement phrase translation however impact complexity imposing constraint well studied paper describe dynamic programming algorithm phrasebased decoding fixed distortion limit runtime algorithm ondlhd n sentence length distortion limit l bound number phrase starting position sentence h related maximum number target language translation source word algorithm make use novel representation give new perspective decoding phrasebased model
machine translation proved easier language closely related german english far apart language chinese english encounter much problem present study focus upon swedish norwegian two language closely related would referred dialect fact royal house army connected despite similarity though difference make translation phase much less straightforward could expected taking outset sentence aligned parallel text study aim highlighting difference formalise result order text aligned smaller unit simple cognate alignment method surprising longer word easier align shorter often highfrequent word became problem also trying align specific word sense dictionary content word rendered better result therefore abandoned use singleword unit searched multiword unit whenever possible study reinforces view machine translation rest upon method based multiword unit search
mapping user location country useful many application dialect identification author profiling recommendation system etc twitter allows user declare location free text userdeclared location often noisy hard decipher automatically paper present largest manually labeled dataset mapping user location arabic twitter corresponding country build effective machine learning model automate mapping significantly better efficiency compared library geopy also show dataset effective data extracted geonames geographical database task latter cover location written formal way
endtoend neural model show great promise towards building conversational agent trained data online experience using supervised reinforcement learning however model require large corpus dialogue learn effectively goaloriented dialogue datasets expensive collect annotate since task involves separate schema database entity wizardofoz approach commonly used dialogue collection provide sufficient coverage salient dialogue flow critical guaranteeing acceptable task completion rate consumerfacing conversational agent paper study recently proposed approach building agent arbitrary task combining dialogue selfplay crowdsourcing generate fullyannotated dialogue diverse natural utterance discus advantage approach industry application conversational agent wherein agent rapidly bootstrapped deploy front user optimized via interactive learning actual user system
linguistic data often contain pii personal identifiable information legal ethical standpoint sharing data permissible according gdpr pseudonymization ie replacement sensitive information surrogate acceptable strategy privacy preservation research conducted detection replacement sensitive data swedish medical data using large language model llm unclear whether model handle pii less structured thematically varied text equally well paper present discus performance llmbased piidetection system swedish learner essay
image captioning system need produce text true also relevant properly aligned current issue instance newspaper article sport event caption identifies player picture also comment ethnicity could create unwanted reader reaction address propose issuesensitive image captioning isic isic captioner given target image issue set image partitioned way specifies information relevant sport article could construct partition place image equivalence class based player position model task use extension rational speech act model extension built top stateoftheart pretrained neural image captioners explicitly us image partition control caption generation automatic human evaluation show model generate caption descriptive issuesensitive finally show isic complement enrich related task visual question answering
recent study revealed security threat natural language processing nlp model called backdoor attack victim model maintain competitive performance clean sample behaving abnormally sample specific trigger word inserted previous backdoor attacking method usually assume attacker certain degree data knowledge either dataset user would use proxy datasets similar task implementing data poisoning procedure however paper find possible hack model datafree way modifying one single word embedding vector almost accuracy sacrificed clean sample experimental result sentiment analysis sentencepair classification task show method efficient stealthier hope work raise awareness critical security risk hidden embedding layer nlp model code available urlhttpsgithubcomlancopkuembeddingpoisoning
gender bias frequent occurrence nlpbased application especially pronounced genderinflected language bias appear association certain adjective animate noun natural gender referent also due unbalanced grammatical gender frequency inflected word type bias becomes evident generating conversational utterance gender specified within sentence current nlp application still work sentencelevel context step towards inclusive nlp paper proposes automatic generalisable rewriting approach short conversational sentence rewriting method applied sentence without extrasentential context multiple equivalent alternative term gender method applied creating gender balanced output well creating gender balanced training data proposed approach based neural machine translation system trained translate one gender alternative another automatic manual analysis approach show promising result respect automatic generation gender alternative conversational sentence spanish
despite popularity pretrain finetune paradigm nlp community existing work quantifying energy cost associated carbon emission largely focused language model pretraining although single pretraining run draw substantially energy finetuning finetuning performed frequently many individual actor thus must accounted considering energy carbon footprint nlp order better characterize role finetuning landscape energy carbon emission nlp perform careful empirical study computational cost finetuning across task datasets hardware infrastructure measurement modality experimental result allow u place finetuning energy carbon cost perspective respect pretraining inference outline recommendation nlp researcher practitioner wish improve finetuning energy efficiency
text classification central tool nlp however target class strongly correlated textual attribute text classification model pick wrong feature leading bad generalization bias social medium analysis problem surface demographic user class language topic gender influence generate text substantial extent adversarial training claimed mitigate problem thorough evaluation missing paper experiment text classification correlated attribute document topic author gender using novel multilingual parallel corpus ted talk transcript finding individual classifier topic author gender indeed biased b debiasing adversarial training work topic break author gender c gender debiasing result differ across language interpret result term feature space overlap highlighting role linguistic surface realization target class
social medium provide platform express discus shape opinion event issue real world important step analyze discussion social medium assist healthy decisionmaking stance detection paper present approach detect stance user toward topic based stance toward topic social medium post user apply factorization machine widely used method item recommendation model user preference toward topic social medium data experimental result demonstrate user post useful model topic preference therefore predict stance silent user
instruction tuning emerged enhance capability large language model llm comprehend instruction generate appropriate response existing method either manually annotate employ llm eg gptseries generate data instruction tuning however often overlook associating instruction existing annotated datasets paper propose dynosaur dynamic growth paradigm automatic curation instructiontuning data based metadata existing datasets use llm automatically construct instructiontuning data identifying relevant data field generating appropriate instruction leveraging existing annotated datasets dynosaur offer several advantage reduces api cost generating instruction eg cost less usd calling gptturbo generating k instruction tuning sample provides highquality data instruction tuning eg performs better alpaca flan superni longform comparable data size support continuous improvement model generating instructiontuning data new annotated dataset becomes available investigate continual learning scheme learning evergrowing instructiontuning dataset demonstrate replaying task diverse instruction embeddings help mitigate forgetting issue generalizes unseen task better code data available httpsgithubcomwadeyindynosaur
paper present webbased multimedia search engine built within buceador wwwbuceadororg research project proofofconcept tool implemented able retrieve information digital library made multimedia document official language spain spanish basque catalan galician retrieved document presented user language translation dubbing four previous language english paper present tool functionality architecture digital library provide information technology involved field automatic speech recognition statistical machine translation texttospeech synthesis information retrieval technology adapted purpose presented tool well interact rest technology involved
recent development neural relation extraction nre made significant stride towards automated knowledge base construction much attention dedicated towards improvement accuracy attempt literature evaluate social bias exhibited nre system paper create wikigenderbias distantly supervised dataset composed sentence including human annotated test set purpose analyzing gender bias relation extraction system find extracting spouseof hypernym ie occupation relation nre system performs differently gender target entity different however disparity appear extracting relation birthdate birthplace also analyze existing bias mitigation technique name anonymization word embedding debiasing data augmentation affect nre system term maintaining test performance reducing bias unfortunately due nre model rely heavily surface level cue find existing bias mitigation approach negative effect nre analysis lay groundwork future quantifying mitigating bias nre
large language model llm gained popularity recently due outstanding performance various downstream natural language processing nlp task however lowresource language still lagging behind current stateoftheart sota development field nlp due insufficient resource train llm ethiopian language exhibit remarkable linguistic diversity encompassing wide array script imbued profound religious cultural significance paper introduces ethiollm multilingual large language model five ethiopian language amharic geez afan oromo somali tigrinya english ethiobenchmark new benchmark dataset various downstream nlp task evaluate performance model across five downstream nlp task opensource multilingual language model new benchmark datasets various downstream task taskspecific finetuned language model discus performance model dataset model available httpshuggingfacecoethionlp repository
chart widely used data analysis providing visual representation insight complex data facilitate chartbased data analysis using natural language several downstream task introduced recently chart question answering chart summarization however existing method task often rely pretraining language visionlanguage task neglecting explicit modeling chart structure eg chart element related address first build large corpus chart covering diverse topic visual style present unichart pretrained model chart comprehension reasoning unichart encodes relevant text data visual element chart us chartgrounded text decoder text generation propose several chartspecific pretraining task include lowlevel task extract visual element eg bar line data chart ii highlevel task acquire chart understanding reasoning skill experiment demonstrate pretraining unichart large corpus chartspecific objective followed finetuning yield stateoftheart performance four downstream task moreover model exhibit superior generalizability unseen chart corpus surpassing previous approach lack chartspecific objective utilize limited chart resource
large language model llm effectively generate fluent text target output follows natural language pattern however structured prediction task confine output format limited ontology causing even large model struggle since never trained restriction mind difficulty using llm direct prediction exacerbated fewshot learning scenario commonly arise due domain shift resource limitation flip problem head leveraging llm tool data augmentation rather direct prediction proposed mixture soft prompt msp serf parameterefficient procedure generating multiattribute data controlled manner denoising mechanism applied improve quality synthesized data automatic metric show method capable producing diverse natural text preserving label semantics moreover msp achieves stateoftheart result three benchmark compared strong baseline method offer alternate datacentric approach applying llm complex prediction task
paper address problem generating question given context answer specifically focusing question require multihop reasoning across extended context previous study suggested key phrase selection essential question generation qg yet still challenging connect disjointed phrase meaningful question particularly long context mitigate issue propose multifactor novel qg framework based multilevel content planning specifically multifactor includes two component famodel simultaneously selects key phrase generates full answer qmodel take generated full answer additional input generate question full answer generation introduced connect short answer selected key phrase thus forming answeraware summary facilitate qg famodel qmodel formalized simpleyeteffective phraseenhanced transformer joint model phrase selection text generation experimental result show method outperforms strong baseline two popular qg datasets code available httpsgithubcomzeavermultifactor
east asian language japanese chinese semantics character somewhat reflected subcharacter element paper examines effect using subcharacters language modeling japanese achieved decomposing character according range character decomposition datasets training neural language model variously decomposed character representation result indicate language modelling improved inclusion subcharacters though result depends good choice decomposition dataset appropriate granularity decomposition
rapid improvement language model raised specter abuse text generation system progress motivates development simple method detecting generated text used nonexperts work introduce gltr tool support human detecting whether text generated model gltr applies suite baseline statistical method detect generation artifact across multiple sampling scheme humansubjects study show annotation scheme provided gltr improves human detectionrate fake text without prior training gltr opensource publicly deployed already widely used detect generated output
although multilingual neural machine translation mnmt enables multiple language translation training process based independent multilingual objective multilingual model explicitly exploit different language pair assist ignoring relationship among work propose novel agreementbased method encourage multilingual agreement among different translation direction minimizes difference among combine multilingual training objective agreement term randomly substituting fragment source language counterpart translation auxiliary language examine effectiveness method conduct experiment multilingual translation task language pair experimental result show method achieves significant improvement previous multilingual baseline
paper describes submission niutrans team wmt quality estimation shared task participated task language pair explored combination transfer learning multitask learning model ensemble result multiple task show deep transformer machine translation model multilingual pretraining method significantly improve translation quality estimation performance system achieved remarkable result multiple level task eg submission obtained best result track sentencelevel direct assessment task
paper report linguisticallyenriched method detecting tokenlevel metaphor second shared task metaphor detection participate four phase competition datasets ie verb allpos vua tofel datasets use modality exclusivity embodiment norm constructing conceptual representation node context system obtains fscore vua verb track higher strong baseline experimental result across model datasets indicate salient contribution using modality exclusivity modality shift information predicting metaphoricity
model production quantified referring expression qres identity collection visual item previous approach called perceptual cost pruning modeled human qre production using preferencebased referring expression generation algorithm first removing fact input knowledge base based model perceptual cost paper present alternative model incrementally construct symbolic knowledge base simulating human visual attentionperception raw image demonstrate model produce output perceptual cost pruning argue extensible approach step toward developing wider range processlevel model human visual description
prior research note berts computational cost grows quadratically sequence length thus leading longer training time higher gpu memory constraint carbon emission recent work seek address scalability issue pretraining issue also prominent finetuning especially long sequence task like document classification work thus focus optimizing computational cost finetuning document classification achieve complementary learning topic language model unified framework named topicbert significantly reduces number selfattention operation main performance bottleneck consequently model achieves x speedup reduction co emission retaining performance datasets
paper report experiment different stack word embeddings evaluation usefulness bulgarian downstream task named entity recognition classification nerc partofspeech po tagging word embeddings stay core development nlp several key language model created last two year like fasttext citation elmo citation bert citation flair citation stacking combining different word embeddings another technique used paper still reported bulgarian nerc wellestablished architecture used sequence tagging task bilstmcrf different pretrained language model combined embedding layer decide combination score better
transformer widely used code representation several recent work develop tree transformer capture syntactic structure source code specifically novel tree positional encoding proposed incorporate inductive bias transformerin work propose novel tree transformer encoding node position based new description method tree structurestechnically local global soft bias shown previous work introduced positional encoding transformer modelour model finally outperforms strong baseline code summarization completion task across two language demonstrating model effectivenessbesides extensive experiment ablation study show combining local global paradigm still helpful improving model performance release code urlhttpsgithubcomawdhanpengtreetransformer
despite huge progress myriad generation task pretrained language model lm gpt still tend generate repetitive text maximizationbased decoding algorithm openended generation attribute overestimation tokenlevel repetition probability learning bias lm capture simple repetitive pattern faster mle loss propose selfcontrastive training penalize output premature checkpoint model incorrectly predicts repetition shown mitigate repetition effectively maintaining fluency two datasets furthermore find lm use longerrange dependency predict repetitive token nonrepetitive one may cause sentencelevel repetition loop
syntactic semantic structure key linguistic contextual clue parsing latter well shown beneficial parsing former however work ever made attempt let semantic parsing help syntactic parsing linguistic representation formalism syntax semantics may represented either span constituentphrase dependency joint learning also seldom explored paper propose novel joint model syntactic semantic parsing span dependency representation incorporates syntactic information effectively encoder neural network benefit two representation formalism uniform way experiment show semantics syntax benefit optimizing joint objective single model achieves new stateoftheart competitive result span dependency semantic parsing propbank benchmark dependency constituent syntactic parsing penn treebank
paper outline work collecting training data developing latingerman neural machine translation nmt system translating th century letter latingerman lowresource language pair term nmt domain th century epistolary latin even limited regard effort data collection data generation able train nmt model provides good translation short medium sentence outperforms googletranslate overall focus correspondence swiss reformer heinrich bullinger parallel corpus nmt system use many text time
paper introduce problem extracting event dialogue previous work event extraction focused newswire however interested extracting event spoken dialogue ground study annotated dialogue transcript fourteen episode podcast american life corpus contains utterance made token represent event agreement corpus cohens kappa opensourced corpus nlp community corpus hand trained support vector machine svm correctly classify phenomenon f using episodefold crossvalidation nearly higher f baseline classifier svm model achieved performance f testing fold report result svm classifier trained four different type feature verb class part speech tag named entity semantic role label different machine learning protocol undersampling trigram context work grounded narratology computational model narrative useful extracting event plot story content spoken dialogue
content warning paper contains example misgendering erasure could offensive potentially triggeringmisgendering act incorrectly addressing someone gender inflicts serious harm pervasive everyday technology yet notable lack research combat first address lack research intervention misgendering conducting survey genderdiverse individual u understand perspective automated intervention textbased misgendering based survey insight prevalence misgendering desired solution associated concern introduce misgendering intervention task evaluation dataset misgendermender define task two subtasks detecting misgendering followed ii correcting misgendering misgendering present domain editing appropriate misgendermender comprises instance social medium content llmgenerations noncisgender public figure annotated presence misgendering additional annotation correcting misgendering llmgenerated text using dataset set initial benchmark evaluating existing nlp system highlighting challenge future model address release full dataset code demo httpstamannahossainkaygithubiomisgendermender
namedentity recognition ner aim identifying entity interest text artificial neural network anns recently shown outperform existing ner system however anns remain challenging use nonexpert user paper present neuroner easytouse namedentity recognition tool based anns user annotate entity using graphical webbased user interface brat annotation used train ann turn predict entity location category new text neuroner make annotationtrainingprediction flow smooth accessible anyone
medical concept normalization mcn ie mapping colloquial medical phrase standard concept essential step analysis medical social medium text main drawback existing stateoftheart approach kalyan sangeetha b learning target concept vector representation scratch requires number training instance model based roberta target concept embeddings model integrate target concept information form target concept vector generated encoding target concept description using sroberta stateoftheart roberta based sentence embedding model b domain lexicon knowledge enriching target concept vector synonym relationship knowledge using retrofitting algorithm first attempt mcn exploit target concept information well domain lexicon knowledge form retrofitted target concept vector model outperforms existing model accuracy improvement three standard datasets model trained mapping lexicon synonym achieves improvement accuracy
wide availability pretrained language model plms multitask finetuning across domain extensively applied task related distant domain different class label set plms may memorize nontransferable knowledge target domain suffer negative transfer inspired metalearning propose meta distant transfer learning metadtl framework learn crosstask knowledge plmbased method metadtl first employ task representation learning mine implicit relation among multiple task class based result train plmbased metalearner capture transferable knowledge across task weighted maximum entropy regularizers proposed make metalearner taskagnostic unbiased finally metalearner finetuned fit task better parameter initialization evaluate metadtl using bert albert seven public datasets experiment result confirm superiority metadtl consistently outperforms strong baseline find metadtl highly effective data available target task
captioning crucial challenging task video understanding video involve active agent human agent action bring myriad change scene observable change movement manipulation transformation object scene reflected conventional video captioning unlike image action video also inherently linked social aspect intention action taking place effect change due action attribute describe agent thus video understanding captioning video answering question video one must understanding commonsense aspect present first work generating textitcommonsense caption directly video describe latent aspect intention effect attribute present new dataset videotocommonsense vc contains textasciitildek video human agent performing various action annotated type commonsense description additionally explore use openended videobased commonsense question answering vcqa way enrich caption generation task qa task used enrich video caption
neural coreference resolution model trained one dataset may transfer new lowresource domain active learning mitigates problem sampling small subset data annotator label active learning welldefined classification task application coreference resolution neither welldefined fully understood paper explores actively label coreference examining source model uncertainty document reading cost compare uncertainty sampling strategy advantage thorough error analysis synthetic human experiment labeling span within document effective annotating span across document finding contribute realistic development coreference resolution model
investigate sentencelevel transformer modified effective sequence labelers token level without direct supervision existing approach zeroshot sequence labeling perform well applied transformerbased architecture transformer contain multiple layer multihead selfattention information sentence get distributed many token negatively affecting zeroshot tokenlevel performance find soft attention module explicitly encourages sharpness attention weight significantly outperform existing method
logical reasoning ongoing pursuit field ai despite significant advancement made large language model llm still struggle complex logical reasoning problem enhance reasoning performance one promising direction scalable oversight requires llm identify error improve various selfverification method proposed pursuit goal nevertheless whether existing model understand error well still investigation paper take closer look selfverification ability llm context logical reasoning focusing ability identify logical fallacy accurately introduce dataset fallacy containing type reasoning fallacy categorized hierarchical taxonomy conducting exhaustive experiment fallacy obtain comprehensive detailed analysis series model verification ability main finding suggest existing llm could struggle identify fallacious reasoning step accurately may fall short guaranteeing validity selfverification method drawing observation offer suggestion future research practical application selfverification method
constituency parsing nested named entity recognition ner similar task since aim predict collection nested noncrossing span work cast nested ner constituency parsing propose novel pointing mechanism bottomup parsing tackle task key idea based observation traverse constituency tree postorder ie visiting parent child two consecutively visited span would share boundary model track shared boundary predicts next boundary step leveraging pointer network result need linear step parse thus efficient also maintains parsing configuration structural consistency ie always outputting valid tree experimentally model achieves stateoftheart performance ptb among bertbased model f score competitive performance ctb constituency parsing also achieves strong performance three benchmark datasets nested ner ace ace genia code available urlhttpsgithubcomxxxxx
current work imagebased story generation suffers fact existing image sequence collection coherent plot behind improve visual story generation producing new imagegrounded dataset visual writing prompt vwp vwp contains almost k selected sequence movie shot including image image sequence aligned total k story collected via crowdsourcing given image sequence set grounded character corresponding image sequence new image sequence collection filtering process allowed u obtain story coherent diverse visually grounded compared previous work also propose characterbased story generation model driven coherence strong baseline evaluation show generated story coherent visually grounded diverse story generated current stateoftheart model code image feature annotation collected story available urlhttpsvwpromptgithubio
despite fact multilingual agreement shown importance multilingual neural machine translation mnmt current methodology field two shortage require parallel data multiple language pair always realistic ii optimize agreement ambiguous direction hamper translation performance present textbfbidirectional textbfmultilingual textbfagreement via textbfswitched textbfbacktextbftranslation textbfbmasbt novel universal multilingual agreement framework finetuning pretrained mnmt model exempts need aforementioned parallel data using novel method called switched bt creates synthetic text written another source language using translation target ii optimizes agreement bidirectionally kullbackleibler divergence loss experiment indicate bmasbt clearly improves strong baseline task mnmt three benchmark ted talk news europarl indepth analyzes indicate bmasbt brings additive improvement conventional bt method
paper present annotation process two estonian named entity recognition ner datasets involving creation annotation guideline labeling eleven different type entity addition commonly annotated entity person name organization name location annotation scheme encompasses geopolitical entity product name titlesroles event date time monetary value percent annotation performed two datasets one involving reannotating existing ner dataset primarily composed news text incorporating new text news social medium domain transformerbased model trained annotated datasets establish baseline predictive performance finding indicate best result achieved training single model combined dataset suggesting domain difference datasets relatively small
lack sufficient amount data tailored task wellrecognized problem many statistical nlp method paper explore whether data sparsity successfully tackled classifying language proficiency level domain learnerwritten output text aim overcoming data sparsity incorporating knowledge trained model another domain consisting input text written teaching professional learner compare different domain adaptation technique find weighted combination two type data performs best even rival system based considerably larger amount indomain data moreover show normalizing error learner text substantially improve classification levelannotated indomain data available
present epic english perspectivist irony corpus first annotated corpus irony analysis based principle data perspectivism corpus contains short conversation social medium five regional variety english annotated contributor five country corresponding variety analyse resource along perspective induced diversity annotator term origin age gender relationship dimension irony topic conversation validate epic creating perspectiveaware model encode perspective annotator grouped according demographic characteristic firstly performance perspectivist model confirms different annotator induce different model secondly classification ironic nonironic text perspectivist model prove generally confident nonperspectivist one furthermore comparing performance perspectivebased test set achieved gold standard test set observe perspectivist model tend detect precisely positive class showing ability capture different perception irony thanks model moreover able show interesting insight variation perception irony different group annotator among different generation nationality
recent effort focused expanding annotation coverage propbank verb relation adjective noun relation well light verb construction eg make offer take bath new relation type presented unique annotation challenge ensuring consistent comprehensive annotation light verb construction proved particularly challenging given light verb construction semiproductive difficult define often borderline case research describes iterative process developing propbank annotation guideline light verb construction current guideline comparison related resource
backtranslation critical component unsupervised neural machine translation unmt generates pseudo parallel data target monolingual data unmt model trained pseudo parallel data textbf translated source translates textbf natural source sentence inference source discrepancy training inference hinders translation performance unmt model carefully designing experiment identify two representative characteristic data gap source texttextitstyle gap ie translated v natural text style lead poor generalization capability texttextitcontent gap induces model produce hallucination content biased towards target language narrow data gap propose online selftraining approach simultaneously us pseudo parallel data natural source translated target mimic inference scenario experimental result several widelyused language pair show approach outperforms two strong baseline xlm mass remedying style content gap
paper introduces robust spin rspin dataefficient domainspecific selfsupervision method speaker noiseinvariant speech representation learning discrete acoustic unit speakerinvariant clustering spin rspin resolve spin issue enhances content representation learning predict acoustic piece rspin offer x reduction computational resource compared previous stateoftheart method outperforming severely distorted speech scenario paper provides detailed analysis show discrete unit contribute speech encoder training improving robustness diverse acoustic environment
canonical automatic summary evaluation metric rouge focus lexical similarity well capture semantics linguistic quality require reference summary costly obtain recently growing number effort alleviate either two drawback paper present proofofconcept study weakly supervised summary evaluation approach without presence reference summary massive data existing summarization datasets transformed training pairing document corrupted reference summary crossdomain test strategy outperforms baseline promising improvement show great advantage gauging linguistic quality metric
text normalization task transforming lexical variant canonical form model problem text normalization characterlevel sequence sequence learning problem present neural encoderdecoder model solving train encoderdecoder model many sentence pair generally required however japanese nonstandard canonical pair scarce form parallel corpus address issue propose method data augmentation increase data size converting existing resource synthesized nonstandard form using handcrafted rule conducted experiment demonstrate synthesized corpus contributes stably train encoderdecoder model improve performance japanese text normalization
contextual wordrepresentations became standard modern natural language processing system model use subword tokenization handle large vocabulary unknown word wordlevel usage system requires way pooling multiple subwords correspond single word paper investigate choice subword pooling affect downstream performance three task morphological probing po tagging ner typologically diverse language compare two massively multilingual model mbert xlmroberta morphological task widely used choose first subword worst strategy best result obtained using attention subwords po tagging strategy perform poorly best choice use small lstm subwords strategy work best ner show mbert better xlmroberta language publicly release code data full result table urlhttpsgithubcomjuditacssubwordchoice
study task semantic parse correction natural language feedback given natural language utterance semantic parsing system pose problem oneshot translation utterance mapped corresponding logical form paper investigate interactive scenario human interact system providing freeform natural language feedback correct system generates inaccurate interpretation initial utterance focus natural language sql system construct splash dataset utterance incorrect sql interpretation corresponding natural language feedback compare various reference model correction task show incorporating rich form feedback significantly improve overall semantic parsing accuracy retaining flexibility natural language interaction estimated human correction accuracy best model achieves leaf large gap improvement future research splash publicly available urlhttpsakamssplashdataset
fastspreading development online streaming service enabled people world listen music however always straightforward given user find right song version looking streaming service may affected potential dissatisfaction among customer quality song presence tag label associated song returned user important thus need precise reliable metadata becomes paramount work particularly interested distinguishing live studio version song specifically tackle problem case littleannotated training data available demonstrate original cotraining algorithm semisupervised setting alleviate problem data scarcity successfully discriminate live studio music recording
complementary potential large language model llm assumes offtheshelf llm heterogeneous expertise wide range domain task ensemble llm achieve consistently better performance existing ensemble method llm mainly focus reward model ranking output leading significant computation overhead combat issue revisit complementary potential llm elaborate mining latent expertise offtheshelf reward model propose zooter rewardguided routing method distilling reward training query train routing function precisely distribute query llm expertise also integrate tagbased label enhancement mitigate noise uncertainty using reward silver supervision zooter show computation efficiency inference introduces minor computation overhead routing function compared reward model ranking method evaluate zooter comprehensive benchmark collection subset different domain task zooter outperforms best single model average rank first task even surpassing multiple reward model ranking method
interpolative data augmentation proven effective nlp task despite merit sample selection process mixup random might make difficult model generalize better converge faster propose ciaug novel curriculumbased learning method build upon mixup leverage relative position sample hyperbolic embedding space complexity measure gradually mix increasingly difficult diverse sample along training ciaug achieves stateoftheart result existing interpolative augmentation method benchmark datasets across language text classification namedentity recognition task also converges achieves benchmark f score time faster empirically analyze various component ciaug evaluate robustness adversarial attack
quality management assurance key space agency guarantee success space mission highrisk extremely costly paper present system generate quiz common resource evaluate effectiveness training session document quality assurance procedure space domain system leverage state art autoregressive model like bart generate question roberta model extract answer question thus verifying suitability
paper describes approach task semeval statement verification evidence finding table participated subtasks namely statement verification evidence finding subtask statement verification extend tapa model adapt unknown class statement finetuning augmented version task data subtask evidence finding finetune distilbert model siamese setting
despite excellent performance visionlanguage pretrained model vlps conventional vqa task still suffer two problem first vlps tend rely language bias datasets fail generalize outofdistribution ood data second inefficient term memory footprint computation although promising progress made problem existing work tackle independently facilitate application vlp vqa task imperative jointly study vlp compression ood robustness however yet explored paper investigates whether vlp compressed debiased simultaneously searching sparse robust subnetworks end systematically study design training compression pipeline search subnetworks well assignment sparsity different modalityspecific module experiment involve vlps compression method training method datasets range sparsity level result show indeed exist sparse robust subnetworks competitive debiased full vlp clearly outperform debiasing sotas fewer parameter ood datasets vqacp v vqavs code found httpsgithubcomphoebussicompressrobustvqa
reasoning inference central human artificial intelligence modeling inference human language challenging availability large annotated data bowman et al recently become feasible train neural network based inference model shown effective paper present new stateoftheart result achieving accuracy stanford natural language inference dataset unlike previous top model use complicated network architecture first demonstrate carefully designing sequential inference model based chain lstms outperform previous model based show explicitly considering recursive architecture local inference modeling inference composition achieve additional improvement particularly incorporating syntactic parsing information contributes best resultit improves performance even added already strong model
phenomenon zero pronoun zp attracted increasing interest machine translation mt community due importance difficulty however previous study generally evaluate quality translating zps bleu score mt testsets expressive sensitive enough accurate assessment bridge data evaluation gap propose benchmark testset target evaluation chineseenglish zp translation humanannotated testset cover five challenging genre reveal different characteristic zps comprehensive evaluation systematically revisit eight advanced model zp translation identify current challenge future exploration release data code model annotation guideline hope significantly promote research field httpsgithubcomlongyuewangdcumzprt
large language model llm displayed impressive ability harness natural language perform complex task explore whether leverage ability find explain pattern data specifically given pretrained llm data example apply interpretable autoprompting iprompt generate natural language string explaining data iprompt iteratively generates explanation llm reranks based performance used prompt experiment wide range datasets synthetic mathematics natural language understanding show iprompt yield meaningful insight accurately finding dataset explanation humaninterpretable moreover iprompt reasonably efficient require access model gradient work relatively small model eg textasciitilde billion parameter rather textgreater billion finally experiment scientific datasets show potential iprompt aid scientific discovery
existing event extraction method classify argument role independently ignoring conceptual correlation different argument role paper propose hierarchical modular event argument extraction hmeae model provide effective inductive bias concept hierarchy event argument role specifically design neural module network basic unit concept hierarchy hierarchically compose relevant unit module logical operation roleoriented modular network classify specific argument role many argument role share highlevel unit module correlation utilized extract specific event argument better experiment realworld datasets show hmeae effectively leverage useful knowledge concept hierarchy significantly outperform stateoftheart baseline source code obtained urlhttpsgithubcomthunlphmeae
paper report preliminary experiment speech processing teochew underresourced sinitic language spoken china around world diasporan community following recent uptick interest teochew heritage speaker diaspora order respond need community develop teochew texttospeech system describe experiment build system assess possible contribution available resource taiwanese hokkien closest language significant body resource result experiment conclusive expected taiwanese dataset help model significantly considering objective find encouraging show large training dataset necessary precise task promising model could still obtained small dataset teochew hope work inspires community speaker language revitalization phase
cyberbullying prevalent social problem inflicts detrimental consequence health safety victim psychological distress antisocial behaviour suicide automation cyberbullying detection recent widely researched problem current research strong focus binary classification bullying versus nonbullying paper proposes novel approach enhancing cyberbullying detection role modeling utilise dataset askfm perform multiclass classification detect participant role eg victim harasser preliminary result demonstrate promising performance including fscore cyberbullying role classification respectively outperforming baseline
existing supervised solution emotion classification demand large amount emotion annotated data resource may available many language however common sentiment annotated data available language sentiment information useful segregate positive emotion negative emotion paper propose unsupervised approach emotion recognition taking advantage sentiment information given sentence sentiment information recognize best possible emotion every sentence semantic relatedness word sentence set emotionspecific word calculated using cosine similarity emotion vector representing emotion score emotion category ekman model created improved dependency relation best possible emotion predicted result show significant improvement fscore value text sentiment information input baseline text without sentiment information report weighted fscore three different datasets ekman emotion model support leveraging sentiment value better emotion annotated data created
electronic patient record eprs valuable resource research confidentiality reason used freely order make eprs available wider group researcher sensitive information personal name removed deidentification process make possible rulebased well statistical machine learning based method exist perform deidentification second method requires annotated training material exists sparsely patient name therefore necessary use rulebased method deidentification eprs much known however order various rule applied different rule influence precision recall paper aim answer research question implementing evaluating four common rule deidentification personal name eprs written swedish dictionary name matching title matching common word filtering learning previous module result show obtain highest recall precision rule applied following order title matching common word filtering dictionary name matching
many system rely ability effectively search database personal organization entity name multiple writing script despite relative lack research studying problem isolation work discus problem detail support future research publishing believe first comprehensive dataset designed task additionally present number baseline future work compared among describe neural solution based byt xue et al demonstrates performance gain preexisting baseline indicating remains much room improvement space
paper describes joint submission university edinburgh uppsala university wmt chat translation task language direction englishgerman use existing stateoftheart machine translation model trained news data finetune indomain pseudoindomain web crawled data baseline system transformerbig model pretrained wmt news translation task finetuned pseudoindomain web crawled data indomain task data also experiment adaptation using speaker domain tag ii using different type amount preceding context observe contrarily expectation exploiting context degrades result analysis data highly contextual however using domain tag improve score according automatic evaluation final primary system use domain tag ensemble model noisy channel reranking output ende system ranked second shared task deen system outperformed system
last year deep learning proved effective paradigm discover pattern large data set unfortunately deep learning training small data set best option time traditional machine learning algorithm could get better score train neural network large data set finetune smaller data set using transfer learning technique paper present system nadi shared task countrylevel dialect identification system based finetuning bert achieves fscore test set rank th team
lifelong learning aim train neural network stream task retaining knowledge previous task however many prior attempt nlp still suffer catastrophic forgetting issue model completely forgets learned previous task paper introduce rational lamol novel endtoend framework language model order alleviate catastrophic forgetting rational lamol enhances lamol recent model applying critical freezing guided human rationale human rationale available propose exploiting unsupervised generated rationale substitution experiment tested rational lamol permutation three datasets eraser benchmark result show proposed framework outperformed vanilla lamol permutation furthermore unsupervised rationale generation able consistently improve overall performance baseline without relying humanannotated rationale
idiom kind idiomatic expression chinese consist four chinese character due property noncompositionality metaphorical meaning chinese idiom hard understood child nonnative speaker study proposes novel task denoted chinese idiom paraphrasing cip cip aim rephrase idiomcontaining sentence nonidiomatic one premise preserving original sentence meaning since sentence without idiom easily handled chinese nlp system cip used preprocess chinese datasets thereby facilitating improving performance chinese nlp task eg machine translation system chinese idiom cloze chinese idiom embeddings study treat cip task special paraphrase generation task circumvent difficulty acquiring annotation first establish largescale cip dataset based human machine collaboration consists sentence pair addition three sequencetosequence method baseline propose novel infillbased approach based text infilling result show proposed method better performance baseline based established cip dataset
sentence classification task context formed sentence adjacent sentence classified provide important information classification context however often ignored method make use context small amount considered making difficult scale present new method sentence classification contextlstmcnn make use potentially large context method also utilizes longrange dependency within sentence classified using lstm shortspan feature using stacked cnn experiment demonstrate approach consistently improves previous method two different datasets
paper present new verification style reading comprehension dataset named vgaokao chinese language test gaokao different existing effort new dataset originally designed native speaker evaluation thus requiring advanced language understanding skill address challenge vgaokao propose novel extractintegratecompete approach iteratively selects complementary evidence novel query updating mechanism adaptively distills supportive evidence followed pairwise competition push model learn subtle difference among similar text piece experiment show method outperform various baseline vgaokao retrieved complementary evidence merit efficiency explainability dataset code released research
paper present ongoing investigation complex syntactic annotation combined linguistic semantics possibly help supporting semiautomatic building shallow ontology text proposing automated extraction possibly underspecified semantic relation linguistically annotated text
natural language generation nlg important component question answeringqa system significant impact system quality tranditional qa system based template rule tend generate rigid stylised response without natural variation human language furthermore method need amount work generate template rule address problem propose contextaware lstm model nlg model completely driven data without manual designed template rule addition context information including question answered semantic value addressed response dialogue act type interaction well approached neural network model enables model produce variant informative response quantitative evaluation human evaluation show calstm obtains stateoftheart performance
emojis assume different relation sentence context occur affective elaboration emojiword redundancy frequently investigated laboratory experiment role emojis inferential process received much less attention used online rating task recognition memory task investigate whether difference emoji function within sentence affect judgment emojitext coherence subsequent recognition accuracy emojis function synonym target word passage rated better fitting passage coherent emojis consistent inference passage type emojis rated coherent incongruent unrelated emojis recognition test emojis consistent semantic content passage synonym inference emojis better recognized incongruent emojis finding present study provide corroborating evidence reader extract semantic information emojis integrate surrounding passage content
accurate processing noncompositional language relies generating good representation expression work study representation language noncompositionality proposing language model pier build bart create semantically meaningful contextually appropriate representation english potentially idiomatic expression pie pie characterized noncompositionality contextual ambiguity literal idiomatic interpretation via intrinsic evaluation embedding quality extrinsic evaluation pie processing nlu task show representation generated pier result higher homogeneity score embedding clustering bart whereas gain accuracy sequence accuracy pie sense classification span detection compared stateoftheart ie representation model giea gain achieved without sacrificing pier performance nlu task accuracy compared bart
paper discusses ml based classifier enhanced disproportionately adding small amount qualitative linguistic knowledge example present danish classifier smatgrisene contribution recent offenseval challenge classifier trained social medium post annotated offensiveness supplemented rule extracted reference work danish offensive language rathje b smatgrisene surprisingly well competition spite extremely simple design showing interesting tradeoff technological muscle linguistic intelligence finally comment perspective combining qualitative quantitative method nlp
consider unanswered question discourse processing community relation classifier trained explicit example connective removed perform poorly real implicit scenario prior work claimed due linguistic dissimilarity explicit implicit example provided empirical evidence study show one cause failure label shift connective eliminated specifically find discourse relation expressed explicit instance change connective disappear unlike previous work manually analyzing example present empirical evidence corpus level prove existence shift analyze label shift occurs considering factor syntactic role played connective ambiguity connective finally investigate two strategy mitigate label shift filtering noisy data joint learning connective experiment pdtb pdtb gum dataset demonstrate classifier trained strategy outperform strong baseline
sentiment analysis one widely studied application nlp work focus language large amount data introduce first largescale humanannotated twitter sentiment dataset four widely spoken language nigeriahausa igbo nigerianpidgin yorubaconsisting around annotated tweet per language including significant fraction codemixed tweet propose text collection filtering processing labeling method enable u create datasets lowresource language evaluate range pretrained model transfer strategy dataset find languagespecific model languageadaptive finetuning generally perform best release datasets trained model sentiment lexicon code incentivize research sentiment analysis underrepresented language
paper describe attempt learn bias news article experiment seems although correlation publisher bias article bias challenging learn bias directly publisher label hand using manuallylabeled sample increase accuracy metric around near system computationally inexpensive us several standard document representation nlp train svm lr classifier system ranked th semeval task code released reproducibility
increasing number user comment diverse domain including comment online journalism ecommerce website manual content analysis comment becomes timeconsuming challenging however research showed user comment contain useful information different domain expert thus worth finding utilizing paper introduces forum opensource framework semiautomatically analyze aggregate visualize user comment based label defined domain expert demonstrate applicability forum comment analytics scenario within domain online journalism app store outline underlying container architecture including webbased user interface machine learning component task manager timeconsuming task finally conduct machine learning experiment simulated annotation different sampling strategy existing datasets domain evaluate forum performance forum achieves promising classification result rocauc mboxgeq annotated sample utilizing transformerbased embeddings lightweight logistic regression model explain forum architecture applicable million user comment realtime yet feasible training classification cost
describe corpus multimodal dialogue mpplayer collected wizardofoz experiment annotated richfeature set several layer using nite xml toolkit nxt represent process data designed nxtdata model converted experiment log file data manualtranscriptions nxt building tool additionalannotation using nxt library annotated corpus used investigate various aspect multimodal presentation andinteraction strategy within across annotation layer ii design initial policy reinforcement learning multimodalclarification request
multicomponent compounding prevalent phenomenon sanskrit understanding implicit structure compound component crucial deciphering meaning earlier approach sanskrit focused binary compound neglected multicomponent compound setting work introduces novel task nested compound type identification necti aim identify nested span multicomponent compound decode implicit semantic relation best knowledge first attempt field lexical semantics propose task present newly annotated datasets including outofdomain dataset task also benchmark datasets exploring efficacy standard problem formulation nested named entity recognition constituency parsing seqseq etc present novel framework named depnecti dependencybased nested compound type identifier surpasses performance best baseline average absolute improvement point fscore term labeled span score lss fold enhancement inference efficiency line previous finding binary sanskrit compound identification task context provides benefit necti task codebase datasets publicly available httpsgithubcomyaswanthiitkgpdepnecti
position paper present research agenda idea facilitating exposure diverse viewpoint news recommendation recommending news diverse viewpoint important prevent potential filter bubble effect news consumption stimulate healthy democratic debate account complexity inherent human citizen democracy anticipate among others individuallevel difference acceptance diversity connect idea technique natural language processing distributional language model would allow u place different user news article multidimensional space based semantic content diversity operationalized distance variance way model individual latitude diversity different user thus personalize viewpoint diversity support healthy public debate addition identify technical ethical conceptual issue related presented idea investigation describes nlp play central role diversifying news recommendation
large pretrained transformerbased language model like bert gpt changed landscape natural language processing nlp however fine tuning model still requires large number training example target task thus annotating multiple datasets training model various downstream task becomes time consuming expensive work propose simple extension prototypical network fewshot text classification main idea replace class prototype gaussians introduce regularization term encourages example clustered near appropriate class centroid experimental result show method outperforms various strong baseline public internal datasets furthermore use class distribution tool detecting potential outofdistribution ood data point deployment
standard measure influence research paper number time cited however paper may cited many reason citation count informative extent paper affected content subsequent publication therefore propose novel method quantify linguistic influence timestamped document collection two main step first identify lexical semantic change using contextual embeddings word frequency second aggregate information change perdocument influence parameter estimating highdimensional hawkes process lowrank parameter matrix resulting measure linguistic influence predictive textitfuture citation specifically estimate linguistic influence two year paper publication correlated predictive citation count following three year demonstrated using online evaluation incremental temporal trainingtest split comparison strong baseline includes predictor initial citation count topic lexical feature
address challenge efficiently extracting structured emission information specifically emission goal company report leveraging potential large language model llm propose twostage pipeline first filter retrieves potentially relevant passage extract structured information using generative model contribute annotated dataset covering text passage extracted expert annotated fact dataset investigate accuracy efficiency limitation llmbased emission information extraction evaluate different retrieval technique assess efficiency gain human analyst using proposed pipeline research demonstrates promise llm technology addressing intricate task sustainable emission data extraction company report
condescending language use caustic bring dialogue end bifurcate community thus system condescension detection could large positive impact challenge condescension often impossible detect isolated utterance depends discourse social context address present talkdown new labeled dataset condescending linguistic act context show extending languageonly model representation discourse improves performance motivate technique dealing low rate condescension overall also use model estimate condescension rate various online community relate difference differing community norm
climate change existential threat humanity proliferation unsubstantiated claim relating climate science manipulating public perception motivating need factchecking climate science work draw recent work us retrievalaugmented generation veracity prediction explanation generation framing explanation generation queryfocused multidocument summarization task adapt primera climate science domain adding additional global attention claim automatic evaluation qualitative analysis demonstrate method effective generating explanation
semantic parsing aim map natural language utterance onto machine interpretable meaning representation aka program whose execution realworld environment produce denotation weaklysupervised semantic parser trained utterancedenotation pair treating program latent task challenging due large search space spuriousness program may execute correct answer generalize unseen example goal instill inductive bias parser help distinguish spurious correct program capitalize intuition correct program would likely respect certain structural constraint aligned question eg program fragment unlikely align overlapping text span propose model alignment structured latent variable order make latentalignment framework tractable decompose parsing task predicting partial abstract program refining modeling structured alignment differential dynamic programming obtain stateoftheart performance wikitablequestions wikisql datasets compared standard attention baseline observe proposed structuredalignment mechanism highly beneficial
paper describes system submission cogalex shared task corpusbased identification semantic relation system first place task second place task evaluation result system test set true fmeasure task detecting semantic similarity excluding random task identifying finergrained semantic relation experiment try word analogy linear regression multitask convolutional neural network cnns word embeddings publicly available word vector found linear regression performs better binary classification task cnns better performance multiclass semantic classification task assume word analogy suited deterministic answer rather handling ambiguity onetomany manytomany relationship also show classifier performance could benefit balancing distribution label training data
present information retrieval based reverse dictionary system using modern pretrained language model approximate nearest neighbor search algorithm proposed approach applied existing estonian language lexicon resource sonaveeb word web purpose enhancing enriching introducing crosslingual reverse dictionary functionality powered semantic search performance system evaluated using existing labeled english dataset word definition extended contain also estonian russian translation novel unlabeled evaluation approach extract evaluation data lexicon resource using synonymy relation evaluation result indicate information retrieval based semantic search approach without model training feasible producing median rank monolingual setting median rank crosslingual setting using unlabeled evaluation approach model trained crosslingual retrieval including estonian training data showing superior performance particular task
sexism harmful phenomenon provokes gender inequality social imbalance expanding application sexist content social medium platform creates unwelcoming discomforting environment many user implication sexism multifaceted subject integrated category discrimination binary classification tool frequently employed identify sexist content provide extensive generic category insight semeval introduced explainable detection online sexism edo task emphasizes detecting explaining category sexist content content paper detail involvement task present neural network architecture employing document embeddings finetuned transformerbased model stacked long shortterm memory lstm fully connected linear fcl layer proposed methodology obtained f score ranked st task achieved f score ranked th ranked th task b c respectively
paper introduce practical first step towards creation automated debate agent stateoftheart recurrent predictive model predicting debate winner accurate predictive model able objectively rate quality statement made specific turn debate model based recurrent neural network architecture attention allows model effectively account entire debate making prediction model achieves stateoftheart accuracy dataset debate transcript annotated audience favorability debate team finally discus future work leverage proposed model creation automated debate agent accomplish determining model input maximize audience favorability toward given side debate arbitrary turn
recently principal reward component dialogue policy reinforcement learning use task success user satisfaction independently neither resulting learned behaviour analysed suitable proper analysis method even existed work employ principal reward component jointly propose method analyse resulting behaviour structured way probing learned policy show blending reward component increase user satisfaction without sacrificing task success hostile environment provide insight action chosen learned policy
distant supervision assumes sentence containing entity pair reflects identical relationship previous work distantly supervised relation extraction dsre task generally focus sentencelevel baglevel denoising technique independently neglecting explicit interaction cross level paper propose hierarchical contrastive learning framework distantly supervised relation extraction hiclre reduce noisy sentence integrate global structural information local finegrained interaction specifically propose threelevel hierarchical learning framework interact cross level generating denoising contextaware representation via adapting existing multihead selfattention named multigranularity recontextualization meanwhile pseudo positive sample also provided specific level contrastive learning via dynamic gradientbased data augmentation strategy named dynamic gradient adversarial perturbation experiment demonstrate hiclre significantly outperforms strong baseline various mainstream dsre datasets
paper present model used team rivercorners repeval shared task first model separately encodes pair sentence variablelength representation using bidirectional lstm later creates fixedlength raw representation mean simple aggregation function refined using attention mechanism finally combine refined representation sentence single vector used classification model obtained test accuracy matched mismatched evaluation track respectively outperforming lstm baseline obtaining performance similar model relies shared information sentence esim using ensemble accuracy increased respectively
present large scale collection diverse natural language inference nli datasets help provide insight well sentence representation encoded neural network capture distinct type reasoning collection result recasting existing datasets semantic phenomenon common nli structure resulting half million labeled contexthypothesis pair total collection diverse datasets available urlhttpwwwdecompnet grow time additional resource recast added novel source
show countbased script induction model chamber jurafsky jan et al unified general framework narrative chain likelihood maximization provide efficient algorithm based association rule mining arm weighted set cover discover interesting pattern training data combine reliable explainable way predict missing event proposed method unlike prior work assume full conditional independence make use higherorder count statistic perform ablation study conclude inductive bias introduced arm conducive better performance narrative cloze test
existing domain taxonomy normalizing content often assumed discussing approach information extraction yet often realworld scenario none one exist information need shift must continually extended slow tedious task one scale well propose interactive tool allows taxonomy built extended textitrapidly textithuman loop control precision apply insight text summarization information extraction reduce search space dramatically leverage modern pretrained language model perform contextualized clustering remaining concept yield candidate node user review show allows user consider many taxonomy concept candidate hour quickly build extend taxonomy better fit information need
paper present new tweetbased approach geolinguistic analysis combine geolocation user id textual feature order identify pattern linguistic variation subcity scale subcity variation connected social driver thus open new opportunity understanding mechanism language variation change however measuring linguistic variation scale challenging due lack highlyspatiallyresolved data well daily movement user mobility inside city obscure relation social context linguistic variation demonstrate combining geolocation user id textual analysis tweet yield information linguistic profile user social context associated specific location connection linguistic variation apply methodology analyze dialect buenos aire find evidence sociallydriven variation method contribute identification sociolinguistic pattern inside city valuable social science social service
ability limit future spread covid part depend understanding psychological sociological process lead people follow reject coronavirus health behavior argue virus taken heterogeneous meaning community across united state disparate meaning shaped community response virus early vital stage outbreak u using word embeddings demonstrate county resident socially distanced less average measured residential mobility semantically associated virus covid discourse concept fraud political left benign illness like flu also show different meaning virus took different community explains substantial fraction call trump gap empirical tendency trumpsupporting county socially distance less work demonstrates communitylevel process meaningmaking part determined behavioral response covid pandemic process measured unobtrusively using twitter
present parent parent retrieval neural tool deeplearningbased multilingual tool performing retrieval word formation classification english german dutch spanish french russian czech parent retrieval refers determining lexeme lexeme input lexeme based eg darkness traced back dark waterfall decomposes water fall additionally parent performs word formation classification determines input lexeme compound eg proofread derivative eg deescalate unmotivated word eg dog seven language selected three major branch indoeuropean language family germanic romance slavic data aggregated range wordformation resource well wiktionary train test tool tool based customarchitecture hybrid transformer blockenriched sequencetosequence neural network utilizing characterbased semantic representation input lexeme two output module one decoderbased dedicated parent retrieval one classifierbased word formation classification parent achieves mean accuracy parent retrieval mean balanced accuracy word formation classification
visual question generation vqg task generating question based image content increasingly important area combine natural language processing computer vision although recent work attempted generate question image open domain task vqg medical domain explored far paper introduce approach generation visual question radiology image called vqgr ie algorithm able ask question shown image vqgr first generates new training data existing example based contextual word embeddings image augmentation technique us variational autoencoders model encode image latent space decode natural language question experimental automatic evaluation performed vqarad dataset clinical visual question show vqgr achieves good performance compared baseline system source code available urlhttpsgithubcomsarroutivqgr
entity bias widely affect pretrained large language model causing rely biased parametric knowledge make unfaithful prediction although causalityinspired method shown great potential mitigate entity bias hard precisely estimate parameter underlying causal model practice rise blackbox llm also make situation even worse inaccessible parameter uncalibrated logits address problem propose specific structured causal model scm whose parameter comparatively easier estimate building upon scm propose causal intervention technique mitigate entity bias whitebox blackbox setting proposed causal intervention perturbs original entity neighboring entity intervention reduces specific biasing information pertaining original entity still preserving sufficient semantic information similar entity whitebox setting trainingtime intervention improves ood performance plms relation extraction machine reading comprehension mrc point point respectively blackbox setting incontext intervention effectively reduces entitybased knowledge conflict gpt achieving point improvement exact match accuracy mrc point reduction memorization ratio
paper describes fujitsu dmath system used wmt news translation biomedical translation task focused lowresource pair using simple system conducted experiment englishhausa xhosazulu englishbasque submitted result xhosazulu news translation task englishbasque biomedical translation task abstract terminology translation subtasks system combine bpe dropout subsubword feature backtranslation transformer base model achieving good result evaluation set
genderinclusive nlp research documented harmful limitation gender binarycentric large language model llm inability correctly use genderdiverse english neopronouns eg xe zir fae data scarcity known culprit precise mechanism scarcity affect behavior remain underexplored discover llm misgendering significantly influenced bytepair encoding bpe tokenization tokenizer powering many popular llm unlike binary pronoun bpe overfragments neopronouns direct consequence data scarcity tokenizer training disparate tokenization mirror tokenizer limitation observed multilingual lowresource nlp unlocking new misgendering mitigation strategy propose two technique pronoun tokenization parity method enforce consistent tokenization across gendered pronoun utilizing preexisting llm pronoun knowledge improve neopronoun proficiency proposed method outperform finetuning standard bpe improving neopronoun accuracy paper first link llm misgendering tokenization deficient neopronoun grammar indicating llm unable correctly treat neopronouns pronoun prone misgender
paper present definition conceptual approach information space entailed multidisciplinary collaborative project cimbrian test case synchronic diachronic language variation provides linguist test bed formal hypothesis concerning human language aim project collect digitize tag linguistic data german variety cimbrian spoken three area northern italy giazza vr luserna tn roana vi make available online valuable innovative linguistic resource indepth study cimbrian task addressed multidisciplinary team linguist computer scientist combining competence aim make available new tool linguistic analysis
despite improvement translation quality neural machine translation nmt often suffers lack diversity generation paper propose generate diverse translation deriving large number possible model bayesian modelling sampling model inference possible model obtained applying concrete dropout nmt model specific confidence prediction corresponds posterior model distribution specific training data principle bayesian modeling variational inference posterior model distribution approximated variational distribution final model inference sampled conducted experiment chineseenglish englishgerman translation task result show method make better tradeoff diversity accuracy
task hate speech detection exists high correlation african american english aae annotator perception toxicity current datasets bias annotated training data tendency machine learning model amplify cause aae text often mislabeled abusiveoffensivehate speech high false positive rate current hate speech classifier use adversarial training mitigate bias experimental result one hate speech dataset one aae dataset suggest method able reduce false positive rate aae text minimal compromise performance hate speech classification
today natural language processing system growing complex need incorporate wider range language resource sophisticated statistical method many case necessary learn component input includes prediction learned component assign simultaneously value would assigned multiple component expressive data dependent structure among result design system multiple learning component inevitably quite technically complex implementation conceptually simple nlp system time consuming prone error new modeling language learning based java lbj facilitates rapid development system learn perform inference lbj already used build state art nlp system paper first demonstrate exists theoretical model describes nlp approach adeptly second show improvement lbj language enable programmer describe theoretical model succinctly finally introduce concept data driven compilation translation process efficiency generated code benefit data given input learning algorithm
propose novel attentionbased selfsupervised approach identify claimworthy sentence fake news article important first step automated factchecking leverage textitaboutness headline content using attention mechanism task identified claim used downstream task claim verification releasing benchmark dataset manually selected compelling article veracity label associated evidence work go beyond stylistic analysis identifying content influence reader belief experiment three datasets show strength model
paper present integration wordnet knowledge resource clinidmap tool aim map identifier clinical ontology lexical resource clinidmap interlinks identifier umls smomedct icd corresponding wikidata wikipedia article concept umls metathesaurus main goal tool provide semantic interoperability across clinical concept various knowledge base side effect mapping enriches already annotated medical corpus multiple language new label new release add wordnet synset using available mapping wikidata thanks crosslingual link mcr also include corresponding synset language also extend clinidmap different domain information finally final resource help task enriching already annotated clinical corpus additional semantic annotation
existing image captioning system dedicated generating narrative caption image spatially detached theimage presentation however text also used decoration image highlight key point increase theattractiveness image work introduce new taskcalled captioning image caponimage aim generatedense caption different location image based contextual information fully exploit surrounding visual context togenerate suitable caption location propose amultimodal pretraining model multilevel pretraining tasksthat progressively learn correspondence text image location easy difficult since model may generateredundant caption nearby location enhance thelocation embedding neighbor location context thisnew task also introduce largescale benchmark called caponimagem contains million product image anaverage spatially localized caption compared image captioning model variant model achieves best resultsin captioning accuracy diversity aspect
explore potential sembanking korean way represent meaning korean sentence paper report process applying abstract meaning representation korean semantic representation framework studied wide range language output korean amr corpus corpus constructed far size sentence raw text exobrain corpus stateled rd project language ai paper also analyzes result qualitative quantitative manner proposing discussion development
logographic language like chinese word meaning constructed using specific character formation help disambiguate word sens beneficial sentiment classification however knowledge rarely explored previous sentiment analysis method paper focus exploring logographic information aspectbased sentiment classification chinese text specifically employ logographic image capture internal morphological structure character sequence logographic image also used learn external relation among context aspect word furthermore propose multimodal language model explicitly incorporate logographic image review text aspectbased sentiment classification chinese experimental result show method brings substantial performance improvement strong baseline result also indicate logographic image important exploring internal structure external relation character sequence
despite advance large pretrained neural language model prone generating toxic language brings security risk application introduce mildecoding detoxifies language model tokenlevel interpolating trained multiple instance learning mil networkmil model trained corpus toxicity label text predict overall toxicity toxicity token context intuitively mil network computes toxicity distribution next token according generated context supplement original language model avoid toxicity evaluate mildecoding automatic metric human evaluation mildecoding outperforms baseline detoxification hurt generation fluency little bit
purpose paper extract market signal major currency eur usd gbp jpy cny analyzing federal reserve system fed minute speech consequently making suggestion going longshort remaining neutral investor thanks causal relationship fed sentiment currency exchange rate purpose aim verify hypothesis currency market dynamic follow trend subject sentiment fed minute speech related specific relevant currency proposed paper highlighted two main finding sentiment expressed fed minute strong influence financial market predictability major currency trend sentiment time grangercauses exchange rate currency immediately also increasing lag according monotonically decreasing impact
tweet product review text ubiquitous web often contains valuable information enterprise consumer however online text generally noisy incomplete requiring user process analyze data extract insight system effective different stage text analysis user lack extensible platform support interactive text analysis workflow endtoend facilitate integrated text analytics introduce leam aim combining strength spreadsheet computational notebook interactive visualization leam support interactive analysis via guibased interaction provides declarative specification language implemented based visual text algebra enable userguided analysis evaluate leam two case study using two popular kaggle text analytics workflow understand strength weakness system
traditional visual question generation vqg image multiple concept eg object category question could generated model trained mimic arbitrary choice concept given training data make training difficult also pose issue evaluation multiple valid question exist image one captured human reference present guiding visual question generation variant vqg condition question generator categorical information based expectation type question object explore propose two variant family explicitly guided model enables actor human automated select object category generate question ii type implicitly guided model learn object category condition based discrete variable proposed model evaluated answercategory augmented vqa dataset quantitative result show substantial improvement current state art bleu increase human evaluation validates guidance help generation question grammatically coherent relevant given image object
propose prefixadaptive decoding preadd flexible method controlled text generation unlike existing method use auxiliary expert model control attribute preadd require external model instead relying linearly combining output logits multiple prompt specifically preadd contrast output logits generated using raw prompt generated using prefixprepended prompt enabling positive negative control respect attribute encapsulated prefix evaluate preadd three taskstoxic output mitigation gender bias reduction sentiment controland find preadd outperforms prompting baseline also auxiliaryexpert control method relative gain main metric task
present scikittalk opensource toolkit processing collection realworld conversational speech python first kind toolkit equips interested studying modeling conversation easytouse interface build explore large collection transcription annotation talkininteraction designed application speech processing conversational ai scikittalk provides tool custombuild datasets task intent prototyping dialog flow testing conversation design textitpreprocessor module come several prebuilt interface common transcription format aim make working across multiple data source accessible textitexplorer module provides collection tool explore analyse data type via string matching unsupervised machine learning technique scikittalk serf platform collect connect different transcription format representation talk enabling user quickly build multilingual datasets varying detail granularity thus toolkit aim make working authentic conversational speech data python accessible provide user comprehensive option work representation talk appropriate detail downstream task latest update information currently supported language language resource please refer urlhttpspypiorgprojectscikittalk
paper present model architecture training pipeline attribute value extraction search query model us weak label generated customer interaction train transformerbased ner model twostage normalization process applied deal problem large label space first model output normalized onto common generic attribute value mapped onto larger range actual product attribute value approach let u successfully apply transformerbased ner model extraction broad range attribute value realtime production environment ecommerce application contrary previous research online test demonstrate business value integrating model system semantic product retrieval ranking
paper presented wsd system us lda topic semantic expansion document word system also us sense frequency information semcor give higher priority sens probable happen
spatial commonsense knowledge spatial position relationship object like relative size lion girl position boy relative bicycle cycling important part commonsense knowledge although pretrained language model plms succeed many nlp task shown ineffective spatial commonsense reasoning starting observation image likely exhibit spatial commonsense text explore whether model visual signal learn spatial commonsense textbased plms propose spatial commonsense benchmark focus relative scale object positional relationship people object different action probe plms model visual signal including visionlanguage pretrained model image synthesis model benchmark find image synthesis model capable learning accurate consistent spatial knowledge model spatial knowledge image synthesis model also help natural language understanding task require spatial commonsense
paper present imperial college london submission wmt quality estimation qe shared task critical error detection approach build crosslingual pretrained representation sequence classification model improve base classifier adding weighted sampler deal unbalanced data ii introducing feature engineering feature related toxicity namedentities sentiment potentially indicative critical error extracted using existing tool integrated model different way train model one type feature time ensemble model improve base classifier development dev set official submission achieve competitive result ranking second three four language pair
recent work crosslingual semantic parsing successfully applied machine translation localize parser new language however advance assume access highquality machine translation system word alignment tool remove assumption study crosslingual semantic parsing zeroshot problem without parallel data ie utterancelogical form pair new language propose multitask encoderdecoder model transfer parsing knowledge additional language using englishlogical form paired data indomain natural language corpus new language model encourages languageagnostic encoding jointly optimizing logicalform generation auxiliary objective designed crosslingual latent representation alignment parser performs significantly translationbased baseline case competes supervised upperbound
uncertainty estimation ue model prediction crucial step variety task active learning misclassification detection adversarial attack detection outofdistribution detection etc work modeling uncertainty deep neural network evaluate method image classification task little attention paid ue natural language processing fill gap perform vast empirical investigation stateoftheart ue method transformer model misclassification detection named entity recognition text classification task propose two computationally efficient modification one approach even outperforms computationally intensive method
rise hate speech phenomenon twittersphere significant research effort undertaken provide automatic solution detecting hate speech varying simple machine learning model complex deep neural network model despite research work investigating hate speech problem arabic still limited paper therefore aim investigate several neural network model based convolutional neural network cnn recurrent neural network rnn detect hate speech arabic tweet also evaluates recent language representation model bert task arabic hate speech detection conduct experiment firstly built new hate speech dataset contains annotated tweet conducted set experiment two datasets evaluate four model cnn gru cnngru bert experimental result dataset outdomain dataset show cnn model give best performance fscore auroc
numerous year researcher employed social medium data gain insight user mental health nevertheless majority investigation concentrate categorizing user experiencing depression considered healthy detection suicidal thought paper aim extract evidence preassigned gold label used suicidality dataset containing reddit post labeled suicide risk level task use large language model llm extract evidence post justifies given label used meta llama b lexicon solving task achieved precision
providing feedback argumentation learner essential developing critical thinking skill however requires lot time effort mitigate overload teacher aim automate process providing feedback especially giving diagnostic comment point weakness inherent argumentation recommended give specific diagnostic comment learner recognize diagnosis without misinterpretation however obvious task providing specific diagnostic comment formulated present formulation task template selection slot filling make automatic evaluation easier behavior model tractable key formulation possibility creating template set sufficient practical use paper define three criterion template set satisfy expressiveness informativeness uniqueness verify feasibility creating template set satisfies criterion first trial show feasible annotation study convert diagnostic comment given text template format corpus used annotation study publicly available
promptbased learning aka prompting achieves high performance bridging gap objective language modeling downstream task domain generalization ability improved prompting since classification across different domain unified prediction set label word remaining challenge domain generalization prompting come discrepancy data distribution different domain improve domain generalization prompting learn distributional invariance across source domain via two alignment regularization loss function first vocabulary distribution alignment us kullbackleibler divergence regularization sourcedomain vocabulary distribution second feature distribution alignment us novel adversarial training strategy learn domain invariant representation across source domain experiment sentiment analysis natural language inference show effectiveness method achieve stateoftheart result six datasets
work present empirical study generation order machine translation building recent advance insertionbased modeling first introduce soft orderreward framework enables u train model follow arbitrary oracle generation policy make use framework explore large variety generation order including uninformed order locationbased order frequencybased order contentbased order modelbased order curiously find wmt english german wmt english chinese translation task order substantial impact output quality moreover english german even discover unintuitive ordering alphabetical shortestfirst match performance standard transformer suggesting traditional lefttoright generation may necessary achieve high performance
multilingual sentence encoders seen much success crosslingual model transfer downstream nlp task success transfer however dependent model ability encode pattern crosslingual similarity variation yet know relatively little property individual language general pattern linguistic variation model encode article investigate question leveraging knowledge field linguistic typology study document structural semantic variation across language propose method separating languagespecific subspace within stateoftheart multilingual sentence encoders laser mbert xlm xlmr respect range typological property pertaining lexical morphological syntactic structure moreover investigate typological information language distributed across layer model result show interesting difference encoding linguistic variation associated different pretraining strategy addition propose simple method study shared typological property language encoded two stateoftheart multilingual modelsmbert xlmr result provide insight informationsharing mechanism suggest linguistic property encoded jointly across typologically similar language model
english speaking assessment pretrained large language model llm bert score constructed response item accurately human raters less research investigated whether llm perpetuate exacerbate bias would pose problem fairness validity test study examines gender native language l bias human automated score using offtheshelf oos bert model analysis focus specific type bias known differential item functioning dif compare examinee similar english language proficiency result show moderate amount dif based examinee l background grade band dif higher scored oos bert model indicating bert may exacerbate bias however practical term degree bert exacerbates dif small additionally dif longer speaking item older examinee bert exacerbate pattern dif
dialogue act da classification task classifying utterance respect function serve dialogue existing approach da classification model utterance without incorporating turn change among speaker throughout dialogue therefore treating different noninteractive written text paper propose integrate turn change conversation among speaker modeling da specifically learn conversationinvariant speaker turn embeddings represent speaker turn conversation learned speaker turn embeddings merged utterance embeddings downstream task da classification simple yet effective mechanism model able capture semantics dialogue content accounting different speaker turn conversation validation three benchmark public datasets demonstrates superior performance model
recently graphbased method adopted abstractive text summarization however existing graphbased method consider either word relation structure information neglect correlation simultaneously capture word relation structure information sentence propose novel dual graph network abstractive sentence summarization specifically first construct semantic scenario graph semantic word relation graph based framenet subsequently learn representation design graph fusion method enhance correlation obtain better semantic representation summary generation experimental result show model outperforms existing stateoftheart method two popular benchmark datasets ie gigaword duc
aspect sentiment triplet extraction aste aim extract aspect term along corresponding opinion term expressed sentiment review important task sentiment analysis previous research effort generally address aste task endtoend fashion tablefilling formalization triplet represented twodimensional table wordpair relation formalization termlevel relation decomposed multiple independent wordlevel relation lead relation inconsistency boundary insensitivity face multiword aspect term opinion term overcome issue propose boundarydriven tablefilling bdtf represents triplet relation region table transforms aste task detection classification relation region also notice quality table representation greatly affect performance bdtf therefore develop effective relation representation learning approach learn table representation fully exploit wordtoword interaction relationtorelation interaction experiment several public benchmark show proposed approach achieves stateoftheart performance
today see ever growing number tool supporting text annotation tool optimized specific usecases named entity recognition however see large growing knowledge base wikipedia google knowledge graph paper introduce nlatool web application developed using humancentered design process application combine supporting text annotation enriching text additional information number source directly within application tool assist user efficiently recognize named entity annotate text automatically provide user additional information solving deep text understanding task
new python api integrated within nltk suite offer access framenet lexical database lexicon structured term frame well annotated sentence processed programatically browsed humanreadable display via interactive python prompt
paper outline approach task b english language track semeval task offenseval multilingual offensive language identification social medium use linear svm document vector computed pretrained word embeddings explore effectiveness lexical part speech dependency named entity ne feature manually annotate subset training data use error analysis tune threshold mapping training confidence value label document vector consistently informative feature task testing development set suggests dependency feature effective addition task ne feature task b
multilingual pretrained language model mplms acquire valuable generalizable linguistic information pretraining advanced state art taskspecific finetuning date textasciitilde textasciitilde african language covered existing language model ameliorate limitation developing serengeti set massively multilingual language model cover african language language variety evaluate novel model eight natural language understanding task across datasets comparing mplms cover african language serengeti outperforms model datasets across eight task achieving average f also perform analysis error model allows u investigate influence language genealogy linguistic similarity model applied zeroshot setting publicly release model research anonymous link
research paper propose multimodal approach hate speech detection directed towards identification hate speech related target method us logistic regression support vector machine svms analyse textual content extracted social medium platform exploit natural language processing technique preprocess extract relevant feature textual content capturing linguistic pattern sentiment contextual information
decade research field computational linguistics witnessed growth corpus model natural language inference nli richresource language english chinese largescale highquality corpus necessary study nli vietnamese considered lowresource language paper introduce vinli vietnamese natural language inference opendomain highquality corpus evaluating vietnamese nli model created evaluated strict process quality control vinli comprises humanannotated premisehypothesis sentence pair extracted online news article distinct topic paper introduce guideline corpus creation take specific characteristic vietnamese language expressing entailment contradiction account evaluate challenging level corpus conduct experiment stateoftheart deep neural network pretrained model dataset best system performance still far human performance gap accuracy vinli corpus challenging corpus accelerate progress vietnamese computational linguistics corpus available publicly research purpose
emotion cause analysis eca aim extract emotion clause find corresponding cause emotion existing method adopt finetuning paradigm solve certain type eca task taskspecific method deficiency universality relation among multiple objective one task explicitly modeled moreover relative position information introduced existing method may make model suffer dataset bias address first two problem paper proposes universal prompt tuning method solve different eca task unified framework third problem paper design directional constraint module sequential learning module ease bias considering commonality among different task paper proposes crosstask training method explore capability model experimental result show method achieves competitive performance eca datasets
present new transition system word reordering unrestricted nonprojective dependency parsing system based decomposed arceager rather arcstandard allows flexible ambiguity resolution local projective nonlocal crossing attachment experiment universal dependency find parser outperforms ordinary swapbased parser particularly language large amount nonprojectivity
reasoning natural language challenging problem nlp work focus proof generation given hypothesis set supporting fact model generates proof tree indicating derive hypothesis supporting fact compared generating entire proof one shot stepwise generation better exploit compositionality generalize longer proof achieved limited success realworld data existing stepwise method struggle generate proof step logically valid relevant hypothesis instead tend hallucinate invalid step given hypothesis paper present novel stepwise method nlproofs natural language proof search learns generate relevant step conditioning hypothesis core approach train independent verifier check validity proof step prevent hallucination instead generating step greedily search proof maximizing global proof score judged verifier nlproofs achieves stateoftheart performance entailmentbank ruletaker specifically improves correctness predicted proof distractor setting entailmentbank demonstrating effectiveness nlproofs generating challenging humanauthored proof
rapid development deep learning seqseq paradigm become prevalent endtoend datatotext generation bleu score increasing recent year however widely recognized still gap quality text generated model text written human order better understand ability seqseq model evaluate performance analyze result choose use multidimensional quality metricmqm evaluate several representative seqseq model endtoend datatotext generation annotate output five model four datasets eight error type find copy mechanism helpful improvement omission inaccuracy extrinsic error increase type error addition pretraining technique highly effective pretraining strategy model size significant structure dataset also influence model performance greatly specific type error generally challenging seqseq model
clickbait spoiling task generating retrieving fairly short text purpose satisfy curiosity content consumer without addressing document linked clickbait post headline paper introduce ensemble approach clickbait spoiling task semeval task consists spoiler classification retrieval webisclickbait dataset show ensemble solution quite successful classification whereas might perform poorly retrieval additional feature conclusion outline thought possible direction improving approach shape set suggestion said feature
short text tweet invoice present challenge classification although term occurrence strong indicator content short text sparsity text make difficult capture important semantic relationship solution call method considers term occurrence also handle sparseness well work introduce approach term based semantic cluster tbsec employ term create distinctive semantic concept cluster cluster ranked using semantic similarity function turn defines semantic feature space used text classification method evaluated invoice classification task compared wellknown content representation method proposed method performs competitively
paper introduces pretrained word embedding manipuri lowresourced indian language pretrained word embedding based fasttext capable handling highly agglutinating language manipuri mni perform machine translation mt experiment using neural network nn model paper confirm following observation firstly reported bleu score transformer architecture fasttext word embedding model emft performs better without nmt experiment secondly observe adding training data different domain test data negatively impact translation accuracy resource reported paper made available elra catalogue help lowresourced language community mtnlp task
people around globe respond major real world event social medium study targeted public sentiment across many language geographic location introduce multilingual connotation frame extension english connotation frame rashkin et al additional european language focusing implied sentiment among event participant engaged frame case study present large scale analysis targeted public sentiment toward salient event entity using million multilingual connotation frame extracted twitter
traditional continual event detection relies abundant labeled data training often impractical obtain realworld application paper introduce continual fewshot event detection cfed commonly encountered scenario substantial number labeled sample accessible cfed task challenging involves memorizing previous event type learning new event type fewshot sample mitigate challenge propose memorybased framework hierarchical augmentation network hanet memorize previous event type limited memory incorporate prototypical augmentation memory set issue learning new event type fewshot scenario propose contrastive augmentation module token representation despite comparing previous stateoftheart method also conduct comparison chatgpt experiment result demonstrate method significantly outperforms method multiple continual fewshot event detection task
introduce method classification text finegrained category sociopolitical event particular method responsive three subtasks task finegrained classification sociopolitical event introduced case workshop aclijcnlp frame task textual entailment given input text candidate event class query model predicts whether text describes event given type model able correctly classify insample event type average fscore struggle outofsample event type despite model show promise zeroshot identification certain sociopolitical event achieving fscore one wholly outofsample event class
last decade rapidly growing body study shown promising result automatic detection extraction speech language feature biomarkers neurodegenerative condition alzheimers disease sparked great optimism development various digital health tool also warning regarding predominance english field call linguistically diverse research well global equitable access novel clinical instrument automatically extract clinically relevant feature transcript lowresource language two approach possible utilizing limited range languagespecific tool translating text english extracting feature evaluate approach partofspeech po rate transcript recorded picture description crosssectional study icelandic speaker different stage alzheimers disease healthy control translation method merit exploration subset po category show promising correspondence direct extraction icelandic transcript result indicating translation method linguistically validated individual po category level
public debate forum provide common platform exchanging opinion topic interest recent study natural language processing nlp provided empirical evidence language debater pattern interaction play key role changing mind reader research psychology shown prior belief affect interpretation argument could therefore constitute competing alternative explanation resistance changing one stance study actual effect language use v prior belief persuasion provide new dataset propose controlled setting take consideration two readerlevel factor political religious ideology find prior belief affected readerlevel factor play important role language use effect argue important account nlp study persuasion
little known trustworthiness prediction made knowledge graph embedding kge model paper take initial step toward direction investigating calibration kge model extent output confidence score reflect expected correctness predicted knowledge graph triple first conduct evaluation standard closedworld assumption cwa predicted triple already knowledge graph considered false show existing calibration technique effective kge common narrow assumption next introduce realistic challenging openworld assumption owa unobserved prediction considered true false groundtruth label obtained show existing calibration technique much less effective owa cwa provide explanation discrepancy finally motivate utility calibration kge practitioner perspective conduct unique case study humanai collaboration showing calibrated prediction improve human performance knowledge graph completion task
weaklysupervised text classification train classifier using label name target class supervision largely reduces human annotation effort existing method first use label name static keywordbased feature generate pseudo label used final classifier training reasonable commonly adopted framework suffers two limitation keywords different meaning different context text may keyword keyword matching induce noisy inadequate pseudo label error made pseudo label generation stage directly propagate classifier training stage without chance corrected paper propose new method pieclass consisting two module pseudo label acquisition module us zeroshot prompting pretrained language model plm get pseudo label based contextualized text understanding beyond static keyword matching noiserobust iterative ensemble training module iteratively train classifier update pseudo label utilizing two plm finetuning method regularize extensive experiment show pieclass achieves overall better performance existing strong baseline seven benchmark datasets even achieves similar performance fullysupervised classifier sentiment classification task
recent year seen colossal effort pretraining multilingual text encoders using largescale corpus many language facilitate crosslingual transfer learning however due typological difference across language crosslingual transfer challenging nevertheless language syntax eg syntactic dependency bridge typological gap previous work shown pretrained multilingual encoders mbert citation capture language syntax helping crosslingual transfer work show explicitly providing language syntax training mbert using auxiliary objective encode universal dependency tree structure help crosslingual transfer perform rigorous experiment four nlp task including text classification question answering named entity recognition taskoriented semantic parsing experiment result show syntaxaugmented mbert improves crosslingual transfer popular benchmark pawsx mlqa point average across language textitgeneralized transfer setting performance boosted significantly point average pawsx mlqa
neural network based model achieved impressive result sentence classification task however previous work focus designing sophisticated network effective learning paradigm monolingual data often suffers insufficient discriminative knowledge classification paper investigate improve sentence classification multilingual data augmentation consensus learning comparing previous method model make use multilingual data generated machine translation mine languageshare languagespecific knowledge better representation classification evaluate model using english ie source language chinese ie target language data several sentence classification task positive classification performance achieved proposed model
deep learning approach exhibit promising performance various text task however still struggling medical text classification since sample often extremely imbalanced scarce different existing mainstream approach focus supplementary semantics external medical information paper aim rethink data challenge medical text present novel frameworkagnostic algorithm called texttree utilizes internal label hierarchy training deep learning model embed icd code tree structure label cascade attention module learning hierarchyaware label representation two new learning scheme similarity surrogate learning ssl dissimilarity mixup learning dml devised boost text classification reusing distinguishing sample label following label representation hierarchy respectively experiment authoritative public datasets realworld medical record show approach stably achieves superior performance classical advanced imbalanced classification method code available httpsgithubcomjyansirtexttree
research focus text processing sphere englishlanguage social medium introduce two database resource first cecs casual english conversion system database lexicontype resource entry constructed use experimental system automated normalization casual irregularlyformed english used communication twitter rulebased approach primarily aim avoid problem caused user creativity individuality language twitterstyle text used input machine translation aid comprehension nonnative speaker english although database still development far carried two evaluation experiment using system shown positive result second database cegs casual english generation system phoneme database contains set alternative spelling phoneme cmu pronouncing dictionary designed use system generating phonemebased casual english text regular english input word automatically producing humanlike creative sentence ai task paper provides overview necessity method application evaluation resource
recent year use social medium increased incredibly social medium permit internet user friendly platform express view opinion along nice distinct communication chance also allows bad thing like usage hate speech online automatic hate speech detection various aspect significant scientific problem paper present instituto politecnico nacional mexico approach semeval task hateval basile et al competition multilingual detection hate speech twitter goal paper detect hate speech immigrant woman b aggressive behavior target classification english spanish proposed approach used bag word model preprocessing stemming stop word removal submitted two different system name cic ii cic hateval shared task used tf value first system tfidf second system first system cic got nd rank subtask b english spanish language emr score english spanish second system cic ranked th subtask st subtask b spanish language macrof score emr score respectively
paper address task amrtotext generation leveraging synchronous node replacement grammar training graphtostring rule learned using heuristic extraction algorithm test time graph transducer applied collapse input amrs generate output sentence evaluated standard benchmark method give stateoftheart result
current topperforming coreference resolution approach limited regard maximum length text accept explore recursive merging technique entity allows u apply coreference model text arbitrary length found many narrative genre experiment established datasets quantify drop resolution quality caused approach finally use underexplored resource form fully coreferenceannotated novel illustrate model performance long document practice achieve stateoftheart performance outperforming previous system capable handling long document
analyze two novel data set german educational medium text targeting adult child analysis based automatically extracted measure linguistic complexity wide range linguistic domain show data set exhibit broad linguistic adaptation target audience generalizes across data set successful binary classification model german readability robustly show high accuracy data set knowledge comprehensive german readability model first robust crosscorpus performance shown research also contributes resource german readability assessment externally validated successful different target audience compiled new corpus german news broadcast subtitle tagesschaulogo corpus crawled geogeolino corpus substantially enlarging data compiled hancke et al
paper study abstractive summarization opendomain video unlike traditional text news summarization goal less compress text information rather provide fluent textual summary information collected fused different source modality case video audio transcript text show multisource sequencetosequence model hierarchical attention integrate information different modality coherent output compare various model trained different modality present pilot experiment textithow corpus instructional video also propose new evaluation metric content f abstractive summarization task measure semantic adequacy rather fluency summary covered metric like rouge bleu
revisit domain adaptation parser neural era first show recent advance word representation greatly diminish need domain adaptation target domain syntactically similar source domain evidence train parser wall street journal alone achieves f brown corpus syntactically distant domain provide simple way adapt parser using dozen partial annotation instance increase percentage errorfree geometrydomain parses heldout set using approximately five dozen training example process demonstrate new stateoftheart single model result wall street journal test set absolute increase previous stateoftheart
resource nonenglish language scarce paper address problem context machine translation automatically extracting parallel sentence pair multilingual article available internet paper used endtoend siamese bidirectional recurrent neural network generate parallel sentence comparable multilingual article wikipedia subsequently showed using harvested dataset improved bleu score nmt phrasebased smt system lowresource language pair englishhindi englishtamil compared training exclusively limited bilingual corpus collected language pair
solving math word problem requires deductive reasoning quantity text various recent research effort mostly relied sequencetosequence sequencetotree model generate mathematical expression without explicitly performing relational reasoning quantity given context empirically effective approach typically provide explanation generated expression work view task complex relation extraction problem proposing novel approach present explainable deductive reasoning step iteratively construct target expression step involves primitive operation two quantity defining relation extensive experiment four benchmark datasets show proposed model significantly outperforms existing strong baseline demonstrate deductive procedure present explainable step also enables u make accurate prediction question require complex reasoning
matching retrieving previously translated segment translation memory key functionality translation memory system however matching retrieving process still limited algorithm based edit distance identified major drawback translation memory system paper introduce sentence encoders improve matching retrieving process translation memory system effective efficient solution replace edit distancebased algorithm
national institute japanese language linguistics japan ninjal undertaken corpus compilation project construct web corpus linguistic research comprising ten billion word project divided four part page collection linguistic analysis development corpus concordance system preservation article present corpus concordance system named bonten enables tenbillionscaled corpus queried string sequence morphological information subtree syntactic dependency structure
paper describes approach automat ically close knowledge gap clickbait post via transformer model trained questionanswering augmented task specific postprocessing step part semeval clickbait shared task frbe et al specifically task devised strategy improve existing model fit task better eg different special mod el postprocessor tailored different inherent challenge task furthermore explored possibility expanding original training data using strategy heuristic labeling semisupervised learn ing adjustment able improve baseline percentage point bleu score
paper present participation apollo team semeval task hypernym discovery subtask generalpurpose hypernym discovery try produce ranked list hypernym specific term propose novel approach automatic extraction hypernymy relation corpus using dependency pattern estimated application pattern lead higher score using traditional lexical pattern
prompting dominant method evaluating linguistic knowledge large language model llm method directly read model probability distribution string prompting requires model access internal information processing linguistic input thereby implicitly testing new type emergent ability metalinguistic judgment study compare metalinguistic prompting direct probability measurement way measuring model linguistic knowledge broadly find llm metalinguistic judgment inferior quantity directly derived representation furthermore consistency get worse prompt query diverges direct measurement nextword probability finding suggest negative result relying metalinguistic prompt taken conclusive evidence llm lack particular linguistic generalization result also highlight value lost move closed apis access probability distribution limited
present sapphire simple aligner phrasal paraphrase hierarchical representation monolingual phrase alignment fundamental problem natural language understanding also crucial technique various application natural language inference semantic textual similarity assessment previous method monolingual phrase alignment languageresource intensive require largescale synonymparaphrase lexica highquality parser different sapphire depends monolingual corpus train word embeddings therefore easily transferable specific domain different language specifically sapphire first obtains word alignment using pretrained word embeddings expands phrase alignment bilingual phrase extraction method estimate likelihood phrase alignment sapphire us phrase embeddings hierarchically composed word embeddings finally sapphire search set consistent phrase alignment lattice phrase alignment candidate achieves searchefficiency constraining lattice path go phrase alignment pair highest alignment score experimental result using standard dataset phrase alignment evaluation show sapphire outperforms previous method establishes stateoftheart performance
paper present design galician syntactic corpus application intonation modeling corpus around sentence designed variation syntactic structure number accent group recorded professional speaker study influence prosodic structure
paper present new task predicting coverage text document relation extraction document contain many relational tuples given entity coverage prediction useful selecting best document knowledge base construction large input corpus study problem present dataset diverse document entity analyze correlation document coverage feature like length entity mention frequency alexa rank language complexity information retrieval score feature moderate predictive power employ method combining feature statistical model like tfidf language model like bert model combining feature bert herb achieves f score demonstrate utility coverage prediction two use case kb construction claim refutation
paper present description proposed system subtask multilingual track semeval task aim classify text generated ai human approach treat binary text classification tokenlevel prediction final classification average tokenlevel prediction use rich representation pretrained transformer model trained selectively aggregate information across different layer score individual token given layer may contain distinct information notably model demonstrates competitive performance test dataset achieving accuracy score furthermore secures nd position multilingual track subtask mere behind leading system
study propose beam search method obtain diverse output local sequence transduction task token source target sentence overlap grammatical error correction gec gec advisable rewrite local sequence must rewritten leaving correct sequence unchanged however existing method acquiring various output focus revising token sentence therefore existing method may either generate ungrammatical sentence force entire sentence changed produce nondiversified sentence weakening constraint avoid generating ungrammatical sentence considering issue propose method rewrite token text rewrite part need diversely corrected beam search method adjusts search token beam according probability prediction copied source sentence experimental result show proposed method generates diverse correction existing method without losing accuracy gec task
explore whether social medium provide window community real estate foreclosure rate price change beyond traditional economic demographic variable find language use twitter predicts real estate outcome well traditional variable across county including twitter language traditional model lead significant improvement eg pearson r r price change overcome challenge relative sparsity noise twitter language variable showing training residual error traditional model lead accurate overall assessment finally discover twitter language related business eg company marketing technology eg technology internet among others yield predictive power economics
prompt tuning largely successful parameterefficient method conditioning largescale pretrained language model perform downstream task thus far soft prompt tuning learns fixed set taskspecific continuous vector ie soft token remain static across task sample fixed prompt however may generalize well diverse kind input task comprises order address propose vectorquantized inputcontextualized prompt vip extension soft prompt tuning framework vip particularly focus two aspectscontextual prompt learns inputspecific contextualization soft prompt token smallscale sentence encoder quantized prompt map contextualized prompt set learnable codebook vector vector quantization network various language understanding task like superglue qa relation classification ner nli vip outperforms soft prompt tuning pt baseline average margin generalization study show vip learns robust prompt representation surpassing pt margin outofdomain qa nli task respectively multitask setup task spanning across domain
build automated simplification system corpus complex sentence simplified version first step understand sentence complexity enable development automatic text simplification system present lexical syntactically simplified urdu simplification corpus detailed analysis various simplification operation human evaluation corpus quality analyze corpus using text readability measure present comparison original lexical simplified syntactically simplified corpus addition compare corpus existing simplification corpus building simplification system evaluating system using bleu sari score system achieves highest bleu score comparable sari score comparison system release simplification corpus benefit research community
language model lm gradually become generalpurpose interface interactive embodied world understanding physical concept essential prerequisite however unclear whether lm understand physical concept human world investigate design benchmark vec cover task visual concept shape material object ii embodied concept learned interaction world temperature object zero fewshot prompting result show understanding certain visual concept emerges scaling lm still basic concept scaling law apply example optb performs close human zeroshot accuracy material concept yet behaves like random guessing mass concept instead visionaugmented lm clip blip achieve humanlevel understanding embodied concept analysis indicates rich semantics visual representation serve valuable source embodied knowledge inspired propose distillation method transfer embodied knowledge vlms lm achieving performance gain comparable scaling parameter lm time dataset available httpsgithubcomtobiasleevec
popularity smartphones witnessed rapid proliferation multimodal post various social medium platform observe multimodal sentiment expression specific global characteristic interdependency object scene within image however previous study considered representation single imagetext post failed capture global cooccurrence characteristic dataset paper propose multichannel graph neural network sentimentawareness mgnns imagetext sentiment detection specifically first encode different modality capture hidden representation introduce multichannel graph neural network learn multimodal representation based global characteristic dataset finally implement multimodal indepth fusion multihead attention mechanism predict sentiment imagetext pair extensive experiment conducted three publicly available datasets demonstrate effectiveness approach multimodal sentiment detection
incivility prevalent online social medium platform also concrete effect individual user online group platform given prevalence effect online incivility challenge involved humanbased incivility detection urgent develop validated versatile automatic approach identifying uncivil post comment project advance neural bertbased classifier well logistic regression classifier identify uncivil comment classifier trained dataset reddit post annotated incivility expanded using combination labeled data reddit twitter best performing model achieves f reddit test set final model applicable across social medium platform distinct data structure also computationally versatile ready used vast volume online data trained model annotated data made available research community
present approach turkunlp group iwpt shared task multilingual parsing enhanced universal dependency task involves treebanks different language requires parser generate graph structure extending basic dependency tree approach combine languagespecific bert model udify parser neural sequencetosequence lemmatization graph transformation approach encoding enhanced structure dependency tree submission averaged ela ranking first shared task make method resource developed study freely available open license urlhttpsturkunlporg
describe new crosslingual strategy development multilingual information service mobile device novelty approach intelligent modeling crosslingual application domain combination textual translation speech generation final system help user speak foreign language communicate local people relevant situation restaurant taxi emergency advantage information service robust enough use realworld situation developed beijing olympic game foreigner rely translation assistance deployment foreseen part planned ubiquitous mobile information system olympic game
current spoken dialogue system initiate turn long period silence m lead little realtime feedback sluggish response overall stilted conversational flow human typically respond within m successfully predicting initiation point advance would allow spoken dialogue agent work predict leadtime initiation using prosodic feature pretrained speech representation model wavvec operating user audio word feature pretrained language model gpt operating incremental transcription evaluate error propose two metric wrt predicted true lead time train evaluate model switchboard corpus find method outperforms feature prior work metric vastly outperforms common approach waiting m silence
identifying irony usergenerated social medium content wide range application however date arabic content received limited attention bridge gap study build new open domain arabic corpus annotated irony detection query twitter using ironyrelated hashtags collect ironic message manually annotated two linguist according working definition irony challenge encountered annotation process reflect inherent limitation twitter message interpretation well complexity arabic dialect published corpus valuable free resource developing open domain system automatic irony recognition arabic language dialect social medium text
pairwise ranking method widely used discriminative training approach structure prediction problem natural language processing nlp decomposing problem ranking hypothesis pairwise comparison enables simple efficient solution however neglecting global ordering hypothesis list may hinder learning propose listwise learning framework structure prediction problem machine translation framework directly model entire translation list ordering learn parameter may better fit given listwise sample furthermore propose toprank enhanced loss function sensitive ranking error higher position experiment largescale chineseenglish translation task show listwise learning framework toprank enhanced listwise loss lead significant improvement translation quality
study outline durationdependent modeling experiment limitedresource hungarian speech recognition task well known short utterance pose significant challenge automatic speech recognition due lack context phenomenon particular found exclusion shorter speech sample finetuning longer duration test data significantly improves recognition rate measured public hungarian datasets beabase commonvoice cv therefore apply tandem modeling approach separate model used short long duration test data strategy improved ability recognize short utterance maintaining recognition long utterance efficiently led significant increase overall recognition accuracy
opendomain question answering answer question based evidence retrieved large corpus stateoftheart neural approach require intermediate evidence annotation training however intermediate annotation expensive method rely transfer common setting questionanswer pair available paper investigates whether model learn find evidence large corpus distant supervision answer label model training thereby generating additional annotation cost introduce novel approach distdr iteratively improves weak retriever alternately finding evidence uptodate model encouraging model learn likely evidence without using evidence label distdr par fullysupervised stateoftheart method multihop singlehop qa benchmark analysis confirms distdr find accurate evidence iteration lead model improvement code available urlhttpsgithubcomhenryzhaodistdr
work explores problem generating task graph realworld activity different prior formulation consider setting text transcript instructional video performing realworld activity eg making coffee provided goal identify key step relevant task well dependency relationship key step propose novel task graph generation approach combine reasoning capability instructiontuned language model along clustering ranking component generate accurate task graph completely unsupervised manner show proposed approach generates accurate task graph compared supervised learning approach task procel crosstask datasets
paraphrase exist different granularity level frequently used one sentential level however argue working sentential level optimal machine human would easier efficient work subsentential level prove quantify analyze difference paraphrase sentence subsentence level order show significance problem first result preliminary dataset seem confirm hypothesis
developing highperforming dialogue system benefit automatic identification undesirable behavior system response however detecting behavior remains challenging draw breadth general knowledge understanding conversational practice although recent research focused building specialized classifier detecting specific dialogue behavior behavior coverage still incomplete lack testing realworld humanbot interaction paper investigates ability stateoftheart large language model llm chatgpt perform dialogue behavior detection nine category real humanbot dialogue aim assess whether chatgpt match specialized model approximate human performance thereby reducing cost behavior detection task finding reveal neither specialized model chatgpt yet achieved satisfactory result task falling short human performance nevertheless chatgpt show promising potential often outperforms specialized detection model conclude indepth examination prevalent shortcoming chatgpt offering guidance future research enhance llm capability
position paper special session multilingual information access comprises three part first part review possible demand multilingual information access hereafter mlia web examines required technical element among second part focus crosslanguage information retrieval hereafter clir particularly scalable architecture enables clir number language combination distributed architecture developed around xirch project international joint experimental project currently involves ntt krdl kaist described certain detail final part discusses nlpmt related issue associated clir architecture
open philology project university leipzig aspires reassert value philology broadest sense philology signifies widest possible use linguistic record enable deep understanding complete lived experience humanity pragmatically focus greek latin substantial collection service already available within language substantial user community exist c unique user month perseus digital library europeanbased project better positioned process extensive cultural heritage material language rather chinese sanskrit open philology project designed hope contribute historical language survives within human record includes three task creation open extensible repurposable collection machinereadable linguistic source development dynamic textbook use annotated corpus customize vocabulary grammar text learner want read time engage student collaboratively producing new annotated data establishment new workflow form publication individual annotation argumentation traditional publication integrated machineactionable data
recent year online shopping gained momentum became important venue customer wishing save time simplify shopping process key advantage shopping online ability read customer saying product interest work aim maintain advantage situation extreme brevity needed example shopping voice suggest novel task extracting single representative helpful sentence set review given product selected sentence meet two condition first helpful purchase decision second opinion express supported multiple reviewer task closely related task multi document summarization product review domain differs objective level conciseness collect dataset english sentence helpfulness score via crowdsourcing demonstrate reliability despite inherent subjectivity involved next describe complete model extract representative helpful sentence positive negative sentiment towards product demonstrate outperforms several baseline
analyze large language model able predict pattern human reading behavior compare performance languagespecific multilingual pretrained transformer model predict reading time measure reflecting natural human sentence processing dutch english german russian text result accurate model human reading behavior indicates transformer model implicitly encode relative importance language way comparable human processing mechanism find bert xlm model successfully predict range eye tracking feature series experiment analyze crossdomain crosslanguage ability model show reflect human sentence processing
learning new vocabulary human machine acquire critical information meaning unfamiliar word contextual information sentence passage however context equally helpful learning unfamiliar target word context provide rich set semantic clue target word meaning others less supportive explore task finding educationally supportive context respect given target word vocabulary learning scenario particularly improving student literacy skill inherent contextbased nature attentionbased deep learning method provide ideal starting point evaluate attentionbased approach predicting amount educational support context ranging simple custom model using pretrained embeddings additional attention layer commercial large language model llm using existing major benchmark dataset educational context support prediction found sophisticated generic llm poor performance simpler model using custom attentionbased approach achieved bestknown performance date dataset
chinese abstract meaning representationcamrbaichuanbcamr
pretrained visionlanguage model vlms achieved remarkable performance image retrieval text however performance drop drastically confronted linguistically complex text struggle comprehend inspired divideandconquer algorithm dualprocess theory paper regard linguistically complex text compound proposition text composed multiple simple proposition sentence propose endtoend neural divideandconquer reasoning framework dubbed ndcr contains three main component divide proposition generator divide compound proposition text simple proposition sentence produce corresponding representation conquer pretrained vlmsbased visuallinguistic interactor achieves interaction decomposed proposition sentence image combine neuralsymbolic reasoner combine reasoning state obtain final solution via neural logic reasoning approach according dualprocess theory visuallinguistic interactor neuralsymbolic reasoner could regarded analogical reasoning system logical reasoning system conduct extensive experiment challenging image retrieval contextual description data set experimental result analysis indicate ndcr significantly improves performance complex imagetext reasoning problem
paper describes contribution pragtag shared task describe compare different approach based sentence classification sentence similarity sequence tagging find bertbased sentence labeling approach integrating positional information outperforms sequence tagging sbertbased sentence classification provide analysis highlighting potential combining different approach
year natural language processing increasingly focused task solved statistical model ignored social aspect language limitation large part due historically available data limitation model narrowed focus biased tool demographically however increased availability data set including sociodemographic information expressive neural model opportunity address issue argue combination broaden focus nlp solve whole new range task enable u generate novel linguistic insight provide fairer tool everyone
glawinette derivational lexicon french used feed demonette database created glawi machine readable dictionary collected couple word definition morphological section dictionary selected one form regular formal analogy instantiate frequent enough formal pattern graph structure morphological family used identify couple lexeme derivational pattern close intuition morphologists
introduce crass counterfactual reasoning assessment data set benchmark utilizing questionized counterfactual conditionals novel powerful tool evaluate large language model present data set design benchmark test six stateoftheart model benchmark result show pose valid challenge model open considerable room improvement
parameterefficient pe method like prompt adapter adapting pretrained language model plm downstream task popular recently however hindrance still prevent method reaching full potential example two significant challenge fewshot adaptation crosstask generalization tackle issue propose general pe priming framework enhance explore fewshot adaptation generalization ability pe method framework plms primed pe method rapidly adapting various target task evaluate generalization ability pe method conduct experiment fewshot crossdomain benchmark containing diverse nlp task experiment reveals best priming strategy also verifies priming facilitates adaptation target task
paper present lig participation ef mt task iwslt primary system proposed made large improvement point bleu tst set compared last year participation part improvment due use extraction gigaword corpus also propose preliminary adaptation driven decoding concept machine translation method allows efficient combination machine translation system rescoring loglinear model nbest list level according auxiliary system basis technique essentially guiding search using one previous system output result show approach allows significant improvement bleu score using google translate guide smt system also try use confidence measure additional loglinear feature could get improvment technique
finetuning pretrained model automatically summarizing doctorpatient conversation transcript present many challenge limited training data significant domain shift long noisy transcript high target summary variability paper explore feasibility using pretrained transformer model automatically summarizing doctorpatient conversation directly transcript show fluent adequate summary generated limited training data finetuning bart specially constructed dataset resulting model greatly surpass performance average human annotator quality previous published work task evaluate multiple method handling long conversation comparing obvious baseline truncating conversation fit pretrained model length limit introduce multistage approach tackle task learning two finetuned model one summarizing conversation chunk partial summary followed one rewriting collection partial summary complete summary using carefully chosen finetuning dataset method shown effective handling longer conversation improving quality generated summary conduct automatic evaluation rouge two conceptbased metric focusing medical finding human evaluation qualitative example literature assessing hallucination generalization fluency general quality generated summary
system story generation asked produce plausible enjoyable story given input context task underspecified vast number diverse story originate single input large output space make difficult build evaluate story generation model existing datasets lack rich enough context meaningfully guide model existing evaluation crowdsourced automatic unreliable assessing longform creative text address issue introduce dataset evaluation platform built storium online collaborative storytelling community authorgenerated dataset contains k lengthy story token finegrained natural language annotation eg character goal attribute interspersed throughout narrative forming robust source guiding model evaluate language model finetuned dataset integrating onto storium real author query model suggested story continuation edit automatic metric computed edits correlate well user rating generated story qualitative feedback semistructured user interview release storium dataset evaluation platform spur principled research story generation
taskoriented dialogue tod human user naturally introduce chitchat beyond immediate scope task interfering flow conversation address issue without need expensive manual data creation use fewshot prompting llamab enhance multiwoz dataset user backstories typical example chitchat interference tod assess impact addition testing two model one trained solely tod another trained tod preliminary chitchat interaction analysis demonstrates enhanced dataset pose challenge system moreover demonstrate dataset effectively used training purpose enabling system consistently acknowledge user backstory also successfully moving task forward turn confirmed human evaluation finding highlight benefit generating novel chitchattod scenario test tod system thoroughly improve resilience natural user interference
article describes analytical approach designed blp workshop task sentiment analysis actual task submission used distilbert however later applied rigorous hyperparameter tuning preprocessing improving result accuracy f micro score vanilla lstm traditional machine learning model applied compare result accuracy achieved traditional svm contribution data augmentation using oversampling method remove data imbalance b attention masking data encoding masked language modeling capture representation language semantics effectively demonstrating explainable ai originally system scored microf competition ranked th among participant basic distilbert model later improved lstm xlmrobertabase model respectively
growing popularity virtual assistant pose new challenge entity resolution task linking mention text referent entity knowledge base specifically shopping domain customer tend mention entity implicitly eg organic milk rather use entity name explicitly leading large number candidate product meanwhile query different customer may expect different result example add milk cart customer may refer certain product hisher favorite brand customer may want reorder product regularly purchase moreover new customer may lack persistent shopping history requires u enrich connection customer product attribute address issue propose new framework leverage personalized feature improve accuracy product ranking first build crosssource heterogeneous knowledge graph customer purchase history product knowledge graph jointly learn customer product embeddings incorporate product customer history representation neural reranking model predict candidate likely purchased specific customer experiment result show model substantially improves accuracy top ranked candidate compared stateoftheart product search model
learning multilingual multidomain translation model challenging heterogeneous imbalanced data make model converge inconsistently different corpus real world one common practice adjust share corpus training learning process balanced lowresource case benefit high resource one however automatic balancing method usually depend intra interdataset characteristic usually agnostic requires human prior work propose approach multiuat dynamically adjusts training data usage based model uncertainty small set trusted clean data multicorpus machine translation experiment two class uncertainty measure multilingual language setting multidomain setting indomain outofdomain englishgerman translation demonstrate approach multiuat substantially outperforms baseline including static dynamic strategy analyze crossdomain transfer show deficiency static similarity based method
realtime summarization news event rts allows person stay uptodate important topic develop time occurrence major subevents medium attention increase large number news article published propose summarization approach detects change selects suitable summarization configuration runtime particular time high medium attention approach exploit redundancy content produce precise summary avoid emitting redundant information find approach significantly outperforms strong nonadaptive rts baseline term emitted summary update achieves best result recent webscale dataset successfully applied different realworld dataset without requiring additional modification
transcription often reported bottleneck endangered language documentation requiring large effort scarce speaker transcriber general automatic speech recognition asr accurate enough accelerate transcription trained large amount transcribed data however single speaker involved several study reported encouraging result phonetic transcription even small amount training expand body work speakerdependent transcription comparing four asr approach notably recent transformer pretrained multilingual model common dataset language automate data preparation training evaluation step also developed phoneme recognition setup handle morphologically complex language writing system pronunciation dictionary exists find finetuning multilingual pretrained model yield average phoneme error rate per language minute less transcribed data training language minute training achieved per less result number varied language suggest asr significantly reduce transcription effort speakerdependent situation common endangered language work
essential task question answering qa system rerank set answer candidate ie answer sentence selection candidate typically sentence either extracted one document preserving natural order retrieved search engine stateoftheart approach task use huge neural model bert complex attentive architecture paper argue exploiting intrinsic structure original rank together effective wordrelatedness encoder achieve highest accuracy among costefficient model two order magnitude fewer parameter current state art model take second train wikiqa dataset ie fast comparison minute required standard bertbase finetuning
propose entity linking el model jointly learns mention detection md entity disambiguation ed model applies taskspecific head top shared bert contextualized embeddings achieve stateoftheart result across standard el dataset using model also study model performance setting handcrafted entity candidate set available find model performs well setting
describe compare different method creating dictionary word corresponding semantic orientation tested well different dictionary helped determine entire text extract individual word used common method based pointwise mutual information mutual information set seed word target word calculated using two different method near search search engine altavista since discontinued search google two dictionary tested manually annotated dictionary positive negative word result show three method quite close none performs particularly well discus possible avenue research also point potential problem calculating pointwise mutual information using google
present extension adverbial entry french morphological lexicon dela dictionnaires electroniques du ladl ladl electronic dictionary adverb extracted lglex nlporiented syntactic resource french turn contains adverb extracted lexicongrammar table simple adverb ending ment ie ly compound adverb work exploit finegrained linguistic information provided existing resource resulting resource reviewed order delete duplicate freely available lgpllr license
information extraction question answering potential introduce new paradigm machine learning applied criminal law existing approach generally use tabular data predictive metric alternative approach needed matter equitable justice individual judged casebycase basis process involving verbal written discussion interpretation case factor discussion individualized nonetheless rely underlying fact information extraction play important role surfacing fact still important understand analyze unsupervised weakly supervised pretrained model ability extract factual information freeform dialogue california parole hearing exception f score use opportunity highlight opportunity research information extraction question answering encourage new development nlp enable analysis review legal case done posthoc predictive manner
paper present automatic annotation bibliographical reference zone paper article xmltei format work applied two phase first use machine learning technology classify bibliographical nonbibliographical paragraph paper mean model initially created differentiate footnote containing containing bibliographical reference previous description one bilbos feature open source software automatic annotation bibliographic reference also suggest method minimize margin error second propose algorithm find largest list bibliographical reference article improvement applied model result increase model efficiency accuracy equal testing work able achieve average percentage success detecting bibliographical reference zone
recent work shown pretrained language model capture social bias large amount text trained attracted attention developing technique mitigate bias work perform empirical survey five recently proposed bias mitigation technique counterfactual data augmentation cda dropout iterative nullspace projection selfdebias sentencedebias quantify effectiveness technique using three intrinsic bias benchmark also measuring impact technique model language modeling ability well performance downstream nlu task experimentally find selfdebias strongest debiasing technique obtaining improved score bias benchmark current debiasing technique perform less consistently mitigating nongender bias improvement bias benchmark stereoset crowspairs using debiasing strategy often accompanied decrease language modeling ability making difficult determine whether bias mitigation effective
present camelira webbased arabic multidialect morphological disambiguation tool cover four major variant arabic modern standard arabic egyptian gulf levantinecamelira offer userfriendly web interface allows researcher language learner explore various linguistic information partofspeech morphological feature lemma system also provides option automatically choose appropriate dialectspecific disambiguator based prediction dialect identification component camelira publicly accessible urlhttpcameliracamellabcom
addressing challenge lowresource information extraction remains ongoing issue due inherent information scarcity within limited training example existing data augmentation method considered potential solution struggle strike balance weak augmentation eg synonym augmentation drastic augmentation eg conditional generation without proper guidance paper introduces novel paradigm employ targeted augmentation back validation produce augmented example enhanced diversity polarity accuracy coherence extensive experimental result demonstrate effectiveness proposed paradigm furthermore identified limitation discussed shedding light area future improvement
mathematical reasoning serf cornerstone assessing fundamental cognitive capability human intelligence recent time notable surge development large language model llm geared towards automated resolution mathematical problem however landscape mathematical problem type vast varied llmoriented technique undergoing evaluation across diverse datasets setting diversity make challenging discern true advancement obstacle within burgeoning field survey endeavor address four pivotal dimension comprehensive exploration various mathematical problem corresponding datasets investigated ii examination spectrum llmoriented technique proposed mathematical problemsolving iii overview factor concern affecting llm solving math iv elucidation persisting challenge within domain best knowledge survey stand one first extensive examination landscape llm realm mathematics providing holistic perspective current state accomplishment future challenge rapidly evolving field
sparsity formal knowledge roughness nonontological construction make sparsity problem particularly prominent open knowledge graph openkgs due sparse link learning effective representation fewshot entity becomes difficult hypothesize introducing negative sample contrastive learning cl formulation could beneficial scenario however existing cl method model kg triplet binary object entity ignoring relationguided ternary propagation pattern generic ie ignore zeroshot fewshot synonymity problem appear openkgs address propose ternarycl cl framework based ternary propagation pattern among head relation tail ternarycl design contrastive entity contrastive relation mine ternary discriminative feature negative entity relation introduces contrastive self help zero fewshot entity learn discriminative feature contrastive synonym model synonymous entity contrastive fusion aggregate graph feature multiple path extensive experiment benchmark demonstrate superiority ternarycl stateoftheart model
generating characterlevel feature important step achieving good result various natural language processing task alleviate need human labor generating handcrafted feature method utilize neural architecture convolutional neural network cnn recurrent neural network rnn automatically extract feature proposed shown great result however cnn generates positionindependent feature rnn slow since need process character sequentially paper propose novel method using densely connected network automatically extract characterlevel feature proposed method require language task specific assumption show robustness effectiveness faster cnn rnnbased method evaluating method three sequence labeling task slot tagging partofspeech po tagging namedentity recognition ner obtain stateoftheart performance fscore accuracy slot tagging po tagging respectively comparable performance stateoftheart fscore ner
previous attempt injecting semantic frame bias smt training low resource language failed either semantic parser available low resource input language b output english language semantic parses excise relevant part alignment space aggressively present first semantic smt model succeed significantly improving translation quality across many low resource input language automatic srl available consistently across common mt metric result report best far date type approach analysis suggest general easier approach toward including semantics training smt model may feasible generally assumed even low resource language semantic parser remain scarce recent proposal use crosslingual evaluation metric xmeant inversion transduction grammar itg induction inapplicable low resource language lack semantic parser break bottleneck via vastly improved method biasing itg induction toward learning semantically correct alignment using monolingual semantic evaluation metric meant unlike xmeant meant requires readilyavailable english output language semantic parser advance report exploit novel realization meant represents excellent way semantically bias expectationmaximization induction even low resource language test system challenging language including amharic uyghur tigrinya oromo result show model influence learning towards semantically correct alignment leading better translation quality standard itg giza based smt training model different datasets
extracting temporal relation eg simultaneous among event crucial natural language understanding one key challenge problem event interest far away text context inbetween often becomes complicated making challenging resolve temporal relationship paper thus proposes new syntaxguided graph transformer network sgt mitigate issue explicitly exploiting connection two event based dependency parsing tree automatically locating temporal cue two event via novel syntaxguided attention mechanism experiment two benchmark datasets matres tbdense show approach significantly outperforms previous stateoftheart method endtoend temporal relation extraction temporal relation classification absolute fscore gain improvement also prof robust contrast set matres make program publicly available paper accepted
sanskrit one oldest language asian subcontinent fell common usage around bc paper attempt translate sanskrit english using neural machine translation approach based reinforcement learning transfer learning never tried tested sanskrit along paper also release monolingual sanskrit parallel aligned sanskritenglish corpus research community methodology outperform previous approach applied sanskrit various searcher help linguistic community accelerate costly time consuming manual translation process
detection reused text important wide range discipline however even research field plagiarism detection constantly improving heavily modified paraphrased text still challenging current methodology historical text problem even severe since text source often subject stronger frequent modification despite need tool automate text criticism eg tracing modification historical text algorithmic support still limited current technique tell frequently text modified little work done determining degree kind paraphrastic modificationdespite information substantial interest scholar present humaninterpretable featurebased method measure paraphrastic modification evaluating technique three data set find approach performs competitive text similarity score borrowed machine translation evaluation much harder interpret
date majority computational model still determines semantic relatedness word larger linguistic unit type level paper compare extend multisense embeddings order model utilise word sens token level focus challenging class complex verb evaluate model variant various semantic task semantic classification predicting compositionality detecting nonliteral language usage overall best model model significantly outperform wordvec singlesense skip baseline thus demonstrating need distinguish word sens distributional semantic model
number sens given word polysemy subjective notion varies widely across annotator resource propose novel method estimate polysemy based simple geometry contextual embedding space approach fully unsupervised purely datadriven rigorous experiment show ranking well correlated strong statistical significance different ranking derived famous humanconstructed resource wordnet ontonotes oxford wikipedia etc different standard metric also visualize analyze correlation human ranking make interesting observation valuable byproduct method ability sample extra cost sentence containing different sens given word finally fully unsupervised nature approach make applicable language code data publicly available urlhttpsgithubcomksipospolysemyassessment
twitter customer service interaction recently emerged effective platform respond engage customer work explore role negation customer service interaction particularly applied sentiment analysis define rule identify true negation cue scope suited conversational data existing general review data using semantic knowledge syntactic structure constituency parse tree propose algorithm scope detection performs comparable state art bilstm investigate result negation scope detection sentiment prediction task customer service conversation data using traditional svm neural network propose antonym dictionary based method negation applied combination cnnlstm sentiment analysis experimental result show antonymbased method outperforms previous lexiconbased neural network method
paper propose formal framework take account influence intended context use nlp system procedure metric used evaluate system introduce particular notion contextdependent quality model explain adapted given context use specifically define vectorspace representation context use quality model connected generic contextual quality model gcqm domain expert evaluation needed build gcqm based analytic knowledge previous evaluation using mechanism proposed main inspiration source work femti framework evaluation machine translation implement partly present model described briefly along insight domain
sentiment analysis subfield natural language processing nlp witnessed significant advancement analysis usergenerated content across diverse language however application lowresource language remains challenge research address gap conducting comprehensive sentiment analysis experiment context mizo language lowresource language predominantly spoken indian state mizoram neighboring region study encompasses evaluation various machine learning model including support vector machine svm decision tree random forest knearest neighbor knn logistic regression transfer learning using xlmroberta finding reveal suitability svm robust performer mizo sentiment analysis demonstrating highest f score accuracy among model tested xlmroberta transfer learning model exhibit competitive performance highlighting potential leveraging pretrained multilingual model lowresource language sentiment analysis task research advance understanding sentiment analysis lowresource language serf stepping stone future investigation domain
codicrac shared task dialogue consists three subtasks subtask resolution anaphoric identity subtask resolution bridging reference subtask resolution discourse deixisabstract anaphora anaphora resolution task detecting mention input document clustering mention entity endtoend model proceeds pruning candidate mention pruning possibility removing correct mention also endtoend anaphora resolution model high model complexity take long time train therefore proceed anaphora resolution twostage pipeline model first mention detection step score candidate word span calculated mention predicted without pruning second anaphora resolution step pair mention anaphora resolution relationship predicted using mention predicted mention detection step propose twostage anaphora resolution pipeline model reduces model complexity training time maintains similar performance endtoend model result experiment anaphora resolution showed performance light ami persuasion switchboard final system ranked rd leaderboard subtask
paper present work ehrsql shared task tackle reliable texttosql modeling electronic health record proposed system tackle task three module abstention module texttosql generation module reliability module abstention module identifies whether question answerable given database schema question answerable texttosql generation module generates sql query associated confidence score reliability module two key component confidence score thresholding reject generation confidence predefined level error filtering identifies excludes sql query result execution error official leaderboard task system rank th also made source code public
deep reinforcement learning shown great potential training dialogue policy however favorable performance come cost many round interaction existing dialogue policy method rely single learning system human brain two specialized learning memory system supporting find good solution without requiring copious example inspired human brain paper proposes novel complementary policy learning cpl framework exploit complementary advantage episodic memory em policy deep qnetwork dqn policy achieve fast effective dialogue policy learning order coordinate two policy proposed confidence controller control complementary time according relative efficacy different stage furthermore memory connectivity time pruning proposed guarantee flexible adaptive generalization em policy dialog task experimental result three dialogue datasets show method significantly outperforms existing method relying single learning system
taskoriented conversational agent attention usually devoted assessing task effectiveness rather textithow task achieved however conversational agent moving towards complex humanlike interaction capability eg ability use formalinformal register show empathetic behavior standard evaluation methodology may suffice paper provide novel methodology assess completely controlled way impact quality experience agent interaction strategy methodology based within subject design two slightly different transcript interaction conversational agent presented user series pilot experiment prove methodology allows fast cheap experimentationevaluation focusing aspect overlooked current method
chainofthought cot prompting large language model proven effective numerous natural language process task designing prompt generalize well diverse problem type challenging citation especially context math word problem solving additionally common large amount training data better diversity coverage cot annotation available limit use supervised learning technique address issue investigate two approach leverage training data fewshot prompting scenario textitdynamic program prompting textitprogram distillationour approach largely inspired citation proposed replace cot program intermediate reasoning step prompting strategy allows u accurately verify answer correctness program execution mwp solvingour dynamic program prompting involves annotating training data sampling correct program large language model program distillation involves adapting smaller model programannotated training dataour experiment three standard mwp datasets demonstrate effectiveness approach yielding significant improvement previous baseline prompting finetuningour result suggest leveraging large amount training data improve generalization ability prompt boost performance finetuned smaller model mwp solving
exist bias individual language use word eg cool used expressing different meaning eg temperature range different word eg cloudy hazy used describing meaning study propose method modeling personal bias word meaning hereafter semantic variation personalized word embeddings obtained solving task subjective text regarding word used different individual different word prevent personalized word embeddings contaminated irrelevant bias solve task identifying reviewtarget objective output given review stabilize training extreme multiclass classification perform multitask learning metadata identification experimental result review retrieved ratebeer confirmed obtained personalized word embeddings improved accuracy sentiment analysis well target task analysis obtained personalized word embeddings revealed trend semantic variation related frequent adjective word
table content toc extraction centre structuring document hierarchical manner paper propose new dataset esgdoc comprising esg annual report company spanning report pose significant challenge due diverse structure extensive length address challenge propose new framework toc extraction consisting three step constructing initial tree text block based reading order font size modelling tree node text block independently considering contextual information captured nodecentric subtree modifying original tree taking appropriate action tree node keep delete move constructionmodellingmodification cmm process offer several benefit eliminates need pairwise modelling section heading previous approach making document segmentation practically feasible incorporating structured information section heading leverage local longdistance context relevant experimental result show approach outperforms previous stateoftheart baseline fraction running time framework prof scalability effectively handling document length
headline generation essential task natural language processing nlp model often exhibit limited ability accurately interpret numeral leading inaccuracy generated headline paper introduces cotnumhg training strategy leveraging chain thought cot paradigm supervised finetuning sft large language model approach aimed enhancing numeral perception interpretability accuracy generation structured output presented semeval task task numeralaware headline generation english challenge divided two specific subtasks first subtask focus numerical reasoning requiring model precisely calculate fill missing number news headline second subtask target generation complete headline utilizing training strategy across subtasks study primarily explores first subtask demonstration training strategy competition cotnumhgmistralb model attained accuracy rate underscoring effectiveness proposed strategy
paper describes examplebased machine translation ebmt system relay various knowledge resource morphologic analysis abstract surface form language translated shallow syntactic rule formalism used percolate feature derivation tree translation example serve decomposition text translated determine transfer lexical value target language translation template determine word order target language type phrase eg noun phrase prepositional phase generated target language induction mechanism generalizes translation template translation example paper outline basic idea underlying ebmt system investigates possibility limit translation template induction process
adversarial attack machine learning model threatened various realworld application spam filtering sentiment analysis paper propose novel framework learning discriminate perturbation disp identify adjust malicious perturbation thereby blocking adversarial attack text classification model identify adversarial attack perturbation discriminator validates likely token text perturbed provides set potential perturbation potential perturbation embedding estimator learns restore embedding original word based context replacement token chosen based approximate knn search disp block adversarial attack nlp model without modifying model structure training procedure extensive experiment two benchmark datasets demonstrate disp significantly outperforms baseline method blocking adversarial attack text classification addition indepth analysis show robustness disp across different situation
radiology report analysis provides valuable information aid public health initiative attracting increasing attention research community work present novel insight structure radiology report namely finding impression section offer different view radiology scan based intuition propose cotraining approach two machine learning model built upon finding impression section respectively use others information boost performance massive unlabeled data semisupervised manner conducted experiment public health surveillance study result show cotraining approach able improve performance using dual view surpass competing supervised semisupervised method
describe open dutch wordnet derived cornetto database princeton wordnet open source resource exploited existing equivalence relation cornetto synset wordnet synset order move open source content cornetto wordnet synset currently open dutch wordnet contains synset synset contain least one dutch synonym leaf synset still obtain dutch synonym average polysemy resource currently delivered xml cc bysa license linked global wordnet grid order use resource refer http githubcommartenpostmaopendutchwordnet
although statistical machine translation smt made great progress since came translation numerical time expression still far satisfactory generally speaking number likely outofvocabulary oov word due nonexhaustive characteristic even size training data large difficult obtain accurate translation result infinite set number depending traditional statistical method propose languageindependent framework recognize translate number precisely using rulebased method designing operator succeed make rule educible totally separate code thus extend rule various languagepairs without recoding contributes lot efficient development smt system good portability classify number time expression seven type arabic number cardinal number ordinal number date time day day week figure greedy algorithm developed deal rule conflict experiment shown approach significantly improve translation performance
intrinsic evaluation oie system carried either manuallywith human evaluator judging correctness extractionsor automatically standardized benchmark latter much costeffective less reliable primarily incompleteness existing oie benchmark ground truth extraction include acceptable variant fact leading unreliable assessment model performance moreover existing oie benchmark available english work introduce benchie benchmark evaluation framework comprehensive evaluation oie system english chinese german contrast existing oie benchmark benchie factbased ie take account informational equivalence extraction gold standard consists textitfact synset cluster exhaustively list acceptable surface form fact moreover mind common downstream application oie make benchie multifaceted ie create benchmark variant focus different facet oie evaluation eg compactness minimality extraction benchmark several stateoftheart oie system using benchie demonstrate system significantly less effective indicated existing oie benchmark make benchie data evaluation code publicly available
article tackle issue limited quantity manually sense annotated corpus task word sense disambiguation exploiting semantic relationship sens synonymy hypernymy hyponymy order compress sense vocabulary princeton wordnet thus reduce number different sense tag must observed disambiguate word lexical database propose two different method greatly reduce size neural wsd model benefit improving coverage without additional training data without impacting precision addition method present wsd system relies pretrained bert word vector order achieve result significantly outperforms state art wsd evaluation task
curriculum learning cl technique training model via ranking example typically increasing difficulty trend aim accelerating convergence improving generalisability current approach natural language understanding nlu task use cl improve indistribution data performance often via heuristicoriented taskagnostic difficulty work instead employ cl nlu taking advantage training dynamic difficulty metric ie statistic measure behavior model hand specific taskdata instance training propose modification existing cl scheduler based statistic differently existing work focus evaluating model indistribution id outofdistribution ood well zeroshot z crosslingual transfer datasets show across several nlu task cl training dynamic result better performance mostly zeroshot crosslingual transfer ood setting improvement certain case overall experiment indicate training dynamic lead better performing model smoother training compared difficulty metric faster average addition analysis shed light correlation taskspecific versus taskagnostic metric
discovering latent topic within text fundamental task many application however conventional topic model suffer different problem different setting latent dirichlet allocation lda may work well short text due data sparsity ie sparse word cooccurrence pattern short document biterm topic model btm learns topic modeling wordpairs named biterms whole corpus assumption strong document long rich topic information exhibit transitivity biterms paper propose novel way called graphbtm represent biterms graph design graph convolutional network gcns residual connection extract transitive feature biterms overcome data sparsity lda strong assumption btm sample fixed number document form minicorpus sample also propose dataset called news extracted news publisher document much longer newsgroups present amortized variational inference method graphbtm method generates coherent topic compared previous approach experiment show sampling strategy improves performance large margin
despite advance multilingual neural machine translation mnmt argue still two major challenge area data imbalance representation degeneration data imbalance problem refers imbalance amount parallel corpus language pair especially longtail language ie lowresource language representation degeneration problem refers problem encoded token tending appear small subspace full space available mnmt model solve two issue propose biacl framework requires targetside monolingual data bilingual dictionary improve performance mnmt model define two module named bidirectional autoencoder bidirectional contrastive learning combine online constrained beam search curriculum learning sampling strategy extensive experiment show proposed method effective strong baseline longtail language highresource language also demonstrate approach capable transferring knowledge domain language zeroshot scenario
alignment word embedding space different language common crosslingual space recently vogue strategy compute pairwise alignment map multiple language single pivot language often english strategy however biased towards choice pivot language given language proximity linguistic characteristic target language strongly impact resultant crosslingual space detriment topologically distant language present strategy eliminates need pivot language learning mapping across language hierarchical way experiment demonstrate strategy significantly improves vocabulary induction score existing benchmark well new nonenglishcentered benchmark built make publicly available
paper measure variation framing function foregrounding backgrounding coreferential corpus range temporal distance one type experiment frameannotated corpus grouped event type contrasted resulting ranking frame typicality rate contrasting publication date different ranking frame emerged document close far event instance second type analysis trained diagnostic classifier frame occurrence order let differentiate document based temporal distance class close far event instance classifier performs chance outperforms model word
article present current outcome curlicat cef telecom project aim collect deeply annotate set large corpus selected domain curlicat corpus includes monolingual corpus bulgarian croatian hungarian polish romanian slovak slovenian containing selected sample respective national corpus corpus automatically tokenized lemmatized morphologically analysed named entity annotated annotation uniformly provided language specific corpus common metadata schema harmonised across language additionally corpus annotated iate term language file format conllu plus format containing ten column specific conllu format three extra column specific corpus defined varadi et al curlicat corpus represent rich valuable source training nmt model also study development machine learning crosslingual terminological data extraction classification
article describes exclusively resourcebased method morphological annotation written korean text korean agglutinative language annotator designed process text operation syntactic parser present state annotates onestem word output graph morpheme annotated accurate linguistic information granularity tagset time higher usual tagsets comparison reference annotated corpus showed achieves recall without corpus training language resource used system lexicon stem transducer suffix transducer generation allomorph easily updated allows user control evolution performance system claimed morphological annotation korean text could performed morphological analysis module accessing lexicon morpheme show also performed directly lexicon word without applying morphological rule annotation time speed annotation word lexicon word obtained maintainable language resource fully automated compilation process
understanding idiom important nlp paper study extent pretrained bert model encode meaning potentially idiomatic expression pie certain context make use existing datasets perform two probing task pie usage classification idiom paraphrase identification experiment result suggest bert indeed separate literal idiomatic usage pie high accuracy also able encode idiomatic meaning pie extent
evolution social medium user behavior time complicates userlevel comparison task verification classification clustering ranking result naive approach may fail generalize new user even future observation previously known user paper propose novel procedure learn mapping short episode user activity social medium vector space distance point capture similarity corresponding user invariant feature fit model optimizing surrogate metric learning objective large corpus unlabeled social medium content learned mapping may applied user seen training time enables efficient comparison user resulting vector space present comprehensive evaluation validate benefit proposed approach using data reddit twitter wikipedia
people frequently interact information retrieval ir system however ir model exhibit bias discrimination towards various demographic inprocessing fair ranking method provides tradeoff accuracy fairness adding fairnessrelated regularization term loss function however havent intuitive objective function depend click probability user engagement directly optimize towards work propose textbfintextbfbatch textbfbalancing textbfregularization ibbr mitigate ranking disparity among subgroup particular develop differentiable textbfnormed pairwise ranking fairness nprf leverage tstatistics top nprf subgroup regularization improve fairness empirical result bertbased neural ranker m marco passage retrieval dataset humanannotated nongendered query benchmark citation show ibbr method nprf achieves significantly less bias minimal degradation ranking performance compared baseline
maritime security requires fulltime monitoring situation mainly based technical data radar ai also osintlike input eg newspaper threat operational reliability maritime surveillance malicious actor introduce discrepancy hard soft data sensor text either tweaking ai emitter emitting false information pseudonewspapers many technique exist identify piece false information including using knowledge base population technique build structured view information paper present use case suspect data identification maritime setting proposed system umbar ingests data sensor text processing information extraction step order feed knowledge base finally perform coherence check extracted fact
twotower visionlanguage vl model shown promising improvement various downstream vl task although advanced work improves performance building bridge encoders suffers ineffective layerbylayer utilization unimodal representation flexibly exploit different level unimodal semantic knowledge work propose managertower novel vl model architecture gather combine insight pretrained unimodal expert different level manager introduced crossmodal layer adaptively aggregate unimodal semantic knowledge facilitate comprehensive crossmodal alignment fusion managertower outperforms previous strong baseline without visionlanguage pretraining vlp vlp data managertower achieves superior performance various downstream vl task especially accuracy vqav teststd ir tr flickrk code checkpoint available urlhttpsgithubcomlooperxxmanagertower
paper describes asu system submitted coling wnut twitter named entity recognition ner task present experimental study applying deep learning extracting named entity ne tweet built two long shortterm memory lstm model task first model built extract named entity without type second model built extract classify finegrained entity class effort show detailed experimentation result effectiveness word embeddings brown cluster partofspeech po tag shape feature gazetteer local context tweet input vector representation lstm model also present set experiment better design network parameter twitter ner task system ranked fifth ten participant final fscore typed class non typed one
information newspaper often showed form numerical expression present comprehension problem many people including people disability illiteracy lack access advanced technology purpose paper motivate describe demonstrate rulebased lexical component simplifies numerical expression spanish text propose approach make news article accessible certain reader rewriting difficult numerical expression simpler way showcase numerical simplification system live demo based execution component different text consider successful unsuccessful simplification case
crosslingual transfer highresource language dialect closely related language variety facilitated similarity however current approach operate embedding space take surface similarity account work present simple yet effective strategy improve crosslingual transfer closely related variety propose augment data highresource source language characterlevel noise make model robust towards spelling variation strategy show consistent improvement several language task zeroshot transfer po tagging topic identification language variety finnic west north germanic western romance language branch work provides evidence usefulness simple surfacelevel noise improving transfer language variety
present submission team dice mlesg rd shared task multilingual esg impact duration inference context joint finnlpkdf workshop series task provides news article seek determine impact duration event news article may company experiment various baseline discus result bestperforming submission based contrastive pretraining stacked model based bagofwords assumption sentence embeddings also explored label correlation among event stemming news article correlation impact level impact length analysis show even simple classifier trained task achieve comparable performance complex model certain condition
word embeddings continue great use nlp researcher practitioner due training speed easiness use distribution prior work shown representation word improved use semantic knowledgebases paper propose novel way combining knowledgebases lexical information cooccurrences word remains conceptually clear consists mapping distributional semantic information multigraph modifying existing node embeddings technique compute word representation experiment show improved result compared vanilla word embeddings retrofitting concatenation technique using information variety datasets word similarity
tremendous success deep learning model computer vision task various emerging work natural language processing nlp task text classification using parametric model however constrains expressability limit function demand enormous empirical effort come robust model architecture also huge parameter involved model cause overfitting dealing small datasets deep gaussian process dgp offer bayesian nonparametric modelling framework strong function compositionality help overcoming limitation paper propose dgp model task text classification empirical comparison performance shallow deep gaussian process model made extensive experimentation performed benchmark text classification datasets trec text retrieval conference sst stanford sentiment treebank mr movie review r reuters demonstrate effectiveness dgp model
incontext learning icl important paradigm adapting large language model llm new task generalization behavior icl remains poorly understood investigate inductive bias icl perspective feature bias feature icl likely use given set underspecified demonstration two feature equally predictive label first characterize feature bias gpt model constructing underspecified demonstration range nlp datasets feature combination find llm exhibit clear feature biasesfor example demonstrating strong bias predict label according sentiment rather shallow lexical feature like punctuation second evaluate effect different intervention designed impose inductive bias favor particular feature adding natural language instruction using semantically relevant label word find many intervention influence learner prefer particular feature difficult overcome strong prior bias overall result provide broader picture type feature icl may likely exploit impose inductive bias better aligned intended task
human moderation commonly employed deliberative context argumentation discussion targeting shared decision issue relevant group eg citizen arguing employ shared budget scale discussion enlarges online setting overall discussion quality risk drop moderation becomes important assist participant cooperative productive interaction scale also make important employ nlp method forsemiautomatic moderation eg prioritize moderation needed work make first step towards semiautomatic moderation using stateoftheart classification model predict post require moderation showing task undoubtedly difficult performance significantly baseline investigate whether argument quality key indicator need moderation showing surprisingly high quality argument also trigger moderation make code data publicly available
hope considered significant wellbeing recuperation restoration human life health professional hope speech reflects belief one discover pathway desired objective become roused utilise pathway encourage research natural language processing towards positive reinforcement approach created hope speech detection dataset paper report shared task hope speech detection tamil english malayalam language shared task conducted part eacl workshop language technology equality diversity inclusion ltedi summarize datasets challenge openly available urlhttpscompetitionscodalaborgcompetitions present overview method result competing system best knowledge first shared task conduct hope speech detection
paper describes multiple solution designed tested problem wordlevel metaphor detection proposed system based variant recurrent neural network architecture specifically explore multiple source information pretrained word embeddings glove dictionary language concreteness transfer learning scenario based state encoder network neural network machine translation system one architecture based combining three system neural crf conditional random field trained directly metaphor data set neural machine translation encoder transfer learning scenario neural network used predict final label trained directly metaphor data set result vary test set neural crf standalone best one submission data combined system score highest test subset randomly selected training data
machine translation natural language generation nlg problem translating source text one language another every task machine learning domain requires evaluation metric obvious one human evaluation expensive case money time consumption last year appearing pretrained transformer architecture large language model llm stateoftheart result automatic machine translation evaluation got huge quality step term correlation expert assessment introduce mrescore semanticallyinformed regression encoder score approach constructing automatic machine translation evaluation system based regression encoder contrastive pretraining downstream problem
recognising dialogue act da important many natural language processing task dialogue generation intention recognition paper propose dualattention hierarchical recurrent neural network da classification model partially inspired observation conversational utterance normally associated da topic former capture social act latter describes subject matter however dependency da topic utilised existing system da classification novel dual taskspecific attention mechanism model able utterance capture information da topic well information interaction experimental result show modelling topic auxiliary task model significantly improve da classification yielding better comparable performance stateoftheart method three public datasets
automated system could assist judge predicting outcome case would help expedite judicial process system practically useful prediction system explainable promote research developing system introduce ildc indian legal document corpus ildc large corpus k indian supreme court case annotated original court decision portion corpus separate test set annotated gold standard explanation legal expert based ildc propose task court judgment prediction explanation cjpe task requires automated system predict explainable outcome case experiment battery baseline model case prediction propose hierarchical occlusion based model explainability best prediction model accuracy versus human legal expert pointing towards complexity prediction task analysis explanation proposed algorithm reveals significant difference point view algorithm legal expert explaining judgment pointing towards scope future research
understanding relation entity denoted np text critical part humanlike natural language understanding however fraction relation covered standard nlp task benchmark nowadays work propose novel task termed textbased np enrichment tne aim enrich np text prepositionmediated relationseither explicit implicitthat hold np text relation represented triplet denoted two np related via preposition human recover relation seamlessly current stateoftheart model struggle due implicit nature problem build first largescale dataset problem provide formal framing scope annotation analyze data report result finetuned language model task demonstrating challenge pose current technology webpage dataexploration ui demo link code model leaderboard foster research challenging problem found yanaielagithubiotne
present semeval task focus toponym resolution scientific article given article pubmed task consists detecting mention name place toponym mapping mention corresponding entry geonamesorg database geospatial location proposed three subtasks subtask asked participant detect toponym article subtask given toponym mention input asked participant disambiguate linking entry geonames subtask asked participant perform detection disambiguation step toponym total team registered team submitted system run summarize corpus tool created challenge freely available urlhttpscompetitionscodalaborgcompetitions also analyze method result error made competing system focus toponym disambiguation
ability quantify incivility online news congressional debate great interest political scientist computational tool detecting online incivility english fairly accessible potentially could applied broadly test jigsaw perspective api ability detect degree incivility corpus developed consisting manual annotation civility american news demonstrate toxicity model exemplified perspective inadequate analysis incivility news carry error analysis point need develop method remove spurious correlation word often mentioned news especially identity descriptor incivility without improvement applying perspective similar model news likely lead wrong conclusion aligned human perception incivility
domain adaption word segmentation po tagging challenging problem chinese lexical processing selftraining one promising solution struggle construct set highquality pseudo training instance target domain previous work usually assumes universal sourcetotarget adaption collect pseudo corpus ignoring different gap target sentence source domain work start joint word segmentation po tagging presenting finegrained domain adaption method model gap accurately measure gap one simple intuitive metric adopt develop pseudo target domain corpus based finegrained subdomains incrementally novel domainmixed representation learning model proposed accordingly encode multiple subdomains effectively whole process performed progressively corpus construction model training experimental result benchmark dataset show method gain significant improvement vary baseline extensive analysis performed show advantage final domain adaption model well
article revisits statistical relationship across romance cognate lexical semantic shift six intralinguistic variable frequency polysemy cognate word derived common etymon case latin ancestor despite shared etymology cognate pair experienced semantic shift degree semantic shift quantified using cosine distance cognate corresponding word embeddings previous literature frequency polysemy reported correlated semantic shift however understanding effect need revision various methodological defect present study perform regression analysis improved experimental condition demonstrate genuine negative effect frequency positive effect polysemy semantic shift furthermore reveal morphologically complex etymon resistant semantic shift cognate use longer timespan prone greater shift meaning finding add understanding historical process semantic change
neural vector representation ubiquitous throughout subfields nlp word vector studied much detail thus far little light shed property sentence embeddings paper assess extent prominent sentence embedding method exhibit select semantic property propose framework generate triplet sentence explore change syntactic structure semantics given sentence affect similarity obtained sentence embeddings
description moz translation support system designed text exhibiting high proportion structured semistructured terminological content system comprises webbased collaborative translation memory high recall via subsentential linguistic analysis facility messaging quality assurance production use translating word per week
monitoring development labor market skill requirement information need approached applying text mining method job advertisement data present approach finegrained extraction classification skill requirement germanspeaking job advertisement adapt pretrained transformerbased language model domain task computing meaningful representation sentence span using context job advertisement large esco domain ontology improve similaritybased unsupervised multilabel classification result best model achieves mean average precision skill class level
reported work straightforward approach shared task classification tweet selfreporting age organized social medium mining health application smmh workshop literature describes approach used build binary classification system classifies tweet related birthday post two class namely exact agepositive class nonexact agenegative class made two submission variation preprocessing text yielded f score evaluated organizer
present deep learning based information extraction system extract design result published abstract describing randomized controlled trial rct contrast approach system regard pico element flat object label structured object thus model task one filling set template slot twostep approach recognizes relevant slot candidate first step assigns corresponding template second step relying learned pairwise scoring function model compatibility different slot value evaluate approach dataset manually annotated abstract type diabetes glaucoma showing positive impact modelling intratemplate entity compatibility main benefit approach yield structured object every rct abstract support aggregation summarization clinical trial result across published study facilitate task creating systematic review metaanalysis
speechtospeech translation typical sequencetosequence learning task naturally two direction effectively leverage bidirectional supervision signal produce highfidelity audio direction existing approach either train two separate model multitasklearned model low efficiency inferior performance paper propose duplex diffusion model applies diffusion probabilistic model side reversible duplex conformer either end simultaneously input output distinct language speech model enables reversible speech translation simply flipping input output end experiment show model achieves first success reversible speech translation significant improvement asrbleu score compared list stateoftheart baseline
conventional approach event detection usually require fixed set predefined event type requirement often challenged realworld application new event continually occur due huge computation cost storage budge infeasible store previous data retrain model previous data new data every time new event arrive formulate challenging scenario incremental event detection requires model learn new class incrementally without performance degradation previous class however existing incremental learning method handle semantic ambiguity training data imbalance problem old new class task incremental event detection paper propose knowledge consolidation network kcn address issue specifically devise two component prototype enhanced retrospection hierarchical distillation mitigate adverse effect semantic ambiguity class imbalance respectively experimental result demonstrate effectiveness proposed method outperforming stateoftheart model whole f score ace benchmark tac kbp benchmark respectively
recent study shown remarkable success crossdomain named entity recognition crossdomain ner despite promising result existing method mainly utilize pretraining language model like bert represent word original chaotic representation may challenge distinguish entity type entity leading entity type misclassification end attempt utilize contrastive learning refine original representation propose modelagnostic framework named mocl crossdomain ner additionally respectively combine mocl two distinctive crossdomain ner method two pretraining language model explore generalization ability empirical result seven domain show effectiveness good generalization ability mocl
natural question generation qg aim generate question passage generated question answered passage model stateoftheart performance model previously generated text decoding step however ignore rich structure information hidden previously generated text ignore impact copied word passage perceive information previously generated word serf auxiliary information subsequent generation address problem design iterative graph networkbased decoder ignd model previous generation using graph neural network decoding step moreover graph model capture dependency relation passage boost generation experimental result demonstrate model outperforms stateoftheart model sentencelevel qg task squad marco datasets
introduce new benchmark assessing quality texttotext model polish benchmark consists diverse task datasets klej benchmark adapted texttotext enpl translation summarization question answering particular since summarization question answering lack benchmark datasets polish language describe detail construction make publicly available additionally present plt generalpurpose texttotext model polish finetuned various natural language processing nlp task single training objective unsupervised denoising pretraining performed efficiently initializing model weight multilingual mt counterpart evaluate performance plt mt polish bart plbart polish gpt papugapt plt score top task except summarization plbart best general except summarization larger model better result encoderdecoder architecture prove better decoderonly equivalent
interpretation lexical aspect verb english play crucial role task recognizing textual entailment learning discourselevel inference show two elementary dimension aspectual class state v event telic v atelic event modelled effectively distributional semantics find verb local context indicative aspectual class demonstrate closed class word tend stronger discriminating context content word approach outperforms previous work three datasets present new dataset humanhuman conversation annotated lexical aspect present experiment show correlation telicity genre discourse goal
summarization system make numerous decision summary property inference eg degree copying specificity length output etc however implicitly encoded within model parameter specific style enforced address introduce hydrasum new summarization architecture extends single decoder framework current model mixtureofexperts version multiple decoder show hydrasums multiple decoder automatically learn contrasting summary style trained standard training objective without extra supervision experiment three summarization datasets cnn newsroom xsum show hydrasum provides simple mechanism obtain stylisticallydiverse summary sampling either individual decoder mixture outperforming baseline model finally demonstrate small modification gating strategy training enforce even stricter style partitioning eg high v lowabstractiveness high v lowspecificity allowing user sample larger area generation space vary summary style along multiple dimension
present system investigation computational property categorial grammar parsing based labelled analytic tableau theorem prover proof method allows u take modular approach basic grammar kept constant range categorial calculus captured assigning different property labelling algebra theorem proving strategy particularly well suited treatment categorial grammar allows u distribute computational cost algorithm deal grammatical type algebraic checker constrains derivation
argument synthesis aim generate rational claim representing fundamental objective field existing model excel summarizing argument engaging debate observe critical gap ability generate accurate argument incorporate forwardlooking perspective light observation paper introduces novel task called forwardlooking claim planning delve task exploring efficacy wellperforming classification generation model furthermore propose several customized preprocessing method yield substantial performance improvement comprehensive discussion analysis also outline future research agenda forwardlooking claim planning task
ambiguity inherent opendomain question answering especially exploring new topic difficult ask question single unambiguous answer paper introduce ambigqa new opendomain question answering task involves finding every plausible answer rewriting question one resolve ambiguity study task construct ambignq dataset covering question nqopen existing opendomain qa benchmark find half question nqopen ambiguous diverse source ambiguity event entity reference also present strong baseline model ambigqa show benefit weakly supervised learning incorporates nqopen strongly suggesting new task data support significant future research effort data baseline available urlhttpsnlpcswashingtoneduambigqa
recent work show large language model prompted generate useful rationale commonsense question answering cqa improve performance model however cost deployment tuning relatively expensive large model work explores distill rationalegeneration ability convenient smallsized model yet typically requires humanauthored qa instance distillation paper propose novel framework leverage knowledge graph large language model synthesize rationaleaugmented cqa data based train leros model generate helpful rationale assist generic qa model accomplish unseen cqa task empirical result demonstrate leros substantially enhance performance qa model five unseen cqa benchmark providing better gain samesized counterpart model trained downstream data x larger language model work reveals novel way integrate knowledge knowledge graph large language model smaller model code synthesized resource publicly available httpsgithubcomwchrepoleros
embeddings entity large knowledge base eg wikipedia highly beneficial solving various natural language task involve real world knowledge paper present wikipediavec pythonbased opensource tool learning embeddings word entity wikipedia proposed tool enables user learn embeddings efficiently issuing single command wikipedia dump file argument also introduce webbased demonstration tool allows user visualize explore learned embeddings experiment tool achieved stateoftheart result kore entity relatedness dataset competitive result various standard benchmark datasets furthermore tool used key component various recent study publicize source code demonstration pretrained embeddings language urlhttpswikipediavecgithubio
survey paper analyzing bias nlp system finding motivation often vague inconsistent lacking normative reasoning despite fact analyzing bias inherently normative process find paper proposed quantitative technique measuring mitigating bias poorly matched motivation engage relevant literature outside nlp based finding describe beginning path forward proposing three recommendation guide work analyzing bias nlp system recommendation rest greater recognition relationship language social hierarchy encouraging researcher practitioner articulate conceptualization biasie kind system behavior harmful way well normative reasoning underlying statementsand center work around lived experience member community affected nlp system interrogating reimagining power relation technologist community
latent structure model powerful tool modeling compositional data discovering linguistic structure building nlp pipeline appealing two main reason allow incorporating structural bias training leading accurate model allow discovering hidden linguistic structure provides better interpretability tutorial cover recent advance discrete latent structure model discus motivation potential limitation explore detail three strategy designing model gradient approximation reinforcement learning endtoend differentiable method highlight connection among method enumerating strength weakness model present analyze applied wide variety nlp task including sentiment analysis natural language inference language modeling machine translation semantic parsing example evaluation covered throughout attending tutorial practitioner better informed method best suited problem
dialogue act tagging iso standard difficult task involves multilabel text classification across diverse set label covering semantic syntactic pragmatic aspect dialogue lack adequately sized training set annotated standard major problem using standard practice work propose neural architecture increase classification accuracy especially lowfrequency finegrained tag model take advantage hierarchical structure iso taxonomy utilises syntactic information form partofspeech dependency tag addition contextual information previous turn train architecture aggregated corpus conversation different domain provides variety dialogue interaction linguistic register approach achieves stateoftheart tagging result dialogbank benchmark data set providing empirical evidence architecture successfully generalise different domain
argument mining achieved significant success classifying argumentative relation statement support attack neutral limited computational understanding logical mechanism constitute relation recent study rely blackbox model linguistically insightful desired hand earlier study use rather simple lexical feature missing logical relation statement overcome limitation work classifies argumentative relation based four logical theoryinformed mechanism two statement namely factual consistency ii sentiment coherence iii causal relation iv normative relation demonstrate operationalization logical mechanism classifies argumentative relation without directly training data labeled relation significantly better several unsupervised baseline demonstrate mechanism also improve supervised classifier representation learning
simultaneous training multitask learning network different domain task always straightforward could lead inferior performance generalization compared corresponding singletask network effective training scheduling method deemed necessary maximize benefit multitask learning traditional scheduler follow heuristic prefixed strategy ignoring relation task sample complexity state emergent shared feature proposed deep qlearning scheduler qls monitor state task shared feature using novel histogram task uncertainty trialanderror learns optimal policy task scheduling extensive experiment multidomain multitask setting various task difficulty profile conducted proposed method benchmarked scheduler superior performance demonstrated result discussed
paper offer indepth overview team odiagens translation system submitted workshop asian translation wat focus lie domain indic multimodal task specifically targeting english hindi english malayalam english bengali translation system us stateoftheart transformerbased architecture specifically nllb model finetuned languagespecific visual genome datasets robust system able manage texttotext multimodal translation demonstrating versatility handling different translation mode result showcase strong performance across board particularly promising result hindi bengali translation task noteworthy achievement system lie stellar performance across texttotext translation task category english hindi english bengali english malayalam translation system claimed top position evaluation challenge set system advance understanding challenge nuance indic language translation also open avenue future research enhance translation accuracy performance
paper present identification formulaic sequence reference corpus spoken slovenian annotation term syntactic structure pragmatic function lexicographic relevance annotation campaign specific term setting subjectivity multifunctionality item investigation resulted preliminary lexicon formulaic sequence spoken slovenian immediate potential future exploration formulaic language research especially relevant notable number identified multiword expression discoursestructuring stancemarking function often overlooked traditional phraseology research
paper outline submission semeval task competition brainteaser novel task defying common sense engage subtasks subtask asentence puzzle subtask bword puzzle evaluate plethora pretrained transformerbased language model different size finetuning subsequently undertake analysis score response aid future researcher understanding utilizing model effectively topperforming approach secured competitive position competition leaderboard across subtasks evaluation phase best submission attained average accuracy score sentence puzzle word puzzle significantly outperforming best neural baseline chatgpt respectively
despite widely successful application bootstrapping finetuning semantic parser still tedious process challenge costly data annotation privacy risk paper suggest alternative humanintheloop methodology learning semantic parser directly user semantic parser introspective uncertainty prompt user demonstration uncertain also get imitate user behavior continue improving autonomously hope eventually may become good user interpreting question combat sparsity demonstration propose novel annotationefficient imitation learning algorithm iteratively collect new datasets mixing demonstrated state confident prediction retrains semantic parser dataset aggregation fashion ross et al provide theoretical analysis cost bound also empirically demonstrate promising performance texttosql problem code available urlhttpsgithubcomsunlabosumisp
national ground intelligence center ngic collect massive quantity textual data foreign language support exploitation light intelligence requirement triage process must applied data requirement emerge identify useful data exploitation machine translation provides critical support triage paper outline type collected data different challenge present machine translation well type triage support collection nature issue raised machine translation us
parseme parsing multiword expression project proposes multilingual corpus annotated multiword expression mwes case study focus turkish corpus parseme turkish agglutinative language show high inflection derivation word form cause issue term automatic morphosyntactic annotation provide overview problem observed morphosyntactic annotation turkish parseme corpus issue mostly observed lemma important approximation type mwe propose modification original corpus enhancement lemma part speech enhancement evaluated identification system parseme shared task detect mwes namely seenseen result show increase fmeasure mwe identification emphasizing necessity robust morphosyntactic annotation mwe processing especially language show high surface variability
empathy link self others detecting understanding empathy key element improving humanmachine interaction however annotating data detecting empathy large scale challenging task paper employ multitask training knowledge distillation incorporate knowledge available resource emotion sentiment detect empathy natural language different domain approach yield better result existing newsrelated empathy dataset compared strong baseline addition build new dataset empathy prediction finegrained empathy direction seeking providing empathy twitter release dataset research purpose
australian national corpus established effort make currently scattered relatively inaccessible data available researcher online portal contrast national corpus conceptualised linked collection many existing future language resource representing language use australia unified common technical standard approach allows u bootstrap significant collection add value existing resource providing unified online toolset support research number discipline paper provides outline technical platform developed support corpus brief overview collection form part initial version australian national corpus
field grammatical error correction gec produced various system deal focused phenomenon general text editing propose automatic way combine blackbox system method automatically detects strength system combination several system per error type improving precision recall optimizing fscore directly show consistent improvement best standalone system configuration tested approach also outperforms average ensembling different rnn model random initialization addition analyze use bert gec reporting promising result end also present spellchecker created task outperforms standard spellcheckers tested task spellchecking paper describes system submission building educational application shared task grammatical error correction combining output top bea shared task system using approach currently hold highest reported score open phase bea shared task improving f score point best result reported
despite improvement performance different natural language generation task deep neural model prone hallucinating fact incorrect nonexistent different hypothesis proposed examined separately different task systematic explanation available across task study draw connection hallucination predictive uncertainty conditional language generation investigate relationship image captioning datatotext generation propose simple extension beam search reduce hallucination analysis show higher predictive uncertainty corresponds higher chance hallucination epistemic uncertainty indicative hallucination aleatoric total uncertainty help achieve better result trading performance standard metric less hallucination proposed beam search variant
automatic summarisation potential aid physician streamlining clerical task note taking notoriously difficult evaluate system demonstrate safe used clinical setting circumvent issue propose semiautomatic approach whereby physician postedit generated note submitting conduct preliminary study time saving automatically generated consultation note postediting evaluator asked listen mock consultation postedit three generated note time find faster writing note scratch present insight lesson learnt experiment
multilingual bert mbert trained language shown surprisingly good crosslingual performance several nlp task even without explicit crosslingual signal however evaluation focused crosslingual transfer highresource language covering third language covered mbert explore mbert performs much wider set language focusing quality representation lowresource language measured withinlanguage performance consider three task named entity recognition language partofspeech tagging dependency parsing language mbert better comparable baseline high resource language much worse low resource language furthermore monolingual bert model language even worse paired similar language performance gap monolingual bert mbert narrowed find better model low resource language require efficient pretraining technique data
paper aim introducing novel model documentlevel neural machine translation instead head back original transformer model hope answer following question capacity current model strong enough documentlevel translation interestingly observe original transformer appropriate training technique achieve strong result document translation even length word evaluate model several recent approach nine documentlevel datasets two sentencelevel datasets across six language experiment show documentlevel transformer model outperforms sentencelevel one many previous method comprehensive set metric including bleu four lexical index three newly proposed assistant linguistic indicator human evaluation
paper address unique challenge associated uncertainty quantification ai model applied patientfacing context within healthcare unlike traditional explainable artificial intelligence xai method tailored model developer domain expert additional consideration communicating natural language presentation evaluating understandability necessary identify challenge communication model performance confidence reasoning unknown knowns using natural language context risk prediction propose design aimed addressing challenge focusing specific application invitro fertilisation outcome prediction
paper tackle task named entity recognition ner applied digitized historical text obtained processing digital image newspaper using optical character recognition ocr technique argue main challenge task ocr process lead misspelling linguistic error output text moreover historical variation present aged document impact performance ner process conduct comparative evaluation two historical datasets german french previous stateoftheart model propose model based hierarchical stack transformer approach ner task historical data finding show proposed model clearly improves result historical datasets degrade result modern datasets
neural dialogue generation model trained onehot target distribution suffer overconfidence issue lead poor generation diversity widely reported literature although existing approach label smoothing alleviate issue fail adapt diverse dialog context paper propose adaptive label smoothing adalabel approach adaptively estimate target label distribution time step different context maximum probability predicted distribution used modify soft target distribution produced novel lightweight bidirectional decoder module resulting target distribution aware previous future context adjusted avoid overtraining dialogue model model trained endtoend manner extensive experiment two benchmark datasets show approach outperforms various competitive baseline producing diverse response
wecantalk wct corpus new multilanguage multimodal resource speaker recognition corpus contains cantonese mandarin english telephony video speech data multilingual speaker located hong kong speaker contributed least telephone conversation minute duration collected via custom telephone platform based hong kong speaker also uploaded least video speaking visible along one selfie image least half call video speaker cantonese remaining recording featured one different language call video made variety noise condition speech video recording audited experienced multilingual annotator quality including presence expected language speaker identity wecantalk corpus used support nist speaker recognition evaluation published ldc catalog
advent internet amount semantic web document describe realworld entity interlinks set statement grown considerably description usually lengthy make utilization underlying entity difficult task entity summarization aim create summary realworld entity gained increasing attention recent year paper propose probabilistic topic model eslda combine prior knowledge statistical learning technique within single framework create reliable representative summary entity demonstrate effectiveness approach conducting extensive experiment show model outperforms stateoftheart technique enhances quality entity summary
paper present paladin opensource webbased annotation tool creating highquality multilabel documentlevel datasets integrating active learning proactive learning annotation task paladin make task less timeconsuming requiring less human effort although paladin designed multilabel setting system flexible adapted task singlelabel setting
making right connection hinge linking data disparate source frequently link may person place something simple mistranslated name cause search miss relevant document swiftly accurately exploit growing flood foreign language information acquired defense nation intelligence community ic linguist analyst need assistance translation accuracy productivity name translation standardizing component computeraided translation cat tool highlight language analysis suite ensures fast reliable translation name arabic dari farsi pashto according number government transliteration standard highlight improves efficiency maximizes utilization scarce human resource
paper present farasa meaning insight arabic fast accurate arabic segmenter segmentation involves breaking arabic word constituent clitics approach based svmrank using linear kernel feature utilized account likelihood stem prefix suffix combination presence lexicon containing valid stem named entity underlying stem template farasa outperforms equalizes stateoftheart arabic segmenters namely qatara madamira meanwhile farasa nearly one order magnitude faster qatara two order magnitude faster madamira segmenter able process one billion word less hour farasa written entirely native java external dependency opensource
semantic parsing play key role digital voice assistant alexa siri google assistant mapping natural language structured meaning representation want improve capability voice assistant adding new domain underlying semantic parsing model need retrained using thousand annotated example new domain timeconsuming expensive work present architecture perform domain adaptation automatically small amount metadata new domain without new training data zeroshot example fewshot use base seqseq sequencetosequence architecture augment concept encoder encodes intent slot tag new domain also introduce novel decoderfocused approach pretrain seqseq model concept aware using wikidata use help model learn important concept perform well lowresource setting report fewshot zeroshot result compositional semantic parsing topv dataset show model outperforms prior approach fewshot setting topv snip datasets
protecting large language model privacy leakage becoming increasingly crucial wide adoption realworld product yet applying differential privacy dp canonical notion provable privacy guarantee machine learning model model remains challenging due tradeoff model utility privacy loss utilizing fact sensitive information language data tends sparse shi et al formalized dp notion extension called selective differential privacy sdp protect sensitive token defined policy function however algorithm work rnnbased model paper develop novel framework finetune twice jft achieves sdp stateoftheart large transformerbased model method easy implement first finetunes model redacted indomain data finetunes original indomain data using private training mechanism furthermore study scenario imperfect implementation policy function miss sensitive token develop systematic method handle experiment show method achieves strong utility compared previous baseline also analyze sdp privacy guarantee empirically canary insertion attack
work explore whether recently demonstrated zeroshot ability model extend named entity recognition outofdistribution language time period using historical newspaper corpus language testbed use prompt extract possible named entity result show naive approach promptbased zeroshot multilingual named entity recognition errorprone highlight potential approach historical language lacking labeled datasets moreover also find tlike model probed predict publication date language document could relevant study historical text
present team scubeds approach c citation context classification task subtask b citation context influence classification approach relies text based feature transformed via tfidf feature followed training variety simple model resulting strong baseline best model leaderboard random forest classifier using citation context text replication analysis find logistic regression gradient boosted tree classifier best performing model submission code found urlhttpsgithubcomnapsternxgcitationcontextclassification
embedllama assessment metric language translation hinge upon utilization recently introduced llama large language model llm specifically focusing embedding layer aim transforming sentence vector space establishes connection geometric semantic proximity
paper describes ongoing work aiming adding pronunciation information lexical semantic resource focus open wordnet goal add new modality semantic network also mark heteronym listed pronunciation information associated different meaning work could contribute longer term disambiguation multimodal resource combining text speech
evaluation recent embeddingbased evaluation metric text generation primarily based measuring correlation human evaluation standard benchmark however benchmark mostly similar domain used pretraining word embeddings raise concern lack generalization embeddingbased metric new noisy domain contain different vocabulary pretraining data paper examine robustness bertscore one popular embeddingbased metric text generation show embeddingbased metric highest correlation human evaluation standard benchmark lowest correlation amount input noise unknown token increase b taking embeddings first layer pretrained model improves robustness metric c highest robustness achieved using characterlevel embeddings instead tokenbased embeddings first layer pretrained model
although deep learning model brought tremendous advancement field opendomain dialogue response generation recent research result revealed trained model undesirable generation behavior malicious response generic boring response work propose framework named negative training minimize behavior given trained model framework first find generated sample exhibit undesirable behavior use feed negative training signal finetuning model experiment show negative training significantly reduce hit rate malicious response discourage frequent response improve response diversity
humanassisting system dialogue system must take thoughtful appropriate action clear unambiguous user request also ambiguous user request even user aware potential requirement construct dialogue agent collected corpus developed model classifies ambiguous user request corresponding system action order collect highquality corpus asked worker input antecedent user request whose predefined action could regarded thoughtful although multiple action could identified thoughtful single user request annotating combination user request system action impractical reason fully annotated test data left annotation training data incomplete order train classification model training data applied positiveunlabeled pu learning method assumes part data labeled positive example experimental result show pu learning method achieved better performance general positivenegative pn learning method classify thoughtful action given ambiguous user request
nonindexed part internet darknet become legal illegal anonymous activity given magnitude network scalably monitoring activity necessarily relies automated tool notably nlp tool however little known characteristic text communicated darknet well offtheshelf nlp tool domain paper tackle gap performs indepth investigation characteristic legal illegal text darknet comparing clear net website similar content control condition taking drugsrelated website test case find text selling legal illegal drug several linguistic characteristic distinguish one another well control condition among distribution po tag coverage named entity wikipedia
paper describes submission iwslt lowresource speech translation shared task ims team utilize stateoftheart model combined several data augmentation multitask transfer learning approach automatic speech recognition asr machine translation mt step cascaded system moreover also explore feasibility full endtoend speech translation st model case constrained amount ground truth labeled data best system achieves best performance among submitted system congolese swahili english french bleu score respectively second best result coastal swahili english bleu score
introduce manually annotated syntactic treebank based universal dependency derived written data second language l korean learner developing new dataset critically evaluated previous work revised annotation guideline better reflect linguistic property korean characteristic l learner l korean treebank encompasses sentence word morpheme publicly available httpsgithubcomnlpxlkoreanlkwcorpus
traditional generative dialogue model generate response solely input query information insufficient generating specific response since certain query could answered multiple way recently researcher attempted fill information gap exploiting information retrieval technique given query similar dialogue retrieved entire training data considered additional knowledge source use retrieval may harvest extensive information generative model could overwhelmed leading unsatisfactory performance paper propose new framework exploit retrieval result via skeletontoresponse paradigm first skeleton extracted retrieved dialogue generated skeleton original query used response generation via novel response generator experimental result show approach significantly improves informativeness generated response
selectional preference sp commonly observed language phenomenon proved useful many natural language processing task provide better evaluation method sp model introduce spk largescale evaluation set provides human rating plausibility sp pair five sp relation covering frequent verb noun adjective american english three representative sp acquisition method based pseudodisambiguation evaluated spk demonstrate importance dataset investigate relationship spk commonsense knowledge conceptnet show potential using sp represent commonsense knowledge also use winograd schema challenge prove proposed new sp relation essential hard pronoun coreference resolution problem
study recruited elder aged discus daily activity focus group transcribed discourse analyzed using chinese version liwc lin et al pennebaker et al cognitive complexity dynamic language well content word related elder daily activity interruption behavior conversation also coded analyzed controlling education gender age result showed cognitive flexibility performance accompanied increasing adoption dynamic language insight word family word finding serve basis predicting elder cognitive flexibility daily language use
large language model llm shown significant promise various task including identifying political belief englishspeaking social medium user post however assessing llm task nonenglish language remains unexplored work ask extent llm predict political ideology user persian social medium answer question first acknowledge political party welldefined among persian user therefore simplify task much simpler task hyperpartisan ideology detection create new benchmark show potential limitation opensource commercial llm classifying hyperpartisan ideology user compare model smaller finetuned model persian language parsbert translated data roberta showing considerably outperform generative llm task demonstrate performance generative llm degrades classifying user based tweet instead bios even tweet added additional information whereas smaller finetuned model robust achieve similar performance class study first step toward political ideology detection persian twitter implication future research understand dynamic ideology persian social medium
phrase representation derived bert often exhibit complex phrasal compositionality model relies instead lexical similarity determine semantic relatedness paper propose contrastive finetuning objective enables bert produce powerful phrase embeddings approach phrasebert relies dataset diverse phrasal paraphrase automatically generated using paraphrase generation model well largescale dataset phrase context mined book corpus phrasebert outperforms baseline across variety phraselevel similarity task also demonstrating increased lexical diversity nearest neighbor vector space finally case study show phrasebert embeddings easily integrated simple autoencoder build phrasebased neural topic model interprets topic mixture word phrase performing nearest neighbor search embedding space crowdsourced evaluation demonstrate phrasebased topic model produce coherent meaningful topic baseline word phraselevel topic model validating utility phrasebert
paper aim classify different offensive content type codemixed dravidian language datasets work leverage existing state art approach text classification incorporating additional data transfer learning pretrained model final submission ensemble awdlstm based model along different transformer model architecture based bert roberta achieved weightedaverage f score malayalamenglish tamilenglish kannadaenglish datasets ranking st nd rd respective sharedtask leaderboards
preserving structural property tree graph embedding metric space allows high degree interpretability shown beneficial downstream task eg hypernym detection natural language inference multimodal retrieval however whereas majority prior work look using structurepreserving embeddings encoding structure given input eg wordnet fellbaum little exploration use embeddings predicting one address gap two structure generation task namely dependency semantic parsing test applicability disk embeddings suzuki et al proposed embedding directed acyclic graph dag tested task generate structure experimental result show task original disk embedding formulation lead much worse performance compared nonstructurepreserving baseline propose enhancement formulation show almost close performance gap dependency parsing however gap still remains notable semantic parsing due complexity meaning representation graph suggesting challenge generating interpretable semantic parse representation
paper investigates state art automatic textual annotation tool examines extent ready use real world define benchmarking criterion measuring usability annotation tool examine factor particularly important real user able determine suitable tool use discus factor usability accessibility interoperability scalability evaluate set annotation tool according factor finally draw conclusion current state research annotation make suggestion future
medical question answering system gained significant attention recent year due potential enhance medical decisionmaking improve patient care however research field focused englishlanguage datasets limiting generalizability mqa system nonenglish speaking region study introduces aramed largescale arabic medical question answering dataset addressing limited resource available arabic medical question answering aramed comprises k questionanswer pair based health consumer question submitted online medical forum experiment using various deep learning model showcase datasets effectiveness particularly arabert model achieving highest result specifically arabertv obtained f score answer selection task comparative analysis different deep learning model provides insight strength limitation finding highlight potential aramed advancing arabic medical question answering research development
probing neural model ability perform downstream task using activation pattern often used localize part network specialize performing task however little work addressed potential mediating factor comparison testcase mediating factor consider prediction context length namely length span whose processing minimally required perform prediction show controlling context length may lead contradictory conclusion localization pattern network depending distribution probing dataset indeed probing bert seven task find possible get different ranking manipulating distribution context length probing dataset conclude presenting best practice conducting comparison future
natural language processing model often exploit spurious correlation taskindependent feature label datasets perform well within distribution trained generalising different task distribution propose tackle problem generating debiased version dataset used train debiased offtheshelf model simply replacing training data approach consists method training data generator generate highquality labelconsistent data sample filtering mechanism removing data point contribute spurious correlation measured term zstatistics generate debiased version snli mnli datasets evaluate large suite debiased outofdistribution adversarial test set result show model trained debiased datasets generalise better trained original datasets setting majority datasets method outperforms performs comparably previous stateoftheart debiasing strategy combined orthogonal technique productofexperts improves outperforms previous best result snlihard mnlihard
n paper outline methodology adopted develop framenet italian main element novelty respect original framenet represented fact creation annotation lexical unit strictly grounded distributional information statistical distribution verbal subcategorization frame lexical semantic preference frame automatically acquired large dependencyparsed corpus claim approach allows u overcome shortcoming classical lexicographic method used create framenet complementing accuracy manual annotation robustness data global distributional pattern verb paper describe method extracting distributional data corpus way used encoding annotation lu longterm goal project create electronic lexicon italian similar original english framenet moment developed database syntactic valence made freely accessible via web interface represents autonomous resource besides framenet lexicon beginning nucleus consisting annotated sentence
evaluation speech intelligibility based read passage often used clinical situation assess impact disease andor treatment spoken communication although scalebased measure often used clinical setting measure susceptible listener response bias automatic evaluation tool developed response drawback perceptual evaluation however large corpus judged listener needed improve test tool end nkiccrt corpus individual listener judgement intelligibility recording speaker treated cancer head neck made available restricted scientific use corpus contains recording perceptual evaluation speech intelligibility three evaluation moment treatment treatment week month treatment mean chemoradiotherapy ccrt thirteen recently graduated speech pathologist rated speech intelligibility recording point scale information recording perceptual evaluation procedure presented addition preliminary rater reliability agreement information preliminary result show many speaker speech intelligibility rated low cancer treatment
report result experiment using bart lewis et al penn discourse tree bank webber et al pdtb generate text correctly realized discourse relation address question left open previous research yung et al ko li concerning whether conditioning model intended discourse relationwhich corresponds adding explicit discourse relation information input modelimproves performance result suggest including discourse relation information input model significantly improves consistency produce correctly realized discourse relation output compare model performance known result concerning discourse structure found written text possible explanation term discourse interpretation strategy hypothesized psycholinguistics literature finding suggest natural language generation model based current pretrained transformer benefit infusion discourse level information aim construct discourse intended relation
granularity polnet polish wordnet main theoretical issue discussed paper describe latest extension polnet including valency information simple verb nounverb collocation using manual machineassisted method valency defined include semantic syntactic selectional restriction assume valency structure verb index meaning consistently consider attribute synset strict application principle result fine granularity verb section wordnet considering valency distinctive feature synset essential step transform initial polnet first intended lexical ontology lexicongrammar present refinement polnet assume category language register part meaning totality polnet synset revised order split polnet synset contain different register word registeruniform subsynsets completed operation synset used value semantic role operation augmented number considered synset paper report extension class collocationbased verb synset
remarkable capability natural language model grasp language subtlety paved way widespread adoption diverse field however adapting specific task requires timeconsuming process finetuning consumes significant computational power energy therefore optimizing finetuning time advantageous study propose alternate approach limit parameter manipulation select layer exploration led identifying layer offer best tradeoff time optimization performance preservation validated approach multiple downstream task result demonstrated potential reduce finetuning time maintaining performance within negligible deviation less research showcase promising technique significantly improving finetuning efficiency without compromising task domainspecific learning capability
increase use web data corpusbuilding coupled use specialist singleuse corpus make increasing reliance language change quickly affecting longterm validity study based method drift time affect user opensource corpus attempting interpret result study based web data attrition document online also called link rot document halflife studied many time purpose optimising search engine web crawler producing robust reliable archival system ensuring integrity distributed information store however affect attrition upon corpus varying construction remains largely unknown paper present preliminary investigation difference attrition rate corpus selected using different corpus construction method represents first step larger longitudinal analysis present uribased content clue chosen relate study area ultimate goal larger study produce detailed enumeration primary bias online identify sampling strategy control minimise unwanted effect document attrition
modern ml system ingest data aggregated diverse source synthetic humanannotated live customer traffic understanding textitwhich example important performance learning algorithm crucial efficient model training recently growing body literature given rise various influence score use training artifact model confidence checkpointed gradient identify important subset data however method primarily developed computer vision setting remains unclear well generalize languagebased task using pretrained model paper explore applicability influence score language classification task evaluate diverse subset score snli dataset quantifying accuracy change response pruning training data random influencescorebased sampling stresstest one score variance gradient vog agarwal hooker nlu model stack exposed dynamic user speech pattern voice assistant type setting experiment demonstrate many case encoderbased language model finetuned roughly original data without degradation performance metric along way summarize lesson learned applying outofthebox implementation influence score quantify effect noisy classimbalanced data offer recommendation scorebased sampling better accuracy training efficiency
weighted pushdown automaton wpdas core many natural language processing task like syntaxbased statistical machine translation transitionbased dependency parsing existing dynamic programming algorithm designed contextfree grammar cfgs algorithm pda often resort pdatocfg conversion paper develop novel algorithm operate directly wpdas algorithm inspired langs algorithm use general definition pushdown automaton either reduce space requirement factor gamma size stack alphabet reduce runtime factor q number state run class pda langs algorithm algorithm spaceefficient factor gamma timeefficient factor q x gamma
present semantic textual similarity approach filtering noisy web crawled parallel corpus using yisia novel semantic machine translation evaluation metric system mainly based supervised approach perform well wmt parallel corpus filtering shared task th place millionword evaluation th place millionword evaluation th place overall submission fact best performing systemnrcyisibicov one four submission ranked top evaluation submitted system also include initial filtering step scaling size test corpus final redundancy removal step better semantic token coverage filtered corpus paper also describe unsuccessful attempt automatically synthesizing noisy parallel development corpus tuning weight combine different parallelism fluency feature
knowledge distillation kd offer natural way reduce latency memoryenergy usage massive pretrained model come dominate natural language processing nlp recent year numerous sophisticated variant kd algorithm proposed nlp application key factor underpinning optimal distillation performance often confounded remain unclear aim identify different component kd pipeline affect resulting performance much optimal kd pipeline varies across different datasetstasks data augmentation policy loss function intermediate representation transferring knowledge teacher student tease apart effect propose distiller meta kd framework systematically combine broad range technique across different stage kd pipeline enables u quantify component contribution within distiller unify commonly used objective distillation intermediate representation universal mutual information mi objective propose class miobjective function better biasvariance tradeoff estimating mi teacher student diverse set nlp datasets best distiller configuration identified via largescale hyperparameter optimization experiment reveal following approach used distill intermediate representation important factor kd performance among different objective intermediate distillation miperforms best data augmentation provides large boost small training datasets small student network moreover find different datasetstasks prefer different kd algorithm thus propose simple autodistiller algorithm recommend good kd pipeline new dataset
java programming language started language oak world wide web still developed cern gained popularity since launch programming language capable used develop application run across internet well local standalone program many technology associated world wide web lot hype confusion misinformation consequently many researcher area natural language processing machine translation heard java may considering using even got far first hello world applet probably fully aware implication using language possible role could development computational linguistic application either intended run locally wide range computing platform remotely across internet paper set address issue presenting java clear concise fashion considering may used computational linguistic application requirement analysis generic natural language processing machine translation tool undertaken consider java could used subsequently two example system developed java accessed internet introduced finally pointer java resource presented researcher interested using language install learn program
phd investigate process common ground shape pragmatic use referring expression humanrobot interaction central point investigation interplay growing common ground change surrounding context create ambiguity variation need pragmatic interpretation outline three objective define scope work obtaining data common ground interaction examining referencemaking evaluating robot interlocutor use datasets well novel interactive experimental framework investigate linguistic process involved shaping referring expression also design interactive robot model model linguistic process use pragmatic inference resolve referring expression work contribute existing work hri reference resolution study common ground
shared task hateful meme challenge aim detection hateful content meme inviting implementation system understand meme potentially combining image textual information challenge consists three detection task hate protected category attack type first binary classification task two multilabel classification task participation included textbased bert baseline txtbert adding information image imgbert neural retrieval approach also experimented retrieval augmented classification model found ensemble txtbert imgbert achieves best performance term roc auc score two three task development set
people choose particular name object dog puppy given dog object naming studied psycholinguistics received relatively little attention computational linguistics review resource language vision could used study object naming large scale discus shortcoming create new dataset affords opportunity analysis modeling dataset manynames provides name annotation k object image selected visualgenome highlight challenge involved provide preliminary analysis manynames data showing high level agreement naming average time average number name type associated object much higher dataset existing corpus language vision manynames provides rich resource studying phenomenon like hierarchical variation chihuahua v dog discussed length theoretical literature less well studied phenomenon like crossclassification cake v dessert
largescale autoregressive model achieved great success dialogue response generation help transformer layer however model learn representative latent space sentence distribution making hard control generation recent work tried learning sentence representation using transformerbased framework model contextresponse relationship embedded dialogue datasets work aim construct robust sentence representation learning model specifically designed dialogue response generation transformerbased encoderdecoder structure utterancelevel contrastive learning proposed encoding predictive information context representation corresponding response extensive experiment conducted verify robustness proposed representation learning mechanism using referencebased referencefree evaluation metric provide detailed analysis generated sentence demonstrating effectiveness proposed model
research address challenge crosslingual summarization cl lowresource scenario imbalanced multilingual data existing cl study mostly resort pipeline framework multitask method bilingual setting however ignore data imbalance multilingual scenario utilize highresource monolingual summarization data paper propose aligned crosslingual summarization across model tackle issue framework aligns lowresource crosslingual data highresource monolingual data via contrastive consistency loss help enrich lowresource information highquality summary addition introduce data augmentation method select informative monolingual sentence facilitates deep exploration highresource information introduce new information lowresource language experiment crosssum dataset show across outperforms baseline model obtains consistently dominant performance language pair
foundation scientific evaluation laborintensive process peer review critical task requires participant consume vast amount highly technical text prior work annotated different aspect review argumentation discourse relation review rebuttal yet examined present disapere labeled dataset k sentence contained reviewrebuttal pair english annotated expert disapere synthesizes label set prior work extends include finegrained annotation rebuttal sentence characterizing context review author stance towards review argument annotate textitevery review rebuttal sentence show discourse cue rebuttal shed light quality interpretation review understanding argumentative strategy employed reviewer author provides useful signal area chair decision maker
although advancement pretrained large language model significantly accelerated recent progress nlp everincreasing size pose significant challenge conventional finetuning especially memoryintensive task investigate potential parameterefficient finetuning focusing lowrank adaptation lora domain multilingual summarization task challenging due typically long input relatively unexplored conduct extensive study across different data availability scenario including high lowdata setting crosslingual transfer leveraging model different size finding reveal lora competitive full finetuning trained high quantity data excels lowdata scenario crosslingual transfer also study different strategy fewshot crosslingual transfer finding continued lora tuning outperforms full finetuning dynamic composition languagespecific lora module
knowledge based question answering kbqa complex task natural language understanding many kbqa approach proposed recent year trained based labeled reasoning path hinders system performance many correct reasoning path labeled ground truth thus learned paper introduce new concept kbqa system leverage multiple reasoning path information requires labeled answer supervision name textbfmutliple textbfreasoning textbfpaths kbtextbfqa system mrpqa conduct experiment several benchmark datasets containing singlehop simple question well mutihop complex question including webquestionsp wqsp complexwebquestion cwq pathquestionlarge pql demonstrate strong performance
previous stateoftheart model lexical simplification consist complex pipeline several component requires deep technical knowledge finetuned interaction achieve full potential alternative describe frustratingly simple pipeline based prompted gpt response beating competing approach wide margin setting training instance bestperforming submission english language track tsar shared task consists ensemble six different prompt template varying context level latebreaking result detail language transfer technique allows simplification language english applied spanish portuguese subset achieve stateoftheart result minor modification original prompt aside detailing implementation setup spend remainder work discussing particularity prompting implication future work code experiment available online urlhttpsgithubcomdennlingertsarsharedtask
increasing amount biomedical information available researcher clinician make harder quickly find right information automatic summarization multiple text provide summary specific user information need paper look use namedentity recognition graphbased summarization extend lexrank algorithm information named entity present entityrank multidocument graphbased summarization algorithm solely based named entity evaluate system datasets human written summary provided bioasq gene summary fetched entrez gene database result show addition namedentity information increase performance graphbased summarizers entityrank significantly outperforms method regard rouge measure
paper address two practical problem concerning use corpus translation study first stem limited resource available targeted language genre within language whereas translation researcher student need sufficiently large modern corpus either reflecting general language specific problem domain second problem concern lackof uniform interface accessing resource even yexist deal first problem developing framework semiautomatic acquisition large corpus internet language relevant research training need outline methodology used discus composition internetderived corpus deal second problem developing uniform interface corpus addition standard option choosingcorpora sorting concordance line interface compute list collocation filter result according touserspecified pattern order detect languagespecific syntacticstructures
event schema structured knowledge source defining typical realworld scenario eg going airport present framework efficient humanintheloop construction schema library based novel script induction system wellcrafted interface allows nonexperts program complex event structure associated work release schema library machine readable resource detailed event schema describe distinct typical scenario term relevant subevent structure happens scenario participant play role scenario finegrained typing participant implied relational constraint make schema library schemablocks interface available online
large language model llm recently made significant advance code generation chainofthought prompting technique technique empowers model autonomously devise solution plan tackle intricate programming challenge thereby improving performance code generation nevertheless smaller model struggling keep llm deducing plan adversely affecting code generation capability given considerable size associated deployment cost along concern data security many team opt deploying smaller model code generation consequently arises compelling need transferring llm code generation reasoning ability smaller model paper propose codeplan framework aim transfer llm reasoning capability smaller model distillation adopt multitask learning approach jointly undertaking code generation solution plan generation task enhance code generation capability smaller model ensure superior quality solution plan advocate utilization backward reasoning plan sampling strategy experiment show comparison conventional finetuning approach approach improves smaller model code generation performance measured pas metric challenging apps benchmark
recent advancement large language model llm reshaping natural language processing nlp task several domain use field human resource hr still room expansion could beneficial several time consuming task example timeoff submission medical claim filing access request noteworthy mean sole instance however aforementioned development must grapple pivotal challenge constructing highquality training dataset one hand conversation datasets solving problem customer employee hand gathering conversation hr could raise privacy concern solve introduce hrmultiwoz fullylabeled dataset conversation spanning hr domain work following contribution first labeled opensourced conversation dataset hr domain nlp research provides detailed recipe data generation procedure along data analysis human evaluation data generation pipeline transferrable easily adapted labeled conversation data generation domain proposed datacollection pipeline mostly based llm minimal human involvement annotation time costefficient
standard approach hate speech detection rely sufficient available hate speech annotation extending previous work repurposes natural language inference nli model zeroshot text classification propose simple approach combine multiple hypothesis improve english nlibased zeroshot hate speech detection first conduct error analysis vanilla nlibased zeroshot hate speech detection develop four strategy based analysis strategy use multiple hypothesis predict various aspect input text combine prediction final verdict find zeroshot baseline used initial error analysis already outperforms commercial system finetuned bertbased hate speech detection model hatecheck combination proposed strategy increase zeroshot accuracy hatecheck percentage point pp accuracy ethos pp
systematic literature review biomedical space often expensive conduct automation machine learning large language model could improve accuracy research outcome review study evaluate pretrained longt model mslr multidocument summarization literature review shared task datasets werent able make improvement dataset benchmark establish evidence current summarization metric insufficient measuring summarization accuracy multidocument summarization web tool also built demonstrate viability summarization model future investigator urlhttpsbenyugithubiosummarizer
previous work arabic information extraction mainly focused named entity recognition little work done arabic relation extraction event recognition moreover modeling arabic data task straightforward morphological richness idiosyncrasy arabic language propose article first neural joint information extraction system arabic language
propose leverage news discourse profiling model documentlevel temporal structure building temporal dependency graph key observation functional role sentence used profiling news discourse signify different time frame relevant news story therefore help recover global temporal structure document analysis experiment widely used knowledge distillation technique show discourse profiling effectively identifies distant intersentence event time expression pair temporally related otherwise difficult locate
italy exhibit rich linguistic diversity across territory due distinct regional language spoken different area recent advance selfsupervised learning provide new opportunity analyze italy linguistic variety using speech data alone includes potential leverage representation learned large amount data better examine nuance closely related linguistic variety study focus automatically identifying geographic region origin speech sample drawn italy diverse language variety leverage selfsupervised learning model tackle task analyze difference similarity italy regional language also seek uncover new insight relationship among diverse yet closely related variety may help linguist understand interconnected evolution regional development time space improve discriminative ability learned representation evaluate several supervised contrastive learning objective pretraining step additional finetuning objective experimental evidence show pretrained selfsupervised model effectively identify region speech recording additionally incorporating contrastive objective finetuning improves classification accuracy yield embeddings distinctly separate regional variety demonstrating value combining selfsupervised pretraining contrastive learning task
unsupervised consistency training way semisupervised learning encourages consistency model prediction original augmented data named entity recognition ner existing approach augment input sequence token replacement assuming annotation replaced position unchanged paper explore use paraphrasing principled data augmentation scheme ner unsupervised consistency training specifically convert conditional random field crf multilabel classification module encourage consistency entity appearance original paraphrased sequence experiment show method especially effective annotation limited
paper present submitted system wojoodner shared task addressing flat nested arabic named entity recognition ner system based bertbased multitask learning model leverage existing arabic pretrained language model plms encode input sentence enhance performance model employed multitask loss variance penalty combined several training objective including crossentropy loss dice loss tversky loss focal loss besides studied performance three existing arabic plms sentence encoding official test set system obtained microf score flat subtask nested subtask ner respectively ranked th nd position among participating system subtask subtask respectively
text retrieval system often return large set document particularly applied large collection stopping criterion reduce number document need manually evaluated relevance predicting suitable level recall achieved work novel method determining stopping criterion proposed model rate relevant document occur using poisson process method allows user specify minimum desired level recall achieve desired probability achieved evaluate method public dataset compare previous technique determining stopping criterion
existing multilingual machine translation approach mainly focus englishcentric direction nonenglish direction still lag behind work aim build manytomany translation system emphasis quality nonenglish language direction intuition based hypothesis universal crosslanguage representation lead better multilingual translation performance end propose mrasp training method obtain single unified multilingual translation model mrasp empowered two technique contrastive learning scheme close gap among representation different language b data augmentation multiple parallel monolingual data align token representation englishcentric direction mrasp achieves competitive even better performance strong pretrained model mbart ten wmt benchmark nonenglish direction mrasp achieves improvement average bleu compared multilingual baseline
paper present friendsqa challenging question answering dataset contains dialogue opendomain question tackle machine comprehension everyday conversation dialogue involving multiple speaker annotated several type question regarding dialogue context answer annotated certain span dialogue series crowdsourcing task conducted ensure good annotation quality resulting high interannotator agreement comprehensive annotation analytics provided deeper understanding dataset three stateoftheart qa system experimented rnet qanet bert evaluated dataset bert particular depicts promising result accuracy answer utterance selection fscore answer span selection suggesting friendsqa task hard yet great potential elevating qa research multiparty dialogue another level
rhetorical figure play important role influencing reader listener word construct deviate usual language structure known persuasive antithesis one figure combine parallel phrase opposite idea word highlight contradiction identifying figure persuasive actor better identified task create annotated german dataset antithesis detection dataset consists post telegram channel criticizing covid politics germany furthermore propose threeblock pipeline approach detect figure antithesis using large language model pipeline split text phrase identifies phrase syntactically parallel structure detects parallel phrase pair present opposing idea finetuning german electra model stateoftheart deep learning model german language furthermore compare result multilingual bert german bert novel approach outperforms stateoftheart method fscore antithesis detection achieving fscore
generation referring expression re nondeterministic task however algorithm generation re standardly evaluated corpus written text include one per reference goal work firstly reproduce one study taking distributional nature generation account add work introducing method exploring variation human choice basis longitudinal corpus substantial corpus single human judgement process composition per focus prediction type proper name description pronoun compare evaluation made distribution type evaluation made parallel human judgement result show agreement evaluation learning algorithm distribution constructed parallel human evaluation longitudinal data
paper present design result crowdsourcing experiment recognition italian event nominal aim experiment assess feasibility crowdsourcing method complex semantic task distinguishing eventive interpretation polysemous nominal taking consideration various type syntagmatic cue detail theoretical background experiment set provided together final result term accuracy interannotator agreement result compared one obtained expert annotator task low value accuracy fleiss kappa crowdsourcing experiment demonstrate crowdsourcing always optimal complex linguistic task hand use nonexpert contributor allows understand ambiguous pattern polysemy useful syntagmatic cue used identify eventive reading nominal
release new benchmark lexical substitution task finding appropriate substitute target word context writing lexical substitution system assist human suggesting word human easily think however existing benchmark depend human recall source data therefore lack coverage substitute would helpful human furthermore annotator often provide substitute low quality actually appropriate given context collect highercoverage higherquality data framing lexical substitution classification problem guided intuition easier human judge appropriateness candidate substitute conjure memory end use contextfree thesaurus produce candidate rely human judgement determine contextual appropriateness compared previous largest benchmark sword benchmark x many substitute per target word level quality substitute x appropriate based human judgement number substitute
study examines whether attention score token bert model significantly vary based lexical category finetuning process downstream task drawing inspiration notion human language processing syntactic semantic information parsed differently categorize token sentence according lexical category focus change attention score among category hypothesis posit downstream task prioritize semantic information attention score centered content word enhanced case emphasizing syntactic information attention score centered function word intensified experimentation conducted six task glue benchmark dataset substantiate hypothesis regarding finetuning process furthermore additional investigation reveal presence bert layer consistently assign bias specific lexical category irrespective task highlighting existence taskagnostic lexical category preference
paper present methodology developed sli computational linguistics group university vigo building processing cluvi corpus showing tmxbased xml specification designed encode morphosyntactic feature translation alignment parallel corpus solution adopted making cluvi parallel corpus freely available www urlhttpsliuvigoescluvi
paper introduce new distributional method modeling predicateargument thematic fit judgment use syntaxbased dsm build prototypical representation verbspecific role every verb extract salient second order context role ie salient dimension typical role filler compute thematic fit weighted overlap top feature candidate filler role prototype experiment show method consistently outperforms baseline reimplementing stateoftheart system achieves better comparable result reported literature unsupervised system moreover provides explicit representation feature characterizing verbspecific semantic role
translating telephone major goal speech translation many year previous approach attempted work limiteddomain fullyautomatic translation towards broadcoverage fullyautomatic translation approaching problem different direction starting broadcoverage fullyautomatic system working towards full automation believe working direction provide u better feedback observing user collecting language data realistic condition thus may allow rapid progress towards ultimate goal initial approach relies widespread availability internet connection web browser provide user interface describe initial work extension diplomat wearable speech translator
machine learning method financial document analysis focusing mainly textual part however numerical part document also rich information content order analyze financial text assay numeric information depth light purpose research identify linking target cashtag target numeral financial tweet challenging analyzing news official document research developed multi model fusion approach integrates bidirectional encoder representation transformer bert convolutional neural network cnn also encode dependency information behind text model derive semantic latent feature experimental result show model achieve remarkable performance outperform comparison
graphemetophoneme conversion important component many speech technology recently multilingual benchmark task third iteration sigmorphon shared task multilingual graphemetophoneme conversion feature many improvement previous year task ashby et al including additional language three subtasks varying amount available resource extensive quality assurance procedure automated error analysis three team submitted total fifteen system best achieving relative reduction word error rate crosslingual subtask verylow resource subtask generally consistent result crosslingual transfer substantially help graphemetophoneme modeling degree inlanguage example
compositionality ability combine simpler concept understand generate arbitrarily complex conceptual structure long thought cornerstone human language capacity recent notable success neural model various nlp task attention naturally turned compositional capacity model paper study compositional generalization property image captioning model perform set experiment controlled condition using model data ablation designed benchmark particular facet compositional generalization systematicity ability model create novel combination concept observed training productivity operationalised capacity model extend prediction beyond length distribution observed training substitutivity concerned robustness model synonym substitution previous work focused primarily systematicity provide indepth analysis strength weakness state art captioning model finding demonstrate model study compositionally generalize term systematicity productivity however robust degree synonym substitution
paper proposes methodology creation specialized data set textual entailment made monothematic texthypothesis pair ie pair one linguistic phenomenon relevant entailment relation highlighted isolated expected benefit derive intuition investigating linguistic phenomenon separately ie decomposing complexity te problem would yield improvement development specific strategy cope annotation procedure assumes human knowledge linguistic phenomenon relevant inference classification phenomenon fine grained macro category suggested experimented proposed methodology sample pair taken rte data set investigated critical issue arising entailment contradiction unknown pair considered result new resource profitably used advance comprehension linguistic phenomenon relevant entailment judgment make first step towards creation largescale specialized data set
paper report attempt assigning semantic information english framenet lexical unit bulgarian valency lexicon paper briefly present model underlying bulgarian framenet bulframenet lexical entry consists lexical unit semantic frame english framenet expressing abstract semantic structure grammatical class defining inflexional paradigm valency frame describing syntactic lexicalsemantic combinatory property optional component semantically syntactically annotated example target corpusbased lexicon giving exhaustive account semantic syntactic combinatory property extensive number bulgarian lexical unit bulgarian framenet database far contains unique description bulgarian lexical unit approx one tenth aligned appropriate semantic frame support xml import export accessible ie displayed queried via web
paper describes sitaka system used task english arabic language sentiment analysis twitter semeval system proposes representation tweet using novel set feature include bag negated word information provided lexicon polarity tweet determined classifier based support vector machine system rank nd among system arabic language tweet rank th among system englishlanguage tweet
internet forum reddit offer people platform ask advice encounter various issue work school relationship telling helpful comment apart unhelpful comment adviceseeking post help people dialogue agent become helpful offering advice propose dataset contains helpful unhelpful comment response request relate helpfulness closely related construct empathy finally analyze language feature associated helpful unhelpful comment
humantohuman conversation user interlocutor assistance center suppose context conclusion dialog characterize notion success failure explicitly annotated deduced study involves different approach expected influence predictive classification model failure one hand aim taking account asymmetry speaker role modelling lexical distribution hand determine whether part lexicon closely relating domain customer assistance studied modifies quality prediction eventually assess perspective generalization morphologically comparable corpus
work try enrich spanish wordnet using spanish taxonomy knowledge source spanish taxonomy composed spanish sens spanish wordnet composed synset mostly linked english wordnet set weighted association spanish word wordnet synset used inferring association taxonomy
example powerful tool help u understand complex concept connection computational linguistics research looking example system output example corpus entry offer wealth insight otherwise accessible paper describes opensource software vulcan visualization tool string graph tree alignment attention vulcan unique ability visualize linguistic structure property neural model make particularly relevant neurosymbolic model neurosymbolic model combining neural network often linguistically grounded structure offer promise increased interpretability age purely neural blackbox endtoend model vulcan aim facilitate interpretability practice vulcan designed easy use powerful capability
growing awareness reproducibility crisis natural language processing nlp focused human evaluation generative system labelling supervised classification task make large part human input system reproduction effort thus far explored paper reimplement human data collection study sentiment analysis codemixed malayalam movie review well automated classification experiment find missing underspecified information make reproduction challenging observe potentially consequential difference original label collect classification result indicate reliability label important stable performance
paper present trmorph twolevel morphological analyzer turkish trmorph fairly complete accurate morphological analyzer turkish however strength trmorph neither performance novelty main feature analyzer availability completely implemented using freely available tool resource twolevel description also distributed license allows others use modify freely different application knowledge trmorph first freely available morphological analyzer turkish make trmorph particularly suitable application analyzer changed way starting point morphological analyzer similar language trmorphs specification turkish morphology relatively complete distributed large lexicon along description analyzer implemented paper provides evaluation analyzer two large corpus
paper provides overview diverse application parallel corpus ancient language particularly ancient greek first part provide fundamental principle parallel corpus short overview application study ancient text second part illustrate leverage parallel corpus perform various nlp task including automatic translation alignment dynamic lexica induction named entity recognition conclusion emphasize current limitation future work
open ai kit implement major component statistical machine translation accessible extendable software development kit broad applicability beyond field machine translation highlevel system design policy kit embrace open source development model provide modular architecture interface may serve basis collaborative research development endeavor artificial intelligence
replication research result become important natural language processing nevertheless still rely result reported literature comparison additionally element experimental setup always completely reported includes limited reporting specific parameter used omitting implementational detail experiment based two frequently used data set domain automatic summarization seemingly full disclosure research artefact examine well result reported replicable element influence success failure replication result indicate publishing research artifact far sufficient publishing relevant parameter possible detail cruicial
query expansion pivotal search engine enhances representation user information need additional term existing method expand query using retrieved generated contextual document approach notable limitation retrievalbased method often fail accurately capture search intent particularly brief ambiguous query generationbased method utilizing large language model llm generally lack corpusspecific knowledge entail high finetuning cost address gap propose novel zeroshot query expansion framework utilizing llm mutual verification specifically first design queryquerydocument generation method leveraging llm zeroshot reasoning ability produce diverse subqueries corresponding document mutual verification process synergizes generated retrieved document optimal expansion proposed method fully zeroshot extensive experiment three public benchmark datasets conducted demonstrate effectiveness existing method code available online httpsgithubcomappliedmachinelearninglabmill ease reproduction
pac french audiovideo conversational corpus made facetoface dyadic interaction lasting around min compared corpus created order explore impact lack personal common ground clark participant collaboration conversation specifically smile topic transition constituted conversational corpus paco replicating experimental protocol cheese priegovalverde al difference distinguishes two corpus degree cg interlocutor cheese interlocutor friend paco know experimental protocol allows analyze participant getting acquainted study brings two main contribution first paco conversational corpus enables compare impact interlocutor common ground second semiautomatic smile annotation protocol allows obtain reliable reproducible smile annotation reducing annotation time factor keywords common ground spontaneous interaction smile automatic detection
field teaching truefalse questioning important educational method assessing student general understanding learning material manually creating question requires extensive human effort expert knowledge question generation qg technique offer possibility automatically generate large number question however limited work automatic truefalse question generation due lack training data difficulty finding questionworthy content paper propose unsupervised truefalse question generation approach tfqg automatically generates truefalse question given passage reading comprehension test tfqg consists templatebased framework aim test specific knowledge passage leveraging various nlp technique generative framework generate flexible complicated question using novel maskingandinfilling strategy human evaluation show approach generate highquality valuable truefalse question addition simulated testing generated question challenge stateoftheart inference model nli qa fact verification task
paper present method create wordnetlike lexical resource different language instead directly translating gloss one language another perform first semantic parsing wordnet gloss translate resulting semantic representation proposed approach simplifies machine translation gloss approach provides ready use semantic representation gloss target language instead plain text
machine translation ancient language face lowresource problem caused limited amount available textual source data translation present multitask modeling approach translating middle egyptian inspired recent successful approach multitask learning endtoend speech translation leverage phonographic aspect hieroglyphic writing system show similar multitask learning speech recognition translation joint learning sharing structural information hieroglyph transcription translation po tagging improve direct translation hieroglyph several bleu point using minimal amount manual transcription
despite promising result standard benchmark nlu model still prone make prediction based shortcut caused unintended bias dataset example nli model may use lexical overlap shortcut make entailment prediction due repetitive data generation pattern annotator also called annotation artifact paper propose causal analysis framework help debias nlu model show defining causal relationship introspect much annotation artifact affect outcome utilize counterfactual inference mitigate bias knowledge found viewing model treatment mitigate bias effectively viewing annotation artifact treatment addition bias mitigation interpret much debiasing strategy affected annotation artifact experimental result show using counterfactual inference improve outofdistribution performance setting maintaining high indistribution performance
paper present two approach arabic finegrained dialect identification first approach based recurrent neural network blstm bgru using hierarchical classification main idea separate classification process sentence given text two stage start higher level classification class finergrained classification class second approach given voting system based naive bayes random forest system achieves f score subtask evaluation dataset
work discus importance external knowledge performing named entity recognition ner present novel modular framework divide knowledge four category according depth knowledge convey category consists set feature automatically generated different information source knowledgebase list name documentspecific semantic annotation show effect performance incrementally adding deeper knowledge discus effectivenessefficiency tradeoff
paper describes system developed automatically classifying tweet mention medication used decision tree classifier task shown using elementary preprocessing step tfidf ngrams led acceptable classifier performance indeed fscore recorded development phase test phase
machine reading comprehension mrc real web data usually requires machine answer question analyzing multiple passage retrieved search engine compared mrc single passage multipassage mrc challenging since likely get multiple confusing answer candidate different passage address problem propose endtoend neural model enables answer candidate different passage verify based content representation specifically jointly train three module predict final answer based three factor answer boundary answer content crosspassage answer verification experimental result show method outperforms baseline large margin achieves stateoftheart performance english msmarco dataset chinese dureader dataset designed mrc realworld setting
dependency parsing tool widely used field natural language processing computational linguistics however hardly work connects dependency parsing monotonicity essential part logic linguistic semantics paper present system automatically annotates monotonicity information based universal dependency parse tree system utilizes surfacelevel monotonicity fact quantifier lexical item tokenlevel polarity information compared system performance existing system literature including natlog ccgmono small evaluation dataset result show system outperforms natlog ccgmono
paper describes participation sigmorphonunimorph shared task typologically diverse acquisitioninspired morphological inflection generation present two approach one modification neural baseline encoderdecoder model handcoded morphological analyzer using finitestate tool fst outside linguistic knowledge proposed modification baseline encoderdecoder model underperforms baseline almost language fst method outperform system respective language large margin confirms purely datadriven approach yet reached maturity replace trained linguist documentation analysis especially considering lowresource endangered language
introduce multitask learning model causeofdeath classification verbal autopsy narrative jointly learns output interpretable key phrase adding key phrase outperforms baseline model topic modeling feature
umrwriter webbased tool annotating semantic graph uniform meaning representation umr scheme umr graphbased semantic representation applied crosslinguistically deep semantic analysis text work implemented new keyboard interface umrwriter powerful addition original mouse interface supporting faster annotation experienced annotator new interface also address issue original mouse interface additionally demonstrate efficient workflow annotation project management umrwriter applied many project
twitter social medium platform offer user chance share idea via short post easy exchange idea value microblogs leveraged people want share hatred individual share negative view individual race group million people click button thus urgent need establish method automatically identify hate speech offensive language contribute development osact workshop shared task undertaken detect offensive language arabic key challenge uniqueness language used social medium prompting outofvocabulary oov problem addition use different dialect arabic exacerbates problem deal issue associated oov generated characterlevel embeddings model trained massive data collected carefully level embeddings work effectively resolving problem oov word ability learn vector character ngrams part word proposed system ranked th th subtasks b respectively
human language often claimed fundamentally differ communication system exactly unites separate category article proposes approach problem termed zipfian challenge standard classification task corpus textual material diverse writing system language well symbolic nonsymbolic system provided subsequently used train test binary classification algorithm assigning label writing nonwriting character string test set performance generally high reaching accuracy best algorithm human language emerge statistical fingerprint large unit inventory high entropy repetition adjacent unit fingerprint used tease apart symbolic nonsymbolic system
propose novel framework cross lingual content flagging limited target language data significantly outperforms prior work term predictive performance framework based nearestneighbor architecture modern instantiation vanilla knearest neighbor model use transformer representation component framework adapt new source language instance without need retrained scratch unlike prior work neighborhoodbased approach encode neighborhood information based query neighbor interaction propose two encoding scheme show effectiveness using qualitative quantitative analysis evaluation result eight language two different datasets abusive language detection show sizable improvement f point absolute italian strong baseline average achieve absolute f point improvement three language jigsaw multilingual dataset point wul dataset
automated claim verification retrieve evidence knowledge base determine veracity claim intuitively retrieval correct evidence play crucial role process often evidence selection tackled pairwise sentence classification task ie train model predict sentence individually whether evidence claim work finetune document level transformer extract evidence wikipedia document show approach performs better comparable model classifying sentence individually relevant evidence selection metric fever complete pipeline building evidence selection procedure produce new stateoftheart result fever popular claim verification benchmark
language variation change driven individual internal cognitive process social structure language propagates wide range computational framework proposed connect driver compare strength weakness existing approach propose new analytic framework combine previous network model ability capture realistic social structure practically elegant computational property framework privilege process language acquisition embeds learner social network modular population structure combined different acquisition model demonstrate two application framework test practical concern arise modeling acquisition population setting application framework recent work phonological merger progress
study led medium insight project showed journalist think clearmarking news reporting commentary opinion eg editorial opedis essential gaining public trust present approach classify news article newsstories ie reporting factual information opinion piece using model aim supplement article content representation argumentation feature hypothesis thatthe nature argumentative discourse important distinguishing news story andopinion article show argumentation feature outperform linguistic feature used previously improve finetuned transformerbased model tested data publishersunseen training automatically flagging opinion piece v news story aid applicationssuch factchecking event extraction
task event detection ed information extraction aim recognize classify trigger word event text recent progress featured advanced transformerbased language model eg bert critical component stateoftheart model ed however length limit input text barrier ed model encode longrange documentlevel context shown beneficial ed address issue propose novel method model documentlevel context ed dynamically selects relevant sentence document event prediction target sentence target sentence augmented selected sentence consumed entirely transformerbased language model improved representation learning ed end reinforce algorithm employed train relevant sentence selection ed several information type introduced form reward function training process including ed performance sentence similarity discourse relation extensive experiment multiple benchmark datasets reveal effectiveness proposed model leading new stateoftheart performance
paper describes xjsa system submission xjtu system created semeval task subtask popular fundamental system based convolutional neural network word embedding used two pretrained word vector adopt dynamic strategy kmax pooling
recent year blog social network particularly boosted interest opinion mining research order satisfy realscale applicative need main task create enhance lexical semantic resource evaluative language classical resource area mostly built english contain simple opinion word marker far cover lexical richness linguistic phenomenon particular infrequent subjective word idiomatic expression cultural stereotype missing resource propose new method applied french enhance automatically opinion word lexicon learning method relies linguistic us internet user semantic test infer degree subjectivity many new adjective noun verb noun phrase verbal phrase usually forgotten resource final appraisal lexicon contains entry evaluate lexicon enhancement without textual context
recent research shown evaluating robustness natural language processing model using textual attack method significant however existing text attack method use heuristic replacement strategy language model generate replacement word word level blind pursuit high attack success rate make difficult ensure quality generated adversarial text result adversarial text often difficult human understand fact many method perform well term text attack often generate adversarial text poor quality address important gap work treat blackbox text attack unsupervised text generation problem proposes search learning framework adversarial text generation search learning atgsl develops three adversarial attack method atgslsa atgslbm atgslfusion black box text attack first apply heuristic search attack algorithm atgslsa linguistic thesaurus generate adversarial sample high semantic similarity process train conditional generative model learn search result smoothing search noise moreover design efficient atgslbm attack algorithm based text generator furthermore propose hybrid attack method atgslfusion integrates advantage atgslsa atgslbm enhance attack effectiveness proposed attack algorithm significantly superior advanced method term attack efficiency adversarial text quality
neural language model critical component stateoftheart system machine translation summarization audio transcription task language model almost universally autoregressive nature generating sentence one token time left right paper study influence token generation order model quality via novel twopass language model produce partiallyfilled sentence template fill missing token compare various strategy structuring two pass observe surprisingly large variation model quality find effective strategy generates function word first pas followed content word second believe experimental result justify extensive investigation generation order neural language model
entity alignment ea aim find equivalent entity two knowledge graph kg existing method usually encode triple entity embeddings learn align embeddings prevents direct interaction original information crosskg entity moreover encode relational triple attribute triple entity heterogeneous embedding space prevents helping paper transform triple unified textual sequence model ea task bidirectional textual entailment task sequence crosskg entity specifically feed sequence two entity simultaneously pretrained language model plm propose two kind plmbased entity aligners model entailment probability sequence similarity entity approach capture unified correlation pattern two kind information entity explicitly model finegrained interaction original entity information experiment five crosslingual ea datasets show approach outperforms stateoftheart ea method enables mutual enhancement heterogeneous information code available urlhttpsgithubcomoreozhaotea
develop calm coordination analyzer improves upon conjuncts identified dependency parses us language model based scoring several linguistic constraint search hierarchical conjunct boundary nested coordination splitting conjunctive sentence around conjuncts calm output several simple sentence demonstrate value coordination analyzer end task open information extraction open ie stateoftheart open ie system lose substantial yield due ineffective processing conjunctive sentence open ie system calmie performs extraction simple sentence identified calm obtain x yield moderate increase precision compared extraction original sentence
paper present unipusflaubert team hybrid system nlptea shared task chinese grammatical error diagnosis cged challenging nlp task cged attracted increasing attention recently yet fully benefited powerful pretrained bertbased model explore experimenting three type model positiontagging model correctiontagging model sequence tagging model finetuned pretrained bertbased model former focus detecting positioning classifying error latter aim correcting error also utilize rich representation bertbased model transferring bertfused model correction task improve performance pretraining vast size unsupervised synthetic data best knowledge first introduce transfer bertfused nmt model sequence tagging model chinese grammatical error correction field work achieved second highest f score detecting error best f score correction top subtask second highest f score correction top subtask
predicting user responds news event enables important application allowing intelligent agent content producer estimate effect different community revise unreleased message prevent unexpected bad outcome social conflict moral injury present new task response forecasting persona news medium estimate response persona characterizing individual group might upon seeing news message compared previous effort predict generic comment news proposed task introduces personalization modeling also predicts sentiment polarity intensity response enables accurate comprehensive inference mental state persona meanwhile generated sentiment dimension make evaluation application reliable create first benchmark dataset consists response news headline twitter evaluate sota neural language model dataset empirical result suggest included persona attribute helpful performance response dimension analysis show bestperforming model capable predicting response consistent persona byproduct task formulation also enables many interesting application analysis social network group opinion discovery extreme opinion group
work proposes standalone complete chinese discourse parser practical application approach chinese discourse parsing variety aspect improve shiftreduce parser integrating pretrained text encoder also employing novel training strategy revise dynamicoracle procedure training shiftreduce parser apply unsupervised data augmentation enhance rhetorical relation recognition experimental result show chinese discourse parser achieves stateoftheart performance
major concern using deep learning based generative model documentgrounded dialog potential generation response faithful underlying document existing automated metric used evaluating faithfulness response respect grounding document measure degree similarity generated response document content however automated metric far well aligned human judgment therefore improve measurement faithfulness propose new metric utilizes conditional pointwise mutual information pmi generated response source document conditioned dialogue pmi quantifies extent document influence generated response higher pmi indicating faithful response build upon idea create new decoding technique incorporates pmi response generation process predict faithful response experiment begin benchmark demonstrate improved correlation metric human evaluation also show decoding technique effective generating faithful response compared standard decoding technique set publicly available documentgrounded dialog datasets
propose method program generation based semantic scaffold lightweight structure representing highlevel semantic syntactic composition program first searching plausible scaffold using constraint beam search program achieve better coverage search space compared existing technique apply hierarchical search method spoc dataset pseudocodetocode generation given linelevel natural language pseudocode annotation aim produce program satisfying executionbased test case using semantic scaffold inference achieve absolute improvement top accuracy previous stateoftheart additionally require candidate reach top performance previous best approach tested unseen problem demonstrating substantial improvement efficiency
bantu language spoken community half country african continent estimated third billion people despite populous amount high quality linguistic research done year bantu language still computationally underresourced biggest limitation development computational method processing bantu language text complex grammatical structure chiefly system noun class investigated use combined syntactic semantic method disambiguate among singular noun class prefix belonging different noun class combination us semantic generalization type noun class overcome limitation relying prefix take used nearest neighbor query word semantic generalization developed tool determine noun class based resource runyankore bantu language indigenous uganda also investigated whether runyankore resource method utility bantu language luganda indigenous uganda kinyarwanda indigenous rwanda three language combined approach resulted improvement accuracy compared using syntactic semantic approach
prior research discussed illustrated need consider linguistic norm community level studying taboo hatefuloffensivetoxic etc language however methodology firmly founded community language norm still largely absent lead bias taboo text classification limitation understanding cause bias propose method study bias taboo classification annotation community perspective front center accomplished using special classifier tuned community language essence classifier represent community level language norm use study bias find example bias largest african american datasets classifier examined contrast previous paper also study community find example strong bias south asian small scale user study illustrate key idea common utterance ie high alignment score community community classifier confidence score unlikely regarded taboo annotator community member contradict taboo classification decision annotation majority instance paper significant step toward reducing false positive taboo decision time harm minority community
sequence sequence neural machine translation achieved significant performance recent year yet existing issue neural machine translation still solve completely two translation long sentence overtranslation address two problem propose approach utilize grammatical information syntactic dependency output generated based abundant information approach syntactic dependency employed decoding addition output model presented simple sequence token linearized tree construction order assess performance construct model based attention mechanism encoderdecoder model source language input encoder sequence decoder generates target language linearized dependency tree structure experiment europarlv dataset frenchtoenglish translation demonstrate proposed method improves bleu score datasets consisting sentence token respectively furthermore proposed method also solved two existing problem ineffective translation long sentence overtranslation neural machine translation
examine behaviour aspectbased sentiment classifier built finetuning bert base model semeval english dataset set masking experiment examine extent token identified salient lime gradientbased method used classifier find method able produce faithful rationale lime outperforming gradientbased method also identify set manually annotated sentiment expression dataset carry masking experiment human rationale enhanced performance classifier see relevant sentiment expression suggests used full potential comparison lime gradient rationale sentiment expression reveals moderate level agreement disagreement related fixed length rationale tendency rationale contain content word related aspect
paraphrase generation benefited extensively recent progress designing training objective model architecture however previous exploration largely focused supervised method require large amount labeled data costly collect address drawback adopt transfer learning approach propose training pipeline enables pretrained language model generate highquality paraphrase unsupervised setting recipe consists taskadaptation selfsupervision novel decoding algorithm named dynamic blocking db enforce surface form dissimilar input whenever language model emits token contained source sequence db prevents model outputting subsequent source token next generation step show automatic human evaluation approach achieves stateoftheart performance quora question pair qqp paranmt datasets robust domain shift two datasets distinct distribution also demonstrate model transfer paraphrasing language without additional finetuning
despite growth number linguistic data center around world accomplishment expansion advance help enable language resource exist small fraction required meet goal human language technology hlt world language promise offer broad access knowledge direct communication across language boundary engagement global community using linguistic data consortium focus case paper sketch progress data center summarizes recent activity turn several issue received inadequate attention proposes new approach resolution
dialogue dataset indispensable resource building dialogue system additional information like emotion interpersonal relationship labeled conversation enables system capture emotion flow participant dialogue however publicly available chinese dialogue dataset emotion relation label paper collect conversion tv series script annotate emotion interpersonal relationship label utterance dataset contains utterance dialogue also set experiment observe effect responded utterance current utterance correlation emotion relation type emotion relation classification task
article describes compositional distributional method generate contextualized sens word identify appropriate translation target language using monolingual corpus word translation modeled way contextualization word meaning bilingual vector space contextualization meaning carried mean distributional composition within structured vector space syntactic dependency bilingual space created mean transfer rule bilingual dictionary phrase source language consisting head dependent translated target language selecting nearest neighbor head given dependent nearest neighbor dependent given head process expanded larger phrase mean incremental composition experiment performed english spanish monolingual corpus order translate phrasal verb context new bilingual data set evaluate strategy aimed translating phrasal verb restricted syntactic domain created released
large language model llm emerged influential instrument within realm natural language processing nevertheless capacity handle multiparty conversation mpcs scenario marked presence multiple interlocutor involved intricate information exchange remains uncharted paper delve potential generative llm chatgpt gpt within context mpcs empirical analysis conducted assess zeroshot learning capability chatgpt gpt subjecting evaluation across three mpc datasets encompass five representative task finding reveal chatgpts performance number evaluated mpc task leaf much desired whilst gpts result portend promising future additionally endeavor bolster performance incorporation mpc structure encompassing speaker addressee architecture study provides exhaustive evaluation analysis applying generative llm mpcs casting light upon conception creation increasingly effective robust mpc agent concurrently work underscore challenge implicit utilization llm mpcs deciphering graphical information flow generating stylistically consistent response
targetguided response generation enables dialogue system smoothly transition conversation dialogue context toward target sentence control useful designing dialogue system direct conversation toward specific goal creating nonobtrusive recommendation introducing new topic conversation paper introduce new technique targetguided response generation first find bridging path commonsense knowledge concept source target us identified bridging path generate transition response additionally propose technique repurpose existing dialogue datasets targetguided generation experiment reveal proposed technique outperform various baseline task finally observe existing automated metric task correlate poorly human judgement rating propose novel evaluation metric demonstrate reliable targetguided response evaluation work generally enables dialogue system designer exercise control conversation system produce
present paradigm extensible lexicon development based lexical conceptual structure support social engineering detection response generation leverage central notion ask elicitation behavior providing access money framing riskreward implied ask demonstrate improvement askframing detection refinement lexical organization show response generation qualitatively improves askframing detection performance improves paradigm present systematic efficient approach resource adaptation improved taskspecific performance
previous event extraction study assume set target event type corresponding event annotation given could expensive paper work new task semisupervised event type induction aiming automatically discover set unseen type given corpus leveraging annotation available seen type design semisupervised vector quantized variational autoencoder framework automatically learn discrete latent type representation seen unseen type optimize using seen type event annotation variational autoencoder introduced enforce reconstruction event mention conditioned latent type distribution experiment show approach achieve stateoftheart performance supervised event detection also discover highquality new event type
eyetracking psycholinguistic study revealed contextword semantic coherence predictability influence language processing paper show approach predict eyetracking feature zuco dataset shared task cognitive modeling computational linguistics cmcl workshop using cosine similarity surprisal within regression model significantly improved baseline mean absolute error computed among five eyetracking feature
organized relational knowledge form knowledge graph important many application however ability populate knowledge base fact automatically extracted document improved frustratingly slowly paper simultaneously address two issue held back prior work first propose effective new model combine lstm sequence model form entity positionaware attention better suited relation extraction build tacred large example supervised relation extraction dataset obtained via crowdsourcing targeted towards tac kbp relation combination better supervised data appropriate highcapacity model enables much better relation extraction performance model trained new dataset replaces previous relation extraction component best tac kbp slot filling system f score increase markedly
paper introduces banglahatebert retrained bert model abusive language detection bengali model trained largescale bengali offensive abusive hateful corpus collected different source made available public furthermore collected manually annotated k bengali hate speech balanced dataset made publicly available research community used existing pretrained banglabert model retrained million offensive post presented result detailed comparison generic pretrained language model retrained abuseinclined version datasets banglahatebert outperformed corresponding available bert model
natural language inference nli garnered significant attention recent year however promise applying nli breakthrough downstream nlp task remained unfulfilled work use multiplechoice reading comprehension mcrc checking factual correctness textual summarization cfc task investigate potential reason finding show relatively shorter length premise traditional nli datasets primary challenge prohibiting usage downstream application better longer context challenge addressed automatically converting resourcerich reading comprehension datasets longerpremise nli datasets model trained converted longerpremise datasets outperform trained using shortpremise traditional nli datasets downstream task primarily due difference premise length
improving accessibility psychotherapy aid large language model llm garnering significant attention recent year recognizing cognitive distortion interviewee utterance essential part psychotherapy especially cognitive behavioral therapy paper propose erd improves llmbased cognitive distortion classification performance aid additional module extracting part related cognitive distortion debating reasoning step multiple agent experimental result public dataset show erd improves multiclass f score well binary specificity score regarding latter score turn method effective debiasing baseline method high false positive rate especially summary multiagent debate provided llm
work aim leverage visual feature space pas information across language show model trained generate textual caption one language conditioned input image leverage jointly trained feature space inference pivot across language particularly demonstrate improved quality caption generated input image leveraging caption second language importantly demonstrate even without conditioning visual input model demonstrates learned implicitly perform extent machine translation one language another shared visual feature space show result germanenglish japaneseenglish language pair pave way using visual world learn common representation language
paper describes system used semeval task subtask message polarity classification english arabic language proposed system ensemble two layer first one us generic framework multilingual polarity classification bmsa second layer combine decision function value predicted bmsa system using nonlinear function evolved using genetic programming system evodag approach best performance reached system macrorecall english arabic set u sixth fourth position result table respectively
investigate new commonsense inference task given event described short freeform text x drink coffee morning system reason likely intent x want stay awake reaction x feel alert event participant support study construct new crowdsourced corpus event phrase covering diverse range everyday event situation report baseline performance task demonstrating neural encoderdecoder model successfully compose embedding representation previously unseen event reason likely intent reaction event participant addition demonstrate commonsense inference people intent reaction help unveil implicit gender inequality prevalent modern movie script
wordnet lexical database semantic relation word concept established resource useful manynlp task automatic text classification wordsense disambiguation machine translation comparison wordnetsthe basque version smaller po underrepresented missing eg adjective adverb work explore anovel approach enrich basque wordnet focusing adjective want prove use effectiveness sentimentlexicons enrich resource without need starting scratch using complementary resource one dictionary thesentiment valence word check word lexicon match meaning synset match addthe word variant basque wordnet following methodology describe frequent adjective positive andnegative valence match possible solution nonmatches
recent advance pretrained multilingual language model lead stateoftheart result task quality estimation qe machine translation carefully engineered ensemble model qe shared task wmt indepth analysis however show success using pretrained language model qe overestimated due three issue observed current qe datasets distribution quality score imbalanced skewed towards good quality score iii qe model perform well datasets looking source translated sentence iii contain statistical artifact correlate well humanannotated qe label finding suggest although qe model might capture fluency translated sentence complexity source sentence model adequacy translation effectively
paper describes submission task semeval ie hyperpartisan news detection model aim detecting hyperpartisan news incorporating stylebased feature contentbased feature extract broad number feature set use learning algorithm gbdt ngram cnn model finally apply weighted average effective learning two model model achieves accuracy test set subtask
deep pretrained language model achieved great success way pretraining first finetuning sequential transfer learning paradigm often confronts catastrophic forgetting problem lead suboptimal performance finetune less forgetting propose recall learn mechanism adopts idea multitask learning jointly learns pretraining task downstream task specifically introduce pretraining simulation mechanism recall knowledge pretraining task without data objective shifting mechanism focus learning downstream task gradually experiment show method achieves stateoftheart performance glue benchmark method also enables bertbase achieve better average performance directly finetuning bertlarge provide opensource recadam optimizer integrates proposed mechanism adam optimizer facility nlp community
identifying release new product predicted demand advance highly valuable ecommerce marketplace retailer information upcoming product release used inventory management marketing campaign preorder suggestion often announcement upcoming product release widely available multiple web page blog chat news article however best knowledge automatic system extract future product release web data presented work describe mlpowered multistage pipeline automatically identify future product release rank predicted demand unstructured page across whole web pipeline includes novel longformerbased model us global attention mechanism guided precalculated named entity recognition prediction related product release model training data based new corpus k web page manually annotated identify future product release made dataset openly available urlhttpsdoiorgzenodo
prevalence depression increasing globally need effective screening detection tool social medium platform offer rich source data mental health research paper aim detect sign depression person social medium posting wherein people share feeling emotion task create system given social medium post english classify level depression depressed moderately depressed severely depressed paper present solution shared task detecting sign depression social medium text ltediranlp proposed system aim develop machine learning model using machine learning algorithm like svm random forest naive bayes detect sign depression social medium text model trained dataset social medium post detect level depression individual depressed moderately depressed severely depressed dataset preprocessed remove duplicate irrelevant feature feature engineering technique used extract meaningful feature text data model trained feature classify text three category performance model evaluated using metric accuracy precision recall fscore ensemble model used combine algorithm give accuracy f score result proposed approach could potentially aid early detection prevention depression individual may risk
present finding loresmt shared task focus machine translation mt covid data lowresource spoken sign language organization task conducted part fourth workshop technology machine translation low resource language loresmt parallel corpus presented publicly available includes following direction englishirish englishmarathi taiwanese sign languagetraditional chinese training data consists segment respectively additional monolingual data set marathi english consist segment result presented based entry total eight team three team submitted system englishirish five team submitted system englishmarathi unfortunately system submission taiwanese sign languagetraditional chinese task maximum system performance computed using bleu follow englishirish irishenglish englishmarathi marathienglish
spatial relation basic part human cognition however expressed natural language variety way previous work suggested current visionandlanguage model vlms struggle capture relational information paper present visual spatial reasoning vsr dataset containing k natural textimage pair type spatial relation english eg front facing using seemingly simple annotation format show dataset includes challenging linguistic phenomenon varying reference frame demonstrate large gap human model performance human ceiling stateoftheart model achieve around observe vlms byrelation performance little correlation number training example tested model general incapable recognising relation concerning orientation object
responsing image recognized important capability intelligent conversational agent yet existing work focus exploring multimodal dialogue model depend retrievalbased method neglecting generation method fill gap first present new task multimodal dialogue response generation mdrg given dialogue history one model need generate text sequence image response learning mdrg model often requires multimodal dialogue containing text image difficult obtain motivated challenge practice consider mdrg natural assumption limited training example available lowresource setting devise novel conversational agent divter order isolate parameter depend multimodal dialogue entire generation model mean major part model learned large number textonly dialogue textimage pair respectively whole parameter well fitted using limited training example extensive experiment demonstrate method achieves stateoftheart result automatic human evaluation generate informative text highresolution image response
codemixed emotion recognition constitutes challenge nlp research due text deviation traditional grammatical structure original language paper describes system submitted racai team semeval task ediref subtasks emotion recognition conversation erc hindienglish codemixed conversation propose system combine transformerbased model two simple neural network
grounding dialogue generation extra knowledge shown great potential towards building system capable replying knowledgeable engaging response existing study focus synthesize response proper knowledge yet neglect knowledge could expressed differently speaker even context work mainly consider two aspect knowledge expression namely structure response style content part therefore introduce two sequential latent variable represent structure content style respectively propose segmentationbased generation model optimize model variational approach discover underlying pattern knowledge expression response evaluation result two benchmark indicate model learn structure style defined example generate response desired content style
substantial overlap coreferent mention conll dataset magnifies recent progress coreference resolution conll benchmark fails evaluate ability coreference resolvers requires linking novel mention unseen train time work create new dataset based conll largely decrease mention overlap entire dataset expose limitation published resolvers two aspectslexical inference ability understanding lowlevel orthographic noise finding show requirement embeddings used resolvers coreference resolution design conflict adversarial approach sometimes legitimate mitigate obstacle may falsely introduce mention overlap adversarial training test set thus giving inflated impression improvement
present computerassisted learning system jastudy particularly designed chinesespeaking learner japanese second language jsl learn japanese functional expression suggestion appropriate example sentence system automatically recognizes japanese functional expression using free japanese morphological analyzer mecab retrained new conditional random field crf model order select appropriate example sentence apply pairwisebased machine learning tool support vector machine ranking svmrank estimate complexity example sentence using japanesechinese homograph important feature addition cluster example sentence contain japanese functional expression two meaning usage based partofspeech conjugation form verb semantic attribute using kmeans clustering algorithm scikitlearn experimental result demonstrate effectiveness approach
paper describes slavner rd multilingual named entity challenge slavic language task involve recognizing mention named entity web document normalization name crosslingual linking challenge cover six language five entity type organized part th baltoslavic natural language processing workshop colocated eacl conference ten team participated competition performance named entity recognition task reached fmeasure much higher reported first edition challenge seven team covered six language five team participated crosslingual entity linking task detailed valuation information available shared task web page
verbnoun combination vncs eg blow whistle hit roof see star common type english idiom ambiguous literal usage paper propose evaluate model classifying vnc usage idiomatic literal based variety approach forming distributed representation result show model based averaging word embeddings performs par better previouslyproposed approach based skipthoughts idiomatic usage vncs known exhibit lexicosyntactic fixedness incorporate information model demonstrating rich linguistic knowledge complementary information carried distributed representation
goal knowledge graph embedding kge learn represent low dimensional vector entity relation based observed triple conventional shallow model limited expressiveness conve dettmers et al take advantage cnn improves expressive power parameter efficient operator increasing interaction head relation embeddings however structural information embedding space conve performance still limited number interaction recent kbgat nathani et al provides another way learn embeddings adaptively utilizing structural information paper take benefit conve kbgat together propose relationaware inception network joint localglobal structural information knowledge graph embedding reinceptione specifically first explore inception network learn query embedding aim increase interaction head relation embeddings propose use relationaware attention mechanism enrich query embedding local neighborhood global entity information experimental result wnrr fbk datasets demonstrate reinceptione achieves competitive performance compared stateoftheart method
datasets integral artifact empirical scientific research however due natural language variation recognition difficult even identified often inconsistently referred across within publication report approach coleridge initiative rich context competition task participant identifying dataset surface form dataset mention extraction associating extracted mention referred dataset dataset classification work propose various neural baseline evaluate model oneplus zeroshot classification scenario explore various joint learning approach exploring synergy task report issue technique
authorship attribution task aim identify author given piece writing aim develop generalized solution handle large number text author topic unavailable training data previous study proposed strategy address either unseen author unseen topic authorship representation learning shown work openset environment large number unseen author explicitly designed crosstopic environment time handle large number unseen author topic propose authorship representation regularization arr distillation framework creates authorship representation reduced reliance topicspecific information assess performance framework also propose crosstopicopenset evaluation method proposed method improved performance crosstopicopen set setup baseline case
although machine translation mt attracting attention translation industry quality current mt system still requires human postedit translation ensure quality time necessary postedit bad quality translation even longer translating without mt system well known however quality mt system generally homogeneous across translated segment order make mt useful translation industry therefore crucial mechanism judge mt quality segment level prevent bad quality translation postedited within translation workflow describe approach estimate translation postediting effort sentence level term humantargeted translation edit rate hter based number feature reflecting difficulty translating source sentence discrepancy source translation sentence hter simple metric obtaining hter annotated data made part translation workflow show approach reliable filtering bad translation simple criterion commonly used translation industry sentence length
paper present year cuni submission wat translation task focusing japaneseenglish translation namely scientific paper subtask patent subtask newswire subtask compare two neural network architecture standard sequencetosequence attention seqseq architecture using convolutional sentence encoder fbconvseq implemented nmt framework neural monkey currently participate developing also compare various type preprocessing source japanese sentence impact overall result furthermore include result experiment outofdomain data obtained combining corpus provided subtask
answering factual question temporal intent knowledge graph temporal kgqa attracts rising attention recent yearsin generation temporal query existing kgqa method ignore fact intrinsic connection event make temporally related may limit capabilitywe systematically analyze possible interpretation temporal constraint conclude interpretation structure semantic framework temporal constraint sftconsbased semantic framework propose temporal question answering method sftqa generates query graph exploring relevant fact mentioned entity exploring process restricted sftcons evaluation show sftqa significantly outperforms existing method two benchmark different knowledge graph
although existing neural retrieval model reveal promising result training data abundant performance keep improving training data increase collecting highquality annotated data prohibitively costly end introduce novel noisy selftraining framework combined synthetic query showing neural retriever improved selfevolution manner reliance external model experimental result show method improves consistently existing method generaldomain eg msmarco outofdomain ie beir retrieval benchmark extra analysis lowresource setting reveals method data efficient outperforms competitive baseline little labelled training data extending framework reranker training demonstrates proposed method general yield additional gain task diverse domain
data drift denotes misalignment distribution reference ie training production data constitutes significant challenge ai application undermines generalisation capacity machine learning ml model therefore imperative proactively identify data drift user meet performance degradation moreover ensure successful execution ai service endeavour directed toward detecting occurrence drift also toward effectively addressing challenge considering limited resource prevalent practical industrial domain work introduce tool designed detect data drift text data addition propose unsupervised sampling technique extracting representative example drifted instance approach bestows practical advantage significantly reducing expense associated annotating label drifted instance essential prerequisite retraining model sustain performance production data
theory mind tom capacity comprehend mental state distinct individual essential numerous practical application development large language model llm heated debate whether able perform tom task previous study used different task prompt test tom llm result inconsistent study asserted model capable exhibiting tom others suggest opposite study present tomchallenges dataset comprehensively evaluating theory mind based sallyanne smarties test diverse set task addition also propose autograder streamline answer evaluation process tested three model davinci turbo gpt evaluation result error analysis show llm inconsistent behavior across prompt task performing tom task robustly remains challenge llm addition paper want raise awareness evaluating tom llm want invite discussion design prompt task tom task better access llm ability
aspect based sentiment analysis absa aim identify sentiment polarity towards given aspect sentence previous model typically exploit aspectindependent weakly associative encoder sentence representation generation paper propose novel aspectguided deep transition model named agdt utilizes given aspect guide sentence encoding scratch speciallydesigned deep transition architecture furthermore aspectoriented objective designed enforce agdt reconstruct given aspect generated sentence representation agdt accurately generate aspectspecific sentence representation thus conduct accurate sentiment prediction experimental result multiple semeval datasets demonstrate effectiveness proposed approach significantly outperforms best reported result setting
user interact text image code editor daily basis however machine learning model rarely trained setting reflect interactivity user editor understandable training ai model real user slow costly model learn may specific user interface design choice unfortunately mean research text code image generation focused noninteractive setting whereby model expected get everything right without accounting input user may willing help introduce new interactive text generation task allows training generation model interactively without cost involving real user using user simulator provide edits guide model towards given target text train interactive model using imitation learning experiment competitive noninteractive generation model show model trained interactively superior noninteractive counterpart even model given budget user input edits
sublanguage source code annotationsexplanatory natural language writing accompanies programming source codeis littlestudied linguistics facilitate research domain developed program prototype extract code comment changelogs ie commit message public opensource code repository automatic tokenization partofspeech tagging extracted text program also automatically detect discard commentedout source code data python repository prevent polluting corpus demonstrating sanitization likely feasible programming language well current tool produced million word corpus englishlanguage comment extracted three different programming language python c c
text summarization simplification among widely used application ai however model often prone hallucination result training model unaligned data one efficient approach address issue loss truncation kang hashimoto approach modify standard log loss adaptively remove noisy example training however find lt alone yield considerable number hallucinated entity various datasets study behavior underlying loss factual nonfactual example understand refine performance lt demonstrate lts performance limited underlying assumption noisy target higher nll loss satisfied find wordlevel nll among entity provides better signal distinguishing factuality leverage propose finegrained nll loss finegrained data cleaning strategy observe improvement hallucination reduction across datasets work available httpsgithubcomyalenlpsimplificationprojects
study carried improve quality acted emotional speech recent paradigm shift speech collection technique method collection highquality spontaneous speech strongly focused however method involve various constraint difficulty controlling utterance sound quality hence study daringly focus acted speech high operability paper propose new method speech collection refining acting script compared speech collected using proposed method collected using imitation legacy method implemented traditional basic emotional word result show advantage proposed method ie possibility generating high f fluctuation acoustical expression one important feature expressive speech ensuring decline naturalness psychological feature
task rich semantic parsing abstract meaning representation amr share similar goal information extraction ie convert natural language text structured semantic representation take advantage similarity propose novel amrguided framework joint information extraction discover entity relation event help pretrained amr parser framework consists two novel component amr based semantic graph aggregator let candidate entity event trigger node collect neighborhood information amr graph passing message among related knowledge element amr guided graph decoder extract knowledge element based order decided hierarchical structure amr experiment multiple datasets shown amr graph encoder decoder provided significant gain approach achieved new stateoftheart performance ie subtasks
common issue realworld application named entity recognition classification nerc absence annotated data target entity class training zeroshot learning approach address issue learning model class training data predict class without paper present first approach zeroshot nerc introducing novel architecture leverage fact textual description many entity class occur naturally address zeroshot nerc specific challenge notanentity class well defined different entity class considered training testing evaluation adapt two datasets ontonotes medmentions emulating difficulty realworld zeroshot learning testing model rarest entity class proposed approach outperforms baseline adapted machine reading comprehension zeroshot text classification furthermore assess effect different class description task
increased attention connecting science topic realworld context like issue social justice teacher need support assess student progress explaining issue work explore robustness nlpbased automatic content scoring model provide insight student ability integrate science social justice idea two different environmental science context leverage encoderonly transformer model capture degree student explain science phenomenon understand intersecting justice issue integrate understanding science social justice developed model training data context well combined dataset found model developed one context generate educationally useful score context model trained combined dataset performed well better model trained separate datasets case quadratic weighted kappa demonstrate model threshold use classroom
relation extraction extensively studied due importance realworld application knowledge base construction question answering existing work train model either distantly supervised data humanannotated data take advantage high accuracy human annotation cheap cost distant supervision propose dual supervision framework effectively utilizes type data however simply combining two type data train model may decrease prediction accuracy since distant supervision labeling bias employ two separate prediction network hanet dsnet predict label human annotation distant supervision respectively prevent degradation accuracy incorrect labeling distant supervision furthermore propose additional loss term called disagreement penalty enable hanet learn distantly supervised label addition exploit additional network adaptively assess labeling bias considering contextual information performance study sentencelevel documentlevel re confirms effectiveness dual supervision framework
entity linking prominent thread research focused structured data creation linking span text ontology knowledge source revisit use structured prediction entity linking classifies individual input token entity aggregate token prediction system called spel structured prediction entity linking stateoftheart entity linking system us new idea apply structured prediction task entity linking including two refined finetuning step context sensitive prediction aggregation strategy reduction size model output vocabulary address common problem entitylinking system training v inference tokenization mismatch experiment show outperform stateoftheart commonly used aida benchmark dataset entity linking wikipedia method also compute efficient term number parameter speed inference
usually high portion different word form corpusreceive reading lexical andor morphological analysis unknown word constitute huge problem nlp analysis task likepostagging syntactic parsing present parameterizable principle languageindependent corpusbasedapproach interpretation unknown word need tokenizedcorpus used offline online application combination linguistic languagedependent rule unknown verb adjective noun multiword unit etc identified depending recognized word class detailed morphosyntactic semantic information additionally identified opposite majority ofother unknown word guessing methodswhich us narrow decision window assign unknown wordits correct reading respective partofspeech tag given text tested approach experiment german data received promising result
nlp period disruptive change impacting methodology funding source public perception work seek understand shape future better understanding past study factor shape nlp field including culture incentive infrastructure conducting longform interview nlp researcher varying seniority research area institution social identity interviewee identify cyclical pattern field well new shift without historical parallel including change benchmark culture software infrastructure complement discussion quantitative analysis citation authorship language use acl anthology time conclude discussing shared vision concern hope future nlp hope study field past present prompt informed discussion community implicit norm deliberate action consciously shape future
crucial component taskoriented dialog system natural language generation nlg module convert dialog act represented semantic form response natural language success traditional templatebased statistical model typically relies heavily annotated data infeasible new domain therefore pivotal nlg system generalize well limited labelled data real application end present fewshotwoz first nlg benchmark simulate fewshot learning setting taskoriented dialog system develop scgpt model pretrained large set annotated nlg corpus acquire controllable generation ability finetuned domainspecific label adapt new domain experiment fewshotwoz large multidomainwoz datasets show proposed scgpt significantly outperforms existing method measured various automatic metric human evaluation
contrastive learning used learn highquality representation image computer vision however contrastive learning widely utilized natural language processing due lack general method data augmentation text data work explore method employing contrastive learning improve text representation bert model relation extraction key knob framework unique contrastive pretraining step tailored relation extraction task seamlessly integrating linguistic knowledge data augmentation furthermore investigate largescale data constructed external knowledge base enhance generality contrastive pretraining bert experimental result three relation extraction benchmark datasets demonstrate method improve bert model representation achieve stateoftheart performance addition explore interpretability model showing bert contrastive pretraining relies rationale prediction code data publicly available urlhttpsgithubcomanonymousfornow
performance cost differential privacy application shown higher minority group fairness conversely shown disproportionally compromise privacy member group work area restricted computer vision risk assessment paper evaluate impact differential privacy fairness across four task focusing attempt mitigate privacy violation betweengroup performance difference interact privacy inhibit attempt ensure fairness end train epsilon deltadifferentially private model empirical risk minimization group distributionally robust training objective consistent previous finding find differential privacy increase betweengroup performance difference baseline setting interestingly differential privacy reduces betweengroup performance difference robust setting explain reinterpreting differential privacy regularization
propose syntactically controlled paraphrase network scpns use generate adversarial example given sentence target syntactic form eg constituency parse scpns trained produce paraphrase sentence desired syntax show possible create training data task first backtranslation large scale using parser label syntactic transformation naturally occur process data allows u train neural encoderdecoder model extra input specify target syntax combination automated human evaluation show scpns generate paraphrase follow target specification without decreasing paraphrase quality compared baseline uncontrolled paraphrase system furthermore capable generating syntactically adversarial example fool pretrained model improve robustness model syntactic variation used augment training data
paper focus generation natural language question based sparql query emphasis conversational use case followup questionanswering study achieved far based current deep learning model namely pretrained bart model knowledgebased qa corpus homogenized task new challenge set introduced first series experiment analyzes impact different training setup second series seek understand still difficult model result automatic metric human evaluation show simple question frequent template sparql query usually well processed whereas complex question conversational dimension coreference ellipsis still difficult handle experimental material publicly available urlhttpsgithubcomorangeopensourcesparqltotext
present new direct data analysis showing dynamicallybuilt contextdependent phrasal translation lexicon useful resource phrasebased statistical machine translation smt conventional static phrasal translation lexicon ignore contextual information several year surprising negative result recent work suggests contextdependent phrasal translation lexicon appropriate framework successfully incorporate word sense disambiguation wsd modeling smt however approach far evaluated using automatic translation quality metric important aggregate many different factor direct analysis still needed understand contextdependent phrasal translation lexicon impact translation quality whether additional complexity introduce really necessary paper focus impact contextdependent translation lexicon lexical choice phrasebased smt show contextdependent lexicon useful phrasebased smt system conventional lexicon typical phrasebased smt system make use longer phrase context modeling including phrase seen frequently training even segmentation identical contextdependent lexicon yield translation match reference often conventional lexicon
paper describes contribution semeval shared task arfisenti task consists several sentiment classification subtasks rarely studied african language predict positive negative neutral class given twitter dataset system utilized three different model fasttext multilang transformer languagespecific transformer find best working model classification challenge experimented mentioned model mostly reached best prediction score using language specific transformer bestsubmitted result ranked rd among submission amharic language obtaining f score behind secondranked system
dataset development automatic summarisation system notoriously englishoriented paper present first largescale nonenglish language dataset specifically curated automatic summarisation documentsummary pair news article manually written summary danish language previously work done establish danish summarisation dataset published work automatic summarisation danish provide therefore first automatic summarisation dataset danish language largescale otherwise support comparison future automatic summarisation system danish include system performance dataset strong wellestablished unsupervised baseline system together oracle extractive summariser first account automatic summarisation system performance danish finally make code automatically acquiring data freely available make explicit technology easily adapted order acquire automatic summarisation datasets language
story cloze test sct designed training evaluating machine learning algorithm narrative understanding inference sota model achieve accuracy predicting last sentence however shown high accuracy achieved merely using surfacelevel feature suspect model may textittruly understand story based sct dataset constructed humanlabeled humanverified commonsense knowledge inference dataset given first four sentence story asked crowdsource worker choose four type narrative inference deciding ending sentence sentence contributes inference accumulated data story three human worker labeled story analysis intracategory intercategory agreement show high level consensus present two new task predicting narrative inference category contributing sentence result show transformerbased model reach sota performance original sct task using transfer learning dont perform well new challenging task
framenet lexical semantic resource based linguistic theory frame semantics number framenet development strategy reported previously involve exploration corpus fair amount manual work despite previous effort exist wellthoughtout automaticsemiautomatic methodology frame construction paper propose datadriven methodology identification semiautomatic construction frame proof concept report initial attempt build widerscale framenet legal domain lawfn using proposed methodology constructed frame stored lexical database together annotated example sentence made available web interface
foreign name expression written chinese character difficult recognize since sequence character represents chinese pronunciation name paper suggests known english german person name reliably identified basis similarity chinese foreign pronunciation addition locating person name text learning foreign corresponding foreign name identified thus gaining precious additional information crosslingual application idea implemented statistical module rulebased shallow parsing system sprout forming hyfex system statistical component invoked sequence trigger character found may correspond foreign name phonetic pinyin representation produced compared phonetic representation sampa given foreign name generated mary tt system german english pronunciation comparison achieved handcrafted metric assigns cost specific edit operation person name corresponding sampa representation lowest cost attached returned similar result threshold exceeded evaluation publicly available data show competitive result
usergenerated text social medium enables health worker keep track information identify possible outbreak forecast disease trend monitor emergency case ascertain disease awareness response official health correspondence exchange health information social medium regarded attempt enhance public health surveillance ph despite potential technology still early stage ready widespread application advancement pretrained language model plms facilitated development several domainspecific plms variety downstream application however plms social medium task involving ph present release phsbert transformerbased plm identify task related public health surveillance social medium compared benchmarked performance phsbert datasets different social medial platform related different ph task compared existing plms mainly evaluated limited task phsbert achieved stateoftheart performance tested datasets showing plm robust generalizable common ph task making phsbert available aim facilitate community reduce computational cost introduce new baseline future work across various phsrelated task
study investigates supervised tokenbased identification multiword expression mwes ongoing research exploit information contained context different instance expression could occur information used investigate question whether expression literal mwe lexical syntactic context feature derived vector representation shown effective traditional statistical measure identify token mwes
fundamental nlp task semantic role labeling srl aim discover semantic role predicate within one sentence paper investigates incorporate syntactic knowledge srl task effectively present different approach en coding syntactic information derived dependency tree different quality representation propose syntaxenhanced selfattention model compare two strong baseline method con duct experiment newly published deep contextualized word representation well experiment result demonstrate proper incorporation high quality syntactic information model achieves new stateoftheart performance chinese srl task conll dataset
pymmax api processing mmax standoff annotation data python provides lightweight basis development code open java xmlbased ecosystem mmax recent pythonbased nlp data science method pymmax pure python functionality implemented scratch api reuses complex implementation essential business logic mmax annotation scheme interfacing original mmax java library pymmax available download urlhttpgithubcomnlpathitspymmax
frame semantic parsing semantic analysis task based framenet received great attention recently task usually involves three subtasks sequentially target identification frame classification semantic role labeling three subtasks closely related previous study model individually ignores intern connection meanwhile induces error propagation problem work propose endtoend neural model tackle task jointly concretely exploit graphbased method regarding frame semantic parsing graph construction problem predicate role treated graph node relation taken graph edge experiment result two benchmark datasets frame semantic parsing show method highly competitive resulting better performance pipeline model
adapting generalpurpose language model proven effective tackling downstream task within specific domain paper address task extracting entity economics literature impact evaluation end release econberta large language model pretrained scientific publication economics econie new expertannotated dataset economics abstract named entity recognition ner find econberta reach stateoftheart performance downstream ner task additionally extensively analyze model generalization capacity finding error correspond detecting subspan entity failure extrapolate longer sequence limitation primarily due inability detect partofspeech sequence unseen training effect diminishes number unique instance training set increase examining generalization ability domainspecific language model pave way towards improving robustness ner model causal knowledge extraction
word sentence embeddings useful feature representation natural language processing however intrinsic evaluation embeddings lag far behind significant update since past decade word sentence similarity task become de facto evaluation method lead model overfit evaluation negatively impacting embedding model development paper first point problem using semantic similarity gold standard word sentence embedding evaluation propose new intrinsic evaluation method called evalrank show much stronger correlation downstream task extensive experiment conducted based model popular datasets certify judgment finally practical evaluation toolkit released future benchmarking purpose
even advanced language model remain susceptible error necessitating modify model without initiating comprehensive retraining process model editing refers modification model knowledge representation manner produce desired outcome prior research primarily centered around editing factual data eg messi play inter miami confining definition edit knowledge triplet ie subject object relation however application language model expand diverse way wish edit refine output study broaden scope editing problem include array editing case debiasing rectifying reasoning error define edit natural language expression solicits change model output introducing dune editing benchmark edits natural language sentence propose dune present challenging yet relevant task substantiate claim conduct extensive series experiment testing various editing approach address dune demonstrating respective strength weakness argue retrievalaugmented language modeling outperform specialized editing technique neither set approach fully solved generalized editing problem covered benchmark
recently influence function present apparatus achieving explainability deep neural model quantifying perturbation individual train instance might impact test prediction objective paper twofold first incorporate influence function feedback model improve performance second dataset extension exercise using influence function automatically identify data point initially silver annotated existing method need crosschecked corrected annotator improve model performance meet objective paper introduce inffeed us influence function compute influential instance target instance toward first objective adjust label target instance based influencers label inffeed outperforms stateoftheart baseline including llm maximum macro fscore margin almost hate speech classification stance classification irony sarcasm detection toward second objective show manually reannotating silver annotated data point extension set negative influence immensely improve model performance bringing close scenario data point extension set gold label allows huge reduction number data point need manually annotated since silver annotated extension dataset influence function scheme pick textasciitilde point need manual correction
paper present analysis computationally generated mixedmodality definite referring expression using combination gesture linguistic description expose striking formal semantic property interaction gesture language conditioned introduction content common ground computational speaker human viewer demonstrate formal feature contribute training better model predict viewer judgment referring expression potentially generation natural informative referring expression
significant development technique encoderdecoder model enabled u represent information comprising multiple modality information enhance many downstream task field information retrieval natural language processing however improvement multimodal technique performance evaluation require largescale multimodal data offer sufficient diversity multilingual modeling variety task like multimodal summarization text generation translation leverage information derived highquality multilingual annotated data work present current largest multilingual multimodal summarization dataset ml consists million instance documentimage pair along professionally annotated multimodal summary pair derived news article published british broadcasting corporationbbc decade span language targeting diversity across five language root also largest summarization dataset language consists crosslingual summarization data language formally define multilingual multimodal summarization task utilizing dataset report baseline score various stateoftheart summarization technique multilingual setting also compare many similar datasets analyze uniqueness difficulty ml dataset code used work made available urlhttpsgithubcomanubhavjangramls
propose task opendomain information narration oin reverse task open information extraction oie implement dual structure language knowledge open domain develop agent called orator accomplish oin task assemble orator recently proposed oie agent logician dual system utilize duality structure reinforcement learning paradigm experimental result reveal dual structure oie oin task help build better oie agent oin agent
work detail approach addressing task b semeval task explainable detection online sexism edo task simple ensemble based majority vote system presented build proposal first review transformer carried best performing model selected part ensemble next model best hyperpameters searched using reduced data set finally trained model using data development phase ensemble system achieved fscore task b developed model based deberta transformer utilizing hyperparameters identified task development phase proposed model attained fscore overall methodology demonstrates effective approach task leveraging advanced machine learning technique hyperparameters search achieve high performance detecting classifying instance sexism online text
computational detection understanding empathy important factor advancing humancomputer interaction yet date textbased empathy prediction following major limitation underestimate psychological complexity phenomenon adheres weak notion ground truth empathic state ascribed third party lack shared corpus contrast contribution present first publicly available gold standard empathy prediction constructed using novel annotation methodology reliably capture empathy assessment writer statement using multiitem scale also first computational work distinguishing multiple form empathy empathic concern personal distress recognized throughout psychology finally present experimental result three different predictive model cnn performs best
issue clarin archive metadata level facilitate user possibility describe data even standard time make metadata meaningful variety user variety resource type ensure metadata useful search across resource national european level see different people different research community fill metadata different way even though metadata defined documented impacted metadata harvested displayed different environment loss information stake paper view challenge ensuring metadata interoperability example propagation metadata value clarindk archive vlo see clarin community many way support interoperability argue agreeing upon standard making clear definition semantics metadata content inevitable interoperability work successfully key point clear freely available definition accessible documentation easily usable facility guideline metadata creator
work examine method data augmentation textbased task neural machine translation nmt formulate design data augmentation policy desirable property optimization problem derive generic analytic solution solution subsumes existing augmentation scheme also lead extremely simple data augmentation strategy nmt randomly replacing word source sentence target sentence random word corresponding vocabulary name method switchout experiment three translation datasets different scale show switchout yield consistent improvement bleu achieving better comparable performance strong alternative word dropout sennrich et al code implement method included appendix
multiword term mwts domainspecific multiword expression mwe two lexeme converge form new unit meaning task processing mwts crucial many natural language processing nlp application including machine translation mt terminology extraction however automatic detection term difficult task research still required give insightful useful result field study seek fill gap using stateoftheart transformer model evaluate bert like discriminative transformer model generative pretrained transformer gpt model task show discriminative model perform better current gpt model multiword term identification task flower plant name english spanish language best discriminate model perform f score english spanish data respectively chatgpt could perform respectively
paper describes method result annotation two discourselevel phenomenon connective pronoun multilingual parallel corpus excerpt europarl english french annotated disambiguation information connective pronoun token data used several way crosslinguistic study training automatic disambiguation software ultimately training testing discourseaware statistical machine translation system paper present annotation procedure result detail overview first system trained annotated resource use machine translation
present detailed comparison two type sequence sequence model trained conduct compositional task model architecturally identical inference time differ way trained baseline model trained tasksuccess signal model receives additional supervision attention mechanism attentive guidance shown effective method encouraging compositional solution first confirm model attentive guidance indeed infer compositional solution baseline training lookup table task presented liska et al indepth analysis structural difference two model type focusing particular organisation parameter space hidden layer activation find noticeable difference aspect guided network focus component input rather sequence whole develop small functional group neuron specific purpose use gate selectively result parameter heat map component swapping graph analysis also indicate guided network exhibit modular structure small number specialized strongly connected neuron
building predictive model information extraction text named entity recognition extraction semantic relationship named entity text requires large corpus annotated text wikipedia often used corpus task annotation named entity linked hyperlink article however editor wikipedia expected link mention order help reader understand content discouraged adding link add benefit understanding article therefore many mention popular entity country popular event history previously linked article well article entity linked paper discus wexea wikipedia exhaustive entity annotation system create text corpus based wikipedia exhaustive annotation entity mention ie linking mention entity corresponding article result huge potential additional annotation used downstream nlp task relation extraction show annotation useful creating distantly supervised datasets task furthermore publish code necessary derive corpus raw wikipedia dump reproduced everyone
paper propose two neural machine translation nmt system frenchtowolof woloftofrench based sequencetosequence attention transformer architecture trained model parallel frenchwolof corpus nguer et al k sentence pair lowresource setting experimented advanced method handling data sparsity including subword segmentation backtranslation copied corpus method evaluate model using bleu score find transformer outperforms classic sequencetosequence model setting addition less sensitive noise general best score achieved training model subwordlevel based unit model using backtranslation prof slightly beneficial lowresource wolof highresource french language translation transformerbased model slight improvement also observed injecting copied monolingual text target language moreover combining copied method data backtranslation lead slight improvement translation quality
paper situates culminative unbounded stress system within subregular hierarchy function baek argued system uniformly understood input tierbased strictly local constraint show defaulttooppositeside defaulttosameside stress system belong distinct subregular class viewed function assign primary stress underlying form former system captured input tierbased input strictly local function subsequential function class define latter system subsequential though weakly deterministic according mccollum et al noninteraction criterion result motivate extension recently proposed subregular language class subregular function argue favor mccollum et al definition weak determinism heinz lai
study problem ontology population domain ontology present solution based semiautomatic technique domain ontology organization often consists class whose instance either specific independent organization eg academic domain ontology class like professor department could organization university specific conference programming language organization independent distinction allows u leverage data source bothwithin organization internet extract entity populate ontology propose technique build open domain ie together user input show comprehensive evaluation semiautomatic technique achieve high precision experimented academic domain built ontology comprising class intranet document five university formed organization specific corpus used open domain knowledge base like wikipedia linked open data web page internet organization independent data source populated ontology built one university comprised instance adhere semantic web standard tool make resource available owl format could useful application information extraction text annotation information retrieval
probing become goto methodology interpreting analyzing deep neural model natural language processing however still lack understanding limitation weakness various type probe work suggest strategy inputlevel intervention naturalistic sentence using approach intervene morphosyntactic feature sentence keeping rest sentence unchanged intervention allows u causally probe pretrained model apply naturalistic causal probing framework analyze effect grammatical gender number contextualized representation extracted three pretrained model spanish multilingual version bert roberta gpt experiment suggest naturalistic intervention lead stable estimate causal effect various linguistic property moreover experiment demonstrate importance naturalistic causal probing analyzing pretrained model urlhttpsgithubcomrycolabnaturalisticcausalprobing
africa world large increasing focus developing neural machine translation nmt system overcome language barrier nmt lowresource language particularly compelling involves learning limited labelled data however obtaining wellaligned parallel corpus lowresource language challenging disparity technological advancement global language lack research nmt local language chad striking endtoend nmt trial lowresource chad language attempted additionally dearth online wellstructured data gathering research natural language processing unlike african language however guided approach data gathering produce bitext data many chadian language translation pair wellknown language ample data project created first sbafr dataset corpus ngambaytofrench translation finetuned three pretrained model using dataset experiment show mm model outperforms model high bleu score original originalsynthetic data publicly available bitext dataset used research purpose
leveraging established exercise negotiation education build novel dataset studying use language shape bilateral bargaining dataset extends existing work two way recruit participant via behavioral lab instead crowdsourcing platform allow participant negotiate audio enabling naturalistic interaction add control setting participant negotiate alternating written numeric offer despite two contrasting form communication find average agreed price two treatment identical subject talk fewer offer exchanged negotiation finish faster likelihood reaching agreement rise variance price subject agree drop substantially propose taxonomy speech act negotiation enrich dataset annotated speech act work also reveals linguistic signal predictive negotiation outcome
research evaluate different approach automatic extraction hypernym relation english dutch technical text detected hypernym relation enable u semantically structure automatically obtained term list domain userspecific data investigated three different hypernymy extraction approach dutch english lexicosyntactic patternbased approach distributional model morphosyntactic method test performance different approach domainspecific data collected manually annotated english dutch data two technical domain viz dredging financial domain experimental result show especially morphosyntactic approach obtains good result automatic hypernym extraction technical domainspecific text
aspectbased sentiment analysis absa stand crucial task predicting sentiment polarity associated identified aspect within text however notable challenge absa lie precisely determining aspect boundary start end index especially long one due user colloquial expression propose diffusionabsa novel diffusion model tailored absa extract aspect progressively step step particularly diffusionabsa gradually add noise aspect term training process subsequently learning denoising process progressively restores term reverse manner estimate boundary design denoising neural network enhanced syntaxaware temporal attention mechanism chronologically capture interplay aspect surrounding text empirical evaluation conducted eight benchmark datasets underscore compelling advantage offered diffusionabsa compared robust baseline model code publicly available httpsgithubcomqlbxdiffusionabsa
argument map structure discourse node tree node argument support opposes parent argument format comprehensible less redundant compared unstructured one exploring map maintaining structure placing new argument suitable parent challenging user huge map typical online discussion support user introduce task node placement suggesting candidate node parent new contribution establish upperbound human performance conduct experiment model various size training strategy experiment selection map kialo drawn heterogeneous set domain based annotation study highlight ambiguity task make challenging human model examine unidirectional relation tree node show encoding node different embeddings parent child case improves performance show fewshot effectiveness approach
text analysis method widely used digital humanity often involve word cooccurrence eg concept cooccurrence network method provide useful corpus overview determine predicate relate cooccurring concept goal identifying proposition expressing point supported opposed participant international climate negotiation word cooccurrence method sufficient analysis based open relation extraction limited coverage nominal predicate present pipeline identifies point different actor support oppose via domain model supportopposition predicate analysis rule exploit output semantic role labelling syntactic dependency anaphora resolution entity linking keyphrase extraction also performed proposition related actor user interface allows examining main concept point supported opposed participant participant agree disagree issue system example tool digital humanity scholar asking render rich textual information beyond word cooccurrence amenable quantitative treatment evaluation tool satisfactory
study emotion recognition er show combining lexical acoustic information result robust accurate model majority study focus setting modality available training evaluation however practice always case getting asr output may represent bottleneck deployment pipeline due computational complexity privacyrelated constraint address challenge study problem efficiently combining acoustic lexical modality training still providing deployable acoustic model require lexical input first experiment multimodal model two attention mechanism assess extent benefit lexical information provide frame task multiview learning problem induce semantic information multimodal model acousticonly network using contrastive loss function multimodal model outperforms previous state art usciemocap dataset reported lexical acoustic information additionally multiviewtrained acoustic network significantly surpasses model exclusively trained acoustic feature
verbal nonverbal communication skill essential humanrobot interaction particular agent involved shared task address specific situation robot agent knowing plan goal task instruct human partner case study brick assembly describe multilayered verbal depictor whose semantic syntactic lexical setting collected evaluated via crowdsourcing one crowdsourced experiment involves robot instructed pickandplace task show implicitly referring achieved subgoals stair pillow etc increase performance human partner
today news medium organization regularly engage reader enabling comment news article creates need comment moderation removal disallowed comment timeconsuming task often performed human moderator paper approach problem automatic news comment moderation classification comment blocked blocked category construct novel dataset annotated english comment experiment crosslingual transfer comment label evaluate several machine learning model datasets croatian estonian news comment team name superadmin challenge detection blocked comment toolsmodels crosloen bert finest bert sata comment dataset ekspress comment dataset
deep learning model automatic readability assessment generally discard linguistic feature traditionally used machine learning model task propose incorporate linguistic feature neural network model learning syntactic dense embeddings based linguistic feature cope relationship feature form correlation graph among feature use learn embeddings similar feature represented similar embeddings experiment six data set two proficiency level demonstrate proposed methodology complement bertonly model achieve significantly better performance automatic readability assessment
pretrained word embeddings improve performance neural model cost increasing model size propose benefit resource without paying cost operating strictly sublexical level approach quite simple taskspecific training first optimize subword parameter reconstruct pretrained word embeddings using various distance measure report interesting result variety task word similarity word analogy partofspeech tagging
interpretable rationale model prediction crucial practical application develop neural model possess interpretable inference process dependency parsing model adopt instancebased inference dependency edge extracted labeled comparing edge training set training edge explicitly used prediction thus easy grasp contribution edge prediction experiment show instancebased model achieve competitive accuracy standard neural model reasonable plausibility instancebased explanation
parsing speech requires richer representation best nbest hypothesis eg lattice moreover previous work show partofspeech po tag valuable resource parsing paper therefore explore joint modeling approach automatic speech recognition asr po tagging enrich asr word lattice end manipulate asr process pronouncing dictionary onward use wordpos pair instead word evaluate asr po tagging dependency parsing dp performance demonstrating successful latticebased integration asr po tagging
deal scenario conversational search user query underspecified ambiguous call mixedinitiative setup userasks query systemanswers well systemasks clarification question user response order clarify information need focus task selecting next clarification question given conversation context method leverage passage retrieval background content finetune two deeplearning model ranking candidate clarification question evaluated method two different usecases first open domain conversational search large web collection second taskoriented customersupport setup show method performs well usecases
pandemic period stayathome trend forced business switch activity digital mode example appbased payment method social distancing via social medium platform digital mean become integral part life sentiment analysis textual information user comment topical task emotion ai user comment review homogeneous contain sparse context behind misleading human computer barrier arise emotional language enriched slang peculiar spelling transliteration use emoji symbolic counterpart codeswitching low resource language sentiment analysis worked upon extensively absence readymade tool linguistic resource sentiment analysis research focus developing method aspectbased sentiment analysis kazakhlanguage review android google play market
pretraining finetuning paradigm alleviating data scarcity problem endtoend speech translation ee st commonplace modality gap speech text data often lead inconsistent input pretraining finetuning however observe gap occurs early stage finetuning major impact final performance hand find another gap call capacity gap high resource task asr mt always require large model fit model reused low resource task ee st get suboptimal performance due overfitting case study find regularization play important role welldesigned modality adaption method achieves ende enfr mustc dataset
longrange semantic coherence remains challenge automatic language generation understanding demonstrate large language model insufficiently learned effect distant word nexttoken prediction present coherence boosting inference procedure increase lm focus long context show benefit coherence boosting pretrained model distributional analysis generated ordinary text dialog response also found coherence boosting stateoftheart model various zeroshot nlp task yield performance gain additional training
largescale visionlanguage pretraining exhibited strong performance various visual textual understanding task recently textual encoders multimodal pretrained model shown generate highquality textual representation often outperform model purely textbased bert study objective utilize textual visual encoders multimodal pretrained model enhance language understanding task achieve generating image associated textual prompt thus enriching representation phrase downstream task result experiment conducted four benchmark datasets demonstrate proposed method leverage visuallyenhanced text representation significantly improves performance entity clustering task
grammatical error correction gec enhances language proficiency promotes effective communication research primarily centered around english propose simple approach multilingual lowresource gec exploring potential multilingual machine translation mt model error correction show mt model capable error correction outofthebox also finetuned even better correction quality result show effectiveness approach multilingual model outperforming similarsized mtbased model even competing favourably larger model
paper mainly introduces method task task b clscisumm task identify reference text reference paper traditional machine learning model mlp model used evaluate performance model submit final result optimal model compared previous work optimize ratio positive negative example data sampling order construct feature classification calculate similarity reference text candidate sentence based sentence vector accordingly nine similarity used eight chosen used clscisumm new sentence similarity based fasttext added task b classify facet reference text unlike method used clscisumm construct input model based word vector add deep learning model classification year
transfer learning tl proposes enhance machine learning performance problem reusing labeled data originally designed related problem particular domain adaptation consists specific task reusing training data developed task distinct domain particularly relevant application deep learning natural language processing usually require large annotated corpus may exist targeted domain exist side domain paper experiment tl task relation extraction biomedical text using treelstm model empirically show impact treelstm alone domain adaptation obtaining better performance state art two biomedical task equal performance two others annotated data available furthermore propose analysis role syntactic feature may play tl
well documented reviewer opinion nativeness expression academic paper affect likelihood accepted publication previous work also shone light stress anxiety author nonnative english speaker experience attempting publish international venue explore might concern field natural language processing nlp conducting comprehensive statistical analysis nlp paper abstract identifying author different linguistic background differ lexical morphological syntactic cohesive aspect writing analysis identify number characteristic highly variable across different corpus examined paper indicates potential presence linguistic bias therefore outline set recommendation publisher academic journal conference regarding guideline resource prospective author order help enhance inclusivity fairness
machine translation english retrieval information language material research program sponsored intelligence advanced research project activity iarpa focus rapid development endtoend system capable retrieving foreign language speech text document relevant different type english query may restricted domain system also provide evidence relevance retrieved content form english summary program focus lessresourced language provides performer team limited amount annotated training data paper describes corpus created system development evaluation six language released program date tagalog swahili somali lithuanian bulgarian pashto corpus include build pack train machine translation automatic speech recognition system document set three text three speech genre annotated domain partitioned analysis development evaluation query several type together corresponding binary relevance judgment entire set document paper also describes detection metric called actual query weighted value developed program evaluate endtoend system performance
creating classifier disinformation timeconsuming expensive requires vast effort expert spanning different field even effort succeed rollout publicly available application stagnates model struggle find consumeraccessible use disinformation behavior online evolves pressing speed hoax get shared various abbreviation social network often userrestricted area making external monitoring intervention virtually impossible repurpose existing nlp method new paradigm sharing misinformation propose leveraging information given text originating news source proxy respective text trustworthiness first present methodology determining source overall credibility demonstrate pipeline construction specific language introduce cnsc novel dataset czech article news source source credibility classification constitute initial benchmark multiple architecture lastly create inthewild wrapper application trained model chatbot browser extension standalone web application
paper present system used submission textitiwpt shared task year official evaluation metric ela therefore dependency parsing might avoided well pipeline stage like po tagging lemmatization nevertheless chose deploy combination dependency parser graph parser dependency parser biaffine parser us transformer representing input sentence feature graph parser semantic parser exploit similar architecture except using sigmoid crossentropy loss function return multiple value predicted arc final output obtained merging output two parser dependency parser achieves top close top la performance respect system report result metric except low resource language tamil estonian latvian
eclipseannotator extensible tool creation multimodal language resource based tasxannotator refactored order fit plugin based architecture new application
paper describes process resource used automatically annotate french corpus spontaneous speech transcription superchunks superchunks enhanced chunk contain lexical multiword unit partial parsing based preprocessing stage spoken data consists reformatting tagging utterance break syntactic structure text disfluency spoken specificity formalized thanks systematic linguistic study hourlong speech transcription corpus chunker us largecoverage finegrained language resource general written language augmented resource specific spoken french consists iteratively applying finitestate lexical syntactic resource outputing finite automaton representing possible chunk analysis best path selected thanks hybrid disambiguation stage show system reach score comparable stateoftheart result field
lexical semantic change detection study word change meaning corpus schlechtweg et al standardized datasets evaluation metric shared task interested applying semantic change detection model small corporaeg digital humanitiesthere need evaluation involving much smaller datasets present method opensource code pipeline downsampling semeval task corpus preserving gold standard measure semantic change evaluate several stateoftheart model trained downsampled corpus find dramatically decreased performance average decrease high variance also propose novel application digital humanity provide case study demonstrating semantic change detection used exploratory manner produce insightful avenue investigation literary scholar
several largescale datasets eg wikisql spider developing natural language interface database recently proposed datasets cover wide breadth domain fall short essential domain finance accounting given accounting database used worldwide particularly nontechnical people imminent need develop model could help extract information accounting database via natural language query resource paper aim fill gap proposing new largescale texttosql dataset accounting financial domain booksql dataset consists k natural language queriessql pair accounting database million record experiment analyze existing stateoftheart model including gpt texttosql task booksql find significant performance gap thus pointing towards developing focused model domain
search space grammarbased natural language generation task get large particularly problematic generating long utterance paragraph using surface realization openccg example show effectively detect partial solution edge ultimately part complete sentence syntactic category formulating completion edge sentence finding solution path large statetransition system demonstrate connection ai planning concerned kind problem design compilation openccg ai planning allowing detection infeasible edge via ai planning deadend detection method proving absence solution compilation experiment show filter large fraction infeasible edge thus benefit performance complex realization process
paper present system used participate task multiconer semeval competition system ranked fourth place track multilingual fifth place track codemixed goal track detect complex named entity multilingual setting track dedicated detecting complex named entity codemixed setting system developed using transformerbased language model used ensemble xlmrobertalarge microsoftinfoxlmlarge conditional random field crf layer addition describe algorithm employed train model hyperparameter selection furthermore study impact different method aggregate output individual model compose ensemble finally present extensive analysis result error
spelling correction attracted lot attention nlp community however model usually evaluated artificiallycreated proprietary corpus publiclyavailable corpus authentic misspelling annotated context still lacking address present release annotated data set spelling error context based corpus essay written english language learner also develop minimallysupervised contextaware approach spelling correction achieves strong result data accuracy approach also train minimal amount annotated data performance reduced less furthermore approach allows easy portability new domain evaluate model data medical domain demonstrate rival performance model trained tuned indomain data
interested certain domain collect analyze data internet newly collected data labeled use labeled data hoped helpful new data perform name entity recognition ner aspectbased sentiment analysis absa multitask learning combine parameter generation network dann architecture build model ner task data labeled tie break task weight adjusted according loss change rate task using dynamic weight average dwa study used two different source domain data set experimental result show tie break improve result model dwa better performance result combination parameter generation network gradient reversal layer used every good learning different domain
paper present multimodal corpus collected annotated nordic nomco project corpus used study communicative phenomenon feedback turn management sequencing already include video material swedish danish finnish estonian several social activity represented data make possible verify empirically gesture head movement facial display hand gesture body posture speech interact three mentioned aspect communication data annotated following mumin annotation scheme provides attribute concerning shape communicative function head movement face expression body posture hand gesture described corpus paper discusses used study way feedback expressed speech gesture report result two pilot study investigated function head gesture single repeated combination feedback expression annotated corpus valuable source research intercultural communication well interaction individual language
recently growing interest automatic generation cooking recipe satisfy form dietary restriction thanks part availability online recipe data prior study used pretrained language model relied small paired recipe data eg recipe paired similar one satisfies dietary constraint however pretrained language model generate inconsistent incoherent recipe paired datasets available scale address deficiency recipecrit hierarchical denoising autoencoder edits recipe given ingredientlevel critique model trained recipe completion learn semantic relationship within recipe work main innovation unsupervised critiquing module allows user edit recipe interacting predicted ingredient system iteratively rewrite recipe satisfy user feedback experiment onthe recipem recipe dataset show model effectively edit recipe compared strong languagemodeling baseline creating recipe satisfy user constraint correct serendipitous coherent relevant measured human judge
language technology contribute promoting multilingualism linguistic diversity around world however small number language world represented rapidly evolving language technology application paper look relation type language resource representation nlp conference understand trajectory different language followed time quantitative investigation underline disparity language especially term resource call question language agnostic status current model system paper attempt convince acl community prioritise resolution predicament highlighted language left behind
article describes proposed arabic sentiment analysis system named arbsen system designed international workshop semantic evaluation semeval task affect tweet arbsen proposes two supervised model estimate sentiment intensity arabic tweet model use set feature including sentiment lexicon negation word embedding emotion symbol feature system combine feature assist sentiment analysis task arbsen system achieves correlation score ranking th among participant valence intensity regression vreg arabic subtask organized within semeval evaluation campaign
knearestneighbor machine translation knnmt recently proposed nonparametric solution domain adaptation neural machine translation nmt aim alleviate performance degradation advanced mt system translating outofdomain sentence coordinating additional tokenlevel featurebased retrieval module constructed indomain data previous study khandelwal et al zheng et al already demonstrated nonparametric nmt even superior model finetuned outofdomain data spite success knn retrieval expense high latency particular large datastores make practical paper explore efficient knnmt propose use clustering improve retrieval efficiency concretely first propose clusterbased compact network feature reduction contrastive learning manner compress context feature lower dimensional vector suggest clusterbased pruning solution filter redundant node large datastores retaining translation quality proposed method achieve better comparable performance reducing inference latency advanced nonparametric mt model several machine translation benchmark experimental result indicate proposed method maintain useful information original datastore compact network show good generalization unseen domain code available urlhttpsgithubcomtjunlplabpckmt
message human conversation inherently convey emotion task detecting emotion textual conversation lead wide range application opinion mining social network however enabling machine analyze emotion conversation challenging partly human often rely context commonsense knowledge express emotion paper address challenge proposing knowledgeenriched transformer ket contextual utterance interpreted using hierarchical selfattention external commonsense knowledge dynamically leveraged using contextaware affective graph attention mechanism experiment multiple textual conversation datasets demonstrate context commonsense knowledge consistently beneficial emotion detection performance addition experimental result show ket model outperforms stateoftheart model tested datasets f score
active learning al us data selection algorithm select useful training sample minimize annotation cost essential tool building lowresource syntactic analyzer partofspeech po tagger existing al heuristic generally designed principle selecting uncertain yet representative training instance annotating instance may reduce large number error however empirical study across six typologically diverse language german swedish galician north sami persian ukrainian found surprising result even oracle scenario know true uncertainty prediction current heuristic far optimal based analysis pose problem al selecting instance maximally reduce confusion particular pair output tag extensive experimentation aforementioned language show proposed al strategy outperforms al strategy significant margin also present auxiliary result demonstrating importance proper calibration model ensure crossview training analysis demonstrating proposed strategy selects example closely follow oracle data distribution code publicly released
eligibility criterion clinical trial specify characteristic patient must must possess order treated according standard clinical care guideline process manual eligibility determination timeconsuming automatic structuring eligibility criterion various semantic category aspect need hour existing method use handcrafted rule featurebased statistical machine learning method dynamically induce semantic aspect however order deal paucity aspectannotated clinical trial data propose novel weaklysupervised cotraining based method exploit large pool unlabeled criterion sentence augment limited supervised training data consequently enhance performance experiment criterion sentence show proposed approach outperforms competitive supervised baseline term microaveraged f score aspect probing deeper analysis observe domainspecific information boost performance significant margin
taxonomy widely used various number downstream nlp task therefore kept uptodate paper present taxfree open source system taxonomy visualisation automatic taxonomy enrichment without predefined candidate example wordnet oppose traditional task formulation list new word provided beforehand provide approach automatic extension taxonomy using large pretrained language model advantage existing visualisation tool wordnet taxfree also integrates graphic representation synset imagenet visualisation tool used updating taxonomy inspecting required modification
paper take stock current state summarization datasets explore different factor datasets influence generalization behaviour neural extractive summarization model specifically first propose several property datasets matter generalization summarization model build connection prior residing datasets model design analyzing different property datasets influence choice model structure design training method finally taking typical dataset example rethink process model design based experience analysis demonstrate deep understanding characteristic datasets simple approach bring significant improvement existing stateoftheart model
existing leading code comment generation approach structuretosequence framework ignores type information interpretation code eg operator string etc however introducing type information existing framework nontrivial due hierarchical dependence among type information order address issue propose type auxiliary guiding encoderdecoder framework code comment generation task considers source code nary tree type information associated node specifically framework featured typeassociated encoder typerestricted decoder enables adaptive summarization source code propose hierarchical reinforcement learning method resolve training difficulty proposed framework extensive evaluation demonstrate stateoftheart performance framework autoevaluated metric case study
challenging task generating summary legal document ability address argumentative nature introduce simple technique capture argumentative structure legal document integrating argument role labeling summarization process experiment pretrained language model show proposed approach improves performance strong baseline
uncertainty measurement classifier prediction especially important application medical diagnosis need ensure limited human resource focus uncertain prediction returned machine learning model however existing uncertainty model attempt improve overall prediction accuracy human resource involved text classification task paper propose novel neuralnetworkbased model applies new dropoutentropy method uncertainty measurement also design metric learning method feature representation boost performance dropoutbased uncertainty method smaller prediction variance accurate prediction trial extensive experiment realworld data set demonstrate method achieve considerable improvement overall prediction accuracy compared existing approach particular model improved accuracy uncertain prediction handed human expert newsgroup data
multihead selfattention popular transformer model widely used within natural language processing nlp including task extractive summarization goal analyzing pruning parameterheavy selfattention mechanism multiple approach proposing parameterlight selfattention alternative paper present novel parameterlean selfattention mechanism using discourse prior new tree selfattention based documentlevel discourse information extending recently proposed synthesizer framework another lightweight alternative show empirical result tree selfattention approach achieves competitive rougescores task extractive summarization compared original singlehead transformer model tree attention approach reach similar performance edu sentence level despite significant reduction parameter attention component significantly outperform head transformer model sentence level applying balanced hyperparameter setting requiring order magnitude less parameter
wrote report japanese translated nec machine translation system pivotje ibs international business service company documentation service contains translation business introduced machine translation system translation business earnest last year introduction machine translation system changed form translation work translation work divided step person isnt experienced became able take work translation step result total translation cost reduced paper first report usage machine translation system next report translation quality translation cost machine translation system lastly report merit gotten introducing machine translation
paper present flexible open source framework deep semantic role labeling aim facilitating easy exploration model structure multiple language different characteristic provides flexibility model construction term word representation sequence representation output modeling inference style come clear output visualization framework available apache license
automatic dialogue summarization task used succinctly summarize dialogue transcript correctly linking speaker speech distinguishes task conventional document summarization address issue reduce said whatrelated error summary propose embedding speaker identity information input embedding dialogue transcript encoder unlike speaker embedding proposed gu et al proposal take account informativeness position embedding experimentally comparing several embedding method confirmed score rouge human evaluation generated summary substantially increased embedding speaker information less informative part fixed position embedding sinusoidal function
recent success large pretrained language model plms heavily hinge massive labeled data typically produce inferior performance lowresource scenario remedy dilemma study selftraining one predominant semisupervised learning ssl approach utilizes largescale unlabeled data generate synthetic example however many noisy label hurt model performance selftraining procedure requires multiple training iteration making expensive model parameter plm updated paper present upet novel uncertaintyaware parameterefficient selftraining framework effectively efficiently address labeled data scarcity issue specifically incorporate monte carlo mc dropout bayesian neural network bnn perform uncertainty estimation teacher model judiciously select reliable pseudolabeled example based confidence certainty student training introduce multiple parameterefficient learning pel paradigm allow optimizes small percentage parameter also propose novel easyhard contrastive tuning enhance robustness generalization extensive experiment multiple downstream task demonstrate upet achieves substantial improvement term performance efficiency code data released http githubcomwjnupet
evolution pretrained language model current opendomain dialogue system achieved great progress conducting onesession conversation contrast multisession conversation msc consists multiple session long term user underinvestigated paper propose historyaware hierarchical transformer haht multisession opendomain dialogue haht maintains longterm memory history conversation utilizes history information understand current conversation context generate wellinformed contextrelevant response specifically haht first encodes history conversation session hierarchically history memory haht leverage historical information facilitate understanding current conversation context encoding history memory together current context attentionbased mechanism finally explicitly utilize historical information haht us historyaware response generator switch generic vocabulary historyaware vocabulary experimental result largescale msc dataset suggest proposed haht model consistently outperforms baseline model human evaluation result support haht generates humanlike contextrelevant historyrelevant response baseline model
fresh way improve user viewing experience video timesync comment attracted lot interest many effort made explore effectiveness timesync comment various application however due complexity interaction among user video comment still remains challenging understand user behavior timesync comment along line study problem timesync comment behavior prediction consideration historical behavior multimodal information visual frame textual comment specifically propose novel multimodal short longrange temporal convolutional network model namely mrt firstly design two amplified temporal convolutional network different size receptive field capture short longrange surrounding context frame timesync comment design bottleneck fusion module obtain multimodal enhanced representation furthermore take user preference consideration generate personalized multimodel semantic representation timestamp finally utilize binary crossentropy loss optimize mrt basis user historical record comparing representative baseline demonstrate effectiveness mrt qualitatively verify necessity utility short longrange contextual multimodal information extensive experiment
supervised training crossentropy loss implicitly force model produce probability distribution follow discrete delta distribution model prediction test time expected similar delta distribution classifier determines class input correctly however shape predicted probability distribution become similar uniform distribution model infer properly exploit observation detecting outofscope oos utterance conversational system specifically propose zeroshot postprocessing step called distancetouniform du exploiting classification confidence score shape entire output distribution later combine learning procedure us du loss calculation supervised setup conduct experiment using six publicly available datasets experimental result show performance oos detection improved postprocessing oos training data well du learning procedure oos training data available
identifying linking named entity across information source basis knowledge acquisition heart web search recommendation analytics important problem context crossdocument coreference resolution ccr computing equivalence class textual mention denoting entity within across document prior method employ ranking clustering probabilistic graphical model using syntactic feature distant feature knowledge base however method exhibit limitation regarding runtime robustness paper present crocs framework unsupervised ccr improving state art two way first extend way knowledge base harnessed constructing notion semantic summary intradocument coreference chain using cooccurring entity mention belonging different chain second reduce computational cost new algorithm embeds samplebased bisection using spectral clustering graph partitioning hierarchical clustering process allows scaling ccr large corpus experiment three datasets show significant gain output quality compared best prior method runtime efficiency crocs
propose sentence chunking way reduce time memory cost realization long sentence chunking divide semantic representation sentence smaller component processed recombined without loss information meaning representation choice dependency minimal recursion semantics dmrs show realizing chunk sentence combining result realization increase coverage long sentence significantly reduces resource required affect quality realization
word class often neglected field nlp resource namely adverb lately described computational lexicon produced cst one result phdproject adverb lexicon integrated danish sto lexicon give detailed syntactic information type modification position well syntactic property approx danish adverb one aim lexicon establish clear distinction syntactic semantic information lexicon often generalize syntactic behavior semantic class adverb every adverb described respect proper syntactic behavior text corpus revealing individual syntactic property syntactic information adverb needed nlp system generating text ensure correct placing phrase modify also system analyzing text information needed order attach adverb right node syntactic parse tree within field linguistic research several result deduced lexicon eg knowledge syntactic class danish adverb
tackle problem neural machine translation mathematical formula ambiguous presentation language unambiguous content language compared neural machine translation natural language mathematical formula much smaller vocabulary much longer sequence symbol translation requires extreme precision satisfy mathematical information need work perform task translating latex mathematica well latex semantic latex recurrent recursive transformer network struggle preserving contained information find convolutional sequencetosequence network achieve exact match respectively
despite many difference phrasebased hierarchical syntaxbased translation model training testing pipeline strikingly similar drawing fact extend moses toolkit implement hierarchical syntactic model making first open source toolkit endtoend support three popular model single package extension substantially lower barrier entry machine translation research across multiple model
expect interact home assistant irrespective language however scaling natural language understanding pipeline multiple language keeping level accuracy remains challenge work leverage inherent multilingual aspect translation model task multilingual intent classification slot filling experiment reveal work equally well generalpurpose multilingual texttotext model furthermore accuracy improved artificially increasing size training set unfortunately increasing training set also increase overlap test set leading overestimating true capability result propose two new evaluation method capable accounting overlap training test set
investigate inputconditioned hypernetworks multitasking nlp generating parameterefficient adaptation decoder using hypernetwork conditioned output encoder approach produce unique decoder adaptation every input instance allowing network larger degree flexibility prior work produce one decoder adaptation per task apply method sequence classification task extractive qa summarisation find surpasses previous parameter efficient finetuning method often outperforms fully finetuning underlying model analysis embeddings used hypernetwork show sensitive output label type suggesting approach better map encoder representation output label code publicly available httpsgithubcomallenaihyperdecoders
neural machine translation nmt achieved great progress recent year still suffers inaccurate translation entity eg personorganization name location due lack entity training instance human encounter unknown entity translation usually first look dictionary organize entity translation together translation part form smooth target sentence inspired translation process propose extractandattend approach enhance entity translation nmt translation candidate source entity first extracted dictionary attended nmt model generate target sentence specifically translation candidate extracted first detecting entity source sentence translating entity looking dictionary extracted candidate added prefix decoder input attended decoder generating target sentence selfattention experiment conducted enzh enru demonstrate proposed method effective improving translation accuracy entity overall translation quality reduction entity error rate gain bleu gain comet
paper describes team submission eacl dravidianlangtechs shared task machine translation dravidian language submitted translation english malayalam tamil telugu also tamiltelugu language pair submission mainly focus adequate amount data backed good preprocessing produce quality translationswhich includes custom made rule remove unnecessary sentence conducted several experiment model tweaking architecturebyte pair encoding bpe hyperparameters
documentlevel mt model still far satisfactory existing work extend translation unit single sentence multiple sentence however study show enlarge translation unit whole document supervised training transformer fail paper find failure caused overfitting sticking around local minimum training analysis show increased complexity targettosource attention reason failure solution propose gtransformer introducing locality assumption inductive bias transformer reducing hypothesis space attention target source experiment show gtransformer converges faster stably transformer achieving new stateoftheart bleu score nonpretraining pretraining setting three benchmark datasets
work study multisource testtime model adaptation user feedback k distinct model established adaptation allow efficient adaptation cast problem stochastic decisionmaking process aiming determine best adapted model adaptation discus two framework multiarmed bandit learning multiarmed dueling bandit compared multiarmed bandit learning dueling framework allows pairwise collaboration among k model solved novel method named coucb proposed work experiment six datasets extractive question answering qa show dueling framework using coucb effective strong baseline studied problem
data sharing restriction common nlp especially clinical domain limited research adapting model new domain without access original training data setting known sourcefree domain adaptation take algorithm traditionally assume access sourcedomain training dataactive learning selftraining data augmentationand adapt source free domain adaptation systematically compare different strategy across multiple task domain find active learning yield consistent gain across semeval task task domain though shared task saw successful selftrained data augmented model systematic comparison find strategy unreliable sourcefree domain adaptation
measuring document similarity play important role natural language processing task existing document similarity approach suffer information gap caused context vocabulary mismatch comparing varyinglength text paper propose unsupervised concept representation learning approach address issue specifically propose novel concept generation network cgnet learn concept representation perspective entire text corpus moreover conceptbased document matching method proposed leverage advance recognition local phrase feature corpuslevel concept feature extensive experiment realworld data set demonstrate new method achieve considerable improvement comparing lengthvarying text particular model achieved better f score compared best baseline model conceptproject benchmark dataset
selfattention mechanism made striking stateoftheart sota progress various sequence learning task standing multiheaded dot product attention attending global context different location pseudo information highway introduce gated component selfdependency unit sdu incorporates lstmstyled gating unit replenish internal semantic importance within multidimensional latent space individual representation subsidiary contentbased sdu gate allow information flow modulated latent embeddings skipped connection leading clear margin convergence speed gradient descent algorithm may unveil role gating mechanism aid contextbased transformer module hypothesizing sdu gate especially shallow layer could push faster step towards suboptimal point optimization process
pretrained language model word representation bert extremely successful several natural language processing task significantly improving stateoftheart largely attributed ability better capture semantic information contained within sentence several task however benefit information available corpus level term frequencyinverse document frequency tfidf work test effectiveness integrating information bert task identifying abuse social medium show integrating information bert indeed significantly improve performance participate subtask abuse detection wherein achieve score within two point top performing team subtask b target detection wherein ranked participating team
typical product place often hundred review summarization text important challenging problem recent progress abstractive summarization domain news driven supervised system trained hundred thousand news article paired humanwritten summary however opinion text large scale datasets rarely available unsupervised method selftraining fewshot learning approach bridge gap work present novel selftraining approach opinesum abstractive opinion summarization selftraining summary approach built automatically using novel application textual entailment capture consensus opinion across various review item method used obtain silverstandard summary large scale train unsupervised fewshot abstractive summarization system opinesum outperforms strong peer system setting
paper describes effort development proposition bank urdu indoaryan language primary goal labeling syntactic node existing urdu dependency treebank specific argument label essence involves annotation predicate argument structure simple complex predicate treebank corpus describe overall process building propbank urdu discus various statistic pertaining urdu propbank issue annotator encountered developing propbank also discus challenge addressed successfully expand propbank corpus reporting interannotator agreement two annotator show annotator share similar understanding annotation guideline linguistic phenomenon present language present size propbank around token doublepropbanked two annotator simple predicate another token annotated complex predicate urdu
pretrained model shown successful performance program language processing well natural language processing adversarial attack model also attract attentionhowever previous work blackbox adversarial attack generated adversarial example inefficient way simple greedy search also failed find better adversarial example hard reduce search space without performance lossin paper propose tab efficient beam search blackbox adversarial attack method adopt beam search find better adversarial example contextual semantic filtering effectively reduce search space contextual semantic filtering reduces number candidate adversarial word considering surrounding context semantic similarityour proposed method show good performance term attack success rate number query semantic similarity attacking model two task nl code search classification retrieval task
electronic health record contain important information regarding patient medical history much information stored unstructured narrative text paper present first danish clinical named entity recognition relation extraction dataset extraction six type clinical event six type attribute three type relation dataset contains paragraph danish electronic health record containing clinical event attribute relation detail methodology developing annotation scheme train transformerbased architecture developed dataset macro f performance clinical event attribute relation respectively
given sentence abby told brittney upset courtney one would struggle understand refers ask clarification however word upset replaced hugged unambiguously refers abby study modern coreference resolution model sensitive pronominal ambiguity end construct ambicoref diagnostic corpus minimal sentence pair ambiguous unambiguous referent example generalize psycholinguistic study human perception ambiguity around particular arrangement verb argument analysis show human less sure referent ambiguous ambicoref example unambiguous one coreference model show little difference output ambiguous unambiguous pair release ambicoref diagnostic corpus testing whether model treat ambiguity similarly human
semantic similarity collocation along word similarity one main issue nlp must addressed particular order facilitate automatic thesaurus generation paper consider logicallinguistic model allows defining relation semantic similarity collocation via logicalalgebraic equation provide model english ukrainian russian text corpus implementation language slightly different equation finite predicate algebra used linguistic resource dataset experiment use pair sentence microsoft research paraphrase corpus english text scientific paper russian ukrainian
uyghur one turkic language altaic language family developing machine translation system translate english uyghur previous research devoted machine translation english uyghur short related work could use base research noted making clear morphological syntactic similarity difference japanese uyghur make use approach method englishjapanese machine translation make faster progress research order attain goal performed comparative study japanese uyghur grammar paper describe similarity well difference japanese uyghur level morphology syntax give brief description englishuyghur transfer method aiming applying comparative study japanese uyghur grammar
paper metu turkish discourse bank browser tool developed browsing annotated annotated discourse relation middle east technical university metu turkish discourse bank tdb project presented tool provides clear interface browsing annotated corpus wide range search option analyze annotation
many domain argumentation people argument driven socalled attitude root ie underlying belief world view corresponding attitude theme given strength latent driver argument recent work psychology suggests instead directly countering surfacelevel reasoning eg falsifying premise one follow argumentation style inspired jiujitsu soft combat system first identify arguer attitude root theme choose prototypical rebuttal aligned driver instead trying invalidate work first explore jiujitsu argumentation peer review proposing novel task attitude themeguided rebuttal generation end enrich existing dataset discourse structure peer review attitude root attitude theme canonical rebuttal facilitate process recast established annotation concept domain peer review eg aspect review sentence relating train domainspecific model propose strong rebuttal generation strategy benchmark novel dataset task endtoend attitude themeguided rebuttal generation two subtasks
comprehending dialogue requires model capture diverse kind key information utterance either scattered around implicitly implied different turn conversation therefore dialogue comprehension requires diverse capability paraphrasing summarizing commonsense reasoning towards objective pretraining zeroshot dialogue comprehension model develop novel narrativeguided pretraining strategy learns narrating key information dialogue input however dialoguenarrative parallel corpus pretraining strategy currently unavailable reason first construct dialoguenarrative parallel corpus automatically aligning movie subtitle synopsis pretrain bart model data evaluate performance four dialoguebased task require comprehension experimental result show model achieves superior zeroshot performance also exhibit stronger finegrained dialogue comprehension capability data code available urlhttpsgithubcomzhaochaocsdiana
paper assess ability bert derivative model roberta distilbert albert shortedits based humor grading test model humor grading classification task humicroedit funlines dataset perform extensive experiment model test language modeling generalization ability via zeroshot inference crossdataset inference based approach also inspect role selfattention layer humorgrading performing qualitative analysis selfattention weight final layer trained bert model experiment show pretrained bert derivative model show significant generalization capability humorgrading related task
prior work natural language inference nli debiasing mainly target one known bias necessarily making model robust paper focus modelagnostic debiasing strategy explore possible make nli model robust multiple distinct adversarial attack keeping even strengthening model generalization power firstly benchmark prevailing neural nli model including pretrained one various adversarial datasets try combat distinct known bias modifying mixture expert moe ensemble method show nontrivial mitigate multiple nli bias time modellevel ensemble method outperforms moe ensemble method also perform data augmentation including text swap word substitution paraphrase prove efficiency combating various though adversarial attack time finally investigate several method merge heterogeneous training data perform model ensembling straightforward effective strengthen nli model
transcription bottleneck often cited major obstacle effort document world endangered language supply language technology one solution extend method automatic speech recognition machine translation recruit linguist provide narrow phonetic transcription sentencealigned translation however believe approach good fit available data skill longestablished practice essentially wordbased seeking effective approach consider century transcription practice wide range computational approach proposing computational model based spoken term detection call sparse transcription represents shift away current assumption transcribe phone transcribe fully transcribe first instead sparse transcription combine older practice wordlevel transcription interpretive iterative interactive process amenable wider participation open way new method processing oral language
formal constraint crossing dependency played large role research formal complexity natural language grammar parsing ask whether apparent evidence constraint crossing dependency treebanks might arise independent constraint tree low arity dependency length minimization address question using two set experiment experiment compare distribution formal property crossing dependency gap degree real tree baseline tree matched rate crossing dependency various property experiment model whether two dependency cross given certain psycholinguistic property dependency find surprisingly weak evidence constraint originating mild contextsensitivity literature gap degree wellnestedness beyond explained constraint rate crossing dependency topological property tree dependency length however measure emerged parsing literature eg edge degree endpoint crossing head depth difference differ strongly real random tree modeling result show cognitive metric relating information locality workingmemory limitation affect whether two dependency cross fully explain distribution crossing dependency natural language together result suggest crossing constraint better characterized processing pressure mildly contextsensitive constraint
paper present extscminetrans englishtochinese speech translation system developed two challenge track iwslt ie offline speech translation st speechtospeech translation sst st track extscminetrans employ practical cascaded system explore limit translation performance constrained unconstrained setting whole system consists automatic speech recognition asr punctuation recognition pc machine translation mt module also investigate effectiveness multiple asr architecture explore two mt strategy supervised indomain finetuning promptguided translation using large language model sst track explore speechtounit su framework build endtoend sst system system encodes target speech discrete unit via trained hubert leverage standard sequencetosequence model directly learn mapping source speech discrete unit without auxiliary recognition task ie asr mt task various effort made improve extscminetranss performance acoustic model pretraining largescale data data filtering data augmentation speech segmentation knowledge distillation consistency training model ensemble etc
age demand innovative motivating language teaching methodology high level treat trilingual reading tutor combine advanced natural language processing nlp technique latest second third language acquisition slatla research intuitive userfriendly environment proven help adult learner native speaker l acquire reading skill unknown l related cognate l know extent corpusbased methodology relies existing linguistic resource well material easy assemble adapted support pair related language well small evaluation study conducted leeds university centre translation study indicates using treat learner feel motivated study unknown l acquire significant linguistic knowledge l l rapidly increase performance translating l l
investigate problem chinese grammatical error correction cgec present new framework named tailtotail textbfttt nonautoregressive sequence prediction address deep issue hidden cgec considering token correct conveyed directly source target error position estimated corrected based bidirectional context information thus employ bertinitialized transformer encoder backbone model conduct information modeling conveying considering relying position substitution handle variablelength correction case various operation substitution deletion insertion local paraphrasing required jointly therefore conditional random field crf layer stacked tail conduct nonautoregressive sequence prediction modeling token dependency since token correct easily predictedconveyed target model may suffer severe class imbalance issue alleviate problem focal loss penalty strategy integrated loss function moreover besides typical fixlength error correction datasets also construct variablelength corpus conduct experiment experimental result standard datasets especially variablelength datasets demonstrate effectiveness ttt term sentencelevel accuracy precision recall fmeasure task error detection correction
paper investigate impact object gender bias image captioning system result show genderspecific object strong gender bias eg womenlipstick addition propose visual semanticbased gender score measure degree bias used plugin image captioning system experiment demonstrate utility gender score since observe score measure bias relation caption related gender therefore score used additional metric existing object gender coocc approach
paper present submission huawei translation service center hwtsc wmt largescale multilingual translation task participate samll track including language javanese jv indonesian id malay m tagalog tl tamil ta english en direction constrained condition use transformer architecture obtain best performance via multiple variant larger parameter size train single multilingual model translate direction perform detailed preprocessing filtering provided largescale bilingual monolingual datasets several commonly used strategy used train model back translation forward translation ensemble knowledge distillation adapter finetuning model obtains competitive result end
paper introduces set freely available opensource tool turkish built around trmorph morphological analyzer introduced earlier coltekin article first provides update analyzer includes complete rewrite using different finitestate description language tool set well major tagset change comply better stateoftheart computational processing turkish user request received far besides major change analyzer paper introduces tool morphological segmentation stemming lemmatization guessing unknown word grapheme phoneme conversion hyphenation morphological disambiguation
machine translation resurfaced viable business solution year ago much hype amount content requiring translation mellowing user expectation translation quality seemed real business value developing machine translation solution since however discount offered enterprise customer remained stubbornly meager range high upfront costsfar anticipated saving paper provides overview challenge encountered value chain customer language service provider lsp keep translation cost high limit machine translation adoption discusses existing potential solution challenge offer suggestion enlist support lsp freelance translator community address challenge
principal barrier training temporal relation extraction model new domain lack varied high quality example challenge collecting present method automatically collecting distantlysupervised example temporal relation scrape automatically label event pair temporal relation made explicit text mask explicit cue forcing model trained data learn signal demonstrate pretrained transformer model able transfer weakly labeled example humanannotated benchmark zeroshot fewshot setting masking scheme important improving generalization
recently semantic search successfully applied ecommerce product search learned semantic space query product encoding expected generalize well unseen query product yet whether generalization conveniently emerge thoroughly studied domain thus far paper examine several generaldomain domainspecific pretrained roberta variant discover generaldomain finetuning really help generalization aligns discovery prior art yet proper domainspecific finetuning clickstream data lead better model generalization based bucketed analysis manually annotated queryproduct relevance data
paper present result premier shared task organized alongside conference machine translation wmt participant asked build machine translation system language pair evaluated test set news story main metric task human judgment translation quality task also opened additional test suite probe specific aspect translation
present multimodal corpus sentiment analysis based existing switchboard telephone speech corpus released linguistic data consortium corpus extends switchboard telephone speech corpus adding sentiment label different human annotator every transcript segment sentiment label one three option positive negative neutral annotator recruited using google cloud data labeling service labeling task conducted internet corpus contains total labeled speech segment covering hour audio best knowledge largest multimodal corpus sentiment analysis includes speech text feature
million article pubmed database facilitate information retrieval curator national library medicine nlm assign set medical subject heading mesh article mesh hierarchicallyorganized vocabulary containing k different concept covering field clinical medicine information science several automatic mesh indexing model developed improve timeconsuming financially expensive manual annotation including nlm official tool medical text indexer winner bioasq taska challenge deepmesh however model complex interpretable propose novel endtoend model attentionmesh utilizes deep learning attention mechanism index mesh term biomedical text attention mechanism enables model associate textual evidence annotation thus providing interpretability word level model also us novel masking mechanism enhance accuracy speed final week bioasq chanllenge taska ranked nd average mif using onconstruction model contest achieve close stateoftheart mif performance using final model human evaluation show attentionmesh also provides high level interpretability retrieving expertlabeled relevant word given mesharticle pair output
declarative knowledge procedural knowledge two key part metacognitive theory two hold significant importance pretraining inference llm however comprehensive analysis comparing two type knowledge lacking primarily due challenge definition probing quantitative assessment paper explore new perspective providing groundtruth knowledge llm evaluating effective score extensive experiment widelyused datasets model get conclusion task benefit declarative knowledge greater procedural knowledge profit procedural knowledge larger declarative knowledge reasoning task simple logic pretraining progress size increase model ability utilize kind knowledge significantly improves different speed detailed analysis finding provide primary guidance evaluation enhancement large language model
factual consistency essential quality text summarization model practical setting existing work evaluating dimension broadly categorized two line research entailmentbased question answering qabased metric different experimental setup often lead contrasting conclusion paradigm performs best work conduct extensive comparison entailment qabased metric demonstrating carefully choosing component qabased metric especially question generation answerability classification critical performance building insight propose optimized metric call qafacteval lead average improvement previous qabased metric summac factual consistency benchmark also outperforms bestperforming entailmentbased metric moreover find qabased entailmentbased metric offer complementary signal combined single metric performance boost
paper present protocol easy evaluation campaign syntactic parser french evalda project technolangue program describe participant corpus genre partitioning annotation scheme allows annotation constituent relation evaluation methodology illustration result obtained one participant half corpus
main objective paper introduce alternationbased model valency lexicon czech verb vallex alternation describe regular change valency structure verb seen transformation taking one lexical unit return modified lexical unit result characterize exemplify syntacticallybased semanticallybased alternation effect verb argument structure alternationbased model allows distinguish minimal form lexicon provides compact characterization valency structure czech verb expanded form lexicon useful application
event coreference resolution aim classify event mention refer realworld event group necessary information aggregation many downstream application resolve event coreference existing method usually calculate similarity event mention specific kind event argument however fail accurately identify paraphrase relation event may suffer error propagation extracting event component ie event mention argument therefore propose new model based eventspecific paraphrase argumentaware semantic embeddings thus called epase event coreference resolution epase recognizes deep paraphrase relation eventspecific context sentence cover event paraphrase situation bringing better generalization additionally embeddings argument role encoded event embedding without relying fixed number type argument result better scalability epase experiment within crossdocument event coreference demonstrate consistent significant superiority compared existing method
document demonstrates group approach clscisumm shared task three task clscisumm task apply siamese neural network identify span text reference paper best reflecting citation task b use svm classify facet citation
humanhuman spoken dialogue considered important tool effective speech interface design often used stochastic model training speech based application however less restricted nature humanhuman interaction compared humansystem interaction may undermine usefulness corpus creating effective usable interface respect work examines difference corpus collected humanhuman interaction corpus collected actual system use order formally assess appropriateness former design implementation spoken dialogue system comparison result show significant difference respect vocabulary sentence structure speech recognition success rate among others nevertheless compared available tool technique humanhuman dialogue may still used temporary least solution building effective working system accordingly way better utilize resource presented
introduce curriculum learning approach adapt generic neural machine translation model specific domain sample grouped similarity domain interest group fed training algorithm particular schedule approach simple implement top neural framework architecture consistently outperforms unadapted adapted baseline experiment two distinct domain two language pair
success word embedding method various natural language processing task field distributional semantics experienced renewed interest beside famous wordvec recent study presented efficient technique build distributional thesaurus particular claveau et al already shown information retrieval ir tool concept successfully used build thesaurus paper address problem evaluation thesaurus embedding model compare result several experiment evaluating directly result reference lexicon show recent irbased distributional model outperform stateoftheart system wordvec following work claveau kijak use ir applicative framework indirectly evaluate generated thesaurus taskbased evaluation validates ir approach used build thesaurus moreover allows u compare result direct evaluation framework used literature observed difference bring evaluation habit question
paper describes method behind system submitted university groningen wmt unsupervised machine translation task germanupper sorbian investigate usefulness data selection unsupervised setting find perform data selection using pretrained model show quality set sentence document great impact performance unmt system trained furthermore show documentlevel data selection preferred training xlm model possible finally show tradeoff quality quantity data used train unmt system
interpreting inner working neural model key step ensuring robustness trustworthiness model work neural network interpretability typically face tradeoff either model constrained useful solution found model complex interpret propose novel strategy achieving interpretability experiment avoids tradeoff approach build success using probability central quantity instance within attention mechanism architecture dolfin distribution latent feature interpretability determine beforehand feature represents feature go altogether unordered set feature associated probability ranging weighing importance processing show unlike attention saliency map approach setup make straightforward compute probability input component support decision neural model make demonstrate usefulness approach apply dolfin text classification show dolfin provides interpretable solution even slightly outperforms classical cnn bilstm text classifier sst agnews datasets
recent advancement large language model llm drawn increasing attention since learned embeddings pretrained largescale datasets shown powerful ability various downstream application however whether learned knowledge llm transferred clinical cardiology remains unknown work aim bridge gap transferring knowledge llm clinical electrocardiography ecg propose approach cardiovascular disease diagnosis automatic ecg diagnosis report generation also introduce additional loss function optimal transport ot align distribution ecg language embedding learned embeddings evaluated two downstream task automatic ecg diagnosis report generation zeroshot cardiovascular disease detection approach able generate highquality cardiac diagnosis report also achieves competitive zeroshot classification performance even compared supervised baseline prof feasibility transferring knowledge llm cardiac domain
paper describe result team liori fincausal shared task held part st joint workshop financial narrative processing multilingual financial summarisation shared task consisted two subtasks classifying whether sentence contains causality labelling phrase indicate cause consequence team ranked st first subtask th second one used transformerbased model jointtask learning ensemble
far different research work conducted achieve short answer question hence due advancement artificial intelligence adaptability deep learning model introduced new model score short answer subjective question using bidirectional answer answer coattention demonstrated extent word sentence feature student answer detected model shown promising result kaggle mohlers dataset experiment amharic short answer dataset prepared research work also show promising result used baseline subsequent work
automatic text simplification at one major natural language processing nlp task aim help people understand text reading ability comprehension at model reconstruct text simpler format deletion substitution addition splitting preserving original meaning maintaining correct grammar simplified sentence usually evaluated human expert based three main factor simplicity adequacy fluency calculating automatic evaluation metric paper conduct metaevaluation referencebased automatic metric english sentence simplification using highquality humanannotated dataset newselalikert study behavior several evaluation metric sentence level across four different sentence simplification model model trained newselaauto dataset correlation metric score human judgement analyzed result used recommend appropriate metric task
enhancing user engagement personalization conversational agent gained significance especially advent large language model generate fluent response personalized dialogue generation however multifaceted varies definition ranging instilling persona agent capturing user explicit implicit cue paper seek systemically survey recent landscape personalized dialogue generation including datasets employed methodology developed evaluation metric applied covering datasets highlight benchmark datasets newer one enriched additional feature analyze seminal work top conference identify five distinct type problem also shed light recent progress llm personalized dialogue generation evaluation section offer comprehensive summary assessment facet metric utilized work conclusion discus prevailing challenge envision prospect direction future research personalized dialogue generation
paper describes creation gold standard chemistrydisease relation patent text start automated annotation named entity domain chemistry eg propranolol disease eg hypertension well related domain like method substance domainrelevant relation entity eg propranolol treat hypertension manually annotated corpus intended suitable developing evaluating relation extraction method addition present two reasoning method high precision automatically extending set extracted relation chain reasoning provides method infer integrate additional indirectly expressed relation occurring relation chain enumeration reasoning exploit frequent occurrence enumeration patent automatically derives additional relation two method applicable verifying extending manually annotated data well potential improvement automatic relation extraction
present method completing multilingual translation dictionary probabilistic approach synthesize new word form allowing operate setting correct translation observed text cf crosslingual embeddings addition propose approximate maximum mutual information mmi decoding objective improve performance manytoone onetoone word level translation task use either multiple input language single target language typical single language pair translation model trained manytomany setting leverage information related language predict word many target language focus language french spanish italian portuguese romanian turkish indirect multilingual information available ensembling mixtureofexperts well incorporating related language lead relative improvement wholeword accuracy prediction singlesource baseline seed completion multilingual data unavailable better decode mmi objective
aspectbased sentiment analysis absa predict sentiment polarity towards particular aspect sentence recently task widely addressed neural attention mechanism computes attention weight softly select word generating aspectspecific sentence representation attention expected concentrate opinion word accurate sentiment prediction however attention prone distracted noisy misleading word opinion word aspect paper propose alternative hardselection approach determines start end position opinion snippet selects word two position sentiment prediction specifically learn deep association sentence aspect longterm dependency within sentence leveraging pretrained bert model detect opinion snippet selfcritical reinforcement learning especially experimental result demonstrate effectiveness method prove hardselection approach outperforms softselection approach handling multiaspect sentence
finding evidence vital importance research well fact checking evidence detection method would useful speeding process however addressing new topic training data two approach get started one could use large amount outofdomain data train stateoftheart method use small data person creates working topic paper address problem two step first simulating user read source document label sentence use evidence thereby creating small amount training data interactively trained evidence detection model second comparing interactively trained model pretrained model trained large outofdomain data found interactively trained model often outperforms stateoftheart model also requires significantly lower amount computational resource therefore especially computational resource scarce eg gpu available training smaller model fly preferable training well generalising resource hungry outofdomain model
utilization monolingual data shown promising strategy addressing lowresource machine translation problem previous study demonstrated effectiveness technique backtranslation selfsupervised objective including masked language modeling causal language modeling denoise autoencoding improving performance machine translation model however manner method contribute success machine translation task effectively combined remains underresearched area study carry systematic investigation effect technique linguistic property use probing task including source language comprehension bilingual word alignment translation fluency evaluate impact pretraining backtranslation multitask learning bitexts varying size finding inform design effective pipeline leveraging monolingual data extremely lowresource lowresource machine translation task experiment result show consistent performance gain seven translation direction provide support conclusion understanding role monolingual data machine translation
application natural language inference nli method large textual corpus facilitate scientific discovery reducing gap current research available largescale scientific knowledge however contemporary nli model still limited interpreting mathematical knowledge written natural language even though mathematics integral part scientific argumentation many discipline one fundamental requirement towards mathematical language understanding creation model able meaningfully represent variable problem particularly challenging since meaning variable assigned exclusively defining type ie representation variable come context recent research formalised variable typing task benchmark understanding abstract mathematical type variable sentence work propose varslot variable slotbased approach delivers stateoftheart result task variable typing also able create contextbased representation variable
massive digital disinformation one main risk modern society hundred model linguistic analysis done compare contrast misleading credible content online however model remove confounding factor topic narrative training resulting model learn clear topical separation misleading versus credible content study feasibility using two strategy disentangle topic bias model understand explicitly measure linguistic stylistic property content misleading versus credible content first develop conditional generative model create news content characteristic different credibility level perform multidimensional evaluation model performance mimicking style linguistic difference distinguish news different credibility using machine translation metric classification model show even though generative model able imitate style language original content additional conditioning news category topic lead reduced performance second approach perform deception style transfer translating deceptive content style credible content vice versa extending earlier study demonstrate conditioned topic deceptive content shorter less readable biased subjective credible content transferring style deceptive credible content challenging opposite direction
growing investment automatic extraction procedure together need extensive resource make semiautomatic construction new viable efficient strategy developing language resource combining accuracy size coverage applicability assumption motivated work depicted paper aiming establishment use lexicalsyntactic pattern extracting semantic relation portuguese corpus part larger ongoing project semiautomatic extension wordnetpt lexicalsyntactic pattern established covering hypernymyhyponymy holonymymeronymy relation nominal item context manually analyzed evaluate productivity pattern set pattern respective example given well data concerning extraction relation right hit wrong hit related hit total occurrence pattern cprc although languagedependent thus clearly obvious interest development lexical resource portuguese result depicted paper also expected helpful basis establishment pattern related language spanish catalan french italian
recent year development deep learning increasing demand medical information acquisition medical information technology application clinical decision support clinical event detection widely studied subtask however directly applying advance deep learning clinical event detection task often produce undesirable result paper proposes multigranularity information fusion encoderdecoder frameworkthat introduces external knowledge first word embedding generated pretrained biomedical language representation model biobert character embedding generatedby convolutional neural network spliced perform partofspeech attention coding characterlevel embedding perform semantic graph convolutional network codingfor spliced characterword embedding finally information three part fusedas conditional random field input generate sequence label word experimental result ib data set show model paper superior existingmodels addition model paper alleviates problem occurrence event typeseem difficult detect event type
iscas participated subtasks semeval task structured sentiment competition design extractionvalidation pipeline architecture tackle monolingual crosslingual subtasks experimental result show multilingual effectiveness crosslingual robustness system system openly released urlhttpsgithubcomluxinyusemevaltask
deploying language model lm within given domain important measure tendency generate factually incorrect information domain existing method factuality evaluation llm generation focus fact sampled lm thus control set evaluated fact might underrepresent domain specific rare fact propose factor factual assessment via corpus transformation scalable approach evaluating lm factuality factor automatically transforms factual corpus interest benchmark evaluating lm propensity generate true fact corpus v similar incorrect statement use framework create three benchmark wikifactor newsfactor expertfactor show benchmark score increase model size improve lm augmented retrieval ii benchmark score perplexity always agree model ranking iii perplexity benchmark score disagree latter better reflects factuality openended generation measured human annotator
named entity recognition ner model play crucial role various nlp task including information extraction ie text understanding academic writing reference machine learning model datasets fundamental component various computer science publication necessitate accurate model identification despite advancement ner existing ground truth datasets treat finegrained type like ml model model architecture separate entity type consequently baseline model recognize paper release corpus manually annotated fulltext scientific publication first baseline model entity type centered around ml model datasets order provide nuanced understanding ml model datasets mentioned utilized dataset also contains annotation informal mention like bertbased model image cnn find ground truth dataset code replicate model training httpsdatagesisorggsapgsapner
large pretrained language model plms gpt shown strong incontext learning capability highly appealing domain biomedicine feature high diverse demand language technology also high data annotation cost paper present first systematic comprehensive study compare fewshot performance gpt incontext learning finetuning smaller ie bertsized plms two representative biomedical information extraction ie task named entity recognition relation extraction follow true fewshot setting avoid overestimating model fewshot performance model selection large validation set also optimize gpts performance known technique contextual calibration dynamic incontext example retrieval however result show gpt still significantly underperforms compared simply finetuning smaller plm addition gpt incontext learning also yield smaller gain accuracy training data becomes available indepth analysis reveal issue incontext learning may detrimental ie task general given high cost experimenting gpt hope study provides helpful guidance biomedical researcher practitioner towards practical solution finetuning small plms better incontext learning available biomedical ie
machine translation mt relatively recently introduced higher education institution specialised course provided student however course often offered postgraduate level towards last year undergraduate programme eg arena moorkens doherty et al previous study focussed postgraduate student undergraduate student last year programme surveyed perception attitude towards mt quantitative questionnaire eg liu et al yang et al yet undergraduate student earlier translation education remain overlooked much known perceive use mt training need may study investigates perception towards mt undergraduate student early stage translator training via qualitative questionnaire yeartwo translation student little mt knowledge reallife translation experience n asked fill questionnaire openended question answer manually analysed researcher using nvivo identify theme argument revealed even without proper training participant recognised mt potential advantage disadvantage certain degree mt often engaged instrument learn language translation rather straightforwardly translation tool none student reported postediting machinegenerated translation translation assignment instead referenced mt output understand term slang fixed combination complicated sentence produce accurate authentic diversified phrase sentence held positive attitude towards mt quality agreed mt increased translation quality felt confident task willing experiment mt translation tool perform postediting future task doubtful mt could introduced classroom current stage translation learning feared mt would impact independent critical thinking student mention potential negative impact mt development language proficiency translation competency hoped finding make evidencebased contribution design mt curriculum teaching pedagogy keywords machine translation postediting translator training perception attitude teaching pedagogy reference arena g moorkens j machine translation postediting training part master programme journal specialised translation doherty kenny way taking statistical machine translation student translator proceeding th conference association machine translation america commercial mt user program liu k kwok h l liu j cheung k sustainability influence machine translation perception attitude translation instructor learner hong kong sustainability yang wang x yuan q measuring usability machine translation classroom context translation interpreting study
present awatif multigenre corpus modern standard arabic msa labeled subjectivity sentiment analysis ssa sentence level corpus labeled using regular well crowd sourcing method three different condition two type annotation guideline describe subcorpora constituting corpus provide example various ssa category process present linguisticallymotivated genrenuanced annotation guideline provide evidence showing impact labeling task
paper investigates problem text normalisation specifically normalisation nonstandard word nsw english nonstandard word defined word token dictionary entry pronounced using usual lettertophoneme conversion rule eg lb emnlp nsw pose challenge proper functioning texttospeech technology solution spell way pronounced appropriately describe fourstage normalisation system made component detection classification division expansion nsw performance favourabe compared previous work field sproat et al normalization nonstandard word well stateoftheart texttospeech software update sproat et al nsw taxonomy create customisable system user able input abbreviation specify variety english currently available british american wish normalise
understanding table important relevant task involves understanding table structure well able compare contrast information within cell paper address challenge presenting new dataset task address goal shared task semeval task fact verification evidence finding tabular data scientific document semtabfacts dataset contains manuallygenerated table autogenerated dataset table providing k statement evidence annotation semtabfacts featured two subtasks subtask goal determine statement supported refuted unknown relation table subtask b focus identifying specific cell table provide evidence statement team signed participate task successful submission subtask successful submission subtask b present result main finding competition
chinese named entity recognition cner widely used technology various application recent study focused utilizing additional information chinese language character enhance cner performance paper focus specific aspect cner known finegrained cner fgcner fgcner involves use hierarchical finegrained category eg personmoviestar label named entity promote research area introduce fine dataset dataset fgcner consisting sentence various domain containing entity finegrained flattened hierarchical category additionally propose softfine novel approach fgcner utilizes customdesigned relevance scoring function based label structure learn potential relevance different flattened hierarchical label experimental result demonstrate proposed softfine method outperforms stateoftheart baseline fine dataset furthermore conduct extensive experiment three datasets including ontonotes weibo resume softfine achieved stateoftheart performance three datasets
multilingual taskoriented dialogue tod facilitates access service information many community speaker nevertheless potential fully realized current multilingual tod datasetsboth modular endtoend modelingsuffer severe limitation created scratch usually small scale fail cover many possible dialogue flow translationbased tod datasets might lack naturalness cultural specificity target language work tackle limitation propose novel outlinebased annotation process multilingual tod datasets domainspecific abstract schema dialogue mapped natural language outline turn guide target language annotator writing dialogue providing instruction turn intent slot process annotate new largescale dataset evaluation multilingual crosslingual tod system crosslingual outlinebased dialogue dataset cod enables natural language understanding dialogue state tracking endtoend dialogue evaluation diverse language arabic indonesian russian kiswahili qualitative quantitative analysis cod versus equivalent translationbased dataset demonstrate improvement data quality unlocked outlinebased approach finally benchmark series stateoftheart system crosslingual tod setting reference score future work demonstrating cod prevents overinflated performance typically met prior translationbased tod datasets
paper present graphical editor directed graph serialised penman format used annotation abstract meaning representation amr tool support creating modifying amr graph directed graph adding deletion instance edge literal renaming concept relation literal setting top node validating edited graph
paper provide overview first evaluation contest named entity recognition portuguese harem feature several original trait provided first state art field portuguese well publicdomain evaluation architecture
paper describes machine translation system developed university sheffield uos team biomedical translation shared task wmt system based transformer model tensorflow model garden toolkit participated ten translation direction englishspanish englishportuguese englishrussian englishitalian englishfrench language pair create training data concatenated several parallel corpus indomain outofdomain source
wide body research concerned semantics narrative term understanding narrative generating fictional narrative story provide dataset summary used proxy entire story analysis summary dataset consists total individual summary across story intend dataset used training evaluation embedding representation story specifically story narrative summary data harvested five different language version wikipedia dataset come rich metadata extract wikidata enabling wide range application operate story summary conjunction metadata set baseline result run retrieval experiment dataset exploring capability similarity model retrieving summary story retrieval crucial element place much emphasis named entity enable retrieval summary work without taking narrative account
preprocessing pipeline natural language processing usually involve step removing sentence consisted illegal character definition illegal character specific removal strategy depend task language domain etc often lead tiresome repetitive scripting rule paper introduce simple statistical method uniblock overcome problem sentence uniblock generates fixedsize feature vector using unicode block information character gaussian mixture model estimated clean corpus using variational inference learned model used score sentence filter corpus present experimental result sentiment analysis language modeling machine translation show simplicity effectiveness method
parsing phrase structure supertagging achieves symbiosis interpretability formal grammar accuracy speed recent neural modelsthe approach recently transferred parsing discontinuous constituency structure linear contextfree rewriting system lcfrswe reformulate parameterize previously fixed extraction process lcfrs supertags aim improve overall parsing qualitythese parameter set context several step extraction process used control granularity extracted grammar rule well association lexical symbol supertagwe evaluate influence parameter set extracted supertags parsing quality using three treebanks english german language compare bestperforming configuration recent stateoftheart parser areaour result show configuration slightly modified parsing process improve quality speed parsing supertags previous approachmoreover achieve parsing score either surpass among stateoftheart discontinuous constituent parsing
neural machine translation nmt sensitive domain shift paper address problem active learning setting spend given budget translating indomain data gradually finetune pretrained outofdomain nmt model newly translated data existing active learning method nmt usually select sentence based uncertainty score method require costly translation full sentence even one two key phrase within sentence informative address limitation reexamine previous work phrasebased machine translation pbmt era selected full sentence rather individual phrase however incorporating phrase pbmt system relatively simple less trivial nmt system need trained full sequence capture larger structural property sentence unique new domain overcome hurdle propose select full sentence individual phrase unlabelled data new domain routing human translator germanenglish translation task active learning approach achieves consistent improvement uncertaintybased sentence selection method improving bleu score strong active learning baseline
pretrained language model like bert performant wide range natural language task however resource exhaustive computationally expensive industrial scenario thus early exit adopted layer bert perform adaptive computation predicting easier sample first layer speed inference work improve efficiency without performance drop propose novel training scheme called learned early exit bert leebert first ask exit learn rather learning last layer second weight different loss term learned thus balancing different objective formulate optimization leebert bilevel optimization problem propose novel crosslevel optimization clo algorithm improve optimization result experiment glue benchmark show proposed method improve performance stateoftheart sota early exit method pretrained model
adversarial regularization improve model generalization many natural language processing task however conventional approach computationally expensive since need generate perturbation sample epoch propose new adversarial regularization method arch adversarial regularization caching perturbation generated cached every several epoch caching perturbation imposes memory usage concern adopt knearest neighborsbased strategy tackle issue strategy requires caching small amount perturbation without introducing additional training time evaluate proposed method set neural machine translation natural language understanding task observe arch significantly eas computational burden save computational time comparison conventional approach surprisingly reducing variance stochastic gradient arch produce notably better task comparable model generalization code publicly available
paper consider problem optimizing neural referring expression generation reg model sequence level objective recently reinforcement learning rl technique adopted train deep endtoend system directly optimize sequencelevel objective however two issue associated rl training effectively applying rl challenging generated sentence lack diversity naturalness due deficiency generated word distribution smaller vocabulary size repetitiveness frequent word phrase alleviate issue propose novel strategy training reg model using minimum risk training mrt maximum likelihood estimation mle show approach outperforms rl wrt naturalness diversity output specifically approach achieves increase cider score two datasets demonstrate robustness proposed method detailed comparison different reg model
recently proposed longform question answering qa system supported large language model llm shown promising capability yet attributing verifying generated abstractive answer difficult automatically evaluating accuracy remains ongoing challengein work introduce new qa task answering multianswer question summarizing multiple diverse source semiextractive fashion specifically semiextractive multisource qa semqa requires model output comprehensive answer mixing factual quoted spanscopied verbatim given input sourcesand nonfactual freetext connector glue span together single cohesive passage setting bridge gap output wellgrounded constrained extractive qa system fluent harder attribute fully abstractive answer particularly enables new mode language model leverage advanced language generation capability also producing fine inline attribution bydesign easy verify interpret evaluate study task create first dataset kind quotesum humanwritten semiextractive answer natural generated question define textbased evaluation metric experimenting several llm various setting find task surprisingly challenging demonstrating importance quotesum developing studying consolidation capability
vector space model word long claimed capture linguistic regularity simple vector translation problem raised claim decompose empirically analyze classic arithmetic word analogy test motivate two new metric address issue standard test distinguish classwise offset concentration similar direction pair word drawn different broad class francelondon chinaottawa pairing consistency existence regular transformation correctlymatched pair franceparischinabeijing show standard analogy test flawed several popular word embeddings nevertheless encode linguistic regularity
paper present comprise cloud platform developed h project present overview comprise project main goal component cloud platform fit context overall project comprise cloud platform presented detail main user use scenario function implementation detail used comprises targeted audience broader languagetechnology community
task texttosql aim convert natural language question corresponding sql query within context relational table existing texttosql parser generate plausible sql query arbitrary user question thereby failing correctly handle problematic user question formalize problem conduct preliminary study observed ambiguous unanswerable case texttosql summarize feature category correspondingly identify cause behind category propose requirement handling ambiguous unanswerable question following study propose simple yet effective counterfactual example generation approach automatically produce ambiguous unanswerable texttosql example furthermore propose weakly supervised dte detectingthenexplaining model error detection localization explanation experimental result show model achieves best result realworld example generated example compared various baseline release data code urlhttpsgithubcomwbbeyourselfdte
nlp model struggle generalization due sampling annotator bias paper focus different kind bias received little attention guideline bias ie bias introduced annotator guideline formulated examine two recently introduced dialogue datasets ccpem taskmaster collected trained assistant wizardofoz setup ccpem show simple lexical bias word like guideline bias data collection bias effect lead poor performance data without bias preference elicitation architecture based bert suffers absolute drop performance like replaced synonymous phrase drop performance evaluated outofsample data taskmaster show order instruction resented bias data collection
present video captioning approach encodes feature progressively completing syntactic structure lstmcss construct basic syntactic structure ie subject predicate object use conditional random field label semantic representation ie motion object argue order improve comprehensiveness description local feature within object region used generate complementary syntactic element eg attribute adverbial inspired redundancy human receptor utilize region proposal network focus object region model final temporal dynamic recurrent neural network path embeddings adopted demonstrate effectiveness lstmcss generating natural sentence term bleu meteor superior performance compared stateoftheart method reported large video description dataset ie msrvtt
recent pretrained transformerbased model perform named entity recognition ner great accuracy limited range remains issue applied long document whole novel alleviate issue solution retrieve relevant context document level unfortunately lack supervision task mean one settle unsupervised approach instead propose generate synthetic context retrieval training dataset using alpaca instructiontuned large language model llm using dataset train neural context retriever based bert model able find relevant context ner show method outperforms several retrieval baseline ner task english literary dataset composed first chapter book
many text generation application require generated text factually consistent input information automatic evaluation factual consistency challenging previous work developed various metric often depend specific function natural language inference nli question answering qa trained limited data metric thus hardly assess diverse factual inconsistency eg contradiction hallucination occur varying inputsoutputs eg sentence document different task paper propose alignscore new holistic metric applies variety factual inconsistency scenario alignscore based general function information alignment two arbitrary text piece crucially develop unified training framework alignment function integrating large diversity data source resulting training example wellestablished task nli qa paraphrasing fact verification information retrieval semantic similarity summarization conduct extensive experiment largescale benchmark including evaluation datasets datasets never seen alignment training alignscore achieves substantial improvement wide range previous metric moreover alignscore parameter match even outperforms metric based chatgpt gpt order magnitude larger
study problem crosslingual transfer learning event detection ed model trained source language expected perform well data new target language among recent work problem main approach involve representation matching eg adversarial training aim eliminate languagespecific feature representation achieve languageinvariant representation however due mix languagespecific feature eventdiscriminative context representation matching method might also remove important feature event prediction thus hindering performance ed address issue introduce novel approach crosslingual ed representation augmented additional context ie eliminating bridge gap language enriching contextual information facilitate ed core method involves retrieval model retrieves relevant sentence target language input sentence compute augmentation representation experiment three language demonstrate stateoftheart performance model crosslingual ed
paper describes humorbert set bert large based model used semeval task detecting rating humor offense present pre post processing technique variable threshold learning meta learning ensemble approach solve various subtasks part challenge also present comparative analysis various model tried method ranked th humor controversy detection th humor detection th average offense score prediction th average humor score prediction globally f score obtained humor classification controversy detection user name leader board thisistheend team name endtimes
emerging line research explainable nlp creation datasets enriched humanannotated explanation rationale used build evaluate model stepwise inference explanation generation capability humanannotated explanation used groundtruth inference lack systematic assessment consistency rigour attempt provide critical quality assessment explanation gold standard xgss nli propose systematic annotation methodology named explanation entailment verification eev quantify logical validity humanannotated explanation application eev three mainstream datasets reveals surprising conclusion majority explanation appearing coherent surface represent logically invalid argument ranging incomplete containing clearly identifiable logical error conclusion confirms inferential property explanation still poorly formalised understood additional work line research necessary improve way explanation gold standard constructed
work provide literature review active learning al application natural language processing nlp addition finegrained categorization query strategy also investigate several important aspect applying al nlp problem include al structured prediction task annotation cost model learning especially deep neural model starting stopping al finally conclude discussion related topic future direction
paper propose scheme annotating utterancelevel unit japanese dialog emerged analysis interrelationship among four scheme interpausal unit ii intonation unit iii clause unit iv pragmatic unit association among label four unit illustrated multiple correspondence analysis hierarchical cluster analysis based result prescribe utteranceunit identification rule identify two sort utteranceunits different granularity short long utteranceunits short utteranceunits identified acoustic prosodic disjuncture considered constitute unit speaker planning hearer understanding long utteranceunits hand recognized syntactic pragmatic disjuncture regarded unit interaction explore characteristic utteranceunits focusing particularly unit duration syntactic property participant response mismatch twolevels also discus twolevel utteranceunits useful analyzing cognitive communicative aspect spoken dialog
pretrained language model ubiquitous natural language processing despite success available model either trained english data concatenation data multiple language make practical use model language except english limited paper investigate feasibility training monolingual transformerbased language model language taking french example evaluating language model partofspeech tagging dependency parsing named entity recognition natural language inference task show use web crawled data preferable use wikipedia data surprisingly show relatively small web crawled dataset gb lead result good obtained using larger datasets gb best performing model camembert reach improves state art four downstream task
large language model llm forefront nlp achievement fall short dealing shortcut learning factual inconsistency vulnerability adversarial input shortcoming especially critical medical context misrepresent actual model capability addressing present semeval task safe biomedical natural language inference clinical trial contribution include refined nlictp dataset ie natural language inference clinical trial perturbed designed challenge llm interventional causal reasoning task along comprehensive evaluation method result participant submission total participant registered task contributing individual submission system overview paper initiative aim advance robustness applicability nli model healthcare ensuring safer dependable ai assistance clinical decisionmaking anticipate dataset model outcome task support future research field biomedical nli dataset competition leaderboard website publicly available
paper present approach computerassisted teaching reading ability using corpus data approach supported set tool automatically selecting classifying text retrieved internet approach based linguistic model textual cohesion describes relation larger textual unit go beyond sentence level show textual connector link textual unit reliably predict different type text information opinion using textual connector feature svm classifier achieves fscore predicting class tool used project teaching reading skill cognate foreign language l cognate known foreign language l
phenomenon incontext learning typically thought learning example work focus machine translation present perspective incontext learning desired generation task maintaining coherency context ie prompt example first investigate randomly sampled prompt across domain find translation performance improves shown indomain prompt next investigate coherency indomain setting us prompt example moving window study respect factor previously identified literature length surface similarity sentence embedding similarity result across model gptneob bloomb xglmb three translation direction enrightarrowpt de fr suggest longterm coherency prompt test sentence good indicator downstream translation performance demonstrate efficacy incontext machine translation onthefly adaptation
propose global optimization method length constraint golc neural text summarization model golc increase probability generating summary high evaluation score rouge paper within desired length compared golc two optimization method maximum loglikelihood minimum risk training cnndaily mail japanese single document summarization data set mainichi shimbun newspaper experimental result show stateoftheart neural summarization model optimized golc generates fewer overlength summary maintaining fastest processing speed overlength summary cnndaily long summary mainichi compared approximately cnndaily mail mainichi optimization method also demonstrate importance generation inlength summary postediting dataset mainich created strict length constraint ex perimental result show approximately improved postediting time use inlength summary
recent progress hardware methodology training neural network ushered new generation large network trained abundant data model obtained notable gain accuracy across many nlp task however accuracy improvement depend availability exceptionally large computational resource necessitate similarly substantial energy consumption result model costly train develop financially due cost hardware electricity cloud compute time environmentally due carbon footprint required fuel modern tensor processing hardware paper bring issue attention nlp researcher quantifying approximate financial environmental cost training variety recently successful neural network model nlp based finding propose actionable recommendation reduce cost improve equity nlp research practice
existing automated essay scoring aes model rely rated essay target prompt training data despite success promptdependent aes effectively predict essay rating promptindependent setting remains challenge rated essay target prompt available close gap twostage deep neural network tdnn proposed particular first stage using rated essay nontarget prompt training data shallow model learned select essay extreme quality target prompt serving pseudo training data second stage endtoend hybrid deep model proposed learn promptdependent rating model consuming pseudo training data first step evaluation proposed tdnn standard asap dataset demonstrates promising improvement promptindependent aes task
ttp tagged text parser fast robust natural language parser specifically designed process vast quantity unrestricted text ttp analyze written text speed approximately secsentence word per second important novel feature ttp parser equipped skipandfit recovery mechanism allows fast closing difficult subconstituents preset amount time elapsed without producing parse although complete analysis attempted sentence parser may occasionally ignore fragment input resume normal processing skipping word fragment later analyzed separately attached incomplete constituent main parse tree ttp recently evaluated several leading parser formal number released formal evaluation planned later year ttp performed surprisingly well main argument paper ttp provide substantial gain parsing speed giving relatively little term quality output produce property allows ttp used effectively parsing large volume text
personalized dialogue system aim endow chatbot agent anthropomorphic trait humanlike interaction previous approach explored explicitly user profile modeling using text description implicit derivation user embeddings utilizing handicraft prompt chatgptlike model however textual persona limited describing multifaceted attribute textiteg textitlanguage style inner character nuance implicit embedding suffers personality sparsity handicraft prompt lack finegrained stable controllability hence approach may struggle complex personalized dialogue generation task require generating controllable response multiple personal attribute end propose textbfmiracle novel personalized dialogue generation method textbfmulttextbfiple petextbfrsonal textbfattributes textbfcontrol within textbflatentspace textbfenergybased model ttributes textbfcontrol within textbflatentspace textbfenergybased model specifically approach first disentangles complex personality multifaceted attribute subsequently employ conditional variational autoencoder align dense personalized response within latent joint attribute space also tailored dedicated energy function customized ordinary differential equation sampling method offer flexible attribute composition precise attribute control extensive experiment demonstrate miracle outperforms several strong baseline term personality controllability response generation quality dataset code available urlhttpsgithubcomlzytheboysmiracle
memo describes ntrtsu submission sigtyp shared task predicting language id speech spoken language identification lid important step multilingual automated speech recognition asr system pipeline many lowresource endangered language singlespeaker recording may available demanding need domain speakerinvariant language id system memo show convolutional neural network selfattentive pooling layer show promising result language identification task
paper present system description offensive language detection tool developed kmicoling offenseval shared task offenseval shared task conducted semeval workshop develop system explored ngrams gram trained three different namely b c system three different subtasks within offenseval task achieves accuracy respectively task completed using dataset provided u offenseval organiser part olid dataset consists tweet extracted twitter annotated three level using crowdsourcing
supervised approach usually achieve best performance word sense disambiguation problem however unavailability large sense annotated corpus many lowresource language make approach inapplicable practice paper mitigate issue persian language proposing fully automatic approach obtaining persian semcor persemcor persian bagofword bow senseannotated corpus evaluated persemcor intrinsically extrinsically showed effectively used training set persian supervised wsd system encourage future research persian word sense disambiguation release persemcor urlhttpnlpsbuacir
task implicit reasoning generation aim help machine understand argument inferring plausible reasoning usually implicit argumentative text task easy human machine still struggle make inference deduce underlying reasoning solve problem hypothesize human reasoning guided innate collection domainspecific knowledge might beneficial create domainspecific corpus machine starting point create first domainspecific resource implicit reasoning annotated wide range argument leveraged empower machine better implicit reasoning generation ability carefully design annotation framework collect large scale crowdsourcing show feasibility creating corpus reasonable cost highquality experiment indicate model trained domainspecific implicit reasoning significantly outperform domaingeneral model automatic human evaluation facilitate research towards implicit reasoning generation argument present indepth analysis corpus crowdsourcing methodology release material ie crowdsourcing guideline domainspecific resource implicit reasoning
existing endtoend dialog system perform less effectively data scarce obtain acceptable success reallife online service handful training example fast adaptability reliable performance highly desirable dialog system paper propose metadialog system md combine advantage metalearning approach humanmachine collaboration evaluate method new extendedbabi dataset transformed multiwoz dataset lowresource goaloriented dialog learning experimental result show md significantly outperforms nonmetalearning baseline achieve perturn accuracy dialog extendedbabi dataset
remarkable development large language model llm ensuring factuality output become challengehowever content response given knowledge fact necessarily good thing dialoguesthis study aimed achieve attractiveness factuality dialogue response task set predict sentence require factual correctness judgment agreeing personal opinionsfeelingswe created dataset dialogue dataset annotated factcheckneeded label ddfc task via crowdsourcing classification task performed several model using datasetthe model highest classification accuracy could yield accurate classification result
social medium notoriously difficult process existing natural language processing tool spelling error nonstandard word shortening nonstandard capitalization punctuation one method circumvent issue normalize input data processing previous work focused one language mostly english paper first propose model crosslingual normalization participate wnut shared task end use monoise starting point make simple adaptation crosslingual application proposed model outperforms leaveasis baseline provided organizer copy input furthermore explore completely different model convert task sequence labeling task performance second system low take capitalization account implementation
po tagger typically fail correctly tag grammatical neologism known word tagger take known tag account hence discard possibility word used novel deviant grammatical category text hand grammatical neologism relatively rare therefore pose significant problem overall performance tagger study neologism grammaticalization process make traditional tagger rather unfit article describes modified po tagger explicitly considers new tag known word hence making better fit neologism research tagger called neotag overall accuracy comparable tagger score much better grammatical neologism achieve tagger applies system textbackslashem lexical smoothing add new category known word based known homograph neotag also lemmatizes word part tagging system achieving high accuracy lemmatization known unknown word without need external lexicon use neotag restricted grammatical neologism detection used purpose well
sufficient resource language x lift underresourced language class necessarily underresearched class paper address problem absence organized benchmark turkish language demonstrate language turkish left behind stateoftheart nlp application solution present mukayese set nlp benchmark turkish language contains several nlp task work one datasets benchmark present two baseline moreover present four new benchmarking datasets turkish language modeling sentence segmentation spell checking datasets baseline available urlhttpsgithubcomalisafayamukayese
mainstream research hate speech focused far predominantly task classifying mainly social medium post respect predefined typology rather coarsegrained hate speech category may sufficient goal detect delete abusive language post however removal always possible due legislation country also evidence hate speech successfully combated merely removing hate speech post countered education counternarratives purpose need identify target given hate speech post ii aspect characteristic target attributed target post first approximation propose adapt generic stateoftheart concept extraction model hate speech domain outcome experiment promising serve inspiration work task
distantly supervised named entity recognition dsner proposed exploit automatically labeled training data instead human annotation distantly annotated datasets often noisy contain considerable number false negative recent approach us weighted sampling approach select subset negative sample training however requires good classifier assign weight negative sample paper propose simple straightforward approach selecting top negative sample high similarity positive sample training method achieves consistent performance improvement four distantly supervised ner datasets analysis also show critical differentiate true negative false negative
present novel approach multilingual audiovisual speech recognition task introducing single model multilingual dataset motivated human cognitive system human intuitively distinguish different language without conscious effort guidance propose model capture language given input speech distinguishing inherent similarity difference language design prompt finetuning technique largely pretrained audiovisual representation model network recognize language class well speech corresponding language work contributes developing robust efficient multilingual audiovisual speech recognition system reducing need languagespecific model
order offer customized script tool inspire professional scriptwriter present vscript controllable pipeline generates complete script including dialogue scene description well present visually using video retrieval interactive interface system allows user select genre input starting word control theme development generated script adopt hierarchical structure first generates plot script visual presentation novel approach also introduced plotguided dialogue generation treating inverse dialogue summarization experiment result show approach outperforms baseline automatic human evaluation especially genre control
text augmentation effective technique alleviating overfitting nlp task existing method text augmentation downstream task mostly performed separately result augmented text may optimal train downstream model address problem propose threelevel optimization framework perform text augmentation downstream task endto end augmentation model trained way tailored downstream task framework consists three learning stage text summarization model trained perform data augmentation first stage summarization example associated weight account domain difference text classification data second stage use model trained first stage perform text augmentation train text classification model augmented text third stage evaluate text classification model trained second stage update weight summarization example minimizing validation loss three stage performed endtoend evaluate method several text classification datasets result demonstrate effectiveness method code available urlhttpsgithubcomsaiashishendtoendtextaugmentation
psychiatric evaluation report represent rich still mostlyuntapped source information developing system automatic diagnosis treatment mental health problem report contain freetext structured within section using convention heading present model automatically detecting position type different psychiatric evaluation report section developed model using corpus sample report gathered web used sentence processing unit section heading used label section type label generated unified hierarchy label section type learned ngram model language found section model convention section order integrated ngram model hierarchical hidden markov model hhmm representing probability observed section order found corpus used hhmm ngram model decoding framework infer likely section boundary section type document section label removed evaluated model two task namely identifying section boundary identifying section type order model significantly outperformed baseline task f identifying section type windowdiff wd pk score respectively identifying section boundary
large amount information digital format exists today make unfeasible use manual mean acquire knowledge contained document therefore necessary develop tool allow u incorporate knowledge structure easy use machine human paper present system incorporate relevant information document format structured unstructured semantic network represents existing knowledge document system independently process structured document based annotation scheme unstructured document written natural language us set sensor identifies relevant information subsequently incorporates enrich semantic network created linking information based knowledge discovered
work previously formalized semantic evaluation task spatial role labeling sprl aim extraction formal spatial meaning text report result initial effort towards exploiting visual information form image help spatial language understanding discus way designing new model framework declarative learningbased programming delbp delbp framework facilitates combining modality representing various data unified graph learning inference model exploit structure unified graph well global first order domain constraint beyond data predict semantics form structured meaning representation spatial context continuous representation used relate various element graph originating different modality improved stateoftheart result sprl
berkeley framenet project bfn urlhttpsframeneticsiberkeleyedufndrupal created description noncore grammatical construction annotation construction example sentence one year project beyond core pilot project cataloging grammatical construction multiword expression english supported national science foundation project aim building fullfledged construction grammar registry english construction created project called constructicon provides representative sample current coverage english construction leegoldman rhodes cxn viewer search tool developed constructicon tool show typical english construction web browser cxn viewer web application consisting html file javascript code tool useful program benefit researcher working data annotated within framework bfn cxn viewer unicodecompliant application deal construction language spanish
paper investigates ordering tone relative segmental string influence calculation phonotactic probability trigram recurrent neural network model trained syllable lexicon four asian syllabletone language mandarin thai vietnamese cantonese tone treated segment occurring different position string trigram model optimal permutation interacted language neural network model relatively unaffected tone position language addition providing baseline future evaluation result suggest phonotactic probability robust choice tone ordered respect element syllable
large language model llm perform well least evaluation fewshot multilingual adaptation reasoning however evaluating intersection two skillsmultilingual fewshot reasoningis difficult even relatively lowresource language found large training corpus raising concern intend evaluate model ability generalize new language language may fact present model training language contamination occurred apparent case fewshot reasoning could actually due memorization towards understanding capability model perform multilingual fewshot reasoning propose modeling benchmark rosetta stone puzzle type puzzle originating competition called linguistics olympiad contain small number sentence target language previously known solver sentence translated solver language provided sentence pair uniquely specify single reasonable underlying set rule solving requires applying rule translate new expression figure modeling language chosen extremely lowresource risk training data contamination low unlike prior datasets consists entirely problem written specifically work measure data leakage empirically find evidence popular llm data leakage benchmark
paper present yamama multidialect arabic morphological analyzer disambiguator system almost five time faster stateofart madamira system slightly lower quality addition speed yamama output rich representation allows wider spectrum use regard yamama transcends system farasa faster provides specific output catering specific application
comparable parallel corpus beneficial many nlp task automatic collection corpus enables largescale resource even lessresourced language turn useful deducing rule pattern text rewriting algorithm subtask automatic text simplification present two method alignment swedish easytoread text segment text segment reference corpus first method originally developed task text reuse detection measuring sentence similarity modified version tfidf vector space model second method also accounting partofspeech tag developed method compared evaluation crowdsourcing platform built human judgement data collection preliminary result showed cosine similarity relates better human rank dice coefficient also saw tendency including syntactic context tfidf vector space model beneficial kind paraphrase alignment task
story generation challenging problem artificial intelligence ai received lot interest natural language processing nlp community previous work tried solve problem using sequence sequence seqseq model trained maximum likelihood estimation mle however pure mle training objective much limit power seqseq model generating highquality story paper propose using adversarial training augmented seqseq model generate reasonable diversified story ending given story context model includes generator defines policy generating story ending discriminator label story ending humangenerated machinegenerated carefully designed human automatic evaluation metric demonstrate adversarial training augmented seqseq model generate reasonable diversified story ending compared purely mletrained seqseq model moreover model achieves better performance task story cloze test accuracy compared stateoftheart baseline method
paper describes proposed model chinese grammatical error diagnosis cged task nlptea goal cged use natural language processing technique automatically diagnose chinese grammatical error sentence end design implement cged model named bert scorefeature gate error diagnoser bsged based bert model bidirectional long shortterm memory bilstm conditional random field crf order address problem losing partialorder relationship embedding continuous feature item previous work propose gating mechanism integrating continuous feature item effectively retains partialorder relationship feature item perform lstm processing encoding result bert model extract sequence feature final testset evaluation obtained highest f score detection level among top f score identification level
multilingual learning neural named entity recognition nner involves jointly training neural network multiple language typically goal improving ner performance one language primary language using assisting language show divergence tag distribution common named entity primary assisting language reduce effectiveness multilingual learning alleviate problem propose metric based symmetric kl divergence filter highly divergent training instance assisting language empirically show data selection strategy improves ner performance many language including limited training data
consulting dictionary glossary familiar way many human figure word particular context mean hypothesize system select proper definition particular word occurrence also naturally solve task related word sens verify hypothesis developed solution multilingual crosslingual wordincontext mclwic task use shared task data wic data training instead trained embed word definition english wordnet word occurrence english text vector space following approach previously proposed word sense disambiguation wsd estimate similarity meaning two word occurrence compared different metric shared vector space found ldistance normalized contextualized word embeddings outperforms traditionally employed cosine similarity several metric solve task language english rely zeroshot crosslingual transfer capability multilingual xlmr masked language model despite using mclwic training data shared task approach achieves accuracy english test set less best system multilingual subtask zeroshot crosslingual transfer show competitive result within best system russian french arabic crosslingual subtask within best system
email widely used tool business communication email marketing emerged costeffective strategy enterprise previous study examined factor affecting email marketing performance limited research focused understanding email response behavior considering email content metadata study proposes prototypebased multiview network prominet incorporates semantic structural information email data utilizing prototype learning prominet model generates latent exemplar enabling interpretable email response prediction model map learned semantic structural exemplar observed sample training data different level granularity document sentence phrase approach evaluated two realworld email datasets enron corpus inhouse email marketing corpus experimental result demonstrate prominet model outperforms baseline model achieving textasciitilde improvement f score datasets additionally model provides interpretability prototype different granularity level maintaining comparable performance noninterpretable model learned prototype also show potential generating suggestion enhance email text editing improve likelihood effective email response research contributes enhancing senderreceiver communication customer engagement email interaction
propose deep learningbased foreign language learning platform named freetalky people experience anxiety dealing foreign language employing humanoid robot nao various deep learning model personabased dialogue system embedded nao provides interesting consistent multiturn dialogue user also grammar error correction system promotes improvement grammar skill user thus system enables personalized learning based persona dialogue facilitates grammar learning user using grammar error feedback furthermore verified whether freetalky provides practical help alleviating xenoglossophobia replacing real human conversation nao robot human evaluation
garden path sentence ie horse raced past barn fell sentence reader initially incorrectly parse requiring partial total reanalysis sentence structure given human difficulty parsing garden path aim compare transformer language model performance sentence assess selection model bert family finetuned questionanswering task evaluate model performance comprehension question based garden path control sentence investigate semantic role assigned argument verb garden path control sentence utilizing probe task directly assess semantic role model assigns find model relatively low performance certain instance question answering based garden path context model incorrectly assigns semantic role aligning part human performance
word choice dependent cultural context writer subject different word used describe similar action object feature based factor class race gender geography political affinity exploratory technique based locating counting word may therefore lead conclusion reinforce culturally inflected boundary offer new method dualneighbors algorithm linking thematically similar document within across discursive linguistic barrier reveal crosscultural connection qualitative quantitative evaluation technique shown applied two cultural datasets interest researcher across humanity social science opensource implementation dualneighbors algorithm provided assist application
large language model llm often struggle complex logical reasoning due logical inconsistency inherent difficulty ofsuch reasoning use lean theorem proving framework address challenge formalizing logical reasoning problem intotheorems within lean solve proving disproving corresponding theorem method reduces risk logical inconsistency help lean symbolic solver also enhances ability treat complex reasoning task using lean extensive library theorem proof method achieves stateoftheart performance folio dataset achieves performance near level proofwriter notably result accomplished finetuning fewer indomain sample dataset
paper present approach training verb subatom embeddings verb learn several embeddings rather one embeddings include verb well embeddings grammatical role verb give example verb give learn four embeddings one lemma give one subject one direct object one indirect object exploited grammatical role embeddings order add new syntagmatic relation wordnet evaluation new relation quality done extrinsically knowledgebased word sense disambiguation task
paper present multilingual artificial intelligence agent assistant maia project led unbabel collaboration cmu inescid lisbon maia employ cuttingedge machine learning natural language processing technology build multilingual ai agent assistant eliminating language barrier maia translation layer empower human agent provide customer support realtime language human quality
recently increased emphasis assessing quality natural language argument existing approach primarily focus evaluating quality individual argument post however often fall short come effectively distinguishing argument possess narrow quality margin address limitation paper delf two alternative method modeling relative quality different argument approach include supervised contrastive learning capture intricate interaction argument incorporating approach aim enhance assessment argument quality effectively distinguishing argument subtle difference quality large language model llm incontext example harness power llm enrich incontext example extensive evaluation analysis publicly available ibmrankk dataset demonstrate superiority contrastive argument quality assessment approach stateoftheart baseline hand llm incontext example showcase commendable ability identify highquality argument post exhibit relatively limited efficacy discerning argument post narrow quality gap
meme form medium spread idea emotion across internet posting meme become new form communication web due multimodal nature meme posting hateful meme related event like trolling cyberbullying increasing day day hate speech offensive content aggression content detection extensively explored single modality text image however combining two modality detect offensive content still developing area meme make even challenging since express humour sarcasm implicit way meme may offensive consider text image therefore necessary combine modality identify whether given meme offensive since publicly available dataset multimodal offensive meme content detection leveraged meme related u presidential election created multioff multimodal meme dataset offensive content detection dataset subsequently developed classifier task using multioff dataset use early fusion technique combine image text modality compare text imageonly baseline investigate effectiveness result show improvement term precision recall fscore code dataset paper published textit urlhttpsgithubcombharathichezhiyanmultimodalmemeclassificationidentifyingoffensivecontentinimageandtext
promptingbased large language model llm surprisingly powerful generating natural language reasoning step chainsofthoughts cot multistep question answering qa struggle however necessary knowledge either unavailable llm uptodate within parameter using question retrieve relevant text external knowledge source help llm observe onestep retrieveandread approach insufficient multistep qa textitwhat retrieve depends textitwhat already derived turn may depend textitwhat previously retrieved address propose ircot new approach multistep qa interleaf retrieval step sentence cot guiding retrieval cot turn using retrieved result improve cot using ircot gpt substantially improves retrieval point well downstream qa point four datasets hotpotqa wikimultihopqa musique iirc observe similar substantial gain outofdistribution ood setting well much smaller model flantlarge without additional training ircot reduces model hallucination resulting factually accurate cot reasoning
journey reducing noise distant supervision d generated training data started since d first introduced relation extraction task past decade researcher apply multiinstance learning mil framework find reliable feature bag sentence although pattern mil bag greatly reduce d noise fails represent many useful sentence feature datasets many case sentence feature acquired extra sentencelevel human annotation heavy cost therefore performance distantly supervised model bounded paper go beyond typical mil framework propose novel contrastive instance learning cil framework specifically regard initial mil relational triple encoder constraint positive pair negative pair instance experiment demonstrate effectiveness proposed framework significant improvement previous method nyt gd kbp
describe contribution semeval afrisentisemeval shared task tackle task sentiment analysis different african language develop monolingual multilingual model full supervised setting subtasks b also develop model zeroshot setting subtask c approach involves experimenting transfer learning using six language model including pretraining model well final finetuning stage best performing model achieve fscore development data fscore test data unsurprisingly result demonstrate effectiveness transfer learning finetuning technique sentiment analysis across multiple language approach applied sentiment analysis task different language domain
recent research shown large natural language processing nlp model vulnerable kind security threat called backdoor attack backdoor attacked model achieve good performance clean test set perform badly input sentence injected designed trigger word work point potential problem current backdoor attacking research evaluation ignores stealthiness backdoor attack existing backdoor attacking method stealthy either system deployers system user address issue first propose two additional stealthinessbased metric make backdoor attacking evaluation credible propose novel wordbased backdoor attacking method based negative data augmentation modifying word embeddings making important step towards achieving stealthy backdoor attacking experiment sentiment analysis toxic detection task show method much stealthier maintaining pretty good attacking performance code available urlhttpsgithubcomlancopkusos
semisupervised learning promising way reduce annotation cost textclassification combining pretrained language model plms eg bert recent semisupervised learning method achieved impressive performance work investigate marriage semisupervised learning pretrained language model unlike existing approach utilize plms model parameter initialization explore inherent topic matching capability inside plms building powerful semisupervised learning approach specifically propose joint semisupervised learning process progressively build standard kway classifier matching network input text class semantic representation csr csr initialized given labeled sentence progressively updated training process mean extensive experiment show method bring remarkable improvement baseline also overall stable achieves stateoftheart performance semisupervised text classification
knowledge graph embedding aim learn representation entity relation knowledge graph find application various downstream task key success knowledge graph embedding model ability model relation pattern including symmetryantisymmetry inversion commutative composition noncommutative composition although existing method fail modeling noncommutative composition pattern several approach support pattern modeling beyond euclidean space complex space nevertheless expanding complicated space quaternion easily lead substantial increase amount parameter greatly reduces computational efficiency paper propose new knowledge graph embedding method called rotatect first transforms coordinate entity represents relation rotation head entity tail entity complex space design rotatect infer noncommutative composition pattern improve computational efficiency experiment multiple datasets empirically show rotatect outperforms stateoftheart method link prediction path query answering
translating secretary asked detail language grammatical gender might necessary determine gender subject secretary sentence contain necessary information always possible disambiguate case machine translation system select common translation option often corresponds stereotypical translation thus potentially exacerbating prejudice marginalisation certain group people argue information necessary adequate translation always deduced sentence translated even might depend external knowledge therefore work propose decouple task acquiring necessary information task learning translate correctly information available end present method training machine translation system use wordlevel annotation containing information subject gender prepare training data annotate regular source language word grammatical gender information corresponding target language word using data train machine translation system reduces reliance gender stereotype information subject gender available experiment five language pair show allows improving accuracy winomt test set percentage point
word ordering sanskrit verse often aligned corresponding prose order conversion verse corresponding prose help better comprehension construction owing resource constraint formulate task word ordering linearisation task completely ignore word arrangement verse side kavya guru approach propose essentially consists pipeline two pretraining step followed seqseq model first pretraining step learns taskspecific token embeddings pretrained embeddings next step generate multiple possible hypothesis possible word arrangement input using another pretraining step use input neural seqseq model final prediction empirically show hypothesis generated pretraining step result prediction consistently outperform prediction based original order verse overall kavya guru outperforms current state art model linearisation poetry prose conversion task sanskrit
addressing challenge automated geometry math problemsolving artificial intelligence ai involves understanding multimodal information mathematics blackcurrent method struggle accurately interpreting geometry diagram hinders effective problemsolving tackle issue present textbfgeometry problem stextbfolver natural textbflanguage textbfdescription gold model gold enhances extraction geometric relation separately processing symbol geometric primitive within diagram subsequently convert extracted relation natural language description efficiently utilizing large language model solve geometry math problem experiment show gold model outperforms geoformer model previous best method unigeo dataset achieving accuracy improvement calculation proving subset additionally surpasses former best model pgpsk geometryk datasets pgpsnet obtaining accuracy enhancement respectively
recent work aspectlevel sentiment classification demonstrated efficacy incorporating syntactic structure dependency tree graph neural network gnn approach usually vulnerable parsing error better leverage syntactic information face unavoidable error propose simple yet effective graph ensemble technique graphmerge make use prediction different parser instead assigning one set model parameter dependency tree first combine dependency relation different parses applying gnns resulting graph allows gnn model robust parse error additional computational cost help avoid overparameterization overfitting gnn layer stacking introducing connectivity ensemble graph experiment semeval task acl twitter datasets show graphmerge model outperforms model single dependency tree also beat ensemble model without adding model parameter
introducing factor say word feature linguistic information referring source token known improve result neural machine translation system certain setting typically recurrent architecture study proposes enhancing current stateoftheart neural machine translation architecture transformer allows introduce external knowledge particular proposed modification factored transformer us linguistic factor insert additional knowledge machine translation system apart using different kind feature study effect different architectural configuration specifically analyze performance combining word feature embedding level encoder level experiment two different combination strategy bestfound configuration show improvement bleu baseline transformer iwslt germantoenglish task moreover experiment challenging flores englishtonepali benchmark includes extremely lowresourced distant language obtain improvement bleu
paper describe first tigrinya language speech corpus designed development speech recognition purpose tigrinya often written tigrigna trinj belongs semitic branch afroasiatic language show characteristic feature semitic language spoken ethnic tigraytigrigna people horn africa paper outline different corpus designing process analysis related work speech corpus creation different language author provide also procedure used creation tigrinya speech recognition corpus underresourced language one hundred thirty speaker native tigrinya language recorded training test dataset set speaker read text consisted syllabically rich balanced sentence ten thousand set sentence used prompt sheet sentence contained contextual syllable phone
resource manual word alignment contain configuration beyond alignment capacity current translation model hence term complex alignment configuration matter debate machine translation community call powerful translation model come complication work investigate instance complex alignment configuration data set four different language pair shed light nature cause configuration englishgerman alignment pado lapata instance find small fraction complex configuration due real annotation error third complex configuration data set could simplified annotating according different style guide remaining one phenomenon one would like able generate translation instance mainly caused different word order english german finding thus motivate research area translation beyond phrasebased contextfree translation modeling
paper describes system submitted semeval task aim system distinguish irony nonirony english tweet create targeted feature set analyse different feature useful task irony detection achieving fscore analysis individual feature provides insight may useful future attempt detecting irony tweet
neural machine translation nmt take deterministic sequence source representation however either wordlevel subwordlevel segmentation multiple choice split source sequence different word segmentors different subword vocabulary size hypothesize diversity segmentation may affect nmt performance integrate different segmentation stateoftheart nmt model transformer propose latticebased encoders explore effective word subword representation automatic way training propose two method lattice positional encoding latticeaware selfattention two method used together show complementary improve translation performance experiment result show superiority latticebased encoders wordlevel subwordlevel representation conventional transformer encoder
transformer model trained english language corpus contain text forum like wikipedia reddit model used many specialized domain scientific peer review legal healthcare performance subpar contain information present data relevant specialized domain help model perform well possible specialized domain one approach collect labeled data particular domain finetune transformer model choice data good approach suffers challenge collecting lot labeled data requires significant manual effort another way use unlabeled domainspecific data pretrain transformer model finetune model labeled data evaluate transformer model perform finetuned labeled data initial pretraining unlabeled data compare performance transformer model finetuned labeled data without initial pretraining unlabeled data perform comparison dataset scientific peer review provided organizer pragtag shared task observe transformer model finetuned labeled data initial pretraining unlabeled data using masked language modelling outperforms transformer model finetuned labeled data without initial pretraining unlabeled data using masked language modelling
large language model llm exhibited exceptional performance across various task also demonstrated spark intelligence recent study focused assessing capability human exam revealed impressive competence different domain however cognitive research overall knowledge structure llm still lacking paper based educational diagnostic assessment method conduct evaluation using moocradar meticulously annotated human test dataset based bloom taxonomy aim reveal knowledge structure llm gain insight cognitive capability research emphasizes significance investigating llm knowledge understanding disparate cognitive pattern llm shedding light model knowledge researcher advance development utilization llm informed effective manner
paper present multilevel alignment pretraining method unified architecture formultilingual semantic parsing architecture use adversarial training method toalign space different language use sentence level word level parallel corpus assupervision information align semantic different language finally jointly train themultilevel alignment semantic parsing task conduct experiment publicly available multilingual semantic parsing dataset atis newly constructed dataset experimentalresults show model outperforms stateoftheart method datasets
large language model llm shown great ability solving traditional natural language task elementary reasoning task appropriate prompting technique however ability still limited solving complicated science problem work aim push upper bound reasoning capability llm proposing collaborative multiagent multireasoningpath comm prompting framework specifically prompt llm play different role problemsolving team encourage different roleplay agent collaboratively solve target task particular discover applying different reasoning path different role effective strategy implement fewshot prompting approach multiagent scenario empirical result demonstrate effectiveness proposed method two collegelevel science problem competitive baseline analysis show necessity prompting llm play different role expert independently
fewshot relation extraction fsre challenging problem since handful training instance existing model follow oneforall scheme one general large model performs individual nwaykshot task fsre prevents model achieving optimal point task view propose model generation framework consists one general model task many tiny taskspecific model individual task general model generates pass universal knowledge tiny model finetuned performing specific task way decouple complexity entire task space individual task absorbing universal knowledgeextensive experimental result two public datasets demonstrate framework reach new stateoftheart performance frse task code available httpsgithubcomnlpwmwhugmgen
paper propose description recent interdisciplinary project aiming analysing conceptual linguistic dimension humanitarian right terminology analysis result form new knowledgebased multilingual terminological resource designed order meet fair principle open science serve future prototype development new software simplified rewriting international legal text relating human right given early stage project focus description rationale planned workflow theoretical approach adopted achieve main goal ambitious research project
earlier nlp study framing political discourse focused heavily shallow classification issue framing framing effect arising pragmatic cue remains neglected put forward latter type framing pragmatic framing bridge gap take presuppositiontriggering adverb study case quantitatively investigate different german newspaper use covertly evoke different attitudinal subtexts report event european refugee crisis study demonstrates crucial role presupposition framing emphasizes necessity attention pragmatic framing research automated framing detection
much previous work transliteration depended resource attribute specific particular language pair work rather focus single language pair create robust model transliterating language large diverse set english create training data language mining name pair wikipedia train system analyze effect amount training data transliteration performance also present analysis type error system make analysis particularly valuable building machine translation system low resource language creating integrating transliteration module language nlp resource may provide substantial gain translation performance
paper design monolingual lexicon induction task observes two factor accompany degraded accuracy bilingual lexicon induction rare word first diminishing margin similarity low frequency regime secondly exacerbated hubness low frequency based observation propose two method address two factor respectively larger issue hubness addressing improves induction accuracy significantly especially lowfrequency word
visual dialog challenging since need answer series coherent question based understanding visual environment ground related visual object one key problem previous study utilize question history attend image achieve satisfactory performance method sufficient locate related visual object without guidance inappropriate grounding visual object prohibits performance visual dialog model paper propose novel approach learn ground visual object visual dialog employ novel visual object grounding mechanism prior posterior distribution visual object used facilitate visual object grounding specifically posterior distribution visual object inferred context history question answer ensures appropriate grounding visual object training process meanwhile prior distribution inferred context used approximate posterior distribution appropriate visual object grounding even without answer inference process experimental result visdial v v datasets demonstrate approach improves previous strong model generative discriminative setting significant margin
paper describes system submitted task semeval ie machine comprehension using commonsense knowledge given passage question two candidate answer task requires participate system select one answer meet meaning original text commonsense knowledge candidate answer task use deep learning method obtain final predict answer calculating relevance choice representation questionaware document representation
extend scope coding query realistic setting propose odex first opendomain executionbased natural language nl python code generation dataset odex nlcode pair spanning diverse library along humanwritten test case execution nlcode pair harvested stackoverflow forum encourage natural practical coding query moreover odex support four natural language intent english spanish japanese russian odex unveils intriguing behavioral difference among topperforming code language model lm codex achieves better overall result codegen improves effectively via scaling codegen b performs comparably codex b model show substantial gap open closed domain codegen gap tend decrease model size codex gap increase release odex facilitate research opendomain problem code generation community
pretrained contextualized embeddings powerful word representation structured prediction task recent work found better word representation obtained concatenating different type embeddings however selection embeddings form best concatenated representation usually varies depending task collection candidate embeddings everincreasing number embedding type make difficult problem paper propose automated concatenation embeddings ace automate process finding better concatenation embeddings structured prediction task based formulation inspired recent progress neural architecture search specifically controller alternately sample concatenation embeddings according current belief effectiveness individual embedding type consideration task update belief based reward follow strategy reinforcement learning optimize parameter controller compute reward based accuracy task model fed sampled concatenation input trained task dataset empirical result task datasets show approach outperforms strong baseline achieves stateoftheart performance finetuned embeddings evaluation
paper investigate impact data size word sense disambiguation task wsd question assumption knowledge acquisition bottleneck known one major challenge wsd solved simply obtaining training data case study manually annotated instance german verb drohen threaten show best performance obtained training full data set carefully selecting new training instance regard informativeness learning process active learning present thorough evaluation impact different sampling method data set propose improved method uncertainty sampling dynamically adapts selection new instance learning progress classifier resulting robust result initial stage learning qualitative error analysis identifies problem automatic wsd discusses reason great gap performance human annotator automatic wsd system
paper describes submission endtoend yitrans speech translation system iwslt offline task translates english audio german chinese japanese yitrans system built largescale pretrained encoderdecoder model specifically first design multistage pretraining strategy build multimodality model large amount labeled unlabeled data finetune corresponding component model downstream speech translation task moreover make various effort improve performance data filtering data augmentation speech segmentation model ensemble experimental result show yitrans system obtains significant improvement strong baseline three translation direction achieves bleu improvement last year optimal endtoend system tst englishgerman
herein present process developing first hungarian dependency treebank first short reference made dependency grammar considered important development treebank second mention made existing dependency corpus language third present step converting szeged treebank dependencytree format originally phrasestructured treebank produced dependency tree automatic conversion checked corrected thereby creating first manually annotated dependency corpus hungarian also go detail two major set problem ie coordination predicative noun adjective fourth give statistic treebank completed annotation business news newspaper article legal text text informatics time planning convert entire corpus dependency tree format finally give hint applicability system present database may utilized among others information extraction machine translation well
thanks growth local community various news website along increasing accessibility web endangered lessresourced language chance revive information era therefore web considered huge resource used extract language corpus enable researcher carry various study linguistics language technology zazagorani language family linguistic subgroup northwestern iranian language significant corpus available motivated create one paper present endeavour collect corpus zazaki gorani language containing k word token respectively corpus publicly available
present work progress temporal progression compositionality nounnoun compound previous work proposed computational method determining compositionality compound method try automatically determine transparent meaning compound whole respect meaning part hypothesize property might change time use timestamped google book corpus diachronic investigation first examine whether vectorbased semantic space extracted corpus able predict compositionality rating despite inherent limitation find using temporal information help predicting rating although correlation rating lower reported corpus finally show change compositionality time selection compound
large transformer pretrained clinical note electronic health record ehr afforded substantial gain performance predictive clinical task cost training model necessity data access coupled utility motivates parameter sharing ie release pretrained model clinicalbert effort used deidentified ehr many researcher access large set sensitive nondeidentified ehr might train bert model similar would safe release weight model work design battery approach intended recover personal health information phi trained bert specifically attempt recover patient name condition associated find simple probing method able meaningfully extract sensitive information bert trained mimiciii corpus ehr however sophisticated attack may succeed facilitate research make experimental setup baseline probing model available urlhttpsgithubcomelehmanexposingpatientdatarelease
modern sentencelevel nmt system often produce plausible translation isolated sentence however put context translation may end inconsistent propose monolingual docrepair model correct inconsistency sentencelevel translation docrepair performs automatic postediting sequence sentencelevel translation refining translation sentence context training docrepair model requires monolingual documentlevel data target language trained monolingual sequencetosequence model map inconsistent group sentence consistent one consistent group come original training data inconsistent group obtained sampling roundtrip translation isolated sentence show approach successfully imitates inconsistency aim fix using contrastive evaluation show large improvement translation several contextual phenomenon englishrussian translation task well improvement bleu score also conduct human evaluation show strong preference annotator corrected translation baseline one moreover analyze discourse phenomenon hard capture using monolingual data
paper describes approach clpsych shared task attempted predict crosssectional psychological health age future psychological distress based childhood essay attempted several modeling approach observed best crossvalidated prediction accuracy relatively simple model based psychological theory model provided reasonable prediction outcome notably model especially successful predicting outofsample psychological distress across people across time age
propose novel data augmentation labeled sentence called contextual augmentation assume invariance sentence natural even word sentence replaced word paradigmatic relation stochastically replace word word predicted bidirectional language model word position word predicted according context numerous appropriate augmentation original word furthermore retrofit language model labelconditional architecture allows model augment sentence without breaking labelcompatibility experiment six various different text classification task demonstrate proposed method improves classifier based convolutional recurrent neural network
crosslingual language model typically pretrained masked language modeling multilingual text parallel sentence paper introduce denoising word alignment new crosslingual pretraining task specifically model first selflabel word alignment parallel sentence randomly mask token bitext pair given masked token model us pointer network predict aligned token language alternately perform two step expectationmaximization manner experimental result show method improves crosslingual transferability various datasets especially tokenlevel task question answering structured prediction moreover model serve pretrained word aligner achieves reasonably low error rate alignment benchmark code pretrained parameter available githubcomczwinxlmalign
paper delf formidable challenge crossdomain generalization multimodal hate meme detection presenting compelling finding provide evidence supporting hypothesis textual component hateful meme enables multimodal classifier generalize across different domain image component prof highly sensitive specific training dataset evidence includes demonstration showing hatetext classifier perform similarly hatememe classifier zeroshot setting simultaneously introduction caption generated image meme hatememe classifier worsens performance average f blackbox explanation identify substantial contribution text modality average diminishes introduction meme image caption additionally evaluation newly created confounder dataset reveals higher performance text confounders compared image confounders average f
propose attentionbased model treat amr parsing sequencetograph transduction unlike amr parser rely pretrained aligners external semantic resource data augmentation proposed parser alignerfree effectively trained limited amount labeled amr data experimental result outperform previously reported smatch score amr ldct amr ldct
conversational machine comprehension requires deep understanding dialogue flow prior work proposed flowqa implicitly model context representation reasoning better understanding paper proposes explicitly model information gain dialogue reasoning order allow model focus informative cue proposed model achieves stateoftheart performance conversational qa dataset quac sequential instruction understanding dataset scone show effectiveness proposed mechanism demonstrate capability generalization different qa model task
people often answer yesno question without explicitly saying yes similar polar keywords figuring meaning indirectanswers challenging even large language model paper investigate problem working dialogue multiple domain present new benchmark three diverse domain movie script tennis interview airline customer service present approach grounded distant supervision blended training quickly adapt new dialogue domain experimental result show approach never detrimental yield f improvement high
holocaust experienced iconic place like auschwitz warsaw ghetto ordinary place city street forest hill home transformed occupation systematic violence place unnamed locationally ambiguous omnipresence throughout postwar testimony witness survivor holocaust emphasize undeniable importance paper share methodology developing typology place order annotate named unnamed place within interview transcript united state holocaust memorial museum ushmm machine learning model approach underscore benefit hybrid analysis automated extraction manual review create distinct category place paper also review testimony transcript converted structured data annotation preview ongoing work design search engine user dynamically query placebased approach studying holocaust
distributed representation word play major role field natural language processing encoding semantic syntactic information word however existing work learning word representation typically regard word individual atomic unit thus blind subword information word give rise difficulty representing outofvocabulary oov word paper present characterbased word representation approach deal limitation proposed model learns generate word representation character model employ convolutional neural network highway network character extract salient feature effectively unlike previous model learn word representation large corpus take set pretrained word embeddings generalize word entry including oov word demonstrate efficacy proposed model perform intrinsic extrinsic task word similarity language modeling respectively experimental result show clearly proposed model significantly outperforms strong baseline model regard word subwords atomic unit example achieve much improvement average perplexity morphologically rich language compared strong baseline language modeling task
paper proposes novel attention mechanism transformer neural machine translation synchronous syntactic attention inspired synchronous dependency grammar mechanism synchronizes sourceside targetside syntactic selfattentions minimizing difference targetside selfattentions sourceside selfattentions mapped encoderdecoder attention matrix experiment show proposed method improves translation performance wmt ende wmt enro aspec jaen point bleu
notwithstanding recent advance syntactic generalization remains challenge text decoder study showed gain incorporating sourceside symbolic syntactic semantic structure text generation transformer little work addressed decoding structure propose general approach tree decoding using transitionbased approach examining challenging test case incorporating universal dependency syntax machine translation present substantial improvement test set focus syntactic generalization presenting improved comparable performance standard mt benchmark qualitative analysis address case syntactic generalization vanilla transformer decoder inadequate demonstrates advantage afforded integrating syntactic information
motivated success texttotext transfer transformer pretrained natural language processing model propose unifiedmodal speecht framework explores encoderdecoder pretraining selfsupervised speechtext representation learning speecht framework consists shared encoderdecoder network six modalspecific speechtext prepostnets preprocessing input speechtext prenets shared encoderdecoder network model sequencetosequence transformation postnets generate output speechtext modality based output decoder leveraging largescale unlabeled speech text data pretrain speecht learn unifiedmodal representation hoping improve modeling capability speech text align textual speech information unified semantic space propose crossmodal vector quantization approach randomly mix speechtext state latent unit interface encoder decoder extensive evaluation show superiority proposed speecht framework wide variety spoken language processing task including automatic speech recognition speech synthesis speech translation voice conversion speech enhancement speaker identification
paper describes working note emotionx shared task hosted socialnlp objective task detect emotion based speaker utterance english taking multiclass text classification problem experimented develop model classify target class primary challenge task detect emotion short message communicated social medium paper describes participation smartdubainlp team emotionx shared task investigation detect emotion utterance using neural network natural language understanding
understanding causality core aspect intelligence event causality identification causal news corpus shared task address two aspect challenge subtask aim detecting causal relationship text subtask requires identifying signal word span refer cause effect respectively system based pretrained transformer stacked sequence tagging synthetic data augmentation rank third subtask win subtask f score corresponding margin pp secondbest system
transformer shown outperform recurrent neural networkbased sequencetosequence model various wordlevel nlp task yet characterlevel transduction task eg morphological inflection generation historical text normalization work outperform recurrent model using transformer empirical study uncover contrast recurrent sequencetosequence model batch size play crucial role performance transformer characterlevel task show large enough batch size transformer indeed outperform recurrent model also introduce simple technique handle featureguided characterlevel transduction improves performance insight achieve stateoftheart performance morphological inflection historical text normalization also show transformer outperforms strong baseline two characterlevel transduction task graphemetophoneme conversion transliteration
behavior pretrained language model lm thoroughly examined happened pretraining rarely studied thus investigate developmental process set randomly initialized parameter totipotent language model refer textitembryology pretrained language model result show albert learns reconstruct predict token different part speech po different learning speed pretraining also find linguistic knowledge world knowledge generally improve pretraining proceeds downstream task performance finding suggest knowledge pretrained model varies pretraining pretrain step necessarily provide model comprehensive knowledge provide source code pretrained model reproduce result urlhttpsgithubcomdalbertembryology
cascade decoding framework shown superior performance event extraction task however treat sentence sequence neglect potential benefit syntactic structure sentence paper improve cascade decoding novel module selfsupervised task specifically propose syntaxaware aggregator module model syntaxof sentence based cascade decoding framework capture event dependency aswell syntactic information moreover design type discrimination task learn better syntactic representation different event type could boost performance eventextraction experimental result two widely used event extraction datasets demonstrate thatour method could improve original cascade decoding framework percentagepoints f score outperform number competitive baseline method introduction
modal verb eg must occur highly frequently scientific article decoding function straightforward often used hedging may also denote ability restriction understanding meaning important accurate information extraction scientific textto foster research usage modal genre introduce mist modal scientific text dataset contains modal instance five scientific domain annotated semantic pragmatic rhetorical function systematically evaluate set competitive neural architecture mist transfer experiment reveal leveraging nonscientific data limited benefit modeling distinction mist corpus analysis provides evidence scientific community differ usage modal verb yet classifier trained scientific data generalize extent unseen scientific domain
natural way design negotiation dialogue system via selfplay rl train agent learns maximize performance interacting simulated user designed imitate humanhuman dialogue data although procedure adopted prior work find result fundamentally flawed system fails learn value compromise negotiation often lead agreement ie partner walking away without deal ultimately hurting model overall performance investigate observation context dealornodeal task multiissue negotiation book hat ball grounded negotiation theory economics modify training procedure two novel way design agent diverse personality analyze performance human partner find although technique show promise selfish agent maximizes performance also avoiding walkaway performs superior variant implicitly learning generate value negotiation partner discus implication finding mean successful negotiation dialogue system system designed future
automatically generating product review meaningful yet wellstudied task sentiment analysis traditional natural language generation method rely extensively handcrafted rule predefined template paper present attentionenhanced attributetosequence model generate product review given attribute information user product rating attribute encoder learns represent input attribute vector sequence decoder generates review conditioning output vector also introduce attention mechanism jointly generate review align word input attribute proposed model trained endtoend maximize likelihood target product review given attribute build publicly available dataset review generation task leveraging amazon book review metadata experiment dataset show approach outperforms baseline method attention mechanism significantly improves performance model
propose task emotion style transfer particularly challenging emotion anger disgust fear joy sadness surprise fence content style understand particular difficulty task design transparent emotion style transfer pipeline based three step select word promising substituted change emotion bruteforce approach selection based attention mechanism emotion classifier find set word candidate substituting word based lexical distributional semantics select promising combination substitution objective function consists component content based bert sentence embeddings emotion based emotion classifier fluency based neural language model comparably straightforward setup enables u explore task understand case lexical substitution vary emotional load text change content style interact odds evaluate pipeline quantitatively automated annotation study based tweet find indeed simultaneous adjustment content emotion conflicting objective show qualitative analysis motivated scherers emotion component model particularly case implicit emotion expression based cognitive appraisal description bodily reaction
conversational ai system gaining lot attention recently industrial scientific domain providing natural way interaction customer adaptive intelligent system key requirement system ability understand user intent provide adequate response one greatest challenge language understanding lu service efficient utterance sentence representation vector space essential step ml task paper propose novel approach generating vector space representation utterance using pairwise similarity metric proposed approach us corpus tune weight similarity metric without relying external general purpose ontology experiment confirm generated vector improve performance lu service unsupervised semisupervised supervised learning task
paper introduce system participated multilingual crosslingual wordincontext disambiguation semeval shared task experiment investigated possibility using allwords finegrained word sense disambiguation system trained purely senseannotated data english draw prediction semantic equivalence word context based similarity ranked list english wordnet synset returned target word decision made overcame multiand crosslingual aspect shared task applying multilingual transformer encoding text written either arabic english french russian chinese result lag behind top scoring submission benefit provides binary flag whether two word context meaning also provides tangible output form ranked list english wordnet synset irrespective language input text framework designed generic possible applied baseline basically language supported multilingual transformed architecture employed even absence additional form language specific training data
current language model usually trained using selfsupervised scheme main focus learning representation word sentence level however limited progress generating useful discourselevel representation work propose use idea predictive coding theory augment bertstyle language model mechanism allows learn suitable discourselevel representation result proposed approach able predict future sentence using explicit topdown connection operate intermediate layer network experimenting benchmark designed evaluate discourserelated knowledge using pretrained sentence representation demonstrate approach improves performance task excelling discourse relationship detection
work lay foundation automated assessment narrative quality student writing first manually score essay narrativerelevant trait subtraits measure interannotator agreement explore linguistic feature indicative good narrative writing use build automated scoring system experiment show feature effective scoring specific aspect narrative quality stateoftheart feature set
paper describes analyzes participation evalnlp shared task focus assessing effectiveness promptbased technique empower large language model handle task quality estimation particularly context evaluating machine translation summary conducted systematic experiment various prompting technique including standard prompting prompt informed annotator instruction innovative chainofthought prompting addition integrated approach zeroshot oneshot learning method maximize efficacy evaluation procedure work reveals combining approach using small open source model orcaminivb yield competitive result
speaker repeat construction frequently dialogue due peculiar informationtheoretic property repetition thought strategy costeffective communication study focus repetition lexicalised constructionsie recurring multiword unitsin english opendomain spoken dialogue hypothesise speaker use construction repetition mitigate information rate leading overall decrease utterance information content course dialogue conduct quantitative analysis measuring information content construction containing utterance estimating information content adaptive neural language model observe construction usage lower information content utterance facilitating effect increase throughout dialogue ii boosted repetition iii grows function repetition frequency density iv stronger repetition referential construction
work extends phrasebased statistical mt smt shallow syntax dependency two stringtochunks translation model proposed factored model augments phrasebased smt layered dependency joint model extends phrase translation table microtags ie perword projection chunk label rely ngram model target sequence different granularity single word microtags chunk particular ngrams defined syntactic chunk model syntactic constraint coping wordgroup movement experimental analysis evaluation conducted two popular chineseenglish task suggest shallowsyntax jointtranslation model potential outperform stateoftheart phrasebased translation reasonable computational overhead
recurrent neural network rnns temporal network cumulative nature shown promising result various natural language processing task despite success still remains challenge understand hidden behavior work analyze interpret cumulative nature rnn via proposed technique named textitlayerwisesemanticaccumulation lisa explaining decision detecting likely ie saliency pattern network relies decision making demonstrate textitlisa rnn accumulates build semantics sequential processing given text example expected response textitexamplepattern saliency pattern look like category data according network decision making analyse sensitiveness rnns different input check increase decrease prediction score extract saliency pattern learned network employ two relation classification datasets semeval task tac kbp slot filling explain rnn prediction via textitlisa textitexamplepattern
system automatically process sign language rely appropriate data therefore present atis sign language corpus based domain air travel information available five language english german irish sign language german sign language south african sign language corpus used different task like automatic statistical translation automatic sign language recognition allows specific modeling spatial reference signing space
data imbalance problem crucial issue multilabel text classification existing work tackle proposing imbalanced loss objective instead vanilla crossentropy loss performance remain limited case extremely imbalanced data propose hybrid solution adapts general network head category fewshot technique tail category propose hybridsiamese convolutional neural network hscnn additional technical attribute ie multitask architecture based single siamese network categoryspecific similarity siamese structure specific sampling method training hscnn result using two benchmark datasets three loss objective show method improve performance single network diverse loss objective tail entire category
twitter medium used adequately user interest derived follows characteristic make attractive source personality derivation set test hypothesis analogous lexical hypothesis posit word use reveal personality following behavior social medium reveal personality aspect used twostep approach wherein first stage selected account possible infer personality profile extent using available literature personality interest account trained regression model segmented derived feature using hierarchical cluster analysis second stage obtained small sample user personality via questionnaire tested whether model stage correlated user step explained variance neurotic neutral neuroticism group indicated significant result r p r p confirming hypothesis following behavior correlated one interest interest correlated neuroticism personality dimension
recent work demonstrated success controlling sentence attribute eg sentiment structure eg syntactic structure based diffusion language model key component drive theimpressive performance generating highquality sample noise iteratively denoise thousand step beneficial complexity starting noise learning step limited implementation many nlp realworld application paper proposes language rectified flow lfour method based reformulation standard probabilistic flow modelslanguage rectified flow learns neural ordinary differentialequation model transport source distribution target distribution henceproviding unified effective solution generative modeling domain transferfrom source distribution language rectified flow yield fast simulation effectively decrease inference time experiment three challenging finegrained control task multiple highquality text editing show method consistently outperforms baseline extensive experiment ablation study demonstrate method general effective beneficial many nlp task
human remarkably flexible understanding new sentence include combination concept never encountered recent work shown deep network mimic human language ability presented novel sentence systematic variation uncovers limitation languageunderstanding ability network demonstrate limitation overcome addressing generalization challenge gscan dataset explicitly measure well agent able interpret novel linguistic command grounded vision eg novel pairing adjective noun key principle employ compositionality compositional structure network reflect compositional structure problem domain address allowing parameter learned endtoend build generalpurpose mechanism enables agent generalize language understanding compositional domain crucially network stateoftheart performance prior work generalizing knowledge prior work network also provides level interpretability enables user inspect part network learns robust grounded language understanding without dramatic failure without corner case critical building safe fair robot demonstrate significant role compositionality play achieving goal
existing approach mitigate demographic bias evaluate monolingual data however multilingual data examined work treat gender domain eg male v female present standard domain adaptation model reduce gender bias improve performance text classifier multilingual setting evaluate approach two text classification task hate speech detection rating prediction demonstrate effectiveness approach three fairaware baseline
paper present newest version retico pythonbased incremental dialogue framework create stateoftheart spoken dialogue system simulation retico provides range incremental module based service like google asr google tt rasa nlu incremental network created either code graphical user interface demo present three use case implemented retico spoken translation tool translates speech realtime conversation simulation model turntaking spoken dialogue restaurant information service
propaganda defined form communication aim influence opinion action people towards specific goal achieved mean welldefined rhetorical psychological device propaganda form know today dated back beginning th century however advent internet social medium propaganda started spread much larger scale thus becoming major societal political issue nowadays large fraction propaganda social medium multimodal mixing textual visual content mind propose new multilabel multimodal task detecting type propaganda technique used meme create release new corpus meme carefully annotated propaganda technique appear text image analysis corpus show understanding modality together essential detecting technique confirmed experiment several stateoftheart multimodal model
incompleteness domain ontology unavailability value two inevitable problem dialogue state tracking dst existing approach generally fall two extreme choosing model without ontology embedding ontology model leading overdependence paper propose new architecture cleverly exploit ontology consists slot attention sa value normalization vn referred savn moreover supplement annotation supporting span multiwoz shortest span utterance support labeled value sa share knowledge slot utterance need simple structure predict supporting span vn designed specifically use ontology convert supporting span value empirical result demonstrate savn achieves stateoftheart joint accuracy multiwoz multiwoz besides evaluate vn incomplete ontology result show even ontology used vn also contribute model
transferring pretrained language model common approach conventionally attach taskspecific classifier top layer adapt pretrained layer investigate whether one could make taskspecific selection subset layer adapt place classifier goal reduce computation cost transfer learning method eg finetuning adaptertuning without sacrificing performancewe propose select layer based variability hidden state given taskspecific corpus say layer already wellspecialized task withinclass variability hidden state low relative betweenclass variability variability metric cheap compute doesnt need training hyperparameter tuning robust data imbalance data scarcity extensive experiment glue benchmark demonstrate selecting layer based metric yield significantly stronger performance using number top layer often match performance finetuning adaptertuning entire language model
scientific literature record research process standardized structure provides clue track progress scientific field understanding internal structure content paramount importance natural language processing nlp technology meet requirement developed multilayered annotated corpus scientific paper domain computer graphic sentence annotated respect role argumentative structure discourse purpose citation specified special feature scientific discourse advantage disadvantage identified addition grade allocated sentence according relevance included summary best knowledge complex multilayered collection annotation metadata characterizing set research paper never grouped together one corpus therefore constitutes newer richer resource respect currently available field
describe finding third nuanced arabic dialect identification shared task nadi nadi aim advancing stateoftheart arabic nlp including arabic dialect affording diverse datasets modeling opportunity standardized context meaningful comparison model approach possible nadi targeted dialect identification subtask dialectal sentiment analysis subtask country level total unique team registered shared task team participated valid submission among team participated subtask participated subtask winning team achieved f subtask f subtask reflecting subtasks remain challenging motivating future work area describe method employed participating team offer outlook nadi
hate offensive language online platform pose significant challenge necessitating automatic detection method particularly case codemixed text common social medium complexity problem increase due cultural nuance different language dravidianlangtecheacl organized shared task detecting hate offensive language telugu complete task study investigates effectiveness transliterationaugmented datasets telugu codemixed text work compare performance various machine learning ml deep learning dl transformerbased model original augmented datasets experimental finding demonstrate superiority transformer model particularly telugubert achieving highest fscore augmented dataset ranking st position leaderboard study highlight potential transliterationaugmented datasets improving model performance suggests exploration diverse transliteration option address realworld scenario
knowledge base question answering kbqa system play pivotal role domain natural language processing information retrieval primary objective bridge gap natural language question structured knowledge representation especially complex kbqa despite significant progress developing effective interconnected kbqa technology recent emergence large language model llm offer opportunity address challenge faced kbqa system efficiently study adopts llm large language model meta ai llama channel connect natural language question structured knowledge representation proposes threestep finetune strategy based large language model implement kbqa system tfskbqa method achieves direct conversion natural language question structured knowledge representation thereby overcoming limitation existing kbqa method addressing large search reasoning space ranking massive candidate evaluate effectiveness proposed method conduct experiment using three popular complex kbqa datasets result achieve stateoftheart performance across three datasets particularly notable result webquestionsp dataset achieves f value
approach authorship attribution task identifying author document based analysis individual writing style andor preferred topic although problem widely explored previous study analysed relationship dataset characteristic effectiveness different type feature study carry analysis four widely used datasets explore different type feature affect authorship attribution accuracy varying condition result analysis applied authorship attribution model based discrete continuous representation apply conclusion analysis extension existing approach authorship attribution outperform prior stateoftheart two four datasets used
retrievalaugmented language model ralms demonstrated significant potential refining expanding internal memory retrieving evidence external source however ralms inevitably encounter textbfknowledge conflict integrating internal memory external source knowledge conflict ensnare ralms tugofwar knowledge limiting practical applicability paper focus exploring resolving knowledge conflict ralms first present evaluation framework assessing knowledge conflict across various dimension investigate behavior preference ralms following two perspective conflict internal memory external source find stronger ralms emerge dunningkruger effect persistently favoring faulty internal memory even correct evidence provided besides ralms exhibit availability bias towards common knowledge conflict truthful irrelevant misleading evidence reveal ralms follow principle majority rule leaning towards placing trust evidence appears frequently moreover find ralms exhibit confirmation bias willing choose evidence consistent internal memory solve challenge knowledge conflict propose method called conflictdisentangle contrastive decoding cd better calibrate model confidence experimental result demonstrate cd effectively resolve knowledge conflict ralms
long time philosopher linguist scientist keen finding answer mindbending question abstract language look like also sprung phenomenon mental imagery emerges mind one way approaching matter word representation exploring common semantic element link word visual language like sign language found reveal enlightening pattern across sign similar meaning pointing towards possibility identifying cluster iconic meaning insight merged understanding verb predicate achieved verbnet study present novel verb classification system based visual shape using graphic animation visually represent class abstract verb considerable agreement participant judged graphic animation based representativeness suggests positive way forward proposal may developed language learning aid educational context multimodal language comprehension tool digital text
recent research demonstrated large language model llm enhance capability utilizing external tool however three pivotal question remain unanswered effective current llm utilizing tool enhance llm ability utilize tool obstacle need overcome leverage tool address question introduce apibank groundbreaking benchmark specifically designed toolaugmented llm first question develop runnable evaluation system consisting api tool annotate tooluse dialogue api call assess existing llm capability planning retrieving calling apis second question construct comprehensive training set containing tooluse dialogue apis spanning distinct domain using dataset train lynx toolaugmented llm initialized alpaca experimental result demonstrate gpt exhibit improved tool utilization compared gpt gpt excels planning however still significant potential improvement moreover lynx surpasses alpaca tool utilization performance pt approach effectiveness gpt error analysis highlight key challenge future research field answer third question
transfer learning based pretraining language model large amount raw data become new norm reach stateoftheart performance nlp still remains unclear approach applied unseen language covered available largescale multilingual language model small amount raw data generally available work comparing multilingual monolingual model show model behave multiple way unseen language language greatly benefit transfer learning behave similarly closely related high resource language whereas others apparently focusing latter show failure transfer largely related impact script used write language show transliterating language significantly improves potential largescale multilingual language model downstream task result provides promising direction towards making massively multilingual model useful new set unseen language
frame communication often evoked multimedia document author decides add image text one modality may evoke communication frame moreover evoking frame author also conveys herhis stance towards frame determining author favor stance towards frame performed automatically processing text due absence stance annotation multimedia document paper introduce mmvaxstance dataset multimedia document retrieved social medium stance annotation towards different frame communication dataset allowed u experiment several model multimedia stance detection revealed important interaction text image inference stance towards communication frame inferring textimage relation set synthetic example multimodal document known stance generated greatly impacted quality identifying multimedia stance yielding improvement fscore
present texigt commandline tool extraction structured linguistic data latex source document language resource generated using tool corpus interlinear glossed text igt extracted open access book published language science press extracted example represented simple xml format easy process used validate certain aspect interlinear glossed text main challenge involved parsing tex latex document review task impossible general texhs haskell library us layered architecture selective early evaluation expansion lexing parsing order provide access structured representation latex document several level particular parsing module generate abstract syntax tree latex document expansion userdefined macro lexerlevel command serf ideal interface extraction interlinear glossed text texigt architecture easily adapted extract type linguistic data structure latex source document
specialized number representation nlp shown improvement numerical reasoning task like arithmetic word problem masked number prediction human also use numeracy make better sense world concept eg seat people room better grasp number improve model understanding concept word paper study effect using six different number encoders task masked word prediction mwp proxy evaluating literacy support investigation develop wikiconvert sentence dataset annotated number unit avoid conflating nominal ordinal number occurrence find significant improvement mwp sentence containing number exponent embeddings best number encoders yielding point jump prediction accuracy bert baseline enhanced literacy skill also generalize context without annotated number release code urlhttpsgitiojuzxn
celebrating th anniversary elra carrying strong involvement hlt field share elras expertise past year article begin presentation elras strategic data lr management plan wide use language community report elras activity service provided since lrec looking cataloguing licensing activity see elra active making metashare repository move toward new development step supporting europe obtain accurate lr within connecting europe facility programme promoting use lr citation creating elra license wizard web portal article elaborates recent lr production activity various written speech video resource commissioned public private customer parallel elda also worked several eufunded project centred strategic issue related european digital single market last part give overview latest dissemination activity special focus celebration th anniversary organised dubrovnik croatia following lrec well launching new elra portal
europeana translate project funded connecting european facility objective take advantage stateoftheart machine translation order increase multilinguality resource cultural heritage domain
alzheimers disease irreversible brain disease slowly destroys memory skill andthinking skill leading need fulltime care early detection alzheimers disease fundamental slow progress disease work developing natural language processing technique detect linguistic characteristic patient suffering alzheimers disease related dementia proposing neural model based cnnlstm architecture able take consideration long language sample handcrafted linguistic feature distinguish dementia affected healthy patient exploring effect introduction attention mechanism model actual state art approach able set new stateofthe art dementiabank dataset achieving f score dementia patient classification supplementary material include code run experiment
interplay cultural linguistic element characterizes metaphorical language pose substantial challenge human comprehension machine processing challenge go beyond monolingual setting becomes particularly complex translation even automatic translation present volimet corpus parallel sentence containing gold standard alignment metaphorical verbobject pair literal paraphrase eg tackleaddress question english german french one hand parallel nature corpus enables u explore monolingual pattern metaphorical v literal us english hand investigate different aspect crosslingual translation german french extent metaphoricity literalness source language transferred target language monolingually finding reveal clear preference using metaphorical literal us verbobject pair crosslingually observe rich variability translation well different behavior two target language
paper aspectbased sentiment analysis absa present first version finegrained annotated corpus targetbased opinion analysis tboa analyze economic activity financial market annotated intrasentential level corpus sentence extracted document representative financial analyst mostread material considering financial actor communicate evolution event trend analyze related publication news official communication etc since focus identifying expression opinion related economy financial market annotated sentence contain least one subjective expression domainspecific term candidate sentence annotation randomly chosen text specialized press professional information channel period ranging annotation scheme relies various linguistic marker like domainspecific vocabulary syntactic structure rhetorical relation explicitly describe author subjective stance investigated evaluated recourse automatic preannotation existing natural language processing technology alleviate annotation workload aim propose corpus usable one hand training material automatic detection opinion expressed extensive range domainspecific aspect hand gold standard evaluation tboa paper present preannotation model evaluation performance introduce annotation scheme report main characteristic corpus
parser parametrize wider scope generally accurate edgefactored model graphbased nonprojective parser wider factorization far implied large increase computational complexity parsing problem paper introduces crossingsensitive generalization thirdorder factorization trade complexity model structure ie scoring feature multiple edge complexity output structure ie producing crossing edge model optimal endpointcrossing tree found time matching asymptotic runtime thirdorder projective parser edgefactored endpointcrossing parser crossingsensitive thirdorder parser significantly accurate thirdorder projective parser many experimental setting significantly less accurate none
recent study emergent capability transformerbased natural language understanding nlu model indicated understanding lexical compositional semantics provide evidence suggests claim taken grain salt find stateoftheart natural language inference nli model sensitive towards minor semantics preserving surfaceform variation lead sizable inconsistent model decision inference notably behaviour differs valid indepth comprehension compositional semantics however neither emerge evaluating model accuracy standard benchmark probing syntactic monotonic logically robust reasoning propose novel framework measure extent semantic sensitivity end evaluate nli model adversarially generated example containing minor semanticspreserving surfaceform input noise achieved using conditional text generation explicit condition nli model predicts relationship original adversarial input symmetric equivalence entailment systematically study effect phenomenon across nli model textemphin textemphoutof domain setting experiment show semantic sensitivity cause performance degradation average textemphin textemphoutof domain setting respectively perform ablation study analysing phenomenon across model datasets variation inference show semantic sensitivity lead major inconsistency within model prediction
paper present new dataset discourse representation structure drss annotated naturallyoccurring sentence importantly sentence varied length average longer existing goldstandard drs dataset parallel meaning bank show therefore much harder parser argue though provides realistic assessment difficulty drs parsing
context voice assistant system steering refers phenomenon user issue followup command attempting direct clarify previous turn propose steer steering detection model predicts whether followup turn user attempt steer previous command constructing training dataset steering use case pose challenge due coldstart problem overcome developed heuristic rule sample optin usage data approximating positive negative sample without annotation experimental result show promising performance identifying steering intent accuracy sampled data moreover steer conjunction sampling strategy aligns effectively realworld steering scenario evidenced strong zeroshot performance humangraded evaluation set addition relying solely user transcript input introduce steer enhanced version model steer utilizes semantic parse tree provide context outofvocabulary word named entity often occur sentence boundary improves model performance reducing error rate domain entity frequently appear messaging lastly present data analysis highlight improvement user experience voice assistant support steering use case
paper explore use small amount new data update taskoriented semantic parsing model desired output example changed making update way one potential problem arises presence conflicting data outofdate label original training set evaluate impact understudied problem propose experimental setup simulating change neural semantic parser show presence conflicting data greatly hinders learning update explore several method mitigate effect multitask data selection method lead large improvement model accuracy compared naive datamixing strategy best method close accuracy gap baseline oracle upper bound
paper present result team participation bea shared task multilingual lexical simplification pipeline mlsp shardlow et al task organizer supplied data combined two component simplification pipeline lexical complexity prediction lexical substitution dataset encompassed ten language including french given absence dedicated training data team challenged employing system trained preexisting resource evaluating performance unexplored test dataour team contributed task using previously developed model predicting lexical difficulty french tack model built deep learning architecture adding participation cwi shared task de hertog tack training dataset comprised binary decision annotation capturing perceived lexical difficulty collected sample nonnative french reader two pretrained neural logistic model used model predicting difficulty word within sentence context model predicting difficulty isolated wordsthe finding revealed despite trained distinct prediction task indicated negative r fit transferring logistic prediction lexical difficulty continuous score lexical complexity exhibited positive correlation specifically result indicated isolated prediction exhibited higher correlation r compared contextualized prediction r moreover isolated prediction demonstrated remarkably higher spearman rank correlation contextualized prediction result align earlier observation tack suggesting ground truth primarily capture lexical access difficulty wordtocontext integration problem
recent algorithm math word problem mwp neglect use outside knowledge present problem capture wordlevel relationship ignore build hierarchical reasoning like human mining contextual structure word sentence paper propose textbfreasoning textbfpretrained textbfknowledge textbfhierarchical textbfstructure textbfrpkhs network contains pretrained knowledge encoder hierarchical reasoning encoder firstly pretrained knowledge encoder aim reasoning mwp using outside knowledge pretrained transformerbased model secondly hierarchical reasoning encoder presented seamlessly integrating wordlevel sentencelevel reasoning bridge entity context domain mwp extensive experiment show rpkhs significantly outperforms stateoftheart approach two largescale commonlyused datasets boost performance mathk mathk fold crossvalidation mawps extensive ablation shown demonstrate effectiveness interpretability proposed method
emotion cause extraction aim identify reason behind certain emotion expressed text much difficult task compared emotion classification inspired recent advance using deep memory network question answering qa propose new approach considers emotion cause identification reading comprehension task qa inspired convolutional neural network propose new mechanism store relevant context different memory slot model context information proposed approach extract word level sequence feature lexical feature performance evaluation show method achieves stateoftheart performance recently released emotion cause dataset outperforming number competitive baseline least fmeasure
stateoftheart statistical machine translation system use hypothesis several maximum posteriori inference step including word alignment parse tree identify translational structure estimate parameter translation model approach lead modular pipeline independently developed component error made singlebest hypothesis propagate downstream estimation step treat input clean trustworthy training data work integrate nbest alignment parses using probability distribution alternative generate posterior fractional count use downstream estimation using fractional count dopinspired syntaxbased translation system show significant improvement translation quality singlebest trained baseline
automated simplification model aim make input text readable method potential make complex information accessible wider audience eg providing access recent medical literature might otherwise impenetrable lay reader however model risk introducing error automatically simplified text instance inserting statement unsupported corresponding original text omitting key information providing readable inaccurate version text may many case worse providing access problem factual accuracy lack thereof received heightened attention context summarization model factuality automatically simplified text investigated introduce taxonomy error use analyze reference drawn standard simplification datasets stateoftheart model output find error often appear captured existing evaluation metric motivating need research ensuring factual accuracy automated simplification model
learning representation knowledge base entity concept becoming increasingly important nlp application however recent entity embedding method relied structured resource expensive create new domain corpus present distantlysupervised method jointly learning embeddings entity text unnanotated corpus using list mapping entity surface form learn embeddings opendomain biomedical corpus compare prior method rely humanannotated text large knowledge graph structure embeddings capture entity similarity relatedness better prior work existing biomedical datasets new wikipediabased dataset release community result analogy completion entity sense disambiguation indicate entity word capture complementary information effectively combined downstream use
humangenerated nonliteral translation reflect richness human language sometimes indispensable ensure adequacy fluency nonliteral translation difficult produce even human translator especially foreign language learner machine translation still way simulate human one aspect order foster study appropriate creative nonliteral translation automatically detecting parallel corpus important step benefit downstream nlp task help construct material teach translation article demonstrates generic sentence representation produced pretrained crosslingual language model could finetuned solve task show exists moderate positive correlation prediction probability human translation nonliteral translation proportion sentence finetuning experiment show accuracy predicting presence nonliteral translation sentence accuracy distinguishing literal nonliteral translation phrase level conduct linguistic error analysis propose direction future work
lack text data major issue codeswitching language modeling paper introduce multitask learning based language model share syntax representation language leverage linguistic information tackle low resource data issue model jointly learns language modeling partofspeech tagging codeswitched utterance way model able identify location codeswitching point improves prediction next word approach outperforms standard lstm based language model improvement perplexity seame phase phase ii dataset respectively
neural sequencetosequence seqseq model grammatical error correction gec two limitation seqseq model may well generalized limited errorcorrected data seqseq model may fail completely correct sentence multiple error normal seqseq inference attempt address limitation proposing fluency boost learning inference mechanism fluency boosting learning generates fluencyboost sentence pair training enabling error correction model learn improve sentence fluency instance fluency boosting inference allows model correct sentence incrementally multiple inference step sentence fluency stop increasing experiment show approach improve performance seqseq model gec achieving stateoftheart result conll jfleg benchmark datasets
implicit motif allow characterization behavior subsequent success longterm development operationalized operant motive test research motif declined mainly due laborintensive costly human annotation study analyze labeled data item participant utilize engineering feature training logistic model tree machine learning model capture manually assigned motif well fscore coming close pairwise annotator intraclass correlation coefficient r addition found significant correlation r subsequent academic success data automatically labeled model extrinsic evaluation
current state art acoustic model easily comprise million parameter growing complexity demand larger training datasets maintain decent generalization final decision function ideal dataset necessarily large size large respect amount unique speaker utilized hardware varying recording condition enables machine learning model explore much domainspecific input space possible parameter estimation work introduces common phone genderbalanced multilingual corpus recorded contributor via mozillas common voice project comprises around hour speech enriched automatically generated phonetic segmentation wavvec acoustic model trained common phone perform phonetic symbol recognition validate quality generated phonetic annotation architecture achieved per entire test set computed unique phonetic symbol showing slight difference individual language conclude common phone provides sufficient variability reliable phonetic annotation help bridging gap research application acoustic model
evaluate feature hashing language identification lid method previously used task using standard dataset first show feature performance high lid data highly dimensional mostly sparse textgreater includes large vocabulary many language memory requirement grow language added next apply hashing using various hash size demonstrating performance loss dimensionality reduction also show using ensemble lowdimension hashbased classifier boost performance feature hashing highly useful lid hold great promise future work area
cognate variant lexical form across different language example fonema spanish phoneme english cognate mean unit sound task automatic detection cognate among two language help downstream nlp task crosslingual information retrieval computational phylogenetics machine translation paper demonstrate use crosslingual word embeddings detecting cognate among fourteen indian language approach introduces use context knowledge graph generate improved feature representation cognate detection evaluate impact cognate detection mechanism neural machine translation nmt downstream task evaluate method detect cognate challenging dataset twelve indian language namely sanskrit hindi assamese oriya kannada gujarati tamil telugu punjabi bengali marathi malayalam additionally create evaluation datasets two indian language konkani nepali observe improvement point term fscore cognate detection furthermore observe cognate extracted using method help improve nmt quality bleu also release code newly constructed datasets crosslingual model publicly
present carefully designed dependency conversion german phrasestructure treebank tiger explicitly represents verb ellipsis introducing empty node tree although conversion process us heuristic like many conversion tool designed fail reasonable solution found failing conversion process make possible detect elliptical construction head missing also allows u find error original annotation discus conversion process heuristic describe design decision error correction applied corpus since today datadriven dependency parser able handle empty node directly parsing conversion tool also derives canonical dependency format without empty node shown experimentally well suited training statistical dependency parser comparing performance two parser different parsing paradigm data set conll shared task data corpus
humor play important role daily life essential fascinating element communication person therefore recognize punchlines dialogue ie conversational humor recognition attracted much interest computational linguistics community however existing work attempted understand conversational humor analyzing contextual information dialogue neglected character interlocutor age gender occupation instance utterance could bring humorous serious person may plain expression naive person end paper proposes character fusion conversational humor recognition model cfchr explore character information recognize conversational humor cfchr utilizes multitask learning framework unifies two highly pertinent task ie character extraction punchline identification based deep neural network trained task jointly sharing weight extract common taskinvariant feature task could still learn taskspecific feature experiment conducted chinese sitcom corpus consisted utterance character experimental result demonstrated cfchr could achieve improvement term fscore strong baseline proved effectiveness character information identify punchlines
understanding implicit value belief diverse group culture using qualitative text longform narrative domainexpert interview fundamental goal social anthropology paper build upon study introduced nlp task recognizing value resonance rvr gauging perspective positive negative neutral implicit value belief textual pair study included novel handannotated dataset world value corpus wvc designed simulate task rvr transformerbased model resonancetuned roberta designed model task extend existing work refining task definition releasing world value corpus wvc dataset conduct several validation experiment designed robustly evaluate need task specific modeling even world llm finally present two additional resonancetuned model trained extended rvr datasets designed improve rvr model versatility robustness result demonstrate resonancetuned model outperform topperforming recognizing textual entailment rte model recognizing value resonance well zeroshot gpt several different prompt structure emphasizing practical applicability finding highlight potential rvr capturing cultural value within text importance taskspecific modeling
study event understanding critical step towards visual commonsense task meanwhile argue current objectbased event understanding purely likelihoodbased leading incorrect event prediction due biased correlation event object propose mitigate bias docalculus proposed causality research overcoming limited robustness optimized aggregation associationbased predictionwe show effectiveness approach intrinsically comparing generated event groundtruth event annotation extrinsically downstream commonsense task
instructionfollowing language model iflms promising versatile tool solving many downstream informationseeking task given success urgent need shared resource determine whether existing new iflms prone produce biased language interaction paper propose prompt association test pat new resource testing presence social bias iflms pat stem weat caliskan et al generalizes notion measuring social bias iflms basically cast weat word test promptized classification task associate metric bias score resource consists prompt experimented several family iflms discovering gender race bias analyzed model expect pat important tool quantifying bias across different dimension therefore encouraging creation fairer iflms distortion consequence real world
labeled data task coreference resolution scarce resource requiring significant human effort stateoftheart coreference model rely data propose approach leverage endtoend neural model setting labeled data unavailable specifically using weak supervision transfer linguistic knowledge encoded stanford rulebased coreference system endtoend model jointly learns rich contextualized span representation coreference chain experiment english ontonotes corpus demonstrate approach effectively benefit noisy coreference supervision producing improvement stanford rulebased system f outperforming previous best unsupervised model f additionally validate efficacy method two datasets preco litbank f stanford system respectively
large instructiontuned language model ie finetuned respond instruction demonstrated remarkable ability generalize zeroshot new task nevertheless depend heavily humanwritten instruction data often limited quantity diversity creativity therefore hindering generality tuned model introduce selfinstruct framework improving instructionfollowing capability pretrained language model bootstrapping generation pipeline generates instruction input output sample language model filter invalid similar one using finetune original model applying method vanilla gpt demonstrate absolute improvement original model supernaturalinstructions par performance instructgpt trained private user data human annotation evaluation curate set expertwritten instruction novel task show human evaluation tuning gpt selfinstruct outperforms using existing public instruction datasets large margin leaving absolute gap behind instructgpt selfinstruct provides almost annotationfree method aligning pretrained language model instruction release large synthetic dataset facilitate future study instruction tuning
paper proposes aeda easier data augmentation technique help improve performance text classification task aeda includes random insertion punctuation mark original text easier technique implement data augmentation eda method wei zou compare result addition keep order word changing position sentence leading better generalized performance furthermore deletion operation eda cause loss information turn misleads network whereas aeda preserve input information following baseline perform experiment five different datasets text classification show using aedaaugmented data training model show superior performance compared using edaaugmented data five datasets source code made available study reproduction result
paper document creation largescale dataset evaluative sentence ie subjective objective sentence found sentimentbearing based mixeddomain professional review various newssources present annotation scheme first result classification experiment effort represents step toward creating norwegian dataset finegrained sentiment analysis
data annotation expensive taskoriented dialogue tod system new intent discovery nid task aim identify novel intent retaining ability recognize known intent essential expanding intent base taskbased dialogue system previous work relying external datasets hardly extendable meanwhile effective one generally depends power large language model llm address limitation model extensibility take advantage llm nid task propose lanid framework leverage llm zeroshot capability enhance performance smaller text encoder nid task lanid employ knn dbscan algorithm select appropriate pair utterance training set llm asked determine relationship collected data used construct finetuning task small text encoder optimized triplet loss experimental result demonstrate efficacy proposed method three distinct nid datasets surpassing strong baseline unsupervised semisupervised setting code found httpsgithubcomfloatsdsdslanid
large language model llm demonstrated potential refine generation based feedback however feedback llm often inaccurate thereby limiting benefit paper propose study assistant large language model salam novel framework auxiliary agent assist main llm learning mistake interactive cooperation gathering phase student assistant agent probe main llm analyzes error collect interaction mistake memory examination phase study assistant provides guideline retrieving relevant case help main llm anticipate avoid similar error first investigate effectiveness general study assistant customize provide llmspecific guidance imitation learning successful guidance experience experiment three llm using two challenging framework demonstrate salam significantly boost llm accuracy margin bbh bbq
present approach mining online forum figurative language metaphor target particular online discussion within illness political conflict domain view constructing corpus metaphor illness discussion andmetaphor political conflict discussion paper report ongoing effort combine manual automatic detection strategy labelling corpus present initial result work showing metaphor use independent illness domain
paper describes design collection current status han christian andersen hca conversation corpus corpus consists five separate corpus represents transcription annotation hour english spoken deictic gesture usersystem interaction recorded mainly child corpus collected part development evaluation process two consecutive research prototype setup used collect corpus described well use corpus system development describe annotation corpus briefly present various us made corpus far hca corpus made publicly available urlhttpwwwniceprojectcomdata march
arabic wordnet awn represents one bestknown lexical resource arabic language however contains various issue affect use different natural language processing nlp application due resource deficiency update arabic wordnet requires much effort two update first published significant represented significant development usability coverage arabic wordnet paper provides study case update arabic wordnet development content precisely present new content term relation added extended version arabic wordnet also validate evaluate content different level use different version word sense disambiguation system finally compare result evaluate result show newly added semantic relation improve performance word sense disambiguation system
kataku hybrid mt system indonesian english english indonesian translation available window linux webbased platform paper briefly present technical background kataku use case extension kataku flagship product toggletext language technology company based melbourne australia
paper present text augmentation based approach table statement support subtask phase semeval task experiment different text augmentation technique back translation synonym swapping using wordvec wordnet show text augmentation technique lead improvement f test set investigate impact domain adaptation joint learning fact verification tabular data utilizing semtabfacts tabfact datasets observe joint learning improves f score semtabfacts tabfact test set respectively
paper describes submission wmt shared metric task unsupervised metric estimate translation quality chunklevel sentencelevel source target sentence chunk retrieved using multilingual chunker chunklevel similarity computed leveraging bert contextual word embeddings sentence similarity score calculated leveraging sentence embeddings languageagnostic bert model final quality estimation score obtained mean pooling chunklevel sentencelevel similarity score paper outline experiment also report correlation human judgement ende enru zhen language pair wmt wmt wmt test set
cooperative dialogue identifying intent one conversation partner acting accordingly great importance endeavour facilitated phrasing intention directly possible observe humanhuman communication number factor cultural norm politeness may result expressing one intent indirectly therefore humancomputer communication anticipate possibility user indirect prepared interpret actual meaning furthermore dialogue system able conform human expectation adjusting degree directness us improve user experience reach goal propose approach differentiate direct indirect utterance find utterance opposite characteristic express intent endeavour employ dialogue vector model recurrent neural network
introduce transductive model parsing universal decompositional semantics uds representation jointly learns map natural language utterance uds graph structure annotate graph decompositional semantic attribute score also introduce strong pipeline model parsing uds graph structure show transductive parser performs comparably additionally performing attribute prediction analyzing attribute prediction error find model capture natural relationship attribute group
laughter intrinsic component humanhuman interaction current automatic speech understanding paradigm stand gain significantly detection modeling current work produce manual segmentation laughter large corpus interactive multiparty seminar promise valuable resource acoustic modeling purpose importantly quantify occurrence laughter new domain contrast observation finding laughter multiparty meeting analysis show respect majority measure explore occurrence laughter domain quite similar
build chat bot iterative content exploration lead user personalized knowledge acquisition session chat bot designed automated customer support product recommendation agent assisting user learning product feature product usability suitability troubleshooting related task control user navigation content extend notion linguistic discourse tree dt towards set document multiple section covering topic given paragraph dt built dt parser combine dts paragraph document form call extended dt basis interactive content exploration facilitated chat bot provide cohesive answer use measure rhetoric agreement question answer tree kernel learning dts
article describes interface searching browsing multimodal recording group meeting provide first overall perspective meeting processing retrieval application distinguish mediamodalities recorded one used browsing proceed describe data annotation stored meeting database two scenario use transcriptbased query browsing interface tqb outlined search browse v overview browse main functionality tqb namely database backend multimedia rendering solution described outline evaluation perspective finally provided description user interaction feature monitored
existing approach automatic verbnetstyle verb classification heavily dependent feature engineering therefore limited language mature nlp pipeline work propose novel crosslingual transfer method inducing verbnets multiple language best knowledge first study demonstrates architecture learning word embeddings applied challenging syntacticsemantic task method us crosslingual translation pair tie six target language bilingual vector space english jointly specialising representation encode relational information english verbnet standard clustering algorithm run top verbnetspecialised representation using vector dimension feature learning verb class result show proposed crosslingual transfer approach set new stateoftheart verb classification performance across six target language explored work
number collocational constraint natural language ought play important role natural language parser thus example hard parser take advantage fact wine typically drunk produced sold probably pruned hard parser know verb go preposition eg set noun fit together form compound noun phrase eg computer programmer paper attempt show many type concern addressed syntactic method symbol pushing need require explicit semantic interpretation found possible identify many interesting cooccurrence relation computing simple summary statistic million word text paper summarize number experiment carried various subset author last year term collocation used quite broadly include constraint svo subject verb object triple phrasal verb compound noun phrase psychoiinguistic notion word association eg doctornurse
aligning sens across resource language challenging task beneficial application field natural language processing electronic lexicography paper describe effort manually aligning monolingual dictionary alignment carried senselevel various resource language moreover sens annotated possible semantic relationship broadness narrowness relatedness equivalence comparison previous datasets task dataset cover wide range language resource focus challenging task linking generalpurpose language believe data pave way advance alignment evaluation word sens creating new solution particularly notoriously requiring data neural network resource publicly available urlhttpsgithubcomelexiseumwsa
present semantic parser abstract meaning representation learns parse string tree representation compositional structure amr graph allows u use standard neural technique supertagging dependency tree parsing constrained linguistically principled type system present two approximative decoding algorithm achieve stateoftheart accuracy outperform strong baseline
position paper describes critique pretrainingagnostic identically distributed paid evaluation paradigm become central tool measuring progress natural language understanding paradigm consists three stage pretraining word prediction model corpus arbitrary size finetuning transfer learning training set representing classification task evaluation test set drawn distribution training set paradigm favor simple lowbias architecture first scaled process vast amount data second capture finegrained statistical property particular data set regardless whether property likely generalize example task outside data set contrast human learn language several order magnitude less data system favored evaluation paradigm generalize new task consistent way advocate supplementing replacing paid paradigm reward architecture generalize quickly robustly human
proliferation fake news malayalam language across digital platform emerged pressing issue employing recurrent neural network rnns type machine learning model aim distinguish original fake news malayalam achieved th rank task rnns chosen ability understand sequence word sentence important language like malayalam main goal develop better model spot fake news effectively analyze various feature understand contributes accuracy hope provide reliable method identifying combating fake news malayalam language
paper proposes system detect rephrase profanity chinese text rather masking detected profanity want revise input sentence using inoffensive word keeping original meaning rephrasing rule invented observing sentence realword social website overall accuracy proposed system
growing footprint ecommerce worldwide role contact center becoming increasingly crucial customer satisfaction effectively handle scale manage operational cost automation chatbots voicebots getting rapidly adopted customer multiple often long list active order first task voicebot identify one calling towards solving problem refer order identification propose twostaged realtime technique combining search prediction sequential manner first stage analogous retrievalbased questionanswering fuzzy search technique us customized textual similarity measure noisy transcript call retrieve order interest coverage fuzzy search limited limited response customer voice prompt hence second stage predictive solution predict likely order customer calling based certain feature order introduced compare multiple relevant technique based word embeddings well ecommerce product search show proposed approach provides best performance coverage accuracy large reallife dataset system based proposed technique also deployed production fraction call landing contact center large ecommerce provider providing real evidence operational benefit well increased customer delight
augmented language model alms empower large language model ability use tool transforming intelligent agent realworld interaction however existing framework alms varying degree deficient following critical feature flexible customization collaborative democratization holistic evaluation paper proposes gentopia lightweight extensible framework alms gentopia allows flexible customization agent simple configuration seamlessly integrating various language model task format prompting module plugins unified paradigm furthermore establish gentpool public platform enabling registration sharing usercustomized agent agent registered gentpool composable assembled together agent collaboration advancing democratization artificial intelligence ensure highquality agent gentbench integral component gentpool designed thoroughly evaluate usercustomized agent across diverse aspect safety robustness efficiency etc release gentopia github continuously move forward
individual often encounter persuasion attempt persuasion agent aim persuade target change target emotion belief behavior persuasion attempt observed various social setting advertising public health political campaign personal relationship persuasion attempt target generally like preserve autonomy response often manifest form resistance like skeptical reaction order detect skepticism response persuasion attempt social medium developed corpus based consumer psychology paper consider one prominent area persuasion attempt unfold social medium influencer marketing paper introduce skepticism detection corpus skotapa developed using multiple independent human annotation intercoder reliability evaluated krippendorffs alpha performed validity test show skepticism detected using potential proxy variable like sentiment sarcasm
annotating large number sentence sens heaviest requirement current word sense disambiguation present trainomatic languageindependent method generating million senseannotated training instance virtually meaning word language vocabulary approach fully automatic human intervention required type human knowledge used wordnetlike resource trainomatic achieves consistently stateoftheart performance across gold standard datasets language time removing burden manual annotation training data available research purpose urlhttptrainomaticorg
propose new neural transfer method termed dual adversarial transfer network datnet addressing lowresource named entity recognition ner specifically two variant datnet ie datnetf datnetp investigated explore effective feature fusion high low resource address noisy imbalanced training data propose novel generalized resourceadversarial discriminator grad additionally adversarial training adopted boost model generalization experiment examine effect different component datnet across domain language show significant improvement obtained especially lowresource data without augmenting additional handcrafted feature pretrained language model
paper describes utility semantic resource web wordnet gazetteer answer selection process questionanswering system contrast previous work using individual semantic resource support answer selection work combine multiple resource boost confidence score assigned correct answer evaluates different combination strategy based unweighted sum weighted linear combination logistic regression apply approach select answer candidate produced three different extraction technique varying quality focusing trec question whose answer represent location propernames experimental result demonstrate combination semantic resource effective individual resource three extraction technique improving answer selection accuracy much location question propername question combination strategy tested logistic regression model produced best result location propername question
neural semantic parsing sentence mapped meaning representation using encoderdecoder framework paper propose apply transformer architecture instead recurrent neural network task experiment two data set different domain different level difficulty show model achieved better result strong baseline certain setting competitive result across experiment
recent approach aspectbased sentiment analysis absa take coextraction approach spanlevel classification task performing subtasks aspect term extraction ate aspect sentiment classification asc simultaneously work build recent progress applying pretraining coextraction task introduction adaptation unsupervised data augmentation semisupervised learning originally implemented uda accommodate spanlevel classification since relies advanced data augmentation technique backtranslation alter sequence length original data cause index mismatch introduce adaptation uda using masked language model mlm unmasking accommodates indexmatch constraint test approach standard absa benchmark datasets show simple augmentation applied modestsized datasets along consistency training lead competitive performance current absa stateoftheart restaurant laptop domain using training data
paper describes winning system semeval task assessing humor edited news headline strategy stacking scale sa heterogeneous pretrained language model plms bert gpt sa first performs finetuning number plms various hyperparameters applies powerful stacking ensemble top finetuned plms experimental result show sa outperforms naive average ensemble leveraging weaker plms well highperforming plms interestingly result show sa captured nonfunny semantics consequently system ranked st subtasks significant margin compared system
trustfulness one general tendency confidence unknown people situation predicts many important realworld outcome mental health likelihood cooperate others clinician datadriven measure interpersonal trust previously introduced develop first languagebased assessment personality trait trustfulness fitting one language accepted questionnairebased trust score using trustfulness type case study explore role questionnaire size well word count developing languagebased predictive model user psychological trait find leveraging longer questionnaire yield greater test set accuracy training find beneficial include user took smaller questionnaire offer observation training similarly noting decrease individual prediction error word count increased found word countweighted training scheme helpful user first place
introduce attentionbased bilstm chinese implicit discourse relation demonstrate modeling argument pair joint sequence outperform word orderagnostic approach model benefit partial sampling scheme conceptually simple yet achieves stateoftheart performance chinese discourse treebank also visualize attention activity illustrate model ability selectively focus relevant part input sequence
propose novel robertabased model roppt introduces targetoriented parse tree structure metaphor detection compared existing model roppt focus semantically relevant information achieves stateoftheart several main metaphor datasets also compare approach several popular denoising pruning method demonstrating effectiveness approach context denoising code dataset found urlhttpsgithubcommajibearroppt
event involved pandemic outbreak step taken planning wedding answer question found collecting many document complex event interest extracting relevant information analyzing present new approach large language model utilized generate source document allow predicting given highlevel event definition specific event argument relation construct schema describes complex event entirety using model complete schema topic generated onthefly without manual data collection ie zeroshot manner moreover develop efficient method extract pertinent information text demonstrate series experiment schema considered complete humancurated one majority examined scenario finally show framework comparable performance previous supervised schema induction method rely collecting real text even reaching best score prediction task
computational argumentation general argument mining particular important research field previous work many challenge automatically extract degree reason natural language argument addressed tool extract argument unit increasingly available open problem addressed work presenting task aspectbased argument mining abam essential subtasks aspect term extraction ate nested segmentation n first instance create release annotated corpus aspect information tokenlevel consider aspect main point argument unit addressing information important downstream task argument ranking argument summarization generation well search counterargument aspectlevel present several experiment using stateoftheart supervised architecture demonstrate performance subtasks annotated benchmark available urlhttpsgithubcomtrtmabam
paper describe new lexical semantic resource rich event ontology provides independent conceptual backbone unify existing semantic role labeling srl schema augment eventtoevent causal temporal relation unifying framenet verbnet automatic content extraction rich entity relation event resource ontology serf shared hub disparate annotation schema therefore enables combination srl training data larger diverse corpus adding temporal causal relational information found independent resource ontology facilitates reasoning across document revealing relationship event come together temporal causal chain build complex scenario envision open resource serving valuable tool moving ontology text query event type scenario interest moving text ontology access interpretation event using combined semantic information housed
increasing use social medium site country like india given rise large volume codemixed data sentiment analysis data provide integral insight people perspective opinion codemixed data often noisy nature due multiple spelling word lack definite order word sentence random abbreviation thus working codemixed data challenging monolingual data interpreting model prediction allows u determine robustness model different form noise paper propose methodology integrate explainable approach codemixed sentiment analysis interpreting prediction sentiment analysis model evaluate well model able adapt implicit noise present codemixed data
metaphor popular figure speech popularity metaphor call automatic identification interpretation unsupervised method directed detection metaphor use handcoded knowledge propose unsupervised framework metaphor detection require handcoded knowledge applied clustering feature derived adjectivenoun pair classifying two disjoint class experimented adjectivenoun pair popular dataset annotated metaphor obtained accuracy kmeans clustering algorithm
paper present approach toward grounding linguistic positional directional label directly human motion course disoriented balancing task multiaxis rotational device use deep neural model predict human subject joystick motion well subject proficiency task combined bert embedding vector positional directional label extracted annotation embodied direction classifier find combining contextualized bert embeddings embeddings describing human motion proficiency successfully predict direction hypothetical human participant move achieve better balance accuracy comparable moderatelyproficient balancing task subject combined embodied model may actually make decision objectively better decision made human
present mkgdb largescale graph database created combination multiple taxonomy backbone extracted existing knowledge graph namely conceptnet dbpedia webisagraph wordnet wikipedia category hierarchy mkgdb thanks versatility neoj graph database manager technology intended favour help development opendomain natural language processing application relying knowledge base information extraction hypernymy discovery topic clustering others resource consists large hypernymy graph count million node million hypernymy relation
present corpus humanagent verbal gestural story retellings designed explore whether human would gesturally entrain embodied intelligent virtual agent used novel data collection method agent presented story component installment human would retell agent end installment human would retell embodied animated agent story whole method designed allow u observe whether change agent gestural behavior would result human gestural change agent modified gesture course story starting first installment gestural behavior designed manifest extraversion slowly modifying gesture express introversion time reverse corpus contains verbal gestural transcript human story retellings gesture coded type handedness temporal structure spatial extent degree participant gesture match produced agent corpus illustrates variation expressive behavior produced user interacting embodied virtual character degree gesture influenced agent dynamic change personalitybased expressive style
paper present approach semeval task semantic textual relatedness str language provided specifically focused english telugu proposal employ advanced natural language processing technique leverage sentence transformer library sentence embeddings english gradient boosting regressor trained distilbert embeddingsachieves competitive result telugu multilingual model coupled hyperparameter tuning yield enhanced performance paper discusses significance semantic relatedness various language highlighting challenge nuance encountered finding contribute understanding semantic textual relatedness across diverse linguistic landscape providing valuable insight future research multilingual natural language processing
automatic summarization typically treated mapping document summary document news article however structured often cover multiple topic aspect reader may interested tackle task aspectbased summarization given document target aspect model generate summary centered around aspect induce latent document structure jointly abstractive summarization objective train model scalable synthetic setup addition improvement summarization topicagnostic baseline demonstrate benefit learnt document structure show model learn accurately segment document aspect b leverage structure produce abstractive extractive aspectbased summary c structure particularly advantageous summarizing long document result transfer synthetic training document natural news article cnndaily mail rcv
among four civilization world longest history chinese civilization inherited never interrupted year important factor chinese nation fine tradition sorting classic recording history word inheriting culture continuous collation indigenous account maintaining spread chinese civilization competition sikuroberta model introduced partofspeech tagging task ancient chinese using zuozhuan data set good prediction result obtained
emotion recognition conversation erc attracted increasing attention natural language processing community previous work commonly first extract semanticview feature via finetuning plms model contextview feature based obtained semanticview feature various graph neural network however difficult fully model interaction utterance simply graph neural network feature semanticview contextview well aligned moreover previous parametric learning paradigm struggle learn pattern tail class given fewer instance end treat pretrained conversation model prior knowledge base elicit correlation utterance probing procedure adopt supervised contrastive learning align semanticview contextview feature two view feature work together complementary manner contributing erc distinct perspective meanwhile propose new semiparametric paradigm inferencing memorization solve recognition problem tail class sample consistently achieve stateoftheart result four widely used benchmark extensive experiment demonstrate effectiveness proposed multiview feature alignment memorization
paper describes work rulebased opensource parser swedish central component widecoverage grammar implemented gf formalism grammatical framework dependently typed grammar formalism based martinlof type theory gf strong support multilinguality far used successfully controlled language recent experiment showed also possible use framework parsing unrestricted language addition gf use two main resource swedish treebank talbanken electronic lexicon saldo combining grammar lexicon extracted saldo obtain parser accepting sentence described given rule develop test example talbanken resulting parser give full syntactic analysis input sentence highly reusable freely available gf provides library compiling grammar number programming language chosen part grammar may used various nlp application
large amount training data possible train asr model generalize well across speaker domain train robust model limited amount available training data experiment reported finetuned pretrained wavvec asr model two transcribed norwegian speech datasets one parliamentary speech one radio recording well combination two datasets subsequently tested model different test set planned unplanned speech speaker various dialect result show model trained combination two datasets generalize better new data singledataset model even length training data lexical analysis shed light type mistake made model importance consistent standardization training combined model kind
succinctly summarizing dialogue task growing interest inherent challenge insufficient training data low information density impede ability train abstractive model work propose novel curriculumbased prompt learning method selftraining address problem specifically prompt learned using curriculum learning strategy gradually increase degree prompt perturbation thereby improving dialogue understanding modeling capability model unlabeled dialogue incorporated mean selftraining reduce dependency labeled data investigate topicaware prompt better plan generation summary experiment confirm model substantially outperforms strong baseline achieves new stateoftheart result ami icsi datasets human evaluation also show superiority model regard summary generation quality
discus learning latent annotation synchronous contextfree grammar scfg purpose improving machine translation show learning annotation nonterminals result accurate translation also faster scfg decoding
article describe participation hateval shared task aimed detection hate speech immigrant woman focused spanish subtasks building previous experience sentiment analysis language trained linear classifier recurrent neural network using classic feature bagofwords bagofcharacters word embeddings also recent technique contextualized word representation particular trained robust taskoriented subwordaware embeddings computed tweet representation using weightedaveraging strategy final evaluation system showed competitive result spanish subtasks esa esb achieving first fourth place respectively
report acl annual meeting panel speech understanding computational linguistics critical examination arpa project stanley r petrick essay lexical semantics vol ii edited v ju rozencvejg ernst von glasersfeld constituent pattern poetry archibald hill james joyce current bibliography
dod already make extensive use machine translation language support tool many environment address variety communication training intelligence challenge done year mr bemish draw personal experience deploying mt well broad exposure translation technology used branch service military intelligence describe current us translation technology across range organization within dod also address technical issue slow deployment cultural challenge involved setting expectation introducing technology change way people work
data augmentation da refers strategy increasing diversity training example without explicitly collecting new data manually used neural network linguistic resource automatic generation text russian system generates new text using information embeddings trained huge amount data neural language model data public domain used experiment generation text increase corpus used train model nlp task machine translation finally analysis result obtained evaluating quality generated text carried text added training process neural machine translation nmt model order evaluate quality nmt model firstly model compared performing quantitative analysis mean several standard automatic metric used machine translation measuring time spent amount text generated good use language industry secondly nmt model compared qualitative analysis generated example translation exposed compared using da method achieve better result baseline model fine tuning nmt system newly generated datasets
sentence containing multiple semantic operator overlapping scope often create ambiguity interpretation known scope ambiguity ambiguity offer rich insight interaction semantic structure world knowledge language processing despite little research modern large language model treat paper investigate different version certain autoregressive language modelsgpt gpt llama gpttreat scope ambiguous sentence compare human judgment introduce novel datasets contain joint total almost unique scopeambiguous sentence containing interaction range semantic operator annotated human judgment using datasets find evidence several model sensitive meaning ambiguity sentence way pattern well human judgment ii successfully identify humanpreferred reading high level accuracy case
large pretrained language model using transformer neural network architecture becoming dominant methodology many natural language processing task question answering text classification word sense disambiguation text completion machine translation commonly comprising hundred million parameter model offer stateoftheart performance expense interpretability attention mechanism main component transformer network present attviz method exploration selfattention transformer network help explanation debugging trained model showing association text token input sequence show existing deep learning pipeline explored attviz offer novel visualization attention head aggregation implemented proposed method online toolkit offline library using example news analysis demonstrate attviz used inspect potentially better understand model learned
narrative comprehension challenging task requires deep understanding foundational element narrative acquiring skill requires extensive annotated data mitigate burden data annotation present parrot zeroshot approach narrative reading comprehension parallel reading involves two parallel narrative tell story leveraging one narrative source supervision signal guide understanding parrot abstract textual content develops genuine narrative understanding evaluation conducted two narrative comprehension benchmark demonstrates parrot surpasses previous zeroshot approach achieves comparable performance fully supervised model code available httpsgithubcomzhaochaocsparrot
develop commonsensegrounded nlp application comprehensive accurate commonsense knowledge graph ckg needed timeconsuming manually construct ckgs many research effort devoted automatic construction ckgs previous approach focus generating concept direct obvious relationship existing concept lack capability generate unobvious concept work aim bridge gap propose general graphtopaths pretraining framework leverage highorder structure ckgs capture highorder relationship concept instantiate general framework four special case long path pathtopath router graphnodepath experiment two datasets demonstrate effectiveness method code released via public github repository
year ago ward birner suggested noncanonical construction english serve mark information status structure information flow discourse one construction preposing phrasal constituent appears left canonical position typically sentenceinitially computational work discourse date ignored noncanonical syntax take account noncanonical syntax providing quantitative evidence relating nppp preposing discourse relation evidence come llm maskfilling task compare prediction mask inserted argument implicit intersentential discourse relation first righthand argument arg start preposed constituent constituent canonical postverbal position result show topranked maskfillers preposed case agree often gold annotation penn discourse treebank latter case preposing arg affect distribution discourserelational sens
rise usergenerated content social medium coupled almost nonexistent moderation many system aggressive content observed rise forum paper work problem aggression detection social medium aggression sometimes expressed directly overtly hidden covert text hand content social medium nonaggressive nature propose ensemble based system classify input post one three class namely overtly aggressive covertly aggressive nonaggressive approach us three deep learning method namely convolutional neural network cnn five layer input convolution pooling hidden output long short term memory network lstm bidirectional long short term memory network bilstm majority voting based ensemble method used combine classifier cnn lstm bilstm trained method facebook comment dataset tested facebook comment indomain social medium post crossdomain system achieves fscore weighted facebook post social medium post
temporal relation annotation clinical domain crucial yet challenging due workload medical expertise required paper propose novel annotation method integrates event startpoints ordering questionanswering qa annotation format focusing two point timeline startpoints ordering reduces ambiguity simplifies relation set considered annotation qa annotation recasts temporal relation annotation reading comprehension task allowing annotator use natural language instead formalism commonly adopted temporal relation annotation based method relation document inferable significantly smaller number explicitly annotated relation showing efficiency proposed method using inferred relation develop temporal relation classification model achieves f score also decomposing annotation process qa generation qa validation method enables collaboration among medical expert nonexperts obtained high interannotator agreement iaa score indicate positive prospect collaboration annotation process annotated corpus annotation tool trained model publicly available httpsgithubcomseijishimizuqastartordering
deciphering historical substitution cipher challenging problem example problem previously studied include detecting cipher type detecting plaintext language acquiring substitution key segmented cipher however attacking unsegmented cipher still challenging task segmentation ie finding substitution unit essential cracking cipher work propose first automatic method segment cipher using byte pair encoding bpe unigram language model method achieve average segmentation error randomlygenerated monoalphabetic cipher real historical homophonic cipher also propose method solving nondeterministic cipher existing key using lattice pretrained language model method lead full solution ia cipher real historical cipher fully solved work
much recent work suggests incorporating syntax information dependency tree improve taskspecific transformer model however effect incorporating dependency tree information pretrained transformer model eg bert remains unclear especially given recent study highlighting model implicitly encode syntax work systematically study utility incorporating dependency tree pretrained transformer three representative information extraction task semantic role labeling srl named entity recognition relation extraction propose investigate two distinct strategy incorporating dependency structure late fusion approach applies graph neural network output transformer joint fusion approach infuses syntax structure transformer attention layer strategy representative prior work introduce additional model design element necessary obtaining improved performance empirical analysis demonstrates syntaxinfused transformer obtain stateoftheart result srl relation extraction task however analysis also reveals critical shortcoming model find performance gain highly contingent availability humanannotated dependency parses raise important question regarding viability syntaxaugmented transformer realworld application
previously reported proposel purposebuilt prosody po english lexicon compatible python natural language toolkit proposec new corpus research resource built using lexicon intended distribution aixmarsec dataset proposec comprises multilevel parallel annotation juxtaposing prosodic syntactic information different version spoken english corpus canonical dictionary form query format optimized perl python text processing program order content field text file follows aixmarsec file number word lob postag c postag aix sampa phonetic transcription sampa phonetic transcription proposel syllable count lexical stress pattern default content function word tag disc stressed syllabified phonetic transcription alternative disc representation incorporating lexical stress pattern nested array phoneme tonic stress mark aix experimental dataset proposec used study correlation annotation tier significant finding expressed additional feature phrasing model integral texttospeech speech recognition training set proposec used machine learning task information retrieval speech understanding system
interactive programming interleaved code snippet cell natural language markdown recently gaining popularity form jupyter notebook accelerate prototyping collaboration study code generation conditioned long context history present juice corpus million example curated test set k instance based online programming assignment compared existing contextual code generation datasets juice provides refined humancurated data opendomain code order magnitude training data using juice train model two task generation api call sequence code cell full code cell generation conditioned nlcode history particular code cell experiment using current baseline code generation model show context distant supervision aid generation dataset challenging current system
increasing prevalence political bias news medium call greater public awareness well robust method detection prior work nlp primarily focused lexical bias captured linguistic attribute word choice syntax type bias stem actual content selected inclusion text work investigate effect informational bias factual content nevertheless deployed sway reader opinion first produce new dataset basil news article annotated bias span find evidence informational bias appears news article frequently lexical bias study annotation observe informational bias surface news article different medium outlet lastly baseline model informational bias prediction presented finetuning bert labeled data indicating challenge task future direction
crisis event people often use social medium platform twitter disseminate information situation warning advice support emergency relief organization leverage information acquire timely crisis circumstance expedite rescue operation existing work utilize information build model crisis event analysis fullysupervised approach require annotating vast amount data impractical due limited response time hand semisupervised model biased performing moderately well certain class performing extremely poorly others resulting substantially negative effect disaster monitoring rescue paper first study two recent debiasing method semisupervised crisis tweet classification propose simple effective debiasing method decrisismb utilizes memory bank store perform equal sampling generated pseudolabels class training iteration extensive experiment conducted compare different debiasing method performance generalization ability indistribution outofdistribution setting result demonstrate superior performance proposed method code available httpsgithubcomhenrypengzoudecrisismb
present domain independent model date document based neologism usage pattern model capture pattern neologism usage time date text provide insight temporal locality word usage span year generalize various domain like news fiction nonfiction competitive performance quite intriguingly show modeling distribution usage count neologism model agnostic particular word achieve competitive performance using several order magnitude fewer feature input feature compared state art model use k feature
machine translation closely related language less challenging exibits smaller number translation error translation distant language still obstacle addressed order improve system work explores obstacle machine translation system closely related south slavic language namely croatian serbian slovenian statistical system language pair translation direction trained using parallel text different domain however mainly spoken language ie subtitle translation serbian croatian rulebased system also explored shown language pair translation system main obstacle difference structural property
neural machine translation nmt model often use subwordlevel vocabulary deal rare unknown word although study shown effectiveness purely characterbased model approach resulted highly expensive model computational term work explore benefit quasicharacterlevel model lowresource language ability mitigate effect catastrophic forgetting problem first conduct empirical study efficacy model function vocabulary training set size range language domain architecture next study ability model mitigate effect catastrophic forgetting machine translation work suggests quasicharacterlevel model practically generalization capability characterbased model lower computational cost furthermore appear help achieve greater consistency domain standard subwordlevel model although catastrophic forgetting problem mitigated
research texttosql conversion largely benchmarked datasets text query corresponds one correct sql however natural language query reallife database frequently involve significant ambiguity intended sql due overlapping schema name multiple confusing relationship path bridge gap develop novel benchmark called ambiqt example text interpretable two plausible sqls due lexical andor structural ambiguity faced ambiguity ideal topk decoder generate valid interpretation possible disambiguation user evaluate several texttosql system decoding algorithm including employing stateoftheart llm find far ideal primary reason prevalent beam search algorithm variant treat sql query string produce unhelpful tokenlevel diversity topk propose logicalbeam new decoding algorithm navigates sql logic space using blend planbased template generation constrained infilling counterfactually generated plan diversify template infilling beamsearch branch solely schema name provides value diversity logicalbeam time effective stateoftheart model generating candidate sqls topk ranked output also enhances top exact execution match accuracy spider kaggle dbqa
demonstrate current stateoftheart approach automated essay scoring aes wellsuited capturing adversarially crafted input grammatical incoherent sequence sentence develop neural model local coherence effectively learn connectedness feature sentence propose framework integrating jointly training local coherence model stateoftheart aes model evaluate approach number baseline experimentally demonstrate effectiveness aes task task flagging adversarial input contributing development approach strengthens validity neural essay scoring model
paper describe concept language model beyond usually used standard trigram use language model statistical machine translation statistical machine translation language model apriori knowledge source system target language one important requirement language model correct word order given certain choice word score translation generated translation model textrmprfjei view syntactic context addition standard mgrams long history examine use partofspeech based model well linguistically motivated grammar stochastic parsing special type language model translation result given verbmobil task translation performed german english vocabulary size word respectively
study target shared task nuanced arabic dialect identification nadi organized workshop arabic natural language processing wanlp focus subtask identification arabic dialect country level specifically study impact traditional approach tfidf move study impact advanced deep learning based method method include fully finetuning marbert well adapter based finetuning marbert without performing data augmentation evaluation show traditional approach based tfidf score best term accuracy testa dataset finetuned marbert adapter augmented data score second macro fscore testb dataset led proposed system ranked second shared task average
audiovisual speech recognition avsr system proven superior audioonly speech recognizers noisy environment incorporating feature visual modality order develop reliable avsr system appropriate simultaneously recorded speech video data needed paper introduce corpus wapusk consists audiovisual data speaker uttering sentence four channel audio stereoscopic video latter intended support accurate lip tracking development stereo data based normalization technique greater robustness recognition result sentence design adopted grid corpus widely used avsr experiment recording made acoustically realistic condition usual office room affordable hardware equipment used precalibrated stereo camera standard pc component software written create corpus designed matlab help hardware specific software provided hardware manufacturer freely available open source software
relation detection core step many natural language process application including knowledge base question answering previous effort show singlefact question could answered high accuracy however one critical problem current approach get high accuracy question whose relation seen training data unseen relation performance drop rapidly main reason problem representation unseen relation missing paper propose simple mapping method named representation adapter learn representation mapping seen unseen relation based previously learned relation embedding employ adversarial objective reconstruction objective improve mapping performance reorganize popular simplequestion dataset reveal evaluate problem detecting unseen relation experiment show method greatly improve performance unseen relation performance seen part kept comparable stateoftheart
traditional evaluation labeled span precision recall fscore undesirable effect due double penalty annotation incorrect label boundary count two error instead one despite closer target annotation false positive false negative paper new error type introduced accurately reflect true annotation quality ensure every annotation count algorithm error identification flat multilevel annotation presented complemented proposal calculate meaningful precision recall fscores based finegrained error type exemplary application three different annotation task ner chunking parsing show suggested procedure prevents double penalty also allows detailed error analysis thereby providing insight actual weakness system
large multilingual pretrained language model mbert xlmroberta found surprisingly effective crosslingual transfer syntactic parsing model wu dredze related language however source training language rarely related parsing truly lowresource language close gap adopt method multitask learning relies automated curriculum learning dynamically optimize parsing performance textitoutlier language show approach significantly better uniform sizeproportional sampling zeroshot setting
paper assumed inconsistency fscores annotator agreement measure discussed exemplified five corpus field argumentation mining high agreement important annotation task also often deemed important annotated dataset useful machine learning however depending annotation task achieving high agreement always easy especially true field argumentation mining argumentation complex well implicit also many different model argumentation seen increasing number argumentation annotated corpus many reach moderate agreement still used machine learning task reaching high fscore paper describe five corpus particular created used see handled disagreement find agreement raised postproduction discussion regarding evaluating calculating agreement needed conclude standardisation model evaluation method could help discussion
temporal knowledge graph tkg sequence kg corresponding different timestamps tkg reasoning aim predict potential fact future given historical kg sequence one key task mine understand evolutional pattern fact sequence evolutional pattern complex two aspect lengthdiversity timevariability existing model tkg reasoning focus modeling fact sequence fixed length discover complex evolutional pattern vary length furthermore model trained offline well adapt change evolutional pattern thus propose new model called complex evolutional network cen us lengthaware convolutional neural network cnn handle evolutional pattern different length via easytodifficult curriculum learning strategy besides propose learn model online setting adapt change evolutional pattern time extensive experiment demonstrate cen obtains substantial performance improvement traditional offline proposed online setting
pretrained transformerbased encoders bert demonstrated achieve stateoftheart performance numerous nlp task despite success bert style encoders large size high latency inference especially cpu machine make unappealing many online application recently introduced compression distillation method provided effective way alleviate shortcoming however focus work mainly monolingual encoders motivated recent success zeroshot crosslingual transfer learning using multilingual pretrained encoders mbert evaluate effectiveness knowledge distillation kd pretraining stage finetuning stage multilingual bert model demonstrate contradiction previous observation case monolingual distillation multilingual setting distillation pretraining effective distillation finetuning zeroshot transfer learning moreover observe distillation finetuning may hurt zeroshot crosslingual performance finally demonstrate distilling larger model bert large result strongest distilled model performs best source language well target language zeroshot setting
largescale pretrained language model led significant improvement natural language processing unfortunately come cost high computational storage requirement complicate deployment lowresource device issue addressed distilling knowledge larger model smaller one pseudolabels taskspecific datasets however difficult task limited data overcome challenge present novel approach knowledge distilled teacher model student model generation synthetic data done first finetune teacher student model well natural language generation nlg model target task dataset let student teacher work together condition nlg model generate example enhance performance student tested approach two data generation method targeted generation using monte carlo tree search mcts algorithm b nontargeted text generation nttg method evaluate effectiveness approach baseline us bert model data augmentation random word replacement testing approach sst mrpc yelp dbpedia trec datasets consistently witnessed considerable improvement wordreplacement baseline
generating text scientific paper requires capturing content contained within given input also frequently acquiring external information called context push forward scientific text generation proposing new task namely contextaware text generation scientific domain aiming exploiting contribution context generated text end present novel challenging largescale scientific paper dataset contextaware text generation scixgen consisting wellannotated paper full reference widelyused object eg table figure algorithm paper comprehensively benchmark using stateofthearts efficacy newly constructed scixgen dataset generating description paragraph dataset benchmark made publicly available hopefully facilitate scientific text generation research
paper describes uwaterloo affect prediction system developed emoint delve feature selection approach affect intensity affect presence sentiment intensity sentiment presence lexica alongside pretrained word embeddings utilized extract emotion intensity signal tweet ensemble learning approach system employ emotion specific model training utilizes distinct model emotion corpus isolation system utilizes gradient boosted regression primary learning technique predict final emotion intensity
cyberbullying serious societal issue widespread various channel platform particularly social networking site platform proven exceptionally fertile ground behavior dearth highquality training data multilingual lowresource scenario data accurately capture nuance social medium conversation often pose roadblock task paper attempt tackle cyberbullying specifically two common manifestation aggression offensiveness present novel manually annotated dataset total english hindienglish codemixed tweet manually annotated aggression detection offensive language detection task annotation supported interannotator agreement score two task indicating substantial agreement perform comprehensive finetuning pretrained language model ptlms using dataset check efficacy challenging test set show best model achieve macro fscores two task respectively perform crossdataset transfer learning benchmark dataset existing aggression offensive language datasets also present detailed quantitative qualitative analysis error prediction paper publicly release novel dataset code model
currently deep learning model widely adopted achieved promising result various application domain despite intriguing performance deep learning model function black box lacking explicit reasoning capability explanation usually essential complex problem take joint inference information extraction example task requires identification multiple structured knowledge text intercorrelated including entity event relationship various deep neural network proposed jointly perform entity extraction relation prediction propagate information implicitly via representation learning however fail encode intensive correlation entity type relation enforce coexistence hand approach adopt rule explicitly constrain certain relational fact although separation rule representation learning usually restrains approach error propagation moreover predefined rule inflexible might result negative effect data noisy address limitation propose variational deep logic network incorporates representation learning relational reasoning via variational em algorithm model consists deep neural network learn highlevel feature implicit interaction via selfattention mechanism relational logic network explicitly exploit target interaction two component trained interactively bring best world conduct extensive experiment ranging finegrained sentiment term extraction endtoend relation prediction endtoend event extraction demonstrate effectiveness proposed method
describe secondplace submission shared task organized fourth workshop language technology equality diversity inclusion ltedi task focus detecting castemigration hate speech tamil included text involve tamil language tamil script transliterated latin script text also english considering different script examined performance transformer language model dev set analysis revealed whole dataset model googlemurillargecased performs best used ensemble several model final challenge submission achieving test dataset
introduce novel translation rule capture discontinuous partial constituent nonprojective phrase source language using traversal order sequence dependency tree proposed method extract synchronous rule linear time combine efficiently using cyk chart parsing algorithm analytically show effectiveness translation rule translating relatively free order sentence empirically investigate coverage proposed method
analyzing online persuasion one important goal semantically understand people construct comment persuade others however analyzing semantic role argument online persuasion less emphasized therefore study propose novel annotation scheme capture semantic role argument popular online persuasion forum socalled changemyview study made following contribution proposing scheme includes five type elementary unit eu two type relation ii annotating changemyview result eu relation post iii analyzing semantic role persuasive argument analysis captured certain characteristic phenomenon online persuasion
paper present corpus interaction older younger user nine different dialogue system corpus fully transcribed annotated dialogue act information state update isu representation dialogue context user underwent comprehensive battery cognitive assessment also rated usability dialogue system standardised questionnaire paper discus corpus collection outline semiautomatic method used discourselevel annotation expect corpus provide key resource modelling older people interaction spoken dialogue system
machinetranslated text play crucial role communication people using different language however adversary use text malicious purpose plagiarism fake review existing method detected machinetranslated text using text intrinsic content unsuitable classifying machinetranslated humanwritten text meaning proposed method extract feature used distinguish machinehuman text based similarity intrinsic text backtranslation evaluation detecting translated sentence french show method achieves accuracy fscore outperforms existing method whose best accuracy fscore proposed method even detects efficiently backtranslated text accuracy higher best previous accuracy also achieve similar result fscore also similar experiment related japanese moreover prove detector recognize machinetranslated machinebacktranslated text without language information used generate machine text demonstrates persistence method various application low richresource language
active learning shown reduce annotation requirement numerous natural language processing task including semantic role labeling srl srl involves labeling argument span potentially multiple predicate sentence make challenging aggregate numerous decision single score determining new instance annotate paper apply two way aggregating score across multiple predicate order choose query sentence two method estimating model certainty using neural network output using dropoutbased bayesian active learning disagreement compare method three passive baseline random sentence selection random wholedocument selection selecting sentence predicate analyse effect strategy learning curve respect reducing number annotated sentence predicate achieve high performance
recently prompt tuning achieved promising result variety natural language processing nlp task typical approach insert text piece ie template input transform downstream task form pretraining essence highquality template foundation prompt tuning support performance converted clozestyle task however sarcasm recognition timeconsuming requires increasingly sophisticated domain knowledge determine appropriate template label word due highly figurative nature work propose sarcprompt incorporate prior knowledge contradictory intention prompt tuning sarcasm recognition sarcprompt inspired speaker usually say opposite actually mean sarcastic text based idea explicitly mimic actual intention prompt construction indicate whether actual intention contradictory literal content verbalizer engineering experiment three public datasets standard lowresource setting demonstrate effectiveness sarcprompt sarcasm recognition
human unique ability infer information participant scene even mentioned text scene computer system without explicit information participant paper address linguistic phenomenon nullinstantiated frame element ie implicit semantic role representation framenet fn motivates fns annotation practice illustrates three type nullinstantiated argument framenet track noting lexical resource record semanticpragmatic information despite need natural language understanding nlu elaborate effort create new datasets challenge community appeal fn data develop sophisticated technique recognizing implicit semantic role creating needed datasets although annotation nullinstantiated role lexicographically motivated fn provides useful information text processing therefore must considered design meaning representation natural language understanding
paper describes participation smmh shared task designed rulebased classifier estimate whether tweet mention adverse effect associated medication system address english french based number specific word list feature cue mostly obtained extensive corpus analysis provided training data different weighting scheme tested manually tuned based logistic regression best one achieving f score english french
recent advance large language model llm llmdriven chatbots chatgpt sparked interest extent artificial system possess humanlike linguistic ability study assessed chatgpts pragmatic capability conducting three preregistered experiment focused ability compute pragmatic implicatures first experiment tested whether chatgpt inhibits computation generalized conversational implicatures gcis explicitly required process text truthconditional meaning second third experiment examined whether communicative context affect chatgpts ability compute scalar implicatures si result showed chatgpt demonstrate humanlike flexibility switching pragmatic semantic processing additionally chatgpts judgment exhibit wellestablished effect communicative context si rate
introduce sharcs adaptive inference take account hardness input sample sharcs train router transformer network enabling model direct different sample subnetworks varying width experiment demonstrate sharcs outperforms complement existing persample adaptive inference method across various classification task term accuracy v flop sharcs generalizes across different architecture even applied compressed efficient transformer encoders improve efficiency sharcs provide time inference speed insignificant drop accuracy
paper focus modeling spatial expression text present guideline used annotate pst corpus polish spatial text corpus designed training testing tool spatial expression recognition corpus contains set text gathered text collected travel blog available creative common license defined guideline based three existing specification english spatialml spatialrole labelling semeval task isospace spaceeval briefly present existing specification discus modification made adapt guideline characteristic polish language also describe process data collection manual annotation including interannotator agreement calculation corpus statistic end present detailed statistic pst corpus include number component relation expression common value spatial indicator motion indicator path indicator distance direction region
work explores application textual entailment news claim verification stance prediction using new corpus arabic publicly available corpus come two perspective version consisting true false claim version consisting pair claim evidence describe methodology creating corpus annotation process using introduced corpus also develop two machine learning baseline two proposed task claim verification stance prediction best model utilizes pretraining bert achieves f stance prediction task f claim verification task preliminary experiment shed light limit automatic claim verification relies claim text result hint linguistic feature world knowledge learned pretraining useful stance prediction learned representation pretraining insufficient verifying claim without access context evidence
previous dialogue summarization technique adapt large language model pretrained narrative text injecting dialoguespecific feature model feature either require additional knowledge recognize make resulting model harder tune bridge format gap dialogue narrative summary dialogue summarization task propose posttrain pretrained language model plms rephrase dialogue narrative model finetuned dialogue summarization usual comprehensive experiment show approach significantly improves vanilla plms dialogue summarization outperforms sota model summary quality implementation cost
present approach learning modeltheoretic semantics natural language tied freebase crucially approach us open predicate vocabulary enabling produce denotation phrase republican frontrunner texas whose semantics represented using freebase schema approach directly convert sentence syntactic ccg parse logical form containing predicate derived word sentence assigning word consistent semantics across sentence logical form evaluated learned probabilistic database defines distribution denotation textual predicate training phase produce probabilistic database using corpus entitylinked text probabilistic matrix factorization novel ranking objective function evaluate approach compositional question answering task outperforms several competitive baseline also compare approach manually annotated freebase query finding open predicate vocabulary enables u answer many question freebase
figurative language commonplace natural language making communication memorable creative difficult understand work investigate robustness question answering qa model figurative text yesno question particular useful probe figurative language understanding capability large language model propose figurativeqa set yesno question figurative nonfigurative context extracted domain restaurant product review show stateoftheart bertbased qa model exhibit average performance drop point answering question figurative context compared nonfigurative one model like gpt chatgpt better handling figurative text show performance gain achieved automatically simplifying figurative context nonfigurative literal counterpart find best overall model chatgpt chainofthought prompting generate nonfigurative context work provides promising direction building robust qa model figurative language understanding capability
present gold standard evaluation cross language information retrieval system domain organic agriculture agroecology presented resource free use research purpose includes collection multilingual document annotated respect domain ontology ontology used annotating resource set query language gold standard correct resource proposed query goal work consists contributing research community resource evaluating multilingual retrieval algorithm particular focus domain adaptation strategy general purpose multilingual information retrieval system effective exploitation semantic annotation domain adaptation fact important activity tuning retrieval system reducing ambiguity improving precision information retrieval domain ontology constitute diffuse practice defining conceptual space corpus mapping resource specific topic lab propose well investigate evaluate impact information enhancing retrieval content initial experiment described giving baseline research proposed gold standard
dialog system widely deployed computerassisted language learning call formative assessment system recent year relatively limited work done respect psychometrics validity technology evaluating providing feedback regarding student learning conversational ability paper formulates markov decision process based measurement model applies text chat data collected crowdsourced native nonnative english language speaker interacting automated dialog agent investigate well model measure speaker conversational ability find effectively capture difference native nonnative speaker english accomplish dialog task model could important implication call system future effectively combine dialog management measurement learner conversational ability realtime
social political researcher require robust event datasets conduct datadriven analysis example need trigger event datasets analyze condition pattern certain triggertype event increase probability mass killing fortunately nlp ml leveraged create robust datasets paper outline robust ml framework prioritizes understandability visualization generalizability ability implement different ml algorithm ii perform comparative analysis ml tool within framework coup trigger iii leverage ml framework along unique combination nlp tool ner knowledge graph produce dataset assassination trigger iv make comprehensive consolidated cohesive assassination dataset publicly available provide temporal data understanding political violence well training data sociopolitical research
subword segmentation currently standard tool training neural machine translation mt system nlp task goal split word source target language smaller unit constitute input output vocabulary mt system aim reducing size input output vocabulary increase generalization capability translation model enabling system translate generate infrequent new unseen word inference time combining previously seen subword unit ideally would expect created unit linguistic meaning word created compositional way however popular wordsplitting method bytepair encoding bpe originates data compression literature include explicit criterion favor linguistic splittings find optimal subword granularity given training data paper propose statistically motivated extension bpe algorithm effective convergence criterion avoids costly experimentation cycle needed select best subword vocabulary size experimental result morphologically rich language show model achieves nearlyoptimal bleu score produce morphologically better word segmentation allows outperform bpes generalization translation sentence containing new word shown via human evaluation
propose use image caption web previously underutilized resource paraphrase ie text message create analyze corresponding dataset image reused web original caption often assigned hypothesize different caption image naturally form set mutual paraphrase demonstrate suitability idea analyze caption english wikipedia editor frequently relabel image different article paper introduces underlying mining technology resulting wikipediaipc dataset compare known paraphrase corpus respect syntactic semantic paraphrase similarity new resource context introduce characteristic map along two similarity dimension identify style paraphrase coming different source annotation study demonstrates high reliability algorithmically determined characteristic map
paper report development collocation extraction system designed within commercial machine translation system order take advantage robust syntactic analysis system offer use analysis refine collocation extraction embedding extraction system also address need provide information source language collocation systemspecific form support automatic generation collocation rulebase analysis translation
paper present quantitative description laughter height hour french spontaneous conversation paper includes raw figure laughter well detail concerning interindividual variability firstly describes extent amount laughter duration varies speaker speaker dialog second suite analysis paper compare corpus previous analyzed corpus final set experiment present fact overlapping laugh paper quantified effect freestyle conversation first time
multilingual contextual embeddings demonstrated stateoftheart performance zeroshot crosslingual transfer learning multilingual bert finetuned one source language evaluated different target language however published result mbert zeroshot accuracy vary much point mldoc classification task across four paper show standard practice using english dev accuracy model selection zeroshot setting make difficult obtain reproducible result mldoc xnli task english dev accuracy often uncorrelated even anticorrelated target language accuracy zeroshot performance varies greatly different point finetuning run different finetuning run reproducibility issue also present task different pretrained embeddings eg mlqa xlmr recommend providing oracle score alongside zeroshot result still finetune using english data choose checkpoint target dev set reporting upper bound make result consistent avoiding arbitrarily bad checkpoint
translatetrain general training approach multilingual task key idea use translator target language generate training data mitigate gap source target language however performance often hampered artifact translated text translationese discover artifact common pattern different language modeled deep learning subsequently propose approach conduct translatetrain using translationese embracing effect artifact tea tea learns mitigate effect training data source language whose original translationese available applies learned module facilitate inference target language extensive experiment multilingual qa dataset tydiqa demonstrate tea outperforms strong baseline
work progress extracting sentence tree structure encoders selfattention weight translating another language using transformer neural network architecture visualize structure discus characteristic respect existing syntactic theory annotation
bert neural networkbased language model pretrained large corpus breakthrough natural language processing significantly outperforming previous stateoftheart model numerous task however report application implicit discourse relation classification clear bert best adapted task paper test three method adaptation perform additional pretraining text tailored discourse classification expectation knowledge transfer explicit discourse relation implicit discourse relation add task named explicit connective prediction additional pretraining step exploit implicit connective given treebank annotator add task named implicit connective prediction finetuning step demonstrate three technique combined straightforwardly single training pipeline comprehensive experiment found first second technique provide additional gain last one
introduce benchmark linguistic minimal pair blimp challenge set evaluating linguistic knowledge language model lm major grammatical phenomenon english blimp consists individual datasets containing minimal pairsthat pair minimally different sentence contrast grammatical acceptability isolate specific phenomenon syntax morphology semantics generate data according linguistcrafted grammar template human aggregate agreement label evaluate ngram lstm transformer gpt transformerxl lm observing whether assign higher probability acceptable sentence minimal pair find stateoftheart model identify morphological contrast related agreement reliably struggle subtle semantic syntactic phenomenon negative polarity item extraction island
south north korea use korean language however korean nlp research focused south korean existing nlp system korean language neural machine translation nmt model properly handle north korean input training model using north korean data straightforward approach solving problem insufficient data train nmt model study create data north korean nmt model using comparable corpus first manually create evaluation data automatic alignment machine translation investigate automatic alignment method suitable north korean finally show model trained north korean bilingual data without human annotation significantly boost north korean translation accuracy compared existing south korean model zeroshot setting
social scientist recently turned analyzing text using tool natural language processing like word embeddings measure concept like ideology bias affinity however word embeddings difficult use regression framework familiar social scientist embeddings neither identified directly interpretable offer two advance standard embedding model remedy problem first develop bayesian word embeddings automatic relevance determination prior relaxing assumption embedding dimension equal weight second apply work identifying latent variable model anchor embeddings identifying making interpretable usable regression apply model anchoring approach two case shift internationalist rhetoric american president inaugural address relationship bellicosity american foreign policy decisionmakers deliberation find inaugural address became less internationalist go conventional wisdom increase bellicosity associated increase hostile action united state showing elite deliberation cheap talk helping confirm validity model
paper describes data collection setup newly recorded dataset main purpose dataset explore pattern focus visual attention human three different condition two human involved taskbased interaction robot two human involved taskbased interaction robot replaced third human free threeparty human interaction dataset contains two part session duration approximately hour session duration approximately hour part dataset rich modality recorded data stream include stream three kinect v device color depth infrared body face data three high quality audio stream three high resolution gopro video stream touch data taskbased interaction system state robot addition second part dataset introduces data stream three tobii pro glass eye tracker language interaction english data stream spatially temporally aligned
every day individual post suicide note social medium asking support resource reason live post receive comment others receive many prior study analyzed whether specific response less helpful clear quantity comment received beneficial reducing symptom keeping user engaged platform hence life present study create large dataset user first rsuicidewatch sw post reddit n collect comment well user subsequent post n determine whether post sw future use propensity score stratification causal inference method observational data estimate whether amount comment measure social support increase decrease likelihood posting sw one hypothesis receiving comment may textitdecrease likelihood user posting sw future either reducing symptom comment untrained peer may harmful contrary find receiving comment textitincreases likelihood user post sw discus receiving comment helpful permanently relieving symptom since user make another sw post second post similar mention suicidal ideation rather reinforcing user seek support remain engaged platform furthermore since receiving comment common case decrease likelihood posting average depending time window important develop system encourage commenting
paper describes attempt reproduce earlier experiment previously conducted author compare hedged nonhedged nlg text part reprogen shared challenge reproduction effort able partially replicate result original study analyisis reproduction effort suggests whilst possible replicate procedural aspect previous study replicating result prove challenging difference participant type potential impact
propose new word representation method derived visual object associated image tackle lexical entailment task although shown textitdistributional informativeness hypothesis dih hold text dih assumes context surrounding hyponym informative hypernym never tested visual object since perception tightly associated language meaningful explore whether dih hold visual object end consider visual object context word represent word bag visual object found image associated word allows u test feasibility visual dih better distinguish word pair hypernym relation relation cohypernyms also propose new measurable function take account difference generality meaning similarity meaning word experimental result show dih hold visual object proposed method combined proposed function outperforms existing unsupervised representation method
paper discusses thai corpus talapi fully annotated word segmentation w partofspeech po named entity ne information aim provide highquality sufficiently large corpus reallife implementation thai language processing tool corpus contains article word entertainment lifestyle nel domain article word news news domain total po tag named entity category particular present approach segment tag foreign loan word expressed transliterated original form thai text corpus see area study adapted unadapted foreign language sequence well addressed literature pose challenge annotation process due increasing use adoption foreign word thai language nowadays reduce ambiguity po tagging provide rich information facilitating thai syntactic analysis adapted po tag used orchid propose framework tag thai text also address tagging loan foreign word based proposed segmentation strategy talapi also includes detailed guideline tagging named entity category
dialectal arabic da refers daytoday vernacular spoken arab world da life sidebyside official language modern standard arabic msa da differs msa level linguistic representation phonology morphology lexicon syntax unlike msa da standard orthography since arabic dialect academy large edited body dialectal literature follows spelling standard paper present coda conventional orthography dialectal arabic designed primarily purpose developing computational model arabic dialect explain design principle coda provide detailed description guideline applied egyptian arabic
recent work shown contextualized word representation derived neural machine translation viable alternative simple word prediction task internal understanding need built order able translate one language another much comprehensive unfortunately computational memory limitation present prevent nmt model using large word vocabulary thus alternative subword unit bpe morphological segmentation character used study impact using different kind unit quality resulting representation used model morphology syntax semantics found representation derived subwords slightly better modeling syntax characterbased representation superior modeling morphology also robust noisy input
versatility large language model llm natural language understanding task made popular research social science properly understand property innate persona llm researcher performed study involve using prompt form question ask llm particular opinion study take cautionary step back examine whether current format prompting llm elicits response consistent robust manner first construct dataset contains question encompassing different instrument persona measurement persona ax additionally design set prompt containing minor variation examine llm capability generate answer well prompt variation examine consistency respect contentlevel variation switching order response option negating statement experiment different llm reveal even simple perturbation significantly downgrade model questionanswering ability llm low negation consistency result suggest currently widespread practice prompting insufficient accurately reliably capture model perception therefore discus potential alternative improve issue
pretraining masked language model mlms consumes massive computation achieve good result downstream nlp task resulting large carbon footprint vanilla mlm virtual token mask act placeholder gather contextualized information unmasked token restore corrupted information raise question whether append mask later layer reduce sequence length earlier layer make pretraining efficient show mask indeed appended later layer disentangled word embedding gathering contextualized information unmasked token conducted layer increasing masking rate pretrain robertabase robertalarge scratch original computational budget without degradation glue benchmark pretraining original budget method outperforms roberta glue task average
indic nlp made rapid advance recently term availability corpus pretrained model benchmark datasets standard nlu task limited end introduce indicxnli nli dataset indic language created highquality machine translation original english xnli dataset analysis attests quality indicxnli finetuning different pretrained lm indicxnli analyze various crosslingual transfer technique respect impact choice language model language multilinguality mixlanguage input etc experiment provide u useful insight behaviour pretrained model diverse set language
paper investigates clauselevel sentiment detection multilingual scenario aiming highprecision finegrained configurable nonbiased system practical use case designed pipeline method make syntactic structure based universal dependency avoiding machinelearning approach may cause obstacle purpose achieved high precision sentiment detection language identified advantage common syntactic structure well issue stemming structural difference universal dependency addition reusable tip handling multilingual syntax provide parallel benchmarking data set research
position paper arguing purely graphical representation natural language semantics lack fundamental degree expressiveness deal even basic boolean operation like negation disjunction moving graph named graph lead representation stand chance sufficient expressive power named mathcalfl graph particular interest
multitree nfsfunded project collecting scholarly hypothesis language relationship visualizing web site form tree graph two open online interface allow scholar student general public easy access search language information comparison competing hypothesis one objective project facilitate research historical linguistics multitree evolved much powerful tool simple repository scholarly information paper present multitree interface impact project beyond field historical linguistics including among others use standardized iso language code creating interconnected database language dialect name code publication author offer dissemination linguistic finding worldwide scholar general public thus boosting collaboration accelerating scientific exchange discus also way multitree develop beyond time duration funding
paper present new taskoriented meaning representation called metasemantics designed detect patient early symptom alzheimers disease analyzing language beyond syntactic semantic level metasemantic representation consists three part entity predicate argument structure discourse attribute derive rich knowledge graph study control patient mild cognitive impairment mci selected metasemantic representation annotated speech transcribed text interannotator agreement score achieved three type annotation respectively five analysis made using annotation depicting clear distinction control mci group finally neural model trained feature extracted analysis classify mci patient normal control showing high accuracy promising
large language model llm shown remarkable capability creating fluent response wide variety user query however also come concern regarding spread misinformation potential misuse within educational context paper describe contribution semeval task wang et al shared task created around detecting machinegenerated text aim create several featurebased model detect whether text machinegenerated humanwritten end obtained accuracy binary humanwritten v machinegenerated text classification task subtask monolingual accuracy multiway machinegenerated textclassification task subtask b future work feature model could implemented
wide range control perspective explored controllable text generation structurecontrolled summarization recently proposed useful interesting research direction however current structurecontrolling method limited effectiveness enforcing desired structure address limitation propose sentencelevel beam search generation method sentbs evaluation conducted throughout generation process select suitable sentence subsequent generation experiment different combination decoding method used subcomponents sentbs evaluate result structurecontrolled dataset mred experiment show explored combination sentbs improve agreement generated text desired structure best method significantly reducing structural discrepancy suffered existing model approximately
describe varide system standing variant identification participated edition parseme shared task automatic identification verbal multiword expression vmwes system focus task vmwe variant identification using morphosyntactic information training data predict candidate extracted test corpus could idiomatic thanks naive bayes classifier report result language
although meaning core human cognition stateoftheart distributional semantic model dsms often agnostic finding area semantic cognition work present novel type dsms motivated dualprocessing cognitive perspective triggered lexicosemantic activation shortterm human memory proposed model shown perform better stateoftheart model computing semantic similarity word fusion different type dsms also investigated achieving result comparable better stateoftheart used corpus along set tool well large repository vectorial word representation made publicly available four language english german italian greek
human use language accomplish wide variety task asking giving advice one online advice forum advice mixed nonadvice like emotional support sometimes stated explicitly sometimes implicitly understanding language advice would equip system better grasp language pragmatic practically ability identify advice would drastically increase efficiency adviceseeking online well advicegiving natural language generation system present dataset english two reddit advice forum raskparents rneedadvice annotated whether sentence post contain advice analysis reveals rich linguistic phenomenon advice discourse present preliminary model showing pretrained language model able capture advice better rulebased system advice identification challenging identify direction future research
paper present approach extract cooccurrence network literary text deliberate decision aim fully automatic pipeline literary research question need guide definition nature thing cooccur well decide cooccurrence showcase approach middle high german romance textitparzival manual inspection discussion show huge impact various choice
goal database question answering enable natural language querying reallife relational database diverse application domain recently largescale datasets spider wikisql facilitated novel modeling technique texttosql parsing improving zeroshot generalization unseen database work examine challenge still prevent technique practical deployment first present kaggledbqa new crossdomain evaluation dataset real web database domainspecific data type original formatting unrestricted question second reexamine choice evaluation task texttosql parser applied reallife setting finally augment indomain evaluation task database documentation naturally occurring source implicit domain knowledge show kaggledbqa present challenge stateoftheart zeroshot parser realistic evaluation setting creative use associated database documentation boost accuracy doubling performance
parallel meaning bank corpus translation annotated shared formal meaning representation comprising million word divided four language english german italian dutch approach based crosslingual projection automatically produced manually corrected semantic annotation english sentence mapped onto wordaligned translation assuming translation meaningpreserving semantic annotation consists five main step segmentation text sentence lexical item ii syntactic parsing combinatory categorial grammar iii universal semantic tagging iv symbolization v compositional semantic analysis based discourse representation theory step performed using statistical model trained semisupervised manner employed annotation model languageneutral first result promising
participated wmt general mt task focus four high resource language pair english chinese chinese english english japanese japanese english submitted system languagex focus data cleaning data selection data mixing tmaugmented nmt rule multilingual language model used data filtering data selection automatic evaluation best submitted english chinese system achieved bleu score comet score highest among submission
paper describes statistical machine translation system developed rwth aachen university germanenglish englishturkish chineseenglish translation task emnlp third conference machine translation wmt use ensemble neural machine translation system based transformer architecture main focus germanenglish task automatic scored first respect metric provided organizer identify data selection finetuning batch size model dimension important hyperparameters total improve bleu last year submission bleu winning system germanenglish task englishturkish task show bleu improvement last year winning system report result chineseenglish task improve bleu average baseline system stay behind winning system
recent work blackbox adversarial attack nlp system attracted attention prior blackbox attack assume attacker observe output label target model based selected input work inspired adversarial transferability propose new type blackbox nlp adversarial attack attacker choose similar domain transfer adversarial example target domain cause poor performance target model based domain adaptation theory propose defensive strategy called learnweight train predict weight adjustment target model order defense attack similardomain adversarial example using amazon multidomain sentiment classification dataset empirically show learnweight model effective attack compared standard blackbox defense method adversarial training defense distillation work contributes growing literature machine learning safety
social medium platform like twitter instagram face surge cyberbullying phenomenon young user need develop scalable computational method limit negative consequence kind abuse despite number approach recently proposed natural language processing nlp research area detecting different form abusive language issue identifying cyberbullying phenomenon scale still unsolved problem need couple abusive language detection textual message network analysis repeated attack person identified paper present system monitor cyberbullying phenomenon combining message classification social network analysis evaluate classification module data set built instagram message describe cyberbullying monitoring user interface
describe enron people assignment epa dataset task described email associated person responsible carrying task identify task responsible people enron email dataset define evaluation method challenge report score model naive baseline resulting model enables user experience operating within commercial email service given person task determines person notified task
neuropsychological examination important screening tool presence cognitive condition eg alzheimers parkinson disease require trained tester conduct exam spoken interaction subject audio relatively easy record remains challenge automatically diarize spoke decode say assess subject cognitive health paper demonstrates method determine cognitive health impaired subject audio diarized using automatic speech recognition system trained ted talk structured language used tester subject using leaveoneout cross validation logistic regression modeling show even noisily decoded data wer still perform accurate enough diarization confusion rate determine cognitive state subject auc
nonextractive commonsense qa remains challenging ai task requires system reason synthesize gather disparate piece information order generate response query recent approach task show increased performance model either pretrained additional information domainspecific heuristic used without special consideration regarding knowledge resource type paper perform survey recent commonsense qa method provide systematic analysis popular knowledge resource knowledgeintegration method across benchmark multiple commonsense datasets result analysis show attentionbased injection seems preferable choice knowledge integration degree domain overlap knowledge base datasets play crucial role determining model success
due success pretrained language model version language english released recent year fact implies need resource evaluate model case spanish way systematically assess model quality paper narrow gap building two evaluation benchmark inspired previous work conneau kiela chen et al introduce spanish senteval spanish discoeval aiming assess capability standalone discourseaware sentence representation respectively benchmark include considerable preexisting newly constructed datasets address different task various domain addition evaluate analyze recent pretrained spanish language model exhibit capability limitation example discover case discourse evaluation task mbert language model trained multiple language usually provides richer latent representation model trained document spanish hope contribution motivate fairer comparable less cumbersome way evaluate future spanish language model
paper investigate processing socalled lexicalized grammar lexicalized grammar schabes abeille joshi elementary structure systema tically associated lexical head structure specify extended domain locality compared cfgs constraint stated grammar consists lexicon lexical item associated finite number structure item head separate grammar rule course rule tell u structure combined general twopass parsing strategy lexicalized grammar follows naturally first stage parser selects set elementary structure associated lexical item input sentence second stage sentence parsed respect set evaluate strategy respect two characteristic first amount filtering entire grammar evaluated first pas performed parser us subset grammar second evaluate use nonlocal information structure selected first pas encode morphological value therefore position string head enables parser use nonlocal form ation guide search take lexicalized tree adjoining grammar stance lexicalized grammar illustrate organization grammar show general earleytype tag parser schabes joshi take advantage lexicalization empirical data show filtering grammar nonlocal formation provided twopass strategy improve performance parser explain constraint elementary structure expressed unification equation parsed simple extension earleytype tag parser lexicalization guarantee termination algorithm without special device restrictors
automatic identification offensive language hate speech important keep discussion civil online community identifying hate speech multimodal content particularly challenging task offensiveness manifested either word image juxtaposition two paper present masonperplexity submission shared task multimodal hate speech event detection case eacl task divided two subtasks subtask focus identification hate speech subtask b focus identification target textembedded image political event use xlmrobertalarge model subtask ensemble approach combining xlmrobertabase bertweetlarge bertbase subtask b approach obtained fscore subtask fscore subtask b ranking rd subtasks
study performance machine learning technique problem identifying speaker meeting anonymous minute issued afterwards data come board meeting sverige riksbank sweden central bank data split two way one reported contribution discussion treated data point another contribution single speaker aggregated using interpretable model find lexical feature topic model generated speech held board member outside board meeting good predictor speaker identity combining topic model feature give prediction accuracy close aggregated data though still sizeable gap performance compared easily interpreted bertbased transformer model offer benchmark
system syntactically parsing sentence long recognized priority natural language processing statisticsbased system require large amount high quality syntactically parsed data using xle toolkit developed parc lfg parsebanker interface developed bergen parsebank project powerset generated rapidly increasing volume syntactically parsed data using tool able leverage lfg framework provide richer analysis via constituent c functional f structure additionally parsebanking project us source data wikipedia rather source data limited specific genre wall street journal paper outline process used creating largescale lfgbased parsebank address many shortcoming previouslycreated parse bank penn treebank parsebank corpus still progress preliminary result using data variety context already show promise
recent model developing summarization system consist million parameter model performance highly dependent abundance training data existing summarization corpus contain data order thousand one million generation largescale summarization datasets order couple million yet explored practically data better generalizing training pattern unseen data paper introduce tldr largescale summarization dataset containing million training instance extracted reddit discussion forum http dataset specifically gathered perform textitextreme summarization ie generating onesentence summary high compression abstraction twice larger previously proposed dataset go one step help human annotation distill finegrained dataset sampling highquality instance tldr call tldrhq dataset pinpoint different stateoftheart summarization model proposed datasets
study address challenge detecting fake news dravidian language leveraging google muril multilingual representation indian language model drawing upon previous research investigate intricacy involved identifying fake news explore potential transformerbased model linguistic analysis contextual understanding supervised learning finetune murilbasecased variant muril using carefully curated dataset labeled comment post dravidian language enabling model discern original fake news inference phase finetuned muril model analyzes new textual content extracting contextual semantic feature predict content classification evaluate model performance using standard metric highlighting effectiveness muril detecting fake news dravidian language contributing establishment safer digital ecosystem keywords fake news detection dravidian language muril transformerbased model linguistic analysis contextual understanding
paper propose use set simple uniform architecture lstmbased model recover different kind temporal relation text using shortest dependency path entity input architecture used extract intrasentence crosssentence document creation time relation doublechecking technique revers entity pair classification boosting recall positive case reducing misclassifications opposite class efficient pruning algorithm resolve conflict globally evaluated qatempeval semeval task proposed technique outperforms stateoftheart method large margin also conduct intrinsic evaluation post stateoftheart result timebankdense
classifying citation according purpose importance challenging task gained considerable interest recent year interest primarily driven need create transparent efficient meritbased reward system academia system go beyond simple bibliometric measure considers semantics citation system quantify classify influence citation act edge link knowledge node graph enable efficient knowledge discovery number researcher experimented variety model experiment typically limited singledomain application resulting model hardly comparable recently two citation context classification c shared task wosp sdp created first benchmark enabling direct comparison citation classification approach revealing crucial impact supplementary data performance model reflecting finding shared task releasing new multidisciplinary dataset act extended sdp c shared task dataset modified corpus annotation citation function importance class newly enriched supplementary contextual noncontextual feature set selection follows list feature used successful team shared task additionally include contextual feature cited paper eg abstract cited paper existing datasets lack lot potential improve result describe methodology used feature extraction challenge involved process feature enriched act dataset available urlhttpsgithubcomoacoreact
accurate detection appropriate handling disruptive talk multiparty dialogue essential user achieve shared goal collaborative gamebased learning environment detecting attending disruptive talk hold significant potential since cause distraction produce negative learning experience student present novel attentionbased useraware neural architecture disruptive talk detection us sequence dropoutbased regularization mechanism disruptive talk detection model evaluated multiparty dialogue collected middle school student interacted collaborative gamebased learning environment proposed disruptive talk detection model significantly outperforms competitive baseline approach show significant potential helping support effective collaborative learning experience
nlp model become increasingly capable understanding document term coherent entity rather string obtaining salient entity document important end task also vital information retrieval ir downstream application controllable summarization paper present evaluate gumsley first entity salience dataset covering named nonnamed salient entity genre english text aligned entity type wikification link full coreference resolution annotation promote strict definition salience using human summary demonstrate high interannotator agreement salience based whether source entity mentioned summary evaluation show poor performance pretrained sota summarization model zeroshot llm prompting capturing salient entity generated summary also show predicting providing salient entity several model architecture enhances performance help derive higherquality summary alleviating entity hallucination problem existing abstractive summarization
humor offense highly subjective due multiple word sens cultural knowledge pragmatic competence hence accurately detecting humorous offensive text several compelling use case recommendation system personalized content moderation however due lack extensive labeled dataset prior work domain havent explored large neural model subjective humor understanding paper explores whether large neural model ensemble capture intricacy associated humoroffense detection rating experiment semeval task hahackathon show develop reasonable humor offense detection system model model ranked rd subtask b consistently ranked around top leaderboard remaining subtasks
recently many work tried augment performance chinese named entity recognition ner using word lexicon representative latticelstm achieved new benchmark result several public chinese ner datasets however latticelstm complex model architecture limit application many industrial area realtime ner response needed work propose simple effective method incorporating word lexicon character representation method avoids designing complicated sequence modeling architecture neural ner model requires subtle adjustment character representation layer introduce lexicon information experimental study four benchmark chinese ner datasets show method achieves inference speed time faster stateoftheart method along better performance experimental result also show proposed method easily incorporated pretrained model like bert
static contextual multilingual embeddings complementary strength static embeddings less expressive contextual language model straightforwardly aligned across multiple language combine strength static contextual model improve multilingual representation extract static embeddings language xlmr validate embeddings crosslingual word retrieval align using vecmap result highquality highly multilingual static embeddings apply novel continued pretraining approach xlmr leveraging high quality alignment static embeddings better align representation space xlmr show positive result multiple complex semantic task release static embeddings continued pretraining code unlike previous work continued pretraining approach require parallel text
paper introduces continuous system capable automatically producing adequate speaking style synthesize desired target text done thanks joint modeling acoustic lexical parameter speaker model adapting cvsm projection training text using mrhmm technique consider long sufficient variety training data available able model continuous lexical space continuous acoustic space proposed continuous automatic text speech system evaluated mean perceptual evaluation order compare traditional approach task system proved capable conveying correct expressiveness average adequacy expressive strength comparable oracle traditional expressive speech synthesis average although drop speech quality mainly due semicontinuous nature data average quality mean proposed system capable improving traditional neutral system without requiring additional user interaction
conducting market research machine translation research volume sale continuously order determine scale machine translation market japan officially announced figure every year furthermore since administered questionnaire regarding web translation
concept normalization task linking textual mention concept concept ontology critical mining analyzing biomedical text propose vectorspace model concept normalization mention concept encoded via transformer network trained via triplet objective online hard triplet mining transformer network refine existing pretrained model online triplet mining make training efficient even hundred thousand concept sampling training triple within minibatch introduce variety strategy searching trained vectorspace model including approach incorporate domainspecific synonym search time model retraining across five datasets model trained corresponding ontology within point stateoftheart model retrained new domain model also trained domain achieving new stateoftheart multiple datasets
paper present system showcase capability latest stateoftheart retrieval augmented generation model trained knowledgeintensive language task slot filling open domain question answering dialogue factchecking moreover given user query show output different model combined crossexamine output particularly show accuracy dialogue improved using question answering model also releasing model used demo contribution paper short video demonstrating system available urlhttpsibmboxcomvemnlpdemos
cancer affect patient physical health also elicit wide spectrum intense emotion patient friend family member people cancer carers family member partner friend increasingly turning web information support despite expansion sentiment analysis context social medium healthcare relatively less research patient narrative longer complex text difficult assess exploratory work examine patient carers express feeling various aspect cancer treatment stage objective paper illustrate example nature language clinical domain well complexity language performing automatic sentiment emotion analysis perform linguistic analysis corpus cancer narrative collected reddit examine performance five stateoftheart model distilbert roberta robertago nrclex see well match human comparison separated linguistic medical background corpus yielded several surprising result could useful sentiment analysis nlp expert linguistic issue encountered classified four category statement expressing variety emotion ambiguous conflicting statement contradictory emotion statement requiring additional context statement sentiment emotion inferred explicitly mentioned
work propose adversarial learning method reward estimation reinforcement learning rl based taskoriented dialog model current rl based taskoriented dialog system require access reward signal either user feedback user rating user rating however may always consistent available practice furthermore online dialog policy learning rl typically requires large number query user suffering sample efficiency problem address challenge propose adversarial learning method learn dialog reward directly dialog sample reward used optimize dialog policy policy gradient based rl evaluation restaurant search domain show proposed adversarial dialog learning method achieves advanced dialog success rate comparing strong baseline method discus covariate shift problem online adversarial dialog learning show address partial access user feedback
introduce novel multiagent system automating story annotation generation tailored prompt large language model llm system utilizes two agent agent responsible generating prompt identify key information necessary reconstructing story agent b reconstructs story annotation provides feedback refine initial prompt human evaluation perplexity score revealed optimized prompt significantly enhance model narrative reconstruction accuracy confidence demonstrating dynamic interaction agent substantially boost annotation process precision efficiency utilizing innovative approach created storysense corpus containing story meticulously annotated facilitate comprehensive story analysis paper also demonstrates practical application annotated dataset drawing story arc two distinct story showcasing utility annotated information story structure analysis understanding
atr collecting analysing meeting data using tabletop sensor device consisting small degree camera surrounded array highquality directional microphone equipment provides stream information audio visual event meeting processed form representation verbal nonverbal interpersonal activity discourse flow meeting paper describes resulting corpus speech video data collected abovere search currently includes data monthly session comprising video audio module collection continuingmonthly scheduled include another ten session
critical component successful language generation pipeline decoding algorithm however general principle guide choice decoding algorithm remain unclear previous work compare decoding algorithm narrow scenario finding generalize across task argue misalignment model likelihood taskspecific notion utility key factor understanding effectiveness decoding algorithm structure discussion introduce taxonomy misalignment mitigation strategy mmss providing unifying view decoding tool alignment mm taxonomy group decoding algorithm based implicit assumption likelihoodutility misalignment yielding general statement applicability across task specifically analyzing correlation likelihood utility prediction across diverse set task provide empirical evidence supporting proposed taxonomy set principle structure reasoning choosing decoding algorithm crucially analysis first relate likelihoodbased decoding algorithm algorithm rely external information valueguided method prompting cover diverse set task date code data model available urlhttpsgithubcomepfldlabunderstandingdecoding
electronic medical record emrs encode extraordinary amount medical knowledge collecting interpreting knowledge however belies significant level clinical understanding automatically capturing clinical information crucial performing comparative effectiveness research paper present datadriven approach model semantic dependency medical concept qualified belief physician dependency captured patient cohort graph clinical picture therapy refined probabilistic graphical model enables efficient inference patientcentered treatment test recommendation based probability perform inference graphical model describe technique smoothing conditional likelihood medical concept semanticallysimilar belief value experimental result compared clinical guideline promising
advance word representation shown tremendous improvement downstream nlp task lack semantic interpretability paper introduce definition frame df matrix distributed representation extracted definition dimension semantically interpretable df dimension correspond qualia structure relation set relation uniquely define term result show dfs competitive performance distributional semantic approach word similarity task
ee nlg challenge shared task generating restaurant description set keyvalue pair paper describes result participation challenge develop simple yet effective neural encoderdecoder model produce fluent restaurant description outperforms strong baseline analyze data provided organizer conclude task also approached templatebased model developed hour
documentlevel neural machine translation docnmt achieves coherent translation incorporating crosssentence context however language pair there shortage parallel document although parallel sentence readily available paper study whether contextual modeling docnmt transferable via multilingual modeling focus scenario zeroshot transfer teacher language document level data student language document sentence level data first time treat documentlevel translation transfer learning problem using simple concatenationbased docnmt explore effect factor transfer number teacher language document level data balance document sentence level data training data condition parallel document genuine v backtranslated experiment europarl iwslt show feasibility multilingual transfer docnmt particularly documentspecific metric observe teacher language adequate data balance contribute better transfer quality surprisingly transfer less sensitive data condition multilingual docnmt delivers decent performance either backtranslated genuine document pair
recent advance interactive large language model like chatgpt revolutionized various domain however behavior natural roleplay conversation setting remains underexplored study address gap deeply investigating chatgpt behaves conversation different setting analyzing interaction normal way roleplay setting introduce novel dataset broad range humanai conversation annotated user motif model naturalness examine human engage conversational ai model ii natural ai model response study highlight diversity user motif interacting chatgpt variable ai naturalness showing nuanced dynamic natural conversation human ai also providing new avenue improving effectiveness humanai communication
metonymy figure speech entity referred another related entity existing datasets metonymy either small size lack sufficient coverage propose new labelled highquality corpus location metonymy called wimcor large size high coverage corpus harvested semiautomatically english wikipedia use different label varying granularity annotate corpus corpus directly used training evaluating automatic metonymy resolution system construct benchmark metonymy resolution evaluate baseline method using new corpus
paper present experiment result obtained suki team discriminating dutch flemish subtitle shared task vardial evaluation campaign best submission ranked th obtaining macro fscore best result produced language identifier implementing heli method without modification describe addition best method used experiment unsupervised clustering
paper describes system developed centre english corpus linguistics cecl discriminating similar language language variety dialect based svm character postag ngrams feature bm weighting scheme achieved accuracy discriminating similar language dsl task ranking first among eleven system lead next three team simpler version system ranked second german dialect identification gdi task thanks several ad hoc postprocessing step complementary analysis carried crossvalidation procedure suggest bm weighting scheme could competitive type task least comparison sublinear tfidf postag ngrams also improved system performance
exposure bias poor translation diversity two common problem neural machine translation nmt caused general teacher forcing strategy training inthe nmt model moreover nmt model usually require largescale highquality parallel corpus however korean low resource language largescale parallel corpus chinese korean challenging researcher therefore wepropose method incorporate translation quality estimation translation processand adopt reinforcement learning evaluation mechanism used guide training model prediction converge completely ground truth word model predicts sequence different ground truth word evaluation mechanism cangive appropriate evaluation reward model addition alleviated lack korean corpus resource adding training data experiment introduce monolingual corpus certain scale construct pseudoparallel data time also preprocessed korean corpus different granularity overcome data sparsity experimental result show work superior baseline chinesekorean koreanchinese translation task fully certificate effectiveness method
aspectbased sentiment analysis absa attracted increasing attention recently due broad application existing absa datasets sentence contain one aspect multiple aspect sentiment polarity make absa task degenerate sentencelevel sentiment analysis paper present new largescale multiaspect multisentiment mam dataset sentence contains least two different aspect different sentiment polarity release dataset would push forward research field addition propose simple yet effective capsnet capsnetbert model combine strength recent nlp advance experiment new dataset show proposed model significantly outperforms stateoftheart baseline method
enable building testing model longdocument comprehension introduce quality multiplechoice qa dataset context passage english average length token much longer typical current model process unlike prior work passage question written validated contributor read entire passage rather relying summary excerpt addition half question answerable annotator working tight time constraint indicating skimming simple search enough consistently perform well baseline model perform poorly task significantly lag behind human performance
paper describe submission text complexity de challenge shared task predicting complexity german sentence compare performance different featurebased regression architecture transformer language model best candidate finetuned german distilbert model ignores linguistic feature sentence model rank th place shared task
hierarchical text classification htc challenging task label text organized category hierarchy deal htc problem many existing work focus utilizing parentchild relationship explicitly shown hierarchy however text category hierarchy also latent relevancy among label level hierarchy refer label peer label peer effect originally utilized work improve classification performance fully explore peerlabel relationship develop peerhtc method method innovatively measure latent relevancy peer label several metric encodes relevancy graph convolutional neural network also propose sample importance learning method ameliorate side effect raised modelling peer label relevancy experiment several standard datasets demonstrate evidence peer label superiority peerhtc stateoftheart htc method term classification accuracy
generative retrieval new advanced paradigm document retrieval recently attracted research interest since encodes document model directly generates retrieved document however power still underutilized since heavily relies preprocessed document identifier docids thus limiting retrieval performance ability retrieve new document paper propose novel fully endtoend retrieval paradigm endtoend learn best docids existing new document automatically via semantic indexing module also perform endtoend document retrieval via encoderdecoderbased generative model namely auto search indexer asi besides design reparameterization mechanism combine two module joint optimization framework extensive experimental result demonstrate superiority model advanced baseline public industrial datasets also verify ability deal new document
speech contains multimedia content pose serious challenge realtime automatic speech recognition asr two reason asr produce meaningless output hurting readability transcript search space asr blown multimedia content encountered resulting large delay compromise realtime requirement paper introduces segmenter aim remove problem detecting music noise segment realtime replacing silence propose two step approach consisting frame classification smoothing first classifier detects speech multimedia frame level second step smoothing algorithm considers temporal context prevent rapid class fluctuation investigate frame classification smoothing setting obtain appealing accuracylatencytradeoff proposed segmenter yield increase transcript quality asr system removing average error caused nonspeech audio stream maintaining realtime applicable delay millisecond
instructing large language model llm solve elementary school math problem shown great success using chain thought cot however cot approach relies llm generate sequence arithmetic calculation prone cascaded calculation error hypothesize llm focus extracting predicate generating symbolic formula math problem description underlying calculation done via external code interpreter investigate using llm generate prolog program solve mathematical question experimental result show prologbased arithmetic problemsolving outperforms cot generation gsmk benchmark across three distinct llm addition given insensitive ordering predicate symbolic formula prolog propose permute ground truth predicate robust llm training via data augmentation
bayesian linguistic phylogeny standardly based cognate matrix word referring fix set meaningstypically around day empirical investigation datasize optimal determine across set language family optimal number meaning required best performance bayesian phylogenetic inference rank meaning stability infer phylogenetic tree using first stable meaning two stable meaning computing quartet distance resulting tree tree proposed language family expert step datasize increase gold standard tree available propose instead compute quartet distance tree based nmost stable meaning one based n stable meaning increasing n n n total number meaning assumption value n quartet distance begin stabilize also value quality tree cease improve show assumption borne result two method vary across family optimal number meaning appears correlate number language consideration
background parallel corpus used train evaluate machine translation system alleviate cost producing parallel resource evaluation campaign existing corpus leveraged however little information may available method used producing corpus including translation direction objective gain insight medline parallel corpus used biomedical task workshop machine translation wmt material method contact information author medline article included englishspanish ene englishfrench enfr englishportuguese enpt wmt test set obtained pubmed publisher website author asked abstract writing practice survey result response rate author reported mainly native speaker language english although manual translation sometimes via professional translation service commonly used abstract translation author article ene enpt set also relied postedited machine translation discussion study provides characterization medline author language skill abstract writing practice conclusion information collected study used inform test set design next wmt biomedical task
paper advocate use message sequence chart msc knowledge representation capture visualize multiactor interaction temporal ordering propose algorithm automatically extract msc history narrative given narrative first identify verb indicate interaction use dependency parsing semantic role labelling based approach identify sender initiating actor receiver actor involved interaction verb final step msc extraction employ stateofthe art algorithm temporally reorder interaction evaluation multiple publicly available narrative show improvement four baseline
absence readily available labeled data given sequence labeling task language annotation projection proposed one possible strategy automatically generate annotated data annotation projection often formulated task transporting parallel corpus label pertaining given span source language corresponding span target language paper present tprojection novel approach annotation projection leverage large pretrained texttext language model stateoftheart machine translation technology tprojection decomposes label projection task two subtasks candidate generation step set projection candidate using multilingual model generated ii candidate selection step generated candidate ranked based translation probability conducted experiment intrinsic extrinsic task indoeuropean lowresource african language demostrate tprojection outperforms previous annotation projection method wide margin believe tprojection help automatically alleviate lack highquality training data sequence labeling task code data publicly available
set covering algorithm efficient tool solving optimal linguistic corpus reduction optimality process directly related descriptive feature sentence reference corpus article suggests verify experimentally behaviour three algorithm greedy approach lagrangian relaxation based one giving importance rare event third one considering kullbackliebler divergence reference ongoing distribution event analysis content reduced corpus show first approach stay effective compress corpus guaranteeing minimal content variant minimises kullbackliebler divergence guarantee distribution event close reference distribution expected however price solution much important corpus proposed experiment also evaluated mixedapproach considering random complement smallest covering
present system answer selection integrates finegrained question classification deep learning model designed answer selection detail necessary change question classification taxonomy system creation new entity identification system method highlighting entity achieve objective experiment show question class strong signal deep learning model answer selection enable u outperform current state art variation experiment except one best configuration mrr map score outperform current state art point version trec answer selection test set standard dataset task
word embeddings ubiquitous form word representation natural language processing application word embeddings monolingual word sense disambiguation wsd english comparison done paper attempt bridge gap examining popular embeddings task monolingual english wsd simplified method lead comparable stateoftheart performance without expensive retraining crosslingual wsd word sens word source language come separate target translation language also assist language learning example providing translation target vocabulary learner thus also applied word embeddings novel task crosslingual wsd chinese provide public dataset benchmarking also experimented using word embeddings lstm network found surprisingly basic lstm network work well discus ramification outcome
existing compositional generalization datasets syntheticallygenerated resulting lack natural language variation recent attempt introduce nonsynthetic datasets compositional generalization suffer either limited data scale lack diversity form combination better investigate compositional generalization linguistic phenomenon compositional diversity propose dish name recognition diner task create large realistic chinese dataset given recipe instruction model required recognize dish name composed diverse combination food action flavor dataset consists dish recipe involves plenty linguistic phenomenon anaphora omission ambiguity provide two strong baseline based large language model llm work contributes challenging task baseline method tackle task insight compositional generalization context dish name recognition
paper describes austalk corpus designed created big asc collaborative project two main goal providing standardised infrastructure audiovisual recording australia producing large audiovisual corpus australian english hour av recording speaker first present overall project describe corpus component strict data collection protocol high level standardisation automation process put place quality control also discus annotation phase project along goal challenge major contribution project explore procedure automating annotation present solution conclude current status corpus example research already conducted new resource austalk one corpus included hcs vlab briefly sketched conclusion
core visionandlanguage navigation vln challenge building robust instruction representation action decoding scheme generalize well previously unseen instruction environment paper report two simple highly effective method address challenge lead new stateoftheart performance first adapt largescale pretrained language model learn text representation generalize better previously unseen instruction second propose stochastic sampling scheme reduce considerable gap expert action training sampled action test agent learn correct mistake long sequential action decoding combining two technique achieve new state art roomtoroom benchmark absolute gain previous best result textgreater success rate weighted path length metric
often difficult reliably evaluate model generate text among text style transfer particularly difficult evaluate success depends number parameter conduct evaluation large number model detoxification task explore relation manual automatic metric find weak correlation dependent type model generated text automatic metric tend less reliable betterperforming model however finding suggest chrf bertscore metric used proxy human evaluation text detoxification extent
examine capability unified multitask framework three information extraction task named entity recognition relation extraction event extraction framework called dygie accomplishes task enumerating refining scoring text span designed capture local withinsentence global crosssentence context framework achieves stateoftheart result across task four datasets variety domain perform experiment comparing different technique construct span representation contextualized embeddings like bert perform well capturing relationship among entity adjacent sentence dynamic span graph update model longrange crosssentence relationship instance propagating span representation via predicted coreference link enable model disambiguate challenging entity mention code publicly available urlhttpsgithubcomdwaddendygiepp easily adapted new task datasets
semantic annotation sa task consists establishing relation textual entity word group word designating named entity real world concept corresponding entity ontology main difficulty task textual entity might highly polysemic potentially related many different ontological representation solve specific problem various information retrieval technique used involves contextual word estimate wich exact textual entity recognized paper present resource contextual word used ir algorithm establish link named entity ne text entry point semantic description linkeddata network
textbased game tbgs emerged important collection nlp task requiring reinforcement learning rl agent combine natural language understanding reasoning key challenge agent attempting solve task generalize across multiple game demonstrate good performance seen unseen object purely deeprlbased approach may perform well seen object however fail showcase performance unseen object commonsenseinfused deeprl agent may work better unseen data unfortunately policy often interpretable easily transferable tackle issue paper present explorer explorationguided reasoning agent textual reinforcement learning explorer neurosymbolic nature relies neural module exploration symbolic module exploitation also learn generalized symbolic policy perform well unseen data experiment show explorer outperforms baseline agent textworld cooking twcooking textworld commonsense twc game
social medium site eg twitter used surveillance drug safety population level study focus effect medication specific set individual rely source data mining social medium data information would require ability distinguish indication personal medication intake medium towards end paper present annotated corpus used train machine learning system determine whether tweet mention medication indicates individual posting taken medication specific time demonstrate utility corpus training set present baseline result supervised classification
presentation highlight key technological innovation provided language io see dynamic mt engine selection based customer content type language pair content well metadata proprietary mt quality estimation mechanism allows customer control human review budget selfimproving glossary technology continuously learn new keywords key phrase based actual content processed platform
paper adapt deepspeare joint neural network model english sonnet chinese poetry illustrate characteristic chinese quatrain explain architecture well training generation procedure differs shakespeare sonnet several aspect analyse generated poetry find model work well chinese poetry generate coherent line quatrain different topic capture rhyme automatically certain extent
machine translation mt become integral part daily life million people output fluent user often distinguish human translation however fluid text often harbor algorithmic trace limited lexical choice societal misrepresentation raise concern possible effect mt natural language human communication call regular evaluation machinegenerated translation different language paper explores output three widely used engine google deepl microsoft azure one smaller commercial system translate english french source text seven diverse parallel corpus german compare mtproduced text human reference term lexical syntactic morphological feature additionally investigate mt leverage lexical borrowing analyse distribution anglicism across german translation
named entity recognition ner cornerstone natural language processing task robustness given little attention paper rethink principle conventional text attack easily violate label consistency original adversarial ner sample due finegrained nature ner even minor word change sentence result emergence mutation entity producing invalid adversarial sample end propose novel oneword modification ner attack based key insight ner model always vulnerable boundary position entity make decision thus strategically insert new boundary sentence trigger victim model make wrong recognition either boundary word word sentence call attack textitvirtual boundary attack viba shown remarkably effective attacking english chinese model attack success rate stateoftheart language model also significantly faster previous method
many existing named entity recognition ner solution built based news corpus data proper syntax solution might lead highly accurate result applied noisy user generated data eg tweet feature sloppy spelling concept drift limited contextualization term concept due length constraint model described paper based linear chain conditional random field crfs use bieou encoding scheme leverage random feature dropout upsampling training data considered feature include word cluster pretrained distributed word representation updated gazetteer feature global context prediction latter feature allows ingesting meaning new rare token system via unsupervised learning alleviating need learn lexicon based feature usually tend high dimensional paper report solution st submitted wnut ner shared task also present improvement original submission si built using semisupervised learning labelled training data pretrained resourced constructed unlabelled tweet data st solution achieved f score higher baseline f task extracting entity type si resulted increase f score baseline st finally si model evaluation test data achieved f score textasciitilde increase nd best submitted solution experimental setup result available standalone twitter ner tool urlhttpsgithubcomnapsternxgtwitterner
paper describes ldc forced aligner designed align audio transcript unlike existing forced aligners ldc forced aligner align partially transcribed audio file also audio file large chunk nonspeech segment noise music silence etc inserting optional wildcard phoneme sequence sentence paragraph boundary based htk tool kit ldc forced aligner align audio transcript sentence word level paper also report usage english mandarin chinese data
paper present algorithm aligning framenet lexical unit wordnet synset framenet wordnet wellknown well widelyused resource entire research community help system comprehension semantics text therefore finding strategy link framenet wordnet involves challenge related better understanding human language deep analysis exploited researcher improve performance application alignment achieved exploiting particular characteristic lexicalsemantic resource special emphasis explicit formal semantic relation semantic neighborhood computed alignment lemma algorithm calculates correlation score comparing neighborhood result suggest proposed algorithm appropriate aligning framenet wordnet hierarchy furthermore algorithm aid research increasing coverage framenet building framenets language creating system querying joint framenetwordnet hierarchy
natural language understanding nlu production system user evolving need necessitate addition new feature time indexed new symbol added meaning representation space requires additional training data result evergrowing datasets present first systematic investigation incremental symbol learning scenario analysis reveals troubling quirk building broadcoverage nlu system training dataset grows performance small set new symbol often decrease show trend hold multiple mainstream model two common nlu task intent recognition semantic parsing rejecting class imbalance sole culprit reveal trend closely associated effect call source signal dilution strong lexical cue new symbol become diluted training dataset grows selectively dropping training example prevent dilution often revers trend showing overreliance mainstream neural nlu model simple lexical cue
identification metaphoric language text critical generating effective semantic representation natural language understanding computational approach metaphor identification largely relied heuristic based model featurebased machine learning using handcrafted lexical resource coupled basic syntactic information however recent work shown predictive power syntactic construction determining metaphoric source target domain sullivan work intends explore syntactic construction relation metaphoric language undertake corpusbased analysis predicateargument construction metaphoric property attempt effectively represent syntactic construction feature metaphor processing identifying source target domain distinguishing metaphoric word nonmetaphoric
past two decade rise new technology social network significantly shaped written language imbuing characteristic akin spoken language study report ongoing initiative build whap corpus resource featuring whatsapp conversation italian encompassing written spoken message totaling present token conversation participant diverse age group geographical region italy specifically paper focus practical step involved construction resource publicly accessible whap corpus enable indepth linguistic research language used whatsapp show unique feature blending written spoken element
sentiment classification becomes important rapid growth user generated content however sentiment classification task usually come two challenge first sentiment classification highly domaindependent training sentiment classifier every domain inefficient often impractical second since quantity labeled data important assessing quality classifier hard evaluate classifier labeled data limited certain domain address challenge mentioned focus learning highlevel feature able generalize across domain global classifier benefit simple combination document multiple domain paper proposed model incorporates sentiment polarity unlabeled data multiple domain learns new feature representation model doesnt require label every domain mean learned feature representation generalized sentiment domain adaptation addition learned feature representation used classifier since model defines meaning feature value arranges highlevel feature prefixed order necessary train another classifier top new feature empirical evaluation demonstrate model outperforms baseline yield competitive result stateoftheart work benchmark datasets
describe simple effective method crosslingual syntactic transfer dependency parser scenario large amount translation data available method make use three step method deriving crosslingual word cluster used multilingual parser method transferring lexical information target language source language treebanks method integrating step densitydriven annotation projection method rasooli collins experiment show improvement stateoftheart several language used previous work setting source translation data bible considerably smaller corpus europarl corpus used previous work result using europarl corpus source translation data show additional improvement result rasooli collins conclude result datasets universal dependency corpus
introduce opensource webbased data annotation framework alpacatag sequence tagging task namedentity recognition ner distinctive advantage alpacatag threefold active intelligent recommendation dynamically suggesting annotation sampling informative unlabeled instance backend active learned model automatic crowd consolidation enhancing realtime interannotator agreement merging inconsistent label multiple annotator realtime model deployment user deploy model downstream system new annotation made alpacatag comprehensive solution sequence labeling task ranging rapid tagging recommendation powered active learning autoconsolidation crowd annotation realtime model deployment
previous work interactive system aimed helping nonexpert user enlarge monolingual dictionary rulebased machine translation mt system worked discarding inflection paradigm generate set inflected word form validated user method however deal common case set different paradigm generate exactly set inflected word form although different inflection information attached paper propose use ngrambased model lexical category inflection information select single paradigm case one paradigm generates set word form result obtained spanish monolingual dictionary show correct paradigm chosen around unknown word thus making resulting system available opensource license valuable help enlarge monolingual dictionary used mt involving nonexpert user without technical linguistic knowledge
deep semantic retrieval achieved remarkable success online ecommerce application majority method aim distinguish positive item negative item query utilizing margin loss softmax loss despite decent performance method highly sensitive hyperparameters ie margin temperature tau measure similarity negative pair affect distribution item metric space design choose adaptively parameter different pair still open challenge recently several method attempted alleviate problem learning parameter trainablestatistical method recommendation argue suitable retrieval scenario due agnosticism diversity query fully overcome limitation propose novel adaptive metric learning method design simple universal hyperparameterfree learning method improve performance retrieval specifically first propose method adaptive obtains hyperparameters relying batch similarity without fixed extratrainable hyperparameters subsequently adopt symmetric metric learning method mitigate model collapse issue furthermore proposed method general shed highlight field extensive experiment demonstrate method significantly outperforms previous method realworld dataset highlighting superiority effectiveness method method successfully deployed online ecommerce search platform brought substantial economic benefit
present conceptual framework unifies variety evaluation metric different structured prediction task eg event relation extraction syntactic semantic parsing framework requires representing output task object certain data type derives metric matching common substructure possibly followed normalization demonstrate commonly used metric number task succinctly expressed framework show new metric naturally derived bottomup way based output structure release library enables derivation create new metric finally consider specific characteristic task motivate metric design decision suggest possible modification existing metric line motivation
three advanced german speech corpus collected thegerman smartweb project one smartweb motorbikecorpus smc described paper smartweb speech corpus smc designed dialogue system dealing open domain corpus recorded special circumstance motorbike ride contains utterance driver related information retrieval various source different topic audio track show characteristic noise engine surrounding traffic well drop out caused transmission bluetooth umts mobile network discus problem technical setup fully automatic evocation naturalspoken query mean dialoguelike sequence
language identification task determining language given text written task important natural language processing information retrieval activity two popular approach language identification ngrams stopwords model paper two model tested different type document short irregular text tweet long regular text wikipedia article
conventional wisdom pruning transformerbased language model pruning reduces model expressiveness thus likely underfit rather overfit however trending pretrainandfinetune paradigm postulate countertraditional hypothesis pruning increase risk overfitting performed finetuning phase paper aim address overfitting problem improve pruning performance via progressive knowledge distillation errorbound property show first time reducing risk overfitting help effectiveness pruning pretrainandfinetune paradigm ablation study experiment glue benchmark show method outperforms leading competitor across different task
introduce preco largescale english dataset coreference resolution dataset designed embody core challenge coreference entity representation alleviating challenge low overlap training test set enabling separated analysis mention detection mention clustering strengthen trainingtest overlap collect large corpus k document word mostly vocabulary englishspeaking preschooler experiment show higher trainingtest overlap error analysis preco efficient one ontonotes popular existing dataset furthermore annotate singleton mention making possible first time quantify influence mention detector make coreference resolution performance dataset freely available urlhttpspreschoollabgithubiopreco
propose method combine hybrid kaldibased automatic speech recognition asr system endtoend wavvec xlsr asr using confidence measure research focused lowresource irish language given limited available opensource resource neither standalone hybrid asr endtoend asr system achieve optimal performance applying recognizer output voting error reduction rover technique illustrate ensemble learning could facilitate mutual error correction asr system paper outline strategy merging hybrid kaldi asr model endtoend xlsr model help confidence score although contemporary stateoftheart endtoend asr model face challenge related prediction overconfidence utilize renyis entropybased confidence approach tuned temperature scaling align kaldi asr confidence although significant difference word error rate wer hybrid endtoend asr could achieve notable reduction wer ensembling rover resulted almost word error rate reduction werr primary test set approximately werr noisy imbalanced test data
humanintheloop system cleaning nlp training data rely automated sieve isolate potentiallyincorrect label manual review developed novel technique flagging potentiallyincorrect label high sensitivity named entity recognition corpus incorporated sieve endtoend system cleaning nlp corpus implemented modular collection jupyter notebook built extension panda dataframe library used system identify incorrect label conll corpus englishlanguage named entity recognition ner one influential corpus ner model research unlike previous work looked subset corpus validation fold automated sieve enabled u examine entire corpus depth across entire conll corpus identified incorrect label corpus published correction along code used experiment developing repeatable version process used conll corpus opensource library
work address problem unsupervised aspect category detection using small set seed word recent work focused learning embedding space seed word sentence establish similarity sentence aspect however aspect representation limited quality initial seed word model performance compromised noise mitigate limitation propose simple framework automatically enhances quality initial seed word selects highquality sentence training instead using entire dataset main concept add number seed word initial set treat task noise resolution task augmenting data lowresource task addition jointly train aspect category detection aspect term extraction aspect term polarity enhance performance approach facilitates shared representation learning allowing aspect category detection benefit additional guidance offered task extensive experiment demonstrate framework surpasses strong baseline standard datasets
automated essay scoring aes involves prediction score relating writing quality essay existing work aes utilize regression objective ranking objective respectively however two type method highly complementary end paper take inspiration contrastive learning propose novel unified neural pairwise contrastive regression npcr model objective optimized simultaneously single loss specifically first design neural pairwise ranking model guarantee global ranking order large list essay extend pairwise ranking model predict relative score input essay several reference essay additionally multisample voting strategy employed inference use quadratic weighted kappa evaluate model public automated student assessment prize asap dataset experimental result demonstrate npcr outperforms previous method large margin achieving stateoftheart average performance aes task
present segmentlevel neural crf combine neural network linear chain crf segmentlevel sequence modeling task named entity recognition ner syntactic chunking segmentlevel crf consider higherorder label dependency compared conventional wordlevel crf since difficult consider possible variable length segment method us segment lattice constructed wordlevel tagging model reduce search space performing experiment ner chunking demonstrate method outperforms conventional wordlevel crf neural network
paper address challenge uncertainty quantification text classification medical purpose provides threefold approach support robust trustworthy decisionmaking medical practitioner also address challenge imbalanced datasets medical domain utilizing mondrian conformal predictor naive bayes classifier
past shared task emotion use data overt expression emotion textiti happy see well subtle expression emotion inferred instance event description datasets focus cause stimulus emotion first time propose shared task system predict emotion large automatically labeled dataset tweet without access word denoting emotion based intention call implicit emotion shared task iest system infer emotion mostly context every tweet occurrence explicit emotion word masked tweet collected manner likely include description cause emotion stimulus altogether team submitted result range macro f score baseline maxent bag word bigram obtains f score available participant development phase study human annotator suggests automatic method outperform human prediction possibly honing subtle textual clue used human corpus resource result available shared task website urlhttpimplicitemotionswassacom
paper describes system developed semeval task hashtagwars learning sense humor learning recognize sense humor important task language understanding application different set feature based frequency word structure tweet semantics used system identify presence humor tweet supervised machine learning approach multilayer perceptron naive bayes used classify tweet three level sense humor given hashtag system find funniest tweet predicts amount funniness tweet official submitted run achieved accuracy using multilayer perceptron subtaska distance subtaskb using naive bayes subtaskb system achieved distance apart official run system scored accuracy subtaska using svm still wide room improvement system
propose novel method bootstrap construction parallel corpus new pair structurally different language combining use pivot language selftraining pivot language enables use existing translation model bootstrap alignment selftraining procedure enables achieve better alignment document sentence level also propose several evaluation method resulting alignment
human use natural language vision context resolve referent environment situated reference resolution trivial ambiguous case arise language underspecified multiple candidate referent study investigates howpragmatic modulators external linguistic content critical correct interpretation referent scenario inparticular demonstrate human subject experiment social norm applicable given context influence theinterpretation referring expression additionally highlight current coreference tool natural language processing fail tohandle ambiguous case also briefly discus implication work assistive robot routinely need resolve referent environment
since inception linguistic data consortium data scholarship program awarded cost grant data recipient country survey twelve cycle date two award fall spring semester fall spring yield interesting view graduate program research trend human language technology related field particular data set deemed important support research survey also reveals region activity appears rise including arabicspeaking region portion america asia
paper describe nordic dialect corpus recently completed corpus variety feature combined make advanced tool language researcher feature include linguistic content dialect five closely related language annotation tagging two type transcription search interface advanced possibility combining large array search criterion result presentation intuitive simple interface many search variable linguisticsbased informantbased timebased multimedia display linking sound video transcription display result map display informant detail number word information informant advanced result handling concordance collocation count statistic shown variety graphical mode plus processing finally importantly corpus freely available research web give example various kind search display result result handling
many knowledgebased solution proposed solve word sense disambiguation wsd problem limited annotated resource wsd algorithm able cover large sense repository still outperformed supervised one benchmark data paper start analysis identifying key property issue application spreading activation algorithm knowledgebased wsd eg influence network local structure interaction context information sense frequency taking observation point departure introduce novel solution new contexttosense matching using bert embeddings iterative parallel spreading activation function selective sense alignment using contextual bert embeddings proposed solution obtains performance beyond stateoftheart contemporary knowledgebased wsd approach english polish data
introduce doctime novel temporal dependency graph tdg parser take input text document produce temporal dependency graph outperforms previous bertbased solution relative three datasets modeling problem graph network pathprediction loss incorporate longer range dependency work also demonstrates tdg graph used improve downstream task temporal question answering nli relative new framework incorporates temporal dependency graph selfattention layer transformer model timetransformer finally develop evaluate new temporal dependency graph dataset domain contractual document previously explored setting
article describes dependencybased strategy us compositional distributional semantics crosslingual word embeddings translate multiword expression mwes unsupervised approach performs translation process word contextualization taking account lexicosyntactic context selectional preference strategy suited translate phraseological combination phrase whose constituent word lexically restricted several experiment adjectivenoun verbobject compound show mutual contextualization cocompositionality clearly outperforms compositional method paper also contributes new freely available dataset englishspanish mwes used validate proposed compositional strategy
label scarcity bottleneck improving task performance specialized domain propose novel compositional transfer learning framework dot zeroshot domain transfer without access indomain label dot jointly learns domain knowledge masked language modelling unlabelled indomain free text task knowledge task training readily available generaldomain data multitask manner improve transferability task training design strategy named nlgu simultaneously train natural language generation nlg indomain labeltodata generation enables data augmentation selffinetuning natural language understanding nlu label prediction evaluate dot biomedical domain resourcelean subdomain radiology focusing natural language inference text summarization embedding learning dot demonstrates effectiveness compositional transfer learning multitask learning particular dot outperforms current stateoftheart zeroshot transfer absolute point accuracy radnli validate dot ablation case study demonstrating ability solve challenging nli example requiring indomain expertise
present new benchmark dataset called parade paraphrase identification requires specialized domain knowledge parade contains paraphrase overlap little lexical syntactic level semantically equivalent based computer science domain knowledge well nonparaphrases overlap greatly lexical syntactic level semantically equivalent based domain knowledge experiment show stateoftheart neural model nonexpert human annotator poor performance parade example bert finetuning achieves f score much lower performance paraphrase identification datasets parade serve resource researcher interested testing model incorporate domain knowledge make data code freely available
article dwell time ie expected time user spend article among important factor showing article engagement great interest predict dwell time article release allows digital newspaper make informed decision publish engaging article paper propose novel contentbased approach based deep neural network architecture predicting article dwell time proposed model extract emotion event entity feature article learns interaction among combine interaction wordbased feature article learn model predicting dwell time experimental result real dataset major newspaper show proposed model outperforms stateoftheart baseline
learning lowdimensional representation entity relation knowledge graph using contrastive estimation represents scalable effective method inferring connectivity pattern crucial aspect contrastive learning approach choice corruption distribution generates hard negative sample force embedding model learn discriminative representation find critical characteristic observed data earlier method either employ simple corruption distribution ie uniform yielding easy uninformative negative sophisticated adversarial distribution challenging optimization scheme explicitly incorporate known graph structure resulting suboptimal negative paper propose structure aware negative sampling sans inexpensive negative sampling strategy utilizes rich graph structure selecting negative sample node khop neighborhood empirically demonstrate sans find semantically meaningful negative competitive sota approach requires additional parameter difficult adversarial optimization
three broad approach attempted combine distributional structuralsymbolic aspect construct meaning representation injecting linguistic feature distributional representation b injecting distributional feature symbolic representation c combining structural distributional feature final representation work focus example third less studied approach extends graphical knowledge representation gkr include distributional feature proposes division semantic labour distributional structuralsymbolic feature propose two extension gkr clearly show division empirically test one proposal nli dataset hard compositional pair
demographicallytagged social medium message common source data computational social science message indicate difference belief behavior demographic group clear understanding different demographic group use platform twitter paper present preliminary analysis group differing behavior may confound analysis group analyzed one million twitter user first inferring demographic attribute measuring several indicator twitter behavior find difference indicator across demographic group suggesting may underlying difference different demographic group use twitter
lot interest scaling property transformer model however much done front investigating effect scaling property different inductive bias model architecture model architecture scale differently inductive bias affect scaling behaviour influence upstream pretraining downstream transfer paper conduct systematic study scaling behaviour ten diverse model architecture transformer switch transformer universal transformer dynamic convolution performer recently proposed mlpmixers via extensive experiment show architecture indeed important consideration performing scaling best performing model fluctuate different scale believe finding outlined work significant implication model architecture currently evaluated community
recent study shown impressive efficacy counterfactually augmented data cad reducing nlu model reliance spurious feature improving generalizability however current method still heavily rely human effort taskspecific design generate counterfactuals thereby impeding cad applicability broad range nlu task paper present autocad fully automatic taskagnostic cad generation framework autocad first leverage classifier unsupervisedly identify rationale span intervened disentangles spurious causal feature autocad performs controllable generation enhanced unlikelihood training produce diverse counterfactuals extensive evaluation multiple outofdomain challenge benchmark demonstrate autocad consistently significantly boost outofdistribution performance powerful pretrained model across different nlu task comparable even better previous stateoftheart humanintheloop taskspecific cad method
paper study different type nod related cognitive state listener distinction made nod movement starting upwards upnods nod movement starting downwards downnods well single repetitive nod data japanese multiparty conversation result accord previous finding indicating upnods related change listener cognitive state hearing partner contribution downnods convey meaning listener cognitive state changed
many natural language assign grammatical gender also inanimate noun language language word relate gendermarked noun inflected agree noun gender show affect word representation inanimate noun resulting noun gender closer noun different gender embedding debiasing method fail remove effect demonstrate careful application method neutralize grammatical gender signal word context training word embeddings effective removing fixing grammatical gender bias result positive effect quality resulting word embeddings monolingual cross lingual setting note successfully removing gender signal achievable trivial languagespecific morphological analyzer together careful usage essential achieving good result
recent success pretraining monolingual data finetuning machine translation mt remains unclear best leverage pretrained model given mt task paper investigates benefit drawback freezing parameter adding new one finetuning pretrained model mt focus finetuning model trained english monolingual data bart finetuning model trained monolingual data language mbart bart get best performance freezing model parameter adding extra positional embeddings mbart match outperform performance naive finetuning language pair encoder decoder frozen encoderdecoder attention parameter important finetune constraining outofdomain training set vietnamese english see largest improvement finetuning baseline
debate use personal data language resource usually focus rightfully anonymisation however debate usually end quickly conclusion proper anonymisation would necessarily cause loss linguistically valuable information paper discusses alternative approach pseudonymisation pseudonymisation solve problem inasmuch pseudonymised data still regarded personal data therefore processing still comply gdpr principle provide significant relief especially process personal data research purpose paper describes pseudonymisation measure safeguard right interest data subject gdpr special focus right informed also provides concrete example pseudonymisation carried within research project institute information technology communication otto von guericke university magdeburg
number frequently utilized daily narrative professional document clinical note scientific paper financial document legal court order ability understand generate number thus one essential aspect evaluating large language model vein propose collection datasets semeval task numeval collection encompasses several task focused numeralaware instance including number prediction natural language inference question answering reading comprehension reasoning headline generation paper offer overview dataset present result subtasks numeval additionally contribute summarizing participant method conducting error analysis best knowledge numeval represents one early task perform peer evaluation semevals history share observation aspect provide suggestion future semeval task
emotion essential storytelling narrative generation relationship story emotion extensively studied author paper including professional novelist examined use natural language processing address problem novelist perspective practical creative writing particular story completion task requires understanding existing unfinished context studied perspective creative support human writer generate appropriate content complete unfinished part found unsupervised pretrained large neural model sequencetosequence type useful task furthermore based plugandplay module controllable text generation using gpt additional module implemented consider emotion although preliminary study result leave room improvement incorporating model practical system effort important step complementing emotional trajectory story
udpipe trainable pipeline performs sentence segmentation tokenization po tagging lemmatization dependency parsing present prototype udpipe evaluate conll ud shared task multilingual parsing raw text universal dependency employ three metric submission ranking participant prototype placed first mlas ranking third la ranking third blex ranking extrinsic parser evaluation epe system ranked first overall score
sequential recurrent neural network achieved superior performance language modeling overlook structure information natural language recent work structureaware model shown promising result language modeling however incorporate structure knowledge corpus without syntactic annotation remains open problem work propose neural variational language model nvlm enables sharing grammar knowledge among different corpus experimental result demonstrate effectiveness framework two popular benchmark datasets help shared grammar language model converges significantly faster lower perplexity new training corpus
writing person may need anticipate question audience different social group may ask different type question someone writing problem want resolve kind followup question domain expert ask could writer better address expert information need rewriting original post paper explore task sociallyaware question generation collect data set question post social medium including background information questionaskers social group find different social group expert novice consistently ask different type question train several textgeneration model incorporate social information find discrete socialrepresentation model outperforms textonly model different social group ask highly different question one another work provides framework developing text generation model help writer anticipate information expectation highly different social group
propose novel hierarchical recurrent neural network rnn learning sequence dialogue act da input task sequence utterance ie conversational contribution comprising sequence token output sequence da label one label per utterance model leverage hierarchical nature dialogue data using two nested rnns capture longrange dependency dialogue level utterance level model combined attention mechanism focus salient token utterance experimental result show model outperforms strong baseline two popular datasets switchboard maptask detailed empirical analysis highlight impact aspect model
ability commonsense reasoning cr decides whether neural machine translation nmt model move beyond pattern recognition despite rapid advancement nmt use pretraining enhance nmt model research cr nmt still infancy leaving much explored term effectively training nmt model high cr ability devising accurate automatic evaluation metric paper present comprehensive study aimed expanding understanding cr nmtfor training confirm effectiveness incorporating pretrained knowledge nmt model subsequently utilizing model robust testbeds investigating cr nmt evaluation propose novel entityaware evaluation method take account nmt candidate important entity candidate aligned human judgement based strong testbed evaluation method identify challenge training nmt model high cr ability suggest direction unlabeled data utilization model design hope method finding contribute advancing research cr nmt source data code script freely available urlhttpsgithubcomyutongwangcrnmt
multimodal named entity recognition mner us visual information improve performance textonly named entity recognition ner however existing method acquiring local visual information suffer certain limitation using attentionbased method extract visual region related text visual region obtained convolutional architecture eg resnet attention distracted entire image rather fully focused visual region relevant text using object detectionbased eg mask rcnn method detect visual object region related text object detection limited range recognition category moreover visual region obtained object detection may correspond entity text summary goal method extract relevant visual region entity text visual region obtained method may redundant insufficient entity text paper propose entity span position visual region espvr module obtain relevant visual region corresponding entity text experiment show proposed approach achieve sota twitter competitive result twitter
order interpret communicative intent utterance need grounded something outside language grounded world modality paper argue dialogue clarification mechanism make explicit process interpreting communicative intent speaker utterance grounding various modality dialogue situated paper frame dialogue clarification mechanism understudied research problem key missing piece giant jigsaw puzzle natural language understanding discus theoretical background practical challenge posed problem propose recipe obtaining grounding annotation conclude highlighting ethical issue need addressed future work
paper present two deeplearning system competed semeval task sentiment analysis twitter participated subtasks english tweet involving messagelevel topicbased sentiment polarity classification quantification use long shortterm memory lstm network augmented two kind attention mechanism top word embeddings pretrained big collection twitter message also present text processing tool suitable social network message performs tokenization word normalization segmentation spell correction moreover approach us handcrafted feature sentiment lexicon ranked st tie subtask achieved competitive result rest subtasks word embeddings text processing tool available research community
video dialog new challenging task requires agent answer question combining video information dialog history different singleturn video question answering additional dialog history important video dialog often includes contextual information question existing visual dialog method mainly use rnn encode dialog history single vector representation might rough straightforward advanced method utilize hierarchical structure attention memory mechanism still lack explicit reasoning process paper introduce novel progressive inference mechanism video dialog progressively update query information based dialog history video content agent think information sufficient unambiguous order tackle multimodal fusion problem propose crosstransformer module could learn finegrained comprehensive interaction inside modality besides answer generation also consider question generation challenging significant complete video dialog system evaluate method two largescale datasets extensive experiment show effectiveness method
increased number machine translation service available unfortunately none provide adequate translation quality input source force user select among service according need however tedious time consuming perform manual selection solution proposed automatic mechanism select appropriate machine translation service although evaluation method available bleu nist wer etc evaluation result unanimous regardless translation source proposed twophase architecture selecting translation service first phase us datadriven classification allow appropriate evaluation method selected according translation source second phase selects appropriate machine translation result selected evaluation method describe architecture detail algorithm construct prototype test show proposal yield better translation quality employing one machine translation service
european language grid enables researcher practitioner easily distribute use nlp resource model corpus classifier describe paper course evalitaelg project integrated datasets system italian language show easy use integrated system demonstrate case study seamless application platform providing italian nlp everyone
fairness environmental impact important research direction sustainable development artificial intelligence however topic active research area natural language processing nlp surprising lack research interplay two field lacuna highly problematic since increasing evidence exclusive focus fairness actually hinder environmental sustainability vice versa work shed light crucial intersection nlp investigating efficiency current fairness approach surveying example method reducing unfair stereotypical bias literature evaluating common technique reduce energy consumption thus environmental impact english nlp model knowledge distillation kd impact fairness case study evaluate effect important kd factor including layer dimensionality reduction respect performance distillation task natural language inference semantic similarity prediction b multiple measure dimension stereotypical bias eg gender bias measured via word embedding association test result lead u clarify current assumption regarding effect kd unfair bias contrary finding show kd actually decrease model fairness
present new approach learning semantic parser multiple datasets even target semantic formalism drastically different underlying corpus overlap handle disjoint data treating annotation unobserved formalism latent structured variable building stateoftheart baseline show improvement framesemantic parsing semantic dependency parsing modeling jointly
factual inconsistency existed output abstractive summarization model original document frequently presented fact consistency assessment requires reasoning capability find subtle clue identify whether modelgenerated summary consistent original document paper proposes finegrained twostage fact consistency assessment framework summarization model sumfc given document summary sentence first stage sumfc selects topk relevant sentence summary sentence document second stage model performs finegrained consistency reasoning sentence level aggregate sentence consistency score obtain final assessment result get training data pair data synthesis adopt contrastive loss data pair help model identify subtle cue experiment result show sumfc made significant improvement previous stateoftheart method experiment also indicate sumfc distinguishes detailed difference better
many nlp application need fundamental tool convert input text appropriate form format extract primary linguistic knowledge word sentence tool perform segmentation text sentence word phrase checking correcting spelling lexical morphological analysis po tagging persian among language complex preprocessing task different writing prescription spacing within word character coding spelling difficulty challenge converting various text standard one lack fundamental text processing tool morphological analyser especially derivational morphology po tagger another problem persian text processing paper introduces set fundamental tool persian text processing step package step standard text preparation persian language performs combination tokenization spell checking morphological analysis po tagging also turn persian text different prescribed form writing series token standard style introduced academy persian language literature apll experimental result show high performance
era pretrained language model transformer de facto choice model architecture recent research shown promise entirely convolutional cnn architecture explored using pretrainfinetune paradigm context language model convolutional model competitive transformer pretrained paper investigates research question present several interesting finding across extensive set experiment datasetstasks find cnnbased pretrained model competitive outperform transformer counterpart certain scenario albeit caveat overall finding outlined paper suggest conflating pretraining architectural advance misguided advance considered independently believe research pave way healthy amount optimism alternative architecture
paper present three electronic collection polarity item negative polarity item romanian ii negative polarity item german iii positive polarity item german presented collection part linguistic resource lexical unit highly idiosyncratic occurrence pattern motivation collecting documenting polarity item provide solid empirical basis linguistic investigation expression databe provides general information collected item specifies syntactic property describes environment license given item licensing context example various corpus internet introduced finally type polarity negative positive class superstrong strong weak open associated given item specified database encoded xml available via internet offering dynamic flexible access
paper present two annotated corpus word alignment japanese english annotated top iwslt ntcir corpus iwslt corpus domain travel conversation ntcir corpus domain patent annotated first sentence pair iwslt corpus first sentence pair ntcir corpus mentioned annotation guideline present two evaluation algorithm use handannotated corpus although one wellknown algorithm word alignment researcher one novel intends evaluate mapbased word aligner okita et al b
research situated space existing nlp capability us educational context analyze oral reading data collected deployed automated speech analysis software consider result automated speech analysis interpreted used inform ideation design new feature feedback learner teacher analysis show detail system performance detail context use significantly impact ideation process
order extract meaningful phrase corpus e g information retrieval context intensive knowledge domain question respective document generally needed moving new domain language underlying knowledge base model need adapted often timeconsuming laborintensive paper adresses described challenge phrase extraction document different domain language proposes approach use comprehensive lexica therefore easily transferred new domain language effectiveness proposed approach evaluated user generated content document patent domain english german
many application natural language processing nlp grammatically tagged corpus needed thus part speech po tagging high importance domain nlp many tagger designed different approach reach high performance accuracy tagger usually deal interword relation make use lexicon paper present new tagging algorithm hybrid approach algorithm combine feature probabilistic rulebased tagger tag persian unknown word contrast many tagging algorithm algorithm deal internal structure word need built knowledge introduced tagging algorithm domain independent us morphological rule algorithm po tag assigned unknown word probability show accuracy assigned po tag although tagger proposed persian adapted language applying morphological rule
crucial step deciphering text identify set character used write requires grouping character token according visual contextual feature challenging human analyst number token underlying type large prior work shown process automated clustering dense representation character image task call script clustering work present novel architecture exploit varying degree contextual visual information learn representation use script clustering evaluate range modern ancient script find model produce representation effective script recovery current stateoftheart despite using textasciitilde many parameter analysis fruitfully applies model assess hypothesis character inventory partiallydeciphered protoelamite script
crowdsourcing frequently employed quickly inexpensively obtain valuable linguistic annotation rarely used parsing likely due perceived difficulty task limited training available worker paper present best knowledge first published use mechanical turk similar platform crowdsource parse tree pay turkers construct unlabeled dependency tree english sentence using interactive graphical dependency tree editor collecting annotation per sentence despite requiring training several prolific worker meet exceed attachment agreement penn treebank ptb portion data furthermore ptb sentence least one turker produce perfect parse thus find supported simple graphical interface people presumably prior experience achieve surprisingly high degree accuracy task facilitate research aggregation technique complex crowdsourced annotation publicly release annotated corpus
paper describes collect transcription large set arabic broadcast news speech data total hour data transcribed transcription factor transcribing broadcast news data reduced using method quick rich transcription qrtr well reducing number quality control performed data data collected several arabic tv radio source modern standard arabic dialectal arabic orthographic transcription included segmentation speaker turn topic sentence unit type minimal noise markup transcript produced part gale project
neural machine translation significantly pushed forward quality field however remaining big issue output translation one fairness neural model trained large text corpus contain bias stereotype consequence model inherit social bias recent method shown result reducing gender bias natural language processing tool word embeddings take advantage fact word embeddings used neural machine translation propose method equalize gender bias neural machine translation using representation specifically propose experiment analyze integration two debiasing technique glove embeddings transformer translation architecture evaluate proposed system wmt englishspanish benchmark task showing gain one bleu point gender bias evaluation generate test set occupation show proposed system learns equalize existing bias baseline system
order improve symbiosis machine translation mt system posteditor enough know output one system better output another system finegrained error analysis needed provide information type location error occurring mt corresponding error occurring postediting pe article report finegrained translation quality assessment approach applied machine translatedtexts postedited version text made student posteditors linking error corresponding source textpassage possible identify passage problematic mt pe passage problematic even pe method provides rich data origin impact error used improve posteditor training well machine translation system present result pilot experiment postediting newspaper article highlight advantage approach
paper explores dutch diary fragment written family coach social sector analysed automatically using machine learning technique quantitatively measure impact social coaching focus lay two task determining sentiment fragment contains sentiment analysis investigating fundamental social right education employment legal aid etc addressed fragment train test new algorithm dataset consisting dutch diary fragment used fragment manually labelled sentiment applicable fundamental social right sentiment analysis model trained classify fragment three class negative neutral positive finetuning dutch pretrained bidirectional encoder representation transformer bertje de vries et al language model surpassed classic algorithm correctly classifying fragment sentiment analysis considered good result technique also achieved best result identification fundamental right every fragment three likely fundamental right given output way present fundamental right correctly recognised knowledge first try extract social right written text help natural language processing technique
describe system developed team national university singapore chineseenglish btec task iwslt evaluation campaign adopted stateoftheart phrasebased statistical machine translation approach focused experiment different chinese word segmentation standard official submission trained separate system segmenter combined output subsequent reranking step given small size training data retrained system development data tuning evaluation result show strategy yield sizeable consistent improvement translation quality
hashtags creative label used microblogs characterize topic messagediscussion regardless use originally intended hashtags used mean cluster message similar content first hashtags created spontaneous highly dynamic way user multiple language topic associated different hashtags conversely hashtag may refer different topic different time period second contrary common word hashtag disambiguation complicated fact sense catalog eg wikipedia wordnet available furthermore hashtag label difficult analyze often consist acronym concatenated word forth common way determine meaning hashtags analyze context pointed hashtags multiple variable meaning article propose temporal sense clustering algorithm based idea semantically related hashtags similar synchronous usage pattern
paper present chinese spelling check approach based language model combined string match algorithm treat problem resulted influence caused cantonese mother tone ngrams first used detecting probability sentence constructed writer string matching algorithm called knuthmorrispratt kmp algorithm used detect correct error according experimental result proposed approach detect error provide corresponding correction
paper describes system automatically classifying adverse effect mention tweet developed task social medium mining health application smmh shared task developed system based lstm neural network inspired excellent result obtained deep learning classifier last edition task network trained along twitter glove pretrained word embeddings
often sentence correct news either made biased towards particular person group person party maybe distorted add sentiment importance engaged reader often able extract inherent meaning synthetic sentence bengali news content synthetic sentence presented rich way usually becomes difficult identify synthetic part used machine learning algorithm classify bengali news sentence synthetic legitimate used rulebased postprocessing model finally developed voting based combination model build hybrid model bengali synthetic sentence identification new task therefore could compare existing work field identification type sentence may used improve performance identifying fake news satire news thus identifying molecular level biasness news article
question answer generation qag effective data augmentation technique improve accuracy question answering system especially lowresource domain recent pretrained large language modelbased qag method made substantial progress face critical issue redundant qa pair generation affecting downstream qa system implicit diversity technique sampling diverse beam search proven effective solution often yield smaller diversity present explicit diversity condition qag focusing spatial aspect question type entity substantially increasing diversity qa generation work emphasizes need explicit diversity condition generating diverse questionanswer synthetic data showing significant improvement downstream qa task existing implicit diversity technique particular generated qa pair explicit diversity condition result average exact match f improvement implicit sampling technique squaddu work emphasizes need explicit diversity condition even lowresource datasets subjqa average qa performance improvement textasciitilde em
large language model encode impressively broad world knowledge parameter however knowledge static language model fall date limiting model effective shelf life online finetuning reduce degradation find naively finetuning stream document lead low level information uptake hypothesize online finetuning sufficiently attend important information gradient signal important token representing factual information drowned gradient inherently noisy token suggesting dynamic contextaware learning rate may beneficial therefore propose learning token upweight metatrain small autoregressive model reweight language modeling loss token online finetuning objective maximizing outofdate base questionanswering model ability answer question document single weighted gradient step call approach contextaware metalearned loss scaling camel across three different distribution document experiment find camel provides substantially improved information uptake stream thousand document compared standard finetuning baseline heuristic reweighting token loss
order nlp technology widely applicable fair useful need serve diverse set speaker across world language equitable ie unduly biased towards particular language inclusive user particularly lowresource setting compute constraint common paper propose evaluation paradigm assesses nlp technology across three dimension diversity inclusion received attention recent literature equity currently unexplored propose address gap using gini coefficient wellestablished metric used estimating societal wealth inequality using paradigm highlight distressed state current technology indian language linguistically large diverse set varied speaker population across three dimension improve upon metric demonstrate importance regionspecific choice model building dataset creation importantly propose novel generalisable approach optimal resource allocation finetuning finally discus step mitigate bias encourage community employ multifaceted evaluation building linguistically diverse equitable technology
typological knowledge base kb wals dryer haspelmath contain information linguistic property world language shown useful downstream application including crosslingual transfer learning linguistic probing major drawback hampering broader adoption typological kb sparsely populated sense language annotation feature skewed feature wide coverage typological feature often correlate one another possible predict thus automatically populate typological kb also focus shared task overall task attracted submission team successful method make use feature correlation however error analysis reveals even strongest submitted system struggle predicting feature value language feature known
following idea one translation per discourse paper aim improve translation consistency via documentlevel translation repair docrepair ie automatic postediting translation document end propose lexical translation inconsistencyaware docrepair explicitly model translation inconsistency first locate inconsistency automatic translation provide translation candidate inconsistency finally propose latticelike input properly model inconsistent token phrase candidate experimental result three documentlevel translation datasets show based gtransformer stateoftheart documenttodocument docdoc translation model docdoc docrepair achieves significant improvement translation quality bleu score also greatly improves lexical translation consistency
biomedical relation extraction aiming automatically discover highquality semantic relation entity free text becoming vital step automated knowledge discovery pretrained language model achieved impressive performance various natural language processing task including relation extraction paper perform extensive empirical comparison encoderonly transformer encoderdecoder transformer specifically ten public biomedical relation extraction datasets study relation extraction task four major biomedical task namely chemicalprotein relation extraction diseaseprotein relation extraction drugdrug interaction proteinprotein interaction also explore use multitask finetuning investigate correlation among major biomedical relation extraction task report performance micro fscore using biobert pubmedbert demonstrating multitask learning improve performance biomedical relation extraction task
present comprehensive computational study underinvestigated phenomenon personal name compound pncs german willkommensmerkel welcomemerkel prevalent news social medium political discourse pncs hypothesized exhibit evaluative function reflected positive negative perception compared respective personal full name angela merkel model pncs corresponding full name discourse level show pncs bear evaluative nature captured variety computational method specifically assess valence information whether pnc positively negatively evaluative person name applying comparing two approach using valence norm ii pretrained language model plms enrich data personal domainspecific extralinguistic information perform range regression analysis revealing factor including compound modifier valence domain political party membership influence pnc evaluated
present system automating semantic role labelling hindienglish codemixed tweet explore issue posed noisy user generated codemixed social medium data also compare individual effect various linguistic feature used system proposed model step system automated labelling give overall accuracy argument classification marking increase existing rulebased baseline model first attempt building statistical semantic role labeller hindienglish codemixed data best knowledge
existing study semantic parsing focus mapping naturallanguage utterance logical form lf one turn however natural language may contain ambiguity variability difficult challenge work investigate interactive semantic parsing framework explains predicted lf step step natural language enables user make correction naturallanguage feedback individual step focus question answering knowledge base kbqa instantiation framework aiming increase transparency parsing process help user trust final answer construct inspired crowdsourced dialogue dataset derived complexwebquestions dataset experiment show framework potential greatly improve overall parse accuracy furthermore develop pipeline dialogue simulation evaluate framework wrt variety stateoftheart kbqa model without crowdsourcing effort result demonstrate framework promise effective across model
morphological complexity language differs widely change time pathway change often driven interplay multiple competing factor hard disentangle focus paradigmatic scenario language change reduction morphological complexity latin towards romance language establish causal explanation phenomenon employ three line evidence analysis parallel corpus measure complexity word actual language production application nlp tool tease apart contribution inflectional morphology word complexity experimental data artificial language learning illustrate learning pressure play morphology simplifies three line evidence converge show pressure associated imperfect language learning good candidate causally explain reduction morphological complexity latintoromance scenario generally argue combining corpus computational experimental evidence way forward historical linguistics linguistic typology
seqseq model demonstrated incredible effectiveness large variety application however recent research shown inappropriate language training sample welldesigned testing case induce seqseq model output profanity output may potentially hurt usability seqseq model make endusers feel offended address problem propose training framework certified robustness eliminate cause trigger generation profanity proposed training framework leverage merely short list profanity example prevent seqseq model generating broader spectrum profanity framework composed patterneliminating training component suppress impact language pattern profanity training set triggerresisting training component provide certified robustness seqseq model intentionally injected profanitytriggering expression test sample experiment consider two representative nlp task seqseq applied ie style transfer dialogue generation extensive experimental result show proposed training framework successfully prevent nlp model generating profanity
digitised cultural heritage ch item usually short description lack rich contextual information wikipedia article contrary include indepth description link related article motivate enrichment ch item information wikipedia paper explore feasibility finding matching article wikipedia given cultural heritage item manually annotated random sample item europeana performed qualitative quantitative study issue problem arise showing kind ch item different need nuanced definition matching article mean addition test wellknown wikification aka entity linking algorithm task result indicate substantial number item effectively linked corresponding wikipedia article
work use sentence similarity lens investigate representation meaning graph v vector semantic textual similarity data examine similarity metric based vector alone sentencebert bertscore fare compared metric based amr graph smatch smatch quantitative qualitative analysis show amrbased metric better capture meaning dependent sentence structure also distracted structural differenceswhereas bertbased metric represent finergrained meaning individual word often fail capture ordering effect word within sentence suffer interpretability problem finding contribute understanding approach semantic representation motivate distinct use case graph vectorbased representation
paper introduces topicnet new python module topic modeling package distributed mit license focus bringing additive regularization topic modelling artm nonspecialists using generalpurpose highlevel language module feature include powerful model visualization technique various training strategy semiautomated model selection support userdefined goal metric modular approach topic model training source code documentation available urlhttpsgithubcommachineintelligencelaboratorytopicnet
addressing task converting natural language sql query several semantic syntactic challenge becomes increasingly important understand remedy point failure performance semantic parsing system improve explore semantic parse correction natural language feedback proposing new solution built success autoregressive decoder texttosql task separating semantic syntactic difficulty task show accuracy texttosql parser boosted one turn correction natural language additionally show tbase model capable correcting error tlarge model zeroshot crossparser setting
topic modeling widely used discovering latent semantic structure document existing method learn topic flat structure although probabilistic model generate topic hierarchy introducing nonparametric prior like chinese restaurant process method data scalability issue study develop treestructured topic model leveraging nonparametric neural variational inference particularly latent component stickbreaking process first learned document affiliation latent component modeled dependency matrix network layer utilizing network structure efficiently extract treestructured topic hierarchy reasonable structure low redundancy adaptable width experiment realworld datasets validate effectiveness method
present framework generating natural language description structured data table problem come category datatotext natural language generation nlg modern datatotext nlg system typically use endtoend statistical neural architecture learn limited amount taskspecific labeled data therefore exhibit limited scalability domainadaptability interpretability unlike system modular pipelinebased approach require taskspecific parallel data rather relies monolingual corpus basic offtheshelf nlp tool make system scalable easily adaptable newer domain system utilizes threestaged pipeline convert entry structured data canonical form ii generates simple sentence atomic entry canonicalized representation iii combine sentence produce coherent fluent adequate paragraph description sentence compounding coreference replacement module experiment benchmark mixeddomain data set curated paragraph description table reveals superiority system existing datatotext approach also demonstrate robustness system accepting popular data set covering diverse data type knowledge graph keyvalue map
excessive pretraining cost arouses need improve efficiency considerable effort made train bert progressivelystart inferior lowcost model gradually increase computational complexity objective help advance understanding transformer growth discover principle guide progressive training first find similar network architecture selection transformer growth also favor compound scaling specifically existing method conduct network growth single dimension observe beneficial use compound growth operator balance multiple dimension eg depth width input length model moreover explore alternative growth operator dimension via controlled comparison give practical guidance operator selection light analysis proposed method compoundgrow speed bert pretraining base large model respectively achieving comparable performance
generic word embeddings trained largescale generic corpus domain specific d word embeddings trained data domain interest paper proposes method combine breadth generic embeddings specificity domain specific embeddings resulting embeddings called domain adapted da word embeddings formed first aligning corresponding word vector using canonical correlation analysis cca related nonlinear kernel cca kcca combining via convex optimization result evaluation sentiment classification task show da embeddings substantially outperform generic d embeddings used input feature standard stateoftheart sentence encoding algorithm classification
pretrained language model plms achieved remarkable performance gain across numerous downstream task natural language understanding various chinese plms successively proposed learning better chinese language representation however current model use chinese character input able encode semantic information contained chinese word recent pretrained model incorporate word character simultaneously usually suffer deficient semantic interaction fail capture semantic relation word character address issue propose simple yet effective plm clower adopts contrastive learning word character representation particular clower implicitly encodes coarsegrained information ie word finegrained representation ie character contrastive learning multigrained information clower great value realistic scenario since easily incorporated existing finegrained based plms without modifying production pipeline extensive experiment conducted range downstream task demonstrate superior performance clower several stateoftheart baseline
semantic parser critically rely accurate highcoverage lexicon however traditional semantic parser usually utilize annotated logical form learn lexicon often suffer lexicon coverage problem paper propose graphbased semisupervised learning framework make use large text corpus lexical resource framework first construct graph phrase similarity model learned utilizing many text corpus lexical resource next graph propagation algorithm identifies label distribution unlabeled phrase labeled one evaluate approach two benchmark webquestions free result show datasets method achieves substantial improvement comparing base system utilize learned lexicon gain competitive result comparing stateoftheart system
propose software architecture designed ease implementation dialogue system modular architecture conversational agent maca us plugnplay style allows quick prototyping thereby facilitating development new technique reproduction previous work architecture separate domain conversation agent dialogue strategy easily extended multiple domain maca provides tool host dialogue agent amazon mechanical turk mturk data collection allows processing source training data current version framework already incorporates several domain existing dialogue strategy recent literature
endtoend neural datatotext dt generation recently emerged alternative pipelinebased architecture however faced challenge generalizing new domain generating semantically consistent text work present datatuner neural endtoend datatotext generation system make minimal assumption data representation target domain take twostage generationreranking approach combining finetuned language model semantic fidelity classifier component learnt endtoend without needing datasetspecific heuristic entity delexicalization postprocessing show datatuner achieves state art result automated metric across four major dt datasets ldct webnlg viggo cleaned ee fluency assessed human annotator nearing exceeding humanwritten reference text generated text better semantic fidelity state art datasets demonstrate modelbased semantic fidelity scorer better assessment tool compared traditional heuristicbased measure semantic accuracy
prompt tuning one effective solution adapting fixed pretrained language model plm various downstream task especially input sample however security issue eg trojan attack prompt tuning data sample wellstudied transferring established data poisoning attack directly fewshot prompt tuning present multiple challenge one significant issue poisoned imbalance issue nontarget class sample added target class resulting greater number targetclass sample compared nontarget class issue critical regular tuning significantly hamper fewshot prompt tuning making difficult simultaneously achieve high attack success rate asr maintain clean data accuracy cda additionally fewshot prompting prone overfitting term asr cda paper introduce trojfsp method designed address challenge solve poisoned imbalance issue develop targetclass shrink tcshrink technique aim equalize number poisoning sample combat overfitting employ selective token poisoning technique boost attack performance furthermore introduce trojantrigger attention objective function amplify attention poisoned trojan prompt trigger experiment show trojfsp achieves asr maintaining negligible decrease cda across various plms datasets source code trojfsp available httpsgithubcomucfmlresearchtrojfsp
paper describe system proposed milanlp team multimedia automatic misogyny identification mami challenge use perceiver io multimodal late fusion unimodal stream address subtasks b build unimodal embeddings using vision transformer image roberta text transcript enrich input representation using face demographic recognition image captioning detection adult content web entity best knowledge work first use perceiver io combining text image modality proposed approach outperforms unimodal multimodal baseline
existing tool question answering qa challenge limit use practice complex set integrate existing infrastructure offer configurable interactive interface cover full set subtasks frequently comprise qa pipeline query expansion retrieval reading explanationsensemaking help address issue introduce neuralqa usable library qa large datasets neuralqa integrates well existing infrastructure eg elasticsearch instance reader model trained huggingface transformer api offer helpful default qa subtasks introduces implement contextual query expansion cqe using masked language model mlm well relevant snippet relsnip method condensing large document smaller passage speedily processed document reader model finally offer flexible user interface support workflow research exploration eg visualization gradientbased explanation support qualitative inspection model behaviour large scale search deployment code documentation neuralqa available open source github
present outcome multimodal figurative language shared task held th workshop figurative language processing figlang colocated naacl task utilized vflute dataset comprised image text pair use figurative language includes detailed textual explanation entailment contradiction relationship pair challenge participant develop model capable accurately identifying visual entailment relationship multimodal instance generating persuasive freetext explanation result showed participant model significantly outperformed initial baseline automated human evaluation also provide overview system submitted analyze result evaluation participating system outperformed llavazs baseline provided u fscore
paper present active approach annotate lexical semantic label italian corpus conversational humanhuman wizardofoz dialogue procedure consists use machine learner assist human annotator labeling task computer assisted process engages human annotator check correct automatic annotation rather starting annotation unannotated data active learning procedure combined annotation error detection control reliablity annotation goal converging fast possible reliable automatic annotation minimizing human effort follow active learning paradigm selects annotation informative training example required achieve better level performance show procedure allows quickly converge correct annotation thus minimize cost human supervision
paper survey first threeyear phase project national research council canada developing software assist indigenous community canada preserving language extending use project aimed work within empowerment paradigm collaboration community fulfillment goal central since many technology developed response community need project ended collection diverse subprojects including creation sophisticated framework building verb conjugators highly inflectional polysynthetic language kanyenkeha iroquoian language family release probably largest available corpus sentence polysynthetic language inuktut aligned english sentence experiment machine translation mt system trained corpus free online service based automatic speech recognition asr easing transcription bottleneck recording speech indigenous language language software implementing text prediction readalong audiobooks indigenous language several subprojects
automated storytelling long captured attention researcher ubiquity narrative everyday life best humancrafted story exhibit coherent plot strong character adherence genre attribute current statesoftheart still struggle produce even using transformer architecture paper analyze work story generation utilize machine learning approach address story generation controllability incorporate commonsense knowledge infer reasonable character action generate creative language
author mohamed abdellatif ahmed elgammal gitlab url urlhttpsgitlabcomabdollatiflrecapp commit hash fbddbdceffedff tag name split dataset file md aeedacedacdc dataset url urlhttpsdrivegooglecomfiledcvhuqhgfvizupfidzreemsgmmviewuspsharing
recent model arabic topic classification leveraged finetuning existing pretrained transformer model targeted limited number category recently advance automated ml generative model introduced novel potential task approach work english question whether perform well lowresourced language arabic particular paper present arboneclass novel arabic dataset extended topic class set covering modern book social science humanity along newspaper article ii set topic classifier built finetuned open llm model build argtclass compared performance best model built vertex ai google automlho autotrainhuggingface argtclass outperformed vertexai automl model reasonably similar autotrain model
learning mapping word embeddings two language given dictionary important problem several application common mapping approach using orthogonal matrix orthogonal procrustes analysis pa algorithm applied find optimal orthogonal matrix solution restricts expressiveness translation model may result suboptimal translation propose natural extension pa algorithm us multiple orthogonal translation matrix model mapping derive algorithm learn multiple matrix achieve better performance bilingual word translation task crosslingual word similarity task compared single matrix baseline also show multiple matrix model multiple sens word
neural machine learning model successfully model language similar training distribution highly susceptible degradation distribution shift occurs many practical application processing outofdomain ood text attributed shortcut learning relying weak correlation arbitrary large context propose method based ood detection random network distillation allow autoregressive language model automatically disregard ood context inference smoothly transitioning towards less expressive robust model data becomes ood retaining full context capability operating indistribution apply method gru architecture demonstrating improvement multiple language modeling lm datasets
paper describe participation semeval task emocontext shared task contextual emotion detection text propose three layer model generic multipurpose approach without task specific optimization achieve competitive result f score emocontext task describe development strategy detail along exposition result
present biomedcurator web application extract structured data scientific article pubmed clinicaltrialsgov biomedcurator us stateoftheart natural language processing technique fill field preselected domain expert relevant biomedical area biomedcurator web application includes text generation based model relation extraction entity detection recognition text classification model extracting several field information retrieval external knowledge base retrieve id patternbased extraction approach extract several field using regular expression pubmed clinicaltrialsgov datasets evaluation result show different approach biomedcurator web application system effective automatic data curation biomedical domain
research spoken language become visual year fundamental applied research progressively included gesture gaze facial expression corpus multimodal conversational speech rare frequently difficult use due privacy copyright restriction freely available annotated corpus presented gratis libre high quality video recording facetoface conversational speech annotation include orthography po tag automatically generated phoneme transcription word boundary addition labeling simple conversational function gaze direction performed within bound law everything done remove copyright use restriction annotation processed rdbms table allow sql query direct connection statistical software experience would like advocate formulation best practises legal handling database storage recording annotation
impersonal sentence russian traditionally construed consist predicate ever since first russian grammar compiled continued pose problem grammarian paper intended review evaluation type socalled impersonal sentence russian language investigation sentence conducted term relationship basic kernel sentence paper attempt define origin impersonal sentence ie sentence might derived within framework generative grammar set rule possessing maximal simplicity maximal generative power longrange aim investigation involves efficient manipulation sentence recognition device russianenglish mt
although automatic speech recognition asr system achieved humanlike performance language majority world language usable system due lack large speech datasets train model crosslingual transfer attractive solution problem lowresource language potentially benefit higherresource language either transfer learning jointly trained multilingual model problem crosslingual transfer well studied asr however recent advance self supervised learning opening avenue unlabeled speech data used multilingual asr model pave way improved performance lowresource language paper survey state art multilingual asr model built crosslingual transfer mind present best practice building multilingual model research across diverse language technique discus open question provide recommendation future work
question answering identification short accurate answer user question longstanding challenge widely studied last decade open domain however still requires effort biomedical domain paper describe participation phase b task b bioasq challenge using biomedical question answering system system dealing four type question ie yesno factoid list summary based dictionarybased approach generating exact answer yesno question umls metathesaurus term frequency metric extracting exact answer factoid list question bm model umls concept retrieving ideal answer ie paragraphsized summary preliminary result show system achieves good competitive result exact ideal answer extraction task compared participating system
finetuning pretrained language model lm enabled appealing performance diverse array task intriguing taskagnostic property driven shifted focus taskspecific taskagnostic distillation lm taskagnostic computeefficient performancepreserved lm yielded taskagnostic distillation previous study mainly sit distillation either encoderonly lm eg bert decoderonly one eg gpt yet largely neglect distillation encoderdecoder lm eg posit distinguished behavior frustratingly discover existing taskagnostic distillation method fail handle distillation encoderdecoder lm demand explore path uncover path named miniend successfully tackle distillation encoderdecoder lm taskagnostic fashion examine miniend language understanding abstractive summarization result showcase miniend generally effective competitive compared alternative scale miniend distillation b encoderdecoder language model interpolated distillation result imply opportunity challenge distilling large language model eg llama
problem blend formation generative linguistics interesting context neologism quick adoption modern life creative generative process guiding formation blend quality depends multitude factor high degree uncertainty work investigate modern neural network model sufficiently capture recognize creative blend composition process propose recurrent neural network sequencetosequence model evaluated multiple blend datasets available literature propose ensemble neural hybrid model outperforms baseline heuristic model upon evaluation test data
introduce neuspell opensource toolkit spelling correction english toolkit comprises ten different model benchmark naturally occurring misspelling multiple source find many system adequately leverage context around misspelt token remedy train neural model using spelling error context synthetically constructed reverse engineering isolated misspelling ii use richer representation context training synthetic example correction rate improve absolute compared case model trained randomly sampled character perturbation using richer contextual representation boost correction rate another toolkit enables practitioner use proposed existing spelling correction system via simple unified command line well web interface among many potential application demonstrate utility spellcheckers combating adversarial misspelling toolkit accessed neuspellgithubio
recent work shown multilingual neural machine translation nmt model used judge well sentence paraphrase another sentence language thompson post however attempting generate paraphrase model using standard beam search produce trivial copy near copy introduce simple paraphrase generation algorithm discourages production ngrams present input approach enables paraphrase generation many language single multilingual nmt model furthermore amount lexical diversity input output controlled generation time conduct human evaluation compare method paraphraser trained large english synthetic paraphrase database parabank hu et al c find method produce paraphrase better preserve meaning gramatical level lexical diversity additional smaller human assessment demonstrate approach also work two nonenglish language
paraphrasing promising approach data augmentation classification task effect named entity recognition ner investigated systematically due difficulty spanlevel label preservation paper utilize simple strategy annotate entity span generation compare established novel method paraphrasing nlp back translation specialized encoderdecoder model pegasus gpt variant effectiveness improving downstream performance ner across different level gold annotation paraphrasing strength datasets thoroughly explore influence paraphrasers dynamic paraphrasing strength gold dataset size ner performance visualization statistical testing find choice paraphraser greatly impact ner performance one larger gpt variant exceedingly capable generating high quality paraphrase yielding statistically significant improvement ner performance increasing paraphrasing strength paraphrasers show mixed result additionally inline auto annotation generated larger gpt strictly better heuristic based annotation also find diminishing benefit paraphrasing gold annotation increase datasets furthermore paraphrasers promote entity memorization ner proposed gpt configuration performs favorably among compared paraphrasers tested unseen entity memorization reducing paraphrasing strength finally explore mention replacement using gpt provides additional benefit base paraphrasing specific datasets
paper present design construction largescale targetbased sentiment annotation corpus chinese financial news text different existing paragraphdocumentbased annotation corpus study targetbased finegrained sentiment annotation performed company brand financial entity regarded target clause reflecting profitability loss business status financial entity regarded sentiment expression determining polarity based high quality annotation guideline effective quality control strategy corpus targetlevel sentiment annotation constructed paragraph chinese financial news text based corpus several stateoftheart sentiment analysis model evaluated
several neuralbased metric recently proposed evaluate machine translation quality however resort point estimate provide limited information segment level made worse trained noisy biased scarce human judgement often resulting unreliable quality prediction paper introduce uncertaintyaware mt evaluation analyze trustworthiness predicted quality combine comet framework two uncertainty estimation method monte carlo dropout deep ensemble obtain quality score along confidence interval compare performance uncertaintyaware mt evaluation method across multiple language pair qt dataset wmt metric task augmented mqm annotation experiment varying number reference discus usefulness uncertaintyaware quality estimation without reference flag possibly critical translation mistake
paper novel approach proposed automatically construct parallel discourse corpus dialogue machine translation firstly parallel subtitle data corresponding monolingual movie script data crawled collected internet tag speaker discourse boundary script data projected subtitle data via information retrieval approach order map monolingual discourse bilingual text evaluate mapping result also integrate speaker information translation experiment show proposed method achieve accuracy speaker dialogue boundary annotation speakerbased language model adaptation obtain around bleu point improvement translation quality finally publicly release around k parallel discourse data manual speaker dialogue boundary annotation
processing information locked within clinical health record challenging task remains active area research biomedical nlp work evaluate broad set machine learning technique ranging simple rnns specialised transformer biobert dataset containing clinical note along set annotation indicating whether sample cancerrelated furthermore specifically employ efficient finetuning method nlp namely bottleneck adapter prompt tuning adapt model specialised task evaluation suggest finetuning frozen bert model pretrained natural language bottleneck adapter outperforms strategy including full finetuning specialised biobert model based finding suggest using bottleneck adapter lowresource situation limited access labelled data processing capacity could viable strategy biomedical text mining
word embeddings capture semantic meaning individual word bridge wordlevel linguistic knowledge sentencelevel language representation open problem paper examines whether sentencelevel representation achieved building custom sentence database focusing one aspect sentence meaning three separate semantic aspect whether sentence communicates causal relationship indicates two thing correlated express information knowledge three classifier provide epistemic information sentence content
lexical substitution l aim finding appropriate substitute target word sentence recently l method based pretrained language model made remarkable progress generating potential substitute target word analysis contextual surroundings however method tend overlook preservation sentence meaning generating substitute study explores generate substitute candidate paraphraser generated paraphrase paraphraser contain variation word choice preserve sentence meaning since directly generate substitute via commonly used decoding strategy propose two simple decoding strategy focus variation target word decoding experimental result show method outperform stateoftheart l method based pretrained language model three benchmark
product aspect extraction review critical task ecommerce service understand customer preference pain point aspect phrase extraction sentiment analysis received lot attention clustering aspect phrase assigning human readable name cluster ecommerce review extremely important challenging problem due scale review make human review infeasible paper propose fully automated method clustering aspect word generating human readable name cluster without manually labeled data train transformer based sentence embeddings aware unique ecommerce language characteristic eg incomplete sentence spelling grammar error vernacular etc also train transformer based sequence sequence model generate human readable aspect name cluster model trained using heuristic based distant supervision additionally model used improve extensive empirical testing showed clustering model improves silhouette score compared stateoftheart baseline aspect naming model achieves high rougel score
multilingual crosslingual semantic role labeling srl recently garnered increasing attention multilingual text representation technique become effective widely available recent work attained growing success result gold multilingual benchmark still easily comparable across language making difficult grasp stand example conll standard benchmark multilingual srl languagetolanguage comparison affected fact language dataset differs others size domain set label annotation guideline paper address issue propose unitedsrl new benchmark multilingual crosslingual span dependencybased srl unitedsrl provides expertcurated parallel annotation using common predicateargument structure inventory allowing direct comparison across language encouraging study crosslingual transfer srl release unitedsrl v urlhttpsgithubcomsapienzanlpunitedsrl
article present use nlp technique text mining text analysis develop specific tool allow create linguistic resource related cultural heritage domain aim approach create tool building online knowledge network automatically extracted text material concerning domain particular methodology experimented dividing automatic acquisition text consequently creation reference corpus two phase first phase online document extracted list link provided human expert document extracted web mean automatic spider stored repository text material basis document automatic parser create reference corpus cultural heritage domain relevant information semantic concept extracted corpus second phase semantically relevant element proper name name institution name place relevant term used basis new search strategy text material heterogeneous source case also specialized crawler tpcrawler used work bulk text material available line
neural taskoriented dialogue system often struggle smoothly interface knowledge base work seek address problem proposing new neural dialogue agent able effectively sustain grounded multidomain discourse novel keyvalue retrieval mechanism model endtoend differentiable need explicitly model dialogue state belief tracker also release new dataset dialogue grounded underlying knowledge base span three distinct task incar personal assistant space calendar scheduling weather information retrieval pointofinterest navigation architecture simultaneously trained data domain significantly outperforms competitive rulebased system existing neural dialogue architecture provided domain according automatic human evaluation metric
paper social network extracted literary text social network show frequent character interact similar social behavior two type similarity measure used first applies cooccurrence statistic second exploit cosine similarity different type word embedding vector result evaluated paid microtask crowdsourcing survey experiment suggest specific type word embeddings like wordvec wellsuited task hand specific circumstance literary fiction text
built thesaurus biblical hebrew connection root based phonetic semantic distributional similarity end apply established algorithm find connection headword based existing lexicon digital resource semantic similarity utilize cosinesimilarity tfidf vector english gloss text hebrew headword ernest klein comprehensive etymological dictionary hebrew language reader english well browndriverbriggs hebrew lexicon phonetic similarity digitize part matityahu clark etymological dictionary biblical hebrew grouping hebrew root phonemic class establish phonetic relationship headword klein dictionary distributional similarity consider cosine similarity ppmi vector hebrew root also somewhat novel approach apply wordvec biblical corpus reduced lexeme resulting resource helpful trying understand biblical hebrew also stand good basis program trying process biblical text
diverse headline generation nlp task given news article goal generate multiple headline true content article different among task aim exhibit exploit semantically similar onetomany relationship source news article multiple target headline toward propose novel model called divhsk two componentskeyselect selecting important keywords seqgen finally generating multiple diverse headline keyselect cluster selfattention head last layer pretrained encoder select mostattentive theme general keywords source article clusterspecific keyword set guide seqgen pretrained encoderdecoder model generate diverse yet semantically similar headline proposed model consistently outperformed existing literature strong baseline emerged stateoftheart model also created highquality multireference headline dataset news article
defeasible reasoning mode reasoning conclusion overturned taking account new evidence existing cognitive science literature defeasible reasoning suggests person form mental model problem scenario answering question research goal asks whether neural model similarly benefit envisioning question scenario answering defeasible query approach given question model first create graph relevant influence leverage graph additional input answering question system curious achieves new stateoftheart three different defeasible reasoning datasets result significant illustrates performance improved guiding system think question explicitly model scenario rather answering reflexively
adversarial attack research natural language processing nlp made significant progress designing powerful attack method defence approach however effort sought identify source sample attackable robust ie determine unseen target model sample vulnerable adversarial attack work formally extends definition sample attackabilityrobustness nlp attack experiment two popular nlp datasets four state art model four different nlp adversarial attack method demonstrate sample uncertainty insufficient describing characteristic attackablerobust sample hence deep learning based detector perform much better identifying attackable robust sample unseen target model nevertheless analysis find little agreement sample considered attackablerobust across different nlp attack method explaining lack portability attackability detection method across attack method
aspect querybased summarization recently caught attention generate differentiated summary based user interest however current dataset aspect querybased summarization either focus specific domain relatively small scale contains aspect type limitation hinder exploration direction work take advantage crowdsourcing knowledge wikipedia automatically create highquality largescale opendomain aspectbased summarization dataset named oasum contains million instance around million different aspect million wikipedia page provide benchmark result oasum demonstrate ability diverse aspectbased summarization generation overcome data scarcity problem specific domain also perform zeroshot fewshot finetuning seven downstream datasets specifically zerofewshot finetuning result show model pretrained corpus demonstrates strong aspect queryfocused generation ability compared backbone model dataset pretrained checkpoint publicly available
aim study investigate conversational feedback contain smile laugh firstly propose statistical analysis smile laugh used generic specific feedback corpus french talkininteraction result show smile low intensity preferentially used produce generic feedback high intensity smile laugh preferentially used produce specific feedback secondly based machine learning approach propose hierarchical classification feedback automatically predict presenceabsence smile also type smile according intensityscale low high
sentencelevel text simplification currently evaluated using automated metric human evaluation automatic evaluation combination metric usually employed evaluate different aspect simplification fleschkincaid grade level fkgl one metric regularly used measure readability system output paper argue fkgl used evaluate text simplification system provide experimental analysis recent system output showing fkgl score easily manipulated improve score dramatically minor impact automated metric bleu sari instead using fkgl suggest component statistic along others used posthoc analysis understand system behavior
widely studied task natural language inference nli requires system recognize whether one piece text textually entailed another ie whether entirety meaning inferred current nli datasets model textual entailment relation typically defined sentence paragraphlevel however even simple sentence often contains multiple proposition ie distinct unit meaning conveyed sentence proposition carry different truth value context given premise argue need recognize textual entailment relation proposition sentence individually propose propsegment corpus k proposition annotated expert human raters dataset structure resembles task segmenting sentence within document set proposition classifying entailment relation proposition respect different yet topicallyaligned document ie document describing event entity establish strong baseline segmentation entailment task case study summary hallucination detection documentlevel nli demonstrate conceptual framework potentially useful understanding explaining compositionality nli label
rhetorical role rr prediction predict label sentence legal document regarded emergent task legal document understanding study present novel method rr task exploiting long context representation specifically legal document known long text previous work ability consider inherent dependency among sentence paper propose gnnrr graph neural network rhetorical role prediction able model crossinformation long text furthermore develop multitask learning incorporating label shift prediction lsp segmenting legal document proposed model evaluated semeval task legal eval understanding legal text rr subtask accordingly method achieves top public leaderboard subtask source code available investigationtextbackslashfootnotehttpsgithubcomhiepnhsemevaltaskrhetoricalroles
neural text classification model typically treat output label categorical variable lack description semantics force parametrization dependent label set size hence unable scale large label set generalize unseen one existing joint inputlabel text model overcome issue exploiting label description unable capture complex label relationship rigid parametrization gain unseen label happen often expense weak performance label seen training paper propose new inputlabel model generalizes previous model address limitation compromise performance seen label model consists joint nonlinear inputlabel embedding controllable capacity jointspacedependent classification unit trained crossentropy loss optimize classification performance evaluate model fullresource low zeroresource text classification multilingual news biomedical text large label set model outperforms monolingual multilingual model leverage label semantics previous joint inputlabel space model scenario
recent year several corpus developed vision language task paper intend start discussion annotation referential phenomenon situated dialogue argue still significant room corpus increase complexity visual linguistic domain capture different variety perceptual conversational context addition rich annotation scheme covering broad range referential phenomenon compatible textual task coreference resolution necessary order take advantage corpus consequently several open question regarding semantics reference annotation extent standard textual coreference account situated dialogue genre working two corpus situated dialogue present extension arrau uryupina et al annotation scheme order start discussion
recent advance training multilingual language model large datasets seem shown promising result knowledge transfer across language achieve high performance downstream task however question extent current evaluation benchmark setup accurately measure zeroshot crosslingual knowledge transfer work challenge assumption high zeroshot performance target task reflects high crosslingual ability introducing challenging setup involving instance multiple language extensive experiment analysis show observed high performance multilingual model largely attributed factor requiring transfer actual linguistic knowledge task surfacelevel knowledge specifically observe transferred across language mostly data artifact bias especially lowresource language finding highlight overlooked drawback existing crosslingual test data evaluation setup calling nuanced understanding crosslingual capability multilingual model
paper propose new task assessing quality natural language argument premise wellreasoned argument provide enough evidence accepting rejecting claim although criterion known sufficiency widely adopted argumentation theory empirical study applicability real argument work show human annotator substantially agree sufficiency criterion introduce novel annotated corpus furthermore experiment featurerich svms convolutional neural network achieve accuracy automatically identifying insufficiently supported argument final corpus well annotation guideline freely available encouraging future research argument quality
paper report result first experiment dealing challenge building machine translation system usergenerated content involving complex south slavic language focus translation english imdb user movie review serbian lowresource scenario explore potential limit phrasebased neural machine translation system trained outofdomain clean parallel data news article ii creating additional synthetic indomain parallel corpus machinetranslating english imdb corpus serbian main finding morphology syntax better handled neural approach phrasebased approach even lowresource mismatched domain scenario however situation different lexical aspect especially person name finding also indicates general machine translation person name slavic language especially requireallow transcription investigated systematically
word polysemous multifaceted many shade meaning suggest sparse distributed representation suitable commonly used dense representation express multiple facet present category builder working system show make use sparse representation support multifaceted lexical representation argue set expansion task well suited study meaning distinction since word may belong multiple set different reason membership therefore exhibit performance category builder task showing representation capture time analogy problem ganga egypt voldemort tolkien category builder shown expressive lexical representation outperform dense representation wordvec analogy class despite shown two three input term
semantic parsing map natural language question logical form executed knowledge base answer realworld application performance parser often limited lack training data facilitate zeroshot learning data synthesis widely studied automatically generate paired question logical form however data synthesis method hardly cover diverse structure natural language leading large gap sentence structure synthetic natural question paper propose decompositionbased method unify sentence structure question benefit generalization natural question experiment demonstrate method significantly improves semantic parser trained synthetic data kqa complexwebquestions term exact match accuracy extensive analysis demonstrates method better generalize natural question novel text expression compared baseline besides semantic parsing idea potentially benefit semantic understanding task mitigating distracting structure feature illustrate extend method task sentence embedding learning observe substantial improvement sentence retrieval hit
work study hallucination neural machine translation nmt lie extreme end spectrum nmt pathology firstly connect phenomenon hallucination source perturbation longtail theory feldman present empirically validated hypothesis explains hallucination source perturbation secondly consider hallucination corpuslevel noise without source perturbation demonstrate two prominent type natural hallucination detached oscillatory output could generated explained specific corpuslevel noise pattern finally elucidate phenomenon hallucination amplification popular datageneration process backtranslation sequencelevel knowledge distillation released datasets code replicate result
multilabel fewshot aspect category detection fsacd new subtask aspectbased sentiment analysis aim detect aspect category accurately limited training instance recently dominant work use prototypical network accomplish task employ attention mechanism extract keywords aspect category sentence produce prototype aspect however still suffer serious noise problem due lack sufficient supervised data previous method easily catch noisy word irrelevant current aspect category largely affect quality generated prototype semanticallyclose aspect category usually generate similar prototype mutually noisy confuse classifier seriously paper resort label information aspect tackle problem along proposing novel labeldriven denoising framework ldf extensive experimental result show framework achieves better performance stateoftheart method
several natural language processing nlp task defined classification problem complex form multilabel hierarchical extreme classification item may associated multiple class set thousand possible class organized hierarchy highly unbalanced distribution term class frequency number label per item analyze state art evaluation metric based set formal property define information theoretic based metric inspired information contrast model icm experiment synthetic data case study real data show suitability icm scenario
rapid development singlemodal pretraining prompted researcher pay attention crossmodal pretraining method paper propose unifiedmodal speechunittext pretraining model speechut connect representation speech encoder text decoder shared unit encoder leveraging hiddenunit interface align speech text decompose speechtotext model speechtounit model unittotext model jointly pretrained unpaired speech text data respectively proposed speechut finetuned evaluated automatic speech recognition asr speech translation st task experimental result show speechut get substantial improvement strong baseline achieves stateoftheart performance librispeech asr mustc st task better understand proposed speechut detailed analysis conducted code pretrained model available httpsakamsspeechut
introduce new domain expert mixture demix layer enables conditioning language model lm domain input text demix layer includes collection expert feedforward network specialized domain make lm modular expert mixed added removed initial training extensive experiment autoregressive transformer lm b parameter show demix layer reduce testtime perplexity especially outofdomain data increase training efficiency enable rapid adaptation mixing expert inference using parameterfree weighted ensemble enables better generalization heterogeneous unseen domain also show possible add expert adapt new domain without forgetting older one remove expert restrict access unwanted domain overall result demonstrate benefit domain modularity language model
czeng updated release czechenglish parallel corpus freely available noncommercial research educational purpose release approximately doubled corpus size reaching million sentence pair million token per language importantly carefully filtered data reduce amount nonmatching sentence pair czeng automatically aligned level sentence well word provide plain text representation also automatic morphological tag surface syntactic well deep syntactic dependency parse tree automatic coreference link english czech paper describes key property released resource including distribution text domain corpus data format toolkit handle provided rich annotation also summarize procedure rich annotation incl coreference resolution automatic filtering finally provide suggestion exploiting automatically annotated sentenceparallel corpus
propose novel paradigm grounding comparative adjective within realm color description given reference rgb color comparative term eg lighter darker model learns ground comparative direction rgb space color along vector rooted reference color satisfy comparison model generates grounded representation comparative adjective average accuracy cosine similarity desired direction change vector approach color deltae score compared target color indicating difference small respect human perception approach make use newly created dataset task derived existing labeled color data
machine learning recently used detect hate speech form abusive language online platform however notable weakness machine learning model vulnerability bias impair performance fairness one type annotator bias caused subjective perception annotator work investigate annotator bias using classification model trained data demographically distinct annotator group sample balanced subset data labeled demographically distinct annotator train classifier subset analyze performance similarly grouped test set compare statistically finding show proposed approach successfully identifies bias demographic feature first language age education correlate significant performance difference
paper deal design synthesis database high quality corpusbased speech synthesis system spanish database designed speech synthesis speech conversion expressive speech design follows specification tcstar project applied collect equivalent english mandarin synthesis database sentence corpus selected mainly transcribed speech novel selection criterion phonetic prosodic coverage corpus completed sentence specifically designed cover frequent phrase word two baseline speaker four bilingual speaker recorded recording consist hour speech baseline speaker one hour speech voice conversion bilingual speaker database labelled segmented pitch mark phonetic segmentation done automatically manually supervised database available elra
investigate gptsw generative language model nordic language assess understanding lowresourced faroese language aim demonstrate advantage using languagefamilyspecific generative model augment data related language fewer resource evaluate gptsw prompting faroese english translation zero one fewshot setting assess translation ensemble score consisting arithmetic average bleu semantic similarity score sbert moreover challenge model faroese language understanding capability small dataset curated faroese trick sentence make qualitative comparison model performance respect open ai gpt gpt demonstrating advantage using languagefamilyspecific generative model navigating nontrivial scenario evaluate pipeline thus created use proof concept create automatically annotated faroese semantic textual similarity sts dataset
development hand crafted rule syllabifying word language expensive task paper proposes several datadriven method automatic syllabification word written manipuri language manipuri one scheduled indian language first propose languageindependent rulebased approach formulated using entropy based phonotactic segmentation second project syllabification problem sequence labeling problem investigate effect using various sequence labeling approach third combine effect sequence labeling rulebased method investigate performance hybrid approach various experimental observation evident proposed method outperform baseline rulebased method entropy based phonotactic segmentation provides word accuracy crf sequence labeling approach provides hybrid approach provides word accuracy
metanetu european project aiming supporting language technology european language multilingualism project metanet network excellence cluster project aiming fostering mission meta multilingual europe technology alliance dedicated building technological foundation multilingual european information society paper describe resource produced lab provide synthethic voice using existing h corpus male female spanish speaker voice developed used festival unitselection statisticalbased technology furthermore using data produced supporting research intra interlingual voice conversion four bilingual voice englishspanish developed paper describes resource available meta furthermore evaluation presented compare different synthesis technique influence amount data statistical speech synthesis effect sharing data bilingual voice
finding name people killed police become increasingly important police shooting get public attention police killing detection unfortunately much work literature addressing problem early work field keith etal proposed distant supervision framework based expectation maximization em deal multiple appearance name document however embased framework take full advantage deep learning model necessitating use handdesigned feature improve detection performance work present novel deep learning method solve problem police killing recognition proposed method relies hierarchical lstms model multiple sentence contain person name interest introduce supervised attention mechanism based semantical word list dependency tree upweight important contextual word experiment demonstrate benefit proposed model yield stateoftheart performance police killing detection
increasingly language model machine translation becoming valuable tool help people communicate others diverse cultural background however current language model lack cultural awareness trained data representing culture within dataset present problem context hate speech classification cultural awareness especially critical study aim quantify cultural insensitivity three monolingual korean english arabic hate speech classifier evaluating performance translated datasets two language research revealed hate speech classifier evaluated datasets culture yield significantly lower f score almost addition produce considerably higher false negative rate magnitude five time greater demonstrating extent cultural gap study highlight severity cultural insensitivity language model hate speech classification
due limitation model structure pretraining objective existing visionandlanguage generation model utilize pairwise image text bidirectional generation paper propose duvlg framework unifies visionandlanguage generation sequence generation problem duvlg trained novel dual pretraining task multimodal denoising autoencoder task modality translation task bridge gap image understanding generation design novel commitment loss compare pretraining objective image captioning texttoimage generation datasets result show duvlg yield better performance variant trained unidirectional generation objective variant without commitment loss also obtain higher score compared previous stateoftheart system three visionandlanguage generation task addition human judge confirm model generates real relevant image well faithful informative caption
multilabel clinical text classification automatic icd coding always challenging subject natural language processing due long domainspecific document longtail distribution large label set existing method adopt different model architecture encode clinical note whereas without digging useful connection label model present huge gap predicting performance rare frequent code work propose novel method mining helpful relation different code via relationenhanced code encoder improve rare code performance starting simple code description model reach comparable even better performance model heavy external knowledge proposed method evaluated mimiciii common dataset medical domain outperforms previous stateofart model overall metric rare code performance moreover interpretation result prove effectiveness method code publicly available urlhttpsgithubcomjiaminchenrareicd
recent study shown dual encoder model trained sentencelevel translation ranking task effective method crosslingual sentence embedding however research indicates tokenlevel alignment also crucial multilingual scenario fully explored previously based finding propose dualalignment pretraining dap framework crosslingual sentence embedding incorporates sentencelevel tokenlevel alignment achieve introduce novel representation translation learning rtl task model learns use oneside contextualized token representation reconstruct translation counterpart reconstruction objective encourages model embed translation information token representation compared tokenlevel alignment method translation language modeling rtl suitable dual encoder architecture computationally efficient extensive experiment three sentencelevel crosslingual benchmark demonstrate approach significantly improve sentence embedding code available urlhttpsgithubcomchillingdreamdap
hosting provider play essential role development internet service eresearch infrastructure order promote development service legislator side atlantic ocean introduced safe harbour provision protect service provider category includes hosting provider legal claim eg copyright infringement relevant provision found united state copyright act art directive ec national implementation cornerstone framework passive role hosting provider knowledge content host arrival web however role hosting provider internet changed change reflected court decision reached varying conclusion last year purpose article present existing framework including recent case law u germany france
automated translation assist variety translation need government speeding access information intelligence work helping human translator increase productivity however government entity need mechanism place know whether trust output automated translation solution presentation language weaver present new capability trustscore automated scoring algorithm communicates good automated translation using meaningful metric capability translation automatically assigned score trustscore score would indicate translation unintelligible score would indicate meaning conveyed translated content actionable score approaching higher would indicate meaning nuance carried automatic prediction quality validated testing done across significant number data point different company different type content outlining trustscore work language weaver discus scoring mechanism like trustscore could used translation productivity workflow government assist linguist day day translation work would enable benefit investment automated translation software language weaver would also share trustscore used commercial deployment cost effectively publish information near real time
various temporal knowledge graph kg completion model proposed recent literature model usually contain two part temporal embedding layer score function derived existing static kg modeling approach since approach differ along several dimension including different score function training strategy individual contribution different temporal embedding technique model performance always clear work systematically study six temporal embedding approach empirically quantify performance across wide range configuration experiment gpu hour classify temporal embeddings two class timestamp embeddings timedependent entity embeddings despite common belief latter expressive extensive experimental study show timestamp embeddings achieve onpar even better performance significantly fewer parameter moreover find trained appropriately relative performance difference various temporal embeddings often shrink sometimes even reverse compared prior result example ttranse citation one first temporal kg model outperform recent architecture icews datasets foster research provide first unified opensource framework temporal kg completion model full composability temporal embeddings score function loss function regularizers explicit modeling reciprocal relation combined arbitrarily
due everincreasing complexity income tax law united state number u taxpayer filing tax using tax preparation software henceforth tax software continues increase according u internal revenue service irs fy nearly taxpayer filed individual income tax using tax software given legal consequence incorrectly filing tax taxpayer ensuring correctness tax software paramount importance metamorphic testing emerged leading solution test debug legalcritical tax software due absence correctness requirement trustworthy datasets key idea behind metamorphic testing express property system term relationship one input slightly metamorphosed twinned input extracting metamorphic property irs tax publication tedious timeconsuming process response paper formulates task generating metamorphic specification translation task property extracted tax document expressed natural language contrastive firstorder logic form perform systematic analysis potential limitation incontext learning large language model llm task outline research agenda towards automating generation metamorphic specification tax preparation software
eurovoc multilingual thesaurus built organizing legislative documentary european union institution contains thousand category different level specificity descriptor targeted legal text almost thirty language work propose unified framework eurovoc classification language finetuning modern transformerbased pretrained language model study extensively performance trained model show significantly improve result obtained similar tool jex dataset code finetuned model open sourced together programmatic interface eas process loading weight trained model classifying new document
present finding first shared task multitask learning dravidian language second workshop speech language technology dravidian language task sentence three dravidian language required classified two closely related task namely textitsentiment analyis textbfsa textitoffensive language identification textbfoli task span three dravidian language namely kannada malayalam tamil one first shared task focus multitask learning closely related task especially lowresourced language family dravidian language family total people signed participate task due intricate nature task especially first iteration submission received
accurately interpreting relationship action recipe text essential successful recipe completion explore using abstract meaning representation amr represent recipe instruction abstracting away syntax sentence structure may order recipe action arbitrary way present algorithm split sentencelevel amrs actionlevel amrs individual cooking step approach provides automatic way derive finegrained amr representation action cooking recipe useful tool downstream instructional task
paper describes approach resultsfor semeval task identifying thetoken index mixed text switchfrom human authorship machinegeneratedtext occurs explore two bilstms oneover sentence feature vector predict theindex sentence containing changeand another character embeddings thetext sentence feature compute tokencount mean token length standard deviationof token length count punctuation andspace character various readability scoresword frequency class word partofspeechclass count sentence class countsthe evaluation performed mean absoluteerror mae predicted actualboundary token index competitionresults notably baseline theremay still useful aspect approach
tremendous growth social medium user interacting online conversation led significant growth hate speech affecting people various demographic prior work focus detecting explicit hate speech overt leverage hateful phrase little work focusing detecting hate speech implicit denotes hatred indirect coded language paper present cosyn context synergized neural network explicitly incorporates user conversationalcontext detecting implicit hate speech online conversation cosyn introduces novel way encode external context employ novel context interaction mechanism clearly capture interplay making independent assessment amount information retrieved noisy context additionally carry operation hyperbolic space account scalefree dynamic social medium demonstrate effectiveness cosyn hate speech datasets show cosyn outperforms baseline detecting implicit hate speech absolute improvement range make code available
linking concept named entity knowledge base become crucial natural language understanding task respect recent work shown key advantage exploiting textual definition various natural language processing application however date reliable largescale corpus senseannotated textual definition available research community paper present largescale highquality corpus disambiguated gloss multiple language comprising sense annotation concept named entity unified sense inventory approach construction disambiguation corpus build upon structure large multilingual semantic network stateoftheart disambiguation system first gather complementary information equivalent definition across different language provide context disambiguation combine semantic similaritybased refinement result obtain multilingual corpus textual definition featuring million definition language make freely available urlhttplcluniromaitdisambiguatedglosses experiment open information extraction sense clustering show two stateoftheart approach improve performance integrating disambiguated corpus pipeline
interactive story system often involve dialogue virtual dramatic character however date character dialogue written hand one way ease authoring process semiautomatically generate dialogue based film character extract feature dialogue film character leading role use characterbased feature drive language generator produce interesting utterance paper describes corpus film dialogue collected imsdb archive annotated linguistic structure character archetype extract different set feature using external source liwc sentiwordnet well using written script automation feature extraction also eas process acquiring additional film script briefly show film character represented model learned corpus model distinguished based different category gender film genre applied language generator generate utterance perceived similar intended character model
narrative event prediction aim predict happens sequence event essential modeling sophisticated realworld event existing study focus mining interevents relationship ignoring event happened called circumstance observation event circumstance indicate happen next incorporate event circumstance narrative event prediction propose circevent adopts two multihead attention retrieve circumstance local global level also introduce regularization attention weight leverage alignment event local circumstance experimental result demonstrate circevent outperforms existing baseline analysis demonstrates effectiveness multihead attention module regularization
generating natural language complex constraint principled formulation towards controllable text generation present framework allow specification combinatorial constraint sentence generation propose tsmc efficient method generate high likelihood sentence respect pretrained language model satisfying constraint approach highly flexible requires taskspecific train ing leverage efficient constraint satisfaction solving technique better handle combinatorial constraint tree search algorithm embedded proposal process markov chain monte carlo mcmc explore candidate satisfy constraint compared existing mcmc approach sampling approach better mixing performance experiment show tsmc achieves consistent significant improvement multiple language generation task
machine translation traditionally treat document set independent sentence many genre however document highly structured structure contains information used improve translation quality present preliminary approach document translation us structural feature modify behaviour language model sentencelevel granularity knowledge first attempt incorporate structural information statistical mt experiment structured englishfrench document hansard corpus demonstrate small statistically significant improvement
negation scope resolution key highquality information extraction clinical text far effort make encoders used information extraction negationaware limited english present universal approach multilingual negation scope resolution overcomes lack training data relying disparate resource different language domain evaluate two approach learn resource training combined data training multitask learning setup experiment show zeroshot scope resolution clinical text possible combining available resource improves performance case
mental health problem challenge modern society prevalence predicted increase worldwide recently surge research demonstrated potential automated detection mental health condition mhc social medium post ultimate goal enabling early intervention monitoring populationlevel health outcome realtime progress area research highly dependent availability highquality datasets benchmark corpus however publicly available datasets understanding modelling mhc largely confined english language paper introduce smhdger selfreported mental health diagnosis german largescale carefully constructed dataset mhc detection built highprecision pattern approach proposed english provide benchmark model dataset facilitate research conduct extensive experiment model leverage engineered psycholinguistic feature well bertgerman also examine nuanced pattern linguistic marker characteristic specific mhc
stateoftheart pretrained contextualized model pcm eg bert use task wic wsd evaluate wordincontext representation inherently assumes performance task reflect well model represents coupled word context semantics question assumption presenting first quantitative analysis contextword interaction tested major contextual lexical semantic task achieve run probing baseline masked input propose measure calculate visualize degree context word bias existing datasets analysis performed model human finding demonstrate model usually tested wordincontext semantics way human task help u better understand modelhuman gap specifically pcms existing datasets fall extreme end retrievalbased task exhibit strong target word bias wicstyle task wsd show strong context bias comparison human less biased achieve much better performance word context available masked input recommend framework understanding controlling bias model interpretation future task design
effort crosslingual transfer learning various task present approach utilizing interpolative data augmentation method mixup improve generalizability model partofspeech tagging trained source language improving performance unseen target language experiment ten language diverse structure language root put forward applicability downstream zeroshot crosslingual task
neural machine translation nmt model typically trained heterogeneous data concatenated randomly shuffled however training data equally useful model curriculum training aim present data nmt model meaningful order work introduce twostage training framework nmt finetune base nmt model subset data selected deterministic scoring using pretrained method online scoring considers prediction score emerging nmt model comprehensive experiment six language pair comprising low highresource language wmt shown curriculum strategy consistently demonstrate better quality bleu improvement faster convergence approximately fewer update
urgent need nonintrusive test detect early sign parkinson disease pd debilitating neurodegenerative disorder affect motor control recent promising research focused disease marker evident finemotor behaviour typing work date focused solely timing keypresses without reference linguistic content paper argue identity key combination produced impact handled people pd provide evidence natural language processing method thus help identifying sign disease test performance bidirectional lstm convolutional feature distinguishing people pd agematched control typing english spanish clinic online
detecting previously unseen named entity text challenging task paper describes three initial classifier model built using conditional random field crfs support vector machine svms long shortterm memory lstm recurrent neural network output three classifier used feature train another crf classifier working ensemble fold crossvalidation based training development data emerging rare named entity recognition shared task showed precision recall fscore respectively surface form evaluation crf ensemblebased system achieved precision recall f score applied unseen test data model reached precision recall fscore entity level evaluation corresponding surface form evaluation value
conventional approach korean analysis verb subcategorization generally used lexical knowledge problem arises however given long sentence two verb subcategorization involved sentence noun phrase may taken constituent one verb cause ambiguity paper present approach solving problem using structural pattern acquired statistical method corpus structural pattern processing unit syntactic analysis translation language well collected unique structural pattern korean corpus million word analyzed sentence shown structural pattern improve accuracy korean analysis
existing question answering datasets focus dealing homogeneous information based either text kbtable information alone however human knowledge distributed heterogeneous form using homogeneous information alone might lead severe coverage problem fill gap present hybridqa new largescale questionanswering dataset requires reasoning heterogeneous information question aligned wikipedia table multiple freeform corpus linked entity table question designed aggregate tabular information text information ie lack either form would render question unanswerable test three different model tableonly model textonly model hybrid model combine heterogeneous information find answer experimental result show em score obtained two baseline hybrid model achieve em gap suggests necessity aggregate heterogeneous information hybridqa however hybrid model score still far behind human performance hence hybridqa serve challenging benchmark study question answering heterogeneous information
address problem automatically predicting quality conclusion given set textual premise argument focusing particular task predicting validity novelty argumentative conclusion propose multitask approach jointly predicts validity novelty textual conclusion relying pretrained language model finetuned task training data task scarce costly obtain experimentally investigate impact data augmentation approach improving accuracy prediction compared baseline relies taskspecific data consider generation synthetic data well integration datasets related argument task show especially synthetic data combined classbalancing instancespecific learning rate substantially improves classification result point fscore using training data retrieved related datasets automatically labeling validity novelty combined synthetic data outperforms baseline point fscore
taskagnostic pretraining objective like masked language model corrupted span prediction applicable wide range nlp downstream task raffel et al outperformed taskspecific pretraining objective like predicting extracted gap sentence summarization zhang et al compare three summarization specific pretraining objective task agnostic corrupted span prediction pretraining controlled study also extend study low resource zero shot setup understand many training example needed order ablate taskspecific pretraining without quality loss result show taskagnostic pretraining sufficient case hopefully reduces need costly taskspecific pretraining also report new stateoftheart number two summarization task using model billion parameter optimal beam search length penalty
keyphrase extraction task finding phrase represent important content document main aim keyphrase extraction propose textual unit represent important topic developed document output keyphrases automatic keyphrase extraction method test document typically evaluated comparing manually assigned reference keyphrases output keyphrase considered correct match one reference keyphrases however choice appropriate textual unit keyphrase topic sometimes subjective evaluating exact matching underestimate performance paper present dataset evaluation score assigned automatically extracted keyphrases human evaluator along reference keyphrases manual evaluation used validate new evaluation measure indeed evaluation measure highly correlated manual evaluation appropriate evaluation automatic keyphrase extraction method
present chinese writing correction system learning chinese foreign language system take wrong input sentence generates several correction suggestion also retrieves example chinese sentence english translation helping user understand correct usage certain grammar pattern first available chinese writing error correction system based neural machine translation framework discus several design choice show empirical result support decision
impression section radiology report imaging study summary radiologist reasoning conclusion also aid referring physician confirming excluding certain diagnosis cascade task required automatically generate abstractive summary typical informationrich radiology report task include acquisition salient content report generation concise easily consumable impression section prior research radiology report summarization focused singlestep endtoend model subsume task salient content acquisition fully explore cascade structure explainability radiology report summarization introduce two innovation first design twostep approach extractive summarization followed abstractive summarization second additionally break extractive part two independent task extraction salient sentence keywords experiment english radiology report two clinical site show novel approach lead precise summary compared singlestep twostepwithsingleextractiveprocess baseline overall improvement f score
relation extraction critical task field natural language processing numerous realworld application existing research primarily focus monolingual relation extraction crosslingual enhancement relation extraction yet remains significant gap understanding relation extraction mixlingual codeswitching scenario individual intermix content different language within sentence generating mixlingual content due lack dedicated dataset effectiveness existing relation extraction model scenario largely unexplored address issue introduce novel task considering relation extraction mixlingual scenario called mixre constructing humanannotated dataset mixred support task addition constructing mixred dataset evaluate stateoftheart supervised model large language model llm mixred revealing respective advantage limitation mixlingual scenario furthermore delve factor influencing model performance within mixre task uncover promising direction enhancing performance supervised model llm novel task
present method populating finegrained class eg american jazz musician instance eg charles mingus stateoftheart method tend treat class label single lexical unit proposed method considers individual modifier class label relative head evaluation task reconstructing wikipedia category page demonstrates textgreater point increase auc strong baseline relying widelyused hearst pattern
machine learning deep learning model shown great potential detecting hate speech social medium post study focus homophobia transphobia detection task ltedi english several machine learning model deep neural network dnn bidirectional encoder representation transformer bert model trained provided dataset using different feature vectorization technique secured top rank best macrof score achieved finetuning bert model english test set
use range morphosyntactic feature inspired research register study eg biber neumann translation study eg ilisei et al zanettin kunilovskaya kutuzov reveal association translationese human translation quality translationese understood statistical deviation translation nontranslations baker assumed affect fluency translation rendering foreignsounding clumsy wording structure connection often posited implied study translationese translational variety de sutter et al rarely directly tested feature include frequency selected morphological form category type syntactic structure relation well several overall text measure extracted universal dependency annotation research corpus include englishtorussian professional student translation informational argumentative newspaper text comparable corpus nontranslated russian result indicate lack direct association translationese quality data feature distinguish translation nontranslations near perfect accuracy performance algorithm quality class barely exceeds chance level
introduce uncertain natural language inference unli refinement natural language inference nli shift away categorical label targeting instead direct prediction subjective probability assessment demonstrate feasibility collecting annotation unli relabeling portion snli dataset probabilistic scale item even categorical label differ likely people judge true given premise describe direct scalar regression modeling approach find existing categoricallylabeled nli data used pretraining best model correlate well human demonstrating model capable subtle inference categorical bin assignment employed current nli task
multitask learning mtl aim achieving better model leveraging data knowledge multiple task however mtl always work sometimes negative transfer occurs task especially aggregating loosely related skill leaving open question mtl work previous study show mtl performance improved algorithmic trick however task skill included less well explored work conduct case study financial nlp multiple datasets exist skill relevant domain numeric reasoning sentiment analysis due task difficulty data scarcity financial nlp domain explore aggregating diverse skill multiple datasets mtl work finding suggest key mtl success lie skill diversity relatedness task choice aggregation size shared capacity specifically mtl work well task diverse related size task aggregation shared capacity model balanced avoid overwhelming certain task
present bbrc collection corpus banking regulatory risk different department banco brasil bb individual corpus investment insurance human resource security technology treasury loan accounting fraud credit card payment method agribusiness risk etc annotated binary form expert indicating whether regulatory document contains regulatory risk may require change product process service channel bank department corpus portuguese contain document brazilian regulatory authority financial sector total annotated document mostly half three page long corpus belong natural language processing nlp application production since work also performed binary classification benchmark corpus experiment carried different sampling technique one sought solve intraclass imbalance problem present corpus corpus benchmark used following classifier multinomial naive bayes random forest svm xgboost bertimbau version bert portuguese bbrc downloaded link article
reviewing contract timeconsuming procedure incurs large expense company social inequality afford work propose documentlevel natural language inference nli contract novel realworld application nli address problem task system given set hypothesis obligation agreement may survive termination contract asked classify whether hypothesis entailed contradicting mentioned neutral contract well identifying evidence decision span contract annotated release largest corpus date consisting annotated contract show existing model fail badly task introduce strong baseline model evidence identification multilabel classification span instead trying predict start end token b employ sophisticated context segmentation dealing long document also show linguistic characteristic contract negation exception contributing difficulty task much room improvement
automated speaking assessment asa typically involves automatic speech recognition asr handcrafted feature extraction asr transcript learner speech recently selfsupervised learning ssl shown stellar performance compared traditional method however sslbased asa system faced least three datarelated challenge limited annotated data uneven distribution learner proficiency level nonuniform score interval different cefr proficiency level address challenge explore use two novel modeling strategy metricbased classification loss reweighting leveraging distinct sslbased embedding feature extensive experimental result icnale benchmark dataset suggest approach outperform existing strong baseline sizable margin achieving significant improvement cefr prediction accuracy
technique tactic procedure ttp mapping important difficult task application cyber threat intelligence cti extraction threat report ttps typically expressed semantic form within security knowledge base like mitre attck serving textual highlevel description sophisticated attack pattern conversely attack cti threat report detailed combination natural technical language form presenting significant challenge even security expert establish correlation mapping corresponding ttpsconventional learning approach often target ttp mapping problem classical multiclasslabel classification setting setting hinders learning capability model due large number class ie ttps inevitable skewness label distribution complex hierarchical structure label space work approach problem different learning paradigm assignment text ttp label essentially decided direct semantic similarity two thus reducing complexity competing solely large labeling space order propose neural matching architecture incorporates sampling based learntocompare mechanism facilitating learning process matching model despite constrained resource
demonstrate trainx system named entity linking medical expert combine stateoftheart entity recognition linking architecture flair finetuned biencoders based bert easytouse interface healthcare professional support medical expert annotating training data using active sampling strategy forward informative sample annotator demonstrate model capable linking large knowledge base umls million entity supporting zeroshot case linker never seen entity zeroshot capability help mitigate problem rare expensive training data common issue medical domain
paper present racais approach experiment result conll shared task multilingual parsing raw text universal dependency handle raw text cover tokenization sentence splitting word segmentation tagging lemmatization parsing result reported strict training development testing condition corpus provided shared task used without modification composition train development set
light verb construction lvc hindi highly productive distinguish case nirnay lenaa decision take decide ordinary verbargument combination kaagaz lenaa paper take take paperit shown aid nlp application parsing begum et al machine translation pal et al paper propose lvc identification system using language specific feature hindi show improvement previous workbegum et al build system carry linguistic analysis hindi lvcs using hindi treebank annotation propose two new feature aimed capturing diversity hindi lvcs corpus find model performs robustly across diverse range lvcs result underscore importance semantic feature keeping finding english error analysis also demonstrates classifier used refine lvc annotation hindi treebank make consistent across board
understanding social medium audience becoming increasingly important social medium analysis paper present approach detects various audience attribute including author location demographic behavior interest work variety social medium source multiple language approach implemented within ibm watson analytics social medium creates author profile different analysis domain every day
word embeddings widely used diverse application natural language processing despite extensive research unclear succeed fail capture human judgement semantic relatedness similarity study examine range model experimental datasets showing current embeddings perform reasonably well overall unable account human judgement antonym polysemy suggest word embeddings perform poorly representing polysemy antonymy consider context human make word similarity judgement support show incorporating additional context transformer embeddings using general corpus lexical dictionary significantly improves fit human judgment result provide insight two key inadequacy word embeddings highlight importance incorporating word context representation word meaning accounting contextfree human similarity judgment
propose postprocessing method enriching word representation also vector space using semantic lexicon call extrofitting method consists step follows expanding dimension word vector filling representative value ii transferring semantic knowledge averaging representative value synonym filling expanded dimension two step make representation synonym close together iii projecting vector space using linear discriminant analysis eliminates expanded dimension semantic knowledge experimenting glove find method outperforms faruquis retrofitting word similarity task also report analysis method respect word vector dimension vocabulary size well wellknown pretrained word vector eg wordvec fasttext
paper proposes multispeaker talkingface synthesis system system incorporates voice cloning lipsyncing technology achieve texttotalkingface generation acquiring audio video clip speaker using zeroshot transfer learning addition used opensource corpus train several taiwaneseaccented model proposed using mandarin phonetic symbol bopomofo character embedding synthesizer improve system ability synthesize chineseenglish codeswitched sentence system user create rich application also research technology novel audiovisual speech synthesis field
work revisits topic jointly parsing constituency dependency tree ie produce compatible constituency dependency tree simultaneously input sentence attractive considering two type tree complementary representing syntax original work zhou zhao performs joint parsing inference phase train two separate parser multitask learning framework ie one shared encoder two independent decoder design adhoc dynamic programmingbased decoding algorithm time complexity finding optimal compatible tree pair compared work make progress three aspect adopting much efficient decoding algorithm time complexity exploring joint modeling training phase instead inference phase proposing highorder scoring component promote constituentdependency interaction conduct experiment analysis seven language covering richresource lowresource scenario result analysis show joint modeling lead modest overall performance boost separate modeling substantially improves complete matching ratio whole tree thanks explicit modeling tree compatibility
intended sarcasm understood listener observes text literal meaning violates truthfulness consequently word meaning play essential role specifying sarcasm enriched feature extraction technique proposed capture word meaning context due overlapping feature sarcastic nonsarcastic text cnn model extract local feature combined classdependent statistical embedding sarcastic text contextualized embedding another component bilstm extract long dependency combined nonsarcastic statistical contextualized embeddings work combine classifier us combined highlevel feature cnn bilstm sarcasm detection produce final prediction experimental analysis presented paper show effectiveness proposed method
large language model llm shown remarkable ability generating natural text various task across different domain however applying llm clinical setting still pose significant challenge requires specialized knowledge vocabulary well reliability work propose novel method instruction finetuning adapting llm clinical domain leverage instructionfollowing capability llm availability diverse realworld data source generate instruction input output covering wide spectrum clinical service primary care nursing radiology physician social work use finetune llm evaluated finetuned llm llamacare various clinical task generating discharge summary predicting mortality length stay using automatic human metric demonstrated llamacare surpasses llm baseline predicting clinical outcome producing accurate coherent clinical text also discus challenge limitation llm need addressed widely adopted clinical setting
emotion recognition wellattended problem natural language processing nlp existing work emotion recognition focus general domain case specific domain like fairy tale blog weather twitter etc emotion analysis system domain security social issue technology politics sport etc rare paper create benchmark setup emotion recognition specialised domain first construct corpus tweet english annotated paul ekman six basic emotion anger disgust fear happiness sadness surprise nonemotive class others thereafter propose deep neural framework perform emotion recognition endtoend setting build various model based convolutional neural network cnn bidirectional long short term memory bilstm bidirectional gated recurrent unit bigru propose hierarchical attentionbased deep neural network emotion detection hated also develop multiple system considering different set emotion class system report detailed comparative analysis result experiment show hierarchical attentionbased model achieves best result among considered baseline accuracy
great progress unifying various tabletotext task using single encoderdecoder model trained via multitask learning xie et al however existing method typically encode task information simple dataset name prefix encoder limit effectiveness multitask learning also hinders model ability generalize new domain task seen training crucial realworld application paper propose compositional task configuration set prompt prepended encoder improve crosstask generalization unified model design task configuration explicitly specify task type well input output type show allows model better learn shared knowledge across different task training also allows u control model composing new configuration apply novel inputoutput combination zeroshot manner demonstrate via experiment ten tabletotext task method outperforms unifiedskg baseline noticeable margin indomain zeroshot setting average improvement using tlarge backbone respectively
continual relation extraction cre aim continuously train model data new relation avoiding forgetting old one previous work proved storing typical sample old relation replaying learning new relation effectively avoid forgetting however memorybased method tend overfit memory sample perform poorly imbalanced datasets solve challenge consistent representation learning method proposed maintains stability relation embedding adopting contrastive learning knowledge distillation replaying memory specifically supervised contrastive learning based memory bank first used train new task model effectively learn relation representation contrastive replay conducted sample memory make model retain knowledge historical relation memory knowledge distillation prevent catastrophic forgetting old task proposed method better learn consistent representation alleviate forgetting effectively extensive experiment fewrel tacred datasets show method significantly outperforms stateoftheart baseline yield strong robustness imbalanced dataset
relation detection core component many nlp application including knowledge base question answering kbqa paper propose hierarchical recurrent neural network enhanced residual learning detects kb relation given input question method us deep residual bidirectional lstms compare question relation name via different level abstraction additionally propose simple kbqa system integrates entity linking proposed relation detector make two component enhance experimental result show approach achieves outstanding relation detection performance importantly help kbqa system achieve stateoftheart accuracy singlerelation simplequestions multirelation webqsp qa benchmark
interested problem understanding personal narrative pn spoken written recollection fact event thought pns define emotion carrier speech text segment best explain emotional state narrator segment may span single multiple word containing example verb noun phrase advanced automatic understanding pns requires prediction narrator emotional state also identify event eg loss relative visit grandpa people eg old group high school mate carry emotion manifested personal recollection work proposes evaluates annotation model identifying emotion carrier spoken personal narrative compared text genre news microblogs spoken pns particularly challenging narrative usually unstructured involving multiple subevents character well thought associated emotion perceived narrator work experiment annotating emotion carrier speech transcription ulm stateofmind speech usoms corpus dataset pns german believe resource could used experiment automatic extraction emotion carrier pn task could provide advancement narrative understanding
numerous study demonstrated ability neural language model learn various linguistic property without direct supervision work take initial step towards exploring less researched topic neural model discover linguistic property word gender well rule governing usage propose use artificial corpus generated pcfg based french precisely control gender distribution training data determine condition model correctly capture gender information contrary appears genderbiased
ongoing pandemic heightened need developing tool flag covidrelated misinformation internet specifically social medium twitter however due novel language rapid change information existing misinformation detection datasets effective evaluating system designed detect misinformation topic misinformation detection divided two subtasks retrieval misconception relevant post checked veracity ii stance detection identify whether post agree disagree express stance towards retrieved misconception facilitate research task release covidlies urlhttpsucinlpgithubiocovid dataset expertannotated tweet evaluate performance misinformation detection system different piece covid related misinformation evaluate existing nlp system dataset providing initial benchmark identifying key challenge future model improve upon
adversarial example generation method nlp rely model like language model sentence encoders determine potential adversarial example valid method valid adversarial example fool model attacked determined semantically syntactically valid second model research date counted example error attacked model contend adversarial example may flaw attacked model flaw model determines validity term invalid input secondorder adversarial example propose constraint robustness curve associated metric acc tool evaluating robustness constraint secondorder adversarial example generate curve design adversarial attack run directly semantic similarity model test two constraint universal sentence encoder use bertscore finding indicate secondorder example exist typically less common firstorder adversarial example stateoftheart model also indicate use effective constraint nlp adversarial example bertscore nearly ineffectual code running experiment paper available
stateoftheart dependency representation stanford typed dependency may represent grammatical relation sentence directed possibly cyclic graph querying syntactically annotated corpus grammatical structure represented graph requires graph matching nontrivial task paper present algorithm graph matching tailored property large syntactically annotated corpus implementation algorithm built top popular ims open corpus workbench allowing corpus linguist reuse existing infrastructure evaluation resulting software cwbtreebank show performance real world application web query interface compare favourably implementation rely relational database dedicated graph database time offering greater expressive power query intuitive graphical interface building query graph available via treebankinfo project
spoken audio data interview data scientific instrument used researcher various discipline crossing boundary social science humanity paper closer look portal designed perform speechtotext conversion audio recording automatic speech recognition asr clarin infrastructure within cluster crossdomain eu project sshoc potential value linguistic tool kit processing spoken language recording found uptake webinar topic task addressing audio analysis panel survey data objective contribution show processing interview research instrument opened fascinating fruitful area collaboration social science humanity ssh
amount labeled data train model speech task limited language however data scarcity exacerbated speech translation requires labeled data covering two different language address issue study simple effective approach build speech translation system without labeled data leveraging recent advance unsupervised speech recognition machine translation speech synthesis either pipeline approach generate pseudolabels training endtoend speech translation model furthermore present unsupervised domain adaptation technique pretrained speech model improves performance downstream unsupervised speech recognition especially lowresource setting experiment show unsupervised speechtotext translation outperforms previous unsupervised state art bleu libritrans benchmark covost best system outperform best supervised endtoend model without pretraining two year ago average bleu five xen direction also report competitive result mustc cvss benchmark
previous preneural work structured prediction produced effective supervised clustering algorithm using linear classifier eg structured svm perceptron however exploit representation learning ability neural network would make supervised clustering even powerful ie general clustering pattern learned automatically paper design neural network based latent structured prediction loss transformer model approach supervised clustering tested method task automatically recreating category intent publicly available question intent corpus result show approach delivers f outperforming state art
paper present approach system description social medium mining health application smmh shared task main contribution show effectiveness transfer learning approach like bert ulmfit generalize classification task like identification adverse drug reaction mention reporting personal health problem tweet show use stacked embeddings combined blstmcrf tagger identifying span mentioning adverse drug reaction tweet also show approach perform well even imbalanced dataset comparison undersampling oversampling
present issue development semantic annotation imagact multimodal multilingual ontology action resource structured action concept meant cognitive entity linguistic caption attached concept annotate minimal thematic structure caption possible argument alternation allowed present insight process regard notion thematic structure relationship action concept linguistic expression empirical evidence provided annotation discus nature thematic structure arguing neither property verb property action concept show relation thematic structure semantic variation action verb lexical variation action concept
stateoftheart machine reading comprehension model capable producing answer factual question given piece text however type question requires commonsense knowledge inferred given text passage thus external semantic information could enhance performance model phd research proposal provides brief overview existing machine reading comprehension datasets model outline possible way improvement
moral value commonsense norm shape everyday individual community behavior possibility extract moral attitude rapidly natural language appealing perspective would enable deeper understanding social interaction dynamic individual cognitive behavioral dimension work focus detecting moral content natural language test method corpus tweet previously labeled containing moral value violation according moral foundation theory develop compare two different approach framebased symbolic value detector based knowledge graph ii zeroshot machine learning model finetuned task natural language inference nli task emotion detection final outcome work consists two approach meant perform without need prior training process moral value detection task
present epidbiobert biosurveillance epidemiological document tagger disease surveillance padiweb system model trained padiweb corpus contains news article animal disease outbreak extracted web train classifier discriminate relevant irrelevant document based epidemiological thematic feature content preparation epidemiology information extraction approach proposes new way perform epidemiological document classification enriching epidemiological thematic feature namely disease host location date used input epidemiological document classifier adopt pretrained biomedical language model novel fine tuning approach enriches epidemiological thematic feature find thematic feature rich enough improve epidemiological document classification smaller data set initially used padiweb classifier improves classifier ability avoid false positive alert disease surveillance system understand information encoded epidbiobert experiment impact epidemiology thematic feature classifier ablation study compare biomedical pretrained approach general language model based model finding thematic feature embeddings pretrained general english document rich enough epidemiology classification task model achieves fscore unseen test set improvement point fscore padiweb classifier nearly half training data set
certainty uncertainty fundamental science communication hedge widely used proxy uncertainty however certainty complex construct author expressing degree type aspect uncertainty order give reader certain impression known introduce new study certainty model level aspect certainty scientific finding using new dataset annotated scientific finding demonstrate hedge alone account partial explanation certainty show overall certainty individual aspect predicted pretrained language model providing complete picture author intended communication downstream analysis k scientific finding news scientific abstract demonstrate modeling sentencelevel aspectlevel certainty meaningful area like science communication model datasets used paper released urlhttpsblablablabsiumicheduprojectscertainty
paper present three corpus coreferential annotation person entity portuguese galician spanish contain coreference link several type pronoun including elliptical possessive indefinite demonstrative relative personal clitic nonclitic pronoun nominal phrase including proper noun statistic computed showing distributional aspect coreference journalistic encyclopedic text furthermore paper show importance coreference resolution task information extraction evaluating output open information extraction system annotated corpus corpus freely distributed two format semeval ii brat rapid annotation tool enlarged improved collaboratively
paper outline automated approach annotate mathematical identifier scientific paper process historically laborious costly employ stateoftheart llm including gpt gpt opensource alternative generate dictionary annotating mathematical identifier linking identifier conceivable description assigning definition respective identifier stance based context evaluation metric include conll score coreference cluster quality semantic correctness annotation
keeping track state entity change text dialog unfolds key prerequisite discourse understanding yet systematic investigation ability large language model llm track discourse entity work present task probing extent language model infer final state entity given english description initial state series statechanging operation use task first investigate whether flant gpt gpt track state entity find gpt model pretrained large amount code exhibit ability investigate whether smaller model pretrained primarily text learn track entity finetuning several trainingevaluation split performance degrades complex split find even evaluated different set entity training longer operation sequence finetuned model perform nontrivial entity tracking taken together result suggest language model learn track entity pretraining text corpus alone make capacity surface
article present domaindriven algorithm task term sense disambiguation tsd tsd aim automatically choosing term record term bank best represents meaning term occurring particular context translation environment finding contextually appropriate term record necessary access proper equivalent used target language text term bank termium plus recently published open access repository chosen domainrich resource testing tsd algorithm using english french source target language devise experiment using english term found scientific article show domaindriven tsd algorithm able bring best term record therefore best french equivalent average rank compared baseline random rank
detecting outofdomain ood intent user query essential taskoriented dialogue system previous ood detection study generally work assumption plenty labeled ind intent exist paper focus practical fewshot ood setting labeled ind data massive unlabeled mixed data may belong ind ood new scenario carry two key challenge learning discriminative representation using limited ind data leveraging unlabeled mixed data therefore propose adaptive prototypical pseudolabelingapp method fewshot ood detection including prototypical ood detection framework protoood facilitate lowresourceood detection using limited ind data adaptive pseudolabeling method produce highquality pseudo ood ind label extensive experiment analysis demonstrate effectiveness method fewshot ood detection
social medium tool communication internet expanded great deal recent year expansion offer diverse set user mean communicate freely spontaneously mixed language genre blog message board chat texting video image dialectal arabic pervasive written social medium however current state art tool made modern standard arabic msa fail arabic dialect colaba enables msa user interpret dialect correctly help find arabic colloquial content currently easily searchable accessible msa query colaba team built suite tool offer user ability anonymously capture online unstructured medium content blog comprehend organize validate content informal colloquial genre online communication msa variety arabic dialect dodcombating terrorism technical support officetechnical support working group cttsotswg awarded contract acxiom corporation partner mtiibm columbia university janya wichita state university bring joint expertise address challenge suite several use application support language cultural learning making colloquial arabic intelligible student msa retrieval prioritization triage content analysis finding arabic colloquial dialect term today search engine miss providing appropriate interpretation colloquial arabic opaque current analytics approach identify named entity event topic sentiment enabling improved translation msatrained mt system decrease outofvocabulary term achieved mean colloquial term conversion msa
norm long time evaluate automated summarization task using popular rouge metric although several study past highlighted limitation rouge researcher struggled reach consensus better alternative today one major limitation traditional rouge metric lack semantic understanding relies direct overlap ngrams paper exclusively focus extractive summarization task propose semanticaware ncg normalized cumulative gainbased evaluation metric called semncg evaluating task one fundamental contribution paper demonstrates generate reliable semanticaware ground truth evaluating extractive summarization task without additional human intervention best knowledge work first kind conducted extensive experiment new metric using widely used cnndailymail dataset experimental result show new semncg metric indeed semanticaware show higher correlation human judgement reliable yield large number disagreement original rouge metric suggesting rouge often lead inaccurate conclusion also verified human
chinese grammatical error diagnosis cged natural language processing task nlptea workshop held acl goal task diagnose chinese sentence containing four kind grammatical error model find sentence error chinese grammatical error diagnosis system important tool help chinese learner automatically diagnose grammatical error many scenario however due limitation chinese language characteristic datasets traditional model face problem extreme imbalance positive negative sample disappearance gradient paper propose sequence labeling method based policy gradient lstm model apply task solve problem result show model achieve higher precision score case lower false positive rate fpr convenient optimize model online
one challenge social medium platform facing nowadays hate speech hence automatic hate speech detection increasingly researched recent year particular rise deep learning problem model vulnerability undesirable bias training data investigate impact political bias hate speech classification constructing three politicallybiased data set leftwing rightwing politically neutral compare performance classifier trained show political bias negatively impairs performance hate speech classifier explainable machine learning model help visualize bias within training data result show political bias training data impact hate speech classification become serious issue
common european framework reference cefr guideline describe language proficiency learner scale level description cefr guideline generic across language development automated proficiency classification system different language follow different approach paper explore universal cefr classification using domainspecific domainagnostic theoryguided well datadriven feature report result preliminary experiment monolingual crosslingual multilingual classification three language german czech italian result show monolingual multilingual model achieve similar performance crosslingual classification yield lower comparable result monolingual classification
discus experiment automatic identification bigram multiword expression parallel latvian lithuanian corpus raw corpus lexical association measure lam supervised machine learning ml used due deficit quality lexical resource eg postagger parser tool combining lam ml rather effective language shown nice result lithuanian latvian well combining lam ml achieved precision recall latvian precision recall lithuanian
mixing two language speech text known codemixing form communication user mix word phrase multiple language codemixing common context indian language due presence multilingual society probability existence codemixed sentence almost indian language since india english dominant language social medium textual communication platform participated wmt shared task codemixed machine translation team name cnlpnitspp task prepared synthetic hinglishenglish parallel corpus using transliteration original hindi sentence tackle limitation parallel corpus mainly considered sentence namedentity proper noun available englishhindi parallel corpus addition synthetic bitext data original parallel corpus train set transformerbased neural machine translation model attained recalloriented understudy gisting evaluation rougel score word error rate wer score subtask englishtohinglish subtask hinglishtoenglish test set result respectively
recently researcher found deep lstms trained task like machine translation learn substantial syntactic semantic information input sentence including partofspeech finding begin shed light pretrained representation like elmo cove beneficial neural language understanding model still though yet clear understanding choice pretraining objective affect type linguistic information model learn mind compare four objectiveslanguage modeling translation skipthought autoencodingon ability induce syntactic partofspeech information holding constant quantity genre training data well lstm architecture
consider problem pretraining twostage opendomain question answering qa system retriever reader strong transfer capability key challenge construct large amount highquality questionanswercontext triplet without taskspecific annotation specifically triplet align well downstream task covering wide range domain opendomain application ii linking question semantically relevant context supporting evidence training retriever iii identifying correct answer context training reader previous pretraining approach generally fall short one requirement work automatically construct largescale corpus meet three criterion consulting million reference cited within wikipedia wellaligned pretraining signal benefit retriever reader significantly pretrained retriever lead absolute gain top accuracy pretrained reader entire system improves exact match
answering natural language question table usually seen semantic parsing task alleviate collection cost full logical form one popular approach focus weak supervision consisting denotation instead logical form however training semantic parser weak supervision pose difficulty addition generated logical form used intermediate step prior retrieving denotation paper present tapa approach question answering table without generating logical form tapa train weak supervision predicts denotation selecting table cell optionally applying corresponding aggregation operator selection tapa extends berts architecture encode table input initializes effective joint pretraining text segment table crawled wikipedia trained endtoend experiment three different semantic parsing datasets find tapa outperforms rival semantic parsing model improving stateoftheart accuracy sqa performing par stateoftheart wikisql wikitq simpler model architecture additionally find transfer learning trivial setting wikisql wikitq yield accuracy point stateoftheart
opendomain keyphrase extraction kpe web fundamental yet complex nlp task wide range practical application within field information retrieval contrast document type web page design intended easy navigation information finding effective design encode within layout formatting signal point important information found work propose modeling approach leverage multimodal signal aid kpe task particular leverage lexical visual feature eg size font position microlevel enable effective strategy induction metalevel feature describe page macrolevel aid strategy selection evaluation demonstrates combination effective strategy induction strategy selection within approach kpe task outperforms stateoftheart model qualitative posthoc analysis illustrates feature function within model
significant interest developing evaluation metric accurately estimate quality generated text without aid humanwritten reference text time consuming expensive collect entirely unavailable online application however work demonstrate referencefree metric inherently biased limited ability evaluate generated text argue used measure progress task like machine translation summarization show referencefree metric equivalent using one generation model evaluate another several limitation metric optimized test time find approximate bestpossible output inherently biased toward model similar biased higherquality output including written human therefore recommend referencefree metric used diagnostic tool analyzing understanding model behavior instead measure well model perform task goal achieve high score possible
paper describe process developing multilayer semantic annotation scheme designed extracting information european portuguese corpus news article three level temporal referential semantic role labelling novelty scheme harmonization part iso language resource management semantic annotation framework annotation framework includes set entity structure participant event time set link temporal aspectual subordination objectal semantic role several tag attribute value ensure adequate semantic visual representation news story
formalism lexicalfunctional grammar lfg introduced one first constraintbased grammatical formalism natural language led substantial contribution linguistic literature construction largescale description particular language investigation mathematical property shown without restriction recognition emptiness generation problem undecidable intractable worst case even commonly applied restriction however grammar real language appear invoke full expressive power formalism indicated fact algorithm implementation recognition generation developed runeven broadcoverage grammarsin typically polynomial time article formalizes restriction notation interpretation compatible convention principle implicit informally stated linguistic theory show lfg grammar respect restriction still suitable description natural language equivalent linear contextfree rewriting system allow tractable computation
propose chill crafting highlevel latents approach naturallanguage specification feature linear model chill prompt llm expertcrafted query generate interpretable feature health record resulting noisy label used train simple linear classifier generating feature based query llm empower physician use domain expertise craft feature clinically meaningful downstream task interest without manually extract raw ehr motivated realworld risk prediction task reproducible proxy use mimiciii mimiccxr data standard predictive task eg day readmission evaluate approach find linear model using automatically extracted feature comparably performant model using reference feature provide greater interpretability linear model using bagofwords feature verify learned feature weight align well clinical expectation
previous research show eyetracking data contains information lexical syntactic property text used improve natural language processing model work leverage eye movement feature three corpus recorded gaze information augment stateoftheart neural model named entity recognition ner gaze embeddings corpus manually annotated named entity label moreover show gaze feature generalized word type level eliminate need recorded eyetracking data test time gazeaugmented model ner using tokenlevel typelevel feature outperform baseline present benefit eyetracking feature evaluating ner model individual datasets well crossdomain setting
british sign language bsl complex language vocabulary grammatical structure separate english despite longstanding widespread use deaf community within uk thus far effective tool translating written english bsl overt lack available resource made learning language highly inaccessible people exacerbating communication barrier hearing deaf individual paper introduces rulebased translation system designed ambitious aim creating first web application able translate sentence written english bsl video output also serve learning aid empower development bsl proficiency
several recent paper investigate active learning al mitigating data dependence deep learning natural language processing however applicability al realworld problem remains open question supervised learning practitioner try many different method evaluating validation set selecting model al affords luxury course one al run agent annotates dataset exhausting labeling budget thus given new task opportunity compare model acquisition function paper provides largescale empirical study deep active learning addressing multiple task multiple datasets multiple model full suite acquisition function find across setting bayesian active learning disagreement using uncertainty estimate provided either dropout bayesbybackprop significantly improves iid baseline usually outperforms classic uncertainty sampling
improved prediction combination using weight based training performance stacking multilayer perceptrons build deeper prediction model rtms become rd system general sentencelevel prediction translation score achieve lowest rmse english german nmt qet result documentlevel task compare documentlevel rtm model sentencelevel rtm model obtained concatenation document sentence obtain similar result
large language model llm made significant progress utilizing tool ability limited api availability instability implicit reasoning particularly planning execution involved overcome limitation propose creator novel framework enables llm create tool using documentation code realization creator disentangles abstract tool creation concrete decision execution resulting improved performance evaluate creator math tabmwp benchmark respectively consisting challenging math competition problem diverse tabular content remarkably creator outperforms existing chainofthought programofthought toolusing baseline additionally introduce creation challenge dataset featuring k diverse question emphasize necessity benefit llm tool creation ability research demonstrates leveraging llm tool creator facilitates knowledge transfer llm exhibit varying level tool creation ability enabling adapt diverse situation tool creation ability revolutionizes llm problemsolving paradigm driving u closer next frontier artificial intelligence
following paper present overview current discussion exchange interface area multilingual processing first discusses principle relevant definition interface present state art proposal area text interface translation memory interface terminology exchange approach bottomup ie start existing interface existing requirement intends practical use reflects discussion current multilingual research project ec like otelo aventinus
emotion recognition conversation erc aim detect emotion utterance conversation existing effort generally focus modeling context knowledgesensitive dependency however observed emotion many utterance correctly detected without context external knowledge case blindly leveraging context external knowledge may impede model training based propose novel framework based contrastive learning cl called ckcl including contrastive learning scenario among context knowledge distinguish utterance better vector representation ckcl framework defines context knowledgeindependent utterance positive sample whose predicted result unchanged even masking context knowledge representation otherwise negative sample obtain latent feature reflecting impact degree context external knowledge predicted result thus effectively denoising irrelevant context knowledge training experimental result four datasets show performance ckclbased model significantly boosted outperforms stateoftheart method
present simple yet powerful data augmentation method boosting neural machine translation nmt performance leveraging information retrieved translation memory tm propose test two method augmenting nmt training data fuzzy tm match test dgttm data set two language pair show consistent substantial improvement range baseline system result suggest method promising translation environment sizeable tm available certain amount repetition across translation expected especially considering ease implementation
social medium content changing way people interact share information personal message opinion situation object past experience social medium text short online conversational post comment contain enough information natural language processing nlp tool often accompanied nonlinguistic contextual information including metadata eg user profile social network user interaction user exploiting different type context interaction make automatic processing social medium text challenging research task indeed simply applying traditional text mining tool clearly suboptimal typically tool take account neither interactive dimension particular nature data share property spoken written language special issue contributes deeper understanding role interaction process social medium data new perspective discourse interpretation introduction first provides necessary background understand context linguistic computational linguistic perspective present recent contextbased approach nlp social medium conclude overview paper accepted special issue highlighting believe future direction processing social medium text
computing author intent multimodal data like instagram post requires modeling complex relationship text image example caption might evoke ironic contrast image neither caption image mere transcript instead combinevia called meaning multiplication bateman et al create new meaning complex relation literal meaning text image introduce multimodal dataset instagram post labeled three orthogonal taxonomy authorial intent behind imagecaption pair contextual relationship literal meaning image caption semiotic relationship signified meaning image caption build baseline deep multimodal classifier validate taxonomy showing employing text image improves intent detection compared using image modality demonstrating commonality nonintersective meaning multiplication gain multimodality greatest image caption diverge semiotically dataset offer new resource study rich meaning result pairing text image
crossdocument event coreference resolution cdcr nlp task mention event need identified clustered throughout collection document cdcr aim benefit downstream multidocument application despite recent progress corpus system development downstream improvement applying cdcr shown yet make observation every cdcr system date developed trained tested single respective corpus raise strong concern generalizabilitya musthave downstream application magnitude domain event mention likely exceed found curated corpus investigate assumption define uniform evaluation setup involving three cdcr corpus ecb gun violence corpus football coreference corpus reannotate token level make analysis possible compare corpusindependent featurebased system recent neural system developed ecb although inferior absolute number featurebased system show consistent performance across corpus whereas neural system hitormiss via model introspection find importance event action event time forth resolving coreference practice varies greatly corpus additional analysis show several system overfit structure ecb corpus conclude recommendation achieve generally applicable cdcr system futurethe important evaluation multiple cdcr corpus strongly necessary facilitate future research release dataset annotation guideline system implementation public
automatically evaluating coherence summary great significance enable costefficient summarizer evaluation tool improving coherence selecting highscoring candidate summary many different approach suggested model summary coherence often evaluated using disparate datasets metric make difficult understand relative performance identify way forward towards better summary coherence modelling work conduct largescale investigation various method summary coherence modelling even playing field additionally introduce two novel analysis measure intrasystem correlation bias matrix help identify bias coherence measure provide robustness systemlevel confounders none currently available automatic coherence measure able assign reliable coherence score system summary across evaluation metric largescale language model finetuned selfsupervised task show promising result long finetuning take account need generalize across different summary length
introduce four task designed determine sentence encoders best capture discourse property sentence scientific abstract namely coherence cohesion clause sentence discourse relation within sentence show even contextual encoders bert scibert encodes coherence discourse unit help predict three discourse relation commonly used scientific abstract discus result underline namely discourse relation based particular phrasing allow noncontextual encoders perform well
although path user interest shift knowledge graph kg benefit conversational recommender system cr explicit reasoning kg well considered cr due complex highorder incomplete path propose crfr effectively explicit multihop reasoning kg conversational contextbased reinforcement learning model considering incompleteness kg instead learning single complete reasoning path crfr flexibly learns multiple reasoning fragment likely contained complete path interest shift fragmentsaware unified model designed fuse fragment information itemoriented conceptoriented kg enhance cr response entity word fragment extensive experiment demonstrate crfrs sota performance recommendation conversation conversation interpretability
integration multidocument pretraining objective language model resulted remarkable improvement multidocument downstream task work propose extending idea pretraining generic multidocument model novel crossdocument question answering pretraining objective end given set cluster topicallyrelated document systematically generate semanticallyoriented question salient sentence one document challenge model pretraining answer question peeking topicallyrelated document similar manner model also challenged recover sentence question generated leveraging crossdocument information novel multidocument qa formulation directs model better recover crosstext informational relation introduces natural augmentation artificially increase pretraining data unlike prior multidocument model focus either classification summarization task pretraining objective formulation enables model perform task involve short text generation eg qa long text generation eg summarizationfollowing scheme pretrain model termed qamden evaluate performance across several multidocument task including multidocument qa summarization queryfocused summarization yielding improvement significantly outperforms zeroshot gpt gpt
many realworld application usergenerated input usually contain various noise due speech recognition error caused linguistic variation typographical error typo thus crucial test model performance data realistic input noise ensure robustness fairness however little study done construct benchmark chinese various languagespecific input noise happen real world order fill important gap construct readin chinese multitask benchmark realistic diverse input noise readin contains four diverse task request annotator reenter original test data two commonly used chinese input method pinyin input speech input designed annotation pipeline maximize diversity example instructing annotator use diverse input method editor imes keyboard noise recruiting speaker diverse dialectical group speech noise experiment series strong pretrained language model well robust training method find model often suffer significant performance drop readin even robustness method like data augmentation first largescale attempt creating benchmark noise geared towards usergenerated input believe readin serf important complement existing chinese nlp benchmark source code dataset obtained urlhttpsgithubcomthunlpreadin
research machine learning morphology often involves formulating morphological description directly surface form word established twolevel morphology paradigm requires knowledge underlying structure widely used setting paper propose formalism describing structural relationship word based theory morphology reject notion internal word structure morpheme formalism cover wide variety morphological phenomenon including nonconcatenative one like stem vowel alternation without need workarounds extension furthermore show morphological rule formulated way easily translated fsts enables u derive performant approach morphological analysis generation automatic rule discovery
many machine learning scenario supervision gold label available conse quently neural model trained directly maximum likelihood estimation weak supervision scenario metricaugmented objective employed assign feedback model output used extract supervision signal training present several objective two separate weakly supervised task machine translation semantic parsing show objective actively discourage negative output addition promoting surrogate gold structure notion bipolarity naturally present ramp loss objective adapt neural model show bipolar ramp loss objective outperform nonbipolar ramp loss objective minimum risk training weakly supervised task well supervised machine translation task additionally introduce novel tokenlevel ramp loss objective able outperform even best sequencelevel ramp loss weakly supervised task
consider problem topicfocused abstractive summarization goal generate abstractive summary focused particular topic phrase one multiple word hypothesize task generating topicfocused summary improved showing model must focus introduce deep reinforcement learning approach topicfocused abstractive summarization trained reward novel negative example baseline define input problem source text preceded topic adapt cnndaily mail new york time summarization datasets task show experiment existing reward use negative example baseline outperform use selfcritical baseline rouge bertscore human evaluation metric
paper place classification scenario target class data type accessible training use metalearning approach determine whether metatrained information common social network data finegrained emotion label achieve competitive performance message labeled different emotion category leverage fewshot learning match classification scenario consider metric learning based metalearning setting prototypical network transformer encoder trained episodic fashion approach prof effective capturing metainformation source emotional tag set predict previously unseen emotional tag even though shifting data type trigger expected performance drop metalearning approach achieves decent result compared fully supervised one
propose novel dataaugmentation technique neural machine translation based rotk ciphertexts rotk simple letter substitution cipher replaces letter plaintext kth letter alphabet first generate multiple rotk ciphertexts using different value k plaintext source side parallel data leverage enciphered training data along original parallel data via multisource training improve neural machine translation method cipherdaug us coregularizationinspired training procedure requires external data source original training data us standard transformer outperform strong data augmentation technique several datasets significant margin technique combine easily existing approach data augmentation yield particularly strong result lowresource setting
coreference resolution span representation play key role predict coreference link accurately present thorough examination span representation derived applying bert coreference resolution joshi et al using probing model result show span representation able encode significant amount coreference information addition find headfinding attention mechanism involved creating span crucial encoding coreference knowledge last analysis show span representation capture nonlocal coreference efficiently local coreference
news aggregation system focused broad news domain certain story may appear multiple article depending relative importance story number version reach dozen hundred within day text version may nearly identical quite different linking multiple version story single group brings several important benefit enduserreducing cognitive load reader well signaling relative importance story present grouping algorithm explore several vectorbased representation input document baseline using keywords method using saliencea measure importance named entity text demonstrate feature beyond keywords yield substantial improvement verified manuallyannotated corpus business news story
increased demand structured scientific knowledge attracted considerable attention extracting scientific relation ever growing scientific publication distant supervision widely applied approach automatically generate large amount labelled data low manual annotation cost however distant supervision inevitably accompanies wrong labelling problem negatively affect performance relation extraction address issue han et al proposes novel framework jointly training model knowledge graph completion kgc model extract structured knowledge nonscientific dataset work firstly investigate feasibility framework scientific dataset specifically biomedical dataset secondly achieve better performance biomedical dataset extend framework competitive kgc model moreover proposed new endtoend kgc model extend framework experimental result show feasibility framework biomedical dataset also indicate effectiveness extension extended model achieves significant consistent improvement distant supervised compared baseline
adapting pretrained language model novel domain clinical application traditionally involves retraining entire set parameter parameterefficient finetuning peft technique finetuning language model significantly reduce computational requirement selectively finetuning small subset parameter study propose twostep peft framework evaluate clinical domain approach combine specialised peft adapter layer designed clinical domain adaptation another adapter specialised downstream task evaluate framework multiple clinical outcome prediction datasets comparing clinically trained language model framework achieves better auroc score averaged across clinical downstream task compared clinical language model particular observe large improvement auroc largescale multilabel classification task diagnosis procedure classification knowledge study first provide extensive empirical analysis interplay peft technique domain adaptation important realworld domain clinical application
article discusses adaptation traditional english readability measure sesotho southern african indigenous lowresource language employ use translated readability corpus extract textual feature sesotho text readability level english translation look correlation different feature ensure noncompeting feature used readability metric next linear regression analysis examine impact text feature sesotho text overall readability level gauged english translation starting structure traditional english readability measure linear regression model identify coefficient intercept different variable considered readability formula sesotho end propose ten readability formula sesotho one initial nine provide two formula based structure gunning fog index also introduce intercept gunning fog index lasbarhets index readability index intercept english variant sesotho formula
multilabel text classification mltccnatural language processingnlppartial selftrainingpstpst
dialogue robot attractive people language learning system motivate learner let practice conversational skill realistic environment however automatic speech recognition asr second language l learner still challenge speech contains pronouncing lexical grammatical error sometimes totally disordered hence propose novel robot assisted language learning rall system using two robot one teacher advanced learner system designed simulate multiparty conversation expecting implicit learning enhancement predictability learner utterance alignment similar interactive alignment observed humanhuman conversation collected database prototype measured much alignment phenomenon observed database initial analysis
bias machine learning model issue model trained particular type data generalize well causing performance certain group user work focus reducing bias related new customer digital voice assistant system observed natural language understanding model often lower performance dealing request coming new user rather experienced user mitigate problem propose framework consists two phase fixing phase four active learning strategy used identify important sample coming new user self training phase teacher model trained first phase used annotate semisupervised sample expand training data relevant cohort utterance explain practical strategy involve identification representative cohortbased sample density clustering well employing implicit customer feedback improve new customer experience demonstrate effectiveness approach real world large scale voice assistant system two language german french offline experiment well ab testing
ixa pipeline modular set natural language processing tool pipe provide easy access nlp technology offer robust efficient linguistic annotation researcher nonnlp expert aim lowering barrier using nlp technology either research purpose small industrial developer smes ixa pipeline used exploit modularity pick change different component given opensource nature also modified extended work language paper describes general datacentric architecture ixa pipeline present competitive result several nlp annotation english spanish
transformerbased model achieved stateoftheart result wide range natural language processing nlp task including document summarization typically system trained finetuning large pretrained model target task one issue transformerbased model scale well term memory compute requirement input length grows thus long document summarization challenging train finetune model work exploit large pretrained transformerbased model address longspan dependency abstractive summarization using two method local selfattention explicit content selection approach compared range network configuration experiment carried standard longspan summarization task including spotify podcast arxiv pubmed datasets demonstrate combining method achieve stateoftheart result three task rouge score moreover without largescale gpu card approach achieve comparable better result existing approach
paper describe addition corpus query system kontext enables enhance search using syntactic attribute addition existing feature mainly lemma morphological category present enhancement corpus query system attribute use represent syntactic structure data example querying syntactically annotated corpus treebanks various language well automatically parsed large corpus
fewshot text classification selftraining popular tool semisupervised learning ssl relies pseudolabels expand data demonstrated success however pseudolabels contain potential noise provoke risk underfitting decision boundary pseudolabeled data indeed noisy fully acquiring flawed data result accumulation noise eventually impacting model performance consequently selftraining present challenge mitigating accumulation noise pseudolabels confronting challenge introduce superficial learning inspired pedagogy focus essential knowledge superficial learning pedagogy learning scheme learns material extent fully understanding material approach usually avoided education counterintuitively context employ superficial learning acquire necessary context noisy data effectively avoiding noise concept serf foundation superst selftraining framework superst applies superficial learning noisy data finetuning less noisy data creating efficient learning cycle prevents overfitting noise span decision boundary effectively notably superst improves classifier accuracy fewshot text classification average compared stateoftheart ssl baseline substantiate claim empirical experiment decision boundary analysis
paper present winning system zeroshot spanish framing detection task also achieves competitive place eight additional language challenge framing detection task lie identifying set frame zero sample available ie multilingual multilabel zeroshot setting developed solution employ pretraining procedure based multilingual transformer using labelaware contrastive loss function addition describing system perform embedding space analysis ablation study demonstrate pretraining procedure support framing detection advance computational framing analysis
casiacassil largescale corpus base chinese humanhuman naturallyoccurring telephone conversation restricted domain first edition consists second conversation belonging tourism domain selected spontaneous telephone recording real scenario corpus annotated wide range linguistic paralinguistic information multilevels annotation include turn speaker gender orthographic transcription chinese syllable chinese phonetic transcription prosodic boundary stress sentence nonspeech sound voice quality topic dialogact adjacency pair illformedness expressive emotion well level total abundant annotation effective especially studying chinese spoken language phenomenon paper describes whole process build conversation corpus including collecting selecting original data followup process transcribing annotating casiacassil extended large scale corpus base annotated chinese dialog spoken chinese study
paper describes system submission wmt shared task similar language translation examined use documentlevel neural machine translation nmt system lowresource similar language pair marathihindi system extension stateoftheart transformer architecture hierarchical attention network incorporate contextual information since nmt requires large amount parallel data available task approach focused utilizing monolingual data back translation train model experiment reveal documentlevel nmt reasonable alternative sentencelevel nmt improving translation quality low resourced language even used synthetic data
recently deep endtoend learning studied intent classification spoken language understanding slu however endtoend model require large amount speech data intent label highly optimized model generally sensitive inconsistency training evaluation condition therefore natural language understanding approach based automatic speech recognition asr remains attractive utilize pretrained general language model adapt mismatch speech input environment using modulebased approach improve noisychannel model handle transcription inconsistency caused asr error propose twostage method contrastive consistency learning ccl correlate error pattern clean noisy asr transcript emphasizes consistency latent feature two transcript experiment four benchmark datasets show ccl outperforms existing method improves asr robustness various noisy environment code available httpsgithubcomsyoungccl
dialogue representation understanding aim convert conversational input embeddings fulfill discriminative task compared freeform text dialogue two important characteristic hierarchical semantic structure multifacet attribute therefore directly applying pretrained language model plms might result unsatisfactory performance recently several work focused dialogueadaptive posttraining dialpost train plms fit dialogue model dialogue comprehensively propose dialpost method dialogpost multilevel selfsupervised objective hierarchical model objective leverage dialoguespecific attribute use selfsupervised signal fully facilitate representation understanding dialogue novel model hierarchical segmentwise selfattention network contains innersegment intersegment selfattention sublayers followed aggregation updating module evaluate effectiveness method first apply two public datasets verification representation ability conduct experiment newlylabelled dataset annotated dialogue understanding task experimental result show method outperforms existing sota model achieves improvement average
past work multimodal machine translation mmt elevate bilingual setup incorporating additional aligned vision informationhowever imagemust requirement multimodal dataset largely hinders mmts development namely demand aligned form image source text target textthis limitation generally troublesome inference phase especially aligned image provided normal nmt setupthus work introduce ikdmmt novel mmt framework support imagefree inference phase via inversion knowledge distillation schemein particular multimodal feature generator executed knowledge distillation module directly generates multimodal feature source text inputwhile prior work entertaining possibility support imagefree inference machine translation performance yet rival imagemust translationin experiment identify method first imagefree approach comprehensively rival even surpass almost imagemust framework achieved stateoftheart result oftenused multik benchmark code data availableat httpsgithubcompengrikdmmttreemaster
address task detecting foiled image caption ie identifying whether caption contains word deliberately replaced semantically similar word thus rendering inaccurate respect image described solving problem principle require finegrained understanding image detect subtle perturbation caption context encoding sufficiently descriptive image information becomes key challenge paper demonstrate possible solve task using simple interpretable yet powerful representation based explicit object information multilayer perceptron model model achieve stateoftheart performance recently published dataset score exceeding achieved human task also measure upperbound performance model using gold standard annotation study analysis reveals simpler model performs well even without image information suggesting dataset contains strong linguistic bias
supervised machine learning become cornerstone today datadriven society increasing need labeled data however process acquiring label often expensive tedious one possible remedy use active learning al special family machine learning algorithm designed reduce labeling cost although al successful practice number practical challenge hinder effectiveness often overlooked existing al annotation tool address challenge developed alanno opensource annotation system nlp task equipped feature make al effective realworld annotation project alanno facilitates annotation management multiannotator setup support variety al method underlying model easily configurable extensible
propose method link automatically parsed linguistic data wordnet apply method trilingual dictionary fula english french dictionary entry parsing used collect linguistic data connect open multilingual wordnet omw two attempt use confidence score quantify accuracy obtained entry parsing linked omw first attempt additional second one link due validated fula speaker added kamusi project database
pretrained language model greatly improve performance various task cost high computation overhead facilitate practical application mainly two line research accelerate model inference model compression dynamic computation eg dynamic token pruning existing work either adopt method individually simply apply dynamic computation approach upon compressed small language model argue suboptimal since two approach separately designed compressed model may tailored dynamic computation tackle problem make compressed small language model faster propose lengthadaptive distillation twostage knowledge distillation framework aim produce customized small language model dynamic token pruning general distillation stage enforce student mimic reconstruct teacher output based dynamically pruned representation taskspecific distillation stage student accustomed token pruning absorbing taskspecific knowledge experimental result glue benchmark demonstrate method make small language model customized dynamic token pruning achieve better speedperformance tradeoff
recently many company providing capability large language model service languagemodelasaservice lmaas offering support variety user task incontext learning prompt include instruction demonstration task however user manually crafting prompt running automatic prompt tuning method demanding despite challenge lmaas provider offer automatic prompt engineering method part service one major obstacle deploying lmaas heavy computational cost associated automatic prompt engineering method method typically designed iterate ten thousand example impose unaffordable overhead lmaas provider paper introduce metalprompt novel lightweight automatic prompt generation method lmaas metalprompt metatrains prompt generation model pgm enable robust learning language model context created generated prompt ie incontext learning thanks metalearning approach pgm generate prompt unseen task without requiring additional training specific task furthermore pgm generate prompt single forward pas significantly reducing computational cost compared previous method evaluate metalprompt range unseen task find improves performance term mean f score qa datasets compared stateoftheart baseline ptuning limited computational cost
crosslingual word embeddings transfer knowledge language model trained highresource language predict lowresource language introduce clime interactive system quickly refine crosslingual word embeddings given classification problem first clime rank word salience downstream task user mark similarity keywords nearest neighbor embedding space finally clime update embeddings using annotation evaluate clime identifying healthrelated text four lowresource language ilocano sinhalese tigrinya uyghur embeddings refined clime capture nuanced word semantics higher test accuracy original embeddings clime often improves accuracy faster active learning baseline easily combined active learning improve result
human communication includes information opinion reaction reaction often captured affectivemessages written well verbal communication work affect modeling extent affective content generation area affective word distribution well studied synset lexica capture semantic relationship across word model however lack encoding affective emotional word interpretation proposed model affvec provides method enriched word embeddings representative affective interpretation word affvec outperforms stateoftheart intrinsic wordsimilarity task use affvec representation outperforms baseline embeddings downstream natural language understanding task including sentiment analysis personality detection frustration prediction
refinding item user forget uncertain identifying detail often rely creative strategy expressing information needscomplex query describe content element eg book character event information beyond document text eg description book cover personal context eg read book standard retrieval model rely lexical semantic overlap query document text challenged retrieval setting known tipofthetongue tot retrieval introduce simple effective framework handling complex query decomposing query llm individual clue routing subqueries specialized retriever ensembling result approach take advantage offtheshelf retriever eg clip retrieving image book cover incorporate retrieverspecific logic eg date constraint show framework incorporating query decomposition retriever improve gold book recall absolute gain recall new collection realworld querybook pair online community resolving tot inquiry
framing bias play significant role exacerbating political polarization distorting perception actual event medium outlet divergent political stance often use polarized language reporting event propose new loss function encourages model minimize polarity difference polarized input article reduce framing bias specifically loss designed jointly optimize model map polarity end bidirectionally experimental result demonstrate incorporating proposed polarity minimization loss lead substantial reduction framing bias compared bartbased multidocument summarization model notably find effectiveness approach pronounced model trained minimize polarity loss associated informational framing bias ie skewed selection information report
cognitive research indicates abstraction ability essential human intelligence remains underexplored language model paper present abspyramid unified entailment graph k textual description abstraction knowledge existing resource touch noun verb within simplified event specific domain abspyramid collect abstract knowledge three component diverse event comprehensively evaluate abstraction ability language model open domain experimental result demonstrate current llm face challenge comprehending abstraction knowledge zeroshot fewshot setting training rich abstraction knowledge find llm acquire basic abstraction ability generalize unseen event meantime empirically show benchmark comprehensive enhance llm across two previous abstraction task
early success queryanswer assistant alexa siri research attempt expand system capability handling service automation abundant however preliminary system quickly found inadequacy relying simple classification technique effectively accomplish automation task main challenge dialogue often involves complexity user intent purpose multiproned subject spontaneous change difficult track furthermore public datasets considered complication general semantic annotation lacking may result zeroshot problem motivated propose labelaware bert attention network laban zeroshot multiintent detection first encode input utterance bert construct label embedded space considering embedded semantics intent label input utterance classified based projection weight intent embedding embedded space show successfully extends fewzeroshot setting part intent label unseen training data also taking account semantics unseen intent label experimental result show approach capable detecting many unseen intent label correctly also achieves stateoftheart performance five multiintent datasets normal case
paper present study automatic normalisation th century document written middle french document present large variety wordforms require spelling normalisation facilitate downstream linguistic historical study frame normalisation process machine translation task starting strong baseline leveraging pretrained encoderdecoder model propose improve baseline combining synthetic data generation method producing artificial training data thus tackling lack parallel corpus relevant task evaluation approach twofold addition automatic metric relying gold reference evaluate model postediting output evaluation method directly measure productivity gain brought model expert conducting normalisation task manually result show token per minute increase productivity using automatic normalisation compared normalising text scratch manually postedited dataset resulting study first parallel corpus normalised th century middle french publicly released along synthetic data automatic normalisation model used trained presented work
paper describes kakao enterprise submission wmt shared machine translation using terminology task integrate terminology constraint pretraining target lemma annotation finetuning exact target annotation utilizing given terminology dataset approach yield model achieves outstanding result term translation quality term consistency ranking first based comet enfr language direction furthermore explore various method backtranslation explicitly training terminology additional parallel data indomain data selection
paper use several combination feature frontend module attention mechanism improve performance speaker verification system updated version ecapatdnn chosen baseline replace integrate different feature frontend attention mechanism module compare find effective model design model would final system use voxceleb dataset training set test performance model several test set final proposed model improved performance baseline voxsrc valudation set achieving better result speaker verification system
role author l sla challenging automated cefr classification text different l group may heterogeneous combine training data experiment recent debiasing approach attempting devoid textual representation l feature result homogeneous group aggregating cefrannotated text different l group leading better classification performance using iterative nullspace projection marginally improve classification performance linear classifier point mlp eg nonlinear classifier remains unaffected procedure discus possible direction future work attempt increase performance gain
recent neural sequencetosequence model shown significant progress short text summarization however document summarization fail capture longterm structure document multisentence summary resulting information loss repetition paper propose leverage structural information document multisentence summary improve document summarization performance specifically import structuralcompression structuralcoverage regularization summarization process order capture information compression information coverage property two important structural property document summarization experimental result demonstrate structural regularization improves document summarization performance significantly enables model generate informative concise summary thus significantly outperforms stateoftheart neural abstractive method
multitask learning mtl deep neural network nlp recently received increasing interest due compelling benefit including potential efficiently regularize model reduce need labeled data brought significant improvement number nlp task mixed result reported little known condition mtl lead gain nlp paper shed light specific task relation lead gain mtl model singletask setup
paper present semantic model protest event called semantic interpretation protest event seminpe analytical framework used building semantic representation inspired objectoriented paradigm computer science cognitive approach linguistic analysis model practical application unified eventity representation uer formalism based unified modeling language uml multilayered architecture model provides flexible mean building semantic representation language object along scale generality specificity thus suitable environment creating element ontology various topic different language
paper proposes new task detecting information override since information web updated timely manner necessity created information overridden another information source discarded task formalized binary classification problem determine whether reference sentence overridden target sentence investigating task paper describes construction procedure dataset overridden information collecting sentence pair difference two version wikipedia developing dataset show old version wikipedia contains much overridden information detection information override necessary
paper explores incorporation lexicosemantic heuristic deterministic coreference resolution cr system classifying named entity documentlevel highest precise sieve cr tool enriched set heuristic merging named entity labeled different class also constraint avoid incorrect merging similar mention several test show strategy improves ner labeling cr cr tool applied combination system named entity recognition using conll format brings benefit text analytics task information extraction experiment carried spanish using three different ner tool
news statement information source often quoted made individual interact news detecting quote gender source key task come medium analysis gender perspective challenging task structure quote variable gender mark present many language quote author often omitted due frequent use coreference paper proposes strategy measure presence woman men information source news approach problem detecting sentence including quote gender speaker joint task mean supervised multiclass classifier sentence created first datasets spanish basque manually annotating quote gender associated source news item result obtained show bert based approach significantly better bagofwords based classical one achieving accuracy close also analyse bilingual learning strategy generating additional training example synthetically provide improvement respectively
probing classifier framework employed interpreting deep neural network model variety natural language processing nlp application study however largely focused sentencelevel nlp task work first apply probing paradigm representation learned documentlevel information extraction ie designed eight embedding probe analyze surface semantic eventunderstanding capability relevant documentlevel event extraction apply representation acquired learning model three different llmbased documentlevel ie approach standard dataset found trained encoders model yield embeddings modestly improve argument detection labeling slightly enhance eventlevel task albeit tradeoff information helpful coherence eventtype prediction found encoder model struggle document length crosssentence discourse
nowadays fake news spreading various way fake information causing lot social damage thus need detect fake information increasing prevent damage caused fake news paper propose novel graphbased fake news detection method using summarization technique us document internal information proposed method represents relationship sentence using graph reflection rate contextual information among sentence computed using attention mechanism addition improve performance fake news detection utilizing summary information important subject document experimental result demonstrate method achieves high accuracy p better previous method
tackle problem weaklysupervised conversational question answering large knowledge graph using neural semantic parsing approach introduce new logical form lf grammar model wide range query graph remaining sufficiently simple generate supervision data efficiently transformerbased model take jsonlike structure input allowing u easily incorporate knowledge graph conversational context structured input transformed list embeddings fed standard attention layer validate approach term grammar coverage lf execution accuracy two publicly available datasets csqa convquestions grounded wikidata csqa approach increase coverage lf execution accuracy respect previous stateoftheart result convquestions achieve competitive result respect stateoftheart
geoentity linking task linking location mention realworld geographic location explore challenging task geoentity linking noisy multilingual social medium data opensource multilingual geoentity linking tool available existing one often rulebased break easily social medium setting llmbased expensive largescale datasets present method represents realworld location averaged embeddings labeled userinput location name allows selective prediction via interpretable confidence score show approach improves geoentity linking global multilingual social medium dataset discus progress problem evaluating different geographic granularity
inductive reasoning fundamental human artificial intelligence inductive reasoning ability current large language model llm evaluated researchwe argue considering induction rule narrow unrealistic since inductive reasoning usually mixed ability like rule application resultsrules validation updated information integrationwe probed llm set designed symbolic task found even stateoftheart sota llm fail significantly showing inability llm perform intuitively simple tasksfurthermore found perfect accuracy smallsize problem guarantee accuracy largersize version problem provoking question assess llm actual problemsolving capabilitieswe also argue chainofthought prompt help llm decomposing problemsolving process llm still learn limitedlyfurthermore reveal fewshot example assist llm generalization outofdomain ood case albeit limited llm start fail problem deviate provided fewshot example
recent advancement large language model llm empowered achieve text generation capability par human recent advance paired wide availability model made large language model adaptable many domain scientific writing story generation along many others recent rise made crucial develop system discriminate humanauthored synthetic text generated large language model llm proposed system alta shared task based ensembling number language model claimed first place development set accuracy third place test set accuracy
paper describes system used team lipn semeval task extracting keyphrases relation scientific publication team participated scenario includes three subtasks identification keyphrases subtask classification identified keyphrases subtask b extraction relationship two identified keyphrases subtask c presented system mainly focused use partofspeech tag sequence filter candidate keyphrases subtask subtasks b addressed sequence labeling problem using conditional random field crfs even though subtask c scope approach one rule included identify synonym
despite success existing referenced metric eg bleu moverscore correlate poorly human judgment openended text generation including story dialog generation notorious onetomany issue many plausible output input may differ substantially literal semantics limited number given reference alleviate issue propose union learnable unreferenced metric evaluating openended story generation measure quality generated story without reference built top bert union trained distinguish humanwritten story negative sample recover perturbation negative story propose approach constructing negative sample mimicking error commonly observed existing nlg model including repeated plot conflicting logic longrange incoherence experiment two story datasets demonstrate union reliable measure evaluating quality generated story correlate better human judgment generalizable existing stateoftheart metric
simultaneous machine translation recently gained traction thanks significant quality improvement advent streaming application simultaneous translation system need find tradeoff translation quality response time purpose multiple latency measure proposed however latency evaluation simultaneous translation estimated sentence level taking account sequential nature streaming scenario indeed sentencelevel latency measure well suited continuous stream translation resulting figure coherent simultaneous translation policy system assessed work proposes stream level adaptation current latency measure based resegmentation approach applied output translation successfully evaluated streaming condition reference iwslt task
recent year task generating realistic short long text made tremendous advancement particular several recently proposed neural networkbased language model demonstrated astonishing capability generate text challenging distinguish humanwritten text naked eye despite many benefit utility neural method application able tell author text question becomes critically important work context turing test investigate socalled authorship attribution problem three version given two text generated method given text written human machine given text k candidate neural method single method among k alternative generated one humanwritten eight machinegenerated text ie ctrl gpt gpt grover xlm xlnet pplm fair empirically experiment performance various model three problem large find generator still generate text significantly different humanwritten one thereby making three problem easier solve however quality text generated gpt grover fair better often confusing machine classifier solving three problem code datasets experiment available urlhttpsbitly zwdz
face face interaction people refer object event mean speech also mean gesture present paper describes building corpus referential gesture aim investigate gestural reference incorporating insight semantic ontology employing holistic view referential gesture paper focus presenting data collection procedure discussing corpus design additionally first insight constructing annotation scheme described
recent year fostered deep learning technology high demand conversational ai various approach proposed address capacity elicit understand user need taskoriented dialogue system focus two core task slot filling sf intent classification ic survey neural based model rapidly evolved address natural language understanding dialogue system introduce three neural architecture independent model model sf ic separately joint model exploit mutual benefit two task simultaneously transfer learning model scale model new domain discus current state research sf ic highlight challenge still require attention
present sicknl read signal dataset targeting natural language inference dutch sicknl obtained translating sick dataset marelli et al english dutch parallel inference dataset allows u compare monolingual multilingual nlp model english dutch two task paper motivate detail translation process perform baseline evaluation original sick dataset dutch incarnation sicknl taking inspiration dutch skipgram embeddings contextualised embedding model addition encapsulate two phenomenon encountered translation formulate stress test verify well dutch model capture syntactic restructurings affect semantics main finding model perform worse sicknl sick indicating dutch dataset challenging english original result stress test show model dont fully capture word order freedom dutch warranting future systematic study
emergence numerous large language model llm usage model various natural language processing nlp application increasing extensively counterspeech generation one key task effort made develop generative model finetuning llm hatespeech counterspeech pair none attempt explores intrinsic property large language model zeroshot setting work present comprehensive analysis performance four llm namely gpt dialogpt chatgpt flant zeroshot setting counterspeech generation first kind gpt dialogpt investigate deviation performance respect size small medium large model hand propose three different prompting strategy generating different type counterspeech analyse impact strategy performance model analysis show improvement generation quality two datasets however toxicity increase increase model size considering type model gpt flant model significantly better term counterspeech quality also high toxicity compared dialogpt chatgpt much better generating counter speech model across metric term prompting find proposed strategy help improving counter speech generation across model
abstract meaning representation amr parsing aim extract abstract semantic graph given sentence sequencetosequence approach linearize semantic graph sequence node edge generate linearized graph directly achieved good performance however observed approach suffer structure loss accumulation decoding process leading much lower fscore node edge decoded later compared decoded earlier address issue propose novel reverse graph linearization rgl enhanced framework rgl defines default reverse linearization order amr graph structure back part default order appear front part reversed order vice versa rgl incorporates reversed linearization original amr parser twopass selfdistillation mechanism guide model generating default linearizations analysis show proposed method significantly mitigates problem structure loss accumulation outperforming previously best amr parsing model smatch score amr amr dataset respectively code available urlhttpsgithubcompkunlpicleramrreversegraphlinearization
disease one fundamental entity biomedical research recognizing entity biomedical text normalizing standardized disease vocabulary offer tremendous opportunity many downstream application previous study demonstrated joint modeling two subtasks superior performance pipelined counterpart although neural joint model based multitask learning framework achieved stateoftheart performance suffers boundary inconsistency problem due separate decoding procedure moreover ignores rich information eg text surface form candidate concept vocabulary quite essential entity normalization work propose neural transitionbased joint model alleviate two issue transform endtoend disease recognition normalization task action sequence prediction task jointly learns model shared representation input also jointly search output state transition one search space moreover introduce attention mechanism take advantage text surface form candidate concept better normalization performance experimental result conducted two publicly available datasets show effectiveness proposed method
recently resource task proposed go beyond state tracking dialogue system example frame tracking task requires recording multiple frame one user goal set dialogue allows user instance compare item corresponding different goal paper proposes model take input list frame created far dialogue current user utterance well dialogue act slot type slot value associated utterance model output frame referenced triple dialogue act slot type slot value show recently published frame dataset model significantly outperforms previously proposed rulebased baseline addition propose extensive analysis frame tracking task dividing subtasks assessing difficulty respect model
readability assessment aim automatically classify text based reader reading level hybrid automatic readability assessment ara model using deep linguistic feature attracted rising attention recent year due impressive performance however deep feature fully explored due scarcity training data fusion deep linguistic feature effective existing hybrid ara model paper propose novel hybrid ara model called promptara employing prompt improve deep feature representation orthogonal projection layer fuse deep linguistic feature series experiment conducted four english two chinese corpus show effectiveness proposed model experimental result demonstrate proposed model superior stateoftheart model
paper present number experiment model change historical portuguese corpus composed literary text purpose temporal text classification algorithm trained classify text respect publication date taking account lexical variation represented word ngrams morphosyntactic variation represented partofspeech po distribution report result accuracy using word unigram feature support vector machine classifier predict publication date document time interval one century half century feature analysis performed investigate informative feature task linked language change
word meaning change time automated procedure extracting information text would useful historical exploratory study information retrieval question answering present dynamic bayesian model diachronic meaning change infers temporal word representation set sens prevalence unlike previous work explicitly model language change smooth gradual process experimentally show modeling decision beneficial model performs competitively meaning change detection task whilst inducing discernible word sens development time application model semeval temporal classification benchmark datasets reveals performs par highly optimized taskspecific system
aspectbased sentiment analysis absa aim predict sentiment towards specific aspect text however existing absa test set used probe whether model distinguish sentiment target aspect nontarget aspect solve problem develop simple effective approach enrich absa test set specifically generate new example disentangle confounding sentiment nontarget aspect target aspect sentiment based semeval dataset construct aspect robustness test set art comprehensive probe aspect robustness absa model data art show high fluency desired sentiment aspect human evaluation using art analyze robustness nine absa model observe surprisingly accuracy drop explore several way improve aspect robustness find adversarial training improve model performance art code new test set available urlhttpsgithubcomzhijingjinartstestset
pretrained language model bert achieved remarkable success several nlp task wide adoption bert realworld application researcher begin investigate implicit bias encoded bert paper assess implicit stock market preference bert finance domainspecific model finbert find interesting pattern example language model overall positive towards stock market significant difference preference pair industry sector even within sector given prevalence nlp model financial decision making system work raise awareness potential implicit preference stock market awareness problem help practitioner improve robustness accountability financial nlp pipeline
one main challenge development summarization tool summarization quality evaluation one hand human assessment summarization quality conducted linguistic expert slow expensive still standardized procedure hand automatic assessment metric reported correlate high enough human quality rating solution propose crowdsourcing fast scalable costeffective alternative expert evaluation assess intrinsic extrinsic quality summarization comparing crowd rating expert rating automatic metric rouge bleu bertscore german summarization data set result provide basis best practice crowdbased summarization evaluation regarding major influential factor best annotation aggregation method influence readability reading effort summarization evaluation optimal number crowd worker achieve comparable result expert especially determining factor overall quality grammaticality referential clarity focus structure coherence summary usefulness summary informativeness
large language model possess remarkable capacity processing language remains unclear whether model generate creative content present study aim investigate creative thinking large language model cognitive perspective utilize divergent association task dat objective measurement creativity asks model generate unrelated word calculates semantic distance compare result across different model decoding strategy finding indicate using greedy search strategy gpt outperforms human gptturbo exceeds average human level stochastic sampling temperature scaling effective obtain higher dat score model except gpt face tradeoff creativity stability result imply advanced large language model divergent semantic association fundamental process underlying creativity
present general framework analyzing existing story corpus generate controllable creative new story proposed framework need little manual annotation achieve controllable story generation creates new interface human interact computer generate personalized story apply framework build recurrent neural network rnnbased generation model control story ending valence storyline experiment show method successfully achieve control enhance coherence story introducing storyline additional control factor generation model get lower perplexity yield coherent story faithful control factor according human evaluation
building automatic extraction model visually rich document like invoice receipt bill tax form etc received significant attention lately key bottleneck developing extraction model new document type cost acquiring several thousand highquality labeled document needed train model acceptable accuracy paper propose selective labeling solution problem key insight simplify labeling task provide yesno label candidate extraction predicted model trained partially labeled document combine custom active learning strategy find prediction model uncertain show experiment document type drawn different domain selective labeling reduce cost acquiring labeled data time negligible loss accuracy
paper present system detail result participation rdoc task bionlpost research domain criterion rdoc construct multidimensional broad framework describe mental health disorder combining knowledge genomics behaviour nonavailability rdoc labelled dataset tedious labelling process hinders use rdoc framework reach full potential biomedical research community healthcare industry therefore task aim retrieval ranking pubmed abstract relevant given rdoc construct task aim extraction relevant sentence given pubmed abstract investigate attention based supervised neural topic model svm retrieval ranking pubmed abstract utilize bm relevance measure reranking supervised unsupervised sentence ranking model utilizing multiview representation comprising queryaware attentionbased sentence representation qar bagofwords bow tfidf best system achieved st rank scored map macro average accuracy task task respectively
recent year show development large scale resource eg framenet frame semantics supported definition several stateoftheart approach natural language processing however reuse existing resource heterogeneous domain human robot interaction straightforward generalization offered many data driven method strongly biased employed data whose performance outofdomain condition exhibit large drop paper present human robot interaction corpus huric made audio file paired transcription referring command robot eg home environment recorded sentence annotated different kind linguistic information ranging morphological syntactic information rich semantic information according frame semantics characterize robot action spatial semantics capture robot environment text represented abstract meaning representation adopt simple expressive representation command easily translated internal representation robot
consider task generating design directly natural language description consider floor plan generation initial research area language conditional generative model recently successful generating highquality artistic image however design must satisfy different constraint present generating artistic image particularly spatial relational constraint make multiple contribution initiate research task first introduce novel dataset telldesign td contains k floor plan design associated natural language instruction second propose sequencetosequence model serve strong baseline future research third benchmark task several textconditional image generation model conclude conducting human evaluation generated sample providing analysis human performance hope contribution propel research languageguided design generation forward
henderson mccready build novel theory socalled dogwhistle communication extending social meaning game burnett work report ongoing project build system model evolution dogwhistle communication population based probability monad erwig kollmansberger kidd ultimate result useful dogwhistles modeling diffusion evolution social meaning population general initial result presented computational implementation henderson mccready serve basis model multiple speaker repeated interaction
stimulate research crosslanguage entity linking present new test collection evaluating accuracy crosslanguage entity linking twentyone language paper describes efficient way create curate collection judiciously exploiting existing language resource query created semiautomatically identifying person name english side parallel corpus using judgment obtained crowdsourcing identify entity corresponding name projecting english name onto nonenglish document using word alignment name projection curated crowdsourcing technique resulted first publicly available multilingual crosslanguage entity linking collection collection includes approximately query comprising query twentyone nonenglish language
pretrained language model achieved huge improvement many nlp task however method usually designed written text consider property spoken language therefore paper aim generalizing idea language model pretraining lattice generated recognition system propose framework train neural lattice language model provide contextualized representation spoken language understanding task proposed twostage pretraining approach reduces demand speech data better efficiency experiment intent detection dialogue act recognition datasets demonstrate proposed method consistently outperforms strong baseline evaluated spoken input code available urlhttpsgithubcommiulablatticeelmo
paper discusses challenge annotating predicateargument structure chinese verb compound uniform meaning representation umr recent meaning representation framework extends abstract meaning representation amr crosslinguistic setting key issue decide whether annotate argument structure verb compound whole annotate argument structure component verb well relation examine different type chinese verb compound propose annotate based principle compositionality level grammaticalization productivity component verb propose solution practical problem define semantic role chinese verb compound quite openended separating compositional verb compound verb compound noncompositional grammaticalized verb component compositional verb compound instead annotating argument structure verb compound whole annotate argument structure component verb well semantic relation creating exhaustive list verb compound infeasible verb compound grammaticalized verb component also tend productive represent grammaticalized verb compound either attribute primary verb relation
paper introduces gentrac openaccess webbased tool built interactively detect analyze potentially traumatic content witness statement genocide mass atrocity trial harnessing recent development natural language processing nlp detect trauma gentrac process format court transcript nlp analysis sophisticated parsing algorithm detects likelihood traumatic content speaker segment tool visualizes density content throughout trial day provides statistic overall amount traumatic content speaker distribution capable processing transcript four prominent international criminal court including international criminal court icc gentracs reach vast tailored handle million page document past future trial detecting potentially retraumatizing examination method enhance development traumainformed legal procedure gentrac also serf reliable resource legal human right professional aiding comprehension mass atrocity emotional toll survivor
social web observatory entitydriven sentimentaware event summarization web platform combining various method tool overview trend across social medium news source greek swo crawl cluster summarizes information following entitycentric view text stream allowing monitor public sentiment towards specific person organization entity paper overview platform outline analysis pipeline describe user study aimed quantify usefulness system especially meaningfulness coherence discovered event
chapter demonstrates compression algorithm used address morphological syntactic complexity detail analysing contribution specific linguistic feature english text point departure ongoing complexity debate quest complexity metric decade adhering equal complexity axiom recent research seek define measure linguistic complexity dahl kortmann szmrecsanyi miestamo et al backdrop present new flavour juolastyle compression technique juola targeted manipulation essentially compression algorithm used measure linguistic complexity via relative informativeness text sample thus assess contribution morphs ing ed functional construction progressive verbing perfect verb past participle syntactic morphological complexity mixedgenre corpus alices adventure wonderland gospel mark newspaper text find higher number marker type lead higher amount morphological complexity corpus syntactic complexity reduced presence morphological marker enhances algorithmic prediction linguistic pattern conclude show informationtheoretic method yield linguistically meaningful result used measure complexity specific linguistic feature naturalistic copora
paper contains description submission karlsruhe institute technology kit multilingual tedx translation task iwslt evaluation campaign main approach develop cascade endtoend system eventually combine together achieve best possible result extremely lowresource setting report also confirms certain consistent architectural improvement added transformer architecture task translation transcription speech translation
recently largescale datasets vastly facilitated development nearly domain natural language processing however currently crosstask dataset nlp hinders development multitask learning propose matinf first jointly labeled largescale dataset classification question answering summarization matinf contains million questionanswer pair humanlabeled category usergenerated question description based rich information matinf applicable three major nlp task including classification question answering summarization benchmark existing method novel multitask baseline matinf inspire research comprehensive comparison experiment matinf datasets demonstrate merit held matinf
common approach pretrain language model large corpus finetune taskspecific data practice observe finetuning pretrained model small dataset may lead andor underestimate problem paper propose mctailor novel method alleviate issue text generation task truncating transferring probability mass overestimated region underestimated one experiment variety text generation datasets show mctailor consistently significantly outperforms finetuning approach
dialogue model trained human conversation inadvertently learn generate toxic response addition producing explicitly offensive utterance model also implicitly insult group individual aligning offensive statement better understand dynamic contextually offensive language investigate stance dialogue model response offensive reddit conversation specifically create toxichat crowdannotated dataset reddit thread model response labeled offensive language stance analysis reveals human response agree toxic comment whereas agree safe comment undesirable behavior learned neural dialogue model dialogpt show two time likely agree offensive comment enable automatic detection offensive language finetuned transformerbased classifier toxichat achieve f offensive label macrof stance label finally quantify effectiveness controllable text generation ctg method mitigate tendency neural dialogue model agree offensive comment compared baseline best ctg model achieves reduction agreement offensive comment produce fewer offensive reply work highlight need effort characterize analyze inappropriate behavior dialogue model order help make safer
dialogue system conveying understanding result user utterance important enables user feel understood system however clear type understanding result conveyed user utterance may offensive may commonsensical paper explored effect conveying understanding result user utterance chatoriented dialogue system experiment using human subject result found certain type understanding result related user permanent state effective improve user satisfaction paper clarifies type understanding result safely uttered system
paper investigates identification populist rhetoric text present novel crosslingual dataset task work based definition populism communication style political actor refers people also includes antielitism another core feature populism accordingly annotate reference people elite german english parliamentary debate hierarchical scheme paper describes dataset annotation procedure report interannotator agreement task next compare evaluate different transformerbased model architecture german dataset report result zeroshot learning smaller english dataset show semisupervised tritraining improve result crosslingual setting dataset used investigate political actor talk elite people study populist rhetoric used strategic device
paper present result classification corporate social responsibility csr theme topic shared task encompasses crosslingual multiclass classification monolingual multilabel classification examine performance multiple machine learning ml model ranging classical model pretrained large language model llm assess effectiveness data augmentation da data translation dt contrastive learning cl find stateoftheart generative llm zeroshot setup still fall behind complex classification task compared finetuning local model enhanced datasets additional training objective work provides wide array comparison highlight relevance utilizing smaller language model complex classification task
paper introduces frenchmedmcqa first publicly available multiplechoice question answering mcqa dataset french medical domain composed question taken real exam french medical specialization diploma pharmacy mixing single multiple answer instance dataset contains identifier question five possible answer manual correction also propose first baseline model automatically process mcqa task order report current performance highlight difficulty task detailed analysis result showed necessary representation adapted medical domain mcqa task case english specialized model yielded better result generic french one even though frenchmedmcqa french corpus model tool available online
despite remarkable advance development language resource recent year still shortage annotated publicly available corpus covering german medical language initial release german guideline program oncology nlp corpus ggponc demonstrated corpus built upon clinical guideline widely available resource many natural language reasonable coverage medical terminology work describe major new release ggponc corpus substantially extended size reannotated new annotation scheme based snomed ct top level hierarchy reaching high interannotator agreement moreover annotated elliptical coordinated noun phrase resolution common language phenomenon german scientific document also trained bertbased named entity recognition model new data set achieve high performance short coarsegrained entity span f rate boundary error increase long entity span ggponc freely available data use agreement trained named entity recognition model well detailed annotation guide also made publicly available
research propose task question summarization first analyzed questionsummary pair extracted community question answering cqa site found proportion question summarized extractive approach requires abstractive approach created dataset regarding questiontitle pair posted cqa site questionsummary pair using data trained extractive abstractive summarization model compared based rouge score manual evaluation experimental result show abstractive method using encoderdecoder model copying mechanism achieves better score rouge fmeasure evaluation human judge
consider task generating dialogue response background knowledge comprising domain specific resource specifically given conversation around movie task generate next response based background knowledge movie plot review reddit comment etc requires capturing structural sequential semantic information conversation context background resource propose new architecture us ability bert capture deep contextualized representation conjunction explicit structure sequence information specifically use graph convolutional network gcns capture structural information ii lstms capture sequential information iii bert deep contextualized representation capture semantic information analyze proposed architecture extensively end propose plugandplay semanticssequencesstructures ss framework allows u effectively combine linguistic information series experiment make interesting observation first observe popular adaptation gcn model nlp task structural information gcns added top sequential information lstms performs poorly task lead u explore interesting way combining semantic structural information improve performance second observe bert already outperforms deep contextualized representation elmo still benefit additional structural information explicitly added using gcns bit surprising given recent claim bert already capture structural information lastly proposed ss framework give improvement blue score baseline
voice assistant cement place technologically advanced society remains need cater diverse linguistic landscape including colloquial form lowresource language study introduces firstever comprehensive dataset intent detection slot filling formal bangla colloquial bangla sylheti language totaling sample across unique intent analysis reveals robustness large language model tackling downstream task inadequate data gpt model achieves impressive f score intent detection slot filling colloquial bangla
neural topic model widely used discovering latent semantics corpus recently several research hierarchical neural topic model since relationship among topic valuable data analysis exploration however existing hierarchical neural topic model limited generate single topic tree study present nonparametric foreststructured neural topic model firstly applying selfattention mechanism capture parentchild topic relationship build sparse directed acyclic graph form topic forest experiment indicate model automatically learn foreststructured topic hierarchy indefinite number tree leaf significantly outperforms baseline model topic hierarchical rationality affinity
understanding difference viewpoint across corpus fundamental task computational social science paper propose sliced word embedding association test sweat novel statistical measure compute relative polarization topical wordset across two distributional representation end sweat us two additional wordsets deemed opposite valence represent two different pole validate approach illustrate case study show usefulness introduced measure
icd coding designed assign disease code electronic health record ehrs upon discharge crucial billing clinical statistic attempt improve effectiveness efficiency manual coding many method proposed automatically predict icd code clinical note however previous work ignore decisive information contained structured medical data ehrs hard captured noisy clinical note paper propose treeenhanced multimodal attention network treeman fuse tabular feature textual feature multimodal representation enhancing text representation treebased feature via attention mechanism treebased feature constructed according decision tree learned structured multimodal medical data capture decisive information icd coding apply multilabel classifier previous text model multimodal representation predict icd code experiment two mimic datasets show method outperforms prior stateoftheart icd coding approach code available urlhttpsgithubcomliuzichentreeman
multitask learning mtl achieved remarkable success natural language processing application work study multitask learning model multiple decoder variety biomedical clinical natural language processing task text similarity relation extraction named entity recognition text inference empirical result demonstrate mtl finetuned model outperform stateoftheart transformer model eg bert variant biomedical clinical domain adaptation respectively pairwise mtl demonstrates detail task improve decrease others particularly helpful context researcher hassle choosing suitable model new problem code model publicly available urlhttpsgithubcomncbinlpbluebert
manuscript describe umuteams participation semeval task shared task identify different persuasion technique meme task divided three subtasks one multimodal subtask identifying whether meme contains persuasion others hierarchical multilabel classification consider textual content alone multimodal setting text visual content multilingual task participated three subtasks focus english dataset approach based finetuning approach pretrained robertalarge model addition multimodal case textual visual content used lmm called llava extract image description combine meme text system performed well three subtasks achieving tenth best result hierarchical f fourth best subtask hierarchical f eighth best subtask b macro f
competitive debater often find facing challenging task debate topic know little minute prepare without access book internet often rely first principle commonplace argument relevant many topic refined past debate work aim explicitly define taxonomy principled recurring argument given controversial topic automatically identify argument relevant topic far know first time approach argument invention formalized made explicit context nlp main goal work show possible define taxonomy taxonomy suggested thought first attempt nonetheless coherent cover well relevant topic coincides professional debater actually argue speech facilitates automatic argument invention new topic
recently bert adopted document encoding stateoftheart text summarization model however sentencebased extractive model often result redundant uninformative phrase extracted summary also longrange dependency throughout document well captured bert pretrained sentence pair instead document address issue present discourseaware neural summarization model discobert discobert extract subsentential discourse unit instead sentence candidate extractive selection finer granularity capture longrange dependency among discourse unit structural discourse graph constructed based rst tree coreference mention encoded graph convolutional network experiment show proposed model outperforms stateoftheart method significant margin popular summarization benchmark compared bertbase model
paper report way constructing translation corpus contains source target text draft final version target text translation hosting site minna honyaku mnh made mnh publicly available april since user registered document translated february english japanese japanese english mnh provides integrated translationaid environment qredit enables translator look highquality dictionary wikipedia well search google seamlessly mnh keep translation log corpus consisting source text draft translation several version final translation constructed naturally mnh february document multiple translation version accumulated edited one translator corpus used selflearning inexperienced translator mnh potentially improving machine translation
describe utfpr system semevals task assessing humor edited news headline minimalist unsupervised system us word cooccurrence frequency large corpus capture unexpectedness mean capture funniness system placed nd shared task task found approach requires text used perform reliably unexpectedness alone sufficient gauge funniness humorous content target diverse target audience
contribution describes collection large diverse corpus speech recognition similar tool using crowdsourced donation built collection platform inspired mozilla common voice specialized need discus importance engaging community motivating contribute case competition given incentive platform easily read large amount utterance observed four case speaker freely donating thousand utterance also seen woman keener participate event throughout age group manually verifying large corpus monumental task attempt automatically verify part data using tool like marosijo montreal forced aligner method proved helpful especially detecting invalid utterance halving work needed crowdsourced verification
present refref tool viewing exploring coreference space publicly available research purpose unlike similar tool currently available whose main goal assist annotation process coreference link refref dedicated viewing exploring coreferenceannotated data whether manually tagged automatically resolved refref also highly customizable tool made available source code paper describe main functionality refref well possibility customization meet specific need user coreferenceannotated text
reasoning commonsense knowledge critical natural language understanding traditional method commonsense machine comprehension mostly focus one specific kind knowledge neglecting fact commonsense reasoning requires simultaneously considering different kind commonsense knowledge paper propose multiknowledge reasoning method exploit heterogeneous knowledge commonsense machine comprehension specifically first mine different kind knowledge including event narrative knowledge entity semantic knowledge sentiment coherent knowledge encode inference rule cost propose multiknowledge reasoning model selects inference rule specific reasoning context using attention mechanism reason summarizing valid inference rule experiment rocstories show method outperforms traditional model significantly
emojis composed convey intricate meaning like english phrase pioneering study present emojilexical composition elco dataset new resource offer parallel annotation emoji sequence corresponding english phrase dataset contains instance spanning diverse concept tangible one like right man abstract one full attention illustrating metaphoric composition focusing face writing hand elco enables analysis pattern shared emoji lexical composition corpus study discovered simple strategy like direct representation reduplication sufficient conveying certain concept richer metaphorical strategy essential expressing abstract idea introduce evaluative task emojibased textual entailment emote assess proficiency nlp model comprehending emoji composition finding reveals challenge understanding emoji composition zeroshot setting current model including chatgpt analysis indicates intricacy metaphorical composition contributes challenge encouragingly model show marked improvement finetuned elco dataset larger model excelling deciphering nuanced metaphorical composition
despite recent success neural taskoriented dialogue system developing realworld system involves accessing largescale knowledge base kb simply encoded neural approach memory network mechanism alleviate problem propose endtoend trainable texttosql guided framework learn neural agent interacts kb using generated sql query specifically neural agent first learns ask confirm customer intent multiturn interaction dynamically determining ground user constraint executable sql query fetch relevant information kb help method agent use less accurate fetched result generate useful response efficiently instead incorporating entire kb evaluate proposed method airdialogue dataset large corpus released google containing conversation customer booking flight ticket agent experimental result show significantly improves previous work term accuracy bleu score demonstrates ability achieve given task also good quality generated dialogue
paper propose effective way biasing attention mechanism sequencetosequence neural machine translation nmt model towards wellstudied statistical word alignment model show novel guided alignment training approach improves translation quality reallife ecommerce text consisting product title description overcoming problem posed many unknown word large typetoken ratio also show metadata associated input text topic category information significantly improve translation quality used additional signal decoder part network novel feature bleu score nmt system product title set improves even larger mt quality gain obtained domain adaptation general domain nmt system ecommerce data developed nmt system also performs well iwslt speech translation task ensemble four variant system outperforms phrasebased baseline bleu absolute
compounding prevalent wordformation process present interesting challenge computational model indeed relation compound constituent often complicated particularly chinese morphology character almost simultaneously bound free treated morpheme model wordformation process propose notch nonlinear transformation character embeddings model character jacobians notch model first learns nonlinear relation constituent word character jacobians describes character role word series experiment show notch model predicts embeddings real word constituent help account behavioral data pseudowords moreover also demonstrated character jacobians reflect character meaning taken together notch model character jacobians may provide new perspective studying wordformation process morphology modern deep learning
task sentiment modification requires reversing sentiment input preserving sentimentindependent content however aligned sentence content different sentiment usually unavailable due lack parallel data hard extract sentiment independent content reverse sentiment unsupervised way previous work usually reconcile sentiment transformation content preservation paper motivated fact nonemotional context eg staff provides strong cue occurrence emotional word eg friendly propose novel method automatically extract appropriate sentiment information learned sentiment memory according specific context experiment show method substantially improves content preservation degree achieves stateoftheart performance
advancement natural language processing given rise variety large language model llm capability extending realm complex problemsolving including brainteasers challenge linguistic fluency also logical reasoning paper document submission semeval brainteaser task investigate performance stateoftheart llm gpt gpt gemini model diverse set brainteasers using prompt engineering tool enhance model problemsolving ability experimented series structured prompt ranging basic integrating task description explanation comparative analysis sought determine combination model prompt yielded highest accuracy solving puzzle finding provide snapshot current landscape ai problemsolving highlight nuanced nature llm performance influenced complexity task sophistication prompt employed
clinical outcome prediction critical condition prediction patient management hospital capacity two kind medical data including time series signal recorded various device clinical note electronic health record ehr used two common prediction target mortality length stay traditional method focused utilizing time series data ignored clinical note development deep learning natural language processing nlp multimodal learning method exploited jointly model time series clinical note different modal however existing method failed fuse multimodal feature patient different view therefore propose patient multiview multimodal feature fusion network clinical outcome prediction firstly patient inner view propose utilize coattention module enhance finegrained feature interaction time series clinical note patient secondly patient outer view correlation patient reflected structural knowledge clinical note exploit structural information extracted clinical note construct patient correlation graph fuse patient multimodal feature graph neural network gnn experimental result mimiciii benchmark demonstrate superiority method
textprocessing algorithm annotate main component storyline presently great need corpus wellagreed annotation scheme text world theory cognitive linguistics offer model generalizes narrative structure form world building element character time space well text world switch conducted survey text world element annotated different project proposed annotation scheme instruction tested first science fiction story remember wholesale philip k dick corrected guideline added computer annotation verb form purpose get higher raters agreement tested short story gift magi henry result agreement among three raters risen due revision test annotation scheme guideline used annotating narrative corpus literary text criminal evidence teaching material quest etc
many recent nlp application including machine translation information retrieval could benefit semantic analysis language data sentence level paper present method automatic disambiguation verb valency frame czech data verb occurrence extracted feature describing local context experimented diverse type feature including morphological syntaxbased idiomatic animacy wordnetbased feature main contribution paper lie determining one useful disambiguation task considered feature classified using decision tree rulebased learning naive bayes classifier evaluated method using fold crossvalidation valeval manually annotated corpus frame annotation containing sentence syntaxbased feature shown effective used full set feature achieved accuracy baseline obtained assigning frequent frame
statistical machine translation model two component language model translation model paper describes improve quality translation model using common word pair extracted two asymmetric learning approach one set word pair extracted viterbi alignment using translation model set extracted viterbi alignment using another translation model created reversing language common word pair extracted word pair two set word pair conducted experiment using english japanese method improves quality original translation model experiment also show proposed learning method improves word alignment quality independent training domain translation model moreover show common word pair almost useful regular dictionary entry training purpose
inquiry conversation common form conversation aim complete investigation eg court hearing medical consultation police interrogation series focus shift occurs many model proposed generate smooth response given conversation history neglecting focus limit performance inquiry conversation order focus play key role paper investigate problem response generation inquiry conversation taking focus consideration propose novel focusaware response generation frg method jointly optimizing multilevel encoder set focal decoder generate several candidate response correspond different focus additionally focus ranking module proposed predict next focus rank candidate response experiment two orthogonal inquiry conversation datasets judicial medical domain demonstrate method generates result significantly better automatic metric human evaluation compared stateoftheart approach
recent advancement diffusion model user generate highquality image writing text prompt natural language however generating image desired detail requires proper prompt often unclear model reacts different prompt best prompt help researcher tackle critical challenge introduce diffusiondb first largescale texttoimage prompt dataset totaling tb containing million image generated stable diffusion million unique prompt hyperparameters specified real user analyze syntactic semantic characteristic prompt pinpoint specific hyperparameter value prompt style lead model error present evidence potentially harmful model usage generation misinformation unprecedented scale diversity humanactuated dataset provide exciting research opportunity understanding interplay prompt generative model detecting deepfakes designing humanai interaction tool help user easily use model diffusiondb publicly available urlhttpspoloclubgithubiodiffusiondb
since th century novel one defining form english writing mainstay popular entertainment academic criticism despite importance however computational study largescale structure novelsand many popular representation discourse modeling work well novelistic text paper describes highlevel representation plot structure track frequency mention different character topic emotional word time representation distinguish high accuracy real novel artificially permuted surrogate character important eliminating random permutation topic effective distinguishing beginning end
finetuning pretrained large language model parameterefficient manner widely studied effectiveness efficiency popular method lowrank adaptation lora offer notable approach hypothesizing adaptation process intrinsically lowdimensional although lora demonstrated commendable performance implemented fixed unalterable intrinsic rank might always ideal choice recognizing need flexible adaptation extend methodology lora innovative approach call sparse lowrank adaptation sora enables dynamic adjustment intrinsic rank adaptation process achieve incorporation gate unit optimized proximal gradient method training stage controlling cardinality rank sparsity gate subsequent inference stage eliminate parameter block corresponding zeroedout rank reduce sora module back concise yet rankoptimal lora approach strengthens representation power lora initializing higher rank efficiently taming temporarily increased number parameter via updating sparse way introduce sparsifying scheduler sora aiming examine impact number nonzero parameter model memorization generalization experimental result demonstrate sora outperform baseline even retained parameter training time
corpusbased treebank annotation known result incomplete coverage mid lowfrequency linguistic construction linguistic representation corpus annotation quality sometimes suboptimal large descriptive grammar cover also many mid lowfrequency construction argue use large descriptive grammar sample sentence basis specifying highercoverage grammatical representation present sample case ongoing project finclarin finntreebank grammatical representation documented annotator manual alongside manual annotation sample sentence extracted large descriptive grammar finnish outline linguistic representation morphology dependency syntax finnish show resulting grammar definition corpus documentation used task specification external subcontractor building parser engine use morphological dependency syntactic analysis large volume finnish parsebanking purpose resulting corpus finntreebank due release june contain ten million word publicly available corpus finnish automatic morphological dependency syntactic analysis use research corpus linguistics language engineering
paper describe endtoend simultaneous speechtotext texttotext translation system submitted iwslt online translation challenge system built adding waitk metalearning approach transformer architecture system evaluated different latency regime simultaneous texttotext translation achieved bleu score compared competition baseline score low latency regime average latency mboxleq simultaneous speechtotext system improves bleu score point competition baseline low latency regime average latency mboxleq
combine advantage probabilistic grammar generalized lr parsing algorithm constructing probabilistic lr parser given probabilistic contextfree grammar needed paper implementation issue adapting tomitas generalized lr parser graphstructured stack perform probabilistic parsing discussed wright wrigley proposed probabilistic lrtable construction algorithm nonleftrecursive contextfree grammar account left recursion method computing item probability using generation system linear equation presented notion deferred probability proposed mean dealing similar item set differing probability assignment
paper present mtrill project aimed investigating impact popular webbased machine translation mt tool cognitive processing english second language methodological approach main result presented
email chat communication tool increasingly important completing daily task accurate realtime phrase completion save time bolster productivity modern text prediction algorithm based large language model typically rely prior word message predict completion examine additional contextual signal previous message time subject affect performance commercial text prediction model compare contextual text prediction chat email message two largest commercial platform microsoft team outlook finding contextual signal contribute performance differently scenario email time context beneficial small relative gain baseline whereas chat scenario using tailored set previous message context yield relative improvement baseline across various critical serviceoriented text prediction metric
dependency parsing increasingly popular parsing formalism practice assignment provides practice exercise implementing shiftreduce dependency parser chen manning parser twolayer feedforward neural network student implement pytorch providing practice developing deep learning model exposure developing parser model
deep pretrained contextualized encoders like bert demonstrate remarkable performance range downstream task recent line research probing investigates linguistic knowledge implicitly learned model pretraining work probing operates task level linguistic task rarely uniform represented variety formalism linguisticsbased probing study thereby inevitably commits formalism used annotate underlying data choice formalism affect probing result investigate conduct indepth crossformalism layer probing study role semantics find linguistically meaningful difference encoding semantic role protorole information bert depending formalism demonstrate layer probing detect subtle difference implementation linguistic formalism result suggest linguistic formalism important dimension probing study along commonly used crosstask crosslingual experimental setting
present contribution sigmorphon shared task crosslinguality context morphology task contextual morphological analysis lemmatization submitted modification udpipe one bestperforming system conll shared task multilingual parsing raw text universal dependency overall winner shared task extrinsic parser evaluation first improvement use pretrained contextualized embeddings bert additional input network secondly use individual morphological feature regularization finally merge selected corpus language lemmatization task system exceeds submitted system wide margin lemmatization accuracy second best third morphological analysis system placed tightly second morphological analysis accuracy winning system
external syntactic semantic information largely ignored existing neural coreference resolution model paper present heterogeneous graphbased model incorporate syntactic semantic structure sentence proposed graph contains syntactic subgraph token connected based dependency tree semantic subgraph contains argument predicate node semantic role label edge applying graph attention network obtain syntactically semantically augmented word representation integrated using attentive integration layer gating mechanism experiment ontonotes benchmark show effectiveness proposed model
identifying causal relation event important task natural language processing area however task challenging event causality usually expressed diverse form often lack explicit causal clue existing method handle well problem especially condition lacking training data nonetheless human make correct judgement based background knowledge including descriptive knowledge relational knowledge inspired propose novel latent structure induction network lsin incorporate external structural knowledge task specifically make use descriptive knowledge devise descriptive graph induction module obtain encode graphstructured descriptive knowledge leverage relational knowledge propose relational graph induction module able automatically learn reasoning structure event causality reasoning experimental result two widely used datasets indicate approach significantly outperforms previous stateoftheart method
analyzed output multiple question answering qa model applied stanford question answering dataset squad identify core challenge qa system data set iterative process challenging aspect hypothesized qualitative analysis common error case classifier constructed predict whether squad test example likely difficult system answer based feature associated hypothesized aspect classifier performance used accept reject aspect indicator difficulty approach ensured hypothesis systematically tested simply accepted based preexisting bias explanation accepted based human evaluation individual example process also enabled u identify primary qa strategy learned model ie system determined acceptable answer type question selected acceptable answer span type containing highest density word present question within local vicinity passage
recent research shown large language model llm achieve remarkable translation performance supervised finetuning sft using small amount parallel data however sft simply instructs model imitate reference translation token level making vulnerable noise present reference hence assistance sft often reach plateau llm achieved certain level translation capability increasing size parallel data provide additional benefit overcome plateau associated imitationbased sft propose preferencebased approach built upon plackettluce model objective steer llm towards nuanced understanding translation preference holistic view also resilient absence gold translation build dataset named maple verify effectiveness approach includes multiple translation varying quality source sentence extensive experiment demonstrate superiority approach breaking plateau across diverse llm test setting indepth analysis underscore pivotal role diverse translation accurate preference score success approach
building opendomain dialogue system capable rich humanlike conversational ability one fundamental challenge language generation however even recent advancement field existing opendomain generative model fail capture utilize external knowledge leading repetitive generic response unseen utterance current work knowledgegrounded dialogue generation primarily focus persona incorporation searching factbased structured knowledge source wikipedia method take broader simpler approach aim improve raw conversation ability system mimicking human response behavior casual interaction found social medium utilizing joint retrievergenerator setup model query large set filtered comment data reddit act additional context seqseq generator automatic human evaluation opendomain dialogue datasets demonstrate effectiveness approach
multidimensional evaluation dominant paradigm human evaluation natural language generation nlg ie evaluating generated text multiple explainable dimension coherence fluency however automatic evaluation nlg still dominated similaritybased metric lack reliable framework comprehensive evaluation advanced model paper propose unified multidimensional evaluator unieval nlg reframe nlg evaluation boolean question answering qa task guiding model different question use one evaluator evaluate multiple dimension furthermore thanks unified boolean qa format able introduce intermediate learning phase enables unieval incorporate external knowledge multiple related task gain improvement experiment three typical nlg task show unieval correlate substantially better human judgment existing metric specifically compared topperforming unified evaluator unieval achieves higher correlation text summarization dialogue response generation also unieval demonstrates strong zeroshot learning ability unseen evaluation dimension task source code data pretrained evaluator available httpsgithubcommaszhongmingunieval
contextualised word embeddings powerful tool detect contextual synonym however current stateoftheart sota deep learning concept extraction method remain supervised underexploit potential context paper propose selfsupervised pretraining approach able detect contextual synonym concept training data created shallow matching apply methodology sparse multiclass setting concept extract phenotype information electronic health record investigate data augmentation technique address problem class sparsity approach achieves new sota unsupervised phenotype concept annotation clinical text f recall outperforming previous sota gain absolute point respectively finetuning little labelled data also outperform biobert clinicalbert extrinsic evaluation three icu benchmark also show benefit using phenotype annotated model feature
paper propose unified approach supporting different generation manner machine translation including autoregressive semiautoregressive refinementbased nonautoregressive model approach work repeatedly selecting position generating token selected position trained approach achieves better competitive translation performance compared strong taskspecific baseline model setting generalization ability benefit mainly new training objective propose validate approach wmt englishgerman iwslt germanenglish translation task experimental result encouraging
challenge towards developing nlp system world language understanding generalize typological difference relevant realworld application end propose mc morphologicallyaware framework behavioral testing nlp model use mc generate test probe model behavior light specific linguistic feature typologically diverse language evaluate stateoftheart language model generated test model excel test english highlight generalization failure specific typological characteristic temporal expression swahili compounding possessive finish finding motivate development model address blind spot
identifying relationship two article eg whether two article published different source describe breaking news critical many document understanding task existing approach modeling matching sentence pair perform well matching longer document embody complex interaction enclosed entity sentence model article pair propose concept interaction graph represent article graph concept match pair article comparing sentence enclose concept vertex series encoding technique aggregate matching signal graph convolutional network facilitate evaluation long article matching created two datasets consisting k pair breaking news article covering diverse topic open domain extensive evaluation proposed method two datasets demonstrate significant improvement wide range stateoftheart method natural language matching
recent text generation research increasingly focused openended domain story poetry generation model built task difficult evaluate automatically researcher space justify modeling choice collecting crowdsourced human judgment text quality eg likert score coherence grammaticality amazon mechanical turk amt paper first conduct survey openended text generation paper find vast majority fail report crucial detail amt task hindering reproducibility run series story evaluation experiment amt worker english teacher discover even strict qualification filter amt worker unlike teacher fail distinguish modelgenerated text humangenerated reference show amt worker judgment improve shown modelgenerated output alongside humangenerated reference enables worker better calibrate rating finally interview english teacher provide deeper insight challenge evaluation process particularly rating modelgenerated text
semantic dependency parsing aim identify semantic relationship word sentence form graph paper propose secondorder semantic dependency parser take consideration individual dependency edge also interaction pair edge show secondorder parsing approximated using mean field mf variational inference loopy belief propagation lbp unfold algorithm recurrent layer neural network therefore train parser endtoend manner experiment show approach achieves stateoftheart performance
present approach disambiguation cluster label capitalizes notion semantic similarity assign wordnet sens cluster label approach provides interesting insight document clustering provide basis developing novel approach word sense disambiguation
speaker identification verification system poor performance model training done one language testing done another situation unusual multilingual environment people able access system language prefers moment without noticing performance drop work study possibility using feature derived prosodic parameter order reinforce language robustness system first feature property term language session variability studied predicting increase language robustness framewise intonation energy value combined traditional mfcc feature experimental result confirm feature provide improvement speaker recognition rate languagemismatch condition whole study carried basque country bilingual region basque spanish language coexist
research related automatically detecting alzheimers disease ad important given high prevalence ad high cost traditional method since ad significantly affect acoustic spontaneous speech speech processing machine learning ml provide promising technique reliably detecting ad however speech audio may affected different type background noise important understand noise influence accuracy ml model detecting ad speech paper study effect fifteen type environmental noise five different category performance four ml model trained three type acoustic representation perform thorough analysis showing ml model acoustic feature affected different type acoustic noise show acoustic noise necessarily harmful certain type noise beneficial ad detection model help increasing accuracy provide recommendation utilize acoustic noise order achieve best performance result ml model deployed real world
assess effectiveness medical intervention researcher must conduct timeintensive manual literature review nlp system help automate assist part expensive process support goal release m multidocument summarization medical study dataset k document k summary derived scientific literature dataset facilitates development system assess aggregate contradictory evidence across multiple study first largescale publicly available multidocument summarization dataset biomedical domain experiment summarization system based bart promising early result though significant work remains achieve higher summarization quality formulate summarization input target free text structured form modify recently proposed metric assess quality system generated summary data model available urlhttpsgithubcomallenaims
paper describe asr system german built university edinburgh uedin iwslt evaluation campaign asr major challenge overcome find suitable acoustic training data due lack expertly transcribed acoustic speech data german acoustic model training performed publicly available data crawled internet evaluation lack manual segmentation utterance handled two different way generating automatic segmentation treating entire input file single segment demonstrating latter method superior current task obtained wer dev set test set
selfaugmentation received increasing research interest recently improve named entity recognition ner performance lowresource scenario token substitution mixup two feasible heterogeneous selfaugmentation technique ner achieve effective performance certain specialized effort noticeably selfaugmentation may introduce potentially noisy augmented data prior research mainly resorted heuristic rulebased constraint reduce noise specific selfaugmentation method individually paper revisit two typical selfaugmentation method ner propose unified metareweighting strategy achieve natural integration method easily extensible imposing little effort specific selfaugmentation method experiment different chinese english ner benchmark show token substitution mixup method well integration achieve effective performance improvement based metareweighting mechanism enhance advantage selfaugmentation technique without much extra effort
among typical forensic voice comparison fvc approach acousticphonetic statistical approach suitable textdependent fvc fully exploit available timevarying information speech modelling automatic approach hand essentially deal textindependent case mean temporal information explicitly incorporated modelling textdependent likelihood ratio lrbased fvc study particular adopt automatic approach preliminary lrbased fvc study compare two statistical model hidden markov model hmm gaussian mixture model gmm calculation forensic lr using speech data fvc experiment carried using different length japanese short word forensically realistic challenging condition two speech token model training lr estimation loglikelihoodratio cost cllr used assessment metric study demonstrates hmm system constantly outperforms gmm system term average cllr value however word longer three mora needed advantage hmm become evident sevenmora word example hmm outperformed gmm cllr value
paper bring light novel intersection corpus linguistics behavioral data employed evaluation metric resource lowdensity language drawing wellestablished psycholinguistic factor using lowdensity language maltese test case highlight challenge face researcher developing resource language sparsely available data identify key empirical link corpus psycholinguistic research tool evaluate corpus resource specifically compare two robust variable identified psycholinguistic literature word frequency measured corpus word familiarity measured rating task apply statistical method evaluate extent familiarity rating predict corpus frequency verb maltese corpus three angle token frequency frequency distribution morphosyntactic type binyan research provides multidisciplinary approach corpus development evaluation particular lessresourced language lack wide access diverse language data
work introduces novel threeclass annotation scheme textbased dementia classification patient based recorded visit interaction multiple model developed utilising bert roberta distilbert two approach employed improve representation dementia sample oversampling underrepresented data point original pitt dataset combining pitt holland kempler datasets distilbert model trained either oversampled pitt dataset combined dataset performed best classifying dementia class specifically model trained oversampled pitt dataset one trained combined dataset obtained stateoftheart performance overall accuracy macroaveraged fscore respectively model output manually inspected saliency highlighting using local interpretable modelagnostic explanation lime provide better understanding prediction
dense retrieval widely used entity linking retrieve entity largescale knowledge base mainstream technique based dualencoder framework encodes mention entity independently calculates relevance via rough interaction metric resulting difficulty explicitly modeling multiple mentionrelevant part within entity match divergent mention aiming learning entity representation match divergent mention paper proposes multiview enhanced distillation mvd framework effectively transfer knowledge multiple finegrained mentionrelevant part within entity crossencoders dualencoders entity split multiple view avoid irrelevant information oversquashed mentionrelevant view design crossalignment selfalignment mechanism framework facilitate finegrained knowledge distillation teacher model student model meanwhile reserve globalview embeds entity whole prevent dispersal uniform information experiment show method achieves stateoftheart performance several entity linking benchmark
korean often referred lowresource language research community claim partially true also availability resource inadequately advertised curated work curate review list korean corpus first describing institutionlevel resource development iterate list current open datasets different type task propose direction opensource dataset construction release done lessresourced language promote research
present bot dialog system developed st nip conversational intelligence challenge convai aim competition implement bot capable conversing human based given passage text enable conversation implemented set skill bot including chitchat topic detection text summarization question answering question generation system trained supervised setting using dialogue manager select appropriate skill generating response latter allows developer focus skill implementation rather finite state machine based dialog manager proposed system bot competition average dialogue quality score given human evaluator source code trained model bot available github
last several year speechbased question answering qa become popular contrast pure search engine based approach desktop opendomain qa system much powerful precise used speech application speechbased question answering system often rely predefined grammar speech understanding order improve coverage complex ai system reused speech pattern used generate textual entailment pattern make multimodal question understanding robust exemplify context domainspecific dialogue scenario result written text input component eg textual input field deal flexible input according derived textual entailment pattern multimodal qa dialogue spanning several domain interest ie personal address book entry question music domain politician celebrity demonstrates textual input mode used multimodal dialogue shell
document equally important language processing increasingly finding use supplement questionnaire assess psychological attribute consenting individual approach neglect consider whether document individual equally informative paper present novel model us messagelevel attention learn relative weight user social medium post assessing five factor personality trait demonstrate model messagelevel attention outperform wordlevel attention ultimately yield stateoftheart accuracy five trait using word message attention combination past approach average increase pearson r addition examination highsignal post identified model provides insight relationship language personality helping inform future work
demonstrate coreference resolution procedural text significantly improved performing transformationbased entity linking prior coreference relation identification event text introduce change state participating entity often impossible accurately link entity anaphoric coreference relation without understanding transformation entity undergo show adding event semantics help better model entity coreference argue transformation predicate creation verb introduce new entity discourse kind generalized result role typically textually mentioned allows u model procedural text process graph compute coreference type two entity recipe present annotation methodology corpus generated well describe experiment coreference resolution entity mention processoriented model event
encouraging neural machine translation satisfy terminology constraint present new approach encourage neural machine translation satisfy lexical constraint method act training step thereby avoiding introduction extra computational overhead inference step proposed method combine three main ingredient first one consists augmenting training data specify constraint intuitively encourages model learn copy behavior encounter constraint term compared previous work use simplified augmentation strategy without source factor second ingredient constraint token masking make even easier model learn copy behavior generalize better third one modification standard cross entropy loss bias model towards assigning high probability constraint word empirical result show method improves upon related baseline term bleu score percentage generated constraint term
metaphor generation attempt replicate human creativity language attractive challengeable text generation task previous effort mainly focus templatebased rulebased method result lack linguistic subtlety order create novel metaphor propose neural approach metaphor generation explore shared inferential structure metaphorical usage literal usage verb approach require manually annotated metaphor training extract metaphorically used verb metaphorical sens unsupervised way train neural language model wiki corpus generate metaphor conveying assigned metaphorical sens improved decoding algorithm automatic metric human evaluation demonstrate approach generate metaphor good readability creativity
korean quantitative speech act study usually conducted single utterance unspecified source study annotate sentence national institute korean language messenger corpus national petition corpus well example sentence academic paper contemporary korean vlogging check discrepancy human annotation model prediction particular sentence difference locutionary illocutionary force analyze cause error see stylistic feature used particular domain affect correct inference speech act see necessity build analyze balanced corpus various text domain taking account case different usage role eg messenger conversation belonging private conversation petition corpusvlogging script unspecified audience
paper examines problem adapting neural machine translation system new lowresourced language lrls effectively rapidly possible propose method based starting massively multilingual seed model trained aheadoftime continuing training data related lrl contrast number strategy leading novel simple yet effective method similarlanguage regularization jointly train lrl interest similar highresourced language prevent overfitting small lrl data experiment demonstrate massively multilingual model even without explicit adaptation surprisingly effective achieving bleu score data lrl proposed similarlanguage regularization method improves adaptation method bleu point average lrl setting
international workshop spoken language translation iwslt evaluation campaign featured two task lowresource machine translation speech translation first task manually transcribed speech translated basque english since translation direction underresourced language pair participant encouraged use additional parallel data related language second task participant translate english audio german text full speechtranslation system baseline condition participant free use composite architecture endtoend condition restricted use single model task year eight research group took part lowresource machine translation task nine speech translation task
paper propose method generate personalized filled pause fps groupwise prediction model compared fluent text generation disfluent text generation widely explored generate humanlike text addressed disfluent text generation usage disfluency fps rephrases word fragment differs speaker speaker thus generation personalized fps required however difficult predict sparsity position frequency difference less frequently used fps moreover sometimes difficult adapt fp prediction model speaker large variation tendency within speaker address issue propose method build groupdependent prediction model grouping speaker basis tendency use fps method require large amount data time train speaker model introduce loss function word embedding model suitable fp prediction experimental result demonstrate groupdependent model predict fps higher score nonpersonalized one introduced loss function word embedding model improve prediction performance
inalienable possession differs alienable possession former eg kinship partwhole relation intrinsic semantic dependency possessor possessum paper report two study used acceptabilityjudgment task investigate whether native mandarin speaker experienced different level interpretational cost resolving different type possessive relation ie inalienable possession kinship term body part alienable one expressed within relative clause result show sentence received higher acceptability rating body part possessum compared sentence alienable possessum indicating inherent semantic dependency facilitates resolution however inalienable kinship term received lowest acceptability rating argue kinship term human feature appeared beginning experimental sentence tended interpreted subject shallow processing feature contradicted semanticsyntactic requirement experimental sentence
paper address challenge faced indian language leveraging deep learning natural language processing nlp due limited resource annotated datasets transformerbased architecture specifically focus telugu aim construct telugu morph analyzer dataset comprising sentence furthermore assess performance established multilingual transformer model mbert xlmr indicbert monolingual transformer model trained scratch extensive telugu corpus comprising sentence bertte finding demonstrate efficacy transformerbased representation pretrained telugu data improving performance telugu morph analyzer surpassing existing multilingual approach highlight necessity developing dedicated corpus annotated datasets machine learning model monolingual setting present benchmark result telugu morph analyzer achieved simple finetuning dataset
adversarial training widely acknowledged effective defense adversarial attack however also well established achieving robustness generalization adversarially trained model involves tradeoff goal work provide depth comparison different approach adversarial training language model specifically study effect pretraining data augmentation well training time input perturbation v embedding space perturbation robustness generalization transformerbased language model finding suggest better robustness achieved pretraining data augmentation training input space perturbation however training embedding space perturbation significantly improves generalization linguistic correlation analysis neuron learned model reveal improved generalization due specialized neuron best knowledge first work carry deep qualitative analysis different method generating adversarial example adversarial training language model
dynamic topic modeling facilitates identification topical trend time temporal collection unstructured document introduce novel unsupervised neural dynamic topic model named recurrent neural networkreplicated softmax model rnnrsm discovered topic time influence topic discovery subsequent time step account temporal ordering document explicitly modeling joint distribution latent topical dependency time using distributional estimator temporal recurrent connection applying rnnrsm year article nlp research demonstrate compared stateofthe art topic model rnnrsm show better generalization topic interpretation evolution trend also introduce metric named span quantify capability dynamic topic model capture word evolution topic time
answering natural language question knowledge base missing fact incomplete schema limited scope naturally lead many question unanswerable answerability explored qa setting studied qa knowledge base kbqa create grailqability new benchmark kbqa dataset unanswerability first identifying various form kb incompleteness make question unanswerable systematically adapting grailqa popular kbqa dataset answerable question experimenting three stateoftheart kbqa model find three model suffer drop performance even suitable adaptation unanswerable question addition often detect unanswerability wrong reason find specific form unanswerability particularly difficult handle underscore need research making kbqa system robust unanswerability
session designed help company people business translation evaluate mt output show human translator feedback tweaked make process objective accurate hear recommendation insight takeaway improve procedure human evaluation achieved understand human eval study machine metric result coheres think future translator look like final human touch automated mt review
automatic speech recognition asr system increasingly prevalent education healthcare employment mobile technology face significant challenge inclusivity particularly millionstrong global community people stutter system often fail accurately interpret speech pattern deviating typical fluency leading critical usability issue misinterpretation study evaluates six leading asrs analyzing performance realworld dataset speech sample individual stutter synthetic dataset derived widelyused librispeech benchmark synthetic dataset uniquely designed incorporate various stuttering event enables indepth analysis asrs handling disfluent speech comprehensive assessment includes metric word error rate wer character error rate cer semantic accuracy transcript result reveal consistent statistically significant accuracy bias across asrs disfluent speech manifesting significant syntactical semantic inaccuracy transcription finding highlight critical gap current asr technology underscoring need effective bias mitigation strategy addressing bias imperative improve technology usability people stutter also ensure equitable inclusive participation rapidly evolving digital landscape
recently relationship automated human evaluation topic model called question method developer staked efficacy new topic model variant automated measure failure approximate human preference place model uncertain ground moreover existing evaluation paradigm often divorced realworld usemotivated content analysis dominant realworld use case topic modeling analyze two related aspect topic model affect effectiveness trustworthiness practice purpose stability estimate extent model discovered category align humandetermined category data find neural topic model fare worse respect compared established classical method take step toward addressing issue tandem demonstrating straightforward ensembling method reliably outperform member ensemble
multilingual sense code may chart constantsense connection path across language writer versed target language may nonetheless proofread sense translation edit ensure meaning conveyed wish language translationready format may thus produced serve printingpress plate precise automatic translation language plurality language translationready format may describe word full document comprehensive code specifies multilingual sense code relevant information word standardized fashion digitally forming unified languageindependent tagging system unified languageindependent lexicon
find existing language modeling datasets contain many nearduplicate example long repetitive substring result unprompted output language model trained datasets copied verbatim training data develop two tool allow u deduplicate training datasetsfor example removing c single word english sentence repeated time deduplication allows u train model emit memorized text ten time less frequently require fewer training step achieve better accuracy also reduce traintest overlap affect validation set standard datasets thus allowing accurate evaluation code deduplication released urlhttpsgithubcomgoogleresearchdeduplicatetextdatasets
herein present languagemodelbased evaluator deletionbased sentence compression view task series deletionandevaluation operation using evaluator specifically evaluator syntactic neural language model first built learning syntactic structural collocation among word subsequently series trialanderror deletion operation conducted source sentence via reinforcement learning framework obtain best target compression empirical study show proposed model effectively generate readable compression comparable superior several strong baseline furthermore introduce sentence test set largescale dataset setting new baseline future research
broad major category machine reading comprehension mrc generalized goal discriminative mrc answer prediction given material however focus various discriminative mrc task may diverse enough multichoice mrc requires model highlight integrate potential critical evidence globally extractive mrc focus higher local boundary preciseness answer extraction among previous work lack unified design pertinence overall discriminative mrc task fill gap propose lightweight posenhanced iterative coattention network poinet first attempt unified modeling pertinence handle diverse discriminative mrc task synchronously nearly without introducing parameter lite unified design brings model significant improvement encoder decoder component evaluation result four discriminative mrc benchmark consistently indicate general effectiveness applicability model code available urlhttpsgithubcomyilinpoinet
knowledge graph embedding model recently received significant attention literature model learn latent semantic representation entity relation given knowledge base representation used infer missing knowledge paper study question well recent embedding model perform task knowledge base completion ie task inferring new fact incomplete knowledge base argue entity ranking protocol currently used evaluate knowledge graph embedding model suitable answer question since subset model prediction evaluated propose alternative entitypair ranking protocol considers model prediction whole thus suitable task conducted experimental study standard datasets found performance popular embeddings model unsatisfactory new protocol even datasets generally considered easy moreover found simple rulebased model often provided superior performance finding suggest need research embedding model well training strategy task knowledge base completion
wikipedia increasingly used knowledge base opendomain named entity linking disambiguation task dictionary entity surface form play important role finding set candidate entity mention text existing dictionary mostly rely wikipedia link structure like anchor text redirect link disambiguation link paper introduce dictionary entity linking includes name variation extracted wikipedia article text addition name variation derived wikipedia link structure approach show increase coverage entity mention dictionary comparison wikipedia based dictionary
creating ontology expensive task vision automatically generate ontology based set relevant document create kickstart ontology creating session paper focus enhancing two often used method openie cooccurrences evaluate method two document set one pizza one agriculture domain method evaluated using two type fscore objective quantitative human assessment subjective qualitative result show cooc performs objectively subjectively better openie filtering method based keywords wordvec perform similarly filtering method perform better compared openie similar cooc coocnvp performs best especially considering subjective evaluation although investigated method provide good start extracting ontology set domain document various improvement still possible especially natural language based method
advancement natural language processing nlp system healthcare hinge language model ability interpret intricate information contained within clinical note process often requires integrating information various time point patient medical history however earlier clinical language model pretrained context length limited roughly one clinical document study introduce clinicalmamba specialized version mamba language model pretrained vast corpus longitudinal clinical note address unique linguistic characteristic information processing need medical domain clinicalmamba model million billion parameter demonstrate superior performance modeling clinical language across extended text length compared mamba clinical model based longformer llama fewshot learning clinicalmamba achieves notable benchmark speed performance outperforming existing clinical language model large language model like gpt longitudinal clinical task
crosslingual phenomenon quite common informal context like social medium user likely mix native language english language however study focused far analyzing crosslingual interaction voiceassistant data present peculiar feature term sentence length named entity use spoken language also little attention posed european country english frequently used second language paper present largescale empirical analysis crosslingual phenomenon codemixing linguistic borrowing foreign named entity interaction largescale voice assistant european country first introduce general highlyscalable technique generate synthetic mixed training data annotated tokenlevel language label train two neural network model predict evaluate model synthetic dataset real dataset codeswitched utterance showing best performance obtained character convolution based model result analysis highlight different behavior country italy highest ratio crosslingual utterance spain marked preference keeping spanish word research paired increase crosslingual phenomenon time motivates research developing multilingual natural language understanding nlu model naturally deal crosslingual interaction
paper present ufaluld team system blp shared task sentiment analysis bangla social medium post task involves classifying text positive negative neutral sentiment part task conducted series experiment several pretrained sequence classification model xlmroberta banglabert bangla bert base multilingual bert among bestperforming model based xlmrobertabase architecture outperforms baseline model system ranked th among team participated task
recent year witnessed emergence textual commonsense knowledge base aimed providing nuanced contextrich knowledge integration external commonsense language model shown key enabler advancing stateoftheart wide range nlp task however incorporating textual commonsense description computationally expensive compared encoding conventional symbolic knowledge paper propose method improve efficiency without modifying model idea group training sample similar commonsense description single batch thus reusing encoded description across multiple sample theoretically investigate problem demonstrate upper bound reduced classic textitgraph kcut problem consequently propose spectral clusteringbased algorithm solve problem extensive experiment illustrate proposed batch partitioning approach effectively reduces computational cost preserving performance efficiency improvement pronounced larger datasets device memory capacity attesting practical utility largescale application
language model process syntactically complex sentence use representation syntax manner consistent grammar language propose alterrep interventionbased method address question linguistic feature given sentence alterrep generates counterfactual representation altering feature encoded leaving tact aspect original representation measuring change model word prediction behavior counterfactual representation substituted original one draw conclusion causal effect linguistic feature question model behavior apply method study bert model different size process relative clause rcs find bert variant use rc boundary information word prediction manner consistent rule english grammar rc boundary information generalizes considerable extent across different rc type suggesting bert represents rcs abstract linguistic category
natural language generation nlg critical component spoken dialogue system classic nlg divided two phase sentence planning deciding overall sentence structure surface realization determining specific word form flattening sentence structure string many simple nlg model based recurrent neural network rnn sequencetosequence seqseq model basically contains encoderdecoder structure nlg model generate sentence scratch jointly optimizing sentence planning surface realization using simple cross entropy loss training criterion however simple encoderdecoder architecture usually suffers generating complex long sentence decoder learn grammar diction knowledge paper introduces hierarchical decoding nlg model based linguistic pattern different level show proposed method outperforms traditional one smaller model size furthermore design hierarchical decoding flexible easilyextendible various nlg system
present vpsgradeup set graded human decision usage pattern english lexical verb pattern dictionary english verb patrick hank annotation contains verb lemma batch concordance given lemma kwic concordance provide graded human decision well individual pdev pattern particular lemma illustrate given concordance indicated point likert scale pdev pattern annotation pursuing pilot investigation foundation human clustering disambiguation decision respect usage pattern verb context data set publicly available urlhttphdlhandlenet
describe efficient hierarchical method compute attention transformer architecture proposed attention mechanism exploit matrix structure similar hierarchical matrix hmatrix developed numerical analysis community linear run time memory complexity perform extensive experiment show inductive bias embodied hierarchical attention effective capturing hierarchical structure sequence typical natural language vision task method superior alternative subquadratic proposal point average long range arena benchmark also set new sota test perplexity onebillion word dataset x fewer model parameter previousbest transformerbased model
fewshot classification powerful technique training requires substantial computing power data propose efficient method small model size less training data training instance per class proposed method ancsetfit target low data scenario anchoring task label information sentence embeddings finetuning sentence transformer model us contrastive learning triplet loss enforce training instance class closest textual semantic label information embedding space thereby learning embed different class instance distinct ancsetfit obtains strong performance datasparse scenario compared existing method across sst emotion detection ag news data even two example per class
increasing interest modeling style choice dialog example enabling dialog system adapt user commonly assumed user stable characteristic interaction style truth assumption well examined investigated using vectorspace model interaction style derived switchboard corpus telephone conversation broad set prosodicbehavior feature individual exhibited interaction style tendency generally far stable predictive model based individual tendency outperforming speakerindependent model tendency somewhat stronger speaker including generally male dimension variation
major challenge video captioning combine audio visual cue existing multimodal fusion method shown encouraging result video understanding however temporal structure multiple modality different granularity rarely explored selectively fuse multimodal representation different level detail remains uncharted paper propose novel hierarchically aligned crossmodal attention haca framework learn selectively fuse global local temporal dynamic different modality furthermore first time validate superior performance deep audio feature video captioning task finally haca model significantly outperforms previous best system achieves new stateoftheart result widely used msrvtt dataset
meaning bankingcreating semantically annotated corpus purpose semantic parsing generationis challenging task quite simple come complex meaning representation hard design simple meaning representation capture many nuance meaning paper list lesson learned nearly ten year meaning annotation development groningen meaning bank bos et al parallel meaning bank abzianidze et al paper format rather unconventional explicit related work methodology section result discussion current snippet abstract actually introductory preface instead structure inspired work traum bender list start brief overview existing meaning bank section rest item roughly divided three group corpus collection section annotation method section design meaning representation section hope overview give inspiration guidance creating improved meaning bank future
show lp constraint together language specific constraint could interpreted metarule extended headcorner parsing algorithm using weakened id rule schema theory hpsg pollard sag
paper proposes new idea us wikipedia category answer type defines candidate set inside wikipedia focus given question searched hierarchy wikipedia main page searching strategy combine headnoun matching synonym matching provided semantic resource set answer candidate determined entry hierarchy wikipedia hyponymy hierarchy wordnet experimental result show approach find candidate set smaller size achieve better performance especially artifact organization type performance better stateoftheart chinese factoid qa system
paper present innovative approach tailored specific characteristic closeddomain dialogue system leveraging scenario dialog graph method effectively address challenge posed highly specialized field context comprehension paramount importance modeling dialogue sequence transition intent representing distinct goal request approach focus accurate intent prediction generating contextually relevant response study conduct thorough evaluation comparing performance stateoftheart sentence encoders conjunction graphbased model across diverse datasets encompassing open closed domain result highlight superiority methodology offering fresh perspective integration advanced sentence encoders graph model precise contextuallydriven intent prediction dialogue system additionally use approach enhances transparency generated output enabling deeper understanding reasoning behind system response study significantly advance field dialogue system providing valuable insight effectiveness potential limitation proposed approach
hierarchical text classification htc challenging task aim extract label tree structure corresponding given text discriminative method usually incorporate hierarchical structure information encoding process generative method decode feature according however data distribution varies widely among different category sample current method ignore data imbalance making prediction biased susceptible error propagation paper propose implicitly augmented generativ e framework distribution modification hierarchical text classification image specifically translate distribution original sample along various direction implicit augmentation get diverse data furthermore given scarcity sample tail class adjust distribution transferring knowledge class label space way generative framework learns better beginning feature sequence without prediction bias avoids misled wrong prediction head class experimental result show image obtains competitive result compared stateoftheart method prove superiority unbalanced data
spanish official language country arrived mean overseas colonisation close contact several coexistent language rich regional cultural diversity produced variety divert study divergence databased approach according qualitative quantitative effect word embeddings generate embeddings spanish country examine topology space due similarity variety contrast happens different language bilingual topological study first scrutinise behaviour three isomorphism measure quasiisomorphic setting relational similarity eigenvalue similarity gromovhausdorff distance use trustworthy measure quantify divergence among variety finally use departure isomorphism build relational tree spanish variety hierarchical clustering
paper present result shared task hosted second dialdoc workshop documentgrounded dialogue conversational question answering colocated acl primary goal shared task build goaloriented informationseeking conversation system grounded domain document dialogue could correspond multiple subtasks based different document task generate agent response natural language given dialogue document context two task setting leaderboards based set domain seen one unseen domain unseen team participating dev phase team participating dev test phase multiple submission significantly outperform baseline bestperforming system achieves f total seen task f total unseen task
neural machine translation nmt currently exhibit bias producing translation short overgenerating frequent word show poor robustness copy noise training data domain shift recent work tied shortcoming beam search de facto standard inference algorithm nmt eikema aziz propose use minimum bayes risk mbr decoding unbiased sample instead paper empirically investigate property mbr decoding number previously reported bias failure case beam search find mbr still exhibit length token frequency bias owing mt metric used utility function mbr also increase robustness copy noise training data domain shift
crossdomain sentiment classification drawn much attention recent year existing approach focus learning domaininvariant representation source target domain pay attention domainspecific information despite nontransferability domainspecific information simultaneously learning domaindependent representation facilitate learning domaininvariant representation paper focus aspectlevel crossdomain sentiment classification propose distill domaininvariant sentiment feature help orthogonal domaindependent task ie aspect detection built aspect varying widely different domain conduct extensive experiment three public datasets experimental result demonstrate effectiveness method
even common nlp task sufficient supervision available many language morphological tagging exception work presented explore transfer learning scheme whereby train characterlevel recurrent neural tagger predict morphological taggings highresource language lowresource language together learning joint character representation among multiple related language successfully enables knowledge transfer highresource language lowresource one
arabic collection dialectal variant historically related significantly different difference seen across region country even city country previous work arabic dialect identification focused mainly specific dialect level region country province city using levelspecific resource different effort used different schema label paper present first effort aiming defining standard unified threelevel hierarchical schema regioncountrycity dialectal arabic classification map different data set unified schema use common mapping facilitate aggregating data set test value aggregation building language model using dialect identification make label mapping code aggregated language model publicly available
conversational question answering convqa required answer current question conditioned observable paragraphlevel context conversation history previous work intensively studied historydependent reasoning perceive absorb topicrelated information prior utterance interactive encoding stage yielded significant improvement compared historyindependent reasoning paper strengthens convqa encoder establishing longdistance dependency among global utterance multiturn conversation use multilayer transformer resolve longdistance relationship potentially contribute reweighting attentive information historical utterance experiment quac show method obtains substantial improvement yielding f score source code available urlhttpsgithubcomjaytsienghr
variational autoencoders vaes widely used natural language generation due regularization latent space however generating sentence continuous latent space explicitly model syntactic information paper propose generate sentence disentangled syntactic semantic space proposed method explicitly model syntactic information vaes latent space using linearized tree sequence leading better performance language generation additionally advantage sampling disentangled syntactic semantic latent space enables u perform novel application unsupervised paraphrase generation syntax transfer generation experimental result show proposed model achieves similar better performance various task compared stateoftheart related work
internet meme emerged increasingly popular mean communication web although meme typically intended elicit humour increasingly used spread hatred trolling cyberbullying well target specific individual community society political sociocultural psychological ground previous work focused detecting harmful hateful offensive meme general identifying meme attack ie victim remains challenging underexplored area attempt address problem paper end create dataset annotate meme victim name targeted person organization communityies propose disarm detecting victim targeted harmful meme framework us namedentity recognition person identification detect entity meme referring incorporates novel contextualized multimodal deep neural network classify whether meme intends harm entity perform several systematic experiment three different test set corresponding entity seen training ii seen harmful target training iii seen training evaluation show disarm significantly outperforms unimodal multimodal system finally demonstrate disarm interpretable comparatively generalizable reduce relative error rate harmful target identification absolute multimodal baseline system
propose neural model generate highquality text structured representation based minimal recursion semantics mr mr rich semantic representation encodes precise semantic detail representation abstract meaning representation amr show sequencetosequence model map linearization dependency mr graphbased representation mr text achieve bleu score trained gold data performance model improved using highprecision broad coverage grammarbased parser generate large silver training corpus achieving final bleu score full test set subset test data closely matching silver data domain result suggest mrsbased representation good choice application need structured semantics ability produce natural language text output
coaching involves classroom observation expert feedback widespread fundamental part teacher training however majority teacher access consistent high quality coaching due limited resource access expertise explore whether generative ai could become costeffective complement expert feedback serving automated teacher coach propose three teacher coaching task generative ai scoring transcript segment based classroom observation instrument bidentifying highlight missed opportunity good instructional strategy c providing actionable suggestion eliciting student reasoning recruit expert math teacher evaluate zeroshot performance chatgpt task elementary math classroom transcript result reveal chatgpt generates response relevant improving instruction often novel insightful example model suggestion point place transcript teacher already implementing suggestion work highlight challenge producing insightful novel truthful feedback teacher paving way future research address obstacle improve capacity generative ai coach teacher
computational approach noun ellipsis resolution sparse naive rulebased approach us syntactic feature constraint marking noun ellipsis licensors selecting antecedent paper ellipsis research exploring several statistical neural model subtasks involved ellipsis resolution process addressing representation contribution manual feature proposed previous research using best performing model build endtoend supervised machine learning ml framework task improves existing f score detection resolution subtask experiment demonstrate robust score pretrained bert bidirectional encoder representation transformer embeddings word representation importance manual feature highlighting syntactic semantic characteristic ellipsis phenomenon classification decision notice simple multilayar perceptron mlp work well detection ellipsis however recurrent neural network rnn better choice much harder resolution step
paper analyze twitter message tweet collected first month covid pandemic europe regard sentiment implemented neural network sentiment analysis using multilingual sentence embeddings separate result country origin correlate temporal development event country allows u study effect situation people mood see example lockdown announcement correlate deterioration mood almost surveyed country recovers within short time span
persuasion common online argument discussion forum analyze persuasive strategy important understand individual construct post comment based semantics argumentative component addition understanding construct argument understanding user post interacts post ie argumentative interpost relation still remains challenge therefore study developed novel annotation scheme corpus capture usergenerated innerpost argument interpost relation user changemyview persuasive forum corpus consists argument elementary unit eu ie proposition eutoeu argumentative relation interpost argumentative relation thread analyzed annotated corpus identify characteristic online persuasive argument result revealed persuasive document claim nonpersuasive one different interaction pattern among persuasive nonpersuasive document corpus used resource analyzing persuasiveness training argument mining system identify extract argument structure annotated corpus annotation guideline made publicly available
developing agent engage complex goaloriented dialogue challenging partly main learning signal sparse long conversation paper propose divideandconquer approach discovers exploit hidden structure task enable efficient policy learning first given successful example dialogue propose subgoal discovery network sdn divide complex goaloriented task set simpler subgoals unsupervised fashion use subgoals learn multilevel policy hierarchical reinforcement learning demonstrate method building dialogue agent composite task travel planning experiment simulated real user show approach performs competitively stateoftheart method requires humandefined subgoals moreover show learned subgoals often human comprehensible
justification explanation support veracity assigned claim factchecking however task justification generation previously oversimplified summarization factcheck article authored factcheckers therefore propose realistic approach generate justification based retrieved evidence present new benchmark dataset called exclaim explainable factchecking realworld claim introduce justilm novel fewshot justification generation based retrievalaugmented language model using factcheck article auxiliary resource training experiment show justilm achieves promising performance justification generation compared strong baseline also enhance veracity classification straightforward extension code dataset released httpsgithubcomznhyjustilm
despite original goal jointly learn align translate neural machine translation nmt model especially transformer often perceived learning interpretable word alignment paper show nmt model learn interpretable word alignment could revealed proper interpretation method propose series method modelagnostic able applied either offline online require parameter update architectural change show force decoding setup alignment induced interpretation method better quality fastalign system performing free decoding agree well alignment induced automatic alignment tool
work aim identify negative comment associated counterspeechxenophobia homophobiatransphobia misandry misogyny noneoftheabove category order identify category given dataset propose three different model traditional machine learning technique deep learning model transfer learning model called bert also used analyze text tamil dataset training model train dataset test model validation data team participated shared task organised dravidianlangtech secured th rank task abusive comment detection tamil macro f score also run submitted abusive comment detection codemixed language tamilenglish secured th rank macrof score
communication human would recognize emotion interlocutor respond appropriate emotion empathy comfort toward developing dialogue system humanlike ability propose method build dialogue corpus annotated two kind emotion collect dialogue twitter annotate utterance emotion speaker put utterance expressed emotion emotion listener felt listening utterance experienced emotion built dialogue corpus japanese using method statistical analysis revealed difference expressed experienced emotion conducted experiment recognition two kind emotion experimental result indicated difficulty recognizing experienced emotion effectiveness multitask learning two kind emotion hope constructed corpus facilitate study emotion recognition dialogue emotionaware dialogue response generation
retrospective study compared early speech development infant cerebral palsy cp typically developing td infant recording utterance collected two cp infant two typicallydeveloping td infant approximately month old data analyzed volubility consonant emergence canonical babbling ratio cbr mean babbling level mbl major finding show comparing td group cp group characteristic lower volubility cbrutter year old mbl score age feature level using consonant mainly two oral place bilabial velar three manner articulation nasal fricative stop year old
describe connectionist model learns parse single sentence sequential word input parse connectionist network contains information role assignment prepositional attachment relative clause structure subordinate clause structure trained network display several interesting type behavior include predictive ability tolerance certain corruption input word sequence generalization capability report experiment small number sentence type successfully learned network work progress larger database application type connectionist model area spoken language processing discussed
neural language model increasingly valued computational psycholinguistics due ability provide conditional probability distribution lexicon predictive human processing time given vast array available model theoretical methodological importance assess feature model influence psychometric quality work focus parameter size showing larger transformerbased language model generate probabilistic estimate less predictive early eyetracking measurement reflecting lexical access early semantic integration however relatively bigger model show advantage capturing late eyetracking measurement reflect full semantic syntactic integration word current language context result supported eye movement data ten language consider four model spanning b parameter
paper describes submission team ynuhpcc semeval task legal argument reasoning task civil procedure task asks candidate topic question answer classifying whether given candidate answer correct true incorrect false make sound judgment propose system system based finetuning legalbert model specializes solving legal problem meanwhileregularized dropout rdrop focal loss used model rdrop used data augmentation focal loss address data imbalance system achieved relatively good result competition official leaderboard code paper available httpsgithubcomynupengshisemevaltask
pretrained language model kobart often fail generating perfect interrogative sentence applied korean question generation mainly due fact language model much experienced declarative sentence interrogative sentence therefore paper proposes novel posttraining kobart enhance korean question generation enhancement kobart accomplished three way introduction question infilling objective kobart enforce focus structure interrogative sentence ii augmentation training data question generation another data set cope lack training instance posttraining iii introduction korean spacing objective make kobart understand linguistic feature korean since standard data set korean question generation paper also proposes korquadqg new data set task verify performance proposed posttraining code publicly available urlhttpsgithubcomgminiparkposttrainingqg
capturing word meaning context distinguishing correspondence variation across language key building successful multilingual crosslingual text representation model however existing multilingual evaluation datasets evaluate lexical semantics incontext various limitation particular language coverage restricted highresource language skewed favor language family area design make task solvable via superficial cue result artificially inflated sometimes superhuman performance pretrained encoders support crosslingual evaluation order address gap present amico adversarial multilingual meaning context widecoverage crosslingual multilingual evaluation set aim faithfully assess ability stateoftheart sota representation model understand identity word meaning crosslingual context language pair conduct series experiment wide range setup demonstrate challenging nature amico result reveal current sota pretrained encoders substantially lag behind human performance largest gap observed lowresource language language dissimilar english
recent study interpretability attention distribution led notion faithful plausible explanation model prediction attention distribution considered faithful explanation higher attention weight implies greater impact model prediction considered plausible explanation provide humanunderstandable justification model prediction work first explain current attention mechanism lstm based encoders neither provide faithful plausible explanation model prediction observe lstm based encoders hidden representation different timesteps similar high conicity attention weight situation carry much meaning even random permutation attention weight affect model prediction based experiment wide variety task datasets observe attention distribution often attribute model prediction unimportant word punctuation fail offer plausible explanation prediction make attention mechanism faithful plausible propose modified lstm cell diversitydriven training objective ensures hidden representation learned different time step diverse show resulting attention distribution offer transparency provide precise importance ranking hidden state ii better indicative word important model prediction iii correlate better gradientbased attribution method human evaluation indicate attention distribution learned model offer plausible explanation model prediction code made publicly available urlhttpsgithubcomakashkminterpretableattention
paper describes gmu system iwslt dialect lowresource speech translation task submitted system five lowresource task dialectal task work explored selfsupervised pretrained speech model finetuned speech translation downstream task use wavvec xlsr hubert selfsupervised model unlike hubert wavvec xlsr achieve best result remove top three layer result show wavvec hubert perform similarly relative best configuration addition found wavvec pretrained audio data language source language speech translation model achieves better result lowresource setting best result achieved using either wavvec hubert model xlsr achieves best result dialectal transfer task find xlsr perform well lowresource task using wavvec report close bleu point improvement test set tamasheqfrench compared baseline system iwslt
automated emotion recognition number application interactive voice response system call center etc employing existing feature set method automated emotion recognition already achieved reasonable result still lot improvement meanwhile optimal feature set used represent speech signal performing speechbased emotion recognition technique still open question research tried figure essential feature selfadaptive multiobjective genetic algorithm feature selection technique probabilistic neural network classifier proposed approach evaluated using number multilanguages database english german represented dimensional feature set according obtained result developed technique allows increase emotion recognition performance relative improvement accuracy moreover emotion recognition performance score applied database improved
medical imaging widely used clinical practice diagnosis treatment reportwriting errorprone unexperienced physician timeconsuming tedious experienced physician address issue study automatic generation medical imaging report task present several challenge first complete report contains multiple heterogeneous form information including finding tag second abnormal region medical image difficult identify third report typically long containing multiple sentence cope challenge build multitask learning framework jointly performs prediction tag generation paragraph propose coattention mechanism localize region containing abnormality generate narration develop hierarchical lstm model generate long paragraph demonstrate effectiveness proposed method two publicly available dataset
internet home thousand community unique worldview associated ideological difference new community constantly emerging serving ideological birthplace battleground bunker critical develop framework understanding worldviews ideological distinction existing work however take predetermined view based political polarization right v left dichotomy u politics reality political polarization worldviews broadly transcend onedimensional difference deserve complete analysis extending ability word embedding model capture semantic cultural characteristic training corpus propose novel method discovering multifaceted ideological worldview characteristic community using b comment collected largest community redditcom representing textasciitilde reddit activity demonstrate efficacy approach uncover complex ideological difference across multiple ax polarization
longstanding goal artificial intelligence ai create humanlike conversational system system ability develop emotional connection user consequently emotion recognition dialogue gained popularity emotion detection dialogue challenging task human usually convey multiple emotion varying degree intensity single utterance moreover emotion utterance dialogue may dependent previous utterance making task complex recently emotion recognition lowresource language like hindi great demand however existing datasets multilabel emotion intensity detection conversation english end propose large conversational dataset hindi named emoinhindi multilabel emotion intensity recognition conversation containing dialogue total utterance prepare dataset wizardofoz manner mental health legal counselling crime victim utterance dialogue annotated one emotion category emotion label including neutral corresponding intensity propose strong contextual baseline detect emotion corresponding emotional intensity utterance given conversational context
work introduce method enhancing distant supervision statechange information relation extraction provide training dataset created via process along manually annotated development test set present analysis curation process data compare standard distant supervision demonstrate addition statechange information reduces noise used static relation extraction also used train relationextraction system detects change state relation
paper proposes adapt selfattention discourse level modeling discourse element argumentative student essay specifically focus two issue first propose structural sentence positional encoding explicitly represent sentence position second propose use intersentence attention capture sentence interaction enhance sentence representation conduct experiment two datasets chinese dataset english dataset find sentence positional encoding lead large improvement identifying discourse element ii structural relative positional encoding sentence show effective iii intersentence attention vector useful kind sentence representation identifying discourse element
demonstrated hidden representation learned deep model encode private information input hence exploited recover information reasonable accuracy address issue propose novel approach called differentially private neural representation dpnr preserve privacy extracted representation text dpnr utilises differential privacy dp provide formal privacy guarantee show masking word via dropout enhance privacy maintain utility learned representation integrate dpnoisy representation robust training process derive robust target model also help model fairness various demographic variable experimental result benchmark datasets various parameter setting demonstrate dpnr largely reduces privacy leakage without significantly sacrificing main task performance
despite widespread success selfsupervised learning via masked language model mlm accurately capturing finegrained semantic relationship biomedical domain remains challenge paramount importance entitylevel task entity linking ability model entity relation especially synonymy pivotal address challenge propose sapbert pretraining scheme selfaligns representation space biomedical entity design scalable metric learning framework leverage umls massive collection biomedical ontology concept contrast previous pipelinebased hybrid system sapbert offer elegant onemodelforall solution problem medical entity linking mel achieving new stateoftheart sota six mel benchmarking datasets scientific domain achieve sota even without taskspecific supervision substantial improvement various domainspecific pretrained mlms biobert scibertand pubmedbert pretraining scheme prof effective robust
recent year brought interest challenging task summarizing conversation thread meeting online discussion etc summary help analysis long text quickly catch decision made thus improve work communication efficiency spur research thread summarization developed abstractive email thread summarization emailsum dataset contains humanannotated short textless word long textless word summary email thread containing email wide variety topic perform comprehensive empirical study explore different summarization technique including extractive abstractive method singledocument hierarchical model well transfer semisupervised learning conduct human evaluation short long summary generation task result reveal key challenge current abstractive summarization model task understanding sender intent identifying role sender receiver furthermore find widely used automatic evaluation metric rouge bertscore weakly correlated human judgment email thread summarization task hence emphasize importance human evaluation development better metric community
paper describes reproduction human evaluation languageagnostic meta learning lowresource texttospeech articulatory feature reported lux vu contribution repronlp shared task reproducibility evaluation nlp original evaluation assessed naturalness audio generated different texttospeech tt system german goal repeat experiment different set evaluator reproduced evaluation based data instruction provided original author uncertainty concerning randomisation question order evaluator recruited via email relevant mailing list received response course three week initial result show low reproducibility assume system original repeat evaluation experiment transposed reproducibility assessment improves markedly know point transposition happened however initial analysis audio video file provides evidence system assignment repeat experiment correct
paper describes tltschool corpus speech utterance collected school northern italy assessing performance student learning english german corpus recorded year student aged nine sixteen year attending primary middle high school utterance scored term predefined proficiency indicator human expert addition utterance recorded manually transcribed carefully guideline procedure used manual transcription utterance described detail well result achieved mean automatic speech recognition system developed u part corpus going freely distributed scientific community particularly interested nonnative speech recognition automatic assessment second language proficiency
interpretability tool offer explanation form dialogue demonstrated efficacy enhancing user understanding slack et al shen et al oneoff explanation may fall short providing sufficient information user current solution dialoguebased explanation however often require external tool module easily transferable task designed textttllmcheckup present easily accessible tool allows user chat stateoftheart large language model llm behavior enable llm generate explanation perform user intent recognition without finetuning connecting broad spectrum explainable ai xai method including whitebox explainability tool feature attribution selfexplanations eg rationale generation llmbased selfexplanations presented interactive dialogue support followup question generates suggestion textttllmcheckup provides tutorial operation available system catering individual varying level expertise xai supporting multiple input modality introduce new parsing strategy substantially enhances user intent recognition accuracy llm finally showcase textttllmcheckup task fact checking commonsense question answering code repository httpsgithubcomdfkinlpllmcheckup
contrastive learning utilizes positive pair inbatch negative optimize loss objective proven effective method learning sentence embeddings however argue previous method constructing positive pair dropout perturbation entailment relation limited since sentence knowable information ski mined sentence external knowledge semantic analysis grammatical description work first handcraft simple effective prompt template able obtain knowable information input sentence llm eg llama combine original sentence knowable information form positive pair contrastive learning evaluate method standard semantic textual similarity sts task experimental result show unsupervised supervised model using textberttextbase achieve average spearmans correlation respectively improvement compared simcse model outperforms previous stateoftheart model promptbert unsupervised supervised setting specifically yield new stateoftheart performance supervised setting
study examines role three influential theory language processing textitviz surprisal theory uniform information density uid hypothesis dependency locality theory dlt predicting disfluency speech production end incorporate feature based lexical surprisal word duration dlt integration storage cost logistic regression classifier aimed predict disfluency switchboard corpus english conversational speech find disfluency occur face upcoming difficulty speaker tend handle lessening cognitive load disfluency occur see reparandums behave differently disfluent filler possibly due lessening cognitive load also happening word choice reparandum ie disfluency uid hypothesis seem play significant role disfluency prediction lexical surprisal dlt cost give promising result explaining language production also find mean lessen cognitive load upcoming difficulty speaker take time word preceding disfluency making duration key element understanding disfluency
user commenting valuable feature many news outlet enabling contact reader enabling reader express opinion provide different viewpoint even complementary information yet large volume user comment hard filter let alone read extract relevant information research summarization user comment still infancy humancreated summarization datasets scarce especially lessresourced language address issue propose unsupervised approach user comment summarization us modern multilingual representation sentence together standard extractive summarization technique comparison different sentence representation approach coupled different summarization approach show successful combination news comment summarization empirical result presented visualisation show usefulness proposed methodology several language
deep neural network often overparameterized may easily achieve model generalization adversarial training shown effectiveness improving generalization regularizing change loss top adversarially chosen perturbation recently proposed sharpnessaware minimization sam algorithm conduct adversarial weight perturbation encouraging model converge flat minimum sam find common adversarial weight perturbation perbatch although perinstance adversarial weight perturbation stronger adversary potentially lead better generalization performance computational cost high thus impossible use perinstance perturbation efficiently sam paper tackle efficiency bottleneck propose sharpnessaware minimization dynamic reweighting deltasam theoretical analysis motivates possible approach stronger perinstance adversarial weight perturbation using reweighted perbatch weight perturbation deltasam dynamically reweights perturbation within batch according theoretically principled weighting factor serving good approximation perinstance perturbation experiment various natural language understanding task demonstrate effectiveness deltasam
work present overview winning system rvq competencebased multimodal question answering task final exact match score task structured questionanswer pair querying well system capable competencebased comprehension recipe propose hybrid rulebased system question answering transformer neural classifier na answer recognition rulebased system focus intent identification data extraction response generation
introduce property satisfied measure referential success set referring expression fuzzy property define family measure basis ncardinality measure illustrate toy example
metaphor pervasive aspect human communication presence multimodal form become prominent progress mass medium however limited research multimodal metaphor resource beyond english language furthermore existing work natural language processing address exploration categorizing source target domain metaphor omission significant considering extensive research conducted field cognitive linguistics emphasizes profound understanding metaphor relies recognizing difference similarity domain category therefore introduce multicmet multimodal chinese metaphor dataset consisting textimage pair advertisement manual annotation occurrence metaphor domain category sentiment metaphor convey also constructed domain lexicon encompasses categorization metaphorical source domain target domain propose cascading domain knowledge integration cdki benchmark detect metaphor introducing domainspecific lexical feature experimental result demonstrate effectiveness cdki dataset code publicly available
world health organization emphasised need stepping suicide prevention effort meet united nation sustainable development goal target goal good health wellbeing address challenging task personality subtyping suicide note research personality subtyping relied statistical analysis feature engineering moreover stateoftheart transformer model automated personality subtyping problem received relatively less attention develop novel emotionassisted personality detection framework empersona annotate benchmark ceasev suicide note dataset personality trait across four dichotomy introversion iextraversion e intuition nsensing thinking tfeeling f judging jperceiving p proposed method outperforms baseline comprehensive evaluation using multiple stateoftheart system across four dichotomy empersona improved accuracy respectively highestperforming singletask system
open information extraction open ie system traditionally evaluated via manual annotation recently automated evaluator benchmark dataset oie released score open ie system automatically matching system prediction prediction benchmark dataset unfortunately analysis reveals data rather noisy tuple matching evaluator issue making result automated comparison less trustworthy contribute carb improved dataset framework testing open ie system best knowledge carb first crowdsourced open ie dataset also make substantive change matching code metric nlp expert annotate carbs dataset accurate oie moreover find one pair open ie system carb framework provides contradictory result oie human assessment verifies carbs ranking two system accurate ranking release carb framework along crowdsourced dataset
mainly due open access movement number scholarly paper freely access drastically increasing huge amount paper promising resource text mining machine learning given set paper example grasp past current trend research community compared trend detection difficult forecast trend near future since number occurrence feature major cue automatic detection word frequency quite small trend emerge first step toward trend forecasting paper devoted finding subtle trend author propose index keywords called normalized impact index visualize keywords index heat map author conducted case study using keywords already known popular found keywords whose frequency large whose index large
scarcity gold standard codemixed pure language parallel data make difficult train translation model reliablyprior work addressed paucity parallel data data augmentation techniquessuch method rely heavily external resource making system difficult train scale effectively multiple languageswe present simple yet highly effective twostage backtranslation based training scheme adapting multilingual model task codemixed translation eliminates dependence external resourceswe show substantial improvement translation quality measured bleu beating existing prior work bleu codemixed hirightarrowen mrrightarrowen bnrightarrowen task lince machine translation leader board achieve highest score codemixed esrightarrowen beating existing best baseline bleu stronger baseline bleu
rising amount digitally available text need efficient processing algorithm growing fast although lot library commonly available modularity interchangeability limited therefore forcing lot reimplementations modification research area also real world application scenario recent year different nlp framework proposed provide efficient robust convenient architecture information processing task paper present overview common approach advantage shortcoming discus respect first standardized architecture unstructured information management architecture uima
people around world learning chinese second language need chinese error correction tool increasing hsk dynamic composition corpus word usage error wue common error type paper build neural network model considers target erroneous token context generate correction vector compare candidate vocabulary propose suitable correction deal potential alternative correction top five proposed candidate judged native chinese speaker case system propose least one acceptable correction within list five candidate best knowledge first research addressing generaltype chinese wue correction system help nonnative chinese learner revise sentence
augmenting pretrained language model plms knowledge graph kg demonstrated superior performance commonsense reasoning given commonsense based qa context question multiple choice existing approach usually estimate plausibility candidate choice separately based respective retrieved kg without considering interference among different choice paper propose attention guided commonsense reasoning network acenet endow neural network capability integrating hybrid knowledge specifically model applies multilayer interaction answer choice continually strengthen correct choice information guide message passing gnn addition also design mix attention mechanism node edge iteratively select supporting evidence hybrid knowledge graph experimental result demonstrate effectiveness proposed model considerable performance gain across commonsenseqa openbookqa datasets
paper conduct set experiment aimed improve understanding lack semantic isometry bert ie lack correspondence embedding meaning space contextualized word representation empirical result show contrary popular belief anisotropy root cause poor performance contextual model embeddings semantic task affect anisotropy semantic isometry set known bias frequency subword punctuation case one measure magnitude effect removal showing bias contribute completely explain phenomenon anisotropy lack semantic isometry contextual language model
existing dense retrieval model scientific document optimized either retrieval short query document similarity usually paper explore space combining multiple objective achieve single representation model present good balance mode dense retrieval combining relevance judgement m marco citation similarity specter selfsupervised objective independent cropping also consider addition training data document cocitation sentence context domainspecific synthetic data show combining multiple objective yield model generalize well across different benchmark task improving model trained single objective
large vision language model vlms like gpt llava instructblip exhibit extraordinary capability knowledge understanding reasoning however reasoning capability model sophisticated problem require external knowledge specific domain assessed well due unavailability necessary datasets work release firstofitskind dataset called indifoodvqa around k data sample consisting explicit knowledgeinfused question answer reason also release indifoodkg related knowledge graph kg k triple data created minimal human intervention via automated pipeline based instructblip gpt also present methodology extract knowledge kg use answer reason upon question employ different model report baseline zeroshot finetuned result finetuned vlms data showed improvement textasciitilde corresponding base model highlighting fact current vlms need domainspecific finetuning excel specialized setting finding reveal explicit knowledge infusion question generation help making question grounded knowledge proper knowledge retrieval often lead betteranswering potential case data code available httpsgithubcomslsravanthiindifoodvqa
matching seller listed item appropriate product important step ecommerce platform recent advancement deep learning different encoder based approach proposed solution textual data two product available crossencoder approach encode jointly biencoder approach encode separately since crossencoders computationally heavy approach based biencoders common practice challenge paper propose crossencoder data annotation technique annotate refine human annotated training data biencoder model using crossencoder model technique enables u build robust model without annotation newly collected training data improve model performance annotated training data evaluate crossencoder data annotation product matching task using realworld ecommerce dataset containing million product experimental result show crossencoder data annotation improves absolute accuracy annotation training data available absolute accuracy annotation training data available
last year author profiling general author gender identification particular become popular research area due potential attractive application range forensic investigation online marketing study however nearly stateoftheart work area still much depend datasets trained tested since heavily draw content feature mostly large number recurrent word combination word extracted training set show using small number feature mainly depend structure text outperform approach depend mainly content text use huge number feature process identifying author text man woman system tested dataset constructed work well two datasets previously used paper
kunsti norwegian national language technology programme running inclusive goal programme boost norwegian language technology research paper describe background objective methodology applied management programme project selected first conclusion also describe national programme form sweden france germany compare objective method
domain robustness key challenge neural machine translation nmt translating text different distribution training set requires nmt model generalize well unseen domain work propose novel way address domain robustness fusing external topic knowledge nmt architecture employ pretrained denoising autoencoder fuse topic information system continued pretraining finetuning model downstream nmt task result show incorporating external topic knowledge well additional pretraining improve outofdomain performance nmt model proposed methodology meet stateoftheart outofdomain performance analysis show low overlap pretraining finetuning corpus well quality topic representation help nmt system become robust domain shift
evergrowing size pretrained language model plm present significant challenge efficiently finetuning deploying model diverse set task within memoryconstrained environmentsin light recent research illuminated possibility selectively updating small subset model parameter finetuning processsince new parameter module added method retain inference speed original model come additional computational cost however open question pertains subset parameter best tuned maximize task performance generalizability investigate paper present comprehensive experiment covering large spectrum subset selection strategy comparatively evaluate impact model performance well resulting model capability generalize different taskssurprisingly find gain achieved performance elaborate selection strategy best marginal compared outcome obtained tuning random selection parameter subset experiment also indicate selectionbased tuning impairs generalizability new task
query expansion aim mitigate mismatch language used query document however query expansion method suffer introducing nonrelevant information expanding query bridge gap inspired recent advance applying contextualized model like bert document retrieval task paper proposes novel query expansion model leverage strength bert model select relevant document chunk expansion evaluation standard trec robust gov test collection proposed bertqe model significantly outperforms bertlarge model
tagged corruption model provide precise control introduction grammatical error clean text capability made powerful tool generating pretraining data grammatical error correction gec english work demonstrate application four language substantially fewer gec resource english german romanian russian spanish release new taggedcorruption dataset consisting example per language generated finetuned palm foundation model pretraining tagged corruption yield consistent gain across four language especially small model size language limited humanlabelled data
propose novel datadriven rulebased preordering approach us tree information multiple syntactic level approach extend treebased reordering one level multiple level capability process complicated reordering case conducted experiment englishtochinese chinesetoenglish translation direction result show approach led improved translation quality applied separately combined reordering approach reordering approach used alone showed improvement bleu score englishtochinese translation direction improvement bleu score chinesetoenglish translation direction comparison baseline used word reordering preordering approach combined short rule long rule tree rule based preordering approach showed improvement bleu score englishtochinese translation direction improvement bleu score chinesetoenglish translation direction translation used preordering approach also found many translation example improved syntactic structure
digital age geopolitical event frequently catalyze discussion among global web user platform social network messaging application serve vital mean information spreading acquisition russian aggression ukraine notably intensified online discourse matter drawing significant audience eager realtime update surge online activity inevitably result proliferation content may unreliable manipulative given context identification content information distortion imperative mitigate bias promote fairness however task present considerable challenge primarily due lack sophisticated language model capable understanding nuance context text lowresource language scarcity wellannotated datasets training model address gap introduce trwu dataset meticulously annotated collection telegram news russian war ukraine gathered starting january paper outline methodology semantic analysis classification message aiming ascertain bias approach enhances ability detect manipulative destructive content descriptive statistical analysis explore deviation message sentiment stance metadata across different type channel level content creation activity finding indicate predominance negative sentiment within dataset additionally research elucidates distinct difference linguistic choice phraseology among channel based stance towards war study contributes broader effort understanding spread mitigating impact biased manipulative content digital communication
paper explores application sqlcoders model pretrained neural network automatic sql query generation natural language question focus model internal functionality demonstrate effectiveness domainspecific validation dataset provided ehrsql sqlcoders model based transformer attention mechanism trained paired example natural language question corresponding sql query take advantage carefully crafted prompt incorporates database schema alongside question guide model towards desired output format
sample contrastive method typically referred simply contrastive foundation unsupervised method learn text sentence embeddings hand different class selfsupervised noncontrastive loss function method considered computer vision community referred dimension contrastive paper thoroughly compare class method standard baseline contrastive sentence embeddings simcse find selfsupervised embeddings trained using dimension contrastive objective outperform simcse downstream task without needing auxiliary loss function
previous research targetdependent sentiment classification tsc mostly focused review social medium domain author tend express sentiment explicitly paper investigate tsc news article much less researched tsc domain despite importance news essential information source individual societal decision making introduce newsmtsc highquality dataset tsc news article key difference compared established tsc datasets including example different mean express sentiment longer text second testset measure influence multitarget sentence also propose model us bigru interact multiple embeddings eg language model external knowledge source proposed model improves performance prior stateoftheart fm realworld sentiment distribution fm multitarget sentence
many text generation task focus recent progress story generation producing text perceived make sense whole automated metric address dimension story quality even shallow lexical level initiate investigation metric apply simple approach identifying word relation contribute narrative sense story use approach comparatively analyze output notable story generation system term relation characterize difference distribution relation according strength within story
automatic postediting ape seek automatically refine output blackbox machine translation mt system human postedits ape system usually trained complementing human postedited data large artificial data generated backtranslations timeconsuming process often easier training mt system scratch paper propose alternative finetune pretrained bert model encoder decoder ape system exploring several parameter sharing strategy training dataset k sentence hour single gpu obtain result competitive system trained artificial sentence add artificial data method obtains stateoftheart result
paper discus five different corpus annotated forprotein name present several within crossdataset proteintagging experiment showing different annotation scheme severelyaffect portability statistical protein tagger mean adetailed error analysis identify crucial annotation issue thatfuture annotation project take careful consideration
corpus linguistic language technological research need empirical corpus data nearly correct annotation high volume enable advance language modelling theorising recent work improving corpus annotation accuracy present semiautomatic method correct analysis error available annotated corpus leaving remaining error undetected annotated corpus review recent advance linguisticsbased partial tagging parsing regard achieved analysis performance sufficient reconsidering previously proposed method combining nearly correct partial automatic analysis minimal amount human postediting disambiguation achieve nearly correct corpus annotation accuracy competitive annotation speed report pilot experiment morphological partofspeech annotation using partial linguistic tagger kind previously reported attractive precisionrecall ratio observe desired level annotation accuracy reached using human disambiguation less textbackslash word corpus
fake news become hotly debated topic journalism paper present entry fake news challenge model detection fake news stance classification task finished th place leader board entry ensemble system classifier developed student context coursework show used stacking ensemble method purpose obtained improvement classification accuracy exceeding individual model performance development data finally discus aspect experimental setup challenge
natural language inference nli widely used task train evaluate model language understanding however ability nli model perform inference requiring understanding figurative language idiom metaphor remains understudied introduce impli idiomatic metaphoric paired language inference dataset english dataset consisting paired sentence spanning idiom metaphor develop novel method generate k semiautomatic pair well manually creating k gold pair use impli evaluate nli model based roberta finetuned widely used mnli dataset show reliably detect entailment relationship figurative phrase literal counterpart perform poorly similarly structured example pair designed nonentailing suggests limit current nli model regard understanding figurative language dataset serf benchmark future improvement direction
experiment use information retrieval augmentation pretrained language model text corpus used information retrieval viewed form episodic memory grows time augmenting gpt information retrieval achieve zero shot relative reduction perplexity gigaword corpus without retraining also validate ir augmentation event coreference task
paper introduce greek version automatic annotation tool errant bryant et al named elerrant errant function rulebased error type classifier used main evaluation tool system participating bea bryant et al shared task discus grammatical morphological difference english greek difference affected development elerrant also introduce first greek native corpus gnc greek wikiedits corpus gwe two new evaluation datasets error native greek learner wikipedia talk page edits respectively two datasets used evaluation elerrant paper sole fragment bigger picture illustrates attempt solve problem lowresource language nlp case greek
vector representation vector space modeling vsm play central role modern machine learning propose novel approach vector similarity searching dense semantic representation word document deployed top traditional invertedindexbased fulltext engine taking advantage robustness stability scalability ubiquity show approach allows indexing querying dense vector text domain open exciting avenue major efficiency gain along simpler deployment scaling monitoring end result fast scalable vector database tunable tradeoff vector search performance quality backed standard fulltext engine elasticsearch empirically demonstrate querying performance quality applying solution task semantic searching dense vector representation entire english wikipedia
many company use dialogue system customer service although rise usage system costello lodolce many system still face challenge comprehending properly responding customer folstadet al project aim figure develop improve conversational agent part project detailed paper focus detection breakdown pattern possible solution repair mitigate negative result error
representation learning text via pretraining language model large corpus become standard starting point building nlp system approach stand contrast autoencoders also trained raw text objective learning encode input vector allows full reconstruction autoencoders attractive latent space structure generative property therefore explore construction sentencelevel autoencoder pretrained frozen transformer language model adapt masked language modeling objective generative denoising one training sentence bottleneck singlelayer modified transformer decoder demonstrate sentence representation discovered model achieve better quality previous method extract representation pretrained transformer text similarity task style transfer example controlled generation singlesentence classification task glue benchmark using fewer parameter large pretrained model
machine translation inevitable technology reduce communication barrier today world made substantial progress recent year widely used commercial well nonprofit sector case european high resource language englishurdu language pair technology infancy stage due scarcity resource present research important milestone englishurdu machine translation present result four major domain including biomedical religious technological general using statistical neural machine translation performed series experiment attempt optimize performance system also study impact data source system finally established comparison data source effect language model size statistical machine translation performance
retrieval model indispensable component realworld knowledgeintensive task eg opendomain question answering odqa separate retrieval skill annotated different datasets recent work focus customized method limiting model transfer ability scalability work propose modular retriever individual module correspond key skill reused across datasets approach support flexible skill configuration based target domain boost performance mitigate task interference design novel modularization parameterization inspired sparse transformer demonstrate model benefit selfsupervised pretraining wikipedia finetuning using multiple odqa datasets multitask fashion approach outperforms recent selfsupervised retriever zeroshot evaluation achieves stateoftheart finetuned retrieval performance nq hotpotqa ottqa
modeling human language requires ability generate fluent text also encode factual knowledge however traditional language model capable remembering fact seen training time often difficulty recalling address introduce knowledge graph language model kglm neural language model mechanism selecting copying fact knowledge graph relevant context mechanism enable model render information never seen well generate outofvocabulary token also introduce linked wikitext dataset corpus annotated text aligned wikidata knowledge graph whose content roughly match popular wikitext benchmark experiment demonstrate kglm achieves significantly better performance strong baseline language model additionally compare different language model ability complete sentence requiring factual knowledge showing kglm outperforms even large language model generating fact
study preliminary exploration concept informativeness much information sentence give word contains potential benefit building quality word representation scarce data propose several sentencelevel classifier predict informativeness perform manual annotation set sentence conclude two measure correspond different notion informativeness however experiment show using classifier prediction train word embeddings impact embedding quality
machine translation mt model used industry constantly changing topic translation news agency need adapt new data maintain performance time aim teach pretrained mt model translate previously unseen word accurately based example propose experimental setup allowing u simulate novel vocabulary appearing humansubmitted translation ii corresponding evaluation metric compare approach extend data augmentation approach using pretrained language model create training example similar context novel word compare different finetuning data augmentation approach show adaptation scale one five example possible combining data augmentation randomly selected training sentence lead highest bleu score accuracy improvement impressively example model report better accuracy score reference system trained average parallel example
introductory talk workshop legal ethical issue human language technology lrec marseille june
paper describes neural machine translation system iiithyderabad ltrcmt wat hindienglish shared task experimented recurrent neural network transformer architecture also show result experiment training nmt model using additional data via backtranslation
previous partofspeech po induction model usually assume certain independence assumption eg markov unidirectional local dependency hold real language example subjectverb agreement longterm bidirectional facilitate flexible dependency modeling propose masked partofspeech model mposm inspired recent success masked language model mlm mposm model arbitrary tag dependency perform po induction objective masked po reconstruction achieve competitive result english penn wsj dataset well universal treebank containing diverse language though modeling longterm dependency ideally help task ablation study show mixed trend different language better understand phenomenon design novel synthetic experiment specifically diagnose model ability learn tag agreement surprisingly find even strong baseline fail solve problem consistently simplified setting agreement adjacent word nonetheless mposm achieves overall better performance lastly conduct detailed error analysis shed light remaining challenge
present approach hybrid machine translation based machinelearning framework method combine output several source system first define extensible total order translation use estimate ranking sentence level given set system introduce define notion joint binarised feature vector train svmbased classifier show classification result used create hybrid translation describe series oracle experiment data set wmt translation task order find upper bound regarding achievable level translation quality also present result first experiment implemented version system evaluation using nist bleu metric indicates proposed method outperform individual source system interesting finding approach allows leverage good translation otherwise bad system translation quality estimation based sentencelevel phenomenon rather corpuslevel metric conclude summarising finding giving outlook future work
individual express locus control control language identify whether control circumstance although control core concept underlying rhetorical style clear whether control expressed author write explore role syntax semantics expressing user sense control ie controlled control circumstance corpus annotated facebook post present rich insight linguistic aspect find language signaling control easy identify challenging label internally externally controlled lexical feature outperforming syntactic feature task finding could important implication studying selfexpression social medium
human translation based linguistic extralinguistic knowledge despite promising pioneering advance knowledgebased machine translation remained tempting vision bottleneck engineering sufficiently comprehensive body relevant knowledge semantic web offer opportunity gradual evolution global heterogeneous knowledge base immediate target modelling certain knowledge domain practical ontology talk demonstrate utilization ontological knowledge indifferent crosslingual application reaching crosslingual document retrieval via crosslingual question answering complex information service involving several crosslingual functionality including machine translation discus ramification development evolution world wide web future direction statistical rulebased machine translation
translation system tend trouble long sentence short one variety reason source target language differ rather markedly japanese english problem reflected lower quality output improve readability experimented automatically splitting long sentence shorter one paper outline problem describes sentence splitting procedure rule provides evaluation result
grammatical error detection ged nonnative writing requires system identify wide range error text written language learner error detection purely supervised task challenging ged datasets limited size label distribution highly imbalanced contextualized word representation offer possible solution efficiently capture compositional information language optimized large amount unsupervised data paper perform systematic comparison elmo bert flair embeddings peter et al devlin et al akbik et al range public ged datasets propose approach effectively integrate representation current method achieving new state art ged analyze strength weakness different contextual embeddings task hand present detailed analysis impact different type error
knowledge graph kg inference aim address natural incompleteness kg including rule learningbased kg embedding kge model however rule learningbased model suffer low efficiency generalization kge model lack interpretability address challenge propose novel effective closedloop neuralsymbolic learning framework enginekg via incorporating developed kge rule learning module kge module exploit symbolic rule path enhance semantic association entity relation improving kg embeddings interpretability novel rule pruning mechanism proposed rule learning module leveraging path initial candidate rule employing kg embeddings together concept extracting highquality rule experimental result four realworld datasets show model outperforms relevant baseline link prediction task demonstrating superiority kg inference model neuralsymbolic learning fashion source code datasets paper available urlhttpsgithubcomnglenginekg
existing metonymy resolution approach rely feature extracted external resource like dictionary handcrafted lexical resource paper propose endtoend wordlevel classification approach based bert without dependency tagger parser curated dictionary place name external resource show approach achieves stateoftheart datasets surpassing conventional bert model benchmark large margin also show approach generalises well unseen data
paper describes jb submission sigmorphon shared task morpheme segmentation paper describe probabilistic model trained expectationmaximization algorithm provide result analyze source error general limitation approach model implemented within modular probabilistic framework
within financial communication domain earnings conference call ecc play pivotal role tracing presentational strategy trustbuilding device used company representative b relevant hottopics stakeholder form evaluation company due formally regulated nature ecc favoured domain study argumentation context extraction argumentative discourse unit adus however idiosyncratic structure dialogical exchange qa session ecc particularly level question formulation challenge existing model argument mining assume adjacency related question answer turn dialogue maximal interrogative unit mius novel approach grouping together topically contiguous argumentative component within question turn miu identification allows application existing argument mining technique less noisy unit text following removal discourse regulator splitting subunit thematically related text evaluation automated method miu recognition also presented respect goldstandard manual annotation
introduce koreanlearnermorpheme klm corpus manually annotated dataset consisting morpheme second language l learner korean featuring morpheme tokenization partofspeech po tagging evaluate performance four korean morphological analyzer tokenization po tagging l korean corpus result highlight analyzer reduced performance l data indicating limitation advanced deeplearning model dealing lkorean corpus show finetuning one model klm corpus improves accuracy tokenization po tagging lkorean dataset
many natural language processing nlp task including generation language grounding reasoning information extraction coreference resolution dialog formulated deep reinforcement learning drl problem however since language often discrete space sentence infinite many challenge formulating reinforcement learning problem nlp task tutorial provide gentle introduction foundation deep reinforcement learning well practical drl solution nlp describe recent advance designing deep reinforcement learning nlp special focus generation dialogue information extraction finally discus succeed may fail aiming providing practical advice deep reinforcement learning solving realworld nlp problem
hardly kind text structure notoriously difficult read patent first due abstract vocabulary complex syntactic construction especially claim patent challenge accordance international patent writing regulation claim must rendered single sentence result sentence word uncommon therefore paraphrasing claim term user understand high demand present rulebased paraphrasing module realizes paraphrasing patent claim english rewriting task prior rewriting proper module implies stage simplification discourse syntactic analysis rewriting make use fullfledged text generator consists number genuine generation task aggregation selection referring expression choice discourse marker syntactic generation generator use matework bench based meaningtext theory linguistics
multitask learning ability share knowledge among related task implicitly increase training data however long frustrated interference among task paper investigates performance capsule network text proposes capsulebased multitask learning architecture unified simple effective advantage capsule feature clustering proposed task routing algorithm cluster feature task network help reduce interference among task experiment six text classification datasets demonstrate effectiveness model characteristic feature clustering
introduce language resource spanish dyslist composed list unique error extracted collection text written people dyslexia error annotated set characteristic well visual phonetic feature best knowledge largest resource kind especially given difficulty finding text written people dyslexia
deep neural network revolutionized many field including natural language processing paper outline teaching material introductory lecture deep learning natural language processing nlp main submitted material cover summer school lecture encoderdecoder model complementary set jupyter notebook slide earlier teaching part lecture based main goal teaching material provide overview neural network approach natural language processing linking modern concept back root showing traditional essential counterpart lecture departs countbased statistical method span gated recurrent network attention ubiquitous today nlp
existing system deliver high accuracy fscores detecting paraphrase semantic similarity traditional cleantext corpus instance cleantext microsoft paraphrase benchmark database existing system attain accuracy high however existing system detecting paraphrase semantic similarity usergenerated shorttext content microblogs twitter comprising noisy ad hoc shorttext need significant research attention paper propose machine learning based approach towards propose set feature although wellknown nlp literature solving problem explored detecting paraphrase semantic similarity noisy usergenerated shorttext data twitter apply support vector machine svm based learning use benchmark twitter paraphrase data released part semeval experiment system delivers paraphrase detection fscore semantic similarity detection fscore thereby significantly outperforming existing system deliver fscores two problem respectively feature also allow u obtain rank among top trained microsoft paraphrase corpus tested corresponding test data thereby empirically establishing approach ubiquitous across different paraphrase detection database
work aim equipping pretrained language model structured knowledge present two selfsupervised task learning raw text guidance knowledge graph building upon entitylevel masked language model first contribution entity masking scheme exploit relational knowledge underlying text fulfilled using linked knowledge graph select informative entity masking mention addition use knowledge graph obtain distractors masked entity propose novel distractorsuppressed ranking objective optimized jointly masked language model contrast existing paradigm approach us knowledge graph implicitly pretraining inject language model structured knowledge via learning raw text efficient retrievalbased method perform entity linking integration finetuning inference generalizes effectively method directly learn concatenated graph triple experiment show proposed model achieves improved performance five benchmark including question answering knowledge base completion
contextual feature always play important role chinese word segmentation cws wordhood information one contextual feature proved useful many conventional characterbased segmenters however feature receives less attention recent neural model also challenging design framework properly integrate wordhood information different wordhood measure existing neural framework paper therefore propose neural framework wmseg us memory network incorporate wordhood information several popular encoderdecoder combination cws experimental result five benchmark datasets indicate memory mechanism successfully model wordhood information neural segmenters help wmseg achieve stateoftheart performance datasets experiment analysis also demonstrate robustness proposed framework respect different wordhood measure efficiency wordhood information crossdomain experiment
text data augmentation complex problem due discrete nature sentence although rulebased augmentation method widely adopted realworld application simplicity suffer potential semantic damage previous researcher suggested easy data augmentation soft label softeda employing label smoothing mitigate problem however finding best factor model dataset challenging therefore using softeda realworld application still difficult paper propose adapting autoaugment solve problem experimental result suggest proposed method boost existing augmentation method rulebased method enhance cuttingedge pretrained language model offer source code
present result shared task workshop dialdoc focused documentgrounded dialogue conversational question answering primary goal shared task build goaloriented informationseeking conversation system identify relevant knowledge associated document generating agent response natural language includes two subtasks predicting agent response first subtask predict grounding text span given document next agent response second subtask generate agent response natural language given context many submission outperform baseline significantly first task bestperforming system achieved exact match f second subtask best system achieved sacrebleu highest rank human evaluation
existing datasets regular expression regex generation natural language limited complexity compared regex task user post stackoverflow regexes datasets simple language used describe diverse introduce structuredregex new regex synthesis dataset differing prior one three aspect first obtain structurally complex realistic regexes generate regexes using probabilistic grammar predefined macro observed realworld stackoverflow post second obtain linguistically diverse natural language description show crowdworkers abstract depiction underlying regex ask describe pattern see rather paraphrase synthetic language third augment regex example collection string matched ground truth regex similar real user give example quantitative qualitative analysis demonstrates advantage structuredregex prior datasets experimental result using various multimodal synthesis technique highlight challenge presented dataset including nonlocal constraint multimodal input
extracting meaningful entity belonging predefined category visuallyrich formlike document vfds challenging task visual layout feature font background color bounding box location size provide important cue identifying entity type however existing model commonly train visual encoder weak crossmodal supervision signal resulting limited capacity capture nontextual feature suboptimal performance paper propose novel visuallyasymmetric consistency learning vancl approach address limitation enhancing model ability capture finegrained visual layout feature incorporation color prior experimental result benchmark datasets show approach substantially outperforms strong layoutlm series baseline demonstrating effectiveness approach additionally investigate effect different color scheme approach providing insight optimizing model performance believe work inspire future research multimodal information extraction
keyphrase extraction essential many information retrieval ir natural language processing nlp task summarization indexing study investigates deep learning approach arabic keyphrase extraction address problem sequence classification create bilstm model classify sequence token either part keyphrase outside extracted word embeddings two pretrained model wordvec bert moreover investigated effect incorporating linguistic positional statistical feature word embeddings performance bestperforming model achieved fscore arabickpe dataset combining linguistic positional feature bert embedding
dating content relevant multiple advanced natural language processing nlp application information retrieval question answering could improved using technique consider temporal dimension process achieve accurate detection temporal expression data source must firstly done dealing appropriated standard format capture time value expression resolved allows reasoning without ambiguity order increase range search quality result returned task completely necessary nlp application efficient temporal reasoning afterwards expected work present typology time expression based empirical inductive approach structural perspective point view resolution furthermore method automatic recognition resolution temporal expression spanish content provided obtaining promising result tested mean evaluation corpus
conversational question answering scenario questioner seek extract information topic series interdependent question answer conversation progress may switch related topic phenomenon commonly observed informationseeking search session however current datasets conversational question answering limiting two way contain topic switch assume reference text conversation given setting opendomain introduce topiocqa pronounced tapioca opendomain conversational dataset topic switch based wikipedia topiocqa contains conversation informationseeking question freeform answer average conversation dataset span questionanswer turn involves four topic document topiocqa pose challenging testbed model efficient retrieval required multiple turn conversation conjunction constructing valid response using conversational history evaluate several baseline combining stateoftheart document retrieval method neural reader model best model achieves f falling short human performance point indicating difficulty dataset dataset code available urlhttpsmcgillnlpgithubiotopiocqa
last minute corpus comprises record transcript naturalistic problem solving dialog n subject companion system simulated wizard oz experiment goal detect dialog situation subject might break dialog system might happen subject unsuccessful present dialog act based representation dialog course problem solving phase experiment propose evaluate measure dialog success failure derived representation dialog act representation refines previous coarse measure enables correct classification many dialog sequence ambiguous dialog act representation useful identification different subject group exploration interesting dialog course corpus find young female successful challenging last part problem solving phase young subject initiative dialog often elderly
modeling parser state key good performance transitionbased parsing recurrent neural network considerably improved performance transitionbased system modelling global state eg stacklstm parser local state modeling contextualized feature eg bilstm parser given success transformer architecture recent parsing system work explores modification sequencetosequence transformer architecture model either global local parser state transitionbased parsing show modification cross attention mechanism transformer considerably strengthen performance dependency abstract meaning representation amr parsing task particularly smaller model limited training data
classical bias detection method used machine learning biased different confounding variable implied assessment initial bias first using template syntactically simple distant target data model deployed second current method assessing bias pretrained language model dataset directly finetuned classifier actually produce harm propose simple method detect bias specific finetuned classifier type unlabeled data idea study classifier behavior creating counterfactual example directly target data distribution quantify amount change work focus named entity perturbation applying named entity recognition targetdomain data modifying accordingly common name location target group gender country several morphosynctactically different language spoken relation country target group used method two model available opensource likely deployed industry two task domain first assess bias multilingual sentiment analysis model trained multiplelanguages tweet available opensource multilingual stance recognition model trained several language assessed english language finally propose link perplexity example bias model looking change label distribution respect language target group work offer finegrained analysis interaction name language revealing significant bias multilingual model
study problem crosslingual event argument extraction ceae task aim predict argument role entity mention event text whose language different language predictive model trained previous work ceae shown crosslingual benefit universal dependency tree capturing shared syntactic structure sentence across language particular work exploit existence syntactic connection word dependency tree anchor knowledge transfer representation learning across language ceae model ie via graph convolutional neural network gcns paper introduce two novel source languageindependent information ceae model based semantic similarity universal dependency relation word pair different language propose use two source information produce shared sentence structure bridge gap language improve crosslingual performance ceae model extensive experiment conducted arabic chinese english demonstrate effectiveness proposed method ceae
subword unit effective way alleviate open vocabulary problem neural machine translation nmt sentence usually converted unique subword sequence subword segmentation potentially ambiguous multiple segmentation possible even vocabulary question addressed paper whether possible harness segmentation ambiguity noise improve robustness nmt present simple regularization method subword regularization train model multiple subword segmentation probabilistically sampled training addition better subword sampling propose new subword segmentation algorithm based unigram language model experiment multiple corpus report consistent improvement especially low resource outofdomain setting
linguistic model reveal emotion associated word study consider task estimating wordlevel emotion intensity score specific emotion exploring unsupervised supervised finally selfsupervised method extracting emotional association pretrained vector model overall find linguistic model carry substantial potential inducing finegrained emotion intensity score showing far higher correlation human ground truth rating stateoftheart emotion lexicon based labeled data
practical realworld scenario longstanding goal universal multilingual translation model incrementally updated new language pair arrive specifically initial vocabulary cover word new language hurt translation quality incremental learning although existing approach attempt address issue replacing original vocabulary rebuilt vocabulary constructing independent languagespecific vocabulary method meet following three demand simultaneously high translation quality original incremental language low cost model training low time overhead preprocessing work propose entropybased vocabulary substitution ev method need walk new language pair incremental learning largescale multilingual data updating remaining size vocabulary method access learn new knowledge updated training sample incrementally keeping high translation quality original language pair alleviating issue catastrophic forgetting result experiment show ev achieve better performance save excess overhead incremental learning multilingual machine translation task
employ imitation learning train neural transitionbased string transducer morphological task inflection generation lemmatization previous approach training type model either rely external character aligner production gold action sequence result suboptimal model due unwarranted dependence single gold action sequence despite spurious ambiguity require warm starting mle model approach requires simple expert policy eliminating need character aligner warm start also address familiar mle training bias lead strong stateoftheart performance several benchmark
study created imperative corpus speech conversation dialogue big bang theory written comment wikipedias article deletion discussion tv show data episode containing statement used manually annotated imperative based annotation guideline adapted condoravdi lauers study used retrieved data assess performance syntaxbased classification rule wikipedia afd comment data first developed leveraged syntaxbased classifier extract statement may imperative manually examined statement identified true positive corpus also examined performance rulebased imperative detection tool result show different outcome speech dialogue written data rulebased classification performs better written data precision compared speech data also rulebased classification lowperformance overall speech data precision recall f measure finding implies syntaxbased model may need adjusted speech dataset imperative oral communication greater syntactic variety highly contextdependent
study problem entity detection normalization applied patient selfreports symptom arise sideeffects vaccine application domain present unique challenge render traditional classification method ineffective number entity type large many symptom rare resulting longtail distribution training example per entity type tackle challenge autoregressive model generates standardized name symptom introduce data augmentation technique increase number training example rare symptom experiment reallife patient vaccine symptom selfreports show approach outperforms strong baseline additional example improve performance longtail entity
convolutional neural network cnns recently achieved remarkably strong performance practically important task sentence classification kim kalchbrenner et al johnson zhang zhang et al however model require practitioner specify exact model architecture set accompanying hyperparameters including filter region size regularization parameter currently unknown sensitive model performance change configuration task sentence classification thus conduct sensitivity analysis onelayer cnns explore effect architecture component model performance aim distinguish important comparatively inconsequential design decision sentence classification focus onelayer cnns exclusion complex model due comparative simplicity strong empirical performance make modern standard baseline method akin support vector machine svms logistic regression derive practical advice extensive empirical result interested getting cnns sentence classification real world setting
crosslingual word embeddings provide way information transferred language paper evaluate extension joint training approach learning crosslingual embeddings incorporates subword information training method could particularly wellsuited lowerresource morphologicallyrich language trained modest size monolingual corpus able represent outofvocabulary word oovs consider bilingual lexicon induction including evaluation focused oovs find method achieves improvement previous approach particularly oovs
many task aim measure machine reading comprehension mrc often focusing question type presumed difficult rarely however task designer start considering system fact comprehend paper make two key contribution first argue existing approach adequately define comprehension unsystematic content tested second present detailed definition comprehensiona template understandingfor widely useful class text namely short narrative conduct experiment strongly suggests existing system task narrative understanding define
explore linguistic indicator schizophrenia reddit discussion forum schizophrenia sz chronic mental disorder affect person thought behavior identifying detecting sign sz difficult given sz relatively uncommon affecting approximately u population people suffering sz often believe disorder linguistic abnormality hallmark sz many illness symptom manifested language paper leverage vast amount data available social medium use statistical machine learning approach study linguistic characteristic sz collected analyzed large corpus reddit post user claiming received formal diagnosis sz identified several linguistic feature differentiated user control ctl group compared result finding social medium linguistic analysis sz also developed machine learning classifier automatically identify selfidentified user sz reddit
describe compilation large corpus frenchdutch sentence pair official belgian document available online version publication belgisch staatsbladmoniteur belge published downloading file batch filtered document translation language document contain several language checking discriminating word pair document substantial difference length segmented document sentence aligned latter resulted million sentence pair onetoone link included parallel corpus million unique pair samplebased evaluation sentence alignment result indicates near accuracy explained text genre procedure filtering weakly parallel article restriction onetoone link corpus larger number wellknown frenchdutch resource made available community investigation needed order determine original language document written
related work section literature review essential part every scientific article crucial paper reviewing assessment automatic generation related work section considered instance multidocument summarization problem order allow study specific problem developed manually annotated machine readable dataset related work section cited paper eg reference sentence together additional layer paper citing reference additionally present experiment identification cited sentence using input citation context corpus alongside gold standard made available use scientific community
abstractive sentence summarization assum target grasping core idea source sentence presenting summary extensively studied using statistical model neural model based largescale monolingual sourcesummary parallel corpus crosslingual parallel corpus whose source sentence language different summary language directly train crosslingual assum system propose solve zeroshot problem using resourcerich monolingual assum system teach zeroshot crosslingual assum system summary word generation attention teaching process along backtranslation process simulates sourcesummary pair experiment crosslingual assum task show proposed method significantly better pipeline baseline previous work greatly enhances crosslingual performance closer monolingual performance
yarn yet another russnet project started aim creating large open wordnetlike thesaurus russian mean crowdsourcing first stage project create noun synset currently resource comprises k word entry k synset people taken part assembling synset throughout project paper describes linguistic technical organizational principle project well evaluation result lesson learned future plan
paper describes participation team qust semeval task monolingual model first evaluated undersampling majority class early stage task pretrained multilingual model finetuned combination class weight sample weight two different finetuning strategy taskagnostic taskdependent investigated experiment conducted fold crossvalidation multilingual approach superior monolingual one submitted system achieves second best italian spanish zeroshot subtask
paper introduces novel method measuring noncooperation dialogue key idea linguistic noncooperation measured term extent dialogue participant deviate convention regarding proper introduction discharging conversational obligation eg obligation respond question previous work non cooperation focused mainly nonlinguistic taskrelated noncooperation modelled noncooperation term special rule describing noncooperative behaviour contrast start rule normalcorrect dialogue behaviour ie dialogue game principle derived corpus cooperative dialogue provide quantitative measure degree participant comply rule evaluated model corpus political interview encouraging result model predicts accurately degree cooperation one two dialogue game role interviewer also relative cooperation role ie interlocutor conversation cooperative able measure cooperation application many area analysis manual semi fully automatic natural language interaction humanlike virtual personal assistant tutoring agent sophisticated dialogue system roleplaying virtual human
present targer open source neural argument mining framework tagging argument free input text keywordbased retrieval argument argumenttagged webscale corpus currently available model pretrained three recent argument mining datasets enable use neural argument mining without reproducibility effort user side open source code ensures portability domain use case
data augmentation technique apply transformation existing text generate additional data transformation may produce lowquality text meaning text changed text may even mangled beyond human comprehension analyzing synthetically generated text corresponding label slow demanding winnow text incorrect label develop inspector humanintheloop data inspection technique inspector combine strength provenance tracking technique assistive labeling inspector allows user group related text textittransformation provenance ie transformation applied original text textitfeature provenance linguistic feature original text assistive labeling inspector computes metric approximate data quality allows user compare corresponding label text prediction large language model user study inspector increase number text correct label identified time sentiment analysis task time hate speech detection task participant found grouping synthetically generated text common transformation useful technique surprisingly grouping text common linguistic feature perceived unhelpful contrary prior work study find single technique obviates need human inspection effort validates design inspector combine analysis data provenance assistive labeling reduce human inspection effort
natural language understanding nlu task typically defined creating annotated dataset utterance encountered data resemble realworld natural language interaction certain utterance encountered frequently others rarely deployed nlu system vital problem since underlying machine learning ml model often finetuned typical nlu data applied realworld data different distribution system need maintain interpretation consistency highfrequency utterance lowfrequency utterance propose alternative strategy explicitly us utterance frequency training data learn model robust unknown distribution present methodology simulate utterance usage two public nlu corpus create new corpus head body tail segment evaluate several method joint intent classification named entity recognition icner use two domain generalization approach adapt ner proposed approach demonstrate upto relative improvement semantic accuracy baseline tail data provide insight proposed approach work show reason observed improvement align reported previous work
automatic generation multiple choice question mcq potential reduce time educator spend student assessment significantly however existing evaluation metric mcq generation bleu rouge meteor focus ngram based similarity generated mcq gold sample dataset disregard educational valuethey fail evaluate mcqs ability assess student knowledge corresponding target fact tackle issue propose novel automatic evaluation metric coined knowledge dependent answerability kda measure mcqs answerability given knowledge target fact specifically first show measure kda based student response human surveythen propose two automatic evaluation metric kdadisc kdacont approximate kda leveraging pretrained language model imitate student problemsolving behaviorthrough human study show kdadisc kdasoft strong correlation kda usability actual classroom setting labeled expert furthermore combined ngram based similarity metric kdadisc kdacont shown strong predictive power various expertlabeled mcq quality measure
ir model using pretrained language model significantly outperform lexical approach like bm particular splade encodes text sparse vector effective model practical use show robustness outofdomain datasets however splade still struggle exact matching lowfrequency word training data addition domain shift vocabulary word frequency deteriorate ir performance splade supervision data scarce target domain addressing domain shift without supervision data necessary paper proposes unsupervised domain adaptation method filling vocabulary wordfrequency gap first expand vocabulary execute continual pretraining masked language model corpus target domain multiply spladeencoded sparse vector inverse document frequency weight consider importance document lowfrequency word conducted experiment using method datasets large vocabulary gap source domain show method outperforms present stateoftheart domain adaptation method addition method achieves stateoftheart result combined bm
data numerical analysis quantitative question answering qqa becomes crucial instrument provides deep insight analyzing large datasets help make wellinformed decision industry finance healthcare business paper explores hijliju team involvement numeval task within semeval particular emphasis quantitative comprehension specifically method address numerical complexity finetuning bert model sophisticated multiplechoice question answering leveraging hugging face ecosystem effectiveness qqa model assessed using variety metric emphasis fscore scikitlearn library thorough analysis macrof microf weightedf average binaryf score yield detailed insight model performance range question format
bert model used specialized domain seem result simple strategy initializing original bert resuming pretraining specialized corpus method yield rather good performance eg biobert lee et al scibert beltagy et al bluebert peng et al however seems reasonable think training directly specialized corpus using specialized vocabulary could result tailored embeddings thus help performance test hypothesis train bert model scratch using many configuration involving general medical corpus based evaluation using four different task find initial corpus weak influence performance bert model pretrained medical corpus
word sense disambiguation wsd fundamental natural language processing task unsupervised knowledgebased wsd relies lexical knowledge base sense inventory wider practical use supervised wsd requires mass senseannotated data hownet widely used lexical knowledge base chinese wsd uniqueness however existing unsupervised wsd method work hownetbased wsd tailormade method obtained satisfying result paper propose new unsupervised method hownetbased chinese wsd exploit masked language model task pretrained language model experiment considering existing evaluation dataset small outofdate build new larger hownetbased wsd dataset experimental result demonstrate model achieves significantly better performance baseline method code data paper available urlhttpsgithubcomthunlpsememewsd
article present first experience reusing swedish framenet swefn resource training semantic role give account procedure used adapt swefn need student linguistics form automatically generated exercise adaptation mapping finegrained distinction role swefn learnerfriendlier coarsegrained role presented major challenge besides discussing detail mapping describe resulting multiplechoice exercise graphical user interface exercise made available larka online platform student linguistics learner swedish second language outline also aspect underlying selection incorrect answer option include semantic well frequencybased criterion finally present observation initial user feedback applicability resource pedagogical domain student answer indicated overall positive experience majority found exercise useful learning semantic role
existing work multilingual pretraining demonstrated potential crosslingual transferability training unified transformer encoder multiple language however much work relies shared vocabulary bilingual context encourage correlation across language loose implicit aligning contextual representation language paper plug crossattention module transformer encoder explicitly build interdependence language effectively avoid degeneration predicting masked word conditioned context language importantly finetuning downstream task crossattention module plugged ondemand thus naturally benefiting wider range crosslingual task language understanding generation result proposed crosslingual model delivers new stateoftheart result various crosslingual understanding task xtreme benchmark covering text classification sequence labeling question answering sentence retrieval crosslingual generation task also outperforms existing crosslingual model stateoftheart transformer variant wmt englishtogerman englishtofrench translation datasets gain bleu
propose korean multimodal dialogue system targeting emotionbased empathetic dialogue research field conducted language english japanese certain circumstance dialogue system consists emotion detector empathetic response generator monitoring interface voice activity detector speech recognizer speech synthesizer gesture classification several controller provide multimodality empathy conversation human machine comparison across visual influence user dialogue system contains two version user interface cat facebased user interface avatarbased user interface evaluated dialogue system investigating dialogue text average mean opinion score three different visual condition visual cat facebased avatarbased expression experimental result stand importance adequate visual expression according user utterance
contextual influence language often exhibit substantial crosslingual regularity example verbose situation require finer distinction however regularity sometimes obscured semantic syntactic difference using newlycollected dataset color reference game mandarin chinese release public confirm variety construction display sensitivity contextual difficulty chinese english show neural speaker agent trained bilingual data simple multitask learning approach display humanlike pattern context dependence pragmatically informative monolingual chinese counterpart moreover expense languagespecific semantic understanding resulting speaker model learns different basic color term system english chinese noteworthy crosslingual influence identify synonym two language using vector analogy operation output layer despite exposure parallel data
human make appropriate response based previous dialogue utterance also implicit background knowledge common sense although neural response generation model seem produce humanlike response mostly endtoend generating intermediate ground dialogue history response work aim study train rg model talk generate implicit knowledge making response investigate model identify generate implicit background knowledge necessary experimental result show compared model directly generate response given dialogue history selftalk model produce betterquality response according human evaluation grammaticality coherence engagingness model trained identify selftalk improves response quality analysis generated implicit knowledge show model mostly use knowledge appropriately response
paper present novel system subsentential alignment bilingual sentence pair however using readilyavailable machinereadable bilingual dictionary performance evaluated existing goldstandard parallel corpus word alignment annotated showing result considerable improvement comparable system giza performance corpus since naive application system n language would require nn dictionary also evaluated using pivot language n dictionary would required surprisingly similar performance system proposed alternative statistical method use small corpus onthefly alignment
introduce seagle platform comparative evaluation semantic text encoding model information retrieval ir task seagle implement word embedding aggregator represent text algebraic aggregation pretrained word embeddings pretrained semantic encoders allows comparative evaluation arbitrary monolingual crosslingual ir collection benchmark seagles model monolingual document retrieval crosslingual sentence retrieval seagle functionality exploited via easytouse web interface modular backend microservice architecture easily extended additional semantic search model
understanding origin militarized conflict complex yet important undertaking existing research seek build understanding considering bilateral relationship entity pair dyadic cause multilateral relationship among multiple entity systemic cause aim work compare two cause term correlate conflict two entity devising set textual graphbased feature represent cause feature extracted wikipedia modeled large graph node graph represent entity connected labeled edge representing ally enemyrelationships allows casting problem edge classification task term dyad classification propose evaluate classifier determine particular pair entity ally enemy result suggest systemic feature might slightly better correlate conflict find wikipedia article ally semantically similar enemy
paper present proposed method annotation scientific argument biologicalbiomedical journal article semantic entity relation used represent propositional content argument instance argument scheme describe experiment encoded argument journal article identify issue approach catalogue argument scheme copy annotated article publically available
today digital world information fact verification system disprove assertion made speech print medium online content need hour propose system would verify claim source classify claim true false outofcontext inappropriate claim respect textual source provided system true label used claim true false false claim relation source classified outofcontext claim verified classified inappropriate would help u verify claim fact well know source knowledge base trying verify fact used twostep approach achieve goal first retrieved evidence related claim textual source using term frequencyinverse document frequencytfidf vector later classified claimevidence pair true false inappropriate context using modified version textual entailment module textual entailment module calculates probability sentence supporting claim contradicting claim providing relevant information using bilstm network assess veracity claim accuracy best performing system
response global challenge mental health problem proposes logical neural network lnn based neurosymbolic ai method diagnosis mental disorder due lack effective therapy coverage mental disorder need ai solution assist therapist diagnosis however current neural network model lack explainability may trusted therapist lnn recurrent neural network architecture combine learning capability neural network reasoning capability classical logicbased ai proposed system us input predicate clinical interview output mental disorder class different predicate pruning technique used achieve scalability higher score addition provide insight extraction method aid therapist diagnosis proposed system address lack explainability current neural network model provides trustworthy solution mental disorder diagnosis
wide spectrum multilingual application aligned parallel corpus prerequisite aim project described paper build multilingual corpus sentence aligned high precision minimal human effort involved experiment combination sentence aligners different underlying algorithm described paper showed verifying link recognized least two aligners error rate reduced compared performance best aligner manual involvement concerned small portion data significantly reduces load manual work necessary achieve nearly accuracy alignment
machine translation highly impacted social bias present data set indicating reflects amplifies stereotype work study mitigating gender bias jointly learning translation partofspeech gender target language different morphological complexity approach shown improvement point gender accuracy without significantly impacting translation quality
software bug reported developer engage discussion collaboratively resolve solution likely formulated within discussion often buried large amount text making difficult comprehend delaying implementation expedite bug resolution propose generating concise natural language description solution synthesizing relevant content within discussion encompasses natural language source code build corpus task using novel technique obtaining noisy supervision repository change linked bug report establish benchmark also design two system generating description ongoing discussion classifying sufficient context performing task emerges realtime automated human evaluation find task form ideal testbed complex reasoning long bimodal dialogue context
current crossprompt automatic essay scoring aes system primarily concerned obtaining shared knowledge specific target prompt using source target prompt essay however may feasible practical situation target prompt essay may available training data constructing model solely source prompt essay capacity generalize target prompt may hindered significant discrepancy among different prompt essay study novel learning framework crossprompt aes proposed order capture general knowledge across prompt improve model capacity distinguish writing level acquire generic knowledge across different prompt primary model trained via meta learning source prompt essay improve model ability differentiate writing level present levelaware learning strategy consisting general scorer three level scorer low middle highlevel essay introduce contrastive learning strategy bring essay representation general scorer closer corresponding level representation far away two level thereby improving system ability differentiate writing level well boosting scoring performance experimental result public datasets illustrate efficacy method
spoken written language processing stand benefit parsing standard parseval metric black et al canonical implementation sekine collins useful text parseval metric undefined word input parser match word gold standard parse tree exactly word error unavoidable automatic speech recognition asr system fill gap developed publicly available tool scoring parses implement variety metric handle mismatch word segmentation including alignmentbased bracket evaluation alignmentbased dependency evaluation dependency evaluation require alignment describe different metric use tool outcome extensive set experiment sensitivity
dedicated resource consisting annotated speech tool workflow design developed detailed investigation discourse phenomenon taiwan mandarin discourse phenomenon function associated position utterance temporal property include discourse marker nage na eg hesitation utterance initiation discourse particle eg utterance finality utterance continuity focus etc filler uhn hesitation distribution particle relation position utterance temporal property particle investigated result investigation diverge considerably claim existing grammar mandarin respect utterance position show general greater length regular syllable property suggest possibility developing automatic discourse item tagger
study influence different activation function output layer pretrained transformer model soft hard label prediction learning disagreement task task goal quantify amount disagreement via predicting soft label predict soft label use bertbased preprocessors encoders vary activation function used output layer keeping parameter constant soft label used hard label prediction activation function considered sigmoid well stepfunction added model posttraining sinusoidal activation function introduced first time paper
conversational search setting user ask question receive answer part conversation ambiguity question common challenge effectively addressed leveraging contextual information conversation history context determining topic continuity reformulating question welldefined query crucial task previous approach typically addressed task either classification task case topic continuity text generation task question reformulation however prior work combined task effectively identify ambiguous question part conversation paper propose multitask learning mtl approach us text generation model question rewriting classification model based bart trained rewrite conversational question identify followup question simultaneously evaluate approach multiple test set demonstrate outperforms singletask learning baseline three lif test set statistically significant improvement ranging term f microf score also show approach outperforms singletask question rewriting model passage retrieval large orquac test set
quantitative reasoning higherorder reasoning skill intelligent natural language understanding system reasonably expected handle present equate evaluating quantitative understanding aptitude textual entailment new framework quantitative reasoning textual entailment benchmark performance published nli model equate find average stateoftheart method achieve absolute improvement majorityclass baseline suggesting implicitly learn reason quantity establish new baseline qreas manipulates quantity symbolically comparison best performing nli model achieves success numerical reasoning test limited verbal reasoning capability hope evaluation framework support development model quantitative reasoning language understanding
sentiment analysis area substantial relevance industry academia including instance social study although supervised learning algorithm advanced considerably recent year many setting remains practical apply unsupervised technique latter oftentimes based sentiment lexicon however existing sentiment lexicon reflect abstract notion polarity justice substantial difference word polarity different domain work draw collection domainspecific data induce set domainspecific sentiment lexicon rely initial linear model induce initial word intensity score train new deep model based word vector representation overcome scarcity original seed data analysis show substantial difference domain make domainspecific sentiment lexicon promising form lexical resource downstream task predicted lexicon indeed perform effectively task review classification crosslingual word sentiment prediction
several recent stateoftheart transfer learning method model classification task text generation label represented string model generate investigate effect choice string used represent label effectively model learns task four standard text classification task design diverse set possible string representation label ranging canonical label definition random string experiment task varying label representation well amount training data find low data setting label representation impact task performance task taskrelated label effective fails impact others full data setting result largely negative different label representation affect overall task performance
paper present tagshare project linguistic resource tool shallow processing portuguese developed scope resource include million token corpus accurately hand annotated variety linguistic information well several state art shallow processing tool capable automatically producing type annotation present linguistic annotation corpus sentence paragraph boundary token boundary morphosyntactic po category value inflection feature lemma namedentities hence set tool comprise sentence chunker tokenizer po tagger nominal verbal analyzer lemmatizers verbal conjugator nominal inflector namedentity recognizer underline several online service
propose structured extension bidirectionalcontext conditional language generation infilling inspired frame semantic theory guidance provided one two approach model finetuning conditioning directly observed symbolic frame novel extension disjunctive lexically constrained decoding leverage frame semantic lexical unit automatic human evaluation confirm frameguided generation allows explicit manipulation intended infill semantics minimal loss distinguishability humangenerated text method flexibly apply variety use scenario provide interactive web demo
native language influence way perceive speech sound affecting ability discriminate nonnative sound compare two idea influence native language speech perception perceptual assimilation model appeal mental classification sound native phoneme category versus idea rich finegrained phonetic representation tuned statistic native language sufficient operationalise idea using representation two stateoftheart speech model dirichlet process gaussian mixture model recent wavvec model present new open dataset french englishspeaking participant speech perception behaviour vowel sound six language show phoneme assimilation better predictor finegrained phonetic modelling discrimination behaviour whole predicting difference discriminability associated difference native language background also show wavvec good capturing effect native language speech perception complementary information native phoneme assimilation provides good model lowlevel phonetic representation supporting idea categorical finegrained perception used speech perception
unsupervised text style transfer challenging task aim alter stylistic attribute given text without affecting original content one method achieve controllable style transfer allows control degree style transfer however issue encountered controllable style transfer instability transferred text fluency degree style transfer change address problem propose novel approach incorporates additional syntax parsing information style transfer leveraging syntactic information model guided generate natural sentence effectively reflect desired style maintaining fluency experimental result show method achieves robust performance improved fluency compared previous controllable style transfer method
recently finetuning pretrained language model prlm labeled sentiment datasets demonstrates impressive performance however collecting labeled sentiment dataset timeconsuming finetuning whole prlm brings much computation cost end focus multisource unsupervised sentiment adaptation problem pretrained feature practical challenging first design dynamic feature network fully exploit extracted pretrained feature efficient domain adaptation meanwhile difference traditional sourcetarget domain alignment method propose novel asymmetric mutual learning strategy robustly estimate pseudolabels target domain knowledge source model experiment multiple sentiment benchmark show method outperforms recent stateoftheart approach also conduct extensive ablation study verify effectiveness proposed module
interesting aspect structured prediction evaluation output structure gold standard especially lossaugmented setting need finding maxviolating constraint severely limited expressivity effective loss function paper trade exact computation enabling use study complex loss function coreference resolution interestingly show function automatically learned also controversial commonly accepted coreference measure eg mela ii successfully used learning algorithm accurate model comparison standard conll setting show benefit expressive loss function
recent approach automatic postediting ape machine translation mt shown best result obtained neural multisource model correct raw mt output also considering information corresponding source sentence aim present first time neural multisource ape model based transformer architecture moreover employ sequencelevel loss function order avoid exposure bias training consistent automatic evaluation metric used task main feature submission wmt ape shared task participated pbsmt subtask ie correction mt output phrasebased system nmt subtask ie correction neural output first subtask system improves baseline ter bleu point ranking second submitted run second one characterized higher quality initial translation report lower statistically significant gain ter bleu ranking first submission
logon machine translation system semantic transfer using minimal recursion semantics developed conjunction two existing broadcoverage grammar norwegian english motivate use grammarspecific semantic interface semi facilitate construction maintenance scalable translation engine semi theoretically grounded component grammar capturing several class lexical regularity also serving crucial engineering function supplying reliable complete specification elementary predication grammar realize make extensive use underspecification type hierarchy maximize generality precision
summary invited talk
popular qa benchmark like squad driven progress task identifying answer span within specific passage model surpassing human performance however retrieving relevant answer huge corpus document still challenging problem place different requirement model architecture growing interest developing scalable answer retrieval model trained endtoend bypassing typical document retrieval step paper introduce retrieval questionanswering reqa benchmark evaluating largescale sentencelevel answer retrieval model establish baseline using neural encoding model well classical information retrieval technique release evaluation code encourage work challenging task
machine reading received recently lot attention thanks availability large corpus squad m marco containing triplet document question answer introduction transformer language model bert obtain excellent result even matching human performance according squad leaderboard one key feature transformer model ability jointly trained across multiple language using shared subword vocabulary leading construction crosslingual lexical representation feature used recently perform zeroshot crosslingual experiment multilingual bert model finetuned machine reading comprehension task exclusively english directly applied chinese french document interesting performance paper study crosslanguage crossdomain capability bert machine reading comprehension task two corpus squad new french machine reading dataset called calorquest semantic annotation available calorquest allows u give detailed analysis kind question properly handled crosslanguage process try answer question factor language mismatch domain mismatch strongest influence performance machine reading comprehension task
translation entail simply translating word one language another vitally essential effective crosscultural communication thus making good translation system important requirement describe system paper submitted wat translation shared task part multimodal translation task textonly translation subtasks submitted three neural machine translation system based transformer model english malayalam english bengali english hindi text translation found significant result leaderboard englishindic enxx system utilizing bleu ribes score comparative metric study respective translation english malayalam bengali hindi obtained bleu score challenge subset benchmark evaluation subset data
deep learning model linguistic task require large training datasets expensive create alternative traditional approach creating new instance repeating process creating one instance propose first collecting set seed example applying humandriven natural perturbation opposed rulebased machine perturbation often change gold label well perturbation advantage relatively easier hence cheaper create writing completely new example help address issue even model achieving humanlevel score nlp datasets known considerably sensitive small change input evaluate idea consider recent questionanswering dataset boolq study approach function perturbation cost ratio relative cost perturbing existing question v creating new one scratch find natural perturbation moderately cheaper create cost ratio effective use training boolq model model exhibit higher robustness stronger generalization retaining performance original boolq dataset
modern encoderdecoder based neural machine translation nmt model normally trained parallel sentence hence give best result translating full sentence rather sentence part thereby task translating commonly used phrase often arises language learner addressed nmt model highresourced language pair humanbuilt phrase dictionary exist lessresourced pair suggest approach building dictionary automatically based giza output show work significantly better translating phrase sentencestrained nmt system
pretrained visually grounded language model vilbert lxmert uniter achieved significant performance improvement visionandlanguage task learn pretraining remains unclear work demonstrate certain attention head visually grounded language model actively ground element language image region specifically head map entity image region performing task known entity grounding head even detect syntactic relation nonentity word image region tracking example association verb region corresponding argument denote ability textitsyntactic grounding verify grounding quantitatively qualitatively using flickrk entity testbed
present first africentric semeval shared task sentiment analysis african language afrisentisemeval dataset available urlhttpsgithubcomafrisentisemevalafrisentsemeval afrisentisemeval sentiment classification challenge african language amharic algerian arabic hausa igbo kinyarwanda moroccan arabic mozambican portuguese nigerian pidgin oromo swahili tigrinya twi xitsonga yorb muhammad et al using data labeled sentiment class present three subtasks task monolingual classification received submission task b multilingual classification received submission task c zeroshot classification received submission best performance task b achieved nlnde team weighted f respectively ucasiienlp achieved best average score task c weighted f describe various approach adopted top system approach
sequencetosequence seqseq model successfully applied automatic math word problem solving despite simplicity drawback still remains math word problem correctly solved one equation nondeterministic transduction harm performance maximum likelihood estimation paper considering uniqueness expression tree propose equation normalization method normalize duplicated equation moreover analyze performance three popular seqseq model math word problem solving find model specialty solving problem consequently ensemble model proposed combine advantage experiment dataset mathk show ensemble model equation normalization significantly outperforms previous stateoftheart method
paper present trentoteam system participated thetask semeval nakov et alwe concentrated work onapplying grice maximsused manystateoftheart machine learning applicationsvogel et al kheirabadiand aghagolzadeh dale reiter franke ranking answer question answer relevancy particularly created ranker systembased relevancy score assigned main component named entity recognition similarity score sentiment analysis system obtained comparable resultsto machine learning system
nounnoun compound nncs occur frequently english language accurate nnc interpretation ie determining implicit relationship constituent nnc crucial advancement many natural language processing task computational nnc interpretation limited approach involving linguistic representation however much research suggests grounding linguistic representation vision modality increase performance task work novel comparison linguistic visuolinguistic representation task nnc interpretation frame nnc interpretation relation classification task evaluating large relationallyannotated nnc dataset combine distributional word vector image vector investigate visual information help improve nnc interpretation system find adding visual vector increase classification performance dataset many case
inability correctly resolve rumour circulating online harmful realworld consequence present method incorporating model data uncertainty estimate natural language processing model automatic rumour verification show estimate used filter model prediction likely erroneous difficult instance prioritised human factchecker propose two method uncertaintybased instance rejection supervised unsupervised also show uncertainty estimate used interpret model performance rumour unfolds
increasing application language model become crucial protect model leaking private information previous work attempted tackle challenge training rnnbased language model differential privacy guarantee however applying classical differential privacy language model lead poor model performance underlying privacy notion overpessimistic provides undifferentiated protection token data given private information natural language sparse example bulk email might carry personally identifiable information propose new privacy notion selective differential privacy provide rigorous privacy guarantee sensitive portion data improve model utility realize new notion develop corresponding privacy mechanism selectivedpsgd rnnbased language model besides language modeling also apply method concrete application dialog system experiment language modeling dialog system building show proposed privacypreserving mechanism achieves better utility remaining safe various privacy attack compared baseline data code released urlhttpsgithubcomwyshilmprivacy facilitate future research
visual entity linking vel task link region image corresponding entity knowledge base kb beneficial many computer vision task image retrieval image caption visual question answering existing task vel either rely textual data complement multimodal linking link object general entity fails perform named entity linking large amount image data paper consider purely visualbased named entity linking vnel task input consists image task identify object interest ie visual entity mention image link corresponding named entity kb since entity often contains rich visual textual information kb thus propose three different subtasks ie visual visual entity linking vvel visual textual entity linking vtel visual visualtextual entity linking vvtel addition present highquality humanannotated visual person linking dataset named wikiperson based wikiperson establish series baseline algorithm solution subtask conduct experiment verify quality proposed datasets effectiveness baseline method envision work helpful soliciting work regarding vnel future code datasets publicly available http githubcomictbigdatalabvnel
nowadays social medium become popular platform company understand customer provides valuable opportunity gain new insight person opinion product influenced friend though various approach proposed study opinion formation problem formulate opinion derived sentiment value either discrete continuous without considering semantic information paper propose contentbased social influence model study implicit mechanism underlying change opinion apply learned model predict user future opinion advantage proposed model ability handle semantic information learn two influence component including opinion influence content information social relation factor experiment conducted twitter datasets model significantly outperforms popular opinion formation model
gender bias widely studied nlp community however subtle variation mansplaining yet received little attention mansplaining discriminatory behaviour consists condescending treatment discourse towards woman paper introduce analyze well actually corpus mansplaining story experienced woman analyze corpus term feature offensiveness sentiment misogyny among others also explore extent large language model llm understand identify mansplaining genderrelated microaggressions specifically experiment chatgptturbo llama b b targeted open question finding suggest although identify mansplaining extent llm still struggle point attitude even reproduce social pattern behind mansplaining situation instance praising men giving unsolicited advice woman
paper present approach identify sample live traffic customer implicitly communicated satisfaction alexas response leveraging interpretation model behavior customer signal noisy adding large number sample live traffic training set make retraining infeasible work address challenge identifying small number sample grow training set textasciitilde producing statistically significant improvement offline online test
keyphrases concisely describe highlevel topic discussed document useful wide range natural language processing task though existing keyphrase generation method achieved remarkable performance task generate many overlapping phrase including subphrases superphrases keyphrases paper propose parallel seqseq network coverage attention alleviate overlapping phrase problem specifically integrate linguistic constraint keyphrase basic seqseq network source side employ multitask learning framework target side addition order prevent generating overlapping phrase keyphrases correct syntax introduce coverage vector keep track attention history decide whether part source text covered existing generated keyphrases experimental result show method outperform stateoftheart copyrnn scientific datasets also effective news domain
despite remarkable performance largescale generative model opendomain conversation known less practical building realtime conversation system due high latency hand retrieval model could return response much lower latency show inferior performance largescale generative model since conversation quality bounded predefined response set take advantage approach propose new training method called gr generativetoretrieval distillation preserve efficiency retrieval model leveraging conversational ability largescale generative model infusing knowledge generative model retrieval model gr consists two distinct technique distillation datalevel gr augments dialogue dataset additional response generated largescale generative model modellevel gr transfer response quality score assessed generative model score retrieval model knowledge distillation loss extensive experiment including human evaluation demonstrate retrievalbased conversation system trained gr show substantially improved performance compared baseline retrieval model showing significantly lower inference latency largescale generative model
availability parallel sentence simplification s scarce neural s modeling propose unsupervised method build s corpus largescale bilingual translation corpus alleviating need s supervised corpus method motivated following two finding neural machine translation model usually tends generate highfrequency token difference text complexity level exists source target language translation corpus taking pair source sentence translation corpus translation reference bridge language construct largescale pseudo parallel s data keep sentence pair higher complexity difference s sentence pair building s corpus unsupervised approach satisfy expectation aligned sentence preserve meaning difference text complexity level experimental result show s method trained corpus achieve stateoftheart result significantly outperform result english benchmark wikilarge
sentiment analysis refers process interpreting sentence emotes classifying positive negative neutral widespread popularity social medium led generation lot text data specifically indian social medium scenario codemixed hinglish text ie word hindi language written roman script along english word common sight ability effectively understand sentiment text much needed paper proposes system titled nitshinglish effectively carry sentiment analysis codemixed hinglish text system fared well final fscore test data
majority approach author profiling author identification focus mainly lexical feature ie content text argue syntactic discourse feature play significantly prominent role given past show achieve stateoftheart performance author gender identification literary corpus keeping feature set small used feature set composed feature still outperforms winner pan shared task author verification literary genre
aim software presentation demonstrate corpusdriven bilingual dictionary generated fully automatic mean suitable human use need dictionary show specifically case lesser used language due low demand pay publisher invest production dictionary previous experiment proven bilingual lexicon created applying word alignment parallel corpus approach especially corpusdriven nature yield several advantage traditional approach importantly automatically attained translation probability able guarantee frequently used translation come first within entry however proposed technique face difficulty well particular scarce availability parallel text medium density language imposes limitation size resulting dictionary objective design implement dictionary building workflow query system apt exploit additional benefit method overcome disadvantage
research shown practice translation exhibit predictable linguistic cue make translated text detectable originallanguage text phenomenon known translationese paper test extent literary translation subject effect whether also exhibit meaningful difference level content research function translation within national literary market using smaller case study suggested translation play cultural role distinct originallanguage literature ie difference reside level translationese level content using dataset consisting originallanguage fiction english translation english language n find one principal function literary translation convey predictable geographic identity local reader nevertheless extend well beyond foreignness person place
propose novel simple method semisupervised text classification method stem hypothesis classifier pretrained word embeddings always outperforms classifier randomly initialized word embeddings empirically observed nlp task method first build two set classifier form model ensemble initializes word embeddings differently one using random using pretrained word embeddings focus different prediction two classifier unlabeled data following selftraining framework also use earlystopping metaepoch improve performance method method deltatraining outperforms selftraining cotraining framework different text classification datasets showing robustness error accumulation
automatic video description generation recently getting attention rapid advancement image caption generation automatically generating description video challenging image due temporal dynamic frame work relied recurrent neural network rnn recently attentional mechanism also applied make model learn focus frame video generating word describing sentence paper focus sequencetosequence approach temporal attention mechanism analyze compare result different attention model configuration applying temporal attention mechanism system achieve meteor score microsoft video description dataset outperformed stateoftheart system far
present experiment assessing grammatical correctness learner answer languagelearning system reference system link released data code withheld anonymity particular explore problem detecting alternativecorrect answer one inflected form lemma fit syntactically semantically given context approach problem method grammatical error detection ged since hypothesize model detecting grammatical mistake assess correctness potential alternative answer learning setting due paucity training data explore ability pretrained bert detect grammatical error finetune using synthetic training data work focus error inflection experiment show pretrained bert performs worse detecting grammatical irregularity russian english b finetuned bert yield promising result assessing correctness grammatical exercise c establish new benchmark russian investigate performance compare finetuned bert one stateoftheart model ged bell et al dataset rulecgec rozovskaya roth release manually annotated learner dataset used testing general use
paper describe morphosyntactic tagger tweet important component cea list deeplima tool multilingual text analysis platform based deep learning tagger built morphosyntactic tagging tweet mtt shared task vardial evaluation campaign mtt task focus morphosyntactic annotation noncanonical twitter variety three southslavic language slovene croatian serbian propose use neural network model trained endtoend manner three language without need task domain specific feature engineering proposed approach combine character word level representation considering lack annotated data social medium domain southslavic language also implemented crossdomain transfer learning tl approach exploit available related outofdomain annotated data
lottery ticket hypothesis suggests overparametrized network consists lottery ticket training certain collection ie subnetwork match performance full model paper study collection ticket referred winning ticket extremely overparametrized model eg pretrained language model observe certain compression ratio generalization performance winning ticket match also exceed full model particular observe phase transition phenomenon compression ratio increase generalization performance winning ticket first improves deteriorates certain threshold refer ticket threshold super ticket show phase transition task model dependent model size becomes larger training data set becomes smaller transition becomes pronounced experiment glue benchmark show super ticket improve single task finetuning point bertbase point bertlarge term taskaverage score also demonstrate adaptively sharing super ticket across task benefit multitask learning
study explored automated creative essay scoring ace pretrained model automatically label essay creative noncreative since creativity evaluation essay subjective evaluator often criterion creativity reason quantifying creativity essay challenging work one preliminary study developing novel model ace deeply investigate correlation creative essay expressiveness specifically explore rare token affect evaluation creativity essay journey present five distinct method extract rare token conduct comparative study correlation rare token creative essay evaluation result using bert experimental result showed clear correlation rare token creative essay test set accuracy rare token maskingbased bert rambert model improved existing bert model
propose novel thai graphemetophoneme conversion method based neural regression model trained using neural network predict similarity candidate correct pronunciation generating set candidate input word phrase using orthography rule model selects bestsimilarity pronunciation candidate method applied language thai simply preparing enough orthography rule reduce mistake neural network model often make show accuracy proposed method comparable encoderdecoder sequence model also demonstrate proposed method superior term difference correct predicted pronunciation incorrect strange output sometimes occurs using encoderdecoder sequence model error within expected range using proposed method
using language model lm pretrained two language large monolingual data order initialize unsupervised neural machine translation unmt system yield stateoftheart result limited data available one language however method lead poor translation present effective approach reuses lm pretrained highresource language monolingual lm finetuned language used initialize unmt model reuse pretrained lm modify predefined vocabulary account new language therefore propose novel vocabulary extension method approach relm outperforms competitive crosslingual pretraining model xlm englishmacedonian enmk englishalbanian ensq yielding bleu point four translation direction
sentence presupposition often treated uninterpretable unvalued neither true false presupposition satisfied however open question satisfaction calculated case determining whether presupposition satisfied trivial task even decidable one yet native speaker able quickly confidently identify instance presupposition failure propose accounted form possible world semantics encapsulates reasoning ability limited computational power thus circumventing need solve computationally difficult problem modeled using variant framework finite state semantics proposed rooth modification system necessary including extension threevalued logic account presupposition within framework logic necessary calculate presupposition satisfaction readily available risk needing exceptional computational power correctly predicts certain presupposition calculated intuitively others easily evaluated
present mixingboard platform quickly building demo focus knowledge grounded stylized text generation unify existing text generation algorithm shared codebase adapt earlier algorithm constrained generation borrow advantage different model implement strategy crossmodel integration token probability level latent space level interface external knowledge provided via module retrieves onthefly relevant knowledge passage web document collection user interface local development remote webpage access restful api provided make simple user build demo
paper describes equerevalda evaluation campaign french evaluation campaign questionanswering qa system equer evaluation campaign included two task automatic answer retrieval first one qa task heterogeneous collection text mainly newspaper article second one specialised one medical field corpus medical text total seven group participated general task five group participated medical task general task best system obtained correct answer evalaution passage obtained evaluation short answer describe herein specification corpus evaluation phase judgment result scoring phase result two different type evaluation
paper describe system submitted nadi subtask countrywise dialect classification designed two type solution first type convolutional neural network cnn classifier trained subword segment optimized length second type finetuned classifier bertbased language specific pretrained model deal missing dialect one test set experimented binary classifier analyzing predicted probability distribution pattern comparing development set pattern better performing approach development set finetuning language specific pretrained model best fscore test set hand obtained best performance cnn model trained subword token obtained unigram model best fscore retraining model sample training data simulating missing dialect gave maximum performance test set version number dialect lesser training set fscore
knowledge distillation effectively transfer knowledge bert deep language representation model traditional shallow word embeddingbased neural network helping approach exceed quality heavyweight language representation model shown previous work critical distillation procedure construction unlabeled transfer dataset enables effective knowledge transfer create transfer set example propose sample pretrained language model finetuned taskspecific text unlike previous technique directly capture purpose transfer set hypothesize principled general approach outperforms rulebased technique four datasets sentiment classification sentence similarity linguistic acceptability show approach improves upon previous method outperform openai gpt deep pretrained transformer three datasets using singlelayer bidirectional lstm run least ten time faster
user physical safety increasing concern market intelligent system continues grow unconstrained system may recommend user dangerous action lead serious injury covertly unsafe text area particular interest text may arise everyday scenario challenging detect harmful propose farm novel framework leveraging external knowledge trustworthy rationale generation context safety particular farm foveates missing knowledge qualify information required reason specific scenario retrieves information attribution trustworthy source knowledge used classify safety original text generate humaninterpretable rationale shedding light risk system specific user group helping stakeholder manage risk system policymakers provide concrete safeguard consumer safety experiment show farm obtains stateoftheart result safetext dataset showing absolute improvement safety classification accuracy
present novel method unsupervised cognateborrowing identification monolingual corpus designed low extremely low resource scenario based combining noisy semantic signal joint bilingual space orthographic cue modelling sound change apply method north indian dialect continuum containing several dozen dialect language spoken million people many language zeroresource therefore natural language processing nonexistent first collect monolingual data indic language previously zeroresource perform exploratory character lexical subword crosslingual alignment experiment first time scale dialect continuum create bilingual evaluation lexicon hindi language apply cognate identification method data show method outperforms traditional orthography baseline well emstyle learnt edit distance matrix best knowledge first work combine traditional orthographic cue noisy bilingual embeddings tackle unsupervised cognate detection truly lowresource setup showing even noisy bilingual embeddings act good guide task release multilingual dialect corpus called hindialect well script evaluation data collection cognate induction
paper present system semeval task measeval measeval novel span extraction classification relation extraction task focused finding quantity attribute quantity additional information including related measured entity property measurement context submitted system placed fifth team rank leaderboard consisted scibert cl token embedding crf layer top also placed first quantity tied unit subtasks second measuredentity modifier qualifies subtasks third qualifier subtask
introduce corpus transcript althingi icelandic parliament corpus syntactically parsed phrase structure according annotation scheme icelandic parsed historical corpus icepahc addition icepahc make diverse respect text type argue syntactically parsed corpus facilitates research differt type text furthermore argue speech corpus treated somewhat like spoken language even though transcript differ various way daily spoken language also compare text type type argue genre shed light property finally exhibit addition icepahc helped u identifying solving issue parsing scheme
current symbolic semantic representation proposed capture semantics human language served well give u insight meaning expressed either complicated largescale annotation task lack expressive power play role inference task propose meaning representation system interlingual modeltheoretic variablefree divide labour involved representing meaning along three level concept role context natural language expressed sequence phoneme word meaning representation propose likewise sequential however resulting meaning representation also visualised directed acyclic graph
paper explore relation gesture language using multimodal dataset consisting ted talk language aligned gesture made speaker adapt semisupervised multimodal model learn gesture embeddings show gesture predictive native language speaker gesture embeddings improve language prediction result addition gesture embeddings might contain linguistic information show probing embeddings psycholinguistic category finally analyze word lead expressive gesture find function word drive expressiveness gesture
although automatic text summarization at researched several decade application graph neural network gnns task started relatively recently survey provide overview rapidly evolving approach using gnns task automatic text summarization particular provide detailed information functionality gnns context at comprehensive overview model utilizing approach
semantic equivalence assessment defined task assesses semantic equivalence sentence pair binary judgment ie paraphrase identification grading ie semantic textual similarity measurement constitutes set task crucial research natural language understanding recently bert realized breakthrough sentence representation learning devlin et al broadly transferable various nlp task berts performance improves increasing model size required computational power obstacle preventing practical application adopting technology herein propose inject phrasal paraphrase relation bert order generate suitable representation semantic equivalence assessment instead increasing model size experiment standard natural language understanding task confirm method effectively improves smaller bert model maintaining model size generated model exhibit superior performance compared larger bert model semantic equivalence assessment task furthermore achieves larger performance gain task limited training datasets finetuning property desirable transfer learning
modeling likely label annotation task perspectivedependent discard relevant source variation come annotator present three approach modeling controversiality particular text first explicitly represented annotator using annotator embeddings predict training signal annotator selection addition majority class label method lead reduction error relative model without feature allowing overall result influence weight annotator final prediction second set experiment annotator modeled individually instead annotator judgment combined pairwise fashion allowed u implicitly combine annotator overall found aggregating explicitly comparing annotator response static document representation produced highquality prediction datasets though system struggle account large variable number annotator
investigate rulebased machine learning method task compound error correction evaluate efficiency north sami low resource language lack errorfree data needed neural approach challenge development tool shared bigger language order compensate used rulebased grammar checker remove erroneous sentence insert compound error splitting correct compound describe set error detection rule train birnn based neural network precision rulebased model tested corpus real error slightly better neural model rulebased model also flexible regard fixing specific error requested user community however neural model better recall result suggest approach combine advantage model would desirable future tool data set opensource freely available github zenodo
social medium provided platform many individual easily express naturally publicly researcher opportunity utilize large quantity data improve author trait analysis technique improve author trait profiling system majority work area however narrowly spent english western european language generally focus single social network time despite large quantity data available across language difference found across platform paper introduces ruadept dataset russian author personality trait scoresbig five dark triad demographic information eg age gender associated corpus author crosscontributions four different social medium platformsvkontakte vk livejournal blogger moi mir believe first publiclyavailable dataset associating demographic personality trait data russianlanguage social medium content first paper describe collection dark triad score text across multiple russianlanguage social medium platform limited extent first publiclyavailable dataset personality trait author content across several different social medium site
reinforcement learning rl made remarkable progress neural machine translation nmt however exists problem uneven sampling distribution sparse reward high variance training phase therefore propose multireward reinforcement learning training strategy decouple action selection value estimation meanwhile method combine language model reward jointly optimize model parameter addition add gumbel noise sampling obtain effective semantic information verify robustness method conducted experiment large corpus also performed lowresource language experimental result show work superior baseline wmt englishgerman ldc chineseenglish cwmt mongolianchinese task fully certificate effectiveness method
po tag taken granted useful resource syntactic parsing become situational popularization deep learning recent work impact po tag graph transitionbased parser suggests useful tagging accuracy prohibitively high lowresource scenario however analysis lacking emerging sequence labeling parsing paradigm especially relevant model explicitly use po tag encoding decoding undertake study uncover trend among po tag generally useful sequence labeling parser paradigm impact accuracy highly encodingdependent posbased headselection encoding best tagging accuracy resource availability high
paper proposes general purpose relation extractor us wikidata description represent relation surface form result tested fewrel dataset provides excellent framework training evaluating proposed zeroshot learning system english relation extractor architecture exploit implicit knowledge language model questionanswering approach
chinese frame semantic parsing cfsp semantic parsing task based chinese framenetcfn paper present solution ccleval task first attempt various pretrained model different subtasks explore multiple approach solving eachtask perspective feature engineering model structure trick finallywe provide prospect task propose potential alternative solution conductedextensive comparative experiment validate effectiveness system introduction
paper describes result nilc team cwi developed solution following three approach feature engineering method using lexical ngram psycholinguistic feature ii shallow neural network method using word embeddings iii long shortterm memory lstm language model pretrained large text corpus produce contextualized word vector feature engineering method obtained best result classification task lstm model achieved best result probabilistic classification task result show deep neural network able perform well traditional machine learning method using manually engineered feature task complex word identification english
paragraphstyle image caption describe diverse aspect image opposed common singlesentence caption provide abstract description image paragraph caption hence contain substantial information image task visual question answering moreover textual information complementary visual information present image discus abstract concept explicit intermediate symbolic information object event scene directly matched textual question copied textual answer ie via easier modality match hence propose combined visual textual question answering vtqa model take input paragraph caption well corresponding image answer given question based input model input fused extract related information crossattention early fusion fused form consensus late fusion finally expected answer given extra score enhance chance selection later fusion empirical result show paragraph caption even automatically generated via rlbased encoderdecoder model help correctly answer visual question overall joint model trained visual genome dataset significantly improves vqa performance strong baseline model
current natural language inference nli model achieve impressive result sometimes outperforming human evaluating indistribution test set however model known learn annotation artefact dataset bias unclear extent model learning task nli instead learning shallow heuristic training datawe address issue introducing logical reasoning framework nli creating highly transparent model decision based logical rule unlike prior work show improved interpretability achieved without decreasing predictive accuracy almost fully retain performance snli also identifying exact hypothesis span responsible model predictionusing esnli human explanation verify model make sensible decision span level despite using span label training improve model performance spanlevel decision using esnli explanation training finally model robust reduced data setting training example outofdistribution performance improves mnli matched mismatched validation set relative baseline training fewer observation yield improvement indistribution outofdistribution
learning interview patient find disease essential part training medical student practical part training traditionally relied paid actor play role patient interviewed process expensive severely limit amount practice per student work present novel data set method based natural language processing making progress towards modern application elearning tool support training providing languagebased user interface virtual patient data set german transcription live doctorpatient interview collected transcription based audio recording exercise session within university doctor utterance could transcribed annotated utterance intent inventory characterizing purpose question statement intent class data contains sample apply information retrieval deep learning method robust respect small amount training data recognizing intent utterance providing correct response result show model effective provide baseline performance score data set research
functional distributional semantics recently proposed framework learning distributional semantics provides linguistic interpretability model meaning word binary classifier rather numerical vector work propose method train functional distributional semantics model grounded visual data train visual genome dataset closer kind data encountered human language acquisition large text corpus four external evaluation datasets model outperforms previous work learning semantics visual genome
paper describes naists system englishtojapanese simultaneous texttotext translation task iwslt evaluation campaign primary submission based waitk neural machine translation sequencelevel knowledge distillation encourage literal translation
sentiment analysis fundamental task structure sentiment analysis ssa important component sentiment analysis however traditional ssa suffering important issue lack interactive knowledge different language small amount annotation data even annotation data address problem incorporate data augment auxiliary task within crosslingual pretrained language model ssa specifically employ xlmroberta enhance mutually interactive information parallel data available pretraining stage furthermore leverage two data augment strategy auxiliary task improve performance fewlabel data zeroshot crosslingual setting experiment demonstrate effectiveness model model rank first crosslingual subtask rank second monolingual subtask semeval task
quality estimation qe machine translation emerged promising way provide realworld application method estimate runtime reliability automatic translation realworld application however pose challenge go beyond current qe evaluation setting instance heterogeneity scarce availability training data might contribute significantly raise bar address issue compare two alternative machine learning paradigm namely online multitask learning measuring capability overcome limitation current batch method result experiment carried experimental setting demonstrate effectiveness two method suggest complementarity indicates promising research avenue possibility combine strength online multitask approach problem
propose data augmentation method neural machine translation work interpreting language model phrasal alignment causally specifically creates augmented parallel translation corpus generating pathspecific counterfactual aligned phrase generate sampling new source phrase masked language model sampling aligned counterfactual target phrase noting translation language model interpreted gumbelmax structural causal model oberst sontag compared previous work method take context alignment account maintain symmetry source target sequence experiment iwslt english vietnamese wmt english german wmt english turkish wmt robust english french show method improve performance translation backtranslation translation robustness
machine learning ml system natural language processing nlp face significant challenge generalizing outofdistribution ood data test distribution differs training data distribution pose important question robustness nlp model high accuracy may artificially inflated due underlying sensitivity systematic bias despite challenge lack comprehensive survey generalization challenge ood perspective natural language understanding therefore paper aim fill gap presenting first comprehensive review recent progress method evaluation topic discus challenge involved potential future research direction providing convenient access existing work hope survey encourage future research area
work aim employ natural language generation nlg rapidly generate item english language learning application requires language model capable generating fluent highquality english control output generation match requirement relevant item experiment deep pretrained model task developing novel method controlling item factor relevant language learning diverse sentence different proficiency level argument structure test grammar human evaluation demonstrates high grammatically score model higher length complexity baseline advanced proficiency model result show achieve strong performance adding additional control ensure diverse tailored content individual user
homophobictransphobic ht content includes hatred discriminatory comment directed lesbian gay bisexual transgender queer lgbtq individual social medium platform unfavourable perception towards lgbtq individual may affect physically mentally necessary detect ht content social medium demand automated tool identify address ht content view paper team mucs describe learning model submitted homophobiatransphobia detection social medium commentsltedieacl shared task european chapter association computational linguistics eacl learning model homoensemble ensemble machine learning ml algorithm trained term frequencyinverse document frequency tfidf syllable ngrams range ii homotl model based transfer learning tl approach bidirectional encoder representation transformer bert model iii homoprobfuse ensemble ml classifier soft voting trained using sentence embeddings except hindi iv homofsl fewshot learning fsl model using sentence transformer st tulu proposed detect ht content given language among model submitted shared task model performed better language include homoensemble model obtained macro f score securing th rank telugu language ii homotl model obtained macro f score securing nd nd st st th rank english marathi hindi kannada gujarathi language respectively iii homoprobfuse model obtained macro f score securing nd th nd rank tamil malayalam spanish language respectively iv homofsl model obtained macro f score securing nd rank tulu dataset
large language model llm exhibited powerful capability various natural language processing task work focus exploring llm performance zeroshot information extraction focus chatgpt named entity recognition ner task inspired remarkable reasoning capability llm symbolic arithmetic reasoning adapt prevalent reasoning method ner propose reasoning strategy tailored ner first explore decomposed questionanswering paradigm breaking ner task simpler subproblems label second propose syntactic augmentation stimulate model intermediate thinking two way syntactic prompting encourages model analyze syntactic structure tool augmentation provides model syntactic information generated parsing tool besides adapt selfconsistency ner proposing twostage majority voting strategy first vote consistent mention consistent type proposed method achieve remarkable improvement zeroshot ner across seven benchmark including chinese english datasets domainspecific generaldomain scenario addition present comprehensive analysis error type suggestion optimization direction also verify effectiveness proposed method fewshot setting llm
present project creating corola reference corpus contemporary romanian onwards international context project find place among initiative gathering huge collection text preprocessing annotating several level also documenting metadata cmdi project joined effort two institute romanian academy foresee corpus million word form covering functional style language although vast majority text written form target hour oral text obligatorily associated transcript text book rest harvested newspaper booklet technical report etc preprocessing includes cleaning data harmonising diacritic sentence splitting tokenization annotation done morphological level first stage followed lemmatization possibility adding syntactic semantic discourse annotation later stage core corola described article target user corpus researcher linguistics language processing teacher romanian student
present first annotated corpus multilingual analysis potentially unfair clause online term service data set comprises total contract obtained document annotated four different language english german italian polish contract potentially unfair clause consumer annotated nine different unfairness category show simple yet efficient annotation projection technique based sentence embeddings could used automatically transfer annotation across language
leveraging knowledge electronic health record ehrs predict patient condition essential effective delivery appropriate care clinical note patient ehrs contain valuable information healthcare professional underused due difficult content complex hierarchy recently hypergraphbased method proposed document classification directly adopting existing hypergraph method clinical note sufficiently utilize hierarchy information patient degrade clinical semantic information frequent neutral word hierarchy imbalanced distribution thus propose taxonomyaware multilevel hypergraph neural network tmhgnn multilevel hypergraphs assemble useful neutral word rare keywords via note taxonomy level hyperedges retain clinical semantic information constructed patient hypergraphs fed hierarchical message passing layer learning balanced multilevel knowledge note taxonomy level validate effectiveness tmhgnn conducting extensive experiment mimiciii dataset benchmark inhospitalmortality prediction
documentation regular part contemporary healthcare practice one documentation task creation discharge summary summarizes care episode however manually write discharge summary timeconsuming task research shown discharge summary often lacking quality various respect alleviate problem text summarization method could applied text electronic health record patient note automatically create discharge summary previous research conducted topic text various language various method research conducted swedish text paper four datasets extracted swedish clinical corpus used finetune four bart language model perform task summarizing swedish patient note discharge summary model best performing model manually evaluated senior retired nurse clinical coder evaluation result show best performing model produce discharge summary overall low quality possibly due issue data extracted health bank research infrastructure warrant work topic
previous research demonstrated potential multitask learning foster conversational agent ability acquire variety skill however approach either suffer interference among different datasets also known negative transfer fail effectively reuse knowledge skill learned datasets contrast previous work develop sparsely activated modular network propose wellrounded set operator instantiate operator independent module formulate dialogue generation execution generated programme recursively composes assembles module extensive experiment datasets verify efficacy method automatic evaluation human evaluation notably model outperforms stateoftheart supervised approach datasets training data thanks modular architecture multitask learning
knowledge distillation known effective technique compressing overparameterized language model work propose break global feature distillation task n local subtasks new framework consider neuron last hidden layer teacher network specialized subteacher also consider neuron last hidden layer student network focused substudent make focused substudent learn one corresponding specialized subteacher ignore others facilitate task substudent keep focused proposed method novel combined distillation technique empirical result show proposed approach outperforms stateoftheart method maintaining higher performance benchmark datasets furthermore propose randomized variant approach called masked onetoone mapping rather learning n subtasks simultaneously focus learning subset subtasks optimization step variant enables student digest received flow knowledge effectively yield superior result
standard resource sensitive invariant categorial grammar suited prune search space presence coordination propose weaker variant count invariancy order prune search space parsing coordinated sentence stage prior proper parsing coordinative count invariant argued strongest possible instrument prune search space parsing coordination categorial grammar mode operation explained effect pruning search space exemplified
continual named entity recognition cner burgeoning area involves updating existing model incorporating new entity type sequentially nevertheless continual learning approach often severely afflicted catastrophic forgetting issue intensified cner due consolidation old entity type previous step nonentity type step leading known semantic shift problem nonentity type paper introduce pooled feature distillation loss skillfully navigates tradeoff retaining knowledge old entity type acquiring new one thereby effectively mitigating problem catastrophic forgetting additionally develop confidencebased pseudolabeling nonentity type ie predicting entity type using old model handle semantic shift nonentity type following pseudolabeling process suggest adaptive reweighting typebalanced learning strategy handle issue biased type distribution carried comprehensive experiment ten cner setting using three different datasets result illustrate method significantly outperforms prior stateoftheart approach registering average improvement micro macro f score respectively
dense retrieval method shown great promise sparse retrieval method range nlp problem among dense phrase retrievalthe finegrained retrieval unitis appealing phrase directly used output question answering slot filling task work follow intuition retrieving phrase naturally entail retrieving larger text block study whether phrase retrieval serve basis coarselevel retrieval including passage document first observe dense phraseretrieval system without retraining already achieves better passage retrieval accuracy top accuracy compared passage retriever also help achieve superior endtoend qa performance fewer passage provide interpretation phraselevel supervision help learn better finegrained entailment compared passagelevel supervision also show phrase retrieval improved achieve competitive performance documentretrieval task entity linking knowledgegrounded dialogue finally demonstrate phrase filtering vector quantization reduce size index x making dense phrase retrieval practical versatile solution multigranularity retrieval
modelling persuasion strategy predictor task outcome several realworld application received considerable attention computational linguistics community however previous research failed account resisting strategy employed individual foil persuasion attempt grounded prior literature cognitive social psychology propose generalised framework identifying resisting strategy persuasive conversation instantiate framework two distinct datasets comprising persuasion negotiation conversation also leverage hierarchical sequencelabelling neural architecture infer aforementioned resisting strategy automatically experiment reveal asymmetry power role noncollaborative goaldirected conversation benefit accrued incorporating resisting strategy final conversation outcome also investigate role different resisting strategy conversation outcome glean insight corroborate past finding also make code dataset work publicly available urlhttpsgithubcomamericastresper
multihop textual question answering requires combining information multiple sentence focus natural setting unlike typical reading comprehension partial information provided question model must retrieve use additional knowledge correctly answer question tackle challenge develop novel approach explicitly identifies knowledge gap key span provided knowledge answer choice model gapqa learns fill gap determining relationship span answer choice based retrieved knowledge targeting gap propose jointly training model simultaneously fill knowledge gap compose provided partial knowledge openbookqa dataset given partial knowledge explicitly identifying whats missing substantially outperforms previous approach
existing opendomain question answering qa model suitable realtime usage need process several long document ondemand every input query computationally prohibitive paper introduce queryagnostic indexable representation document phrase drastically speed opendomain qa particular densesparse phrase encoding effectively capture syntactic semantic lexical information phrase eliminates pipeline filtering context document leveraging strategy optimizing training inference time model trained deployed even single gpu server moreover representing phrase pointer start end token model index phrase entire english wikipedia billion phrase using tb experiment squadopen show model par accurate previous model x reduced computational cost translates least x faster endtoend inference benchmark cpu code demo available nlpcswashingtonedudenspi
detecting depression personality trait tutoring student behaviour system identifying case cyberbulling wide range application automatic detection emotion crucial element emotion detection potential high impact contributing benefit business society politics education given context main objective research contribute resolution one important challenge textual emotion detection task problem emotional corpus annotation tackled proposing new semiautomatic methodology innovative methodology consists two main phase automatic process preannotate unlabelled sentence reduced number emotional category refinement manual process human annotator determine predominant emotion emotional category selected phase proposal paper show evaluate preannotation process analyse feasibility benefit methodology proposed result obtained promising allow obtaining substantial improvement annotation time cost confirm usefulness preannotation process improve annotation task
incontext learning shown great success iid semantic parsing split training test set drawn distribution setup model typically prompted demonstration similar input utterance however setup compositional generalization model tested output structure absent training set selecting similar demonstration insufficient often example similar enough input work propose method select diverse demonstration aim collectively cover structure required output program order encourage model generalize new structure demonstration empirically show combining diverse demonstration incontext learning substantially improves performance across three compositional generalization semantic parsing datasets pure incontext learning setup combined finetuning
realworld natural language processing nlp model need continually updated fix prediction error outofdistribution ood data stream overcoming catastrophic forgetting however existing continual learning cl problem setup cover realistic complex scenario response propose new cl problem formulation dubbed continual model refinement cmr compared prior cl setting cmr practical introduces unique challenge boundaryagnostic nonstationary distribution shift diverse mixture multiple ood data cluster errorcentric stream etc extend several existing cl approach cmr setting evaluate extensively benchmarking analysis propose general sampling algorithm obtain dynamic ood data stream controllable nonstationarity well suite metric measuring various aspect online performance experiment detailed analysis reveal promise challenge cmr problem supporting studying cmr dynamic ood stream benefit longevity deployed nlp model production
several study indicate level predicateargument structure relevant modeling prevalent phenomenon current textual entailment corpus although large resource like framenet recently become available attempt integrate type information system textual entailment confirm expected gain performance reason fully obvious candidate include framenets restricted coverage limitation semantic parser insufficient modeling framenet information enable insight issue paper present fate framenetannotated textual entailment manually crafted fully reliable frameannotated rte corpus annotation carried pair rte test set dataset offer safe basis rte system experiment enables researcher develop clearer idea effectively integrate frame knowledge semantic inferenence task like recognizing textual entailment describe present statistic adopted annotation introduces new schema based fulltext annotation called relevant frame evoking element
recent year seen increased interest adapting translation model test domain known advance well using latent topic representation adapt unknown test domain however relationship domain latent topic still somewhat unclear topic adaptation approach typically make use domain knowledge training data show empirically combining domain topic adaptation approach beneficial topic representation used predict domain test document best combined model yield gain bleu domainadapted translation system bleu unadapted system measured stronger two training condition
data visualization emerged effective tool getting insight massive datasets due hardness manipulating programming language data visualization automatic data visualization generation natural language texttovis becoming increasingly popular despite plethora research effort english texttovis study yet conducted data visualization generation question chinese motivated propose chinese texttovis dataset paper demonstrate first attempt tackle problem model integrates multilingual bert encoder boost crosslingual ability infuses ngram information word representation learning experimental result show dataset challenging deserves research
study variant domain adaptation namedentity recognition multiple heterogeneously tagged training set available furthermore test tagset identical individual training tagset yet relation tag provided tag hierarchy covering test tag combination training tag setting occurs various datasets created using different annotation scheme also case extending tagset new tag annotating new tag new dataset propose use given tag hierarchy jointly learn neural network share tagging layer among tagsets compare model combining independent model model based multitasking approach experiment show benefit taghierarchy model especially facing nontrivial consolidation tagsets
named entity recognition ner system focus improving model performance ignoring need quantify model uncertainty critical reliability ner system open environment evidential deep learning edl recently proposed promising solution explicitly model predictive uncertainty classification task however directly applying edl ner application face two challenge ie problem sparse entity oovood entity ner task address challenge propose trustworthy ner framework named ener introducing two uncertaintyguided loss term conventional edl along series uncertaintyguided training strategy experiment show ener applied multiple ner paradigm obtain accurate uncertainty estimation furthermore compared stateoftheart baseline proposed method achieves better oovood detection performance better generalization ability oov entity
predictive model make mistake bias combat need understand predictionsexplainable ai xai provides insight model vision language tabular data however approach exist speech classification model previous work focus selection spoken language understanding slu task user find explanation challenging interpretwe propose novel approach explain speech classification model provides two type insight wordlevel measure impact audio segment aligned word outcome ii paralinguistic evaluate nonlinguistic feature eg prosody background noise affect outcome perturbedwe validate approach explaining two stateoftheart slu model two task english italian test plausibility human subject rating result show explanation correctly represent model inner working plausible human
keystroke dynamic extensively used psycholinguistic writing research gain insight cognitive processing keystroke log contain actual signal used learn better natural language processing model postulate keystroke dynamic contain information syntactic structure inform shallow syntactic parsing test hypothesis explore label derived keystroke log auxiliary task multitask bidirectional long shortterm memory bilstm result show promising result two shallow syntactic parsing task chunking ccg supertagging model simple advantage data come distinct source produce model significantly better model trained text annotation alone
naturallanguage prompt recently used coax pretrained language model performing ai task using fillintheblank paradigm petroni et al fewshot extrapolation paradigm brown et al example language model retain factual knowledge training corpus extracted asking fill blank sentential prompt however prompt come explore idea learning prompt gradient descenteither finetuning prompt taken previous work starting random initialization prompt consist soft word ie continuous vector necessarily word type embeddings language model furthermore task optimize mixture prompt learning prompt effective ensemble across multiple english lm task approach hugely outperforms previous method showing implicit factual knowledge language model previously underestimated moreover knowledge cheap elicit random initialization nearly good informed initialization
research work center enable humanlike interaction generating contextual emotional proactive response taskoriented chitchat spoken dialogue system sdss natural lan guage generation nlg indispensable component sdss directly affect user interactive expe rience entire dialogue system addition nlg also interested natural language understanding nlu play crucial role sdss prerequisite dialogue system generate reply
present approach online handling outofvocabulary oov term urduenglish mt since urdu morphologically richer english expect large portion oov term urdu morphological variation irrelevant english describe approach automatically learn englishirrelevant targetirrelevant urdu source morphological variation rule standard phrase table rule learned unsupervised lightly supervised manner exploiting redundancy urdu collocation english translation use rule hypothesize invocabulary alternative oov term result show reduce oov rate standard baseline average average relative decrease also increase bleu score absolute relative standard test set manual error analysis show handled oov case produce acceptable translation context
paper focus identifying interactive argument pair two post opposite stance certain topic considering opinion exchanged different perspective discussing topic study discrete representation argument capture varying aspect argumentation language eg debate focus participant behavior moreover utilize hierarchical structure model postwise information incorporating contextual knowledge experimental result largescale dataset collected cmv show proposed framework significantly outperform competitive baseline analysis reveal model yield superior performance prove usefulness learned representation
describe system submitted jack ryder team semeval task hyperpartisan news detection task asked participant predict whether given article hyperpartisan ie extremeleft extremeright proposed approach based bert finetuning ranked th team distantly supervised dataset article hyperpartisannonhyperpartisan news outlet considered hyperpartisannonhyperpartisan manually annotated test dataset human annotator doublechecked label ranked th team
analyzing large hierarchical table multilevel header present challenge due complex structure implicit semantics calculation relationship recent advancement large language model llm shown promise flat table analysis application hierarchical table constrained reliance manually curated exemplar model token capacity limitation addressing challenge introduce novel codeaugmented llmbased framework e zeroshot hierarchical table question answering approach encompasses selfexplaining table hierarchical structure code generation extract relevant information apply operation external code execution prevent hallucination leveraging llm reasoning final answer derivation empirical result indicate method based gpt outperforms stateoftheart finetuning method exact match improvement furthermore present f adaptive algorithm designed tokenlimited scenario effectively condensing large table maintaining useful information experiment prove efficiency enabling processing large table even model limited context length code available httpsgithubcomzzhsjtuehierarchicaltableanalysis
paper describes powla generic formalism represent linguistic corpus mean rdf owldl unlike earlier approach direction powla tied specific selection annotation layer rather designed support kind textoriented annotation powla inherits generic character underlying data model paula dipper chiarcos et al based early sketch iso tcsc linguistic annotation framework ide romary opposed existing standoff xml linearizations generic data model us rdf representation formalism owldl validation paper discusses advantage approach particular respect interoperability queriability illustrated masc corpus open multilayer corpus american english ide et al
standard finetuning large pretrained language model plms downstream task requires updating hundred million billion parameter storing large copy plm weight every task resulting increased cost storing sharing serving model address parameterefficient finetuning peft technique introduced small trainable component injected plm updated finetuning propose adamix general peft method tune mixture adaptation module given underlying peft method choice introduced transformer layer keeping plm weight frozen instance adamix leverage mixture adapter like houlsby mixture low rank decomposition matrix like lora improve downstream task performance corresponding peft method fully supervised fewshot nlu nlg task design adamix match computational cost number tunable parameter underlying peft method tuning plm parameter show adamix outperforms sota parameterefficient finetuning full model finetuning nlu nlg task
paper present approach improve accuracy strong transitionbased dependency parser exploiting dependency language model extracted large parsed corpus integrated small number feature based dependency language model parser demonstrate effectiveness proposed approach evaluate parser standard english chinese data base parser could achieve competitive accuracy score enhanced parser achieved stateoftheart accuracy chinese data competitive result english data gained large absolute improvement one point uas chinese point english
fundamental natural language processing task one core knowledge extraction technique named entity recognition ner widely used extract information text downstream task nested ner branch ner named entity ne nested however previous study nested ner usually apply linear structure model nested ne actually accommodated hierarchical structure thus order address mismatch work model full nested ne sentence holistic structure propose holistic structure parsing algorithm disclose entire ne besides research applying corpuslevel information ner currently make loss information introduce pointwise mutual information pmi frequency feature corpusaware statistic even better performance holistic modeling sentencelevel corpuslevel experiment show model yield promising result widelyused benchmark approach even achieve stateoftheart empirical study show proposed corpusaware feature substantially improve ner domain adaptation demonstrates surprising advantage proposed corpuslevel holistic structure modeling
many language large generallanguage corpus available web institution could little shake head dismay corpusbuilding long slow expensive advent web highly automated thereby fast inexpensive developed corpus factory build large corpus paper describe method use worked various problem solved eight language dutch hindi indonesian norwegian swedish telugu thai vietnamese use bootcat method take set seed word language wikipedia several hundred time randomly select three four seed word send query google yahoo bing return search hit page gather page google yahoo point save text form corpus clean remove navigation bar advertisement etc remove duplicate tokenise tool available lemmatise partofspeech tag load corpus query tool sketch engine corpus developed available use sketch engine corpus query tool
paper propose sequencebased pretraining method enhance procedural understanding natural language processing procedural text containing sequential instruction accomplish task difficult understand due changing attribute entity context focus recipe commonly represented ordered instruction use order supervision signal work one first compare several orderassupervision transformer pretraining method including permutation classification embedding regression skipclip show method give improved result compared baseline sota llm two downstream entitytracking datasets npncooking dataset recipe domain propara dataset open domain proposed method address nontrivial entity tracking task requires prediction entity state across procedure step requires understanding order step method show improvement best baseline npncooking propara datasets respectively across metric
last year increasing availability large corpus spanning several time period opened new opportunity diachronic analysis language type analysis bring light linguistic phenomenon related shift word meaning time also used study impact societal cultural trend language change paper introduces new resource performing diachronic analysis named entity built upon wikipedia page revision resource enables analysis time change relation entity concept surface form word context surrounding entity surface form analysing whole history wikipedia internal link provide useful use case prove impact resource diachronic study delineate possible future usage
patient chronic condition like heart failure likely rehospitalized one step towards avoiding rehospitalization devise strategy motivating patient take care health paper perform quantitative analysis patient narrative experience heart failure explore different topic patient talk compare two different group patient unable take charge illness make effort improve health use finding analysis refine personalize summary hospitalization system automatically generates
due exponential increasing reach social medium essential focus negative aspect potentially divide society incite people violence paper present system description work shared task commaicon classify aggressive sentence sentence genderbiased communal biased three could primary reason cause significant problem society approach utilizes different pretrained model attention mean pooling method able get rank instance f score bengali rank instance f score multilingual set rank instance f score meitei rank instance f score hindi source code pretrained model work found
crosslingual pretraining method mask predict token multilingual text generalize diverse multilingual information however due lack sufficient aligned multilingual resource pretraining process method may fully explore multilingual correlation masked token resulting limitation multilingual information interaction paper propose lifelong multilingual multigranularity semantic alignment approach continuously extract massive aligned linguistic unit noisy data via maximum cooccurrence probability algorithm approach release version multilingual multigranularity semantic alignment resource supporting seven language namely english czech german russian romanian hindi turkish finally propose use resource improve translation performance wmt benchmark twelve direction experimental result show average bleu improvement translation benchmark analysis discussion also demonstrate superiority potential proposed approach resource used work publicly available
paper introduce unifiedm generalpurpose misinformation model jointly model multiple domain misinformation single unified setup model trained handle four task detecting news bias clickbait fake news verifying rumor grouping task together unifiedm learns richer representation misinformation lead stateoftheart comparable performance across task furthermore demonstrate unifiedms learned representation helpful fewshot learning unseen misinformation tasksdatasets model generalizability unseen event
discus ongoing work automating multilingual digital helpdesk service available via text messaging pregnant breastfeeding mother south africa anonymized dataset consists short informal question often lowresource language unreliable language label spelling error codemixing well template answer inconsistency explore crosslingual word embeddings train parametric nonparametric model k sample answer selection set template preliminary result indicate lstms trained endtoend perform best test accuracy recall demonstrate accelerate response time several order magnitude
paper present set experiment area morphological modelling prediction test whether morphological segmentation compete statistical segmentation task language modelling predictive text entry two underresourced indigenous language kiche chukchi use different segmentation method statistical morphological make datasets used train model different type singleway segmented trained using data one segmenter twoway segmented trained using concatenated data two segmenters finetuned trained two datasets different segmenters compute word character level perplexity find singleway segmented model trained morphologically segmented data show highest performance finally evaluate language model task predictive text entry using gold standard data measure average number click per character keystroke saving rate find model trained morphologically segmented data show better score although substantial room improvement last propose usage morphological segmentation order improve enduser experience using predictive text plan testing assumption enduser evaluation
time fly close five half year since became editorinchief computational linguistics july editorial describe change introduced journal highlight achievement challenge journal
nlp community generally aware resource disparity among language lack research quantifies extent type disparity prior survey estimating availability resource based number datasets misleading dataset quality varies many datasets automatically induced translated english data provide comprehensive picture language resource examine characteristic publicly available nlp datasets manually annotate created including input text label source tool used build study task address motivation creation quantifying qualitative nlp resource gap across language discus improve data collection lowresource language survey languageproficient nlp researcher crowd worker per language finding estimated availability correlate dataset availability crowdsourcing experiment identify strategy collecting highquality multilingual data mechanical turk platform conclude making macro microlevel suggestion nlp community individual researcher future multilingual data development
present procedure implemented carry system oriented evaluation syntaxbased word aligner alibi crosscorpus evaluation still relatively rare nlp take approach regarding crosscorpus evaluation part system oriented evaluation hypothesis granularity alignment level syntactic correspondence depend corpus type objective assess impact alignment quality test system three englishfrench parallel corpus evaluation procedure defined accordance stateoftheart word alignment evaluation principle include corpus creation reference set containing multiple annotation data assessment interannotator agreement rate analysis reference set obtained show alignment performance varies across corpus according multiple reference annotation produced motivate choice preserving reference annotation without solving disagreement annotator
paper challenge assumption political ideology inherently built text presenting investigation impact experiential factor annotator perception political ideology construct annotated corpus u political discussion addition ideology label text annotator provide information political affiliation exposure political news familiarity source domain discussion reddit investigate variability ideology judgment across annotator finding evidence experiential factor may influence consistency political ideology perceived finally present evidence understanding human perceive interpret ideology text remains challenging task stateoftheart language model pointing towards potential issue modeling user experience may require contextual knowledge
paper discusses issue semantic annotation quantification phenomenon general particular markup language quantml proposed form part iso standard annotation scheme quantification natural language data quantml annotation claimed compositional semantic interpretation formal specification quantml official iso documentation provide sufficient detail judge paper aim fill gap
motivated need intelligent question answering qa system holy quran success first quran question answering shared task quran qa osact organized second version arabicnlp quran qa composed two subtasks passage retrieval pr task machine reading comprehension mrc task main aim shared task encourage stateoftheart research arabic pr mrc holy quran shared task attracted team submit run pr task team submit run mrc task paper present overview task provide outline approach employed participating team subtasks
parameterefficient tuning petuning method deemed many new paradigm using pretrained language model plms tuning fraction amount parameter comparing full model finetuning petuning method claim achieved performance par even better finetuning work take step back reexamine petuning method conducting first comprehensive investigation training evaluation found problematic validation testing practice current study accompanied instability nature petuning method led unreliable conclusion compared truly fair evaluation protocol petuning yield consistently competitive performance finetuning remains bestperforming method medium highresource setting delve deeper cause instability observed number trainable parameter training iteration two main factor reducing trainable parameter prolonging training iteration may lead higher stability petuning method
paper present definition implementation hunter event interface hei system hei system system event annotation temporal reasoning natural language text medium mainly oriented text historical cultural content available web work assume event defined various component action participant location occurrence interval hei system independent service locates annotates various component successively associate specific event objective work build system integrating service identification event discovery connection evaluation consistency believe interface useful develop application use notion story integrate data digital cultural archive build system fruition field hei system partially developed within trastest project
curriculum learning machine training strategy feed training instance model easy hard proven facilitate dialogue generation task meanwhile knowledge distillation knowledge transformation methodology among teacher student network yield significant performance boost student model hence paper introduce combination curriculum learning knowledge distillation efficient dialogue generation model curriculum learning help knowledge distillation data model aspect start data aspect cluster training case according complexity calculated various type feature sentence length coherence dialog pair furthermore employ adversarial training strategy identify complexity case model level intuition discriminator tell generated response teacher student case difficult student model adapted yet finally use selfpaced learning extension curriculum learning assign weight distillation conclusion arrange hierarchical curriculum based two aspect student model guidance teacher model experimental result demonstrate method achieve improvement compared competitive baseline
paper show disambiguation discourse connective improve automatic translation preserving overall performance statistical mt measured bleu stateoftheart automatic classifier rhetorical relation used prior mt label discourse connective signal relation label used mt two way augmenting factored translation model using probability distribution label order train tune smt improvement translation quality demonstrated using new semiautomated metric discourse connective englishfrench wmt data bleu score remain comparable nondiscourseaware system due low frequency discourse connective
paper describes method submitted germeval shared task identifying toxic engaging factclaiming comment social medium text risch et al explore simple strategy semiautomatic generation rulebased system high precision low recall use achieve slight overall improvement standard bertbased classifier
big shift mt rd region many largescale project conducted past ten year multilingual machine translation mmt project one significant rd project increased great number nlp related researcher research activity seen increasing number research institute recent year learned lot collaboration research across language still hope rigorous step future mt rd region though mt system still far extreme goal perfect translation observed mt system actually used support information retrieval internet
robustness counterfactual bias usually evaluated test dataset however evaluation robust test dataset perturbed slightly evaluation result keep paper propose double perturbation framework uncover model weakness beyond test dataset framework first perturbs test dataset construct abundant natural sentence similar test data diagnosis prediction change regarding singleword substitution apply framework study two perturbationbased approach used analyze model robustness counterfactual bias english robustness focus synonym substitution identify vulnerable example prediction altered proposed attack attains high success rate finding vulnerable example original robustly trained cnns transformer counterfactual bias focus substituting demographic token eg gender race measure shift expected prediction among constructed sentence method able reveal hidden model bias directly shown test dataset code available urlhttpsgithubcomchongznlpsecondorderattack
many year istituto di teoria e tecniche dellinformazione giuridica ittig consiglio nazionale delle ricerche studied evolution legal language creating database documentation digital retrieval law text ittig attending document legal language information technology order provide wide access possible finding institute recently created online digital database includes full text important italian law code constitution th th century ittig also process preparing another database made context original th th century legal source
question answering qa one main fouses natural language proessing nlp researh however arabi question answering still within reah hallenges arabi language lak resoures made diffiult provide powerful arabi qa system high auray low auray may aepted general purpose system ritial field suh religious affair therefore need speialized aurate system target ritial field paper propose transformerbased qa system using mt language model lm finetuned model qurani reading omprehension dataset qrd whih provided ontext quran qa shared task qrd dataset onsists questionpassage pair input orresponding adequate answer provided expert annotator output evaluation result dataset show best model ahieve f sore dev set test set disuss result hallenges propose potential solution possible improvement soure ode available repository
translating natural language utterance executable query helpful technique making vast amount data stored relational database accessible wider range nontechsavvy end user prior work area largely focused textual input linguistically correct semantically unambiguous however realworld user query often succinct colloquial noisy resembling input search engine work introduce data augmentation technique samplingbased contentaware bert model colloql achieve robust texttosql modeling natural language search nls question due lack evaluation data curate new dataset nls question demonstrate efficacy approach colloqls superior performance extends wellformed text achieving logical execution accuracy wikisql dataset making best knowledge highest performing model use execution guided decoding
current model document summarization disregard user preference desired length style entity user might interested much document user already read present neural summarization model simple effective mechanism enable user specify high level attribute order control shape final summary better suit need user input system produce high quality summary follow user preference without user input set control variable automatically full text cnndailymail dataset outperform state art abstractive system term frouge v frouge human evaluation
despite significant progress achieved text summarization factual inconsistency generated summary still severely limit practical application among key factor ensure factual consistency reliable automatic evaluation metric first crucial one however existing metric either neglect intrinsic cause factual inconsistency rely auxiliary task leading unsatisfied correlation human judgment increasing inconvenience usage practice light challenge propose novel metric evaluate factual consistency text summarization via counterfactual estimation formulates causal relationship among source document generated summary language prior remove effect language prior cause factual inconsistency total causal effect generated summary provides simple yet effective way evaluate consistency without relying auxiliary task conduct series experiment three public abstractive text summarization datasets demonstrate advantage proposed metric improving correlation human judgment convenience usage source code available urlhttpsgithubcomxieyxclackfactualcoco
machine reading comprehension help machine learn utilize human knowledge written form text existing approach made significant progress comparable humanlevel performance still limited understanding paragraph failing properly comprehend lengthy document paper propose novel deep neural network architecture handle longrange dependency rc task detail method two novel aspect advanced memoryaugmented architecture expanded gated recurrent unit dense connection mitigate potential information distortion occurring memory proposed architecture widely applicable model performed extensive experiment wellknown benchmark datasets triviaqa quasart squad experimental result demonstrate proposed method outperforms existing method especially lengthy document
describe structure creation sagewrite corpus manually annotated corpus created support automatic language generation automatic quality assessment academic article corpus currently contains annotation excerpt taken various scientific article excerpt corpus contains draft version excerpt ii annotation reflect stylistic linguistics merit excerpt whether text clearly structured sagewrite corpus first corpus finetuning textgeneration algorithm specifically address academic writing
introduce dictionary containing normalized form common word various swiss german dialect high german swiss german predominantly spoken language significant variation written form even speaker dialect alleviate uncertainty associated diversity complement pair swiss german high german word swiss german phonetic transcription sampa dictionary becomes thus first resource combine largescale spontaneous translation phonetic transcription moreover control regional distribution insure equal representation major swiss dialect coupling phonetic written swiss german form powerful show sufficient train transformerbased phoneme grapheme model generates credible novel swiss german writing addition show inverse mapping grapheme phoneme modeled transformer trained novel dictionary generation pronunciation previously unknown word key training extensible automated speech recognition asr system key beneficiary dictionary
article present latest dissemination activity technical development carried international standard language resource number islrn service also recall main principle submission process provider obtain digit islrn identifier march language resource allocated islrn number elras ldcs catalogued language resource also one important organisation like joint research centre jrc resource management agency rma expressed strong support initiative research field assigning unique identification number important also referring language resource object textitper se like publication become obvious requirement islrn could also become important parameter considered compute language resource impact factor lrif order recognize merit producer language resource integrating islrn number lroriented bibliographical reference thus part objective idea make use bibtex entry would take account language resource item including islrnthe islrn requested field within lrec submission expect several lr allocated islrn number conference date expansion number aim spreadlyused lr citation instrument within work referring lr
automatic extraction relation interaction biological entity scientific literature remains extremely challenging problem biomedical information extraction natural language processing general one reason slow progress relative scarcity standardized publicly available benchmark paper introduce biorelex new dataset fully annotated sentence biomedical literature capture textitbinding interaction protein andor biomolecules foster reproducible research interaction extraction task define precise transparent evaluation process tool error analysis significance test finally conduct extensive experiment evaluate several baseline including sciie recently introduced neural multitask architecture demonstrated stateoftheart performance several task
imagecaption pretraining quite successfully used downstream vision task like zeroshot image classification object detection however imagecaption pretraining still hard problem requires multiple concept noun caption aligned several object image tackle problem go root best learner child take inspiration cognitive science study dealing childrens language learning propose curriculum learning framework learning begin easytoalign image caption pair containing one concept per caption difficulty progressively increased new phase adding one concept per caption correspondingly knowledge acquired learning phase utilized subsequent phase effectively constrain learning problem aligning one new conceptobject pair phase show learning strategy improves vanilla imagecaption training various setting pretraining scratch using pretrained image orand pretrained text encoder low data regime etc
recent year pretrained language model demonstrated exceptional performance across various natural language processing nlp task one fundamental component model selfattention mechanism played vital role capturing meaningful relationship token however question still remains whether injecting lexical feature selfattention mechanism enhance understanding performance language model paper present novel approach injecting semanticpolarity knowledge referred sentiment lexical attention directly selfattention mechanism transformerbased model primary goal improve performance sentiment classification task approach involves consistently injecting sentiment lexical attention derived lexicon corpus attention score throughout training process empirically evaluate method nsmc sentiment classification benchmark showcasing significant performance improvement achieving stateoftheart result furthermore approach demonstrates robustness effectiveness outofdomain task indicating potential broad applicability additionally analyze impact sentiment lexical attention view cl token attention distribution method offer fresh perspective synergizing lexical feature attention score thereby encouraging investigation realm knowledge injection utilizing lexical feature
text matching fundamental research problem natural language understanding interactionbased approach treat text pair single sequence encode cross encoders representationbased model encode text pair independently siamese dual encoders interactionbased model require dense computation thus impractical realworld application representationbased model become mainstream paradigm efficient text matching however model suffer severe performance degradation due lack interaction pair text remedy propose virtual interaction mechanism virt improving representationbased text matching maintaining efficiency particular introduce interactive knowledge distillation module applied training enables deep interaction text effectively transferring knowledge interactionbased model light interaction strategy designed fully leverage learned interactive knowledge experimental result six text matching benchmark demonstrate superior performance method several stateoftheart representationbased model show virt integrated existing method plugins lift performance
paper report detailed quantitative analysis distributional language data italian czech highlighting relative contribution number distributed grammatical factor sentencebased identification subject direct object work based maximum entropy model stochastic resolution grammatical conflicting constraint demonstrably capable putting explanatory theoretical account challenging test extensive usagebased empirical verification
paper investigates problem automatically annotating resource np coreference information using parallel corpus englishromanian order transfer word alignment coreference chain english part romanian part corpus result show detect romanian referential expression coreference chain fmeasure thus using method preprocessing step followed manual correction part annotation effort creating large romanian corpus coreference information worthwhile
recent year seen surge propagation online hate speech social medium platform according multitude source european council hate speech lead act violence conflict broader scale led creased awareness government company scientific community although field relatively new considerable advancement field result collective effort despite increasingly better result research focus popular language ie english german arabic whereas less popular language bulgarian balkan language neglected aggregated realworld dataset bulgarian online forum manually annotated sentence described category racism sexism rudeness profanity developed evaluated various classifier dataset found support vector machine linear kernel trained characterlevel tfidf feature best model work seen another piece puzzle building strong foundation future work hate speech classification bulgarian
work propose method incorporating questionanswering qa signal summarization model method identifies salient noun phrase np input document automatically generating whquestions answered np automatically determining whether question answered gold summary qabased signal incorporated twostage summarization model first mark salient np input document using classification model conditionally generates summary experiment demonstrate model trained using qabased supervision generate higherquality summary baseline method identifying salient span benchmark summarization datasets show content generated summary controlled based np marked input document finally propose method augmenting training data gold summary consistent marked input span used training show result model learn better exclude unmarked document content
taskoriented dialog tod system advanced structured db system aim collect relevant knowledge answering user question also progressed despite advancement method face challenge dealing subjective question user overcome dstc released subjectiveknowledgebased tod sktod dataset benchmark paper introduces framework effectively solves sktod task leveraging large language model llm demonstrate proficient use llm subtask including adaptersbased method knowledgegrounded data augmentation proposed method utilize llm efficient tool outperform baseline performance approach directly use llm onestep subtask solver showing superior taskspecific optimization
growing privacy concern surrounding natural language understanding nlu application need train highquality model safeguarding data privacy reached unprecedented importance federated learning fl offer promising approach collaborative model training exchanging model gradient however many study show eavesdropper fl could develop sophisticated data reconstruction attack dra accurately reconstruct client data shared gradient regrettably current dra method federated nlu mostly conducted public datasets lacking comprehensive evaluation realworld privacy datasets address limitation paper present pioneering study reexamines performance dra method well corresponding defense method specifically introduce novel realworld privacy dataset called fedattack lead significant discovery existing dra method usually fail accurately recover original text realworld privacy data detail token within recovery sentence disordered intertwined token sentence training batch moreover experiment demonstrate performance dra also influenced different language domain discovering finding work lay solid foundation research development practical dra method corresponding defense
voice enabled human computer interface hci integrate automatic speech recognition texttospeech synthesis natural language understanding become commodity introduced immersion smart phone gadget daily life smart assistant able respond simple query similar textbased questionanswering system perform simple task call number reject call etc help organizing appointment paper introduce newly created process automation platform enables user control application home appliance query system information using natural voice interface offer overview technology enabled u construct system present different usage scenario home office environment
pcbertcnnff
paper present nttnaist smt system englishgerman germanenglish mt task iwslt evaluation campaign system based generalized minimum bayes risk system combination three smt system foresttostring hierarchical phrasebased phrasebased preordering individual smt system include data selection domain adaptation rescoring using recurrent neural net language model interpolated language model compound word splitting germanenglish
work propose novel annotation scheme factor hate speech five separate discursive category evaluate scheme construct corpus twitter post containing hateful expression directed jew annotate sample dataset tweet present statistical analysis annotated dataset well discus annotation example conclude discussing promising direction future work
active learning play important role lowresource setting ie annotated data scarce selecting instance may worthy annotate active learning approach machine translation assume existence pool sentence source language rely human annotator provide translation postedits still costly article apply active learning realworld humanintheloop scenario assume source sentence may readily available instead arrive stream automatic translation receive feedback form rating instead correctedited translation since humanintheloop might user looking translation able provide one tackle challenge deciding whether incoming pair sourcetranslations worthy query human feedback resort number streambased active learning query strategy moreover know advance query strategy adequate certain language pair set machine translation model propose dynamically combine multiple strategy using prediction expert advice experiment different language pair feedback setting show using active learning allows u converge best machine translation system fewer human interaction furthermore combining multiple strategy using prediction expert advice outperforms several individual active learning strategy even fewer interaction particularly partial feedback setting
recent pretrained language model plms achieve promising result existing abstractive summarization datasets however existing summarization benchmark overlap time standard pretraining corpus finetuning datasets hence strong performance plms may rely parametric knowledge memorized pretraining finetuning moreover knowledge memorized plms may quickly become outdated affect generalization performance plms future data work propose temposum novel benchmark contains data sample understand temporal generalization ability abstractive summarization model extensive human evaluation show parametric knowledge stored summarization model significantly affect faithfulness generated summary future data moreover existing faithfulness enhancement method reliably improve faithfulness summarization model future data finally discus several recommendation research community evaluate improve temporal generalization capability text summarization model
understanding interpersonal relationship helpful many context system seek assist human task using textual information eg case note speech transcript post book input specifically system first extract qualitative quantitative information element call signal interaction among person aggregate provide condensed view relationship enables user explore facet resulting social multigraph visual interface
develop model classify desirable evidence desirable reasoning revision student argumentative writing explore two way improve classifier performance using essay context revision using feedback student received revision perform intrinsic extrinsic evaluation model report qualitative analysis result show model using feedback information improves baseline model model utilizing context either alone feedback successful identifying desirable revision
crossdomain relation extraction aim transfer knowledge source domain different target domain address lowresource challenge however semantic gap caused data bias domain major challenge especially fewshot scenario previous work mainly focused transferring knowledge domain shared feature representation without analyzing impact factor may produce data bias based characteristic domain work take causal perspective proposes new framework causalgf constructing unified structural causal model estimating causal effect factor syntactic structure label distributionand entity outcome causalgf calculates causal effect among factor adjusts dynamically based domain characteristic enabling adaptive gap filling experiment show approach better fill domain gap yielding significantly better result crossdomain fewshot relation extraction task
keyword keyphrase extraction identify word phrase presenting main topic document paper proposes attentionrank hybrid attention model identify keyphrases document unsupervised manner attentionrank calculates selfattention crossattention using pretrained language model selfattention designed determine importance candidate within context sentence crossattention calculated identify semantic relevance candidate sentence within document evaluate attentionrank three publicly available datasets seven baseline result show attentionrank effective robust unsupervised keyphrase extraction model long short document source code available github
regular polysemy extensively investigated lexical semantics phenomenon little studied distributional semantics propose model regular polysemy detection based sense vector allows work directly sens semantic vector space method able detect polysemous word regular sense alternation given example word two automatically induced sens represent one polysemy pattern animal food method work equally well noun verb adjective achieves average recall average precision ten different polysemy pattern
training classification model clinical speech timesaving effective solution many healthcare challenge screening alzheimers disease phone one primary limiting factor success artificial intelligence ai solution amount relevant data available clinical data expensive collect sufficient largescale machine learning neural method often shareable institution due data protection law increasing demand ai health system generating synthetic clinical data maintains nuance underlying patient pathology next pressing task previous work shown automated evaluation clinical speech task via automatic speech recognition asr comparable manually annotated result diagnostic scenario even though asr system produce error transcription process work propose generate synthetic clinical data simulating asr deletion error transcript produce additional data compare synthetic data real data traditional machine learning method test feasibility proposed method using dataset cognitively impaired control dutch speaker ten additional data point synthetically generated subject increasing training size training point find consistent comparable performance model trained synthetic data auc real data auc variety traditional machine learning scenario additionally linear model able distinguish real synthetic data
text summarization aim extract essential information piece text transform text concise version existing unsupervised abstractive summarization model leverage recurrent neural network framework recently proposed transformer exhibit much capability moreover previous summarization model ignore abundant unlabeled corpus resource available pretraining order address issue propose ted transformerbased unsupervised abstractive summarization system pretraining largescale data first leverage lead bias news article pretrain model million unlabeled corpus next finetune ted target domain theme modeling denoising autoencoder enhance quality generated summary notably ted outperforms unsupervised abstractive baseline nyt cnndm english gigaword datasets various document style analysis show summary generated ted highly abstractive component objective function ted highly effective
visual dialog task guesswhat two player maintain dialog order identify secret object image computationally modeled using question generation module guesser module questioner role answering model oracle answer generated question raise question whats risk imperfect oracle model present work progress study impact different answering model human generated question guesswhat show access better quality answer direct impact guessing task human dialog argue better answer could help train better question generation model
introduce chrentranslate online machine translation demonstration system translation english endangered language cherokee support statistical neural translation model well provides quality estimation inform user reliability two user feedback interface expert common user respectively example input collect human translation monolingual data word alignment visualization relevant term cherokee english dictionary quantitative evaluation demonstrates backbone translation model achieve stateoftheart translation performance quality estimation well correlate bleu human judgment analyzing piece expert feedback find nmt preferable copy less smt general current model translate fragment source sentence make major mistake add expertcorrected parallel text training set retrain model equal slightly better performance observed demonstrates indicates potential humanintheloop learning
neural architecture search na method automatically learn entire neural model individual neural cell architecture recently achieved competitive stateoftheart sota performance variety natural language processing computer vision task including language modeling natural language inference image classification work explore applicability sota na algorithm efficient neural architecture search enas pham et al two sentence pair task paraphrase detection semantic textual similarity use enas perform microlevel search learn taskoptimized rnn cell architecture dropin replacement lstm explore effectiveness enas experiment three datasets mrpc sick stsb two different model esim bilstmmax two set embeddings glove bert contrast prior work applying enas nlp task result mixed find enas architecture sometimes always outperform lstms perform similarly random architecture search
satirical news considered entertainment potentially deceptive harmful despite embedded genre article everyone recognize satirical cue therefore believe news true news observe satirical cue often reflected certain paragraph rather whole document existing work consider documentlevel feature detect satire could limited consider paragraphlevel linguistic feature unveil satire incorporating neural network attention mechanism investigate difference paragraphlevel feature documentlevel feature analyze large satirical news dataset evaluation show proposed model detects satirical news effectively reveals feature important level
writing job vacancy repetitive expensive task human research focus automatically generating benefit section vacancy redacted job attribute using mt multilingual version stateoftheart transformer trained general domain generate text multiple language transformer accurate generating coherent text sometimes incorrect including structured data input generated text including input correctly crucial vacancy text generation otherwise candidate may get misled evaluate model includes input developed domainspecific metric input generation accuracy necessary relation generation preexisting evaluation metric datatotext generation us string matching suitable dataset due binary field help new evaluation method able measure well input included generated text separately different type input binary categorical numeric offering another contribution field additionally also evaluated accurate mt model generates text requested language result show mt accurate generating text correct language including seen categorical input binary value correctly generated text however mt performed worse generating text unseen city name working numeric input furthermore found generating additional synthetic training data sample numeric input increase input generation accuracy however work number integer cover small range
paper present system developed sartipisedighin team semeval task shared task focused multilingual complex named entity recognition ner multiconer ii goal task identify classify complex named entity ne text across multiple language tackle multiconer ii task leveraged pretrained language model plms finetuned language included dataset addition also applied data augmentation technique increase amount training data available model specifically searched relevant ne already existed training data within wikipedia added new instance entity training corpus team achieved overall f score english track multilingual track across track shared task submitted
introduce mtvr largescale multilingual video moment retrieval dataset containing k english chinese query k tv show video clip dataset collected extending popular tvr dataset english paired chinese query subtitle compared existing moment retrieval datasets mtvr multilingual larger come diverse annotation propose mxml multilingual moment retrieval model learns operates data language via encoder parameter sharing language neighborhood constraint demonstrate effectiveness mxml newly collected mtvr dataset mxml outperforms strong monolingual baseline using fewer parameter addition also provide detailed dataset analysis model ablation data code publicly available urlhttpsgithubcomjayleicnmtvretrieval
defacto standard decoding method semantic parsing recent year autoregressively decode abstract syntax tree target program using topdown depthfirst traversal work propose alternative approach semiautoregressive bottomup parser smbop construct decoding step topk subtrees height mboxleq parser enjoys several benefit compared topdown autoregressive parsing efficiency perspective bottomup parsing allows decode subtrees certain height parallel leading logarithmic runtime complexity rather linear modeling perspective bottomup parser learns representation meaningful semantic subprogram step rather semanticallyvacuous partial tree apply smbop spider challenging zeroshot semantic parsing benchmark show smbop lead x speedup decoding time textasciitildex speedup training time compared semantic parser us autoregressive decoding smbop obtains denotation accuracy spider establishing new stateoftheart exact match comparable exact match autoregressive ratsqlgrappa
stereotypical language express widelyheld belief different social category many stereotype overtly negative others may appear positive surface still lead negative consequence work present computational approach interpreting stereotype text stereotype content model scm comprehensive causal theory social psychology scm proposes stereotype understood along two primary dimension warmth competence present method defining warmth competence ax semantic embedding space show four quadrant defined subspace accurately represent warmth competence concept according annotated lexicon apply computational scm model textual stereotype data show compare favourably surveybased study psychological literature furthermore explore various strategy counter stereotypical belief antistereotypes known countering stereotype antistereotypical example one effective way reduce biased thinking yet problem generating antistereotypes previously studied thus better understanding generate realistic effective antistereotypes contribute addressing pressing societal concern stereotyping prejudice discrimination
radiology report contain important clinical information patient often tied spatial expression spatial expression trigger mainly used describe positioning radiographic finding medical device respect anatomical structure expression result mental visualization radiologist interpretation varied complex focus work automatically identify spatial expression term three different radiology subdomains propose hybrid deep learningbased nlp method includes generating set candidate spatial trigger exact match known trigger term training data applying domainspecific constraint filter candidate trigger utilizing bertbased classifier predict whether candidate trigger true spatial trigger result promising improvement point average f measure compared standard bertbased sequence labeler
coralbrasil brazilian portuguese spontaneous speech corpus compiled following architecture adopted coralrom resource main goal documentation diaphasic diastratic variation brazilian portuguese diatopic variety represented metropolitan area belo horizonte capital city mina gerais even though primary goal nice balance achieved term speaker diastratic feature sex age school level corpus entirely dedicated informal spontaneous speech comprises informal speech text word hour recording distributed familyprivate public context lr includes audio file transcript text format texttospeech alignment accessible winpitch pro software coralbrasil also provides transcript partofspeech annotation implemented parser system palavras transcript validated regarding proper application transcription criterion also annotation prosodic boundary quantitative feature coralbrasil comparison informal coralrom reported
language cause effect capture essential component semantics text however causal language also intertwined semantic relation temporal precedence correlation make difficult determine causation primary intended meaning paper present new version corpus exhaustively annotated expression causal language also seven semantic relation frequently copresent causation new corpus show high interannotator agreement yield insight linguistic expression causation process annotating copresent semantic relation
extracting dense representation term phrase task great importance knowledge discovery platform targeting highlytechnical field dense representation used feature downstream component multiple application ranging ranking result search summarization common approach create dense representation include training domainspecific embeddings selfsupervised setup using sentence encoder model trained similarity task contrast static embeddings sentence encoders suffer outofvocabulary oov problem impose significant computational cost paper propose fully unsupervised approach text encoding consists training small characterbased model objective reconstructing large pretrained embedding matrix model trained approach match quality sentence encoders technical domain time smaller time faster even highend gpus
clinical knowledge graph lack meaningful diagnostic relation eg comorbidities signsymptoms limiting ability represent realworld diagnostic process previous method biomedical relation extraction focused concept relation genedisease diseasedrug largely ignored clinical process thesis leverage clinical reasoning ontology propose method extract relation physicianfacing pointofcare reference wiki consumer health resource text given lack data labeled diagnostic relation also propose new method evaluating correctness extracted triple zeroshot setting describe process intrinsic evaluation new fact triple confidence filtering clinician manual review well extrinsic evaluation form differential diagnosis prediction task
multilingual topic model enable crosslingual task extracting consistent topic multilingual corpus model require parallel comparable training corpus limit ability generalize paper first demystify knowledge transfer mechanism behind multilingual topic model defining alternative equivalent formulation based analysis relax assumption training data required existing model creating model requires dictionary training experiment show new method effectively learns coherent multilingual topic partially fully incomparable corpus limited amount dictionary resource
machine translation becomes critical piece localization industry kind different data monitor machine translation quality localized content build quality analytics framework paper describes process starting collecting daily operation data cleaning data building analytics framework get insight data finally going share build data collecting matrix script clean data run analytics automation script last would share different visualized report box polit standard deviation mean mt touchpoint golden ratio report
paper examine analyze challenge associated developing introducing language technology lowresource language community bring light success failure past work area challenge faced achieved throughout paper take problemfacing approach describe essential factor success technology hinge upon present various aspect manner clarify lay different task involved aid organization looking make impact area take example gondi extremelylow resource indian language reinforce complement discussion
relation extraction important text mining task basis complex advanced task stateoftheart approach syntactic information obtained parsing play crucial role context biomedical previous study report usage various automatic preprocessing technique applied parsing input text however study specify extent technique improve result extent corpus specific well parser specific paper aim addressing issue using various preprocessing technique two syntactic tree kernel based approach two different parser widely used benchmark biomedical corpus proteinprotein interaction ppi extraction task also provide analysis various corpus characteristic verify whether correlation characteristic result obtained analysis corpus characteristic exploited compare ppi corpus
current decoderbased pretrained language model plms successfully demonstrate multilingual capability however unclear model handle multilingualismwe analyze neuronlevel internal behavior multilingual decoderbased plms specifically examining existence neuron fire uniquely language within decoderonly multilingual plmswe analyze six language english german french spanish chinese japanese show languagespecific neuron unique slight overlap textless language neuron mainly distributed model first last layer trend remains consistent across language modelsadditionally tamper less total neuron model inference demonstrate tampering languagespecific neuron drastically change probability target language occurrence text generation
multilingual bert mbert demonstrated considerable crosslingual syntactic ability whereby enables effective zeroshot crosslingual transfer syntactic knowledge transfer successful language well understood lead variation whether fairly reflects difference language work investigate distribution grammatical relation induced mbert context typologically different language demonstrate distance distribution different language highly consistent syntactic difference term linguistic formalism difference learnt via selfsupervision play crucial role zeroshot transfer performance predicted variation morphosyntactic property language result suggest mbert properly encodes language way consistent linguistic diversity provide insight mechanism crosslingual transfer
paper introduce lefff freely available accurate largecoverage morphological syntactic lexicon french used many nlp tool largecoverage parser first describe alexina lexical framework lefff developed well linguistic notion formalism based next describe various source lexical data used building lefff particular semiautomatic lexical development technique conversion merging existing resource finally illustrate coverage precision resource comparing resource assessing impact various nlp tool
definition generation task help language learner providing explanation unfamiliar word task attracted much attention recent year propose novel task simple definition generation sdg help language learner low literacy reader significant challenge task lack learner dictionary many language therefore lack data supervised training explore task propose multitasking framework simpdefiner requires standard dictionary complex definition corpus containing arbitrary simple text disentangle complexity factor text carefully designing parameter sharing scheme two decoder jointly training component framework generate complex simple definition simultaneously demonstrate framework generate relevant simple definition target word automatic manual evaluation english chinese datasets method outperforms baseline model sari score english dataset raise proportion low level hsk level word chinese definition
numerical table widely employed communicate report classification performance machine learning ml model respect set evaluation metric nonexperts domain knowledge required fully understand interpret information presented numerical table paper proposes new natural language generation nlg task neural model trained generate textual explanation analytically describing classification performance ml model based metric score reported table presenting generated text along numerical table allow better understanding classification performance ml model constructed dataset comprising numerical table paired corresponding textual explanation written expert facilitate nlg task experiment dataset conducted finetuning pretrained language model bart generate analytical textual explanation conditioned information table furthermore propose neural module metric processing unit mpu improve performance baseline term correctly verbalising information corresponding table evaluation analysis conducted indicate exploring pretrained model datatotext generation lead better generalisation performance produce highquality textual explanation
many classification model work poorly short text due data sparsity address issue propose topic memory network short text classification novel topic memory mechanism encode latent topic representation indicative class label different prior work focus extending feature external knowledge pretrained topic model jointly explores topic inference text classification memory network endtoend manner experimental result four benchmark datasets show model outperforms stateoftheart model short text classification meanwhile generates coherent topic
speech recognition active research area advance technology continuously driven development research work however due lack adequate resource certain language sinhala left underutilize technology technique crowdsourcing web scraping several sinhala corpus created made publicly available despite large generic correctness consistency text data remain questionable especially due lack uniformity language used different source web scraped text addressing requires thorough understanding technical linguistic particular pertaining language often leaf issue unattended followed systematic approach derive refined corpus using publicly available corpus sinhala speech recognition particular standardized transcription corpus removing noise text applied correction based sinhala linguistics comparative experiment show promising effect linguistic correction relative reduction worderrorrate
language important marker cultural group large small one aspect language variation community employment highly specialized term unique significance group study high affinity term across wide variety community leveraging rich diversity redditcom provide systematic exploration high affinity term often rapid semantic shift undergo relationship subreddit characteristic across diverse subreddits result show high affinity term effective signal loyal community undergo semantic shift low affinity term partial barrier entry new user conclude reddit robust valuable data source testing theory high affinity term across community
work investigate different approach translate similar language despite low resource limitation work done participation ubc nlp research group wmt similar language translation shared task participated language pair performed various experiment used transformer architecture model used backtranslation one language pair explore bilingual multilingual approach describe preprocessing training translation result model also investigate role mutual intelligibility model performance
recognizing complex ambiguous named entity ne one formidable task nlp domain however diversity linguistic constituent syntactic structure semantic ambiguity well difference traditional ne make challenging identify complex ne address challenge semeval task introduced shared task multiconer focusing complex named entity recognition multilingual setting paper present participation task propose two different approach including bilstmcrf model stackedembedding strategy transformerbased approach proposed method achieved competitive performance among participant method language
time crisis human mind often voracious information forager might immediately apparent one want need people frequently look answer pressing question worst fear context pandemic demonstrated social medium source like erstwhile twitter rich medium datadriven communication expert publichowever lay user must find needle haystack distinguish credible actionable information signal noise work leverage literature crisis communication propose aidriven sensemaking model bridge gap people seek need crisis model learns contrast social medium message concerning expert guidance subjective opinion enables semantic interpretation message characteristic based communicative intent message author provide example tweet collection present hypothetical social medium usage scenario demonstrate efficacy proposed model
paper focus generation case marker free word order language use case marker phrasal clitics marking relationship dependentnoun head generation clitics becomes essential task especially translating fixed word order language syntactic relation identified position dependentnouns address problem missing marker sourceside artificial marker added source improve alignment target counterpart bleu point increase observed baseline different test set englishtourdu
billion public domain document remain trapped hard copy lack accurate digitization modern natural language processing method used index retrieve summarize text conduct computational textual analysis extract information statistical analysis text incorporated language model training given diversity sheer quantity public domain text liberating scale requires optical character recognition ocr accurate extremely cheap deploy sampleefficient customize novel collection language character set existing ocr engine largely designed smallscale commercial application high resource language often fall short requirement effocr efficientocr novel opensource ocr package meet computational sample efficiency requirement liberating text scale abandoning sequencetosequence architecture typically used ocr take representation learned vision model input learned language model instead effocr model ocr character wordlevel image retrieval problem effocr cheap sample efficient train model need learn character visual appearance used sequence form language model effocr model zoo deployed offtheshelf line code include lightweight model designed mobile phone extremely cheap deploy importantly effocr also allows easy sample efficient customization simple model training interface minimal labeling requirement due sample efficiency illustrate utility effocr cheaply accurately digitizing million historical u newspaper scan evaluating zeroshot performance randomly selected document u national archive accurately digitizing japanese document collection ocr solution failed
research study author profiling large quantity correctly labeled data used train model however reflect reality forensic scenario practical linguistic forensic investigation resource available profile author text usually scarce pay tribute fact implemented semisupervised learning variant k nearest neighbor algorithm us small set labeled data larger amount unlabeled data classify author text gender man v woman describe enriched knn algorithm show use unlabeled instance improves accuracy gender identification model also present feature set facilitates use small number instance reaching accuracy higher instance train model also shown algorithm also performs well using publicly available data
dynamic landscape generative nlp traditional text processing pipeline limit research flexibility reproducibility tailored specific dataset task model combination escalating complexity involving system prompt modelspecific format instruction call shift structured modular customizable solutionaddressing need present unitxt innovative library customizable textual data preparation evaluation tailored generative language model unitxt natively integrates common library like huggingface lmevalharness deconstructs processing flow modular component enabling easy customization sharing practitioner component encompass modelspecific format task prompt many comprehensive dataset processing definition unitxt catalog centralizes component fostering collaboration exploration modern textual data workflow beyond tool unitxt communitydriven platform empowering user build share advance pipeline collaboratively join unitxt community httpsgithubcomibmunitxt
paper describes experiment estimating emotion intensity tweet using generalized regressor system system combine various independent feature extractor train general regressors finally combine best performing model create ensemble proposed system stood rd system leaderboard wassa shared task emotion intensity
paper present prophetmt treebased smtdriven controlled language cl authoring postediting tool prophetmt employ sourceside rule translation model provides autosuggestion user accordingly one might say user writing controlled language understood computer prophetmt also allows user easily attach structural information compose content specific rule selected partial translation promptly generated onthefly help structural information experiment conducted englishtochinese show proposed prophetmt system better regularise author writing behaviour also significantly improve translation fluency vital reduce postediting time additionally writing translation process prophetmt provide effective colour scheme improve productivity posteditors explicitly featuring relation source target rule
despite agreement importance detecting outofdistribution ood example little consensus formal definition distribution shift ood example best detect categorize example exhibiting background shift semantic shift find two major approach ood detection calibration density estimation language modeling text distinct behavior type ood data across pair indistribution ood english natural language understanding datasets find density estimation method consistently beat calibration method background shift setting perform worse semantic shift setting addition find method generally fail detect example challenge data indicating example constitute different type ood data overall categorization apply explains many difference two method result call explicit definition ood create better benchmark build detector target type ood data expected test time
everyone make mistake human annotator curating label named entity recognition ner label mistake might hurt model training interfere model comparison study dive deep one widelyadopted ner benchmark datasets conll ner able identify label mistake test sentence significant ratio considering stateoftheart test f score already around therefore manually correct label mistake form cleaner test set reevaluation popular model corrected test set lead accurate assessment compared original test set importantly propose simple yet effective framework crossweigh handle label mistake ner model training specifically partition training data several fold train independent ner model identify potential mistake fold adjusts weight training data accordingly train final ner model extensive experiment demonstrate significant improvement plugging various ner model proposed framework three datasets implementation corrected test set available github repo urlhttpsgithubcomzihanwangkicrossweigh
paper introduce university tsukubas submission iwslt open domain translation task participate chinesejapanese japanesechinese direction direction machine translation system based transformer architecture several technique integrated order boost performance model data filtering largescale noised training model ensemble reranking postprocessing consequently effort achieve bleu score chinesejapanese translation bleu score japanesechinese translation
fewshot named entity recognition ner shown remarkable progress identifying entity lowresource domain however fewshot ner method still struggle outofdomain ood example due reliance manual labeling target domain address limitation recent study enable generalization unseen target domain labeled example using data augmentation technique two important challenge remain first augmentation limited training data resulting minimal overlap generated data ood example second knowledge transfer implicit insufficient severely hindering model generalizability integration knowledge source domain paper propose framework prompt learning typerelated feature pltr address challenge identify useful knowledge source domain enhance knowledge transfer pltr automatically extract entity typerelated feature trf based mutual information criterion bridge gap training ood data pltr generates unique prompt unseen example selecting relevant trf show pltr achieves significant performance improvement indomain crossdomain datasets use pltr facilitates model adaptation increase representation similarity source unseen domain
paper propose rulebased approach extract dependency grammatical function venice italian treebank treebank written text po constituent label consisting utterance token manual corpus annotation expensive timeconsuming decided exploit existing constituencybased treebank derive dependency structure lower effort describing procedure extract head dependent based head percolation table italian introduce rule adopted add grammatical relation label purpose manually relabeled noncanonical argument frequent italian automatically labeled remaining complement argument following syntactic restriction based position constituent wrt parent sibling node final section paper describes evaluation result evaluation carried two step one dependency relation one grammatical role result line similar conversion algorithm carried language precision dependency arc fmeasure main grammatical function scoring except oblique
word embedding model gained lot traction natural language processing community however suffer unintended demographic bias approach evaluate bias rely vector space based metric like word embedding association test weat approach offer great geometric insight unintended bias embedding vector space fail offer interpretable meaning embeddings could cause discrimination downstream nlp application work present transparent framework metric evaluating discrimination across protected group respect word embedding bias metric relative negative sentiment bias rnsb measure fairness word embeddings via relative negative sentiment associated demographic identity term various protected group show framework metric enable useful analysis bias word embeddings
present ongoing norlm initiative support creation use large contextualised language model norwegian principle nordic language including readytouse software environment well experience report data preparation training paper introduces first largescale monolingual language model norwegian based elmo bert framework addition detailing training process present contrastive benchmark result suite nlp task norwegian additional background access data model software please see urlhttpnorlmnlpleu
mechanism underlying human communication investigation decade answer understanding locutors emerges remains incomplete interaction theory suggest development structural alignment speaker allowing construction shared knowledge base common ground paper propose apply metric derived information theory quantify amount information exchanged participant dynamic information exchange provide objective way measure common ground instantiation focus corpus free conversation augmented prosodic segmentation expert annotation thematic episode show free conversation amount information remains globally constant scale conversation varies depending thematic structuring underlining role speaker introducing theme propose original methodology applied uncontrolled material
paper describe textent neural network model learns distributed representation entity document directly knowledge base kb given document kb consisting word entity annotation train model predict entity document describes map document target entity close continuous vector space model trained using large number document extracted wikipedia performance proposed model evaluated using two task namely finegrained entity typing multiclass text classification result demonstrate model achieves stateoftheart performance task code trained representation made available online academic research
work describe submission social medium mining health smmh shared task investigated effectiveness joint training approach task specifically classification extraction normalization adverse drug effect ade mention english tweet approach performed well normalization task achieving average f score less classification extraction f score respectively experiment also showed larger dataset negative result led stronger result smaller balanced dataset even datasets positive example finally also submitted tuned bert model task classification covid tweet containing symptom achieved average f score
automatic story ending generation interesting challenging task natural language generation previous study mainly limited generate coherent reasonable diversified story ending work focus controlling sentiment story ending paper focus generating story ending meet given finegrained sentiment intensity two major challenge task first lack story corpus finegrained sentiment label second difficulty explicitly controlling sentiment intensity generating ending therefore propose generic novel framework consists sentiment analyzer sentimental generator respectively addressing two challenge sentiment analyzer adopts series method acquire sentiment intensity story dataset sentimental generator introduces sentiment intensity decoder via gaussian kernel layer control sentiment output best knowledge first endeavor control finegrained sentiment story ending generation without manually annotating sentiment label experiment show proposed framework generate story ending coherent fluent also able meet given sentiment intensity better
evergrowing number people suffering mental distress motivated significant research initiative towards automated depression estimation despite multidisciplinary nature task approach include medical professional research process thus ignoring vital source domain knowledge paper propose bring domain expert back loop incorporate knowledge within goldstandard daicwoz dataset particular define novel transformerbased architecture analyse performance light expert annotation overall finding demonstrate strong correlation psychological tendency medical professional behavior proposed model additionally provides new stateoftheart result
multilingual named entity recognition ner key intermediate task needed many area nlp paper address wellknown issue data scarcity ner especially relevant moving multilingual scenario go beyond current approach creation multilingual silver data task exploit text wikipedia introduce new methodology based effective combination knowledgebased approach neural model together novel domain adaptation technique produce highquality training corpus ner evaluate datasets extensively standard benchmark ner yielding substantial improvement spanbased fscore point previous stateoftheart system data creation
russian language currently poorly supported wordnetlike resource one new effort building russian wordnet involves mining monolingual dictionary step building process straightforward word sense disambiguation wsd source problem due limited word context specific wsd mechanism required kind relation mined paper describes wsd method used mining hypernym relation first part paper explains main reason choosing monolingual dictionary primary source information russian language wordnet state problem faced information extraction second part defines algorithm used extract hyponymhypernym pair third part describes algorithm used wsd
existing englishbased text similarity measurement primarily focus semantic dimension neglecting unique linguistic attribute found language like korean honorific expression explicitly integrated address limitation study proposes kosmic novel korean textsimilarity metric encompasses semantic tonal facet given text pair evaluation introduce novel benchmark annotated human expert empirically showing kosmic outperforms existing method moreover leveraging kosmic assess various korean paraphrasing method determine technique effective preserving semantics tone
amongst best mean summarize highlighting paper aim generate summary highlight overlaid original document make easier reader sift large amount text method allows summary understood context prevent summarizer distorting original meaning abstractive summarizers usually fall short particular present new method produce selfcontained highlight understandable avoid confusion method combine determinantal point process deep contextualized representation identify optimal set subsentence segment important nonredundant form summary highlight demonstrate flexibility modeling power method conduct extensive experiment summarization datasets analysis provides evidence highlighting promising avenue research towards future summarization
paper introduce notion demandweighted completeness allowing estimation completeness knowledge base respect used defining entity class employ usage data predict distribution relation entity example instance person knowledge base may require birth date name nationality considered complete predicted relation distribution enable detection important gap knowledge base define required fact unseen entity characterisation knowledge base also quantify usage completeness change time demonstrate method measure demandweighted completeness show simple neural network model performs well prediction task
immense opportunity enabled large language model become apparent nlp system increasingly expected excel realworld setting however many instance powerful model alone yield translational nlp solution especially formulated problem well aligned realworld task work study case umls vocabulary insertion important realworld task hundred thousand new term referred atom added umls one comprehensive opensource biomedical knowledge base previous work aimed develop automated nlp system make timeconsuming costly errorprone task efficient nevertheless practical progress direction difficult achieve due problem formulation evaluation gap research output realworld task order address gap introduce new formulation umls vocabulary insertion mirror realworld task datasets faithfully represent several strong baseline developed repurposing existing solution additionally propose effective ruleenhanced biomedical language model enables important new model behavior outperforms strong baseline provides measurable qualitative improvement editor carry uvi task hope case study provides insight considerable importance problem formulation success translational nlp solution
large pretrained language model lm gpt acquired surprising ability perform zeroshot learning example classify sentiment without training example prompt lm review label description user like movie ask whether next word yes however next word prediction training objective still misaligned target zeroshot learning objective address weakness propose metatuning directly optimizes zeroshot learning objective finetuning pretrained language model collection datasets focus classification task construct metadataset aggregating existing datasets annotating label description questionanswering qa format evaluated unseen task metatuned model outperform samesized qa model previous sota zeroshot learning system based natural language inference additionally increasing parameter count improves aucroc score forecast even larger model would perform better therefore measuring zeroshot learning performance language model outofthebox might underestimate true potential communitywide effort aggregating datasets unifying format help build model answer prompt better
safety detection increasingly important topic recent year become even necessary develop reliable safety detection system rapid development large language model however currently available safety detection system limitation term versatility interpretability paper first introduce instructsafety safety detection framework unifies common subtasks safety detection task unified similar form different instruction conduct comprehensive survey existing safety detection datasets process humanannotated datasets instruction tuning also construct adversarial sample enhance model robustness finetuning flant collected data developed safetyflant multidimensional explainable safety detector conduct comprehensive experiment variety datasets task demonstrate strong performance safetyflant comparison supervised baseline served apis perspective api chatgpt instructgpt release processed data finetuned safetyflant related code public use
introduction transformer successively bert brought revolution field natural language processing model pretrained vast amount data easily extensible used wide variety task transfer learning continual work transformer based architecture led variety new model state art result robertacitation one model brings series change bert architecture capable producing better quality embeddings expense functionality paper attempt solve well known text classification task finegrained domain classification using bert roberta perform comparative analysis also attempt evaluate impact data preprocessing specially context finegrained domain classification result obtained outperformed model icon techdofication subtaska finegrained domain classification task ranked first prof effectiveness approach
attribution bias refers tendency people attribute success ability failure external factor business context internal factor might restructuring firm external factor might unfavourable change exchange interest rate accounting research presence attribution bias demonstrated narrative section annual financial report previous study applied manual content analysis problem paper present novel work automate analysis attribution bias using machine learning algorithm previous study applied manual content analysis small scale reveal bias narrative section annual financial report work group expert accounting finance labelled annotated list sentence random sample uk preliminary earning announcement pea allow u examine whether sentence pea contain internal external attribution kind attribution linked positive negative performance wished examine whether human annotator could agree coding difficult task whether machine learning ml could applied reliably replicate coding process much larger scale best machine learning algorithm correctly classified performance sentence accuracy detected tone attribution financial pea accuracy
introduce generic humanoutoftheloop pipeline erlkg perform rapid association analysis biomedical entity existing entity corpus domain pipeline consists knowledge graph kg created open source cord dataset fully automating procedure information extraction using scibert best latent entity representation found benchnmarking different kg embedding technique task link prediction using graph convolution network auto encoder gcnae demonstrate utility erlkg respect covid multiple qualitative evaluation due lack gold standard propose relatively large intrinsic evaluation dataset covid use validating top two performing kg embedding technique find transd best performing kg embedding technique pearson spearman correlation score respectively demonstrate considerable number erlkgs top protein chemical disease prediction currently consideration covid related research
document describes finding second workshop neural machine translation generation held concert annual conference association computational linguistics acl first summarize research trend paper presented proceeding note particular interest linguistic structure domain adaptation data augmentation handling inadequate resource analysis model second describe result workshop shared task efficient neural machine translation participant tasked creating mt system accurate efficient
statistical morphological inflectors typically trained fully supervised typelevel data one remaining open research question following effectively exploit raw tokenlevel data improve performance end introduce novel generative latentvariable model semisupervised learning inflection generation enable posterior inference latent variable derive efficient variational inference procedure based wakesleep algorithm experiment language using universal dependency corpus simulated lowresource setting find improvement absolute accuracy case
introduce feverlike dataset covidfact claim concerning covid pandemic dataset contains claim evidence claim contradictory claim refuted evidence unlike previous approach automatically detect true claim source article generate counterclaim using automatic method rather employing human annotator along constructed resource formally present task identifying relevant evidence claim verifying whether evidence refutes support given claim addition scientific claim data contains simplified general claim medium source making better suited detecting general misinformation regarding covid experiment indicate covidfact provide challenging testbed development new system approach reduce cost building domainspecific datasets detecting misinformation
multilingual pretraining finetuning remarkably succeeded various natural language processing task transferring representation one language another especially crucial crosslingual learning one expect machine translation objective well suited fostering capability involve explicit alignment semantically equivalent sentence different language paper investigates potential benefit employing machine translation continued training objective enhance language representation learning bridging multilingual pretraining crosslingual application study question two lens quantitative evaluation performance existing model analysis latent representation result show contrary expectation machine translation continued training fails enhance crosslingual representation learning multiple crosslingual natural language understanding task conclude explicit sentencelevel alignment crosslingual scenario detrimental crosslingual transfer pretraining important implication future crosslingual transfer study furthermore provide evidence similarity measure investigation parameter lack positive influence due output separabilitywhich argue use machine translation detrimental elsewhere
retrievalenhanced method become primary approach fact verification fv requires reasoning multiple retrieved piece evidence verify integrity claim retrieve evidence existing work often employ offtheshelf retrieval model whose design based probability ranking principle argue rather relevance fv need focus utility claim verifier derives retrieved evidence introduce textbffeedbackbased evidence retriever fer optimizes evidence retrieval process incorporating feedback claim verifier feedback signal use divergence utility effectively verifier utilizes retrieved evidence groundtruth evidence produce final claim label empirical study demonstrate superiority fer prevailing baseline
language model lm shown memorize great deal factual knowledge contained training data lm generates assertion often difficult determine learned information whether true paper propose problem fact tracing identifying training example taught lm generate particular factual assertion prior work training data attribution tda may offer effective tool identifying example known proponent present first quantitative benchmark evaluate compare two popular family tda method gradientbased embeddingbased find much headroom remains example method lower proponentretrieval precision information retrieval baseline bm access lm identify key challenge may necessary improvement overcoming problem gradient saturation also show several nuanced implementation detail existing neural tda method significantly improve overall fact tracing performance
goal text simplification t transform difficult text version easier understand broadly accessible wide variety reader domain healthcare fully automated approach used since information must accurately preserved instead semiautomated approach used assist human writer simplifying text faster higher quality paper examine application autocomplete text simplification medical domain introduce new parallel medical data set consisting aligned english wikipedia simple english wikipedia sentence examine application pretrained neural language model pnlms dataset compare four pnlms bert roberta xlnet gpt show additional context sentence simplified incorporated achieve better result absolute improvement best individual model also introduce ensemble model combine four pnlms outperforms best individual model resulting overall word prediction accuracy
plagiarism major issue science education complex plagiarism plagiarism idea hard detect therefore especially important track improvement method correctly paper study performance plagdet main measure plagiarim detection manually paraphrased datasets pan summary reveal fallibility certain condition propose evaluation framework normalization inner term resilient dataset imbalance conclude experimental justification proposed measure implementation new framework made publicly available github repository
finegrained sentiment analysis receiving increasing attention recent year extracting opinion target expression ote review often important step finegrained aspectbased sentiment analysis retrieving information usergenerated text however difficult customer review instance prone contain misspelled word difficult process due domainspecific language work investigate whether characterlevel model improve performance identification opinion target expression integrate information character structure word sequence labeling system using characterlevel word embeddings show positive impact system performance specifically obtain increase point fscore respect baseline model experiment reveal encoded character pattern learned embeddings give nuanced view performance difference model
paper present modified version cbow algorithm implemented fasttext framework modified algorithm cbowtag build vector space model includes representation original word form annotation time illustrate result presenting model built corpus includes morphological syntactic annotation simultaneous presence unannotated element different annotation time model make possible constrain nearest neighbour query specific type element model thus efficiently answer question eat skeleton else eat etc error analysis reveals model highlight error introduced annotation tagger parser used generate annotation well lexical peculiarity corpus especially limit vocabulary model frequent item
able induce word translation nonparallel data often prerequisite crosslingual processing resourcescarce language domain previous endeavor typically simplify task imposing onetoone translation assumption strong hold natural language remove constraint introducing earth mover distance training bilingual word embeddings way take advantage capability handle multiple alternative word translation natural form regularization approach show significant consistent improvement across four language pair also demonstrate approach particularly preferable resourcescarce setting requires minimal seed lexicon
abstractmachine translation mt technology facilitated daily task providing accessible shortcut gathering processing communicating information however suffer bias harm user society large relatively new field inquiry study gender bias mt still lack cohesion advocate unified framework ease future research end critically review current conceptualization bias light theoretical insight related discipline ii summarize previous analysis aimed assessing gender bias mt iii discus mitigating strategy proposed far iv point toward potential direction future work
paper investigate problem adapting machine translation system feedback provided multiple posteditors well know translator might different postediting style variability hinders application online learning method indeed assume homogeneous source adaptation data hence propose multitask learning leverage bias information single posteditors order constrain evolution smt system new framework significance testing sentence level metric described show multitask learning approach outperforms existing online learning approach significant gain ter score strong online adaptive baseline test set postedits produced four translator text popular benchmark multiple reference respectively
present result machine reading question answering mrqa shared task evaluating generalization capability reading comprehension system task adapted unified distinct question answering datasets format among six datasets made available training six datasets made available development rest hidden final evaluation ten team submitted system explored various idea including data sampling multitask learning adversarial training ensembling best system achieved average f score heldout datasets absolute point higher initial baseline based bert
answering complex question often requires reasoning knowledge graph kg stateoftheart method often utilize entity question retrieve local subgraphs fed kg encoder eg graph neural network gnns model local structure integrated language model question answering however paradigm constrains retrieved knowledge local subgraphs discard diverse triplet buried kg disconnected useful question answering paper propose simple yet effective method first retrieve relevant triplet kg rerank concatenated question fed language model extensive result commonsenseqa openbookqa datasets show method outperform stateoftheart absolute accuracy
nlp community long advocated construction multiannotator datasets better capture nuance language interpretation subjectivity ambiguity paper conduct retrospective study show performance score vary dataset expands single annotation per instance multiple annotation propose novel multiannotator simulation process generate datasets varying annotation budget show similar datasets annotation budget lead varying performance gain finding challenge popular belief model trained multiannotation example always lead better performance model trained single fewannotation example
among proposal multidimensional grammar family constraintbased grammatical framework including relational grammar relational language expression formally defined set relation whose tuples taken indexed set symbol bottomup parsing earleystyle parsing algorithm previously proposed different class relational language relational language class earley style parsing wittenburg requires relation partial order however realworld domain relation naturally conform restriction paper discus motivation method predictive earleystyle parsing multidimensional language relation involved necessarily yield ordering eg relation symmetric andor nontransitive solution involves guaranteeing single initial start position parsing associated member input set domain issue discussed involve incremental parsing interface offline verification multidimensional data
pseudo relevance feedback prf commonly used boost performance traditional information retrieval ir model using topranked document identify weight new query term thereby reducing effect querydocument vocabulary mismatch neural retrieval model recently demonstrated strong result adhoc retrieval combining prf straightforward due incompatibility existing prf approach neural architecture bridge gap propose endtoend neural prf framework used existing neural ir model embedding different neural model building block extensive experiment two standard test collection confirm effectiveness proposed nprf framework improving performance two stateoftheart neural ir model
sigmorphonunimorph shared task large scale morphological inflection generation included wide range typologically diverse language language toplevel language family arabic modern standard assamese braj chukchi eastern armenian evenki georgian gothic gujarati hebrew hungarian itelmen karelian kazakh ket khalkha mongolian kholosi korean lamahalot low german ludic magahi middle low german old english old high german old norse polish pomak slovak turkish upper sorbian veps xibe emphasize generalization along different dimension year evaluating test item unseen lemma unseen feature separately small large training condition across five submitted system two baseline prediction inflection unseen feature proved challenging average performance decreased substantially last year true even language form principle predictable suggests work needed designing system capture various type generalization required world language
nowadays scarcity dispersion opensource nlp resource tool african language make difficult researcher truly fit language current algorithm artificial intelligence resulting stagnation numerous language far technological progress concerned created aim building community voluntary contributor around african native andor national language culture nlp technology artificial intelligence ntealan association set series web collaborative platform intended allow aforementioned community create manage lexicographic linguistic resource paper aim presenting first version three lexicographic platform developed african language restgraphql api saving lexicographic resource dictionary management platform collaborative dictionary platform also describe data representation format used resource experimenting dictionary looking user feedback convinced collaborationbased approach platform effectively respond challenge producing quality resource african native andor national language
work neural natural language generation nnlg focus controlling content generated text experiment controling several stylistic aspect generated text addition content method based conditioned rnn language model desired content well stylistic parameter serve conditioning context demonstrate approach movie review domain show successful generating coherent sentence corresponding required linguistic style content
investigate method improving memory efficiency chart parser specifically propose technique reduce number active arc created process parsing sketch difference chart algorithm provide empirical result demonstrate effectiveness technique
consortium ecess european center excellence speech synthesis set framework evaluation software module tool relevant speech synthesis till two line evaluation campaign established evaluation ecess tt module text processing prosody acoustic synthesis evaluation ecess tool pitch extraction voice activity detection phonetic segmentation functionality interface ecess tt developed joint effort ecess ecfunded project tcstar first evaluation campaign conducted within tcstar using ecess framework tcstar finished march ecess continued extended evaluation ecess tt module tool within paper describe novel framework allows performing remote evaluation module via web first experimental result reported result several evaluation campaign tool handling pitch extraction voice activity detection presented
common european language data space lds integral part eu data strategy aim developing single market data decentralised technical infrastructure governance scheme currently developed lds project also dedicated task proofofconcept prototype handling legal aspect raising awareness promoting lds event social medium channel lds part broader vision establishing necessary component develop european large language model
paper describes system solomon detail result participation semeval task detection propaganda technique news article participated task technique classification tc multiclass classification task address tc task used roberta based transformer architecture finetuning propaganda dataset prediction roberta finetuned classdependentminorityclass classifier special classifier employ dynamically adapted least common subsequence algorithm used adapt intricacy repetition class compared participating system submission ranked th leaderboard
provide first exploration sentence embeddings texttotext transformer including effect scaling sentence encoders b parameter sentence embeddings broadly useful language processing task achieves impressive performance language task unclear produce sentence embeddings encoderdecoder model investigate three method construct sentencet st model two utilize encoder one using full encoderdecoder establish new sentence representation transfer benchmark sentglue extends senteval toolkit nine task glue benchmark encoderonly model outperform previous best model senteval sentglue transfer task including semantic textual similarity sts scaling st million billion parameter shown consistently improve performance finally encoderdecoder method achieves new stateoftheart sts using sentence embeddings
paper introduces model setting submitted inlg dialogsum chal lenge shared task generate summary reallife scenario dialogue two peo ple paper explored using interme diate task transfer learning reported speech use supplementary dataset addi tion base finetuned bart model ever use method final model none improved result final model dialogue task achieved score slightly top submission hidden test set score rouge rouge rougel bertscore respectively top submitted model also receive human evaluation
spanbased nested namedentity recognition ner cubictime complexity using avariant cyk algorithm show adding supplementary structural constraint search space nested ner quadratictime complexity asymptotic complexity nonnested case proposed algorithm cover large part three standard english benchmark delivers comparable experimental result
paper describes corpus consisting audio data automatic space monitoring based solely perceived acoustic information particular database created part project aiming detection abnormal event lead lifethreatening situation property damage audio corpus composed vocal reaction environmental sound usually encountered atypical situation audio data composed three part phase professional sound effect collection phase ii recording obtained action drama movie phase iii vocal reaction related realworld emergency event retrieved television radio broadcast news documentary etc annotation methodology given detail along preliminary classification result statistical analysis dataset regarding phase main objective dataset provide training data automatic recognition machine detect hazardous situation provide security enhancement public environment otherwise require human supervision
task dialogue rewriting aim reconstruct latest dialogue utterance copying missing content dialogue context existing model task suffer robustness issue ie performance drop dramatically testing different dataset address robustness issue proposing novel sequencetaggingbased model search space significantly reduced yet core task still well covered common issue tagging model text generation model output may lack fluency alleviate issue inject loss signal bleu gpt reinforce framework experiment show huge improvement model current stateoftheart system transferring another dataset
text representation model prone exhibit range societal bias reflecting noncontrolled biased nature underlying pretraining data consequently lead severe ethical issue even bias amplification recent work predominantly focused measuring mitigating bias pretrained language model surprisingly landscape bias measurement mitigation resource method conversational language model still scarce limited type bias artificially constructed resource completely ignores impact debiasing method may final perfor mance dialog task eg conversational response generation work present redditbias first conversational data set grounded actual human conversation reddit allowing bias measurement mitigation across four important bias dimension genderracereligion queerness develop evaluation framework simultaneously measure bias developed redditbias resource evaluates model capability dialog task model debiasing use evaluation framework benchmark widely used conversational dialogpt model along adaptation four debiasing method result indicate dialogpt biased respect religious group debiasing technique remove bias preserving downstream task performance
paper present number possible criterion system transliterate south asian language native script latin script process known romanization criterion related either fidelity human linguistic behavior pronunciation transparency naturalness conventionality processing utility people ease input well underthehood system invertibility stability across language script addressing differing criterion several linguistic consideration modeling prominent phonological process relation orthography need taken account discus key linguistic detail context brahmic script language use hindi malayalam present core feature several romanization algorithm implemented finite state transducer fst formalism address differing criterion implementation algorithm released part nisaba finitestate script processing library
large language model llm show extraordinary performance broad range cognitive task yet capability reproduce human semantic similarity judgement remains disputed report experiment finetune two llm slovene monolingual slot multilingual mt well mt english generate word association model finetuned human word association norm created within small world word project recently started collect data slovene since aim explore difference human modelgenerated output model parameter minimally adjusted fit association task perform automatic evaluation using set method measure overlap ranking addition subset human modelgenerated response manually classified four category meaning positionand formbased erratic result show humanmachine overlap small model produce similar distribution association category human
study investigate effectiveness using crosslingual word embeddings zeroshot transfer learning language abundant resource english languagewith limited resource isizulu isizulu part south african nguni language family characterised complex agglutinating morphology use vecmap open source tool obtain crosslingual word embeddings perform extrinsic evaluation effectiveness embeddings train news classifier labelled english data order categorise unlabelled isizulu data using zeroshot transfer learning study found model weighted average fscore finding demonstrate vecmap generates modular word embeddings crosslingual space impact downstream classifier used zeroshot transfer learning
viewing machine translation structured classification problem provided gateway host structured prediction technique enter field particular largemargin structured prediction method discriminative training feature weight structured perceptron mira started match exceed performance existing method mert one issue structured problem general difficulty obtaining fully structured label eg machine translation obtaining reference translation parallel sentence corpus arbitrary language pair another issue specific translation domain difficulty online training machine translation system since existing method often require bilingual knowledge correct translation output online propose solution two problem demonstrating way incorporate binarylabeled feedback ie feedback whether translation hypothesis good understandable one form supervision easily integrated online manner machine translation framework experimental result show marked improvement incorporating binary feedback unseen test data gain exceeding bleu point
creating new wordnet mean trivial task target language underresourced case language currently included multilingual african wordnet afwn developer need rely heavily human expertise different phase development afwn incorporated various method fasttracking ease tedious timeconsuming work method proven effective others seem little positive impact work rate case many underresourced language expand model implemented throughout thus depending english source data english princeton wordnet pwn translated target language assumption new language share underlying structure pwn paper discusses problem encountered along way point various possibility semi automated quality assurance measure refinement afwn ensure accelerated growth paper aim highlight lesson learnt handson experience order facilitate similar project particular language african country
codeswitching c common linguistic phenomenon wherein speaker fluidly transition language conversation cognitive process driving c remain complex domain earlier investigation shed light multifaceted trigger study delf influence partofspeech po propensity bilingual engage c employing comprehensive analysis spanishenglish mandarinenglish corpus compared prior research finding affirm existence statistically significant connection po likelihood c across language pair notably find relationship exhibit maximum strength proximity c instance progressively diminishing token distance c point
understanding expected academic writing difficult novice writer assimilate recent year seen several automated tool become available support academic writing work present framework annotating feature related work section academic writing support writer feedback
social consensus established severity online hate speech since cause mental harm target also give displeasure people read korean definition scope hate speech discussed widely research consideration hardly extended construction hate speech corpus therefore create korean online hate speech dataset concrete annotation guideline see real world toxic expression concern sociolinguistic discussion inductive observation reveals hate speech online news comment mainly composed social bias toxicity furthermore check final corpus corresponds definition scope hate speech confirm overall procedure outcome concurrence sociolinguistic discussion
paper present ongoing work conducted within cleartext project specifically focusing resource creation simplification spanish people cognitive disability resource include clearsim corpus simpletext tool one hand description corpus compilation process help apsa detailed along information regarding whether text bronze silver gold standard simplification version original text goal reach text total end project hand aim explore large language model llm sequencetosequence setup text simplification document level therefore tool objective technical aspect preliminary result derived early experimentation also presented initial result subject improvement given experimentation preliminary stage despite showcasing flaw inherent generative model eg hallucination repetitive text examine resolution lack thereof complex linguistic phenomenon learned corpus issue addressed throughout remainder project expected positive result project impact society threefold nature scientifictechnical social economic
dense retrieval model exhibited remarkable effectiveness rely abundant labeled data face challenge applied different domain previous domain adaptation method employed generative model generate pseudo query creating pseudo datasets enhance performance dense retrieval model however approach typically use unadapted rerank model leading potentially imprecise label paper demonstrate significance adapting rerank model target domain prior utilizing label generation adaptation process enables u obtain accurate label thereby improving overall performance dense retrieval model additionally combining adapted retrieval model adapted rerank model achieve significantly better domain adaptation result across three retrieval datasets release code future research
aim paper twofold firstly approach presented select correct antecedent anaphoric element according kind text segment occur basically information logical text structure eg chapter section paragraph used order select antecedent life span linguistic expression ie linguistic expression likely chosen antecedent throughout whole text others addition appropriate search scope anaphora expressed expression defined according document structuring element include linguistic expression corpus investigation give rise supposition logical text structure influence search scope candidate antecedent second solution presented integrate resource used anaphora resolution approach multilayered xml annotation used order make set resource accessible anaphora resolution system
visionandlanguage navigation vln natural language grounding task agent learns follow language instruction navigate specified destination realworld environment key challenge recognize stop correct location especially complicated outdoor environment existing method treat stop action equally action result undesirable behavior agent often fails stop destination even though might right path therefore propose learning stop lstop simple yet effective policy module differentiates stop action approach achieves new state art challenging urban vln dataset touchdown outperforming baseline absolute improvement success weighted edit distance sed
one way reduce network traffic multinode dataparallel stochastic gradient descent exchange largest gradient however damage gradient degrades model performance transformer model degrade dramatically impact rnns smaller restore gradient quality combining compressed global gradient node locally computed uncompressed gradient neural machine translation experiment show transformer convergence restored rnns converge faster method training node converges x fast uncompressed gradient scale x relative singlenode training
present codex set knowledge graph completion datasets extracted wikidata wikipedia improve upon existing knowledge graph completion benchmark scope level difficulty term scope codex comprises three knowledge graph varying size structure multilingual description entity relation ten thousand hard negative triple plausible verified false characterize codex contribute thorough empirical analysis benchmarking experiment first analyze codex dataset term logical relation pattern next report baseline link prediction triple classification result codex five extensively tuned embedding model finally differentiate codex popular fbk knowledge graph completion dataset showing codex cover diverse interpretable content difficult link prediction benchmark data code pretrained model available urlhttpsbitlyepbrjs
halfday tutorial provides broad overview evaluate translation produced machine translation system range issue covered includes broad survey human evaluation measure commonlyused automated metric review used various type evaluation task assessing translation quality mttranslated sentence comparing performance alternative mt system measuring productivity gain incorporating mt translation workflow
parmenides project developed text mining application applied three different domain exemplified case study three user partner project lifetime project parallel development system evaluation framework developed author conjunction user eventually applied system object exercise twofold firstly develop perform complete usercentered evaluation system assess well answered user requirement secondly develop general framework could applied context user requirement modification similar system paper describe framework process building parameterising quality model case study perhaps interestingly way quality model user requirement expectation evolved time
paper present first shared task irony detection given tweet automatic natural language processing system determine whether tweet ironic task type irony expressed task b ironic tweet collected using ironyrelated hashtags ie irony sarcasm subsequently manually annotated minimise amount noise corpus prior distributing data hashtags used collect tweet removed corpus task training corpus tweet provided well test set containing tweet shared task received submission team binary classification task team multiclass task b highest classification score obtained subtasks respectively f f demonstrate finegrained irony classification much challenging binary irony detection
describe entry cl conll shared task parsing universal dependency raw text system feature ensemble three global parsing paradigm one graphbased two transitionbased model leverage characterlevel bidirectional lstms lexical feature extractor encode morphological information though relying baseline tokenizers focusing parsing system ranked second official endtoend evaluation macroaverage la f score test treebanks addition top average performance four surprise language small treebank subset
present robust approach detecting intrinsic sentence importance news training two corpus documentsummary pair used singledocument summarization approach combined beginning document heuristic outperforms stateoftheart summarizer beginningofarticle baseline automatic manual evaluation result represent important advance absence crossdocument repetition single document summarizers news able consistently outperform strong beginningofarticle baseline
animate entity narrative comic story expressed number visual representation across panel identifying entity necessary recognizing character analysing narrative affordances unique comic integrating linguistic reference annotation however annotation process animate entity identification received adequate attention research explores method identifying animate entity visually comic using annotation experiment two round interannotator agreement experiment run first asks annotator outline area comic page using polygon segmentation tool second prompt annotator assign outlined entity animacy type derive quantitative measure agreement first experiment result show polygonbased outline successfully produce qualitative measure agreement second experiment support animacy status best conceptualised graded rather binary concept
large language model llm demonstrated impressive performance range natural language processing nlp task unfortunately immense amount computation memory access required llm training make prohibitively expensive term hardware cost thus challenging deploy use case ondevice learning paper motivated observation llm training memorybound propose novel dynamic quantization strategy termed dynamic stashing quantization dsq put special focus reducing memory operation also enjoys benefit low precision training reduced arithmetic cost conduct thorough study two translation task trainedfromscratch three classification task finetuning dsq reduces amount arithmetic operation time number dram operation time iwslt compared standard bit fixedpoint widely used ondevice learning
aspectcategory sentiment analysis acsa aim predict sentiment polarity sentence respect given aspect category detect sentiment toward particular aspect category sentence previous method first generate aspect categoryspecific sentence representation aspect category predict sentiment polarity based representation method ignore fact sentiment aspect category mentioned sentence aggregation sentiment word indicating aspect category sentence lead suboptimal performance paper propose multiinstance multilabel learning network aspectcategory sentiment analysis acmimlln treat sentence bag word instance word indicating aspect category key instance aspect category given sentence aspect category mentioned sentence acmimlln first predicts sentiment instance find key instance aspect category finally obtains sentiment sentence toward aspect category aggregating key instance sentiment experimental result three public datasets demonstrate effectiveness acmimlln
knowledgebased visual question answering qa aim answer question requires visuallygrounded external knowledge beyond image content answering complex question require multihop reasoning weak supervision considered challenging problem since supervision given reasoning process ii highorder semantics multihop knowledge fact need captured paper introduce concept hypergraph encode highlevel semantics question knowledge base learn highorder association proposed model hypergraph transformer construct question hypergraph queryaware knowledge hypergraph infers answer encoding interassociations two hypergraphs intraassociations hypergraph extensive experiment two knowledgebased visual qa two knowledgebased textual qa demonstrate effectiveness method especially multihop reasoning problem source code available urlhttpsgithubcomyujungheokbvqapublic
standardized corpus foundation spoken language research work introduce annotated standardized corpus spoken dialog system sd domain data let go bus information system carnegie mellon university pittsburgh formatted parameterized annotated quality emotion task success label containing dialog systemuser exchange total parameter derived automatically semiautomatically automatic speech recognition asr spoken language understanding slu dialog manager dm property spoken user utterance emotion label set garbage nonangry slightly angry angry assigned addition manual annotation interaction quality iq exchange level performed three raters achieving kappa value iq score express quality interaction systemuser exchange score presented corpus intended standardized basis classification evaluation task regarding task success prediction dialog quality estimation emotion recognition foster comparability different approach field
relation extraction task aim extract relation two entity sentence performance method task depends datasets quantity quality paper propose use large language model llm data augmentation moreover compared traditional finetuning method research focus prompt learning however prompt template ignore relative order entity believe affect prediction error due propose novel bidirectional prompt template prompt learning design training strategy utilizing template try fit probability distribution prompt learning finetuning method model end propose relation classification via bidirectional prompt learning data augmentation llm rcbp conduct experiment four datasets tacred retacred tacrev semeval result show rcbp performs well datasets outperforms stateoftheart tacrev retacred datasets
paper describes system submitted iitpmt team computational approach linguistic codeswitching calcs shared task mt englishhinglish submit neural machine translation nmt system trained synthetic codemixed cm englishhinglish parallel corpus propose approach create codemixed parallel corpus clean parallel corpus unsupervised manner alignment based approach use linguistic resource explicitly marking token codeswitching also train nmt model gold corpus provided workshop organizer augmented generated synthetic codemixed parallel corpus model trained generated synthetic cm data achieves bleu point given test set
paper discusses hybrid approach transliterating matching arabic name implemented dataflux quality knowledge base qkb knowledge base used data management software system sa institute inc approach transliteration relies lexicon name corresponding transliteration primary method fall back perl regular expression rule transliterate name exist lexicon transliteration qkb bidirectional technology transliterates arabic name written arabic script latin script transliterates arabic name written latin script arabic arabic name matching take similar approach relies lexicon arabic name corresponding transliteration falling back phonetic transliteration rule transliterate name latin script name ultimately rendered latin script matching take place thus technology capable matching name across arabic latin script well within arabic script within latin script goal author paper build software system capable transliterating matching arabic name across script accuracy deemed acceptable according internal software quality standard
paper describes submission system hitscir conll shared task crossframework crosslingual meaning representation parsing task includes five framework graphbased meaning representation ie ucca ed ptg amr drg solution consists two subsystem transitionbased parser flavor framework ucca ed ptg iterative inference parser flavor framework drg amr final evaluation system ranked rd among seven team crossframework track crosslingual track macroaveraged mrp f score
attentionbased neural model employed detect different aspect sentiment polarity target targeted aspectbased sentiment analysis tabsa however existing method specifically pretrain reasonable embeddings target aspect tabsa may result target aspect vector representation different context losing contextdependent information address problem propose novel method refine embeddings target aspect pivotal embedding refinement utilizes sparse coefficient vector adjust embeddings target aspect context hence embeddings target aspect refined highly correlative word instead using contextindependent randomly initialized vector experiment result two benchmark datasets show approach yield stateoftheart performance tabsa task
comparable news text frequently proposed potential source alignable subsentential fragment use statistical machine translation system assess potentially useful paper first discus scheme classifying news text pair according degree relatedness event report investigate robust classification scheme via multilingual annotation exercise propose annotation methodology similar used summarization evaluation allow u identify quantify shared content subsentential level news text pair report preliminary exercise assess method conclude discussing work fit broader programme assessing potential utility comparable news text extracting paraphrasestranslational equivalent use language processing application
paper present thorough investigation method align pretrained contextualized embeddings shared crosslingual contextaware embedding space providing strong reference benchmark future contextaware crosslingual model propose novel challenging task bilingual tokenlevel sense retrieval btsr specifically evaluates accurate alignment word meaning crosslingual nonparallel context currently evaluated existing task bilingual contextual word similarity sentence retrieval show proposed btsr task highlight merit different alignment method particular find using context average typelevel alignment effective transferring monolingual contextualized embeddings crosslingually especially nonparallel context time improves monolingual space furthermore aligning independently trained model yield better performance aligning multilingual embeddings shared vocabulary
recent study shown bias thetext suggestion system percolate theusers writing pilot study ask thequestion people interact text prediction model inline next phrase suggestion interface introducing sentiment bias text prediction model affecttheir writing present pilot study afirst step answer question
learning disentangled representation realworld data challenging open problem previous method focused either supervised approach use attribute label unsupervised approach manipulate factorization latent space model variational autoencoder vae training taskspecific loss work propose polarizedvae approach disentangles select attribute latent space based proximity measure reflecting similarity data point respect attribute apply method disentangle semantics syntax sentence carry transfer experiment polarizedvae outperforms vae baseline competitive stateoftheart approach general framework applicable attribute disentanglement task
paper describes system submitted supervised track track semeval semantic textual relatedness african asian language challenged datasets varying size small sample observe pear system using smaller pretrained masked language model process sentence pair pair encoding result model efficiently adapt taskin addition simplistic modeling approach experiment hyperparameter optimization data expansion provided training set using multilingual biencoders sampling dynamic number nearest neighbor augmented resampling final model lightweight allowing fast experimentation integration new language
investigate ability language model perform compositional reasoning task overall solution depends correctly composing answer subproblems measure often model correctly answer subproblems generate overall solution ratio call compositionality gap evaluate ratio asking multihop question answer require composing multiple fact unlikely observed together pretraining gpt family model model size increase show singlehop question answering performance improves faster multihop performance therefore compositionality gap decrease surprising result suggests powerful model memorize recall factual knowledge show corresponding improvement ability perform kind compositional reasoning demonstrate elicitive prompting chain thought narrow compositionality gap reasoning explicitly instead implicitly present new method selfask improves chain thought method model explicitly asks answer followup question answering initial question finally show selfasks structured prompting let u easily plug search engine answer followup question additionally improves accuracy
analogy one core capacity human cognition faced new situation often transfer prior experience domain work computational analogy relies heavily complex manually crafted input work relax input requirement requiring name entity mapped automatically extract commonsense representation use identify mapping entity unlike previous work framework handle partial analogy suggest new entity added moreover method output easily interpretable allowing user understand specific mapping chosen experiment show model correctly map classical x analogy problem guess level larger problem achieves accuracy mean guess level another experiment show algorithm outperforms human performance automatic suggestion new entity resemble suggested human hope work advance computational analogy paving way flexible realistic input requirement broader applicability
deep learning model reignited interest anomaly detection research recent year method anomaly detection text shown strong empirical result adhoc anomaly setup usually made downsampling class labeled dataset lead reproducibility issue model biased toward detecting particular anomaly failing recognize sophisticated scenario present work provide unified benchmark detecting various type anomaly focusing problem naturally formulated anomaly detection text ranging syntax stylistics way hoping facilitate research text anomaly detection also evaluate analyze two strong shallow baseline well two current stateoftheart neural approach providing insight knowledge neural model learning performing anomaly detection task provide code evaluation downloading preprocessing dataset httpsgithubcommateibejanadnlp
automatic extraction causeeffect relationship natural language text challenging open problem artificial intelligence early attempt solution used manually constructed linguistic syntactic rule restricted domain data set advent big data recent popularization deep learning paradigm tackle problem slowly shifted work proposed transformer based architecture automatically detect causal sentence textual mention identify corresponding causeeffect relation describe submission fincausal shared task based method model achieves fscore task fscore task shared task data set financial document
paper introduce largescale indonesian summarization dataset harvest article liputancom online news portal obtain documentsummary pair leverage pretrained language model develop benchmark extractive abstractive summarization method dataset multilingual monolingual bertbased model include thorough error analysis examining machinegenerated summary low rouge score expose issue rouge well extractive abstractive summarization model
syntaxcontrolled paraphrase generation aim produce paraphrase conform given syntactic pattern address task recent work started use parse tree syntactic template guide generationa constituency parse tree contains abundant structural information parentchild relation sibling relation alignment relation word node previous work utilized parentchild alignment relation may affect generation quality address limitation propose structural informationaugmented syntaxcontrolled paraphrasing siscp model particularly design syntax encoder based treetransformer capture parentchild sibling relation model alignment relation word node propose attention regularization objective make decoder accurately select corresponding syntax node guide generation word experiment show siscp achieves stateoftheart performance term semantic syntactic quality two popular benchmark datasets additionally propose syntactic template retriever str retrieve compatible syntactic structure validate str capable retrieving compatible syntactic structure demonstrate effectiveness siscp generate diverse paraphrase retrieved syntactic structure
present method regroups surface form cluster representing synonym help disambiguate homograph well homophone method applied posthoc trained contextual word embeddings beneficial language homograph homophone abound compromise efficiency language model cause underestimation problem evaluation taking japanese example evaluate accurate disambiguation much underestimation mitigated
identifying correcting inconsistency wordnet natural part development focusing subproblem missing link aim find automatically possible parent parentless synset isa hierarchy target wordnet mean source wordnet target source wordnet xmlformat equipped collaborative interlingual index cili paper describe algorithm provide statistic possible parent parentless synset wordnet included study additionally investigate suitability proposed potential parent synset correcting noun verb synset within estonian wordnet
shared task typical question answering task aim test accurately participant answer question exam typically question four candidate answer one answer correct existing method task usually implement recurrent neural network rnn long shortterm memory lstm however rnn lstm biased model word tail sentence dominant word header paper propose use attentionbased lstm atlstm model task adding attention mechanism standard lstm model easily capture long contextual information
describe focused effort investigate performance phrasebased human evaluation machine translation output achieving high annotator agreement define phrasebased evaluation describe implementation appraise toolkit support manual evaluation machine translation result phrase ranking done using either finegrained sixway scoring scheme allows differentiate much better slightly better reduced subset ranking choice afterwards discus kappa value scoring model several experiment conducted human annotator result show phrasebased evaluation used fast evaluation obtaining significant agreement among annotator granularity ranking choice however finegrained seems confuse annotator thus reduces overall agreement work reported paper confirms previous work field illustrates usage human evaluation machine translation reconsidered appraise toolkit available opensource downloaded author website
contextualized word embeddings elmo bert provide foundation strong performance across wide range natural language processing task pretraining large corpus unlabeled text however applicability approach unknown target domain varies substantially pretraining corpus specifically interested scenario labeled data available canonical source domain newstext target domain distinct labeled pretraining text address scenario propose domainadaptive finetuning contextualized embeddings adapted masked language modeling text target domain test approach sequence labeling two challenging domain early modern english twitter domain differ substantially existing pretraining corpus domainadaptive finetuning yield substantial improvement strong bert baseline particularly impressive result outofvocabulary word conclude domainadaptive finetuning offer simple effective approach unsupervised adaptation sequence labeling difficult new domain
choosing transfer language crucial step transfer learning much previous research dependency parsing related language successfully used however parsing latin suggested language ancient greek could helpful work parse latin lowresource scenario main goal investigate greek language helpful parsing latin related italic language show indeed case investigate influence factor including training set size content well linguistic distance find one explanatory factor seems syntactic similarity latin ancient greek influence genre shared annotation project seems smaller impact
recent language model improved addition external memory nearest neighbor language model retrieve similar context assist word prediction addition locality level allows model learn weight neighbor based relative location current text source document shown improve model performance nearest neighbor model explored controllable generation examined use locality level present novel approach purpose evaluate using automatic human evaluation politeness formality supportiveness toxicity textual data find model successfully able control style provides better fluencystyle tradeoff previous work
clara common language resource application marie curie initial training network ran aim providing researcher training crucial area related language resource infrastructure scope project broad included infrastructure design lexical semantic modeling domain modeling multimedia multimodal communication application parsing technology grammar model international consortium partner associate partner employed researcher new position organized training program consisting thematic course summerwinter school project resulted new theoretical insight well new resource tool importantly project trained new generation researcher perform advanced research development language resource technology
surge interest development opendomain chatbots driven recent advancement large language model openness dialogue expected maximized providing minimal information user common ground expect including presumed joint activity however evidence suggests effect opposite asking user chat anything result narrow form dialogue refer opendomain paradox position paper explain paradox theory common ground basis humanlike communication furthermore question assumption behind opendomain chatbots identify path forward enabling common ground humancomputer dialogue
size computational load finetuning largescale pretrained neural network becoming two major obstacle adopting machine learning many application continual learning cl serve remedy enabling knowledgetransfer across sequentially arriving task relaxes need finetune network weight scratch however existing cl algorithm primarily consider learning unimodal visiononly languageonly task develop transformerbased cl architecture learning bimodal visionandlanguage task based increasing number learnable parameter dynamically using knowledge distillation new additional parameter used specialize network task approach enables sharing information task addressing challenge catastrophic forgetting approach scalable learning large number task requires little memory time overhead model reach stateoftheart performance challenging visionandlanguage task
paper introduces novel framework harness large language model llm epidemic intelligence focusing identifying categorizing emergent sociopolitical phenomenon within health crisis spotlight covid pandemic approach diverges traditional method topic model providing explicit support analyst identification distinct thematic area generation clear actionable statement topic support zeroshot classification mechanism enabling effective matching news article finegrain topic without need model finetuning framework designed transparent possible producing linguistically informed insight make analysis accessible analyst may familiar every subject matter inherently emerging phenomenon process enhances precision relevance extracted epidemic intelligence also foster collaborative environment system linguistic ability analyst domain expertise integrated
nearest neighbor machine translation knnmt interpolates target token probability estimate derived additional example achieved significant improvement attracted extensive interest recent year however existing research explicitly consider source context retrieving similar example potentially leading suboptimal performance address comprehensively revisit role source context propose simple effective method improving neural machine translation via source context enhancement demonstrating crucial role retrieving superior example determining suitable interpolation coefficient furthermore reveal probability estimation optimized incorporating sourceaware distance calibration module comprehensive experiment show proposed approach seamlessly integrated representative knnmt baseline resulting substantial improvement strong baseline across number setting domain remarkably improvement reach bleu point
answer selection aim identifying correct answer given question set potentially correct answer contrary previous work typically focus semantic similarity question answer hypothesis questionanswer pair often analogical relation using analogical inference use case propose framework neural network architecture learning dedicated sentence embeddings preserve analogical property semantic space evaluate proposed method benchmark datasets answer selection demonstrate sentence embeddings indeed capture analogical property better conventional embeddings analogybased question answering outperforms comparable similaritybased technique
coverage quality conceptual information contained lexical semantic resource crucial many task natural language processing automatic alignment complementary resource one way improving coverage quality however past attempt always pair specific resource paper establish settheoretic convention describing concept alignment use describe method automatically constructing nway alignment arbitrary pairwise alignment apply technique production threeway alignment previously published wordnetwikipedia wordnetwiktionary alignment present quantitative informal qualitative analysis aligned resource threeway alignment found greater coverage enriched sense representation coarser sense granularity original resource pairwise alignment though came cost accuracy evaluation induced word sense cluster word sense disambiguation task showed better random cluster equivalent granularity however use alignment enrich sense inventory additional sense gloss significantly improve performance baseline knowledgebased wsd algorithm
paper perform modality prediction financial dialogue end introduce new dataset develop binary classifier detect strong weak modal answer depending surface lexical semantic representation preceding question financial feature contrast different algorithm feature category fusion method perhaps counterintuitively result indicate strongest feature given task financial uncertainty measure market individual firm risk
image captioning system involves module computer vision well natural language processing computer vision module detecting salient object extracting feature image natural language processing nlp module generating correct syntactic semantic image caption although many image caption datasets flickrk flickrk mscoco publicly available datasets captioned english language image caption corpus myanmar language myanmar image caption corpus manually built part flickrk dataset current work furthermore generative merge model based convolutional neural network cnn longshort term memory lstm applied especially myanmar image captioning next two conventional feature extraction model visual geometry group vgg oxfordnet layer layer compared performance system evaluated myanmar image caption corpus using bleu score fold cross validation
documentlevel relation extraction requires intersentence reasoning capability capture local global contextual information multiple relational fact improve intersentence reasoning propose characterize complex interaction sentence potential relation instance via graph enhanced dual attention network geda geda sentence representation generated sentencetorelation sr attention refined synthesized heterogeneous graph convolutional network fed relationtosentence r attention design simple yet effective regularizer based natural duality sr r attention whose weight also supervised supporting evidence relation instance training extensive set experiment existing largescale dataset show model achieve competitive performance especially intersentence relation extraction neural prediction also interpretable easily observed
learning effective language representation crowdsourced label crucial many realworld machine learning task challenging aspect problem quality crowdsourced label suffer high intra interobserver variability since highcapacity deep neural network easily memorize disagreement among crowdsourced label directly applying existing supervised language representation learning algorithm may yield suboptimal solution paper propose textittacma temporalaware language representation learning heuristic crowdsourced label multiple annotator proposed approach explicitly model intraobserver variability attention mechanism computes aggregate persample confidence score multiple worker address interobserver disagreement proposed heuristic extremely easy implement around line code proposed heuristic evaluated four synthetic four realworld data set result show approach outperforms wide range stateoftheart baseline term prediction accuracy auc encourage reproducible result make code publicly available urlhttpsgithubcomcrowdsourcingminingtacma
text generation may require pluralization noun contextsensitive user interface natural language generation broadly solved widelyused language still challenge language bantu language family pluralization result obtained isizulu runyankore showed similarity approach including need combine syntax semantics despite belonging different language zone suggests bootstrapping generalizability might feasible investigated systematically seven language across three different guthrie language zone first outcome meinhofs specification noun class indeed inadequate computational purpose examined language due nondeterminism prefix thus redefined characteristic noun class table noun class second main result generic pluralizer achieved accuracy coverage testing random sample comparable languagespecific isizulu runyankore pluralizers
deploying largescale pretrained model prompttuning paradigm demonstrated promising performance fewshot learning particularly visionlanguage pretraining model vlptms intensively explored various fewshot downstream task however existing work apply vlptms visual task like image classification attempt made language task like text classification fewshot text classification feasible paradigm deploying vlptms align input sample category name via text encoders however lead waste visual information learned image encoders vlptms overcome drawback propose novel method named visual prompt tuning vpt best knowledge method first attempt deploy vlptm fewshot text classification task main idea generate image embeddings wrt category name visual prompt add aligning process extensive experiment show vpt achieve significant improvement zeroshot fewshot setting importantly vpt even outperforms recent prompttuning method five public text classification datasets
paper address problem building conceptual resource multilingual application describe new technique largescale construction chineseenglish lexicon verb using thematicrole information create link chinese english conceptual information present approach compensating gap existing resource resulting lexicon used multilingual application machine translation crosslanguage information retrieval
dialogue state tracking important component taskoriented dialogue system identify user goal request dialogue proceeds however previous model dependent dialogue slot model complexity soar number slot increase paper put forward slotindependent neural model sim track dialogue state keeping model complexity invariant number dialogue slot model utilizes attention mechanism user utterance system action sim achieves stateoftheart result woz dstc task model size previous model
nowadays research conducted field abstractive text summarization focus neuralbased model alone without considering combination knowledgebased approach could enhance efficiency direction work present novel framework combine sequencetosequence neuralbased text summarization along structure semanticbased methodology proposed framework capable dealing problem outofvocabulary rare word improving performance deep learning model overall methodology based welldefined theoretical model knowledgebased content generalization deep learning prediction generating abstractive summary framework composed three key element preprocessing task ii machine learning methodology iii postprocessing task preprocessing task knowledgebased approach based ontological knowledge resource word sense disambiguation named entity recognition along content generalization transforms ordinary text generalized form deep learning model attentive encoderdecoder architecture expanded enable coping coverage mechanism well reinforcement learning transformerbased architecture trained generalized version textsummary pair learning predict summary generalized form postprocessing task utilizes knowledge resource word embeddings word sense disambiguation heuristic algorithm based text similarity method order transform generalized version predicted summary final humanreadable form extensive experimental procedure three popular data set evaluates key aspect proposed framework obtained result exhibit promising performance validating robustness proposed approach
following recent advance large language model llm subsequent chat model new wave large visionlanguage model lvlms emerged model incorporate image input addition text perform task visual question answering image captioning story generation etc examine potential gender racial bias system based perceived characteristic people input image accomplish present new dataset pair parallel image everyday scenario pair dataset contains set aigenerated image people image highly similar term background visual content differ along dimension gender man woman race black white querying lvlms image observe significant difference response according perceived gender race person depicted
paper present novel highorder dependency parsing framework target nonprojective treebanks imitates human parses sentence intuitive way every step parse determines word easiest process among remaining word identifies head word fold head word work flexible enough augmented parsing technique
paper analyze nurse dialogue conversation data set manual transcription show feature recently medical risk management recognized important hospital patient carry medical risk management important model nursing activity well collect many accident incident example therefore researching strategy modeling nursing activity order understand enightingale project model nursing activity necessary collect data nurse activity actual situation accurately understand activity situation developed method determine type nursing activity voice data however found method could determine several activity misunderstood special nursing term improve accuracy method focus analyzing nurse dialogue conversation data collecting special nursing term already collected hour nurse dialogue conversation data set hospital find tendency feature nurse use special term abbreviation jargon well new term consequently paper categorize nursing term according usage effectiveness addition based result show rough strategy building nursing dictionary
address problem determining entityoriented polarity business news viewed classifying polarity sentiment expressed toward given mention company news article present complete endtoend approach problem introduce new dataset manually labeled document substantially larger currently available resource propose benchmark solution based convolutional neural network classifying entityoriented polarity although dataset much larger currently available small scale datasets commonly used training robust neural network model compensate use transfer learningpretrain model much larger dataset annotated related different classification task order learn good representation business text finetune smaller polarity dataset
fake news detection dravidian language shared task identifies youtube comment malayalam language fake news detection work proposed transformerbased model crossentropy loss focal loss classifies comment fake authentic news used different transformerbased model dataset modification experimental setup finetuned model based muril focal loss achieved best overall macro fscore got second position final leaderboard
proper name organisation special case collective noun meaning conceptualised collective unit plurality person allowing different morphological marking coreferent anaphoric pronoun paper explores variability reference organisation name corpus analysis two crowdsourced story continuation experiment first show preference singular v plural conceptualisation dependent level formality text second observe strong preference plural otherwise typical informal speech using edited corpus data instead constructed sentence stimulus reduces preference
commonsense knowledge graph cskgs crucial commonsense reasoning yet constructing human annotation costly result various automatic method proposed construct cskg larger semantic coverage however unsupervised approach introduce spurious noise lower quality resulting cskg tackled easily existing denoising algorithm due unique characteristic node structure cskgs address issue propose gold global localaware denoising denoising framework cskgs incorporates entity semantic information global rule local structural information cskg experiment result demonstrate gold outperforms baseline method noise detection task synthetic noisy cskg benchmark furthermore show denoising realworld cskg effective even benefit downstream zeroshot commonsense questionanswering task code data publicly available httpsgithubcomhkustknowcompgold
sentiment analysis provides useful overview customer review content many review website allow user enter summary addition full review intuitively summary information may give additional benefit review sentiment analysis paper conduct study exploit method better use summary information start finding sentimental signal distribution review corresponding summary fact complementary thus explore various architecture better guide interaction two propose hierarchicallyrefined reviewcentric attention model empirical result show reviewcentric model make better use userwritten summary review sentiment analysis also effective compared existing method user summary replaced summary generated automatic summarization system
dialogue system potential change people interact machine highly dependent quality data used train therefore important develop good dialogue annotation tool improve speed quality dialogue data annotation mind introduce lida annotation tool designed specifically conversation data far know lida first dialogue annotation system handle entire dialogue annotation pipeline raw text may output transcription service structured conversation data furthermore support integration arbitrary machine learning model annotation recommenders also dedicated interface resolve interannotator disagreement crowdsourcing annotation dataset lida fully open source documented publicly availableurlhttpsgithubcomwluperlida textgreater screen cast urlhttpsvimeocom
paper present autobank prototype tool constructing widecoverage minimalist grammar mg stabler semiautomatically converting penn treebank ptb deep minimalist treebank front end tool graphical user interface facilitates rapid development seed set mg tree via manual reannotation ptb preterminals mg lexical category system extract various dependency mapping source target tree us concert nonstatistical mg parser automatically reannotate rest corpus autobank thus enables deep treebank conversion subsequent modification without need complex transduction algorithm accompanied cascade ad hoc rule instead locus human effort fall directly task grammar construction
dialogue system need produce response realize multiple type dialogue act da high semantic fidelity past natural language generator nlgs dialogue trained large parallel corpus map domainspecific da semantic attribute output utterance recent work show pretrained language model llm offer new possibility controllable nlg using promptbased learning develop novel fewshot overgenerateandrank approach achieves controlled generation da compare eight fewshot prompt style include novel method generating textual pseudoreferences using textual style transfer approach develop six automatic ranking function identify output correct da high semantic accuracy generation time test approach three domain four llm knowledge first work nlg dialogue automatically rank output using da attribute accuracy completeness compare result finetuned fewshot model trained instance per da result show several prompt setting achieve perfect da accuracy near perfect semantic accuracy perform better fewshot finetuning
present two method improve assessment cognitive model first method applicable model computing average acceptability rating model propose extension simulates full rating distribution instead average rating allows generating individual rating second method enables bayesian inference model generating individual data end propose use crossmatch test rosenbaum likelihood function exemplarily present method using cognitive model domain spatial language use spatial language use determining linguistic acceptability judgment spatial preposition depicted spatial relation assumed crucial process logan sadler existing model process compute average acceptability rating extend model based existing data show extended model allow extracting information empirical data yield readily interpretable information model success failure applying bayesian inference find model performance relies less mechanism capturing geometrical aspect mapping captured geometry rating interval
goal documentgrounded dialogue docgd generate response anchoring evidence supporting document accordance dialogue context entail four causally interconnected variable taskspecific pretraining significantly enhanced performance numerous downstream task existing docgd method still rely general pretrained language model without specifically tailored pretraining approach explicitly capture causal relationship address present first causallycomplete dataset construction strategy developing millionscale docgd pretraining corpus additionally propose causallyperturbed pretraining strategy better capture causality introducing perturbation variable optimizing overall causal effect experiment conducted three benchmark datasets demonstrate causal pretraining yield substantial consistent improvement fullysupervised lowresource fewshot zeroshot setting
large language model llm recently gained incontext learning icl ability model scaling allowing quickly adapt downstream task demonstration example prepended input sequence nonetheless current practice icl treat demonstration example equally still warrant improvement quality example usually uneven paper investigate determine approximately optimal weight demonstration example apply icl assess quality weight absence additional validation data design masked selfprediction msp score exhibit strong correlation final icl performance expedite weightsearching process discretize continuous weight space adopt beam search approximately optimal weight obtained propose two strategy apply demonstration different model position experimental result text classification task show approach outperforms conventional icl large margin code publicly available httpsgithubcomzheyoungwicl
paper describe submission codemixed machine translation mixmt shared task mixmt objective translate hinglish english vice versa submission focused codemixed pretraining multiway finetuning submission achieved rank term automatic evaluation score hinglish english translation submission achieved rank well
paper investigates construction strong baseline based general purpose sequencetosequence model constituency parsing incorporate several technique mainly developed natural language generation task eg machine translation summarization demonstrate sequencetosequence model achieves current topnotch parser performance almost without requiring explicit taskspecific knowledge architecture constituent parsing
large amount research multimodal inference across text vision recently developed obtain visually grounded word sentence representation paper use logicbased representation unified meaning representation text image present unsupervised multimodal logical inference system effectively prove entailment relation show combining semantic parsing theorem proving system handle semantically complex sentence visualtextual inference
natural language analysis system combine knowledgebased corpusbased method becoming accurate enough used various application describe one parsing system dutch known alpino show corpusbased method essential obtain accurate knowledgebased parser particular show variety case large amount parser output used improve parser
paper explore three unsupervised learning model applied task brainteaser semeval two model incorporate word sense disambiguation partofspeech tagging specifically leveraging sensembert stanford loglinear partofspeech tagger third model relies traditional language modelling approach best performing model bagofwords model leveraging word sense disambiguation partofspeech tagging secured th spot place sentence puzzle word puzzle subtasks
resource paper introduces dataset multiscale rating inference film review score based upon review summary dataset task unique pairing text regression problem rating given multiple scale eg af letter scale point star scale retains entity identifier film reviewer name paper describes construction dataset exploring potential baseline architecture task evaluating performance baseline based classifierperscale affineperscale ordinal regression model presented evaluated bertbase backbone additional experiment used ground discussion different architecture merit drawback regard explainability model interpretation
paper describes method temporal meaning shift detection implemented tempowic shared task present two system without time span data usage approach based language model finetuned twitter domain system outperformed competition baseline except timelmssim best submission achieved macrof score took th place result achieved using diachronic language model timelms project
codeswitching prevalent linguistic phenomenon multilingual individual seamlessly alternate language despite widespread use online recent research trend area research codeswitching present unique challenge primarily stemming scarcity labelled data available resource study investigate pretrained language model handle codeswitched text three dimension ability plms detect codeswitched text b variation structural information plms utilise capture codeswitched text c consistency semantic information representation codeswitched text conduct systematic controlled evaluation language model question create novel dataset wellformed naturalistic codeswitched text along parallel translation source language finding reveal pretrained language model effective generalising codeswitched text shedding light ability model generalise representation c corpus release code data including novel corpus httpsgithubcomfrancesitacodemixedprobes
paper present killkan first dataset automatic speech recognition asr kichwa language indigenous language ecuador kichwa extremely lowresource endangered language resource killkan kichwa incorporated application natural language processing dataset contains approximately hour audio transcription translation spanish morphosyntactic annotation format universal dependency done elan annotation software audio data retrieved publicly available radio program kichwa paper also provides corpuslinguistic analysis dataset special focus agglutinative morphology kichwa frequent codeswitching spanish experiment show dataset make possible develop first asr system kichwa reliable quality despite small dataset size dataset asr model code used develop publicly available thus study positively showcase resource building application lowresource language community
computational psycholinguistics various language model evaluated human reading behavior eg eye movement build humanlike computational model however previous effort focused almost exclusively english despite recent trend towards linguistic universal within general community order fill gap paper investigates whether established result computational psycholinguistics generalized across language specifically reexamine established generalization textitthe lower perplexity language model humanlike language model japanese typologically different structure english experiment demonstrate established generalization exhibit surprising lack universality namely lower perplexity always humanlike moreover discrepancy english japanese explored perspective nonuniform information density overall result suggest crosslingual evaluation necessary construct humanlike computational model
neural machine translation nmt word represented lowdimension realvalue vector encoding syntax semantic information mean even word different sentence context represented fixed vector learn source representation moreover large number outofvocabulary oov word different syntax semantic information represented vector representation unk alleviate problem propose novel contextaware smoothing method dynamically learn sentencespecific vector word including oov word depending local context word sentence learned contextaware representation integrated nmt improve translation performance empirical result nist chinesetoenglish translation task show proposed approach achieves bleu improvement average strong attentional nmt outperforms existing system
work partofspeech po tagging focused high resource language examines lowresource active learning setting simulated study evaluate po tagging technique actual endangered language griko present resource contains narrative griko along sentencelevel translation italian provides gold annotation test set based previously collected small corpus investigate several traditional method well method take advantage monolingual data project crosslingual po tag show combination semisupervised method crosslingual transfer appropriate extremely challenging setting best tagger achieving accuracy applied active learning scheme use collect sentencelevel annotation test set achieve improvement percentage point
recent advance pretrained multilingual model multilingual mt facilitated crosslingual transfer learning shared representation across language leveraging pretrained multilingual model scaling morphology analyzer lowresource language unique opportunity underexplored far investigate line research context indian language focusing two important morphological subtasks root word extraction tagging morphosyntactic description msd viz gender number person gnp experiment six indian language two language family dravidian indoaryan train multilingual morphology analyzer first time indian language demonstrate usability multilingual model fewshot crosslingual transfer average increase gnp tagging crosslingual setting compared monolingual setting controlled experiment provide overview state datasets available related task pointout modeling limitation due datasets lastly analyze crosslingual transfer morphological tag verb noun provides proxy quality representation word marking learned model
parsing morphologicallyrich language neural model beneficial model input character level claimed characterlevel model learn morphology test claim comparing characterlevel model oracle access explicit morphological analysis twelve language varying morphological typology result highlight many strength characterlevel model also show poor disambiguating word particularly face case syncretism demonstrate explicitly modeling morphological case improves best model showing characterlevel model benefit targeted form explicit morphological modeling
order successfully model long distance dependency ldds necessary understand fullrange characteristic ldds exhibited target dataset paper use strictly kpiecewise language generate datasets various property compute characteristic ldds datasets using mutual information analyze impact factor k ii length ldds iii vocabulary size iv forbidden string v dataset size analysis reveal number interacting element dependency important characteristic ldds lead u challenge modelling multielement longdistance dependency result suggest attention mechanism neural network may aide modeling datasets multielement longdistance dependency however conclude need develop efficient attention mechanism address issue
article outline evaluation protocol provides main result french evaluation campaign machine translation system cesta following initial objective evaluation plan evaluation metric briefly described along fluency adequacy assessed human judge number recently proposed automated metric used two evaluation campaign organized first one general domain second one medical domain six system translating english french two system translating arabic french took part campaign numerical result illustrate difference class system provide interesting indication reliability automated metric french target language comparison human judge using correlation metric corpus produced well information reliability metric constitute reusable resource mt evaluation
article ongoing research presented immediate goal create corpus annotated semantic role label hungarian used train parserbased system capable formulating relevant question text process briefly describe objective research effort eliminating error hungarian universal dependency corpus use base annotation effort creating hungarian verbal argument database annotated thematic role classifying adjunct matching verbal argument frame specific occurrence verb participle corpus
instructionfinetuned large language model llm gained huge popularity recently thanks ability interact user conversation work aim evaluate ability complete multiturn task interact external database context established taskoriented dialogue benchmark show explicit belief state tracking llm underperform compared specialized taskspecific model nevertheless show ability guide dialogue successful ending generated response provided correct slot value furthermore ability improves fewshot indomain example
natural language understanding recently seen surge progress use sentence encoders like elmo peter et al bert devlin et al pretrained variant language modeling conduct first largescale systematic study candidate pretraining task comparing different task alternative complement language modeling primary result support use language modeling especially combined pretraining additional labeleddata task however result mixed across pretraining task show concerning trend elmos pretrainthenfreeze paradigm random baseline worryingly strong result vary strikingly across target task addition finetuning bert intermediate task often negatively impact downstream transfer positive trend see modest gain multitask training suggesting development sophisticated multitask transfer learning technique avenue research
querybased text summarization aimed extracting essential information answer query original text answer presented minimal often predefined number word paper introduce new unsupervised approach querybased extractive summarization based minimum description length mdl principle employ krimp compression algorithm vreeken et al key idea approach select frequent word set related given query compress document sentence better therefore describe document better summary extracted selecting sentence best cover queryrelated frequent word set approach evaluated based duc duc datasets specifically designed querybased summarization duc competes best result
generalization model outofdistribution ood data captured tremendous attention recently specifically compositional generalization ie whether model generalizes new structure built component observed training sparked substantial interest work investigate compositional generalization semantic parsing natural testbed compositional generalization output program constructed subcomponents analyze wide variety model propose multiple extension attention module semantic parser aiming improve compositional generalization find following factor improve compositional generalization using contextual representation elmo bert b informing decoder input token previously attended c training decoder attention agree precomputed token alignment downsampling example corresponding frequent program template substantially reduce gap indistribution ood generalization performance ood composition still substantially lower
heart failure global epidemic debilitating effect people heart failure need actively participate home selfcare regimen maintain good health however regimen effective could influenced variety factor patient minority community like african american aa hispaniclatino hl often poor outcome compared average caucasian population paper lay groundwork develop interactive dialogue agent assist aa hl patient culturally sensitive linguistically accurate manner heart health care need achieved extracting relevant educational concept interaction health educator patient thus far recorded transcribed interaction paper describe data collection process thematic initiative analysis interaction outline future step
paper proposes new crossdocument coreference resolution cdcr dataset identifying coreferring radiological finding medical device across patient radiology report annotated corpus contains mention finding device spanning mimiciii radiology report across patient covering multiple imaging modality anatomy total mention chain describe annotation process detail highlighting complexity involved creating sizable realistic dataset radiology cdcr apply two baseline methodsstring matching transformer language model bertto identify crossreport coreference result indicate requirement model development targeting better understanding domain language context address challenging unexplored task dataset serve resource develop advanced natural language processing cdcr method future one first attempt focusing cdcr clinical domain hold potential benefiting physician clinical research longterm tracking radiology finding
present multimodal dialogue system allows doctor interact medical decision support system virtual reality vr integrate interactive visualization patient record radiology image data well therapy prediction therapy prediction computed realtime using deep learning model
continuing spread misinformation disinformation online increasing importance develop combating mechanism scale form automated system support multiple language one task interest claim veracity prediction addressed using stance detection respect relevant document retrieved online end present new arabic stance detection dataset arastance claimarticle pair diverse set source comprising three factchecking website one news website arastance cover false true claim multiple domain eg politics sport health several arab country wellbalanced related unrelated document respect claim benchmark arastance along two stance detection datasets using number bertbased model best model achieves accuracy macro f score leaf room improvement reflects challenging nature arastance task stance detection general
userdependency text simplification make evaluation obscure targeted evaluation dataset clarifies purpose simplification though specification hard define built jade japanese dataset evaluation simplification text simplification dataset targeted nonnative japanese speaker according public vocabulary grammar profile jade comprises complexsimple sentence pair annotated expert analysis jade show wide multiple rewriting operation applied simplification furthermore analyzed output jade several benchmark system automatic manual score result analysis highlight difference english japanese operation evaluation
entity linking wellestablished task nlp consisting associating entity mention entry knowledge base current model demonstrated competitive performance standard text setting however come noisy domain social medium certain challenge still persist typically evaluate entity linking existing benchmark comprehensive knowledge base necessary model expected possess understanding entity contained within knowledge base however practical scenario objective retrieve sentence specifically related particular entity strict adherence complete understanding entity knowledge base may necessary address gap introduce tweetter tweet target entity retrieval novel benchmark aim bridge challenge entity linking distinguishing feature benchmark approach reframing entity linking binary entity retrieval task enables evaluation language model performance without relying conventional knowledge base providing practical versatile evaluation framework assessing effectiveness language model entity retrieval task
intelligent dialogue system multiturn setting generate response good quality also generate response lead longterm success dialogue although current approach improved response quality overlook training signal present dialogue data leverage signal generate weakly supervised training data learning dialog policy reward estimator make policy take action generates response foresee future direction successful rewarding conversation simulate dialogue agent user modelled similar agent supervised learning objective interact agent us dynamic blocking generate ranked diverse response explorationexploitation select among topk response simulated stateaction pair evaluated work weak annotation three quality module semantic relevant semantic coherence consistent flow empirical study two benchmark indicate model significantly outperform response quality lead successful conversation automatic evaluation human judgment
emoji one fastest growing language popculture especially social medium unlikely usage decrease generally used bring extra level meaning text posted social medium platform providing added info give insight plain text arising hidden interpretation within text paper explains analysis task multilingual emoji prediction sharedtask conducted semeval task predicted emoji based piece twitter text labelled different class commonly used emojis class learnt predicted made unseen twitter text work experimented analysed emojis predicted based twitter text classification problem entailing emoji considered label every individual text data implemented using distributed representation text fasttext also made effort demonstrate fasttext framework useful case emoji prediction task divide two subtask based dataset presented two different language english spanish
modern language model often exhibit powerful brittle behavior leading development larger diverse benchmark reliably assess behavior suggest model performance benchmarked elucidated much smaller evaluation set first show six popular language classification benchmark model confidence correct class many pair point strongly correlated across model build upon phenomenon propose anchor point selection technique select small subset datasets capture model behavior across entire dataset anchor point reliably rank model across diverse language modelprompt pair evaluating model using anchor point outperforms uniform sampling baseline accurately ranking model moreover dozen anchor point used estimate model perclass prediction point dataset low error sufficient gauging model likely fail lastly present anchor point map visualizing insight facilitating comparison performance different model various region within dataset distribution
discourse segmentation crucial step building endtoend discourse parser however discourse segmenters exist language domain typically detect intrasentential segment boundary assuming gold standard sentence token segmentation relying highquality syntactic parses rich heuristic generally available across language domain paper propose statistical discourse segmenters five language three domain rely gold preannotations also consider problem learning discourse segmenters labeled data available language fully supervised system obtains f english newswire slight drop performance domain report supervised unsupervised crosslingual result five language total
understand kind linguistic knowledge encoded pretrained chinese language model lm introduce benchmark sino linguistics sling consists k minimal sentence pair mandarin chinese grouped highlevel linguistic phenomenon pair demonstrates acceptability contrast specific syntactic semantic phenomenon eg key lost v key lost lm assign lower perplexity acceptable sentence contrast climp dataset xiang et al also contains chinese minimal pair created translating vocabulary english blimp dataset minimal pair sling derived primarily applying syntactic lexical transformation naturallyoccurring linguistannotated sentence chinese treebank thus addressing severe issue climps data generation process test publicly available pretrained monolingual eg bertbasezh cpm multilingual eg mt xlm language model sling experiment show average accuracy lm far human performance v bertbasezh achieves highest accuracy tested lm even much larger one additionally find lm strong gender number singularplural bias perform better local phenomenon hierarchical one
paper report development hungarian gigaword corpus hgc extended new edition hungarian national corpus upgraded redesigned linguistic annotation increased size billion token issue concerning standard step corpus collection preparation discussed special emphasis linguistic analysis annotation due hungarian challenging characteristic respect computational processing hgc designed serve resource wide range linguistic research well interested public number issue resolved raised trying find balance two application area following main objective defined development hgc focusing pivotal concept increase size extending corpus minimum billion word quality using new technology development analysis coverage representativity taking new sample language use including variant transcribed spoken language data user generated content social medium internet particular
deep neural network dnn widely employed industry address various natural language processing nlp task however many engineer find big overhead choose multiple framework compare different type model understand various optimization mechanism nlp toolkit dnn model generality flexibility greatly improve productivity engineer saving learning cost guiding find optimal solution task paper introduce neuronblocks toolkit encapsulating suite neural network module building block construct various dnn model complex architecture toolkit empowers engineer build train test various nlp model simple configuration json file experiment several nlp datasets glue wikiqa conll demonstrate effectiveness neuronblocks code urlhttpsgithubcommicrosoftneuronblocks demo urlhttpsyoutubexcopvszcdo
general domain named entity recognition ner datasets like conll mostly annotate coarsegrained location entity country city many application require identifying finegrained location text mapping precisely geographic site eg crossroad apartment building grocery store paper introduce new dataset harveyner finegrained location annotated tweet dataset present unique challenge characterizes many complex long location mention informal description built strong baseline model using curriculum learning experimented different heuristic curriculum better recognize difficult location mention experimental result show simple curriculum improve system performance hard case overall performance outperform several baseline system dataset baseline model found urlhttpsgithubcombrickeeharveyner
endtoend question answering using differentiable knowledge graph promising technique requires weak supervision produce interpretable result fully differentiable previous implementation technique cohen et al focused singleentity question using relation following operation paper propose model explicitly handle multipleentity question implementing new intersection operation identifies shared element two set entity find introducing intersection improves performance baseline model two datasets webquestionssp hit complexwebquestions hit particular improves performance question multiple entity webquestionssp complexwebquestions
present first supervised approach rhyme detection siamese recurrent network srn offer near perfect performance accuracy single model rhyme pair german english french allowing future large scale analysis srns learn similarity metric variable length character sequence used judgement distance imperfect rhyme pair binary classification training construct diachronically balanced rhyme goldstandard new high german nhg poetry testing sample second collection nhg poetry set contemporary hiphop lyric annotated rhyme assonance train several highperforming srn model evaluate qualitatively selected sonnetts
paper present submission semeval task suggestion mining system one series system compare approach using expertdefined rule comparable one using machine learning target task syntactic semantic component might better described human understanding task machine learner able count feature semeval task expert rule clearly outperformed machine learning model training testing equally balanced testsets
sequential finetuning multitask learning method aiming incorporate knowledge multiple task however suffer catastrophic forgetting difficulty dataset balancing address shortcoming propose adapterfusion new two stage learning algorithm leverage knowledge multiple task first knowledge extraction stage learn task specific parameter called adapter encapsulate taskspecific information combine adapter separate knowledge composition step show separating two stage ie knowledge extraction knowledge composition classifier effectively exploit representation learned multiple task nondestructive manner empirically evaluate adapterfusion diverse nlu task find effectively combine various type knowledge different layer model show approach outperforms traditional strategy full finetuning well multitask learning code adapter available adapterhubml
question answering qa question generation qg closely related task could improve however connection two task well explored literature paper give systematic study seek leverage connection improve qa qg present training algorithm generalizes generative adversarial network gan generative domainadaptive net gdan question answering scenario two key idea improving qg model qa incorporating additional qaspecific signal loss function improving qa model qg adding artificially generated training instance conduct experiment document based knowledge based question answering task two main finding firstly performance qg model eg term bleu score could easily improved qa model via policy gradient secondly directly applying gan regard generated question negative instance could improve accuracy qa model learning regard generated question positive instance could bring performance boost
paper study problem answering clozestyle question document model gatedattention ga reader integrates multihop architecture novel attention mechanism based multiplicative interaction query embedding intermediate state recurrent neural network document reader enables reader build queryspecific representation token document accurate answer selection ga reader obtains stateoftheart result three benchmark taskthe cnn daily mail news story dataset effectiveness multiplicative interaction demonstrated ablation study comparing alternative compositional operator implementing gatedattention
language used online forum differs many way traditional language resource news one difference use frequency nonliteral subjective dialogue act sarcasm whether aim develop theory sarcasm dialogue engineer automatic method reliably detecting sarcasm major challenge simply difficulty getting enough reliably labelled example paper describe work method achieving highly reliable sarcasm annotation untrained annotator mechanical turk explore use number common statistical reliability measure kappa kargers majority class em show sophisticated measure appear yield better result data simple measure assuming correct label one majority turkers apply
large howto website wikihows mission empower every person planet learn anything important part including everyone also linguistically use genderneutral language short paper study far article wikihow fulfill criterion based manual annotation automatic classification particular employ classifier analyze use genderneutral language developed time result show although article wikihow written genderneutral way outset revision higher tendency add genderspecific language change inclusive wording
large language model llm significantly advanced field natural language processing nlp lack interpretability major concern current method interpreting llm post hoc applied inference time limitation focus lowlevel feature lack explainability higherlevel text unit work introduce protolm prototypical networkbased whitebox framework allows llm learn immediately interpretable embeddings finetuning stage maintaining competitive performance method applicability interpretability demonstrated experiment wide range nlp task result indicate new possibility creating interpretable model without sacrificing performance novel approach interpretability llm pave way interpretable model without need sacrifice performance release code httpsgithubcomyxprotolm
textual deepfakes cause harm especially social medium moment model trained detect deepfake message mainly english language research datasets currently exist detecting lowresource language bulgarian address gap explore three approach first machine translate englishlanguage social medium dataset bot message bulgarian however translation quality unsatisfactory leading u create new bulgarianlanguage dataset real social medium message generated two language model new bulgarian gpt model gptwebbg chatgpt machine translate english test existing english gpt chatgpt detector achieving accuracy next train classifier bulgarian dataset obtaining accuracy additionally apply classifier highest result recently released bulgarian social medium dataset manually factchecked message successfully identifies message generated language model lm result show use machine translation suitable textual deepfakes detection conclude combining lm text detection factchecking appropriate method task identifying bulgarian textual deepfakes indeed possible
transformerbased language model lm offer superior performance wide range nlp task compared previous paradigm however vast majority world language adequate training data available monolingual lm joshi et al use multilingual lm might address data imbalance evidence multilingual lm struggle come model adaptation resourcepoor language wu dredze language typological characteristic unseen lm ustun et al approach aim adapt monolingual lm resourcepoor language related model language however conflicting finding regarding whether language relatedness correlate successful adaptation de vries et al ac et al gradual lm adaptation approach presented extended abstract add research direction monolingual lm adaptation instead direct adaptation target language propose adaptation stage first adapting one intermediate language final adaptation step inspired principle curriculum learning bengio et al search ideal ordering language result improved lm performance target language follow evidence typological similarity might correlate success crosslingual transfer pires et al ustun et al de vries et al believe success transfer essential successful model adaptation thus order language based relative typological similarity approach quantify typological similarity using structural vector derived count dependency link bjerva et al finegrained measure give accurate picture typological characteristic language ponti et al believe gradual lm adaptation may lead improved lm performance range resourcepoor language typologically diverse language additionally enables future research evaluate correlation success crosslingual transfer various typological similarity measure
subtitling audiovisual translation recognized area could greatly benefit introduction statistical machine translation smt followed postediting order increase efficiency subtitle production process fp european project sumat online service subtitling machine translation urlhttpwwwsumatprojecteu aim develop online subtitle translation service nine european language combined different language pair order semiautomate subtitle translation process freelance translator subtitling company large scale paper discus data collection parallel corpus compilation training smt system includes several procedure data partition conversion formatting normalization alignment discus detail data preprocessing step using various approach apart quantity around million subtitle per language pair sumat corpus number important characteristic first high quality term translation term highprecision alignment parallel document content achieved secondly content provided one consistent format encoding finally additional information type content term genre domain available
multilingual speaker switch language nontrivial fashion displaying inter sentential intra sentential congruent lexicalization based transition monolingual asr system may capable recognizing word foreign language usually robust enough handle varied style codeswitching also lack large codeswitched speech corpus capturing style making difficult build codeswitched speech recognition system hypothesize may useful asr system able first detect switching style particular utterance acoustic use specialized language model adaptation technique decoding speech paper look first problem detecting codeswitching style acoustic classify codeswitched spanishenglish hindienglish corpus using two metric show feature extracted acoustic alone distinguish different kind codeswitching language pair
propose use wordnet synset syntaxbased reordering model hierarchical statistical machine translation hpbsmt enable model generalize phrase seen training data equivalent meaning detail methodology incorporate synset knowledge reordering model evaluate resulting wordnetenhanced smt system englishtofarsi language direction inclusion synset lead best bleu score outperforming baseline standard hpbsmt point absolute
present use countbased predictive language model exploring language use german reference corpus dereko collocation analysis along syntagmatic axis employ traditional association measure based cooccurrence count well predictive association measure derived output weight skipgram word embeddings inspecting semantic neighbourhood word along paradigmatic axis visualize high dimensional word embeddings two dimension using tstochastic neighbourhood embeddings together visualization provide complementary explorative approach analysing large corpus addition corpus querying moreover discus countbased predictive model wrt scalability maintainability large corpus
simile play imperative role creative writing story dialogue generation proper evaluation metric like beacon guiding research simile generation sg however remains underexplored criterion considered quantify criterion metric whether metric effective comprehensive efficient reliable sg evaluation address issue establish hauser holistic automatic evaluation system sg task consists five criterion three perspective automatic metric criterion extensive experiment verify metric significantly correlated human rating perspective compared prior automatic metric resource hauser publicly available urlhttpsgithubcomabbeyhauser
supervised model based transformer shown achieve impressive performance many natural language processing task however besides requiring large amount costly manually annotated data supervised model tend adapt characteristic training dataset usually created adhoc whose data distribution often differs one real application showing significant performance degradation realworld scenario perform extensive assessment outofdistribution performance supervised model classification emotion hatespeech detection task show nlibased zeroshot model often outperform making taskspecific annotation useless characteristic finaluser data known advance benefit supervised zeroshot approach propose finetune nlibased model taskspecific dataset resulting model often outperforms available supervised model distribution distribution thousand training sample
present crosslinguistic study vowel harmony aim quantifies phenomenon using datadriven computational modeling concretely define informationtheoretic measure harmonicity based predictability vowel natural language lexicon estimate using phonemelevel language model plms prior quantitative study heavily relied inflected wordforms analysis vowel harmony contrary train model using crosslinguistically comparable lemma form little inflection enables u cover understudied language training data plms consists word list offering maximum entry per language despite fact data employ substantially smaller previously used corpus experiment demonstrate neural plms capture vowel harmony pattern set language exhibit phenomenon work also demonstrates word list valuable resource typological research offer new possibility future study lowresource understudied language
current abstractive summarization system tend hallucinate content unfaithful source document posing risk misinformation mitigate hallucination must teach model distinguish hallucinated summary faithful one however commonly used maximum likelihood training disentangle factual error model error address issuewe propose backtranslationstyle approach augment negative sample mimic factual error made model specifically train elaboration model generates hallucinated document given reference summary generates negative summary fake document incorporate negative sample training controlled generator produce faithfulunfaithful summary conditioned control code additionally find adding textual entailment data multitasking boost performance experiment three datasets xsum gigaword wikihow show method consistently improves faithfulness without sacrificing informativeness according human automatic evaluation
researcher witnessing knowledgeinspired natural language processing shift focus entitylevel eventlevel whereas event coreference resolution one core challenge paper proposes novel model withindocument event coreference resolution basis event entity model learns integrates multiple representation event alone event pair former introduce multiple linguisticsmotivated event alone feature discriminative event representation latter consider multiple similarity measure capture distinction event pair proposed model achieves new stateoftheart ace benchmark demonstrating effectiveness proposed framework
growing evidence change speech language may early marker dementia much previous nlp work area limited size available datasets compare several method domain adaptation augment small french dataset picture description n much larger english dataset n task automatically distinguishing participant dementia control first challenge identify set feature transfer across language addition previously used feature based information unit introduce new set feature model order information unit produced dementia patient control conceptbased language model feature improve classification performance english french separately best result auc achieved using multilingual training set combination information language model feature
lay summarization aim simplify complex scientific information nonexpert audience paper investigates tradeoff readability relevance lay summarization long biomedical document introduce twostage framework attains best readability metric first subtask biolaysumm fleschkincaid grade level dalechall readability score however come cost reduced relevance factuality emphasizing inherent challenge balancing readability content preservation lay summarization first stage generates summary using large language model bart lsg attention second stage us zeroshot sentence simplification method improve readability summary second subtask hybrid dataset employed train model capable generating lay summary abstract approach achieves best readability score share top overall rank leading method study underscore importance developing effective method creating accessible lay summary maintaining information integrity future work integrate simplification summary generation within joint optimization framework generates highquality lay summary effectively communicate scientific content broader audience
main goal machine translation convey correct content stylistic consideration best secondary show consequence output three commercial machine translation system bing deepl google make demographically diverse sample five language sound older male original finding suggest translation model reflect demographic bias training data open interesting new research avenue machine translation take stylistic consideration account
formulate novel task automatically updating existing natural language comment based change body code accompanies propose approach learns correlate change across two distinct language representation generate sequence edits applied existing comment reflect source code modification train evaluate model using dataset collected commit history opensource software project example consisting concurrent update method corresponding comment compare approach multiple baseline using automatic metric human evaluation result reflect challenge task model outperforms baseline respect making edits
fast align simple fast word alignment tool widely used stateoftheart machine translation system yield comparable result endtoend translation experiment various language pair however fast align perform well giza applied language pair distinct word order like english japanese paper given lexical translation table output fast align propose realign word using hierarchical subsentential alignment approach experimental result show simple additional processing improves performance word alignment measured counting alignment match comparison fast align also report result final machine translation englishjapanese japaneseenglish show best system provided significant improvement baseline measured bleu ribes
retrieverreader pipeline shown promising performance opendomain qa suffers slow inference speed recently proposed question retrieval model tackle problem indexing questionanswer pair searching similar question model shown significant increase inference speed cost lower qa performance compared retrieverreader model paper proposes twostep question retrieval model squid sequential questionindexed dense retrieval distant supervision training squid us two biencoders question retrieval firststep retriever selects topk similar question secondstep retriever find similar question topk question evaluate performance computational efficiency squid result show squid significantly increase performance existing question retrieval model negligible loss inference speed
document alignment technique based multilingual sentence representation recently shown state art result however technique rely unsupervised distance measurement technique finedtuned task hand paper instead unsupervised distance measurement technique employ metric learning derive taskspecific distance measurement measurement supervised meaning distance measurement metric trained using parallel dataset using dataset belonging english sinhala tamil belong three different language family show taskspecific supervised distance learning metric outperform unsupervised counterpart document alignment
medium indispensable source information opinion shaping belief attitude society obviously medium portal also provide overly biased content eg reporting political event selective incomplete manner relevant question hence whether form unfair news coverage exposed paper address automatic detection bias go one step explores political bias unfairness manifested linguistically utilize new corpus news article label derived adfontesmediacom develop neural model bias assessment analyzing model article excerpt find insightful bias pattern different level text granularity single word whole article discourse
propose graphbased method tackle dependency tree linearization task formulate task traveling salesman problem tsp use biaffine attention model calculate edge cost facilitate decoding solving tsp subtree combining solution projective tree design transition system postprocessing inspired nonprojective transitionbased parsing obtain nonprojective sentence proposed method outperforms stateoftheart linearizer time faster training decoding
given text query task natural language video localization nlvl localize temporal moment untrimmed video semantically match query paper adopt proposalbased solution generates proposal ie candidate moment select best matching proposal top modeling crossmodal interaction candidate moment query proposed moment sampling detr msdetr enables efficient momentmoment relation modeling core idea sample subset moment guided learnable template adopted detr framework achieve design multiscale visuallinguistic encoder anchorguided moment decoder paired set learnable template experimental result three public datasets demonstrate superior performance msdetr
task shared sponsor hope speech detection equality diversity inclusion ltediaclthe goal task identify whether given comment contains hope speech notand hope considered significant wellbeing recuperation restoration human life work aim change prevalent way thinking moving away preoccupation discrimination loneliness worst thing life building confidence support good quality based comment individual response need detect equality diversity inclusion hope speech multilingual environment built integration model achieved well performance multiple datasets presented sponsor specific result referred experimental result section
string comparison method bleu papineni et al de facto standard mt evaluation mte mt system parameter tuning och difficult metric recognize legitimate lexical grammatical paraphrase important mt system tuning madnani present two method address shallow lexical substitution technique grammardriven paraphrasing technique grammatically precise paraphrasing novel context mte demonstrating usefulness key contribution paper use technique paraphrase single reference used parameter tuning lead superior translation performance baseline use humanauthored reference
paper present overview text visualization technique relevant data perspectivism aiming facilitate analysis annotated datasets datasets creator stakeholder data perspectivism advocate publishing nonaggregated annotated text data recognizing highly subjective task bias detection hate speech detection disagreement among annotator may indicate conflicting yet equally valid interpretation text publication nonaggregated annotated data make different interpretation text corpus available barrier still exist investigating pattern outlier annotation text technique text visualization overcome barrier facilitating intuitive data analysis nlp researcher practitioner well stakeholder nlp system may data science computing skill paper discus challenge current dataset creation practice annotation platform followed discussion text visualization technique enable openended multifaceted iterative analysis annotated data
mixed counting model use negative binomial distribution prior well model overdispersed hierarchically dependent random variable thus attracted much attention mining dispersed document topic however existing parameter inference method like monte carlo sampling quite timeconsuming paper propose two efficient neural mixed counting model ie negative binomialneural topic model nbntm gamma negative binomialneural topic model gnbntm dispersed topic discovery neural variational inference algorithm developed infer model parameter using reparameterization gamma distribution gaussian approximation poisson distribution experiment realworld datasets indicate model outperform stateoftheart baseline model term perplexity topic coherence result also validate nbntm gnbntm produce explainable intermediate variable generating dispersed proportion document topic
deep latent variable model lvm variational autoencoder vae recently played important role text generation one key factor exploitation smooth latent structure guide generation however representation power vaes limited due two reason gaussian assumption often made variational posterior meanwhile notorious posterior collapse issue occurs paper advocate samplebased representation variational distribution natural language leading implicit latent feature provide flexible representation power compared gaussianbased posterior develop lvm directly match aggregated posterior prior viewed natural extension vaes regularization maximizing mutual information mitigating posterior collapse issue demonstrate effectiveness versatility model various text generation scenario including language modeling unaligned style transfer dialog response generation source code reproduce experimental result available github
depression prevalent mental illness characterized feeling sadness lack interest daily activity early detection depression crucial prevent severe consequence making essential observe treat condition onset acl depsignltedi project aimed identify sign depression individual based social medium post people often share emotion feeling using social medium posting english system categorized depression sign three label depressed moderately depressed severely depressed achieve team applied mentalroberta model trained big data mental health test result indicated macro fscore ranking fourth shared task
annotated data essential ingredient natural language processing training evaluating machine learning model therefore desirable annotation high quality recent work however shown several popular datasets contain surprising number annotation error inconsistency alleviate issue many method annotation error detection devised year researcher show approach work well newly introduced datasets rarely compare method previous work datasets raise strong concern method general performance make difficult assess strength weakness therefore reimplement method detecting potential annotation error evaluate english datasets text classification well token span labeling addition define uniform evaluation setup including new formalization annotation error detection task evaluation protocol general best practice facilitate future research reproducibility release datasets implementation easytouse open source software package
recent research adopted new experimental field centered around concept text perturbation revealed shuffled word order little impact downstream performance transformerbased language model across many nlp task finding contradict common understanding model encode hierarchical structural information even question word order modeled position embeddings end paper proposes nine probing datasets organized type controllable text perturbation three indoeuropean language varying degree word order flexibility english swedish russian based probing analysis mbert mbart model report syntactic sensitivity depends language model pretraining objective also find sensitivity grows across layer together increase perturbation granularity last least show model barely use positional information induce syntactic tree intermediate selfattention contextualized representation
latest large language model lm support increasingly longer context trend permit using substantial amount text sota lm requiring large lm process potentially redundant irrelevant data needlessly increase inference time cost remedy problem propose blinder method leverage small finetuned lm sample minimal set input feature maximizes performance downstream lm blinder train lm value head estimate likelihood optimal output downstream lm given input evaluate blinder embodied decision making task notoriously verbose state description nethack robot planning blinder reduces length lm actor input improving task success rate nethack robot planning respectively represents substantial inference cost saving actually increasing performance
paper present multilingual natural language generation system produce technical instruction text bulgarian czech russian generates several type text common software manual two style illustrate system functionality example input output behaviour discus criterion procedure adopted evaluating system summarise result system embodies novel approach providing multilingual documentation ranging reuse largescale broad coverage grammar english order develop lexicogrammatical resource necessary generation three target language adoption knowledge editing approach specifying desired content text generated independently target language text finally appear
dealing multiple topic considered important issue dialogue summarization dialogue unlike document prone topic drift thus propose new dialogue summarization model reflects dialogue topic distribution consider topic present dialogue first distribution dialogue topic estimated effective topic discovery model topicinformed prompt transfer estimated topic distribution information output encoder decoder vector finally topic extractor estimate summary topic distribution output context vector decoder distinguish difference dialogue topic distribution consider proportion topic distribution appeared dialogue extractor trained reduce difference distribution dialogue summary experimental result samsum dialogsum show model outperforms stateoftheart method rouge score human evaluation result also show framework well generates comprehensive summary
hallmark variational autoencoders vaes text processing combination powerful encoderdecoder model lstms simple latent distribution typically multivariate gaussians model pose difficult optimization problem especially bad local optimum variational posterior always equal prior model use latent variable kind collapse encouraged kl divergence term objective work experiment another choice latent distribution namely von misesfisher vmf distribution place mass surface unit hypersphere choice prior posterior kl divergence term depends variance vmf distribution giving u ability treat fixed hyperparameter show averts kl collapse consistently give better likelihood gaussians across range modeling condition including recurrent language modeling bagofwords document modeling analysis property vmf representation show learn richer nuanced structure latent representation gaussian counterpart
sentence matching key issue natural language inference paraphrase identification despite recent progress multilayered neural network cross sentence attention one sentence learns attention intermediate representation another sentence propagated preceding layer therefore uncertain unstable matching particularly risk error propagation paper present original semanticsoriented attention deep fusion network osoadfn sentence matching unlike existing model attention layer osoadfn oriented original semantic representation another sentence capture relevant information fixed matching target multiple attention layer allow one sentence repeatedly read important information another sentence better matching additionally design deep fusion propagate attention information matching layer last introduce selfattention mechanism capture global context enhance attentionaware representation within sentence experiment result three sentence matching benchmark datasets snli scitail quora show osoadfn ability model sentence matching precisely
tokenization fundamental pretrained language model plms existing tokenization method chinese plms typically treat character indivisible token however ignore unique feature chinese writing system additional linguistic information exists character level ie subcharacter level utilize information propose subcharacter subchar short tokenization specifically first encode input text converting chinese character short sequence based glyph pronunciation construct vocabulary based encoded text subword segmentation experimental result show subchar tokenizers two main advantage existing tokenizers tokenize input much shorter sequence thus improving computational efficiency pronunciationbased subchar tokenizers encode chinese homophone transliteration sequence produce tokenization output hence robust homophone typo time model trained subchar tokenizers perform competitively downstream task release code model urlhttpsgithubcomthunlpsubchartokenization facilitate future work
paper address unsupervised chunking new task syntactic structure induction helpful understanding linguistic structure human language well processing lowresource language propose knowledgetransfer approach heuristically induces chunk label stateoftheart unsupervised parsing model hierarchical recurrent neural network hrnn learns induced chunk label smooth noise heuristic experiment show approach largely bridge gap supervised unsupervised chunking
effectiveness model heavily reliant quality fusion representation multiple modality multimodal sentiment analysis moreover modality extracted raw input integrated rest construct multimodal representation although previous method proposed multimodal representation achieved promising result focus forming positive negative pair neglecting variation sentiment score within class additionally fail capture significance unimodal representation fusion vector address limitation introduce framework called supervised angularbased contrastive learning multimodal sentiment analysis framework aim enhance discrimination generalizability multimodal representation overcome bias fusion vector modality experimental result along visualization two widely used datasets demonstrate effectiveness approach
interacting robot situated spoken dialogue setting human dialogue partner tend assign anthropomorphic social characteristic robot paper explore age educational level human dialogue partner assign three different robotic system including unembodied spoken dialogue system found robot speaks important human perception way robot look using data experiment derived prosodic emotional linguistic feature participant train evaluate classifier predicts perceived intelligence age education level
statistical machine translation smt system requires homogeneous training data order get domainsensitive contextsensitive terminology translation data contains various domain difficult smt learn contextsensitive terminology mapping probabilistically yet terminology translation accuracy important issue mt user paper explores approach tackle terminology translation problem smt propose way identify terminology translation mt output automatically swap userdefined translation approach simple applied type mt system call prototype term swapper term swapper allows mt user draw dictionary without affecting part mt output except terminology translation question using smt developed microsoft research called msrmt quirk et al menezes quirk conducted initial experiment investigate coverage rate term swapper impact overall quality mt output result experiment show high coverage positive impact overall mt quality
crosslingual annotation projection practical method improving performance low resource structured prediction task important step annotation projection obtaining alignment source target text enables mapping annotation across text manually correcting automatically generated alignment examine impact alignment qualityautomatic manual mixedon downstream performance two information extraction task quantify tradeoff annotation effort model performance
diacritic restoration gained importance growing need machine understand written text task typically modeled sequence labeling problem currently bidirectional long short term memory bilstm model provide stateoftheart result recently bai et al show advantage temporal convolutional neural network tcn recurrent neural network rnn sequence modeling term performance computational resource diacritic restoration benefit previous well subsequent timesteps apply evaluate variant tcn acausal tcn atcn incorporates context direction previous future rather strictly incorporating previous context case tcn atcn yield significant improvement tcn diacritization three different language arabic yoruba vietnamese furthermore atcn bilstm comparable performance making atcn efficient alternative bilstm since convolution trained parallel atcn significantly faster bilstm inference time improvement amount text diacritized per minute
paper describe ongoing work circumstantial event ontology ceo newly developed ontology calamity event model semantic circumstantial relation event class circumstantial relation designed manually based shared property event class discus contrast two type event circumstantial relation semantic circumstantial relation episodic circumstantial relation show metamodel current content ontology outline evaluation ceo
introduce bitfit sparsefinetuning method biasterms model subset modified show smalltomedium training data applying bitfit pretrained bert model competitive sometimes better finetuning entire model larger data method competitive sparse finetuning method besides practical utility finding relevant question understanding commonlyused process finetuning support hypothesis finetuning mainly exposing knowledge induced languagemodeling training rather learning new taskspecific linguistic knowledge
development environment spoken dialogue system popular today enable rapid creation dialogue system time usage voice ai assistant constantly growing describe graphical discoursedriven integrated dialogue development environment ddidde spoken opendomain dialogue system ddidde allows dialogue architect interactively define dialogue flow skillschatbots aid discoursedriven recommendation system enhance flow pythonbased dsl deploy improve based skillschatbots usage statistic show skillschatbots specified graphical user interface within v code extension run top dialog flow framework dff earlier version framework adopted one alexa prize socialbots updated version specifically designed power described ddidde solution
democratization ecommerce platform moved increasingly diversified indian user base shop online deployed reliable precise largescale machine translation system several indian regional language work building system challenge lowresource nature indian language develop structured model development pipeline closed feedback loop external manual feedback active learning component show strong synthetic parallel data generation capability consistent improvement model iteration starting parallel pair englishhindi compiled corpus synthetic high quality parallel pair across different domain need colloquial translation preserve intent friendliness english content regional language make easier understand user perform robust effective domain adaptation step achieve colloquial translation iteration show bleu point improvement english hindi translation model along hindi show overall approach best practice extends well indian language resulting deployment model across indian language
one critical component process building automatic speech recognition asr capability new language lexicon pronouncing dictionary practical reason desirable manually create minimal lexicon using available nativespeaker phonetic expertise use resulting seed lexicon machine learning based induction highquality lettertosound l model generation pronunciation remaining word language paper examines viability scenario specifically investigating three possible strategy selection lexeme word manual transcription choosing frequent lexeme language choosing lexeme randomly selection lexeme via information theoretic diversity measure relative effectiveness three strategy evaluated function number lexeme transcribed create bootstrapping lexicon generally newly developed orthographic diversity based selection strategy outperforms others scenario limited number lexeme transcribed experiment also provide generally useful insight expected l accuracy sacrifice function decreasing training set size
sequencetosequence seqseq network wellestablished model text summarization task learn produce readable content however fall short effectively identifying key region source paper approach content selection problem clinical abstractive summarization augmenting salient ontological term summarizer experiment two publicly available clinical data set report mimiccxr report openi show model statistically significantly boost stateoftheart result term rouge metric improvement rg rg rgl healthcare domain range improvement impact patient welfare
screenplay summarization task extracting informative scene screenplay screenplay contains turning point tp event change story direction thus define story structure decisively accordingly task defined tp identification task suggest using dialogue information one attribute screenplay motivated previous work discovered tps relation dialogue appearing screenplay teach model characteristic add dialogue feature input embedding moreover attempt improve model architecture previous study replace lstm transformer observed model better identify tps screenplay using dialogue information model adopting transformer outperforms lstmbased model
vector representation word seen increasing success past year variety nlp task seems consensus usefulness word embeddings learn still unclear representation capture meaning phrase even whole sentence recent work shown simple operation outperform complex deep architecture work propose two novel constraint computing noun phrase vector representation first propose semantic syntactic contribution component noun phrase considered resulting composed vector express phrase meaning second composition process two phrase vector apply suitable dimension selection way specific semantic feature captured phrase meaning become salient proposed method compared approach including popular baseline neural net architecture evaluated across task datasets result show constraint lead expressive phrase representation applied stateoftheart method improve performance
pointofinterest poi type prediction task inferring type place social medium post shared inferring poi type useful study computational social science including sociolinguistics geosemiotics cultural geography application geosocial networking technology recommendation visualization system prior effort poi type prediction focus solely text without taking visual information account however reality variety modality well semiotic relationship one another shape communication interaction social medium paper present study poi type prediction using multimodal information text image available posting time purpose enrich currently available data set poi type prediction image accompany text message proposed method extract relevant information modality effectively capture interaction text image achieving macro f across category significantly outperforming stateoftheart method poi type prediction based textonly method finally provide detailed analysis shed light crossmodal interaction limitation best performing model
textual information extraction typical research topic nlp community several nlp task named entity recognition relation extraction entity wellstudied previous work however work pay attention implicit information example financial news article mentioned apple inc may also related samsung even though samsung explicitly mentioned article work present novel dynamic graph transformer distills textual information entity relation fly experimental result confirm effectiveness approach implicit tag recognition
retrieving research paper patent important researcher assessing scope field high industrial relevance however term used patent often abstract creative used research paper intended widen scope claim therefore method required translating scholarly term patent term paper propose six method translating scholarly term patent term using two synonym extraction method statistical machine translation smtbased method distributional similarity dsbased method conducted experiment confirm effectiveness method using dataset patent mining task ntcir workshop aim task classify japanese language research paper pair title abstract using ipc system subclass third level main group fourth level subgroup fifth detailed level result showed smtbased method smtabstidf performed best subgroup level whereas dsbased method dsidf performed best subclass level
help document supposed aid smartphone user resolving query block call unknown number however given query identifying right help document understanding instruction document using resolve issue hand challenging user experience may enhanced converting instruction help document stepbystep tutorial overlaid phone ui successful execution task requires overcoming research challenge retrieval parsing grounding multilingualmultimodal setting example user query one language may matched instruction another language turn need grounded multimodal ui yet another language moreover isnt relevant dataset task order bridge gap introduce ugifdataset multilingual multimodal ui grounded dataset stepbystep task completion smartphone containing task across language instruction step ugifdataset available english challenge involves operation crossmodal crosslingual setting compare performance different large language model task find endtoend task completion rate drop english language demonstrating significant overall headroom improvement hopeful ugifdataset analysis aid research important problem sequential task completion multilingual multimodal setting
test state art dialogue system behaviour response userinitiated subdialogues ie interaction system question responded question request user thus initiate subdialogue look subdialogues within single app subdialogue concern another topic original domain across apps subdialogue concern different domain overall conclusion test none system said deal appropriately userinitiated subdialogues
despite recent improvement abstractive summarization current approach generate summary factually consistent source document severely restricting trust usage realworld application recent work shown promising improvement factuality error identification using text dependency arc entailment however consider entire semantic graph simultaneously end propose factgraph method decomposes document summary structured meaning representation mr suitable factuality evaluation mr describe core semantic concept relation aggregating main content document summary canonical form reducing data sparsity factgraph encodes graph using graph encoder augmented structureaware adapter capture interaction among concept based graph connectivity along text representation using adapterbased text encoder experiment different benchmark evaluating factuality show factgraph outperforms previous approach furthermore factgraph improves performance identifying content verifiability error better capture subsentencelevel factual inconsistency
machine translation task made great progress help autoregressive decoding paradigm transformer architecture paradigm though encoder obtain global source representation decoder use translation history determine current word previous promising work attempted address issue applying draft fixedlength semantic embedding targetside global information however method either degrade model efficiency show limitation expressing semantics motivated functional equivalence theory extract several semantic kernel source sentence express one semantic segment original sentence together semantic kernel capture global semantic information project target embedding space guide target sentence generation force model use semantic kernel decoding step adaptive mask algorithm empirical study various machine translation benchmark show approach gain approximately improvement bleu score benchmark transformer baseline time faster previous work average inference time
neural extractive summarization model usually employ hierarchical encoder document encoding trained using sentencelevel label created heuristically using rulebased method training hierarchical encoder textitinaccurate label challenging inspired recent work pretraining transformer sentence encoders devlin et al propose hibert shorthand textbfhierachical textbfbidirectional textbfencoder textbfrepresentations textbftransformers document encoding method pretrain using unlabeled data apply pretrained hibert summarization model outperforms randomly initialized counterpart rouge cnndailymail dataset rouge version new york time dataset also achieve stateoftheart performance two datasets
identification lexical borrowing transfer word language essential practice historical linguistics vital tool analysis language contact cultural event general seek improve tool automatic detection lexical borrowing focusing detecting borrowed word monolingual wordlists starting recurrent neural lexical language model competing entropy approach incorporate current transformer based lexical model experiment several different model approach including lexical donor model augmented wordlist transformer model reduces execution time minimally improves borrowing detection augmented donor model show promise substantive change approach model needed make significant gain identification lexical borrowing
chinese spelling check csc detects corrects spelling error chinese text previous approach combined characterlevel phonetic graphic information ignoring importance segmentlevel information according pilot study spelling error always associated incorrect word segmentation appropriate word boundary provided csc performance greatly enhanced based finding present wspeller csc model take account word segmentation fundamental component wspeller wmlm trained predicting visually phonetically similar word modification embedding layer input word segmentation information incorporated additionally robust module trained assist wmlmbased correction module predicting correct word segmentation sentence containing spelling error evaluate wspeller widely used benchmark datasets sighan sighan sighan model superior stateoftheart baseline sighan sighan maintains equal performance sighan
contrastive learning attracting much attention learning unsupervised sentence embeddings current stateoftheart unsupervised method unsupervised simcse unsupsimcse unsupsimcse take dropout minimal data augmentation method pass input sentence pretrained transformer encoder dropout turned twice obtain two corresponding embeddings build positive pair length information sentence generally encoded sentence embeddings due usage position embedding transformer positive pair unsupsimcse actually contains length information thus unsupsimcse trained positive pair probably biased would tend consider sentence similar length similar semantics statistical observation find unsupsimcse problem alleviate apply simple repetition operation modify input sentence pas input sentence modified counterpart pretrained transformer encoder respectively get positive pair additionally draw inspiration community computer vision introduce momentum contrast enlarging number negative pair without additional calculation proposed two modification applied positive negative pair separately build new sentence embedding method termed enhanced unsupsimcse esimcse evaluate proposed esimcse several benchmark datasets wrt semantic text similarity sts task experimental result show esimcse outperforms stateoftheart unsupsimcse average spearman correlation bertbase
paper present collection german lemmatised word rated four psycholinguistic affective attribute rating obtained via supervised learning algorithm automatically calculate numerical rating word applied algorithm abstractness arousal imageability valence comparison human rating reveals high correlation across rating type full resource publically available urlhttpwwwimsunistuttgartdedataaffectivenorms
neural machine translation nmt obtained significant performance improvement recent year however nmt model still face various challenge including fragility lack style flexibility moreover current method instancelevel constraint limited either constraintspecific modelspecific end propose promptdriven neural machine translation incorporate prompt enhancing translation control enriching flexibility empirical result demonstrate effectiveness method prompt responding translation quality human evaluation show flexibility prompt control efficiency humanintheloop translation
describe two constraintbased method used improve recall shallow discourse parser based conditional random field chunking method us set natural structural constraint well others follow annotation guideline penn discourse treebank evaluated resulting system standard test set pdtb achieved rebalancing precision recall improved fmeasures across board especially notable used evaluation metric taking partial match account measure achieved fmeasure improvement several point
hierarchical multiscale lstm chung et al stateoftheart language model learns interpretable structure characterlevel input model provide fertile ground cognitive computational linguistics study however high complexity architecture training implementation might hinder applicability provide detailed reproduction ablation study architecture shedding light potential caveat repurposing complex deeplearning architecture show simplifying certain aspect architecture fact improve performance also investigate linguistic unit segment learned various level model argue quality correlate overall performance model language modeling
present first neural machine translation system translation endangered erzya language russian dataset collected u train evaluate bleu score translation erzya russian respectively half translation rated acceptable native speaker also adapt model translate erzya language without additional parallel data quality direction remains low release translation model along collected text corpus new language identification model multilingual sentence encoder adapted erzya language resource available urlhttpsgithubcomslonenlpmyvnmt
paper firstly empirically find existing model struggle handle hard mention due insufficient context consequently limit overall typing performance end propose exploit sibling mention enhancing mention representation specifically present two different metric sibling selection employ attentive graph neural network aggregate information sibling mention proposed graph model scalable unseen test mention allowed added new node inference exhaustive experiment demonstrate effectiveness sibling learning strategy model outperforms ten strong baseline moreover experiment indeed prove superiority sibling mention helping clarify type hard mention
one processing task large multimodal data stream automatic image description image classification object segmentation classification although number diversity image datasets constantly expanding still huge demand datasets term variety domain object class covered goal project multilingual image corpus mic provide large image dataset annotated object object description language multilingual image corpus consists ontology visual object based wordnet collection thematically related image whose object annotated segmentation mask label describing ontology class dataset designed image classification object detection semantic segmentation main contribution work provision large collection high quality copyrightfree image b formulation ontology visual object based wordnet noun hierarchy c precise manual correction automatic object segmentation within image annotation object class association object image extended multilingual description based wordnet inner interlingual relation dataset used also multilingual image caption generation imagetotext alignment automatic question answering image video
growing body work show model exploit annotation artifact achieve stateoftheart performance standard crowdsourced benchmarksdatasets collected crowdworkers create evaluation taskwhile still failing outofdomain example task recent work explored use counterfactuallyaugmented datadata built minimally editing set seed example yield counterfactual labelsto augment training data associated benchmark build robust classifier generalize better however khashabi et al find type augmentation yield little benefit reading comprehension task controlling dataset size cost collection build upon work using english natural language inference data test model generalization robustness find model trained counterfactuallyaugmented snli dataset generalize better unaugmented datasets similar size counterfactual augmentation hurt performance yielding model less robust challenge example counterfactual augmentation natural language understanding data standard crowdsourcing technique appear effective way collecting training data innovation required make general line work viable
work provide recipe training machine translation model limited resource setting leveraging synthetic target data generated using large pretrained model show consistently across different benchmark bilingual multilingual speech translation setup training model synthetic target outperforms training actual groundtruth data performance gap grows bigger increasing limit amount available resource form size dataset number parameter model also provide preliminary analysis whether boost performance linked ease optimization deterministic nature prediction whether paradigm lead better outofdistribution performance across different testing domain
present analysis tool based joint matrix factorization comparing latent representation multilingual monolingual model alternative probing tool allows u analyze multiple set representation joint manner using tool study extent morphosyntactic feature reflected representation learned multilingual pretrained model conduct largescale empirical study language morphosyntactic category finding demonstrate variation encoding morphosyntactic information across upper lower layer categoryspecific difference influenced language property hierarchical clustering factorization output yield tree structure related phylogenetic tree manually crafted linguist moreover find factorization output exhibit strong association performance observed across different crosslingual task release code facilitate future research
although commonly assumed word sense disambiguation wsd help improve lexical choice improve quality machine translation system successfully integrate word sens system remains unanswered question successful approach involved reformulating either wsd word sens produce work using traditional word sens improve machine translation met limited success paper build upon previous work experimented including word sens contextual feature maxentbased translation model training large opendomain corpus europarl demonstrate aproach yield significant improvement machine translation english portuguese
deep learning introduced significant improvement many software analysis task although large language model llm based neural code model demonstrate commendable performance trained tested within intraproject independent identically distributed iid setting often struggle generalize effectively realworld interproject outofdistribution ood data work show phenomenon caused heavy reliance projectspecific shortcut prediction instead groundtruth evidence propose condidf measurement interpret behavior quantifies relatedness token label projectspecificness strong correlation model behavior proposed measurement indicates without proper regularization model tend leverage spurious statistical cue prediction equipped observation propose novel bias mitigation mechanism regularizes model learning behavior leveraging latent logic relation among sample experimental result two representative program analysis task indicate mitigation framework improve interproject ood generalization adversarial robustness sacrificing accuracy intraproject iid data
use natural language processing technique legal domain become established supporting attorney domain expert content retrieval decisionmaking however understanding legal text pose relevant challenge recognition domainspecific entity adaptation explanation predictive model paper address legal entity name recognition lner court judgment prediction cpj explanation cjpe task lner solution explores use various transformerbased model including entityaware method attending domainspecific entity cjpe proposed method relies hierarchical bertbased classifier combined local input attribution explainers propose broad comparison explainable ai methodology along novel approach based ner lner task experimental result remark importance domainspecific pretraining cjp lightweight solution show performance line existing approach nerboosted explanation show promising cjpe result term conciseness prediction explanation
narrow specialized comparable corpus often small size particularity make difficult build efficient model acquire translation equivalent especially less frequent rare word one way overcome issue enrich specialized corpus outofdomain resource although recent study shown improvement using data augmentation enrichment method roughly conducted adding outofdomain data particular attention given enrich word optimally paper contrast several data selection technique improve bilingual lexicon induction specialized comparable corpus first apply two wellestablished data selection technique often used machine translation tfidf cross entropy propose exploit bert data selection overall proposed technique improve quality extracted bilingual lexicon large margin best performing model cross entropy obtaining gain point map decreasing computation time factor
unlock value highquality bilingual translated document need parallel data sentencealigned translation pair fuel neural machine translation customize mt create translation memory client automate process automatic segmentation alignment required despite arabic fifth biggest language world language technology arabic many time way behind language show struggled find proper sentence segmentation arabic instead explored different framework statistical deep learning end finetuning arabic dl segmentation model highlight learning challenge segmenting aligning arabic english bilingual data finally show impact proprietary nmt engine started unlock value could leverage data translated offline outside cat tool well comparable corpus feed nmt
transcript segmentation task dividing single continuous transcript multiple segment document segmentation popular task transcript segmentation significant challenge due relatively noisy sporadic nature data propose pretraining strategy address challenge strategy based next conversation prediction ncp underlying idea pretraining model identify consecutive conversation introduce advanced ncp make pretraining task relevant downstream task segmentation break prediction significantly easier finally introduce curriculum advanced ncp curricular ncp based similarity pretraining downstream task sample curricular ncp applied stateoftheart model text segmentation outperforms prior result also show pretraining strategy make model robust speech recognition error commonly found automatically generated transcript
simple reference game central theoretical empirical importance study situated language use although language provides rich compositional truthconditional semantics facilitate reference speaker listener may sometimes lack overall lexical cognitive resource guarantee successful reference mean alone however language also rich associational structure serve resource achieving successful reference investigate use associational information setting associational information available simplified version popular game codenames using optimal experiment design technique compare range model varying type associative information deployed level pragmatic sophistication human behavior setting find listener behavior reflects direct bigram collocational association strongly wordembedding semantic knowledge graphbased association little evidence pragmatically sophisticated behavior part either speaker listener generally demonstrate effective use simple task derive insight nature complex linguistic phenomenon
paper present tencents submission wmt quality estimation qe shared task sentencelevel postediting effort englishchinese task system ensemble two architecture xlmbased transformerbased predictorestimator model xlmbased predictorestimator architecture predictor produce two type contextualized token representation ie masked xlm nonmasked xlm lstmestimator transformerestimator employ two effective strategy topk multihead attention enhance sentence feature representation transformerbased predictorestimator architecture improve topperforming model conducting three modification using multidecoding machine translation module creating new model replacing transformerbased predictor xlmbased predictor finally integrating two model weighted average submission achieves pearson correlation ranking first tied englishchinese
thought disorder linguistic disturbance including incoherence derailment topic seen individual risk psychosis method computational linguistics increasingly sought quantify thought disorder detect group difference clinical population healthy control previous work quite successful classification task lack interpretability computational metric made unclear whether fact measuring thought disorder paper dive measure try better understand reflect find group difference atrisk healthy control population also find measure mostly correlate existing measure thought disorder symptom intended measure rather correlate surface property speech eg sentence length sociodemographic property speaker eg race result highlight importance considering interpretability front center field continues grow ethical use computational measure like studied especially highstakes context clinical care requires u devote substantial attention potential bias measure
multimodal emotion recognition aim recognize emotion utterance multiple modality received increasing attention application humanmachine interaction current graphbased method fail simultaneously depict global contextual feature local diverse unimodal feature dialogue furthermore number graph layer increasing easily fall oversmoothing paper propose method joint modality fusion graph contrastive learning multimodal emotion recognition joyful multimodality fusion contrastive learning emotion recognition jointly optimized specifically first design new multimodal fusion mechanism provide deep interaction fusion global contextual unimodal specific feature introduce graph contrastive learning framework inter intraview contrastive loss learn distinguishable representation sample different sentiment extensive experiment three benchmark datasets indicate joyful achieved stateoftheart sota performance compared baseline code released github httpsanonymousopensciencermercf
deep neural network model helped named entity recognition achieve amazing performance without handcrafting feature however existing system require large amount human annotated training data effort made replace human annotation external knowledge eg ne dictionary partofspeech tag another challenge obtain effective resource work propose fully unsupervised ne recognition model need take informative clue pretrained word embeddingswe first apply gaussian hidden markov model deep autoencoding gaussian mixture model word embeddings entity span detection type prediction design instance selector based reinforcement learning distinguish positive sentence noisy sentence refine coarsegrained annotation neural network extensive experiment two conll benchmark ner datasets conll english dataset conll spanish dataset demonstrate proposed light ne recognition model achieves remarkable performance without using annotated lexicon corpus
discourse information difficult represent annotate among major framework annotating discourse information rst pdtb sdrt widely discussed used theoretical foundation focus corpus annotated different framework vary considerably make better use existing discourse corpus achieve possible synergy different framework worthwhile investigate systematic relation different framework devise method unifying framework although issue framework unification topic discussion long time currently comprehensive approach considers unifying discourse structure discourse relation evaluates unified framework intrinsically extrinsically plan use automatic mean unification task evaluate result structural complexity downstream task also explore application unified framework multitask learning graphical model
parallelizable attention network neural transformer fast train however due autoregressive architecture selfattention decoder decoding procedure becomes slow alleviate issue propose average attention network alternative selfattention network decoder neural transformer average attention network consists two layer average layer model dependency previous position gating layer stacked average layer enhance expressiveness proposed attention network apply network decoder part neural transformer replace original targetside selfattention model masking trick dynamic programming model enables neural transformer decode sentence four time faster original version almost loss training time translation performance conduct series experiment wmt translation task different language pair obtain robust consistent speedup decoding
describe weaklysupervised method training deep learning model task adhoc document retrieval method based generative discriminative model trained using weaksupervision document corpus present endtoend retrieval system start traditional information retrieval method followed two deep learning rerankers evaluate method three different datasets covid related scientific literature dataset two news datasets show method outperforms stateoftheart method without need expensive process manually labeling data
research natural language processing often relies large collection manually annotated document however currently reliable genreannotated corpus web page employed automatic genre identification agi agi document classified based genre rather topic subject major shortcoming available web genre collection relatively low intercoder agreement reliability annotated data essential factor reliability research result paper present first web genre corpus reliably annotated developed precise consistent annotation guideline consist welldefined wellrecognized category annotating corpus used crowdsourcing novel approach genre annotation computed overall well individual category chancecorrected interannotator agreement result show corpus annotated reliably
describe longitudinal user study conducted context spoken dialogue system household robot examined influence time displacement situational risk user preferred response effect employed corpus spoken request asked robot fetch move object room first stage study participant selected among four response type request two risk condition low high time participant rated several response previous request response instantiated four response type result show participant rate highly response type moreover rated response type similarly different one suggests least context people preference particular point time may reflect general attitude various reasonable response type may equally acceptable study also reveals situational risk influence acceptability response type
article describes development bidirectional shallowtransfer based machine translation system spanish aragonese based apertium platform reusing resource provided translator built platform system morphological analyser built first resource kind aragonese morphological analyser coverage textbackslash reused create spelling checker aragonese translator bidirectional word error rate spanish aragonese aragonese spanish
classifying stance expressed online microblogging social medium emerging problem opinion mining propose probabilistic approach stance classification tweet model stance target stance sentiment tweet jointly instead simply conjoining sentiment target variable extra variable feature space use novel formulation incorporate threeway interaction among sentimentstanceinput variable threeway interaction among targetstanceinput variable proposed specification intuitively aim discriminate sentiment feature target feature stance classification addition regularizing single stance classifier handle target act soft weightsharing among demonstrate discriminative training model achieves stateoftheart result supervised stance classification generative training obtains competitive result weakly supervised setting
clickbait spoiling shared task aim tackling two aspect spoiling classifying spoiler type based length generating spoiler paper focus task classifying spoiler type better classification spoiler type would eventually help generating better spoiler post use bertbase cased classify clickbait post model achieves balanced accuracy give post content input model instead concatenation post title post content find difference post title might bringing
describe set new method partially automate linguistic phylogenetic inference given cognate set respective protoforms sound law mapping phone articulatory feature typological database sound changeswe train neural network sound change data weight articulatory distance phone predict intermediate sound change step historical protoforms modern descendant replacing linguistic expert part parsimonybased phylogenetic inference algorithm best experiment tukanoan language method produce tree generalized quartet distance tree used expert annotation significant improvement semiautomated baseline discus potential benefit drawback neural approach parsimonybased tree prediction also experiment minimal generalization learner automatic sound law induction finding less effective sound law expert annotation code publicly available
modeling natural language inference challenging task large annotated data set available become feasible train complex neural network based inference method achieve state art performance however shown model also learn subtle bias inherent datasets citation work explore two technique delexicalization modify datasets way control importance neuralnetwork based method place lexical entity demonstrate proposed method maintain performance indomain also improve performance outofdomain setting example using delexicalized version fever dataset indomain performance state art neural network method dropped outofdomain performance fnc dataset improved release delexicalized version three common datasets used natural language inference datasets delexicalized using two method one replaces lexical entity overlapaware manner second additionally incorporates semantic lifting noun verb wordnet hypernym synset
welldocumented several language human interlocutor tend adapt linguistic production become similar behavior known entrainment affect lexical choice well regard specific word referring expression overall style offer believe first investigation lexical entrainment hebrew using two existing measure analyze hebrew speaker interacting map task popular experimental setup find rich evidence lexical entrainment analyzing speaker pair combination gender well speaker individual gender find clear pattern difference however find speaker position less power entrain greater power match theoretical account overall result mostly accord american english lack entrainment hedge word main difference
aim paper mitigate shortcoming automatic evaluation opendomain dialog system multireference evaluation existing metric shown correlate poorly human judgement particularly opendomain dialog one alternative collect human annotation evaluation expensive time consuming demonstrate effectiveness multireference evaluation augment test set dailydialog multiple reference series experiment show use multiple reference result improved correlation several automatic metric human judgement quality diversity system output
arabizi form writing arabic text relies latin letter numeral punctuation rather arabic letter literature difficulty associated arabizi sentiment analysis underestimated principally due complexity arabizi paper present approach automatically classify sentiment arabizi message positive negative proposed approach arabizi message first transliterated arabic afterwards automatically classify sentiment transliterated corpus using automatically annotated corpus corpus validation shallow machine learning algorithm support vector machine svm naive bay nb used simulation result demonstrate outperformance nb algorithm others highest achieved fscore manually automatically transliterated dataset respectively ongoing work aimed improving transliterator module annotated sentiment dataset
communication physician patient lead misunderstanding especially disabled people automatic system translates natural language pictographic language one solution could help overcome issue preliminary study present french version translation system using arasaac pictograph investigate strategy used speech therapist translate pictograph also evaluate medical coverage tool translating physician question patient instruction
encoderonly transformer model successfully applied different table understanding task tapa major limitation architecture constrained classificationlike task cell selection entailment detection present tabt encoderdecoder model generates natural language text based table textual input tabt overcomes encoderonly limitation incorporating decoder component leverage input structure table specific embeddings pretraining tabt achieves new stateoftheart result several domain including spreadsheet formula prediction increase sequence accuracy qa increase sequence accuracy datatotext generation increase bleu
context catch research program currently carried number large dutch cultural heritage institution ambition combine exchange heterogeneous multimedia annotation project institution first step designed annotation meta model simple powerful rdfowl model mainly addressing anchoring annotation segment many different medium type used collection archive museum library involved model includes support annotation annotation segment annotation value able layer annotation way enable project process others annotation data primary data annotation basis amm designed application programming interface accessing annotation repository implemented software library web service finally report experience application model api repository developing web application collection manager cultural heritage institution
compiled new sentence splitting corpus composed k pair aligned complex source simplified target sentence contrary previously proposed text simplification corpus contain small number split example present dataset input sentence broken set minimal proposition ie sequence sound selfcontained utterance presenting minimal semantic unit decomposed meaningful proposition corpus useful developing sentence splitting approach learn transform sentence complex linguistic structure finegrained representation short sentence present simple regular structure easier process downstream application thus facilitates improves performance
protolanguage reconstruction central historical linguistics comparative method one influential theoretical methodological framework history language science allows linguist infer protoforms reconstructed ancestral word reflex related modern word based assumption regular sound change surprisingly numerous computational linguist attempted operationalize comparative reconstruction various computational model successful supervised encoderdecoder model treat problem predicting protoforms given set reflex sequencetosequence problem argue framework ignores one important aspect comparative method protoforms inferable cognate set set related reflex reflex also inferable protoforms leveraging another line researchreflex predictionwe propose system candidate protoforms reconstruction model reranked reflex prediction model show complete implementation comparative method allows u surpass stateoftheart protoform reconstruction method three four chinese romance datasets
large language model llm solve problem stepbystepwhile chainofthought cot reasoning boost llm performance unclear llm know use cot whether cot always necessary answer question paper show llm tend generate redundant calculation reasoning manually constructed math qa dataset gsmkzerogsmkzero constructed question answered without calculation llm including llama model claude tend generate lengthy unnecessary calculation answer questionswe also conduct experiment explain llm generate redundant calculation reasoning
negotiation complex activity involving strategic reasoning persuasion psychology average person often far expert negotiation goal assist human become better negotiator machineintheloop approach combine machine advantage datadriven decisionmaking human language generation ability consider bargaining scenario seller buyer negotiate price item sale textbased dialogue negotiation coach monitor message recommends strategy real time seller get better deal eg reject proposal propose price talk personal experience product best strategy largely depends context eg current price buyer attitude therefore first identify set negotiation strategy learn predict best strategy given dialogue context set humanhuman bargaining dialogue evaluation humanhuman dialogue show coach increase profit seller almost
individual communicate use different vocabulary speaking speed facial expression body language depending people talk paper focus speaker age factor affect change communication collected multimodal dialogue corpus wide range speaker age dialogue task focus travel interest people age set task based tourism consultation operator customer travel agency paper provides detail dialogue task collection procedure annotation analysis characteristic dialogue facial expression focusing age speaker result analysis suggest adult speaker independent opinion older speaker frequently express opinion frequently compared age group operator expressed smile frequently minor speaker
linguistic data consortium ldc seek provide member quality linguistic resource service order pursue ideal remain current ldc monitor need sentiment community one mechanism ldc us generate feedback consortium resource issue ldc member survey survey allows ldc member nonmember provide ldc valuable insight unique circumstance current future data need view ldcs role meeting survey found useful tool communicating consortium membership survey organized administered result survey ldc confirmed made positive impact community identified way improve quality service diversity monthly offering many respondent recommended way improve ldcs function ordering mechanism webpage comment inspired change ldcs operation strategy
paper proposes novel problem setting selectional preference sp predicate argument called contextsensitive sp csp csp model narrative consistency predicate preceding context argument addition conventional sp based semantic type furthermore present novel csp model extends neural sp model van de cruys incorporate contextual information distributed representation argument experimental result demonstrate proposed csp model successfully learns csp outperforms conventional sp model coreference cluster ranking
pretrained transformer ubiquitous natural language processing despite high endtask performance little known empirically whether calibrated specifically model posterior probability provide accurate empirical measure likely model correct given example focus bert roberta work analyze calibration across three task natural language inference paraphrase detection commonsense reasoning task consider indomain well challenging outofdomain setting model face example uncertain show used outofthebox pretrained model calibrated indomain compared baseline calibration error outofdomain much x lower temperature scaling effective reducing calibration error indomain using label smoothing deliberately increase empirical uncertainty help calibrate posterior outofdomain
growing interest large language model llm specialized application revealed significant challenge tailored specific domain llm tend experience catastrophic forgetting compromising general capability leading suboptimal user experience additionally crafting versatile model multiple domain simultaneously often result decline overall performance due confusion domain response issue present role prompting guided multidomain adaptation rega strategy novel approach effectively manages multidomain llm adaptation three key component selfdistillation construct replay generaldomain exemplar alleviate catastrophic forgetting role prompting assigns central prompt general domain unique role prompt specific domain minimize interdomain confusion training role integration reuses integrates small portion domainspecific data generaldomain data trained guidance central prompt central prompt used streamlined inference process removing necessity switch prompt different domainsempirical result demonstrate rega effectively alleviates catastrophic forgetting interdomain confusion lead improved domainspecific performance compared standard finetuned model still preserving robust general capability
text editing crucial task modifying text better align user intent however existing text editing benchmark datasets contain coarsegrained instruction lack explainability thus resulting output deviate intended change outlined gold reference comprehensively investigate text editing capability large language model llm paper introduces xatu first benchmark specifically designed finegrained instructionbased explainable text editing xatu considers finergrained text editing task varying difficulty simplification grammar check factcheck etc incorporating lexical syntactic semantic knowledgeintensive edit aspect enhance interpretability combine llmbased annotation human annotation resulting benchmark includes finegrained instruction goldstandard edit explanation evaluating existing llm benchmark demonstrate effectiveness instruction tuning impact underlying architecture across various editing task furthermore extensive experimentation reveals significant role explanation finetuning language model text editing task benchmark opensourced support reproduction facilitate future research httpsgithubcommegagonlabsxatu
chemical named entity recognition ner model used many downstream task adverse drug reaction identification pharmacoepidemiology however unknown whether model work everyone performance disparity potentially cause harm rather intended good paper assesses genderrelated performance disparity chemical ner system develop framework measuring gender bias chemical ner model using synthetic data newly annotated corpus word selfidentified gender information reddit evaluation multiple biomedical ner model reveals evident bias instance synthetic data suggests female name frequently misclassified chemical especially come brand name mention additionally observe performance disparity female maleassociated data datasets many system fail detect contraceptive birth control finding emphasize bias chemical ner model urging practitioner account bias downstream application
nonparametric neural language model nlms learn predictive distribution text utilizing external datastore allows learn explicitly memorizing training datapoints effective model often require retrieval large datastore test time significantly increasing inference overhead thus limiting deployment nonparametric nlms practical application paper take recently proposed knearest neighbor language model example exploring method improve efficiency along various dimension experiment standard wikitext benchmark domainadaptation datasets show method able achieve x speedup inference speed retaining comparable performance empirical analysis present may provide guideline future research seeking develop deploy efficient nonparametric nlms
automatic emotion analysis highly challenging task natural language processing far mainly relied textual content determine emotion text however word medium carry emotional information social medium people also use emojis convey feeling recently researcher studied emotional aspect emojis use emoji information improve emotion detection classification many issue remain addressed study examine impact emoji embedding emotion classification intensity prediction four individual emotion category including anger fear joy sadness order investigate emojis affect automatic analysis individual emotion category intensity conducted comparative study testing five machine learning model without emoji embeddings involved experiment demonstrates emojis varying impact different emotion category potential emojis used enhance emotion information processing
product key memory pkm proposed lample et al enables improve prediction accuracy increasing model capacity efficiently insignificant computational overhead however empirical application limited causal language modeling motivated recent success pretrained language model plms investigate incorporate large pkm plms finetuned wide variety downstream nlp task define new memory usage metric careful observation using metric reveals memory slot remain outdated training pkmaugmented model train better plms tackling issue propose simple effective solution initialization model weight pretrained without memory augmenting pkm addition rather replacing feedforward network verify crucial pretraining pkmaugmented plms enhancing memory utilization downstream performance code pretrained weight available urlhttpsgithubcomclovaaipkmtransformers
paper describes system used semeval task reading comprehension abstract meaning achieving st subtask nd subtask leaderboard propose ensemble electrabased model taskadaptive pretraining multihead attention multiplechoice classifier top pretrained model main contribution system revealing performance discrepancy different transformerbased pretraining model downstream task presentation efficient method generate large taskadaptive corpus pretraining also investigated several pretraining strategy contrastive learning objective system achieves test accuracy subtask subtask respectively
analyst various domain especially intelligence financial constantly extract useful knowledge large amount unstructured semistructured data keywordbased search faceted search questionanswering etc automated methodology used help analyst task generalpurpose domainspecific ontology proposed help automated method organizing data providing access useful information however problem ontology creation maintenance resulted expensive procedure expandingmaintaining ontology library available support growing evolving need analyst paper present generalized improved procedure automatically extract deep semantic information text resource rapidly create semanticallyrich domain ontology keeping manual intervention minimum also present evaluation result intelligence financial ontology library semiautomatically created proposed methodology using freelyavailable textual resource web
mainstream approach view knowledge graphtotext kgtotext generation sequencetosequence task finetune pretrained model plm generate target text linearized knowledge graph however linearization knowledge graph structure plms lead loss large amount graph structure information moreover plms lack explicit graphtext alignment strategy discrepancy structural textual information solve two problem propose synergetic kgtotext model dualpath encoder alignment module guidance module dualpath encoder consists graph structure encoder text encoder better encode structure text information knowledge graph alignment module contains twolayer transformer block mlp block aligns integrates information dual encoder guidance module combine improved pointer network mlp block avoid errorgenerated entity ensures fluency accuracy generated text approach obtains competitive performance three benchmark datasets code available httpsgithubcomimumachinelearningsxdgt
paper concerned technology using par englishrussian bi directional machine translation system teaching english foreign language technology connection old form computerassisted language learning us drillandpractice computer exercise provides sort surrogate electronic teacher main objective educational implication par help learner become familiar word normal context introduction machine translation system teaching foreign language intended get fruitful pedagogical result use personal computer expose learner uptodate information technology
knowledge graph completion kgc aim automatically predicting missing link largescale knowledge graph vast number stateoftheart kgc technique got published top conference several research field including data mining machine learning natural language processing however notice several recent paper report high performance largely outperforms previous stateoftheart method paper find attributed inappropriate evaluation protocol used propose simple evaluation protocol address problem proposed protocol robust handle bias model substantially affect final result conduct extensive experiment report performance several existing method using protocol reproducible code made publicly available
study power crossattention transformer architecture within context transfer learning machine translation extend finding study crossattention training scratch conduct series experiment finetuning translation model data either source target language changed experiment reveal finetuning crossattention parameter nearly effective finetuning parameter ie entire translation model provide insight case observe limiting finetuning manner yield crosslingually aligned embeddings implication finding researcher practitioner include mitigation catastrophic forgetting potential zeroshot translation ability extend machine translation model several new language pair reduced parameter storage overhead
paper partial report research effort evaluating effect crowdsourced postediting first discus emerging trend crowdsourced postediting machine translation output along benefit drawback second describe pilot study conducted platform facilitates crowdsourced postediting finally provide plan study insight effective crowdsourced postediting
textual style transfer involves modifying style text preserving content assumes possible separate style content paper investigates whether separation possible use sentiment transfer case study style transfer analysis experimental methodology frame style transfer multiobjective problem balancing style shift content preservation fluency due lack parallel data style transfer employ variety adversarial encoderdecoder network experiment also use probing methodology analyse model encode stylerelated feature latent space result experiment confirmed human evaluation reveal inherent tradeoff multiple style transfer objective indicates style usefully separated content within styletransfer system
multilingual image captioning recently tackled training largescale machine translated data expensive noisy timeconsuming process without requiring multilingual caption data propose lmcap imageblind fewshot multilingual captioning model work prompting language model retrieved caption specifically instead following standard encoderdecoder paradigm given image lmcap first retrieves caption similar image using multilingual clip encoder caption combined prompt xglm decoder order generate caption desired language word generation model directly process image instead process retrieved caption experiment xm dataset geographically diverse image show model competitive fullysupervised multilingual captioning model without requiring supervised training captioning data
paper describes practical experience professional translator task consisted translating page russian scientific material covering fundamental science english within month job fulfilled using three computerbased system par russianenglish bidirectional machine translation system lingvistica co polyglossum dictionarysupport software ets ltd random house electronic dictionary english language paper analyzes plus minus translating scientific text using computer program give numerous example translation main conclusion machine translation reasonable alternative large volume scientific text translated professionally within short period time
system description shown use context information detecting emotion dialogue guideline handle emojis also laid developing system realized importance preprocessing conversational text data general nlp related task emphasized
ability learn large unlabeled corpus allowed neural language model advance frontier natural language understanding however existing selfsupervision technique operate word form level serf surrogate underlying semantic content paper proposes method employ weaksupervision directly word sense level model named sensebert pretrained predict masked word also wordnet supersenses accordingly attain lexicalsemantic level language model without use human annotation sensebert achieves significantly improved lexical understanding demonstrate experimenting semeval word sense disambiguation attaining state art result word context task
large language model become prevalent possible harmful inappropriate response cause concern paper introduces unique dataset containing adversarial example form question call attaq designed provoke harmful inappropriate response assess efficacy dataset analyzing vulnerability various model subjected additionally introduce novel automatic approach identifying naming vulnerable semantic region input semantic area model likely produce harmful output achieved application specialized clustering technique consider semantic similarity input attack harmfulness model responsesautomatically identifying vulnerable semantic region enhances evaluation model weakness facilitating targeted improvement safety mechanism overall reliability
neural encoderdecoder model widely applied conversational response generation research hot spot recent year however conventional neural encoderdecoder model tend generate commonplace response like dont know regardless input paper analyze problem new perspective latent vector based propose easytoextend learning framework named memd multiencoder multidecoder auxiliary encoder auxiliary decoder introduced provide necessary training guidance without resorting extra data complicating network inner structure experimental result demonstrate method effectively improve quality generated response according automatic metric human evaluation yielding diverse smooth reply
investigate feasibility defining sentiment evoked finegrained news event research question based premise method detecting implicit sentiment news key driver content diversity one way mitigate detrimental effect filter bubble recommenders based collaborative filtering may produce experiment based news article major flemish newspaper manually annotated high agreement implicit sentiment lexical resource prove insufficient sentiment analysis data genre result demonstrate machine learning model based svm bert able automatically infer implicit sentiment evoked news event
space situational awareness typically make use physical measurement radar telescope asset monitor satellite spacecraft operational navigational defense purpose work explore using textual input space situational awareness task construct corpus k news article spanning known active satellite using dependencyrulebased extraction system designed target three highimpact event spacecraft launch failure decommissionings identify spaceevent sentence annotated human k label event slot empirically demonstrate stateoftheart neural extraction system achieves overall f per slot event extraction lowresource highimpact domain
multiturn response selection extensively studied applied many realworld application recent year however current method typically model interaction multiturn utterance candidate response iterative approach practical turn conversation vary besides latent feature user intent conversation topic underdiscovered existing work work propose intrainterinteraction network latent interaction modeling comprehensively model multilevel interaction utterance context response specific first encode intra interutterance interaction given response individual utterance overall utterance context develop latent multiview subspace clustering module model latent interaction utterance response experimental result show proposed method substantially consistently outperforms existing stateoftheart method three multiturn response selection benchmark datasets
semantic projection method often used terminology structuring infer semantic relation term semantic projection relies upon assumption semantic compositionality relation link simple term pair remains valid pair complex term built simple term paper proposes investigate whether assumption commonly adopted natural language processing actually valid first describe process constructing list semantically linked multiword term mwts related environmental field extraction semantic variant second present analysis result semantic projection find context play essential role defining relation mwts
clinical coding task transforming medical document structured code following standard ontology since terminology composed hundred code problem considered extreme multilabel classification task paper proposes novel neural networkbased architecture clinical coding first take full advantage hierarchical nature ontology create cluster based semantic relation use matcher module assign probability document belonging cluster finally ranker calculates probability code considering document cluster division allows finegrained differentiation within cluster addressed using single classifier addition since previous work focused solving task english conducted experiment three clinical coding corpus spanish experimental result demonstrate effectiveness model achieving stateoftheart result two three datasets specifically outperformed previous model two subtasks codiesp shared task codiespd disease codiespp procedure automatic coding profoundly impact healthcare structuring critical information written free text electronic health record
use euphemism known driver language change proposed woman use euphemism men although several study investigating gender difference language claim euphemism usage tested comprehensively time woman use euphemism could mean woman also lead formation new euphemism language change time using four large diachronic text corpus english evaluate claim woman use euphemism men quantitative analysis assembled list euphemismtaboo pair analyze relative use time gender corpus contrary existing belief result show woman use euphemism higher proportion men repeated analysis using different subset euphemismtaboo pair list found result robust study indicates broad range setting involving speech writing varying degree formality woman use form euphemism men
paper present featurebart linguistically motivated sequencetosequence monolingual pretraining strategy syntactic feature lemma partofspeech dependency label incorporated span prediction based pretraining framework bart automatically extracted feature incorporated via approach concatenation relevance mechanism among latter known better former used lowresource nmt downstream task show feature based model give large improvement bilingual setting modest one multilingual setting counterpart use feature
lowrank adaptation lora widely used parameterefficient finetuning peft method update initial weight matrix w delta matrix delta w consisted two lowrank matrix b previous study suggested correlation w delta w study aim delve deeper relationship w lowrank matrix b comprehend behavior lora particular analyze conversion matrix transform w lowrank matrix encapsulates information relationship analysis reveals conversion matrix similar across layer inspired finding hypothesize single linear layer take layer w input yield taskadapted lowrank matrix confirm hypothesis devise method named conditionally parameterized lora condlora update initial weight matrix lowrank matrix derived single linear layer empirical result show condlora maintains performance par lora despite fact trainable parameter condlora fewer lora therefore conclude single linear layer yield taskadapted lowrank matrix code used experiment available urlhttpsgithubcomcyberagentailabcondlora
paper hypothesize sarcasm closely related sentiment emotion thereby propose multitask deep learning framework solve three problem simultaneously multimodal conversational scenario first manually annotate recently released multimodal mustard sarcasm dataset sentiment emotion class implicit explicit multitasking propose two attention mechanism viz intersegment intermodal attention ieattention intrasegment intermodal attention iaattention main motivation ieattention learn relationship different segment sentence across modality contrast iaattention focus within segment sentence across modality finally representation attention concatenated shared across five class ie sarcasm implicit sentiment explicit sentiment implicit emotion explicit emotion multitasking experimental result extended version mustard dataset show efficacy proposed approach sarcasm detection existing stateoftheart system evaluation also show proposed multitask framework yield better performance primary task ie sarcasm detection help two secondary task emotion sentiment analysis
parallel language corpus regular text aligned simplified version used natural language processing theoretical linguistic study essential task automatic text simplification also provide valuable insight characteristic make text accessible reveal strategy human expert use simplify text today exist parallel datasets english simple english many language lack data paper describe work creating aligned russiansimple russian dataset composed russian literature text adapted learner russian foreign language first parallel dataset domain one first simple russian datasets general
queryfocused text summarization qfts task aim building system generate summary text document based given query key challenge addressing task lack large labeled data training summarization model article address challenge exploring series domain adaptation technique given recent success pretrained transformer model wide range natural language processing task utilize model generate abstractive summary qfts task singledocument multidocument scenario domain adaptation apply variety technique using pretrained transformerbased summarization model including transfer learning weakly supervised learning distant supervision extensive experiment six datasets show proposed approach effective generating abstractive summary qfts task setting new stateoftheart result several datasets across set automatic human evaluation metric
paper consider advancing webscale knowledge extraction alignment integrating openie extraction form subject predicate object triple knowledge base kb traditional technique universal schema schema mapping fall two extreme either perform instancelevel inference relying embedding subject object pair thus handle pair absent existing triple perform predicatelevel mapping completely ignore background evidence individual entity thus achieve satisfying quality propose textitopenki handle sparsity openie extraction performing instancelevel inference entity encode rich information neighborhood kb openie extraction leverage information relation inference exploring different method aggregation attention order handle unseen entity model designed without creating entityspecific parameter extensive experiment show method significantly improves stateoftheart conventional openie extraction like reverb also boost performance openie semistructured data new entity pair abundant data fairly sparse
research contributes task predicting empathy personality trait within dialogue important aspect natural language processing part experimental work wassa empathy emotion shared task predicting empathy emotion polarity emotion intensity turn within dialogue employ adapter trained social medium interaction labeled empathy rating stacked composition target task adapter furthermore embed demographic information predict interpersonal reactivity index iri subscales big five personality trait utilizing bertbased model result study provide valuable insight contributing advancement understanding human behavior interaction text team ranked nd personality empathy prediction task th interpersonal reactivity index th conversational task
endtoend automatic speech recognition asr model significantly advanced field speech processing streamlining traditionally complex asr system pipeline promising enhanced accuracy efficiency despite advancement notable absence freely available medical conversation speech corpus burmese one lowresource language addressing gap present manually curated burmese medical speech conversation mymedicon corpus encapsulating conversation among medical doctor nurse patient utilizing espnet speech processing toolkit explore endtoend asr model burmese language focus transformer recurrent neural network rnn architecture corpus comprises speaker including three male nine female total speech duration nearly hour within medical domain assess asr performance applied word syllable segmentation text corpus asr model evaluated using character error rate cer word error rate wer translation error rate ter experimental result indicate rnnbased burmese speech recognition syllablelevel segmentation achieved best performance yielding cer moreover rnn approach significantly outperformed transformer model
commonlyused method debiasing natural language understanding nlu model dataset refinement approach heavily rely manual data analysis thus maybe unable cover potential biased feature paper propose ibadr iterative biasaware dataset refinement framework debiases nlu model without predefining biased feature maintain iteratively expanded sample pool specifically iteration first train shallow model quantify bias degree sample pool pair sample bias indicator representing bias degree use extended sample train sample generator way generator effectively learn correspondence relationship bias indicator sample furthermore employ generator produce pseudo sample fewer biased feature feeding specific bias indicator finally incorporate generated pseudo sample pool experimental result indepth analysis two nlu task show ibadr significantly outperforms existing dataset refinement approach achieving sota also compatible modelcentric method
paper part collaboration computer scientist historian aimed development novel tool method improve analysis historical newspaper present case study ideological term ending ism suffix nineteenth century finnish newspaper propose twostep procedure trace difference word usage time training diachronic embeddings several time slice clustering embeddings selected word together neighbour obtain historical context obtained cluster turn useful historical study paper also discus specific difficulty related development historianoriented tool
skip connection widelyused technique improve performance convergence deep neural network believed relieve difficulty optimization due nonlinearity propagating linear component neural network layer however another point view also seen modulating mechanism input output input scaled predefined value one work investigate scale factor effectiveness skip connection reveal trivial adjustment scale lead spurious gradient exploding vanishing line deepness model could addressed normalization particular layer normalization induces consistent improvement plain skip connection inspired finding propose adaptively adjust scale input recursively applying skip connection layer normalization promotes performance substantially generalizes well across diverse task including machine translation image classification datasets
human gather information conversation involving series interconnected question answer machine assist information gathering therefore essential enable answer conversational question introduce coqa novel dataset building conversational question answering system dataset contains k question answer obtained k conversation text passage seven diverse domain question conversational answer freeform text corresponding evidence highlighted passage analyze coqa depth show conversational question challenging phenomenon present existing reading comprehension datasets eg coreference pragmatic reasoning evaluate strong dialogue reading comprehension model coqa best system obtains f score point behind human performance indicating ample room improvement present coqa challenge community urlhttpsstanfordnlpgithubiocoqa
present cavat tool performs corpus analysis validation timeml cavat open source modular checking utility statistical analysis feature specific temporallyannotated natural language corpus provides reporting highlight salient link variety general timespecific linguistic feature also validates temporal annotation ensure logically consistent sufficiently annotated uniquely cavat provides analysis specific timemlannotated temporal information timeml standard annotating temporal information natural language text paper present reporting part cavat errorchecking ability including working several novel timeml document verification method followed execution example task using tool show relation time event signal link also demonstrate inconsistency timeml corpus timebank detected cavat
many nlp application online review comparison two opinionbearing sentence key argue general purpose text similarity metric applied purpose limited exploration applicability opinion text address gap literature studying human judge similarity pair opinionbearing sentence degree existing text similarity metric particularly embeddingbased one correspond human judgment crowdsourced annotation opinion sentence pair main finding annotator tend agree whether opinion sentence similar different embeddingbased metric capture human judgment opinion similarity opinion difference based analysis identify area current metric improved propose learn similarity metric opinion similarity via finetuning sentencebert sentenceembedding network based review text weak supervision review rating experiment show learned metric outperforms existing text similarity metric especially show significantly higher correlation human annotation differing opinion
recent study demonstrated naturallanguage prompt help leverage knowledge learned pretrained language model binary sentencelevel sentiment classification task specifically method utilize fewshot learning setting finetune sentiment classification model using manual automatically generated prompt however performance method sensitive perturbation utilized prompt furthermore method depend labeled instance automatic prompt generation prompt ranking study aim find highquality prompt given task zeroshot setting given base prompt proposed approach automatically generates multiple prompt similar base prompt employing positional reasoning paraphrasing technique rank prompt using novel metric empirically demonstrate topranked prompt highquality significantly outperform base prompt prompt generated using fewshot learning binary sentencelevel sentiment classification task
functional distributional semantics provides linguistically interpretable framework distributional semantics representing meaning word function binary classifier instead vector however large number latent variable mean inference computationally expensive training model therefore slow converge paper introduce pixie autoencoder augments generative model functional distributional semantics graphconvolutional neural network perform amortised variational inference allows model trained effectively achieving better result two task semantic similarity context semantic composition outperforming bert large pretrained language model
functional magnetic resonance imaging fmri provides mean investigate human conceptual representation cognitive neuroscience study researcher predict fmri activation elicited stimulus input previous work mainly us single source feature particularly linguistic feature predict fmri activation however relatively little work done investigating richsource feature conceptual representation paper systematically compare linguistic visual well auditory input feature conceptual representation introduce associative conceptual feature obtained small world word game predict fmri activation experimental result show richsource feature enhance performance predicting fmri activation analysis indicates information rich source present conceptual representation human brain particular visual feature weight conceptual representation consistent recent cognitive science study
consider cross multilingual text classification approach identification online register genre ie text variety specific situational characteristic register important predictor linguistic variation register information could improve potential online data many application introduce first manually annotated nonenglish corpus online register featuring full range linguistic variation found online data set consists finnish document follows register taxonomy developed corpus online register english core using core newly introduced corpus demonstrate feasibility crosslingual register identification using simple approach based convolutional neural network multilingual word embeddings find register identification result improved multilingual training even substantial number annotation available target language
propose objectoriented neural programming oonp framework semantically parsing document specific domain basically oonp read document parses predesigned objectoriented data structure reflects domainspecific semantics document oonp parser model semantic parsing decision process neural netbased reader sequentially go document build update intermediate ontology process summarize partial understanding text oonp support big variety form symbolic differentiable representing state document rich family operation compose representation oonp parser trained supervision different form strength including supervised learning sl reinforcement learning rl hybrid two experiment synthetic realworld document parsing task shown oonp learn handle fairly complicated ontology training data modest size
discus related story compared character investigate character graph social network order measure evolution character importance time illustrate chose siegfriedsigurd myth may come merovingian king named sigiberthus nibelungenlied volsunga saga history frank three resource used
tutorial target researcher practitioner interested ml technology nlp indirect supervision particular present diverse thread indirect supervision study try answer following question provide supervision target task data corresponds related task ii human use exhaustive supervision rely occasional feedback learn incidental signal various source effectively incorporate supervision machine learning iii leverage multimodal supervision help nlp end discus several line research address challenge including indirect supervision handle output spanning moderate size open space ii use sparsely occurring incidental signal partial label noisy label knowledgebased constraint crossdomain crosstask annotationsall statistical association task iii principled way measure understand incidental signal contribute target task iv indirect supervision visionlanguage signal conclude tutorial outlining direction investigation
unsupervised crosslingual language representation initialization method together mechanism denoising backtranslation advanced unsupervised neural machine translation unmt achieved impressive result meanwhile still several challenge unmt tutorial first introduces background latest progress unmt examine number challenge unmt give empirical result well technology currently hold
introduce generic seqseq parsing framework cast constituency parsing problem syntactic discourse parsing series conditional splitting decision parsing model estimate conditional probability distribution possible splitting point given text span support efficient topdown decoding linear number node conditional splitting formulation together efficient beam search inference facilitate structural consistency without relying expensive structured inference crucially discourse analysis show formulation discourse segmentation framed special case parsing allows u perform discourse parsing without requiring segmentation prerequisite experiment show model achieves good result standard syntactic parsing task setting withwithout pretrained representation rival stateoftheart sota method computationally expensive discourse parsing method outperforms sota good margin
autoregressive ar nonautoregressive nar model superiority performance latency combining one model may take advantage current combination framework focus integration multiple decoding paradigm unified generative model eg masked language model however generalization harmful performance due gap training objective inference paper aim close gap preserving original objective ar nar unified framework specifically propose directional transformer diformer jointly modelling ar nar three generation direction lefttoright righttoleft straight newly introduced direction variable work controlling prediction token specific dependency direction unification achieved direction successfully preserve original dependency assumption used ar nar retaining generalization performance experiment wmt benchmark demonstrate diformer outperforms current unitedmodelling work bleu point ar nar decoding also competitive stateoftheart independent ar nar model
study influence context human evaluate complexity sentence english collect new dataset sentence sentence rated perceived complexity within different contextual window carry indepth analysis detect linguistic feature correlate complexity judgment degree agreement among annotator train several regression model using either explicit linguistic feature contextualized word embeddings predict mean complexity value assigned sentence different contextual window well standard deviation result show model leveraging explicit feature capturing morphosyntactic syntactic phenomenon perform always better especially access feature extracted contextual sentence
sarcasm common phenomenon social medium inherently difficult analyse automatically often human important effect sentiment usually ignored social medium analysis considered tricky handle exist system detect sarcasm almost work carried studying effect sarcasm sentiment tweet incorporating automatic tool sentiment analysis perform analysis effect sarcasm scope polarity tweet compiled number rule enable u improve accuracy sentiment analysis sarcasm known present consider particular effect sentiment sarcasm contained hashtags developed hashtag tokeniser gate sentiment sarcasm found within hashtags detected easily according experiment hashtag tokenisation achieves precision sarcasm detection achieved precision polarity detection
web page offer reliable metadata concerning creation date time however getting document creation time necessary step allowing apply temporal normalization system web page paper present dctfinder system parses web page extract content title creation date web page dctfinder combine heuristic title detection supervised learning conditional random field crfs document date extraction rulebased creation time recognition using system allows deep efficient temporal analysis web page evaluation three corpus english french web page indicates tool extract document creation time reasonably high accuracy dctfinder made freely available urlhttpsourceforgenetprojectsdctfinder well resource vocabulary annotated document built training evaluating system english french english trained model
paper present novel bilingual czech english dataset called shadowsense developed purpose word sense induction wsi evaluation unlike existing wsi datasets shadowsense annotated multiple annotator whose interannotator agreement represents key reliability score used evaluation system automatically inducing word sens paper clarify motivation approach describe dataset detail provide evaluation three neural wsi system showing substantial difference compared traditional evaluation paradigm
endtoend sign language translation slt aim directly convert sign language video spoken language text without intermediate representation challenging due data scarcity labeled data modality gap sign video text tackle challenge propose novel crossmodality data augmentation xmda framework transfer powerful glosstotext translation capability endtoend sign language translation ie videototext specifically xmda consists two key component crossmodality mixup crossmodality knowledge distillation former one explicitly encourages alignment sign video feature gloss embeddings bridge modality gap latter one utilizes generation knowledge glosstotext teacher model guide spoken language text generation experimental result two widely used slt datasets ie phoenixt csldaily demonstrate proposed xmda framework significantly consistently outperforms baseline model extensive analysis confirm claim xmda enhances endtoend sign language translation reducing representation distance sign video gloss well improving translation lowfrequency word long sentence
empathy requires perspectivetaking empathetic response require person reason another experienced communicate understanding language however nlp approach empathy explicitly model alignment process introduce new approach recognizing alignment empathetic speech grounded appraisal theory introduce new dataset k spanlevel annotation different type appraisal person experience k empathetic alignment speaker observer speech computational experiment show appraisal alignment accurately recognized experiment reddit conversation find appraisal capture meaningful grouping behavior response minimal alignment however find mental health professional engage substantially empathetic alignment
present edm novel approach event detection ed based decomposing reformulating ed finetuning atomic subtasks edm enhances knowledge transfer mitigating prediction error propagation inherent pipelined approach edm infers datasetspecific knowledge required complex primary task atomic task making adaptable set event type evaluate edm multiple ed datasets achieving stateoftheart result ram v f competitive performance wikievents maven mlee present ablation study rare event type textless instance training data maven edm achieves textasciitilde f best author knowledge first analyze ed performance nonstandard event configuration ie multiword multiclass trigger experimental result show edm achieves textasciitilde exact match accuracy multiword trigger textasciitilde prediction accuracy multiclass trigger work establishes effectiveness edm enhancing performance complex information extraction task
paper address automatic recognition telicity aspectual notion telic event includes natural endpoint walked home atelic event walked around recognizing difference prerequisite temporal natural language understanding english classification task difficult telicity covert linguistic category contrast slavic language aspect part verb meaning even available machinereadable dictionary contribution follows successfully leverage additional silver standard training data form projected annotation parallel englishczech data well context information improving automatic telicity classification english significantly compared previous work also create new data set english text manually annotated telicity
propose contextualised graph convolution network multiple dependencybased subgraphs relation extraction novel method construct multiple subgraphs using word shortest dependency path word linked entity dependency parse proposed graph convolution operation performed resulting multiple subgraphs obtain informative feature useful relation extraction experimental result show proposed method achieves superior performance existing gcnbased model achieving stateoftheart performance crosssentence nary relation extraction dataset semeval task sentencelevel relation extraction dataset model also achieves comparable performance sota tacred dataset
aim paper present system semantic text annotation called inforex inforex webbased system designed managing annotating text corpus semantic level including annotation named entity ne anaphora word sense disambiguation wsd relation named entity system also support manual text cleanup automatic text preprocessing including text segmentation morphosyntactic analysis word selection word sense annotation inforex accessed standardcompliant web browser supporting javascript user interface form dynamic html page using ajax technology server part system written php data stored mysql database system make use external tool installed server accessed via web service document stored database original format either plain text xml html tokenization sentence segmentation optional stored separate table token stored pair value representing index first last character token set feature representing morphosyntactic information
present encoderdecoder model semantic parsing ucca semeval task encoder bilstm decoder us recursive selfattention proposed model alleviates challenge feature engineering traditional transitionbased graphbased parser resulting parser simple proved effective semantic parsing task
unlike domain medical text inevitably accompanied private information sharing copying text strictly restricted however training medical relation extraction model requires collecting privacysensitive text storing one machine come conflict privacy protection paper propose privacypreserving medical relation extraction model based federated learning enables training central model single piece private local data shared exchanged though federated learning distinct advantage privacy protection suffers communication bottleneck mainly caused need upload cumbersome local parameter overcome bottleneck leverage strategy based knowledge distillation strategy us uploaded prediction ensemble local model train central model without requiring uploading local parameter experiment three publicly available medical relation extraction datasets demonstrate effectiveness method
mathematical language scientific communication educational scenario important yet relatively understudied compared natural language recent work mathematical language focus either representing standalone mathematical expression especially natural tree format mathematical reasoning pretrained natural language model existing work jointly modeling generating natural mathematical language simply treat mathematical expression text without accounting rigid structural property mathematical expression paper propose series modification existing language model jointly represent generate text math representing mathematical expression sequence node token operator tree format using math symbol tree position embeddings preserve semantic structural property mathematical expression using constrained decoding method generate mathematically valid expression ground modification gpt resulting model mathgpt demonstrate outperforms baseline mathematical expression generation task
automated essay scoring aes aim score essay written given prompt defines writing topic existing aes system assume grade essay prompt used training assign holistic score however setting conflict realeducation situation pregraded essay particular prompt lacking detailed trait score subrubrics required thus predicting various trait score unseenprompt essay called crossprompt essay trait scoring remaining challenge aes paper propose robust model prompt trait relationaware crossprompt essay trait scorer encode promptaware essay representation essayprompt attention utilizing topiccoherence feature extracted topicmodeling mechanism without access labeled data therefore model considers prompt adherence essay even crossprompt setting facilitate multitrait scoring design traitsimilarity loss encapsulates correlation trait experiment prove efficacy model showing stateoftheart result prompt trait significant improvement lowresourceprompt inferior trait indicate model strength
understanding event description central aspect language processing current approach focus overwhelmingly single sentence document aggregating information event across document offer much richer understanding end present famus new corpus wikipedia passage report event paired underlying genrediverse nonwikipedia source article event event crosssentence argument report source annotated framenet providing broad coverage different event type present result two key event understanding task enabled famus source validationdetermining whether document valid source target report eventand crossdocument argument extractionfulldocument argument extraction target event report correct source article
paper examine different meaning representation commonly used different natural language application today discus limit term aspect natural language meaning modelling term aspect application used
esp game also known google image labeler demonstrated crowd could perform task straightforward human challenging computer providing label image game facilitated task basic image labeling however label generated nonspecific limited ability distinguish similar image one another limiting ability search task annotating image visually impaired training computer vision machine algorithm paper describe cluemein entertaining webbased game purpose generates detailed image label esp game conduct experiment generate specific image label show result lead improvement accuracy image search image label generated esp game using public dataset
topological data analysis tda focus inherent shape spatial data may provide useful method explore spatial representation linguistic data embeddings become central nlp paper aim introduce tda researcher language technology use tda represent document structure socalled story tree story tree hierarchical representation created semantic vector representation sentence via persistent homology used identify clearly visualize prominent component story line showcase potential using story tree create extractive summary news story
